{
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-app-service-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.0546,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.334,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-application-gateway-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33331,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-containers-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33331,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-cosmos-db-document-db-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-cost-management-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-data-factory-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05457,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3333,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure API Management monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "API Management Service data"
      ],
      "title": "Azure API Management monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "c14b2e2440545d9d2c6d4d50df72dd404770d209",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-api-management-monitoring-integration/",
      "published_at": "2021-06-15T13:12:04Z",
      "updated_at": "2021-03-16T06:10:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Microsoft Azure API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your Azure service in New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Azure API Management integration: New Relic polling interval: 5 minutes View and use data To view your integration data, go to one.newrelic.com > Infrastructure > Azure and select an integration. Data is attached to the following event type: Entity Event type Provider Service AzureApiManagementServiceSample AzureApiManagementService For more on how to use your data, see Understand and use integration data. Metric data This integration collects Azure API Management data for Service. API Management Service data Metric Unit Description totalRequests Count The total number of gateway requests in a given period. successfulRequests Count The total number of successful gateway requests in a given period. unauthorizedRequests Count The total number of unauthorized gateway requests in a given period. failedRequests Count The total number of failed gateway requests in a given period. otherRequests Count The total number of gateway requests in a given period that do not fall into the successful, unauthorized, or failed categories. durationMilliseconds Milliseconds The time between when API Management receives a request from a client and when it returns a response to the client. capacityPercent Percent Indicator of load on an API Management instance. eventHubTotalEvents Count The total number of events sent to EventHub from API Management in a given period. eventHubSuccessfulEvents Count The total number of successful EventHub events in a given period. eventHubTotalFailedEvents Count The total number of failed EventHub events in a given period. eventHubRejectedEvents Count The total number of rejected EventHub events (wrong configuration or unauthorized) in a given period. eventHubThrottledEvents Count The total number of throttled EventHub events in a given period. eventHubTimedoutEvents Count The total number of timed out EventHub events in a given period. eventHubDroppedEvents Count The total number of events skipped because of queue size limit reached in a given period. eventHubTotalBytesSentBytes Bytes The total size of EventHub events in bytes in a given period.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.56277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> API Management monitoring <em>integration</em>",
        "sections": "<em>Azure</em> API Management monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic offers an integration for reporting your <em>Microsoft</em> <em>Azure</em> API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your <em>Azure</em> service"
      },
      "id": "603ea20164441f8ed44e8872"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    },
    {
      "sections": [
        "Azure API Management monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "API Management Service data"
      ],
      "title": "Azure API Management monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "c14b2e2440545d9d2c6d4d50df72dd404770d209",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-api-management-monitoring-integration/",
      "published_at": "2021-06-15T13:12:04Z",
      "updated_at": "2021-03-16T06:10:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Microsoft Azure API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your Azure service in New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Azure API Management integration: New Relic polling interval: 5 minutes View and use data To view your integration data, go to one.newrelic.com > Infrastructure > Azure and select an integration. Data is attached to the following event type: Entity Event type Provider Service AzureApiManagementServiceSample AzureApiManagementService For more on how to use your data, see Understand and use integration data. Metric data This integration collects Azure API Management data for Service. API Management Service data Metric Unit Description totalRequests Count The total number of gateway requests in a given period. successfulRequests Count The total number of successful gateway requests in a given period. unauthorizedRequests Count The total number of unauthorized gateway requests in a given period. failedRequests Count The total number of failed gateway requests in a given period. otherRequests Count The total number of gateway requests in a given period that do not fall into the successful, unauthorized, or failed categories. durationMilliseconds Milliseconds The time between when API Management receives a request from a client and when it returns a response to the client. capacityPercent Percent Indicator of load on an API Management instance. eventHubTotalEvents Count The total number of events sent to EventHub from API Management in a given period. eventHubSuccessfulEvents Count The total number of successful EventHub events in a given period. eventHubTotalFailedEvents Count The total number of failed EventHub events in a given period. eventHubRejectedEvents Count The total number of rejected EventHub events (wrong configuration or unauthorized) in a given period. eventHubThrottledEvents Count The total number of throttled EventHub events in a given period. eventHubTimedoutEvents Count The total number of timed out EventHub events in a given period. eventHubDroppedEvents Count The total number of events skipped because of queue size limit reached in a given period. eventHubTotalBytesSentBytes Bytes The total size of EventHub events in bytes in a given period.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.56277,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> API Management monitoring <em>integration</em>",
        "sections": "<em>Azure</em> API Management monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic offers an integration for reporting your <em>Microsoft</em> <em>Azure</em> API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your <em>Azure</em> service"
      },
      "id": "603ea20164441f8ed44e8872"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-postgresql-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-event-hub-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-express-route-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.0545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-firewalls-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.0545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33327,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-front-door-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.0545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-functions-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.0545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-key-vault-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-load-balancer-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-logic-apps-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05447,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-machine-learning-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-power-bi-dedicated-capacities-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33324,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-redis-cache-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-service-bus-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-service-fabric-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-sql-database-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-sql-managed-instances-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33388,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.3332,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-storage-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-virtual-machine-scale-sets-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05441,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-virtual-machines-scale-sets-monitoring-integration": [
    {
      "sections": [
        "Azure virtual machine scale sets monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Virtual machine scale sets ScaleSet data"
      ],
      "title": "Azure virtual machine scale sets monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "2b25b6720032817e09a6e844210f020b3a4fc98b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-virtual-machine-scale-sets-monitoring-integration/",
      "published_at": "2021-06-15T12:05:19Z",
      "updated_at": "2021-03-16T04:41:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Azure virtual machine scale sets data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your Azure service in New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Azure virtual machine scale sets integration: New Relic polling interval: 5 minutes Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and select an integration. You can query and explore your data using the following event type: Entity Event type Provider ScaleSet AzureVirtualMachineScaleSetSample AzureVirtualMachineScaleSet For more on how to use your data, see Understand and use integration data. Metric data This integration collects Azure virtual machine scale sets data for ScaleSet. Virtual machine scale sets ScaleSet data Metric Unit Description cpuPercent Percent The percentage of allocated compute units that are currently in use by the Virtual Machine(s) networkInBytes Bytes The number of billable bytes received on all network interfaces by the Virtual Machine(s) (Incoming Traffic) networkOutBytes Bytes The number of billable bytes out on all network interfaces by the Virtual Machine(s) (Outgoing Traffic) diskReadBytes Bytes Bytes read from disk during monitoring period diskWriteBytes Bytes Bytes written to disk during monitoring period diskReadOperationsCountPerSecond CountPerSecond Disk Read IOPS diskWriteOperationsCountPerSecond CountPerSecond Disk Write IOPS cpuCreditsRemaining Count Total number of credits available to burst cpuCreditsConsumed Count Total number of credits consumed by the Virtual Machine dataDiskReadBytesCountPerSecond CountPerSecond Bytes/Sec read from a single disk during monitoring period dataDiskWriteBytesCountPerSecond CountPerSecond Bytes/Sec written to a single disk during monitoring period dataDiskReadOperationsCountPerSecond CountPerSecond Read IOPS from a single disk during monitoring period dataDiskWriteOperationsCountPerSecond CountPerSecond Write IOPS from a single disk during monitoring period dataDiskQueueDepth Count Data Disk Queue Depth(or Queue Length) osDiskReadBytesCountPerSecond CountPerSecond Bytes/Sec read from a single disk during monitoring period for OS disk osDiskWriteBytesCountPerSecond CountPerSecond Bytes/Sec written to a single disk during monitoring period for OS disk osDiskReadOperationsCountPerSecond CountPerSecond Read IOPS from a single disk during monitoring period for OS disk osDiskWriteOperationsCountPerSecond CountPerSecond Write IOPS from a single disk during monitoring period for OS disk osDiskQueueDepth Count OS Disk Queue Depth(or Queue Length) inboundFlows Count Inbound Flows are number of current flows in the inbound direction (traffic going into the VM) outboundFlows Count Outbound Flows are number of current flows in the outbound direction (traffic going out of the VM) inboundFlowsMaximumCreationRateCountPerSecond CountPerSecond The maximum creation rate of inbound flows (traffic going into the VM) outboundFlowsMaximumCreationRateCountPerSecond CountPerSecond The maximum creation rate of outbound flows (traffic going out of the VM) premiumDataDiskCacheReadHitPercent Percent Premium Data Disk Cache Read Hit premiumDataDiskCacheReadMissPercent Percent Premium Data Disk Cache Read Miss premiumOSDiskCacheReadHitPercent Percent Premium OS Disk Cache Read Hit premiumOSDiskCacheReadMissPercent Percent Premium OS Disk Cache Read Miss networkInTotalBytes Bytes The number of bytes received on all network interfaces by the Virtual Machine(s) (Incoming Traffic) networkOutTotalBytes Bytes The number of bytes out on all network interfaces by the Virtual Machine(s) (Outgoing Traffic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1231.0979,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> <em>virtual</em> <em>machine</em> <em>scale</em> <em>sets</em> <em>monitoring</em> <em>integration</em>",
        "sections": "<em>Azure</em> <em>virtual</em> <em>machine</em> <em>scale</em> <em>sets</em> <em>monitoring</em> <em>integration</em>",
        "tags": "Microsoft <em>Azure</em> <em>integrations</em>",
        "body": " data. Metric data This <em>integration</em> collects <em>Azure</em> <em>virtual</em> machine <em>scale</em> <em>sets</em> data for <em>ScaleSet</em>. <em>Virtual</em> machine <em>scale</em> <em>sets</em> <em>ScaleSet</em> data Metric Unit Description cpuPercent Percent The percentage of allocated compute units that are currently in use by the <em>Virtual</em> Machine(s) networkInBytes Bytes"
      },
      "id": "603ea1cfe7b9d2a8342a0819"
    },
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 168.02628,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs <em>monitoring</em> <em>integration</em>",
        "sections": "<em>Azure</em> VMs <em>monitoring</em> <em>integration</em>",
        "tags": "Microsoft <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>monitoring</em> provides an <em>integration</em> for Microsoft <em>Azure</em> <em>Virtual</em> <em>Machines</em> (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this <em>integration</em> and describes the data that can be captured. Features New Relic&#x27;s <em>integration</em>"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Introduction to the Kubernetes integration",
        "Get started: Install the Kubernetes integration",
        "Tip",
        "Why it matters",
        "Navigate all your Kubernetes events",
        "Bring your cluster logs to New Relic",
        "Check the source code"
      ],
      "title": "Introduction to the Kubernetes integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "c641d1367f1f8fd2b589a2707112759becae609b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration/",
      "published_at": "2021-06-16T01:58:24Z",
      "updated_at": "2021-06-02T01:43:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration gives you full observability into the health and performance of your environment, no matter whether you run Kubernetes on-premises or in the cloud. With our cluster explorer, you can cut through layers of complexity to see how your cluster is performing, from the heights of the control plane down to applications running on a single pod. one.newrelic.com > Kubernetes cluster explorer: The cluster explorer is our powerful, fully visual answer to the challenges associated with running Kubernetes at a large scale. You can see the power of the Kubernetes integration in the cluster explorer, where the full picture of a cluster is made available on a single screen: nodes and pods are visualized according to their health and performance, with pending and alerting nodes in the innermost circles. Predefined alert conditions help you troubleshoot issues right from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes integration We have an automated installer to help you with many types of installations: servers, virtual machines, and unprivileged environments. It can also help you with installations in managed services or platforms, but you'll need to review a few preliminary notes before getting started. Here's what the automated installer does: Asks for the cluster name and namespace of the integration. Asks for additional setup options, such as Kube state metrics. Asks for the installation method: manifest file or Helm. Generates either the manifest or Helm chart. Read the install docs Start the installer Tip If your New Relic account is in the EU region, access the automated installer from one.eu.newrelic.com. Why it matters Governing the complexity of Kubernetes can be challenging; there's so much going on at any given moment, with containers being created and deleted in a matter of minutes, applications crashing, and resources being consumed unexpectedly. Our integration helps you navigate Kubernetes abstractions across on-premises, cloud, and hybrid deployments. In New Relic, you can build your own charts and query all your Kubernetes data, which our integration collects by instrumenting the container orchestration layer. This gives you additional insight into nodes, namespaces, deployments, replica sets, pods, and containers. one.newrelic.com > Dashboards: Using the query builder you can turn any query on Kubernetes data to clear visuals. With the Kubernetes integration you can also: Link your APM data to Kubernetes to measure the performance of your web and mobile applications, with metrics such as request rate, throughput, error rate, and availability. Monitor services running on Kubernetes, such as Apache, NGINX, Cassandra, and many more (see our tutorial for monitoring Redis on Kubernetes). Create new alert policies and alert conditions based on your Kubernetes data, or extend the predefined alert conditions. These features are in addition to the data New Relic already reports for containerized processes running on instrumented hosts. Navigate all your Kubernetes events The Kubernetes events integration, which is installed separately, watches for events happening in your Kubernetes clusters and sends those events to New Relic. Events data is then visualized in the cluster explorer. To set it up, check the Kubernetes events box in step 3 of our install wizard, or follow the instructions. one.newrelic.com > Kubernetes cluster explorer > Events: Browse and filter all your Kubernetes events, and dig into application logs and infrastructure data. Bring your cluster logs to New Relic Our Kubernetes plugin for log monitoring can collect all your cluster's logs and send them to our platform, so that you can set up new alerts and charts. To set it up, check the Log data box in step 3 of our install wizard, or follow the instructions. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or you can create your own fork and build it. For more information, see the README.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.99825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Kubernetes <em>integration</em>",
        "sections": "Introduction to the Kubernetes <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " from the start. Clicking each node reveals its status and how each app is performing. Get started: Install the Kubernetes <em>integration</em> We have an automated installer to help you with many types of installations: servers, <em>virtual</em> <em>machines</em>, and unprivileged environments. It can also help you"
      },
      "id": "6043a212196a678d86960f46"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-virtual-network-monitoring-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.0544,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration": [
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33386,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33319,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    },
    {
      "sections": [
        "Azure API Management monitoring integration",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "API Management Service data"
      ],
      "title": "Azure API Management monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "c14b2e2440545d9d2c6d4d50df72dd404770d209",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-api-management-monitoring-integration/",
      "published_at": "2021-06-15T13:12:04Z",
      "updated_at": "2021-03-16T06:10:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers an integration for reporting your Microsoft Azure API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your Azure service in New Relic. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Azure API Management integration: New Relic polling interval: 5 minutes View and use data To view your integration data, go to one.newrelic.com > Infrastructure > Azure and select an integration. Data is attached to the following event type: Entity Event type Provider Service AzureApiManagementServiceSample AzureApiManagementService For more on how to use your data, see Understand and use integration data. Metric data This integration collects Azure API Management data for Service. API Management Service data Metric Unit Description totalRequests Count The total number of gateway requests in a given period. successfulRequests Count The total number of successful gateway requests in a given period. unauthorizedRequests Count The total number of unauthorized gateway requests in a given period. failedRequests Count The total number of failed gateway requests in a given period. otherRequests Count The total number of gateway requests in a given period that do not fall into the successful, unauthorized, or failed categories. durationMilliseconds Milliseconds The time between when API Management receives a request from a client and when it returns a response to the client. capacityPercent Percent Indicator of load on an API Management instance. eventHubTotalEvents Count The total number of events sent to EventHub from API Management in a given period. eventHubSuccessfulEvents Count The total number of successful EventHub events in a given period. eventHubTotalFailedEvents Count The total number of failed EventHub events in a given period. eventHubRejectedEvents Count The total number of rejected EventHub events (wrong configuration or unauthorized) in a given period. eventHubThrottledEvents Count The total number of throttled EventHub events in a given period. eventHubTimedoutEvents Count The total number of timed out EventHub events in a given period. eventHubDroppedEvents Count The total number of events skipped because of queue size limit reached in a given period. eventHubTotalBytesSentBytes Bytes The total size of EventHub events in bytes in a given period.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 155.56276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> API Management monitoring <em>integration</em>",
        "sections": "<em>Azure</em> API Management monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic offers an integration for reporting your <em>Microsoft</em> <em>Azure</em> API Management data. This document explains how to activate this integration and describes the data that can be reported. Activate integration To enable the integration follow standard procedures to activate your <em>Azure</em> service"
      },
      "id": "603ea20164441f8ed44e8872"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vpn-gateway-integration": [
    {
      "sections": [
        "Azure VMs monitoring integration",
        "Features",
        "Requirements",
        "Activate integration",
        "Important",
        "Configuration and polling",
        "Find and use data",
        "Inventory data",
        "Other system data",
        "Troubleshooting"
      ],
      "title": "Azure VMs monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "b77f3bb6f9dd73582e5789d2c2553a946de28e2b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-vms-monitoring-integration/",
      "published_at": "2021-06-15T13:20:52Z",
      "updated_at": "2021-05-21T18:18:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure monitoring provides an integration for Microsoft Azure Virtual Machines (VMs) that reports data from your Azure VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic's integration for Azure Virtual Machines reports data about your VMs service, like the VM ID, the VM size, the availability set, and the region name. You can monitor and alert on your Azure VMs data from New Relic, and you can create custom queries and chart dashboards. Requirements Requirements include: New Relic infrastructure agent installed with Infrastructure agent version 1.0.775 or higher. (Update the infrastructure agent.) New Relic Azure integrations activated Activate integration To enable this integration follow standard procedures to activate your Azure service in New Relic. Important You must install the infrastructure agent on each VM to see metrics from that host. Connecting your Azure subscription allows New Relic to access VM metadata. Configuration and polling You can change the polling frequency and filter data using configuration options. Default polling information for the Virtual Machines integration: Polling interval: 5 minutes Resolution: 1 data point per minute Find and use data To find your integration data, go to one.newrelic.com > Infrastructure > Azure and look for the integration. You can query and explore your data using the AzureVirtualMachineSample event type. The provider value is AzureVirtualMachine. For more on how to find and use integration data, see Understand and use data. Inventory data Inventory data is information about your system's state and configuration. For details on how to find and use inventory data, see Understand and use data. The Azure Virtual Machines integration reports this inventory data: availabilitySet bootDiagnosticsEnabled image linuxConfiguration name networkInterfaces osDisk provisioningState regionName resourceGroupName (deprecates resourceGroup) vmId vmSize windowsConfiguration Other system data The Azure Virtual Machines integration also collects the following attributes about the service and its configuration: Region Availability zone Instance type Instance ID Troubleshooting If you use Host not reporting alert conditions, the importing of Azure metadata for your VMs will change the hosts registry and result in false alert notifications. To prevent false positives: For each Azure instance, disable its Host not reporting alert condition. Update the infrastructure agent for all instances that used this alert condition. Re-enable each Host not reporting alert condition.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.05438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "sections": "<em>Azure</em> VMs monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure monitoring provides an integration for <em>Microsoft</em> <em>Azure</em> Virtual Machines (VMs) that reports data from your <em>Azure</em> VMs service to New Relic. This document explains how to activate this integration and describes the data that can be captured. Features New Relic&#x27;s integration"
      },
      "id": "6044e56164441faf31378f07"
    },
    {
      "sections": [
        "Azure Database for MySQL monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "Find and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mysql/server/"
      ],
      "title": "Azure Database for MySQL monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "8155643271b086f6fee3b52ca040ff863fab6ed9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mysql-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:03:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the Azure Database for MySQL service, which provides fully managed, enterprise-ready MySQL Community database as a service. The service provides high availability, elastic scaling, automatic backups, and data protection at-rest and in-motion. Using New Relic, you can: View Azure Database for MySQL data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure. Configuration and polling You can change the polling frequency and filter data using configuration options. New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for MySQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute Find and use data To explore your integration data, go to one.newrelic.com > Infrastructure > Azure > (select an integration). Data about a single database is attached to the AzureMySqlServerSample event type, with a provider value of AzureMySqlServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. azure/mysql/server/ administratorLogin configuration databaseNames databases domainName earliestRestoreDate firewalls geoRedundantBackup isDataWarehouse isReplica MasterServerid maxConnections name regionName replicaCapacity resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MySQL monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MySQL metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers database data from the <em>Azure</em> Database"
      },
      "id": "603ec29a196a677188a83de6"
    },
    {
      "sections": [
        "Azure Database for MariaDB monitoring integration",
        "Features",
        "Activate integration",
        "Configuration and polling",
        "View and use data",
        "Metric data",
        "Database sample metrics",
        "Inventory data",
        "azure/mariadb/server"
      ],
      "title": "Azure Database for MariaDB monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Azure integrations list"
      ],
      "external_id": "048605d109fc89086a983491bfbb1280923ea186",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/azure-integrations-list/azure-database-mariadb-monitoring-integration/",
      "published_at": "2021-06-15T13:14:23Z",
      "updated_at": "2021-05-16T00:02:29Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's integrations include an integration for reporting your Microsoft Azure Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the Azure Database for MariaDB service, which provides a fully managed, enterprise-ready database as a service. MariaDB provides predictable performance and scalability for applications using open-source tools and platforms. Using New Relic, you can: View Azure Database for MariaDB data in pre-built dashboards. Run custom queries and visualize the data in New Relic One. Create alert conditions to notify you of changes in data. Activate integration Follow standard procedures to activate your Azure service in New Relic Infrastructure, using the generic Reader role. Configuration and polling New Relic queries your Azure Database services according to a default polling interval, which varies depending on the integration. For Azure Database for PostgreSQL integrations: Polling interval: 5 minutes (maximum recommended polling frequency: 1 hour) Resolution: 1 data point per minute You can change the polling frequency and filter data using configuration options. View and use data To explore your integration data: Go to one.newrelic.com > Infrastructure > Azure > (select an integration). In New Relic, data about a single database is attached to the AzureMariaDbServerSample event type, with a provider value of AzureMariaDbServer. Metric data This integration collects the following metric data. Database sample metrics Metric Description activeConnections Count of active connections. backupStorageUsedBytes Backup storage used, in bytes. connectionsFailed Count of failed connections. cpuPercent Percentage of CPU used. ioConsumptionPercent Percentage of I/O consumption used. memoryPercent Percentage of memory used. networkEgressBytes Network Out across active connections, in bytes. networkIngressBytes Network In across active connections, in bytes. secondsBehindMaster Replication lag, in seconds. serverlogStorageLimitBytes Server log storage limit, in bytes. serverlogStoragePercent Percentage of server log storage used. serverlogStorageUsageBytes Server log storage used, in bytes. storageLimitBytes Amount of storage available, in bytes. storagePercent Percentage of available storage used. storageUsedBytes Amount of storage used, in bytes. Inventory data This integration collects the following inventory data about your system's state and configuration. For more information, see the Microsoft Azure documentation for MariaDB. azure/mariadb/server administratorLogin configuration databaseNames databases, including id, name, type, charset, and collation domainName earliestRestoreDate firewalls, including id, name, type, startIpAddress, and endIpAddress geoRedundantBackup id isReplica masterServerId (only for a replica server) maxConnections name regionName replicaCapacity (only for a replica server) replicationRole (only for a replica server) resourceGroupName skuCapacity skuFamily skuName skuTier sslEnforcement storageAutoGrow tags type userVisibleState version",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 179.33318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "sections": "<em>Azure</em> Database for MariaDB monitoring <em>integration</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>integrations</em> include an integration for reporting your <em>Microsoft</em> <em>Azure</em> Database for MariaDB metrics and inventory data to New Relic. This document explains how to activate the integration and describes the data reported. Features New Relic gathers data from the <em>Azure</em> Database"
      },
      "id": "603ea5b6196a674f45a83df2"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/get-started/activate-azure-integrations": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Tip",
        "Requirements",
        "Features"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f99e6127548c87b6d54587ee8fba6f03ef3fdf2e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-06-15T13:21:50Z",
      "updated_at": "2021-03-13T03:33:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as New Relic APM's .NET support for Azure. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.97906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Azure</em> monitoring <em>integrations</em>",
        "sections": "Introduction to <em>Azure</em> monitoring <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "Our <em>Microsoft</em> <em>Azure</em> <em>integrations</em> allow you to monitor and report data about your <em>Azure</em> services to New Relic, providing a comprehensive view of your entire architecture in one place. The <em>Azure</em> <em>integrations</em> are not the same as New Relic APM&#x27;s .NET support for <em>Azure</em>. Tip To use <em>Azure</em> <em>integrations</em>"
      },
      "id": "6044e562e7b9d2e5c15799f8"
    },
    {
      "sections": [
        "Polling intervals for Azure integrations",
        "View polling data",
        "New Relic polling intervals"
      ],
      "title": "Polling intervals for Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "82db3eae120c4318365cf0d0e5bfee69930b969f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/getting-started/polling-intervals-azure-integrations/",
      "published_at": "2021-06-15T13:23:01Z",
      "updated_at": "2021-03-13T03:47:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Azure integrations query your Azure services according to a polling interval specific to the integration. The polling interval applies for every Azure entity related to the integrated service. For example, if you have thirteen CosmosDB instances, each of the thirteen instances will be polled every five minutes. View polling data After you activate an Azure integration, New Relic starts polling data from Azure and makes the data accessible through infrastructure Inventory and New Relic dashboards. You can query the Azure data along with additional data imported from any other New Relic features. You can also view dashboard data for a specific integration or across your account. For visualizations of polling intervals, API calls, and other data for your Azure integrations: Go to one.newrelic.com > Infrastructure > Azure. To view data for a specific integration: Select the Dashboards link for the integration's row. New Relic polling intervals For polling and resolution details, see the documentation for a specific integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.39855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Polling intervals for <em>Azure</em> <em>integrations</em>",
        "sections": "Polling intervals for <em>Azure</em> <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>Azure</em> <em>integrations</em> query your <em>Azure</em> services according to a polling interval specific to the integration. The polling interval applies for every <em>Azure</em> entity related to the integrated service. For example, if you have thirteen CosmosDB instances, each of the thirteen instances"
      },
      "id": "6044e560196a671d6f960f72"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.04232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/get-started/azure-integration-metrics": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Tip",
        "Requirements",
        "Features"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f99e6127548c87b6d54587ee8fba6f03ef3fdf2e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-06-15T13:21:50Z",
      "updated_at": "2021-03-13T03:33:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as New Relic APM's .NET support for Azure. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.97905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Azure</em> monitoring <em>integrations</em>",
        "sections": "Introduction to <em>Azure</em> monitoring <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "Our <em>Microsoft</em> <em>Azure</em> <em>integrations</em> allow you to monitor and report data about your <em>Azure</em> services to New Relic, providing a comprehensive view of your entire architecture in one place. The <em>Azure</em> <em>integrations</em> are not the same as New Relic APM&#x27;s .NET support for <em>Azure</em>. Tip To use <em>Azure</em> <em>integrations</em>"
      },
      "id": "6044e562e7b9d2e5c15799f8"
    },
    {
      "sections": [
        "Activate Azure integrations",
        "Tip",
        "Requirements",
        "Step 1: Get Azure subscription and tenant IDs",
        "Step 2: Register your app and get ID",
        "Step 3: Create a client secret in Azure",
        "Step 4: Provide permissions to services",
        "Step 5: Add app to New Relic",
        "Explore app data in New Relic Infrastructure's UI"
      ],
      "title": "Activate Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f65679179e13aa1b503b4b95010e296cbe269c29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/activate-azure-integrations/",
      "published_at": "2021-06-15T13:21:50Z",
      "updated_at": "2021-03-13T03:44:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations allow you to report data from specific systems and supplement infrastructure's default, automatic monitoring. The Microsoft Azure integrations report data from various Azure platform services to your New Relic account. This document explains how to activate Azure integrations. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements The Azure integration activation process requires you to: Create a New Relic application and key in Azure. Grant this application access to the Azure services you want to monitor. Place required information in the New Relic's Integrations UI. To use these integration activation instructions directly from the Infrastructure UI, go to one.newrelic.com > Infrastructure > Azure > Add an Azure account. Step 1: Get Azure subscription and tenant IDs To get your Azure account's subscription id and tenantId, use your local terminal if you have Azure's tools installed, or use Azure's Cloud Shell terminal in the Azure portal. Open a terminal with access to your Azure account. Type the following: az account show Copy Copy and save the subscription id and tenantID from the output response for later use. The response should look similar to the response below. The subscription id and tenantID are highlighted. @Azure:~$ az account show { \"environmentName\": \"AzureCloud\", \"id\": \"9ffe9512-f4a2-42dd-1230-518aec34be21\" , \"isDefault\": true, \"name\": \"Beyond Team Sandbox\", \"state\": \"Enabled\", \"tenantId\": \"ac6692da-1231-422f-22a8-9eed6dbe83f1\" , \"user\": { \"name\": \"youremail@domain\", \"type\": \"user\" } Copy Step 2: Register your app and get ID You must have Azure permissions to register your application and copy its Application ID. To register your app in Azure: Sign in to the Azure portal and go to the Azure Active Directory. From Manage, select App registrations > New registration. Enter a name for the application. We recommend that you name your app NewRelic-Integrations. In Redirect URI select Weband add https://www.newrelic.com as the sign-on URI. Create the application by clicking Register. From the Overview of your app, copy the Application (client) ID, and save it for later use. Step 3: Create a client secret in Azure To create a client secret associated with your application: In Azure, under the application you've just created, select Certificates & secrets. Under Client secrets, click on New client secret and then on Add. Copy the value of Client Secret and save it for later use. Step 4: Provide permissions to services Your app must provide Reader permissions for each Azure service you want New Relic to monitor: In the Azure Subscriptions section, select the subscriptions that you want New Relic to monitor. Select Access control (IAM) > Add > Add role assignment. From the Role dropdown, select Reader. From the Select dropdown, select the app's name; for example, NewRelic-Integrations. From Selected members, verify your app name appears, then select Save. Some Azure services, including Azure CosmosDB and Azure VMs, require additional steps. See the Azure integration documentation for the services you want to enable. Step 5: Add app to New Relic Now you can activate the Azure integration in the Infrastructure UI. The UI will require the information you have saved in the previous steps, including: Your Azure account's subscription id and tenantId The application's application ID The application's client secret To add your Azure app to New Relic: Go to one.newrelic.com > Infrastructure > Azure and select the Azure Service you wish to add. Follow the steps in the UI to activate the integration in New Relic. If you have already completed the Azure account steps, skip to the end of the steps to fill out the form. (For Azure account name, enter the name you want to use to identify the account in your Integrations dashboard.) Explore app data in New Relic Infrastructure's UI After you activate an Azure integration, New Relic will start monitoring your Azure data at regular polling intervals. To find and use your data, use the data explorer or go to one.newrelic.com > Infrastructure > Azure",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.54715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Activate <em>Azure</em> <em>integrations</em>",
        "sections": "Activate <em>Azure</em> <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> allow you to report data from specific systems and supplement infrastructure&#x27;s default, automatic monitoring. The <em>Microsoft</em> <em>Azure</em> <em>integrations</em> report data from various <em>Azure</em> platform services to your New Relic account. This document explains how to activate"
      },
      "id": "6044e5a9196a671bfa960f79"
    },
    {
      "sections": [
        "Polling intervals for Azure integrations",
        "View polling data",
        "New Relic polling intervals"
      ],
      "title": "Polling intervals for Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "82db3eae120c4318365cf0d0e5bfee69930b969f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/getting-started/polling-intervals-azure-integrations/",
      "published_at": "2021-06-15T13:23:01Z",
      "updated_at": "2021-03-13T03:47:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Azure integrations query your Azure services according to a polling interval specific to the integration. The polling interval applies for every Azure entity related to the integrated service. For example, if you have thirteen CosmosDB instances, each of the thirteen instances will be polled every five minutes. View polling data After you activate an Azure integration, New Relic starts polling data from Azure and makes the data accessible through infrastructure Inventory and New Relic dashboards. You can query the Azure data along with additional data imported from any other New Relic features. You can also view dashboard data for a specific integration or across your account. For visualizations of polling intervals, API calls, and other data for your Azure integrations: Go to one.newrelic.com > Infrastructure > Azure. To view data for a specific integration: Select the Dashboards link for the integration's row. New Relic polling intervals For polling and resolution details, see the documentation for a specific integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.39855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Polling intervals for <em>Azure</em> <em>integrations</em>",
        "sections": "Polling intervals for <em>Azure</em> <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>Azure</em> <em>integrations</em> query your <em>Azure</em> services according to a polling interval specific to the integration. The polling interval applies for every <em>Azure</em> entity related to the integrated service. For example, if you have thirteen CosmosDB instances, each of the thirteen instances"
      },
      "id": "6044e560196a671d6f960f72"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations": [
    {
      "sections": [
        "Activate Azure integrations",
        "Tip",
        "Requirements",
        "Step 1: Get Azure subscription and tenant IDs",
        "Step 2: Register your app and get ID",
        "Step 3: Create a client secret in Azure",
        "Step 4: Provide permissions to services",
        "Step 5: Add app to New Relic",
        "Explore app data in New Relic Infrastructure's UI"
      ],
      "title": "Activate Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f65679179e13aa1b503b4b95010e296cbe269c29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/activate-azure-integrations/",
      "published_at": "2021-06-15T13:21:50Z",
      "updated_at": "2021-03-13T03:44:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations allow you to report data from specific systems and supplement infrastructure's default, automatic monitoring. The Microsoft Azure integrations report data from various Azure platform services to your New Relic account. This document explains how to activate Azure integrations. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements The Azure integration activation process requires you to: Create a New Relic application and key in Azure. Grant this application access to the Azure services you want to monitor. Place required information in the New Relic's Integrations UI. To use these integration activation instructions directly from the Infrastructure UI, go to one.newrelic.com > Infrastructure > Azure > Add an Azure account. Step 1: Get Azure subscription and tenant IDs To get your Azure account's subscription id and tenantId, use your local terminal if you have Azure's tools installed, or use Azure's Cloud Shell terminal in the Azure portal. Open a terminal with access to your Azure account. Type the following: az account show Copy Copy and save the subscription id and tenantID from the output response for later use. The response should look similar to the response below. The subscription id and tenantID are highlighted. @Azure:~$ az account show { \"environmentName\": \"AzureCloud\", \"id\": \"9ffe9512-f4a2-42dd-1230-518aec34be21\" , \"isDefault\": true, \"name\": \"Beyond Team Sandbox\", \"state\": \"Enabled\", \"tenantId\": \"ac6692da-1231-422f-22a8-9eed6dbe83f1\" , \"user\": { \"name\": \"youremail@domain\", \"type\": \"user\" } Copy Step 2: Register your app and get ID You must have Azure permissions to register your application and copy its Application ID. To register your app in Azure: Sign in to the Azure portal and go to the Azure Active Directory. From Manage, select App registrations > New registration. Enter a name for the application. We recommend that you name your app NewRelic-Integrations. In Redirect URI select Weband add https://www.newrelic.com as the sign-on URI. Create the application by clicking Register. From the Overview of your app, copy the Application (client) ID, and save it for later use. Step 3: Create a client secret in Azure To create a client secret associated with your application: In Azure, under the application you've just created, select Certificates & secrets. Under Client secrets, click on New client secret and then on Add. Copy the value of Client Secret and save it for later use. Step 4: Provide permissions to services Your app must provide Reader permissions for each Azure service you want New Relic to monitor: In the Azure Subscriptions section, select the subscriptions that you want New Relic to monitor. Select Access control (IAM) > Add > Add role assignment. From the Role dropdown, select Reader. From the Select dropdown, select the app's name; for example, NewRelic-Integrations. From Selected members, verify your app name appears, then select Save. Some Azure services, including Azure CosmosDB and Azure VMs, require additional steps. See the Azure integration documentation for the services you want to enable. Step 5: Add app to New Relic Now you can activate the Azure integration in the Infrastructure UI. The UI will require the information you have saved in the previous steps, including: Your Azure account's subscription id and tenantId The application's application ID The application's client secret To add your Azure app to New Relic: Go to one.newrelic.com > Infrastructure > Azure and select the Azure Service you wish to add. Follow the steps in the UI to activate the integration in New Relic. If you have already completed the Azure account steps, skip to the end of the steps to fill out the form. (For Azure account name, enter the name you want to use to identify the account in your Integrations dashboard.) Explore app data in New Relic Infrastructure's UI After you activate an Azure integration, New Relic will start monitoring your Azure data at regular polling intervals. To find and use your data, use the data explorer or go to one.newrelic.com > Infrastructure > Azure",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.54715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Activate <em>Azure</em> <em>integrations</em>",
        "sections": "Activate <em>Azure</em> <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> allow you to report data from specific systems and supplement infrastructure&#x27;s default, automatic monitoring. The <em>Microsoft</em> <em>Azure</em> <em>integrations</em> report data from various <em>Azure</em> platform services to your New Relic account. This document explains how to activate"
      },
      "id": "6044e5a9196a671bfa960f79"
    },
    {
      "sections": [
        "Polling intervals for Azure integrations",
        "View polling data",
        "New Relic polling intervals"
      ],
      "title": "Polling intervals for Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "82db3eae120c4318365cf0d0e5bfee69930b969f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/getting-started/polling-intervals-azure-integrations/",
      "published_at": "2021-06-15T13:23:01Z",
      "updated_at": "2021-03-13T03:47:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Azure integrations query your Azure services according to a polling interval specific to the integration. The polling interval applies for every Azure entity related to the integrated service. For example, if you have thirteen CosmosDB instances, each of the thirteen instances will be polled every five minutes. View polling data After you activate an Azure integration, New Relic starts polling data from Azure and makes the data accessible through infrastructure Inventory and New Relic dashboards. You can query the Azure data along with additional data imported from any other New Relic features. You can also view dashboard data for a specific integration or across your account. For visualizations of polling intervals, API calls, and other data for your Azure integrations: Go to one.newrelic.com > Infrastructure > Azure. To view data for a specific integration: Select the Dashboards link for the integration's row. New Relic polling intervals For polling and resolution details, see the documentation for a specific integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.39855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Polling intervals for <em>Azure</em> <em>integrations</em>",
        "sections": "Polling intervals for <em>Azure</em> <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic&#x27;s <em>Azure</em> <em>integrations</em> query your <em>Azure</em> services according to a polling interval specific to the integration. The polling interval applies for every <em>Azure</em> entity related to the integrated service. For example, if you have thirteen CosmosDB instances, each of the thirteen instances"
      },
      "id": "6044e560196a671d6f960f72"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.04223,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/integrations/microsoft-azure-integrations/getting-started/polling-intervals-azure-integrations": [
    {
      "sections": [
        "Introduction to Azure monitoring integrations",
        "Tip",
        "Requirements",
        "Features"
      ],
      "title": "Introduction to Azure monitoring integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f99e6127548c87b6d54587ee8fba6f03ef3fdf2e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/introduction-azure-monitoring-integrations/",
      "published_at": "2021-06-15T13:21:50Z",
      "updated_at": "2021-03-13T03:33:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Microsoft Azure integrations allow you to monitor and report data about your Azure services to New Relic, providing a comprehensive view of your entire architecture in one place. The Azure integrations are not the same as New Relic APM's .NET support for Azure. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements Check the Azure integrations documentation for requirements on individual integrations. New Relic cannot obtain monitoring data from resources that are located in Azure Government or that were created through the classic deployment model. Features After you activate your Azure integration, New Relic begins to query your Azure platform services according to a regular polling interval. You can use our integrations UI to: View performance data from Integrations dashboards that automatically scale as you make changes to your ecosystem. Manage alert conditions with alerts. Query your data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 130.97905,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Azure</em> monitoring <em>integrations</em>",
        "sections": "Introduction to <em>Azure</em> monitoring <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "Our <em>Microsoft</em> <em>Azure</em> <em>integrations</em> allow you to monitor and report data about your <em>Azure</em> services to New Relic, providing a comprehensive view of your entire architecture in one place. The <em>Azure</em> <em>integrations</em> are not the same as New Relic APM&#x27;s .NET support for <em>Azure</em>. Tip To use <em>Azure</em> <em>integrations</em>"
      },
      "id": "6044e562e7b9d2e5c15799f8"
    },
    {
      "sections": [
        "Activate Azure integrations",
        "Tip",
        "Requirements",
        "Step 1: Get Azure subscription and tenant IDs",
        "Step 2: Register your app and get ID",
        "Step 3: Create a client secret in Azure",
        "Step 4: Provide permissions to services",
        "Step 5: Add app to New Relic",
        "Explore app data in New Relic Infrastructure's UI"
      ],
      "title": "Activate Azure integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Microsoft Azure integrations",
        "Get started"
      ],
      "external_id": "f65679179e13aa1b503b4b95010e296cbe269c29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/microsoft-azure-integrations/get-started/activate-azure-integrations/",
      "published_at": "2021-06-15T13:21:50Z",
      "updated_at": "2021-03-13T03:44:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic infrastructure integrations allow you to report data from specific systems and supplement infrastructure's default, automatic monitoring. The Microsoft Azure integrations report data from various Azure platform services to your New Relic account. This document explains how to activate Azure integrations. Tip To use Azure integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Requirements The Azure integration activation process requires you to: Create a New Relic application and key in Azure. Grant this application access to the Azure services you want to monitor. Place required information in the New Relic's Integrations UI. To use these integration activation instructions directly from the Infrastructure UI, go to one.newrelic.com > Infrastructure > Azure > Add an Azure account. Step 1: Get Azure subscription and tenant IDs To get your Azure account's subscription id and tenantId, use your local terminal if you have Azure's tools installed, or use Azure's Cloud Shell terminal in the Azure portal. Open a terminal with access to your Azure account. Type the following: az account show Copy Copy and save the subscription id and tenantID from the output response for later use. The response should look similar to the response below. The subscription id and tenantID are highlighted. @Azure:~$ az account show { \"environmentName\": \"AzureCloud\", \"id\": \"9ffe9512-f4a2-42dd-1230-518aec34be21\" , \"isDefault\": true, \"name\": \"Beyond Team Sandbox\", \"state\": \"Enabled\", \"tenantId\": \"ac6692da-1231-422f-22a8-9eed6dbe83f1\" , \"user\": { \"name\": \"youremail@domain\", \"type\": \"user\" } Copy Step 2: Register your app and get ID You must have Azure permissions to register your application and copy its Application ID. To register your app in Azure: Sign in to the Azure portal and go to the Azure Active Directory. From Manage, select App registrations > New registration. Enter a name for the application. We recommend that you name your app NewRelic-Integrations. In Redirect URI select Weband add https://www.newrelic.com as the sign-on URI. Create the application by clicking Register. From the Overview of your app, copy the Application (client) ID, and save it for later use. Step 3: Create a client secret in Azure To create a client secret associated with your application: In Azure, under the application you've just created, select Certificates & secrets. Under Client secrets, click on New client secret and then on Add. Copy the value of Client Secret and save it for later use. Step 4: Provide permissions to services Your app must provide Reader permissions for each Azure service you want New Relic to monitor: In the Azure Subscriptions section, select the subscriptions that you want New Relic to monitor. Select Access control (IAM) > Add > Add role assignment. From the Role dropdown, select Reader. From the Select dropdown, select the app's name; for example, NewRelic-Integrations. From Selected members, verify your app name appears, then select Save. Some Azure services, including Azure CosmosDB and Azure VMs, require additional steps. See the Azure integration documentation for the services you want to enable. Step 5: Add app to New Relic Now you can activate the Azure integration in the Infrastructure UI. The UI will require the information you have saved in the previous steps, including: Your Azure account's subscription id and tenantId The application's application ID The application's client secret To add your Azure app to New Relic: Go to one.newrelic.com > Infrastructure > Azure and select the Azure Service you wish to add. Follow the steps in the UI to activate the integration in New Relic. If you have already completed the Azure account steps, skip to the end of the steps to fill out the form. (For Azure account name, enter the name you want to use to identify the account in your Integrations dashboard.) Explore app data in New Relic Infrastructure's UI After you activate an Azure integration, New Relic will start monitoring your Azure data at regular polling intervals. To find and use your data, use the data explorer or go to one.newrelic.com > Infrastructure > Azure",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.54715,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Activate <em>Azure</em> <em>integrations</em>",
        "sections": "Activate <em>Azure</em> <em>integrations</em>",
        "tags": "<em>Microsoft</em> <em>Azure</em> <em>integrations</em>",
        "body": "New Relic infrastructure <em>integrations</em> allow you to report data from specific systems and supplement infrastructure&#x27;s default, automatic monitoring. The <em>Microsoft</em> <em>Azure</em> <em>integrations</em> report data from various <em>Azure</em> platform services to your New Relic account. This document explains how to activate"
      },
      "id": "6044e5a9196a671bfa960f79"
    },
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.042145,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    }
  ],
  "/docs/integrations/mlops-integrations/algorithmia-mlops-integration": [
    {
      "sections": [
        "Configure polling frequency and data collection for cloud integrations",
        "Tip",
        "Overview of settings",
        "Caution",
        "Change polling frequency",
        "Specify data to be fetched",
        "Data collection",
        "Filters",
        "Potential impact on alerts and charts"
      ],
      "title": "Configure polling frequency and data collection for cloud integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Infrastructure integrations",
        "Cloud integrations"
      ],
      "external_id": "b900b7545f9032201c212449be114e10176bf789",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/",
      "published_at": "2021-06-15T13:00:43Z",
      "updated_at": "2021-06-15T13:00:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our cloud integrations get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud integrations. Read on to see what changes you can make and the reasons for making them. Tip To use integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Overview of settings New Relic cloud integrations get data from cloud providers' APIs. Data is generally collected from monitoring APIs such as AWS CloudWatch, Azure Monitor, and GCP Stackdriver, and inventory metadata is collected from the specific services' APIs. You can use the account status dashboard to see how your cloud integrations are handling data from a cloud service provider. If you want to report more or less data from your cloud integrations, or if you need to control the use of the cloud providers' APIs to prevent reaching rate and throttling limits in your cloud account, you can change the configuration settings to modify the amount of data they report. The two main controls are: Change polling frequency Change what data is reported Examples of business reasons for wanting to change your polling frequency include: Billing: If you need to manage your AWS CloudWatch bill, you may want to decrease the polling frequency. Before you do this, make sure that any alert conditions set for your cloud integrations are not affected by this reduction. New services: If you are deploying a new service or configuration and you want to collect data more often, you may want to increase the polling frequency temporarily. Caution Changing the configuration settings for your integrations may impact alert conditions and chart trends. Change polling frequency The polling frequency configuration determines how often New Relic reports data from your cloud provider for each service. By default, the polling frequency is set to the maximum frequency that is available for each service. To change the polling frequency for a cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Use the dropdowns next to Data polling interval every to select how frequently you want New Relic to capture your cloud integration data. Specify data to be fetched You can specify which information you want captured for your cloud integration by enabling the collection of additional data and by applying multiple filters to each integration. To change this settings for your cloud integration: Go to one.newrelic.com > Infrastructure. Select the tab that corresponds to your cloud service provider. Select Configure next to the integration. Under Data collections and filters, turn the toggles you want On. For filters, select or enter the values that you want included in your reported data. Data collection For some cloud integrations, an additional number of calls to the cloud provider APIs are needed in order to collect data. For example, to fetch tags for AWS Elastic Map Reduce clusters, an additional call to the service API is required. To better control the amount of API calls that are sent to your cloud account for these integrations, you can specify when you need these types of data to be collected. Different data collection toggles are available, depending on the integration. Toggle Description Collect tags Some integrations require additional API calls to the cloud provider to report tags. Tag collection is enabled by default. Switch this to Off if you don't want the integration to collect your cloud resource tags and thus reduce the volume of API calls. Collect extended inventory Some integrations can collect extended inventory metadata about your cloud resources by making additional API calls to the cloud provider. The metadata included within the extended inventory for each cloud integration is described in the integration documentation. Extended inventory collection is disabled by default. Switch this to On if you want to monitor extended inventory. This will increase the volume of API calls. Collect shards data Available for AWS Kinesis Streams integration. By default, we don't report shard metrics. Switch this to On if you want to monitor shard metrics in addition to data stream metrics. Collect Lambda@Edge data Available for AWS CloudFront integration. By default, we don't report Lambda@Edge data. Switch this to On if you're using Lambda@Edge in AWS CloudFront and want to get Lambda execution location metadata. Collect node data Available for AWS Elasticsearch integration. By default, we don't report Elasticsearch node metrics. Switch this to On if you want to monitor node metrics in addition to cluster metrics. Collect NAT Gateway data and Collect VPN data Available for AWS VPC integration. By default, we don't report NAT Gateway nor VPN metrics. Switch these to On if you want to monitor NAT Gateway and VPN metrics and inventory, in addition to other VPC related entities inventory. Collect IP addresses Available for AWS EC2 integration. By default, we collect EC2 instance metadata that includes public and private IP addresses, and network interface details. Switch this to Off if you don't want New Relic to store and display these IP data. Filters When a filter is On, you specify the data that you want to be collected; for example, if the Limit to AWS region is On, the regions that you select will be the ones that data will be collected for. There are different filters available, depending on the integration: Filter Description Region Select the regions that include the resources that you want to monitor. Queue prefixes Available for AWS SQS integration. Enter each name or prefix for the queues that you want to monitor. Filter values are case-sensitive. Load balancer prefixes Available for AWS ALB integration. Enter each name or prefix for the application load balancers that you want to monitor. Filter values are case-sensitive. Stage name prefixes Available for AWS API Gateway integration. Enter each name or prefix for the stages that you want to monitor. Filter values are case-sensitive. Tag key Enter one tag key that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag value filter. Tag value Enter one tag value that is associated with the resources that you want to monitor. Filter values are case-sensitive, and you can use this filter in combination with tag key. Resource group Select the resource groups that are associated with the resources that you want to monitor. Potential impact on alerts and charts If you change an integration's configuration, it can impact alert conditions and charts. Here are some things to consider: If you change this setting... It may have this impact... Any configuration setting When you change the configuration settings, the data that New Relic displays in infrastructure charts, on the inventory page, and in the events feed changes as well. Any filters When you create alert conditions after you set filters, make sure that your alerts are not triggered by resources that you filtered out. Filter for regions If you filter for specific regions, it may lower the amount of data reported to New Relic, which could trigger an alert. If you create an alert condition for a specific region and then filter that region out, the region would no longer report data and would never trigger the alert. Polling frequency When you create an alert, make sure that you define the threshold for a time period that is longer than the polling frequency. Tags and extended inventory If you turn on tags and/or extended inventory, New Relic makes more API calls to the cloud provider, which could increase your cloud provider API usage bill.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 50.982445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Configure polling frequency and data collection for cloud <em>integrations</em>",
        "sections": "Configure polling frequency and data collection for cloud <em>integrations</em>",
        "tags": "<em>Integrations</em>",
        "body": "Our cloud <em>integrations</em> get data from cloud provider APIs. In New Relic, you can change some of the data collection-related settings for your cloud <em>integrations</em>. Read on to see what changes you can make and the reasons for making them. Tip To use <em>integrations</em> and the rest of our observability"
      },
      "id": "603e8eef64441fcc7e4e8853"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-15T11:35:32Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 42.86769,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon CloudWatch Metric Streams <em>integration</em>",
        "sections": "Migrating from poll-based AWS <em>integrations</em>",
        "tags": "<em>Integrations</em>",
        "body": "New Relic currently provides independent <em>integrations</em> with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New"
      },
      "id": "606a036de7b9d2bfef9445f2"
    },
    {
      "sections": [
        "Monitor services running on Amazon ECS",
        "Requirements",
        "How to enable",
        "Step 1: Enable EC2 to install the infrastructure agent",
        "For CentOS 6, RHEL 6, Amazon Linux 1",
        "CentOS 7, RHEL 7, Amazon Linux 2",
        "Step 2: Enable monitoring of services"
      ],
      "title": "Monitor services running on Amazon ECS",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "dc178f5c162c1979019d97819db2cc77e0ce220a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs/",
      "published_at": "2021-06-15T11:57:52Z",
      "updated_at": "2021-06-15T11:57:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have services that run on Docker containers in Amazon ECS (like Cassandra, Redis, MySQL, and other supported services), you can use New Relic to report data from those services, from the host, and from the containers. Requirements To monitor services running on ECS, you must meet these requirements: An auto-scaling ECS cluster running Amazon Linux, CentOS, or RHEL that meets the infrastructure agent compatibility and requirements. ECS tasks must have network mode set to none or bridge (awsvpc and host not supported). A supported service running on ECS that meets our integration requirements: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP How to enable Before explaining how to enable monitoring of services running in ECS, here's an overview of the process: Enable Amazon EC2 to install our infrastructure agent on your ECS clusters. Enable monitoring of services using a service-specific configuration file. Step 1: Enable EC2 to install the infrastructure agent First, you must enable Amazon EC2 to install our infrastructure agent on ECS clusters. To do this, you'll first need to update your user data to install the infrastructure agent on launch. Here are instructions for changing EC2 launch configuration (taken from Amazon EC2 documentation): Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. Replace user data with one of the following snippets: For CentOS 6, RHEL 6, Amazon Linux 1 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/6/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy CentOS 7, RHEL 7, Amazon Linux 2 Replace the highlighted fields with relevant values: Content-Type: multipart/mixed; boundary=\"MIMEBOUNDARY\" MIME-Version: 1.0 --MIMEBOUNDARY Content-Disposition: attachment; filename=\"init.cfg\" Content-Transfer-Encoding: 7bit Content-Type: text/cloud-config Mime-Version: 1.0 yum_repos: newrelic-infra: baseurl: https://download.newrelic.com/infrastructure_agent/linux/yum/el/7/x86_64 gpgkey: https://download.newrelic.com/infrastructure_agent/gpg/newrelic-infra.gpg gpgcheck: 1 repo_gpgcheck: 1 enabled: true name: New Relic Infrastructure write_files: - content: | --- # New Relic config file license_key: YOUR_LICENSE_KEY path: /etc/newrelic-infra.yml packages: - newrelic-infra - nri-* runcmd: - [ yum, install, newrelic-infra, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] --MIMEBOUNDARY Content-Transfer-Encoding: 7bit Content-Type: text/x-shellscript Mime-Version: 1.0 #!/bin/bash # ECS config { echo \"ECS_CLUSTER=YOUR_ECS_CLUSTER_NAME\" } >> /etc/ecs/ecs.config start ecs echo \"Done\" --MIMEBOUNDARY-- Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop-down menu for Launch configuration, select the new launch configuration created. Click Save. To test if the agent is automatically detecting instances, terminate an EC2 instance in the auto scaling group: the replacement instance will now be launched with the new user data. After five minutes, you should see data from the new host on the Hosts page. Next, move on to enabling the monitoring of services. Step 2: Enable monitoring of services Once you've enabled EC2 to run the infrastructure agent, the agent starts monitoring the containers running on that host. Next, we'll explain how to monitor services deployed on ECS. For example, you can monitor an ECS task containing an NGINX instance that sits in front of your application server. Here's a brief overview of how you'd monitor a supported service deployed on ECS: Create a YAML configuration file for the service you want to monitor. This will eventually be placed in the EC2 user data section via the AWS console. But before doing that, you can test that the config is working by placing that file in the infrastructure agent folder (etc/newrelic-infra/integrations.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from the service is being reported to New Relic. If you are satisfied with the data you see, you can then use the EC2 console to add that configuration to the appropriate launch configuration, in the write_files section, and then update the auto scaling group. In the runcmd section, add the yum command to install the integration to the appropriate launch configuration. Here's a detailed example of doing the above procedure for NGINX: Ensure you have SSH access to the server or access to AWS Systems Manager Session Manager. Log in to the host running the infrastructure agent. Via the command line, change the directory to the integrations configuration folder: cd /etc/newrelic-infra/integrations.d Copy Create a file called nginx-config.yml and add the following snippet: --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 Copy This configuration causes the infrastructure agent to look for containers in ECS that contain nginx. Once a container matches, it then connects to the NGINX status page. For details on how the discovery.ip snippet works, see auto-discovery. For details on general NGINX configuration, see the NGINX integration. If your NGINX status page is set to serve requests from the STATUS_URL on port 80, the infrastructure agent starts monitoring it. After five minutes, verify that NGINX data is appearing in the Infrastructure UI (either: one.newrelic.com > Infrastructure > Third party services, or one.newrelic.com > Explorer > On-host). If the configuration works, place it in the EC2 launch configuration: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Launch configurations. On the next page, select the launch configuration you want to update. Right click and select Copy launch configuration. On the Launch configuration details tab, click Edit details. In the User data section, edit the write_files section (in the part marked text/cloud-config). Add a new file/content entry: - content: | --- discovery: docker: match: image: /nginx/ integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}:/status REMOTE_MONITORING: true METRICS: 1 path: /etc/newrelic-infra/integrations.d/nginx-config.yml Copy Also edit the runcmd section to include the yum command to install nri-nginx: runcmd: - [ yum, install, newrelic-infra, -y ] - [ yum, install, nri-nginx, -y ] - [ systemctl, daemon-reload ] - [ systemctl, enable, newrelic-infra.service ] - [ systemctl, start, --no-block, newrelic-infra.service ] Copy Choose Skip to review. Choose Create launch configuration. Next, update the auto scaling group: Open the Amazon EC2 console. On the navigation pane, under Auto scaling, choose Auto scaling groups. Select the auto scaling group you want to update. From the Actions menu, choose Edit. In the drop down menu for Launch configuration, select the new launch configuration created. Click Save. When an EC2 instance is terminated, it is replaced with a new one that automatically looks for new NGINX containers.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 40.94765,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Integrations</em>",
        "body": " that file in the infrastructure agent folder (etc&#x2F;newrelic-infra&#x2F;<em>integrations</em>.d) in EC2. That config file must use our container auto-discovery format, which allows it to automatically find containers. The exact config options will depend on the specific integration. Check to see that data from"
      },
      "id": "60450959e7b9d2475c579a0f"
    }
  ],
  "/docs/integrations/new-relic-integrations/getting-started/integration-dashboards-infrastructure-beta-transition-guide": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/cloud-integration-release-notes/changes-curated-dashboards/",
      "sections": [
        "Changes in curated dashboards",
        "Other changes",
        "New"
      ],
      "published_at": "2021-06-15T09:27:22Z",
      "title": "Changes in curated dashboards",
      "updated_at": "2021-03-16T16:57:40Z",
      "type": "docs",
      "external_id": "e8bcff90d46de24933446830d551bcab22a2da5c",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Changes in curated dashboards New Relic Infrastructure integrations will not automatically create new dashboards in New Relic Insights when an integration is enabled. Instead, curated dashboards for On-host and Cloud integrations data will be embedded in the New Relic Infrastructure UI, and they can be reached from the following links: On-host integrations: https://infrastructure.newrelic.com/accounts/<your_account_ID>/integrations/onHostIntegrations AWS integrations: https://infrastructure.newrelic.com/accounts/<your_account_ID>/integrations/aws Azure integrations: https://infrastructure.newrelic.com/accounts/<your_account_ID>/integrations/azure GCP integrations: https://infrastructure.newrelic.com/accounts/<your_account_ID>/integrations/gcp Please refer to the transition guide and the Infrastructure integration dashboards and charts documentation for more details about the new pre-built integration dashboards. Note the existing curated dashboards that had been automatically created in New Relic Insights through the InfrastructurePro@newrelic.com user are still available. These dashboards won't be automatically updated anymore, but now you can edit and remove them. By default, they have the same name as the dashboard in New Relic Infrastructure, that takes this format: For on-host integrations: <Integration name> For cloud integrations: <Integration name> - <Linked account name> Other changes The former systemErrors metric in the AWS DynamoDB integration is now reported in several different metrics which represent the total number of requests that generate an HTTP 500 status per operation type. Please refer to AWS DynamoDB monitoring integration for details. New The AWS RDS integration now provides new metrics for RDS database instances and Amazon Aurora clusters. Check AWS RDS monitoring integration for details. The Azure App Service integration now provides new metrics to monitor connections and performance of Web Apps. Check Azure App Service monitoring integration for details.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.07314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Changes <em>in</em> curated <em>dashboards</em>",
        "sections": "Changes <em>in</em> curated <em>dashboards</em>",
        "body": ":&#x2F;&#x2F;<em>infrastructure</em>.newrelic.com&#x2F;accounts&#x2F;&lt;your_account_ID&gt;&#x2F;integrations&#x2F;azure GCP integrations: https:&#x2F;&#x2F;<em>infrastructure</em>.newrelic.com&#x2F;accounts&#x2F;&lt;your_account_ID&gt;&#x2F;integrations&#x2F;gcp Please refer to the <em>transition</em> <em>guide</em> and the <em>Infrastructure</em> <em>integration</em> <em>dashboards</em> and charts documentation for more details about the new pre"
      },
      "id": "603e8dcbe7b9d203892a07e2"
    },
    {
      "sections": [
        "Transition to New Relic One from Insights",
        "Important",
        "Features",
        "Improved query abilities",
        "Improved visualizations",
        "Steps for a successful transition"
      ],
      "title": "Transition to New Relic One from Insights",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "4af99cd8030909a71d21a359a60af5ac93b93a66",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/transition-new-relic-one-insights/",
      "published_at": "2021-06-15T10:26:33Z",
      "updated_at": "2021-05-22T00:14:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important As of April 12, 2021, we're upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. Released in 2014, New Relic Insights was our original way to create custom queries, charts, and dashboards. With New Relic One, we have modernized the experience for you to access, analyze, and visualize your data. New Relic One offers an improved charts and dashboards experience, and it provides a platform where we can more rapidly bring new innovations to you. This transition guide can help you understand: What are some of the new and improved features you get with New Relic One charts, dashboards, and queries Why it's easy to transition to New Relic One What to know and considerations when you make the switch How to get the most out of using New Relic One Features You can scroll down to the transition details, but first here are some features we've added that show how New Relic One dashboards are a clear improvement over Insights dashboards. Improved query abilities With New Relic One, you get: Ability to query many accounts from the same widget: New Relic One lets you query across all your associated accounts in one place. Better querying and charting experiences: Query access is available globally, no matter where you are in New Relic One. This includes a \"basic\" query mode that doesn't require knowledge of NRQL. Improved query experience: You can query both the Metric data type and metric timeslice data. Easy customization: Every visualization now has the query accessible. You can augment any curated chart just by changing the NRQL query. Improved visualizations Not only can you select a wide range of visualization options, you can also add more to your dashboards: Better display options: Make your data easier to understand by using visualizations other than dense, line-heavy charts. New Relic One also offers a better TV mode. Facet linking: You can filter your dashboards by faceted attributes, making your dashboards more interactive and easy to use. There's also support for cases. Learn more. More charts or widgets in an area: Insights restricted you to a 3-across limit. Now you can display up to 12 across your dashboard, providing increased data density along with improved tooltips and tracking across charts. Easier creation of multi-page dashboards: Insights referred to these as data apps. Your Insights data apps are preserved as multi-page dashboards in New Relic One. Chart consistency and flexibility: Dashboards include facet color consistency across widgets and faster loading times for more performant dashboards. Also, you can add any chart type to a dashboard in New Relic One! The New Relic Insights UI has served our users well for many years, but it's time to give you an even better experience. Join us and make the switch to New Relic One! Steps for a successful transition The transition to New Relic One has two parts: the UI and mobile app experience (April 12, 2021) and the Dashboard API (July 2021). Insights functionality Transition to New Relic One UI We have already taken care of your transition from Insights to New Relic One for you! As of April 12, 2021, your old Insights web URLs redirect automatically to New Relic One. We recommend that you familiarize yourself with the new UI features available to you, as described in this transition guide. If you need to view any Insights charts embedded in other websites, go to one.newrelic.com > More > Manage Data. (These older embedded charts will continue to function as expected.) Mobile apps Your Insights mobile app is deprecated as of April 11, 2021. Go to the Google Play Store 2 or Apple App store. Delete your old Insights mobile app, and download the New Relic One mobile app. tvOS apps and large displays New Relic's tvOS app is still available. No action is needed by you at this time. Some New Relic customers with the original pricing model may have set up dashboards on wall screens for restricted users with kiosk mode. No action is required for you to continue to view these dashboards. APIs In July of 2021, the Insights Dashboard API will be deprecated and replaced with NerdGraph functionality. For more on this change, and tips on how to migrate, see NerdGraph API for dashboards. Partnership accounts This applies only if your account is one of the few using our partnership account structure to deliver New Relic services to your direct customers. In this situation, the Insights EOL will not affect your customers pricing. This is simply an EOL for the UI, not an EOL for the account type. Questions If you have questions about the transition, please comment in our Explorers Hub post. Or, if you work with an account team, they will be happy to help you.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.519424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Transition</em> to New Relic One from <em>Insights</em>",
        "sections": "<em>Transition</em> to New Relic One from <em>Insights</em>",
        "body": " experience, and it provides a platform where we can more rapidly bring new innovations to you. This <em>transition</em> <em>guide</em> can help you understand: What are some of the new and improved features you get with New Relic One charts, <em>dashboards</em>, and queries Why it&#x27;s easy to <em>transition</em> to New Relic One What to know"
      },
      "id": "6044171164441f454a378ee2"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "Get access to the Quickstarts App",
        "Import dashboards from Quickstarts App",
        "Manage your data",
        "Migrating from poll-based AWS integrations",
        "Query, dashboard, and alert considerations",
        "Troubleshooting",
        "No metrics or errors appear on New Relic",
        "Missing metrics for certain AWS namespaces",
        "Metric values discrepancies between AWS CloudWatch and New Relic",
        "AWS Metric Streams Operation",
        "Errors in the Status Dashboard"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "4ccc7fb5ba31643ae4f58f7fc647d71b8145d61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-06-15T11:35:32Z",
      "updated_at": "2021-06-15T11:35:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: Third-party service provider Ensure the following settings are defined: Third-party service provider: New Relic - Metrics New Relic configuration HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = cloudwatch-metric-streams. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum('aws.s3.5xxErrors') FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from all services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for different AWS Services is available in the New Relic One Quickstarts app. Get access to the Quickstarts App Follow these steps in order to browse and import dashboards: Navigate to the Apps catalog in New Relic One. Search and select the Quickstarts app. Click on the Add this app link in the top-right corner. To enable the app, select target accounts and confirm clicking the Update account button. If applicable, review and confirm the Terms and Conditions of Use. Note that it might take a few minutes until permissions are applied and the app is ready to be used. Once available, confirm the app is enabled. The Quickstarts app will be listed in the Apps catalog. Import dashboards from Quickstarts App Follow these steps in order to import any of the curated dashboards: Navigate to Apps and open the Quickstarts app. Browse the AWS Dashboards. If you don't find a dashboard for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own dashboard. Select the dashboard, confirm the target account and initial dashboard name. A copy of the dashboard should be imported in the target account. Additional customization is possible using any of the New Relic One dashboarding features. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in CloudWatch Metric Stream is order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from poll-based AWS integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Query, dashboard, and alert considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Custom dashboards that use poll-based AWS integration events should work as expected. Alert conditions that use poll-based AWS events might need to be adapted with dimensional metric format. Use the NRQL source for the alert condition. Entities in New Relic Explorer might be duplicated for up to 24 hours. The AWS CloudWatch Metric Streams integration only collects metrics. Integrations such as AWS Health, AWS Billing, and AWS CloudTrail collect additional instrumentation that's not available for metric streams. In order to continue collecting that additional data, keep those enabled as polling integrations. Troubleshooting No metrics or errors appear on New Relic If you are not seeing data in New Relic once the AWS CloudWatch Metric Stream has been connected to AWS Kinesis Data Firehose, then follow the steps below to troubleshoot your configuration: Check that the Metric Stream is in a state of Running via the AWS console or API. Please refer to AWS Troubleshooting docs for additional details. Check the Metric Stream metrics under AWS/CloudWatch/MetricStreams namespace. You will see a count of metric updates and errors per Metric Streams. This will indicate that the Metric Stream is successfully emitting data. If you see errors, confirm the IAM role specified in the Metric Streams configuration grants the CloudWatch service principal permissions to write to it. Check the Monitoring tab of the Kinesis Data Firehose in the Kinesis console to see if the Firehose is successfully receiving data. You can enable CloudWatch error logging on your Kinesis Data Firehose to get more detailed information for debugging issues. Refer to Amazon Kinesis Data Firehose official documentation for more details. Confirm that you have configured your Kinesis Data Firehose with the correct destination details: Ensure the New Relic API Key/License Key contains your 40 hexadecimal chars license key. Ensure the right data center US or EU has been selected for your New Relic account (hint: if the license_key starts with eu then you need to select the EU data center). Check that your Kinesis Data Firehose has permissions to write to the configured destination, for example: the S3 bucket policy allows write. Missing metrics for certain AWS namespaces New Relic does not apply any filter on the metrics received from the AWS CloudWatch metric stream. If you are expecting certain metrics to be ingested and its not the case, please verify the following: Make sure theres no Inclusion or Exclusion filter in your CloudWatch Metric Stream. Make sure metrics are available in AWS as part of CloudWatch. Confirm you see the metrics in the AWS CloudWatch interface. Important AWS CloudWatch doesn't include metrics that are not available in less than 2 hours. For example, some S3 metrics are aggregated on a daily basis. We plan to make some of these special metrics available in New Relic. Metric values discrepancies between AWS CloudWatch and New Relic Metrics are processed, mapped, and stored as received from AWS CloudWatch metric stream. Some discrepancies might be observed when comparing AWS CloudWatch and New Relic dashboards. On limited scenarios, AWS CloudWatch applies specific functions and logic before rendering the metrics. These guidelines should help understand the root cause of the discrepancy: Check that the same function is used on the metrics (for example average, min, max). On the New Relic side, make sure you filter the same timestamp or timeframe (considering the timezone) to show the exact same time as in AWS CloudWatch. When using timeseries, the New Relic user interface might perform some rounding based on intervals. You can get a list of the raw metric received by time using a query like this one (note that no function is applied to the selected metric): FROM Metric SELECT aws.outposts.InstanceTypeCapacityUtilization WHERE collector.name = 'cloudwatch-metric-streams' Copy Remember that AWS fixes the maximum resolution for every metric reported in AWS CloudWatch (for example: 1 minute, 5 minutes, etc). AWS Metric Streams Operation You can see the state of the Metric Stream(s) in the Streams tab in the CloudWatch console. In particular, a Metric Stream can be in one of two states: running or stopped. Running: The stream is running correctly. Note that there may not be any metric data been streamed due to the configured filters. Although there is no data corresponding to the configured filters, the status of the Metric Stream can be running still. Stopped: The stream has been explicitly set to the halted state (not because of an error). This state is useful to temporarily stop the streaming of data without deleting the configuration. Errors in the Status Dashboard New Relic relies on the AWS Config service to collect additional metadata from resources in order to enrich metrics received via CloudWatch Metric Stream. Make sure AWS Config is enabled in your AWS Account, and ensure the linked Role has the following permission or inline policy created: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"config:BatchGetResourceConfig\", \"Resource\": \"*\" } ] } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.816315,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon CloudWatch Metric Streams <em>integration</em>",
        "sections": "Amazon CloudWatch Metric Streams <em>integration</em>",
        "tags": "<em>Integrations</em>",
        "body": " these steps in order to import any of the curated <em>dashboards</em>: Navigate to Apps and open the Quickstarts app. Browse the AWS <em>Dashboards</em>. If you don&#x27;t find a <em>dashboard</em> for your AWS service please submit your feedback on the top navigation bar or feel free to contribute with your own <em>dashboard</em>. Select"
      },
      "id": "606a036de7b9d2bfef9445f2"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/dropwizard/dropwizard-reporter": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.04108,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "Introduction to New Relic's open source telemetry integrations",
        "Tip",
        "Types of integrations",
        "How they work"
      ],
      "title": "Introduction to New Relic's open source telemetry integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "Get started"
      ],
      "external_id": "239889ec292525fcfd6b417d243943ea7b3e0529",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations/",
      "published_at": "2021-06-15T13:23:46Z",
      "updated_at": "2021-03-16T06:12:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides open source integrations that report telemetry data from telemetry tools to your New Relic account. Tip To use telemetry integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of integrations We have open source integrations that report data from OpenCensus, OpenTelemetry, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your telemetry data in one place: the New Relic platform. See our list of open source telemetry integrations (to browse all New Relic solutions, see our integrations page). How they work These integrations were built using our Telemetry SDKs, which are open-source language-specific libraries for reporting metrics, trace data, and other telemetry data to New Relic. If our pre-built integrations don't meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest APIs. For example, metrics reported by the DropWizard exporter are ingested via the Metric API, so to understand how to query and chart that type of data, you could read Query metric data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.01886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "sections": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": " to 100GB of data for free each month. Forever. Types of <em>integrations</em> We have <em>open</em> <em>source</em> <em>integrations</em> that report data from <em>Open</em>Census, <em>OpenTelemetry</em>, <em>DropWizard</em>, Prometheus, and more. With these solutions, you can aggregate all your <em>telemetry</em> data in one place: the New Relic platform. See our list"
      },
      "id": "603e95ab28ccbc036aeba789"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.42453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/elixir/elixir-open-source-agent": [
    {
      "sections": [
        "Roku open-source agent",
        "Tip",
        "Get started",
        "For more help"
      ],
      "title": "Roku open-source agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Open-source licensed agents",
        "Open-source licensed agents"
      ],
      "external_id": "f0982a0ff96c8a85683bf3ef27a2e4cde85ff274",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/roku/roku-open-source-video-agent/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-04-27T11:09:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor Roku behavior with New Relic using the Roku open-source agent. The agent contains two parts, to capture two separate categories of Roku behavior: App events like app starts and HTTP requests Video playback within the app Tip This agent is released as open source on GitHub. A change log is also available there for the latest updates. Get started For requirements, installation, and configuration information, see the Open Source Roku Agent README on GitHub. Visit New Relics Roku repository on GitHub for questions about installation, usage, or other topics. Report issues or bugs as an issue in the GitHub repository. For more help Recommendations for learning more: Browse New Relic's Explorers Hub for community discussions about the open-source Roku agent. Review New Relic's licenses, attributions, data usage limits, and other notices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 396.904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Roku <em>open</em>-<em>source</em> <em>agent</em>",
        "sections": "Roku <em>open</em>-<em>source</em> <em>agent</em>",
        "tags": "<em>Open</em>-<em>source</em> <em>licensed</em> <em>agents</em>",
        "body": "Monitor Roku behavior with New Relic using the Roku <em>open</em>-<em>source</em> <em>agent</em>. The <em>agent</em> contains two parts, to capture two separate categories of Roku behavior: App events like app starts and HTTP requests Video playback within the app Tip This <em>agent</em> is released as <em>open</em> <em>source</em> on GitHub. A change log"
      },
      "id": "6087f0ff64441f618a9d8533"
    },
    {
      "sections": [
        "Java agent configuration: Config file",
        "Configuration file structure",
        "Tip",
        "Configuration settings precedence",
        "Configuring the Java extensions directory",
        "Create an extensions directory",
        "Specify an existing extensions directory",
        "General configuration settings",
        "license_key (REQUIRED)",
        "app_name (REQUIRED)",
        "agent_enabled",
        "apdex_t (DEPRECATED)",
        "appserver_port",
        "Important",
        "audit_mode",
        "ca_bundle_path",
        "use_private_ssl",
        "enable_auto_app_naming",
        "enable_auto_transaction_naming",
        "Caution",
        "enable_custom_tracing",
        "event_ingest_uri",
        "extensions.dir",
        "high_security",
        "insert_api_key",
        "labels",
        "max_stack_trace_lines",
        "metric_ingest_uri",
        "proxy_host",
        "proxy_password",
        "proxy_port",
        "proxy_user",
        "proxy_scheme",
        "reactor-netty.errors.enabled",
        "send_data_on_exit",
        "send_data_on_exit_threshold",
        "send_environment_info",
        "send_jvm_props",
        "ssl (DEPRECATED)",
        "sync_startup",
        "scala_futures_as_segments",
        "Logging configuration",
        "log_daily",
        "log_file_count",
        "log_file_name",
        "log_file_path",
        "log_level",
        "log_limit_in_kbytes",
        "JMX",
        "enabled",
        "linkingMetadataMBean",
        "JFR (Real-time profiling)",
        "audit_logging",
        "Attributes",
        "include",
        "exclude",
        "Transaction tracer",
        "explain_enabled",
        "explain_threshold",
        "insert_sql_max_length",
        "log_sql",
        "record_sql",
        "stack_based_naming (Play 2.x+ only)",
        "stack_trace_threshold",
        "top_n",
        "transaction_threshold",
        "slow_query_whitelist (DEPRECATED)",
        "collect_slow_queries_from",
        "attributes.enabled",
        "attributes.include",
        "attributes.exclude",
        "token_limit",
        "segment_limit",
        "Transaction segments",
        "Browser monitoring",
        "auto_instrument",
        "disabled_auto_pages",
        "External tracer",
        "exclude_request_uri",
        "Cross application tracer",
        "Error collector",
        "ignore_classes",
        "ignore_messages",
        "ignore_status_codes",
        "ignoreErrorPriority",
        "expected_classes",
        "expected_messages",
        "expected_status_codes",
        "ignore_errors (DEPRECATED)",
        "Strip exceptions",
        "whitelist (DEPRECATED)",
        "allowed_classes",
        "Thread profiler",
        "Transaction events",
        "max_samples_stored",
        "custom_request_headers",
        "Custom events",
        "Hostname configuration",
        "display_name",
        "ipv_preference",
        "Custom instrumentation",
        "trace_annotation_class_name",
        "com.newrelic.instrumentation.servlet-user",
        "System properties",
        "newrelic.config.process_host.display_name",
        "newrelic.config.file",
        "newrelic.debug",
        "newrelic.environment",
        "newrelic.home",
        "newrelic.logfile",
        "Environment variables",
        "NEW_RELIC_APP_NAME (REQUIRED)",
        "NEW_RELIC_DISTRIBUTED_TRACING_ENABLED",
        "NEW_RELIC_PROCESS_HOST_DISPLAY_NAME",
        "NEW_RELIC_LICENSE_KEY (REQUIRED)",
        "NEW_RELIC_LOG",
        "Cloud platform utilization",
        "detect_aws",
        "detect_docker",
        "Async instrumentation",
        "token_timeout",
        "segment_timeout",
        "Circuit breaker",
        "memory_threshold",
        "gc_cpu_threshold",
        "Message tracer",
        "segment_parameters.enabled",
        "Distributed tracing",
        "exclude_newrelic_header",
        "Infinite Tracing",
        "trace_observer.host",
        "Span events",
        "Jar collector",
        "skip_temp_jars",
        "jars_per_second"
      ],
      "title": "Java agent configuration: Config file",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Configuration"
      ],
      "external_id": "1d61f848fa192438225eae269421b8d384915c8b",
      "image": "https://docs.newrelic.com/static/60ca967eab99ca225186310913ae2de6/8c557/java-config-cascade.png",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/configuration/java-agent-configuration-config-file/",
      "published_at": "2021-06-15T00:58:19Z",
      "updated_at": "2021-06-15T00:58:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Java agent reads its configuration from the newrelic.yml file. By default the agent looks for this file in the directory that contains newrelic.jar. You can override the config file's location by setting the newrelic.config.file system property to a fully qualified file name. Configuration file structure The newrelic.yml file is split into stanzas corresponding to different environments: Test Development Staging Production (default) New Relic applies settings in the common stanza to each of these environments. You can select other environments as the default by setting the newrelic.environment system property to the environment name. Tip A newrelic.yml template is available. If you edit newrelic.yml, be careful to conform to the YAML format. Use a YAML validator to ensure the syntax is accurate before using the file with New Relic's Java agent, and follow these rules: Java agent newrelic.yml Requirements Format YML files are case sensitive. Indentations All indentations must be in increments of two characters. Other indentations will result in an Unable to parse configuration file error upon agent startup. Use the same level of indentation for data in the same stanza of the file. Indent any sub-stanzas by an additional two spaces. Changes to file You must restart your JVM host process for changes to take effect. Exception: Property changes to log_level and audit_mode do not require a restart. Property changes under circuit breaker don't require a restart. Configuration settings precedence To override any setting in the config file, use a system property override. In certain environments, environment variables can also be used to override both the config file and the system properties. The environment variables primarily exist to support Heroku. When used, server-side configuration overrides all other configuration settings. With the Java agent, server-side configuration overrides all other settings. Environment variables override Java system properties. Java properties override user configuration settings in your newrelic.yml file. User settings override the newrelic.yml default settings. Configuring the Java extensions directory The Java agent reads the configuration files on process startup. To identify the directory where the files are located, either create a new or specify an existing extensions directory: Create an extensions directory To create the extensions directory: Navigate to the directory where newrelic.jar and newrelic.yml are located. Create a directory named extensions. In newrelic.yml, check that the property extensions.dir is not set. Specify an existing extensions directory To use an existing Java extensions directory: In your newrelic.yml file, locate the common section. Use the property extensions.dir to specify the location of the file. General configuration settings Set these options in the common stanza. To override any of these options, use a newrelic.config prefixed system property. license_key (REQUIRED) Type String Default (none) This setting is required. You must specify the license key associated with your New Relic account. This key binds your agent's data to your account in the New Relic service. app_name (REQUIRED) Type String Default (none) This setting is required. Defines the application name used to report data to New Relic. If enable_auto_app_naming is false, the agent reports all data to this application. Otherwise, the agent reports only background tasks (transactions for non-web applications) to this application. To report data to more than one application, separate the application names with a semicolon. For example, to report data to My Application and My Application 2 use this: app_name: My Application;My Application 2 Copy For more methods of naming your application, see Name your Java application. agent_enabled Type Boolean Default true Flag to enable the agent. Use this setting to force the agent to run or not run. apdex_t (DEPRECATED) Type Float Default 1.0 The apdex_t threshold in seconds for the application's Apdex score. For Java agent versions 1.2.008 or higher, the apdex_t value is set in the UI and the value in newrelic.yml is ignored. appserver_port Type Integer Default (none) Number to differentiate JVMs for the same app on the same machine. New Relic uses host/port for uniqueness, so you can distinguish the JVMs by putting a switch like this into the startup arguments for each JVM: -Dnewrelic.config.appserver_port=8081 Copy Once you have used appserver_port to name the JVMs and restart them, you should be able to see them individually in the dropdown and in the profiling interface. Important This is only a change for New Relic; it doesn't actually affect the port on which the host communicates in any way. audit_mode Type Boolean Default false Enables plain text logging of all data sent to New Relic to the agent logfile. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. ca_bundle_path Type String Value Format /path/to/ca/cert/bundle.pem Specifies a path to a custom SSL certificate bundle that will be used by the agent to establish a secure connection to New Relic. If your custom SSL certificate bundle doesn't include certificates that are sufficient to connect to New Relic then you'll need to merge the required certs into your custom certificate bundle. use_private_ssl Type Boolean Default false The following SSL certificates are bundled into the agent jar: META-INF/certs/eu-newrelic-com.pem META-INF/certs/eu01-nr-data-net.pem META-INF/certs/newrelic-com.pem Copy By default (use_private_ssl: false) the agent will use the SSL certificates bundled into the JDK to establish a secure connection to New Relic or the custom SSL certificates bundle specified by ca_bundle_path. If you want to use the SSL certificates bundled with the agent, set use_private_ssl: true. Note: use_private_ssl will be ignored if ca_bundle_path is set. enable_auto_app_naming Type Boolean Default false Enables the reporting of data separately for each web app. Set to true to enable support for auto app naming. The name of each web app is detected automatically and the agent reports data separately for each one. This provides a finer-grained performance breakdown for web apps in New Relic. For more information, see Automatic application naming. For more methods of naming your application, see Name your Java application. enable_auto_transaction_naming Type Boolean Default true Enables component-based transaction naming. Set to true to enable component-based transaction naming. Set to false to use the URI of a web request as the name of the transaction. For more information, see Naming web transactions. Caution Unless you implement API calls to name your transactions, disabling auto-transaction naming is very likely to cause Metric grouping issues. enable_custom_tracing Type Boolean Default true Enables all instrumentation using an @Trace annotation. Disabling this causes @Trace annotations to be ignored. event_ingest_uri Type String Default https://insights-collector.newrelic.com/v1/accounts/events Event ingest URI used by some agent features. Defaults to the US production ingest endpoint. Can be manually configured to send events to other ingest endpoints (for example, EU production: https://insights-collector.eu01.nr-data.net/v1/accounts/events). extensions.dir Type String Default (none) Defines the location of the optional extensions directory. If this property is not set, the agent will look for a subdirectory named extensions in the same directory as newrelic.jar and newrelic.yml. high_security Type Boolean Default false In order for high security to be enabled, this property must be set to true and the high security property in the New Relic user interface must be enabled. Enabling high security means SSL is turned on, request and message queue parameters are not collected, and queries cannot be sent to New Relic in their raw form. Important As of Java agent 3.48.0, SSL is enabled by default and the config option to disable it has been deprecated. As of Java agent 4.0.0, the ability to disable SSL has been removed. insert_api_key Type String Default (none) A valid Insert API Key for your account. This is not currently used by the agent. labels Type String Default \"\" Attach tags to this app. Note that this option now enables tags, which replaced the label feature. You can still query your historical labels. max_stack_trace_lines Type Integer Default 30 Limits the number of lines the agent collects from each stack trace. Increasing this value may impact performance, because it increases the amount of memory the agent uses and the amount of data sent to New Relic. metric_ingest_uri Type String Default https://metric-api.newrelic.com/metric/v1 Metric ingest URI used by some agent features. Defaults to the US production ingest endpoint. Can be manually configured to send metrics to other ingest endpoints (for example EU production: https://metric-api.eu.newrelic.com/metric/v1). proxy_host Type String Default (none) The proxy host through which to connect to the New Relic collector. If a proxy is used, the host setting is required. Other proxy settings are optional. proxy_password Type String Default (none) The password for proxy authentication. If a proxy is used, the host setting is required. Other proxy settings are optional. The username and password settings will be used to authenticate to Basic Auth challenges from a proxy server. Important The Java agent supports Basic (clear text) authentication. proxy_port Type String Default 8080 The proxy host port number. If a proxy is used, the host setting is required. Other proxy settings are optional. proxy_user Type String Default (none) The username for proxy authentication, such as Basic (clear text) authentication. If a proxy is used, the host setting is required. Other proxy settings are optional. The username and password settings will be used to authenticate to Basic Auth challenges from a proxy server. proxy_scheme Type String Default (none) The proxy scheme used. Setting proxy_scheme: \"https\" will allow the agent to connect through proxies using the HTTPS scheme. reactor-netty.errors.enabled Type Boolean Default false Whether errors are reported for Reactor Netty. Default is false. If set to true, Reactor Netty errors will be reported. Important Only available in Java agent 6.3.0 and above. Notice, default was changed to false as of Java agent 6.5.0. send_data_on_exit Type Boolean Default false Enable delayed JVM shutdown to give the agent a chance to send latest metric data to New Relic before JVM shutdown. send_data_on_exit_threshold Type Integer Default 60 The number of seconds after which the agent will use the send_data_on_exit setting. send_environment_info Type Boolean Default true Enable reporting of JVM settings to New Relic. send_jvm_props Type Boolean Default true When set to true, JVM properties will be sent to New Relic. ssl (DEPRECATED) Type Boolean Default true Requires connections to the New Relic collector to go over SSL. The agent communicates with New Relic via HTTPS by default, and New Relic requires HTTPS for all traffic to APM and the New Relic REST API. This work is done asynchronously to the threads that process your application code, so response times will not be directly affected by this change. Important As of Java agent 3.48.0, SSL is enabled by default and the config option to disable it has been deprecated. As of Java agent 4.0.0, the ability to disable SSL has been removed. sync_startup Type Boolean Default false Enable the agent to connect the New Relic collector immediately upon app startup. scala_futures_as_segments Important This applies to Java agent version 3.44.0 or higher. Type Boolean Default false For more concise transaction trace details, the agent does not report Scala Futures as transaction segments, and those Futures do not contribute to the transactions total time. Enabling scala_futures_as_segments increases your overhead. If you want Scala Futures to report as transaction segments so you can view them in a transaction trace, you can enable it: scala_futures_as_segments: enabled: true Copy Logging configuration These are part of the general configuration variables. They are broken out here because they are frequently tweaked for debugging. Some of the logging configuration variables are dynamic and do not need a host restart for them to take effect. For instance, if log files are growing too quickly, log_level can be set to a less verbose setting to reduce the reporting rate. Here is the order of precedence for configuration variables affecting log rotation. If log_daily is true, other log rotation settings are ignored. If log_file_count is 1 or 0, the size limit is ignored. Finally, the agent applies log_limit_in_kbytes. Depending on the growth rate, it is possible for the log file size to exceed the configured value by a small amount. log_daily Type Boolean Default false Set to true to roll the logs daily. Overrides the other configuration variables that affect log rotation. log_file_count Type Integer Default 1 The maximum number of log files to keep when using log rotation. log_file_name Type String Default newrelic_agent.log The unqualified log file name or the string STDOUT which will log to standard out. log_file_path Type String Default logs subdirectory where newrelic.jar is located The log file path. Tip If log_file_path is specified, the directory must already exist. If the default value is used, the agent will attempt to create the directory. log_level Type String Default info The log verbosity level. The agent uses its own log file to keep its logging separate from that of your application. Valid options, in order of verboseness, are: off severe warning info fine finer finest This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. log_limit_in_kbytes Type Integer Default 0 The log file size in kilobytes at which log files are rotated. Set to 0 for no limit. JMX To set these options, use the jmx stanza. To override them, use a newrelic.config.jmx prefixed system property. The Java agent uses JMX to collect JVM data. Additionally the agent can expose linking metadata over JMX that can be used by other tracing systems. enabled Type Boolean Default true This setting can be used to turn on or off all JMX functionality. linkingMetadataMBean Type Boolean Default false This setting can be enabled to allow the Java agent to expose linking metadata over remote JMX. Important This applies to Java agent version 6.1.0 or higher. JFR (Real-time profiling) The Java agent uses Java Flight Recorder (JFR) to collect high fidelity JVM data for Real-time profiling. Real-time profiling can be configured in the jfr stanza in the agent yaml, with system properties prefixed by newrelic.config.jfr., or with environment variables prefixed with NEW_RELIC_JFR_. enabled Type Boolean Default false Set to true to enable Real-time profiling with JFR. Important This applies to Java agent version 7.0.0 or higher. audit_logging Type Boolean Default false Set to true to enable audit logging which will display all JFR metrics and events in each harvest batch. Audit logging is extremely verbose and should only be used for troubleshooting purposes. Important This applies to Java agent version 7.0.0 or higher. Attributes To set these options, use the attributes stanza. To override them, use a newrelic.config.attributes prefixed system property. Attributes are key-value pairs that provide information for transaction traces, traced errors, browser monitoring, and transaction events. There is also an attribute stanza under each destination. For more information, see Java agent attributes, Enabling and disabling attributes and Attribute examples. enabled Type Boolean Default true This setting can be used to turn on or off all attributes. Important For security reasons, capturing custom attributes using the Custom Instrumentation Editor is set to false by default. include Type List of Strings Default (none) If attributes are enabled, attribute keys found in this list will be sent to New Relic. Separate the keys in the list with a comma; for example: key1, key2, key3 Copy Also refer to the agent attribute rules. exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic. Separate the keys in the list with a comma; for example: key1, key2, key3 Copy Also refer to the agent attribute rules. Transaction tracer These options are set in the transaction_tracer stanza and can be overridden by using a newrelic.config.transaction_tracer prefixed system property. Transaction tracing captures deep information about slow transactions and sends this to the New Relic service. The transaction includes the exact call sequence of the transactions, including any query statements issued. Important Do not use brackets [suffix] at the end of your transaction name. New Relic automatically strips brackets from the name. Instead, use parentheses (suffix) or other symbols if needed. enabled Type Boolean Default true The transaction tracer is enabled by default. Set this to false to turn it off. explain_enabled Type Boolean Default true Determines whether the agent will capture the EXPLAIN plan for slow queries. Only supported for MySQL and PostgreSQL. explain_threshold Type Float Default 0.5 Threshold in seconds for query execution time below which the slow query and the EXPLAIN plan (if supported) will not be captured. Relevant to slow queries only when record_sql is set to raw or obfuscated. Relevant to EXPLAIN plans only when explain_enabled is set to true. insert_sql_max_length Type Integer Default 2000 The character limit for the SQL query string. If you have many slow SQL queries with large chunks of information, this could negatively affect performance or how quickly you see your data in New Relic. Increase the value gradually until you find the right balance of information and performance. log_sql Type Boolean Default false Set to true to enable logging of queries to the agent log file instead of uploading to New Relic. Queries are logged using the record_sql mode. record_sql Type String Default obfuscated When the transaction tracer is on, query statements can optionally be recorded. The recorder has three modes: off: Send no queries. raw: Send the query statement in its original form. obfuscated: Strips out numeric and string literals. stack_based_naming (Play 2.x+ only) Type Boolean Default False Defaulted to true until Java agent version 3.12.1, when it was changed to false. This option is for Play 2.x+ only. Play/Scala instrumentation can use Thread.getStackTrace() to improve tracer naming, but at the cost of increased overhead. stack_trace_threshold Type Integer Default 0.5 Defines a threshold (in seconds) for collecting stack traces from an SQL call. When SQL statements exceed this threshold, the agent will capture the current stack trace. This is useful for pinpointing where long SQL calls originate from. top_n Type Integer Default 20 Use this setting to control the variety of your transaction traces. top_n is an integer that represents the number of unique, slow transactions that traces will be created for. If you want transaction traces to more accurately reflect the actual slowest transactions in your app, make this value lower. If you want to sample a more diverse array of transactions, make the value higher. A value of 0 would mean that only the slowest transaction is always traced. This is considered not to be optimal, though, because you may have one or two transactions that are always the slowest, and repeatedly seeing those same transaction traces will probably not give you much value. If the same transaction is often the slowest, the top_n setting allows the Java agent (over time) to sample the slowest n transactions. This gives you greater variety and more insight into your application. transaction_threshold Type String (float) Default apdex_f The time threshold used to determine when a transaction is eligible to be traced. When the transaction's response time exceeds this threshold, a transaction trace will be recorded and sent to New Relic. The default is apdex_f (default), which sets the threshold to be the \"Frustrated\" Apdex level (four times the apdex_t value). You can also set a specific time threshold by entering a float value that represents a number of seconds. slow_query_whitelist (DEPRECATED) Type String Default (none) Important This config has been deprecated as of agent version 5.10.0 and will be removed in a future agent version. Instead use collect_slow_queries_from. By default, high security mode does not allow the agent to collect slow queries. Enable this option to collect Cassandra queries from the DataStax driver, even with high security enabled. If you don't use high security, the agent collects slow queries automatically. For DataStax driver 2.1.2, add this rule to your allow list: transaction_tracer: slow_query_whitelist: 'com.newrelic.instrumentation.cassandra-datastax-2.1.2' Copy For DataStax driver 3.0.0, add this rule to your allow list: transaction_tracer: slow_query_whitelist: 'com.newrelic.instrumentation.cassandra-datastax-3.0.0' Copy collect_slow_queries_from Type String Default (none) By default, high security mode does not allow the agent to collect slow queries. Enable this option to collect Cassandra queries from the DataStax driver, even with high security enabled. If you don't use high security, the agent collects slow queries automatically. For DataStax driver 2.1.2, add this rule to your allow list: transaction_tracer: collect_slow_queries_from: 'com.newrelic.instrumentation.cassandra-datastax-2.1.2' Copy For DataStax driver 3.0.0, add this rule to your allow list: transaction_tracer: collect_slow_queries_from: 'com.newrelic.instrumentation.cassandra-datastax-3.0.0' Copy attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for transaction traces. If attributes.enabled at the root level is false, no attributes will be sent to transaction traces regardless on how this property (transaction_tracer.attributes.enabled) is set. attributes.include Type List of strings Default (none) If attributes are enabled for transaction traces, all attribute keys found in this list will be sent to New Relic in transaction traces. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in transaction traces. For more information, see the agent attribute rules. token_limit Type Integer Default 3000 Limits the number of Tokens that can be created per Transaction. Increasing this value may impact performance, because it increases the amount of memory the agent uses and the amount of data sent to New Relic. segment_limit Type Integer Default 3000 Limits the number of segments that can be created per transaction. Increasing this value may impact performance, because it increases the amount of memory the agent uses and the amount of data sent to New Relic. Transaction segments These options are set in the transaction_segments stanza and can be overridden by using a newrelic.config.transaction_segments prefixed system property. Transaction segments represent discrete pieces of work (generally method calls) and are displayed within transaction traces. Important Transaction segment attribute filtering requires Java agent version 4.10.0 or higher. attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for transaction segments. If attributes.enabled at the root level is false, no attributes will be sent to transaction segments regardless on how this property (transaction_segments.attributes.enabled) is set. attributes.include Type List of strings Default (none) If attributes are enabled for transaction segments, all attribute keys found in this list will be sent to New Relic in transaction segments. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in transaction segments. For more information, see the agent attribute rules. Browser monitoring These options are set in the browser_monitoring stanza and can be overridden by using a newrelic.config.browser_monitoring prefixed system property. Browser monitoring gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. auto_instrument Type Boolean Default true By default the agent automatically inserts API calls in compiled JSPs to inject the monitoring JavaScript into web pages. Set this attribute to false to turn off this behavior. disabled_auto_pages Type Comma-separated list of strings Default (none) When auto_instrument is true, by default all pages are instrumented. List all pages that you want the auto instrumentation to skip here. You can still use manual instrumentation on these pages. For example: browser_monitoring: disabled_auto_pages: /WEB-INF/jsp/testpage_1.jsp, /WEB-INF/jsp/testpage_2.jsp Copy attributes.enabled Type Boolean Default false This setting can be used to turn on or off all attributes for browser monitoring. This is the data you can query. If attributes.enabled is false at the root level, no attributes will be sent up in browser monitoring regardless on how this property under browser_monitoring is set. attributes.include Type List of Strings Default (none) If attributes are enabled for browser_monitoring, all attribute keys found in this list will be sent to New Relic in page views. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in page views. For more information, see the agent attribute rules. External tracer The external tracing options are set in the external_tracer stanza and can be overridden by using a newrelic.config.external_tracer prefixed system property. exclude_request_uri Type Boolean Default false This setting can be used to control the collection of outgoing request URIs for errors and transaction traces. Set this to true to disable collecting this information. Cross application tracer The cross application tracing options are set in the cross_application_tracer stanza and can be overridden by using a newrelic.config.cross_application_tracer prefixed system property. Cross application tracing adds request and response headers to external calls using the Apache HttpClient libraries. This provides better performance data when calling applications monitored by other New Relic Agents. enabled Type Boolean Default true Cross application tracing is enabled by default. Set this to false to turn it off. Error collector These options are set in the error_collector stanza and unless noted otherwise can be overridden by using a newrelic.config.error_collector prefixed system property. The error collector captures information about uncaught exceptions and sends them to New Relic for viewing. Tip For how to configure errors for the Java agent, including how to configure errors via the UI, see Java agent error configuration. enabled Type Boolean Default true Enable error collection. ignore_classes Type Stanza containing a list of fully qualified class_name strings Default (none) Specified exception class names will be ignored and will not affect error rate or Apdex score, or be reported to APM. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: ignore_classes: - \"com.example.MyException\" - \"com.example.DifferentException\" Copy ignore_messages Type Stanza containing a fully qualified class_name and a list of messages per error class Default (none) Specify exception class names the agent should ignore. Ignored messages will not affect error rate or Apdex score, or be reported to APM. Contains yaml pairs consisting of: A fully qualified exception class name that should not be reported to APM AND A list of exception messages to match against (at least one is required) If the exception class name matches an error but the message does not, then that error will not be ignored. Message strings use contains for matching. A message cannot be provided on its own and must always be paired with a fully qualified class name. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: ignore_messages: com.example.MyException: - \"Some error message to ignore\" - \"Some other error message to ignore\" com.example.DifferentException: - \"Some different error message to ignore\" Copy ignore_status_codes Type Comma-separated list of strings and ranges Default 404 A comma-separated list comprised of individual and dashed ranges of HTTP status codes that should not be treated as errors. If this property is commented out in the newrelic.yml configuration file, then the 404 status code will automatically be ignored. When using server-side configuration, the status code 404 must be specified in order for it to be ignored. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: ignore_status_codes: 404,507-511 Copy ignoreErrorPriority Type Boolean Default false With default ignoreErrorPriority as false, the agent reports the last error noticed if noticeError() is called multiple times in a transaction. If set to true, the agent reports the first error noticed if noticeError() is called multiple times in a transaction. For example: error_collector: ignoreErrorPriority: true Copy expected_classes Type Stanza containing a List of fully qualified class_name strings Default (none) Prevents specified exception classes from affecting error rate or Apdex score while still reporting the errors to APM. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: expected_classes: - \"com.example.MyException\" - \"com.example.DifferentException\" Copy expected_messages Type Stanza containing a fully qualified class_name and a List of messages per error class Default (none) Contains yaml pairs consisting of a fully qualified exception class name that should be marked as expected and thus prevented from affecting error rate or Apdex score and a List of exception messages to match against, the latter of which at least one is required. If the exception class name matches an error but the message does not, then that error will not be marked as expected and therefore will affect error rate and Apdex score. Message strings use contains for matching. A message cannot be provided on its own and must always be paired with a fully qualified class name. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: expected_messages: com.example.MyException: - \"Some expected error message\" - \"Some other expected error message\" com.example.DifferentException: - \"Some different expected error message\" Copy expected_status_codes Type Comma-separated list of strings and ranges Default (none) A comma-separated list comprised of individual and dashed ranges of HTTP status codes to be marked as expected and thus prevented from affecting error rate or Apdex score. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: expected_status_codes: 415,500-506 Copy attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for traced errors. If attributes.enabled is false at the root level, then no attributes will be sent to traced errors regardless of how this property is set under error_collector. attributes.include Type List of strings Default (none) If attributes are enabled for traced errors, all attribute keys found in this list will be sent to New Relic in traced errors. For more information, see the agent attribute rules. attributes.exclude Type List of strings Default (none) Attribute keys found in this list will not be sent to New Relic in traced errors. For more information, see the agent attribute rules. ignoreErrorPriority Type Boolean Default true When multiple errors are noticed in a transaction, only the last error will be reported by default. Setting this property to false will instead report only the first error that is noticed. For more information, see the noticeError API. For example: error_collector: ignoreErrorPriority: false Copy ignore_errors (DEPRECATED) Type Comma-separated list of Strings Default (none) All specified exception class names specified will not be treated as errors. Deprecated as of Java agent 3.40.0 and replaced by ignore_classes. For example: error_collector: ignore_errors: some.other.MyException Copy Strip exceptions These options are set in the strip_exception_messages stanza and unless noted otherwise can be overridden by using a newrelic.config.strip_exception_messagesprefixed system property. This configuration can be enabled to control whether Java exception messages are reported to New Relic. enabled Type Boolean Default false By default, this is set to false, which means that the agent sends messages from all exceptions to the New Relic collector. If you set this to true, the agent strips the messages from exceptions in order to prevent it from inadvertently capturing sensitive information. If you enable high security mode, this is automatically set to true. If you set enabled to true but you want the agent to capture messages from specific exceptions, add the exceptions to your allow list. whitelist (DEPRECATED) Type String Default (none) Important This config has been deprecated as of agent version 5.10.0 and will be removed in a future agent version. Instead use allowed_classes. If you set enabled to true but you want the agent to capture messages for specific exceptions, add each exception to the whitelist, separated by a comma. allowed_classes Type String Default (none) If you set enabled to true but you want the agent to capture messages for specific exceptions, add each exception to allowed_classes, separated by a comma. Thread profiler These options are set in the thread_profiler stanza and can be overridden by using a newrelic.config.thread_profiler prefixed system property. Thread profiler measures wall clock time, CPU time, and method call counts in your application's threads as they run. enabled Type Boolean Default true Enable the thread profiler. Transaction events These options are set in the transaction_events stanza and can be overridden by using a newrelic.config.transaction_events prefixed system property. Transaction events provide the data for displaying histograms and percentiles in the UI. Important Previously this stanza was called analytics_events. If your configuration file still uses analytics_events, update your agent to use transaction_events. enabled Type Boolean Default true Enable the transaction events service. max_samples_stored Type Integer Default 2000 Max 10000 The maximum number of sampled transaction events reported every 60 seconds. custom_request_headers Type List of maps Default None Important Unlike other settings, custom_request_headers have to be paired together and must be set in the newrelic.yml file. They can't be overwritten by Java virtual machine arguments (system property) or environment variables. A list of maps with the paired keys header_name and the optional header_alias. Choose one or more custom HTTP request headers to add as transaction attributes. You can list multiple header configurations: transaction_events: custom_request_headers: - header_name: \"X-Custom-Header-1\" - header_name: \"X-Custom-Header-2\" header_alias: \"CustomHeader2alias\" Copy In the first map set, X-Custom-Header-1 is captured and reported by the agent as the header name for a corresponding value from the request object. The header_name will also be the name of the attribute sent to New Relic. In the second map set, the request header is X-Custom-Header-2, but the CustomHeader2alias is the name sent to New Relic. attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for transaction events. If attributes.enabled is false at the root level, then no attributes will be sent to transaction events regardless of how this property is set under transaction_events. attributes.include Type List of Strings Default (none) If attributes are enabled for transaction events, all attribute keys found in this list will be sent to New Relic in transaction events. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in transaction events. For more information, see the agent attribute rules. Custom events Custom events are set in the custom_insights_events stanza and can be overridden by using a newrelic.config.custom_insights_events prefixed system property. APM lets you record custom event data via the New Relic language agent APIs, which you can then query. Important For Java agent versions prior to 4.1.0, the following YAML configuration is recognized: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy For agent versions 4.1.0 and above, the YAML configuration uses the nested stanza formatting: custom_insights_events: enabled: false max_samples_stored: 5000 Copy enabled Type Boolean Default true This enables the custom event service. max_samples_stored Type Integer Default/Max 10000 The maximum number of sampled custom events reported every 60 seconds. Hostname configuration These options are set in the process_host stanza and can be overridden by using a newrelic.config.process_host prefixed system property. These properties are used for configuring the hostname displayed in the UI: display_name Type String Default (none) Set a display name to decorate the \"host:port\" label in the New Relic UI. ipv_preference Type String Default 4 If the hostname cannot be determined, then the IP address of the host will be used. This property determines whether the IPv4 or IPv6 address should be used. The default is IPv4. Custom instrumentation These options set in the class_transformer stanza and can be overridden by using a newrelic.config.class_transformer prefixed system property. trace_annotation_class_name Type String Default (none) String containing the full class name of the annotation class the agent uses to determine which user-specified methods to instrument. For more information about custom annotations, see Java custom metric collection. com.newrelic.instrumentation.servlet-user Type Boolean Default false Enable this option to capture the userPrincipal name. This name is included as a transaction trace attribute, and can be queried. System properties You can override any setting in the newrelic.yml file by setting a system property. The system property corresponding to a given setting in the config file is the setting name prefixed by newrelic.config. For example, the system property for the log_level setting is newrelic.config.log_level. For settings nested in stanzas, prepend the stanza name to the setting name. For example, the system property for the enabled setting in the transaction_tracer stanza is newrelic.config.transaction_tracer.enabled. In addition to overriding configuration settings, the following system properties are recognized by the agent: newrelic.config.process_host.display_name Type String Default (none) Set a display name to decorate the \"host:port\" label in the New Relic UI. Requires Java agent 3.17 or higher. newrelic.config.file Type String Default (none) String containing a fully qualified path to the newrelic configuration file. If empty, the agent assumes newrelic.yml is in the same directory as newrelic.jar. newrelic.debug Type Boolean Default (none) Enable debug logging. newrelic.environment Type String Default (none) String containing the environment configuration for the agent to use. newrelic.home Type String Default (none) String containing the home directory of agent. This defaults to the same directory as the agent jarfile. newrelic.logfile Type String Default newrelic_agent.log String containing the name of the agent log file. Environment variables Environment variables take the highest precedence and override the system properties and yml config settings. To set environment variables, use the export VARNAME=value command. To permanently set environment variables, add the export line to a file such as ~/.bashrc or ~/.bash_profile. You can override any setting from a system property or in the newrelic.yml by setting an environment variable. The environment variable corresponding to a given setting in the config file is the setting name prefixed by NEW_RELIC with all dots (.) and dashes (-) replaced by underscores (_). For example, the environment variable for the log_level setting is NEW_RELIC_LOG_LEVEL. For settings nested in stanzas, prepend the stanza name to the setting name. For example, the environment variable for the enabled setting in the transaction_tracer stanza is NEW_RELIC_TRANSACTION_TRACER_ENABLED. Important Agent configuration via environment variables requires Java agent version 4.10.0 or higher. For agent versions older than 4.10.0 the following environment variables are available: NEW_RELIC_APP_NAME (REQUIRED) Type String Default (none) This setting is required. Contains the application name under which to report data to New Relic. Set the name of your application as you want it to appear in New Relic. If enable_auto_app_naming is false, the agent reports all data to this application. Otherwise, the agent reports only background tasks (transactions for non-web applications) to this application. To report data to more than one application, separate the application names with a semicolon ;. For example, to report data to My Application and My Application 2: app_name: My Application;My Application 2 Copy For more methods of naming your application, see Name your Java application. NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Type String Default false Enables distributed tracing. Case sensitive: use true or false. For more information, see the distributed tracing section. NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Type String Default (none) Set a display name to decorate the \"host:port\" label in the New Relic UI. NEW_RELIC_LICENSE_KEY (REQUIRED) Type String Default (none) This setting is required. Contains your New Relic account license. You must specify the license key associated with your New Relic account. This key binds your agent's data to your account in the New Relic service. NEW_RELIC_LOG Type String Default newrelic_agent.log The unqualified log file name or the string STDOUT which will log to standard out. Cloud platform utilization These options are set in the utilization stanza and can be overridden by using a newrelic.config.utilization prefixed system property. The agent collects utilization information and sends it to the New Relic service. The agent can collect information from Amazon Web Services (AWS) EC2 instances and Docker containers. detect_aws Type Boolean Default true Determines whether the agent polls AWS metadata API. detect_docker Type Boolean Default true Determines whether the agent reads Docker information from the file system. Async instrumentation These options are set directly in the common stanza and can be overridden by using a prefixed system property. token_timeout Type Integer Default (seconds) 180 The number of seconds after which the agent will automatically expire an async token that has not been explicitly expired with token.expire(). For usage instructions, see Tokens: Connect async threads. Important Increasing this value may impact performance, because it increases the amount of memory the agent uses and prevents transactions from being reported due to unexpired tokens. segment_timeout Type Integer Default (seconds) 600 The number of seconds after which the agent will automatically end a segment that has not been explicitly ended with segment.end() or segment.ignore(). For usage instructions, see Segments: Time arbitrary async activity. Important Increasing this value may impact performance, because it increases the amount of memory the agent uses and prevents transactions from being reported due to un-ended segments. Circuit breaker These settings customize the behavior of the Java circuit breaker. These settings are not included in newrelic.yml by default. You do not need to restart your JVM after changing them. If you want to customize the circuit breaker, add the stanza under the common stanza: common: &default_settings  OTHER_CONFIG_SETTINGS circuitbreaker: enabled: true memory_threshold: 20 gc_cpu_threshold: 10 Copy enabled Type Boolean Default true If your application is behaving as expected, you may want to disable the circuit breaker. memory_threshold Type Integer (0 to 100) Default 20 Customize the precentage of free heap memory below which the circuit breaker should trip. When the percentage of free heap memory is less than memory_threshold, and the CPU time spent doing garbage collection is greater than gc_cpu_threshold, the circuit breaker trips. In order to make the circuit breaker less likely to trip, decrease memory_threshold and/or increase gc_cpu_threshold. Adjust these values as needed, based on your application's operating performance and behavior. gc_cpu_threshold Type Integer (0 to 100) Default 10 Customize the precentage of garbage collection CPU time above which the circuit breaker should trip. When the percentage of free heap memory is less than memory_threshold, and the CPU time spent doing garbage collection is greater than gc_cpu_threshold, the circuit breaker trips. In order to make the circuit breaker less likely to trip, decrease memory_threshold and/or increase gc_cpu_threshold. Adjust these values as needed, based on your application's operating performance and behavior. Message tracer These options are set in the message_tracer stanza and can be overridden by using a newrelic.config.message_tracer prefixed system property. segment_parameters.enabled Type Boolean Default true Adds message properties to tracer attributes. Set this to false to turn it off. Distributed tracing Important Enabling distributed tracing disables cross application tracing, and has other effects on APM features. Before enabling, read the transition guide. Requires Java agent version 4.3.0 or higher. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. In the config file, it can be set in the distributed_tracing stanza. It can be overridden using a newrelic.config.distributed_tracing prefixed system property. enabled Type Boolean Default false Set this to true to enable distributed tracing. For example, to enable this in the config file, you would use: distributed_tracing: enabled: true Copy To enable this using a system property, you would use: -Dnewrelic.config.distributed_tracing.enabled=true Copy exclude_newrelic_header Type Boolean Default false By default, supported versions of the agent utilize both the newrelic header and W3C Trace Context headers for distributed tracing. The newrelic distributed tracing header allows interoperability with older agents that don't support W3C Trace Context headers. Agent versions that support W3C Trace Context headers will prioritize them over newrelic headers for distributed tracing. If you do not want to utilize the newrelic header, setting this to true will result in the agent excluding the newrelic header and only using W3C Trace Context headers for distributed tracing. For example, to exclude newrelic headers in the config file, you would use: distributed_tracing: exclude_newrelic_header: true Copy To exclude newrelic headers using a system property, you would use: -Dnewrelic.config.distributed_tracing.exclude_newrelic_header=true Copy Infinite Tracing Important Requirements: Java Agent 5.12.1 or higher. Infinite Tracing does not work if enable_auto_app_naming is enabled. To turn on Infinite Tracing, enable distributed tracing and add the additional setting below. For an example, see Language Agents: Configure Distributed Tracing. trace_observer.host Type String Default None For help getting a valid Infinite Tracing trace observer host entry, see find or create a Trace Observer. You can configure this via YAML: infinite_tracing: trace_observer: host: YOUR_TRACE_OBSERVER_HOST Copy You can also use the system property newrelic.config.infinite_tracing.trace_observer.host or the environment variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST. Span events Span events are reported for distributed tracing. Distributed tracing must be enabled to report span events. Span configuration is set in the span_events stanza and can be overridden by using a newrelic.config.span_events prefixed system property. Options include: enabled Type Boolean Default true Used to enable/disable span event reporting. attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for span events. If attributes.enabled at the root level is false, no attributes will be sent to span events regardless on how this property (span_events.attributes.enabled) is set. attributes.include Type List of strings Default (none) If attributes are enabled for span events, all attribute keys found in this list will be sent to New Relic in span_events. For more information, see the agent attribute rules. attributes.exclude Type List of strings Default (none) All attribute keys found in this list will not be sent to New Relic in span events. For more information, see the agent attribute rules. Important Span event attribute filtering requires Java agent version 4.10.0 or higher. Jar collector The Java agent collects and information about jars and their versions on the application classpath. Jar collection configuration is set in the jar_collector stanza and can be overridden by using a newrelic.config.jar_collector prefixed system property. Options include: enabled Type Boolean Default true Used to enable/disable jar collection and reporting. skip_temp_jars Type Boolean Default true Used to enable/disable collection of temporary jars. Temporary jars are those residing in the directory specified by the system property java.io.tmpdir. jars_per_second Type Integer Default 10 The maximum number of jars to process per second. Must be positive.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 34.34841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java <em>agent</em> configuration: Config file",
        "sections": "Java <em>agent</em> configuration: Config file",
        "tags": "<em>Agents</em>",
        "body": " false Enables plain text logging of all data sent to New Relic to the <em>agent</em> logfile. This setting is dynamic, so running <em>agents</em> will notice changes to newrelic.yml without a JVM restart. ca_bundle_path Type String Value Format &#x2F;path&#x2F;to&#x2F;ca&#x2F;cert&#x2F;bundle.pem Specifies a path to a custom SSL certificate"
      },
      "id": "603eb739e7b9d2a2432a07e0"
    },
    {
      "sections": [
        ".NET agent configuration",
        "Configuration overview",
        "Important",
        "Configuration methods and precedence levels",
        "Required environment variables",
        "Caution",
        ".NET Framework environment variables",
        ".NET Core environment variables",
        "Profiler conflict explanation",
        "Optional environment variables",
        "Setup options, newrelic.config",
        "Configuration element",
        "agentEnabled",
        "maxStackTraceLines",
        "timingPrecision",
        "Service element",
        "licenseKey (required)",
        "sendEnvironmentInfo",
        "syncStartup",
        "sendDataOnExit",
        "sendDataOnExitThreshold",
        "completeTransactionsOnThread",
        "requestTimeout",
        "autoStart",
        "ssl (DEPRECATED)",
        "Obscuring key element",
        "Proxy element",
        "host",
        "port",
        "uriPath",
        "domain",
        "user",
        "password",
        "passwordObfuscated",
        "Log element",
        "level",
        "auditLog",
        "console",
        "directory",
        "fileName",
        "Application element (required)",
        "name",
        "disableSamplers",
        "Data transmission element",
        "putForDataSend",
        "Host name",
        "Set using config file",
        "Set using environment variable",
        "Cloud platform utilization",
        "detectAws",
        "detectAzure",
        "detectGcp",
        "detectPcf",
        "detectDocker",
        "detectKubernetes",
        "Instrumentation options",
        "Instrumentation element",
        "Applications element (instrumentation)",
        "Attributes element",
        "enabled",
        "include",
        "exclude",
        "Feature options",
        "App pools",
        "defaultBehavior",
        "applicationPool",
        "Cross application traces",
        "Error collection",
        "Tip",
        "captureEvents",
        "maxEventSamplesStored",
        "ignoreClasses",
        "ignoreMessages",
        "ignoreErrors (DEPRECATED)",
        "ignoreStatusCodes",
        "expectedClasses",
        "expectedMessages",
        "expectedStatusCodes",
        "attributes",
        "High security mode",
        "Strip exception messages",
        "Transaction events",
        "maximumSamplesStored",
        "Custom events",
        "Custom parameters",
        "Labels (tags)",
        "Browser instrumentation",
        "autoInstrument",
        "requestPathsExcluded",
        "Slow queries",
        "Transaction traces",
        "transactionThreshold",
        "recordSql",
        "explainEnabled",
        "explainThreshold",
        "maxSegments",
        "maxExplainPlans",
        "Datastore tracer",
        "instanceReporting",
        "databaseNameReporting",
        "queryParameters",
        "Distributed tracing",
        "excludeNewrelicHeader",
        "Disable span events via config file",
        "Disable span events via environment variable",
        "Infinite Tracing",
        "trace_observer",
        "Span events",
        "Capture HTTP Request Headers",
        "Settings in app.config or web.config",
        "Enable and disable the agent",
        "Application name",
        "License key",
        "Change newrelic.config location",
        "Settings in appsettings.json"
      ],
      "title": ".NET agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Configuration"
      ],
      "external_id": "b89fa7fc399f2729bfee8f5106e777798a73177a",
      "image": "https://docs.newrelic.com/static/cffd7eb2d22c8e338531c38f35208c7c/c1b63/net-agent-config-settings-precedence_0.png",
      "url": "https://docs.newrelic.com/docs/agents/net-agent/configuration/net-agent-configuration/",
      "published_at": "2021-06-15T00:58:19Z",
      "updated_at": "2021-06-15T00:58:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains the configuration options for the APM .NET agent. Configuration overview APM agent configuration options allow you to control some aspects of how the agent behaves. Some of these config options are part of the basic install process (like setting your license key and app name), but most are more advanced settings, such as: setting a log level, setting up proxy host access, excluding certain attributes, and enabling distributed tracing. The .NET agent gets its configuration from the newrelic.config file, which is generated as part of the install process. By default, only a global newrelic.config file is created, but you can also create app-local newrelic.config files for finer control over a multi-app system. Other ways to set config options include: using environment variables, or setting server-side configuration from the UI. For more on the various config options and what overrides what, see Config settings precedence. Support for both .NET Framework and .NET Core use the same configuration options and have the same APM features, unless otherwise stated. If you make changes to the config file and want to validate that it's in the right format, you can check it against the XSD file (for example, at C:\\ProgramData\\New Relic\\.NET Agent\\newrelic.xsd for Windows) with any XSD validator. Important For IIS: after you change your newrelic.config or app.config file, perform an IISRESET from an administrative command prompt. Log level adjustments do not require a reset. Configuration methods and precedence levels Upon installation, the .NET agent's configuration file (newrelic.config) applies to all monitored applications, but you can configure the agent in other ways. Here's a diagram showing how different configuration options take precedence over one another: This diagram explains the order of precedence for different ways you might configure the .NET agent. Here are details about the configuration methods shown in the diagram, and their precedence levels: .NET configuration Details and precedence web.config or app.config or appsettings.json Configuration settings set in these files take highest precedence. However, if the agent is disabled in the local or global newrelic.config, the NewRelic.AgentEnabled settings in these files will be ignored. Environment variables Second-highest precedence. For more about these, see .NET environment variables. Server-side configuration Third-highest precedence. A limited number of server-side configuration settings are available; the other settings will come from other configuration sources. App-local newrelic.config Fourth-highest precedence. You can create app-local newrelic.config files to configure individual apps on a multi-app system. These local configuration files override settings in the global newrelic.config file. The agent looks for app-local config files in the following directories, in this order: A directory specified in your web.config or app.config file with the NewRelic.ConfigFile property The web app's root directory (with the app.config or web.config) The directory containing your app's executable file Note that the app-local config file must be complete and validate against the XSD file (for example, at C:\\ProgramData\\New Relic\\.NET Agent\\newrelic.xsd for Windows). Default (global) newrelic.config Default source and the lowest precedence. Will configure all applications on a host in the absence of other config files. The global config file is located in the New Relic agent home directory: %PROGRAMDATA%\\New Relic\\.NET Agent Required environment variables New Relic's .NET agent relies on environment variables to tell the .NET Common Language Runtime (CLR) to attach New Relic to your processes. Some .NET agent install procedures (like the MSI installer) will automatically set these variables for you; some procedures will require you to manually set them. Caution Security recommendation: You should consider what users can set system environment variables. You should also secure the accounts under which your applications execute to prevent user environment variables overriding system environment variables .NET Framework environment variables For .NET Framework, the following variables are required: COR_ENABLE_PROFILING=1 COR_PROFILER={71DA0A04-7777-4EC6-9643-7D28B46A8A41} NEWRELIC_INSTALL_PATH=path\\to\\agent\\directory Copy The .NET agent installer will add these to IIS or as system-wide environment variables. .NET Core environment variables For .NET Core, the following variables are required: Linux: CORECLR_ENABLE_PROFILING=1 CORECLR_PROFILER={36032161-FFC0-4B61-B559-F6C5D41BAE5A} CORECLR_NEWRELIC_HOME=path/to/agent/directory CORECLR_PROFILER_PATH=\"${CORECLR_NEWRELIC_HOME}/libNewRelicProfiler.so\" Copy Windows: CORECLR_ENABLE_PROFILING=1 CORECLR_PROFILER={36032161-FFC0-4B61-B559-F6C5D41BAE5A} NEWRELIC_INSTALL_PATH=path\\to\\agent\\directory CORECLR_NEWRELIC_HOME=path\\to\\agent\\directory Copy The .NET agent installer will add these to IIS or as system-wide environment variables. If your system has previously used monitoring services (non-New Relic), you may have a \"profiler conflict\" when trying to install and use the New Relic agent. More details: Profiler conflict explanation New Relics .NET agents rely on environment variables to tell the .NET Common Language Runtime (CLR) to load New Relic into your processes. The install-related environment variables are Microsoft variables, not New Relic variables. They can be used by other .NET profilers, and only one profiler can be attached to a process at a time. For this reason, if you have used previous application monitoring products, you may have profiler conflicts. For specific install instructions, see the .NET agent install documentation. Optional environment variables Some configuration options in New Relic's .NET agent can be set via environment variables as an alternative to setting them in a config file. Below is a list of environment variables recognized by the .NET agent with example values. NEW_RELIC_LICENSE_KEY=XXXXXXXX NEW_RELIC_LOG=MyApp.log NEW_RELIC_APP_NAME=Descriptive Name MAX_TRANSACTION_SAMPLES_STORED=500 MAX_EVENT_SAMPLES_STORED=500 NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_SPAN_EVENTS_ENABLED=false NEW_RELIC_LABELS=foo:bar;zip:zap NEW_RELIC_CONFIG_OBSCURING_KEY=XXXXXXXX NEW_RELIC_DISABLE_SAMPLERS=true NEWRELIC_PROFILER_LOG_DIRECTORY=path\\to\\agent\\directory (not configurable via config file) Copy Setup options, newrelic.config Use these options to setup and configure your agent via the newrelic.config file. The New Relic .NET agent supports the following categories of setup options: Configuration element Service element Obscuring key element Proxy element Log element Application element (configuration) Data transmission element Host name Configuration element The root element of the configuration document is a configuration element. <configuration xmlns=\"urn:newrelic-config\" agentEnabled=\"true\" maxStackTraceLines=\"50\" timingPrecision=\"low\"> Copy The configuration element supports the following attributes: agentEnabled Type Boolean Default true Enable or disable the New Relic agent. maxStackTraceLines Type Integer Default 80 The maximum number of stack frames to trace in any stack dump. timingPrecision Type String Default low Controls the precision of the timers. High precision will provide better data, but at a lower execution speed. Possible values are high and low. Service element The first child of the configuration element is a service element. The service element configures the agent's connection to the New Relic service. <service licenseKey=\"YOUR_LICENSE_KEY\" sendEnvironmentInfo=\"true\" syncStartup=\"false\" sendDataOnExit=\"false\" sendDataOnExitThreshold=\"60000\" autoStart=\"true\"/> Copy The service element supports the following attributes: licenseKey (required) Type String Default (none) Your New Relic license key. New Relic uses the license key to match your app's data to the correct account in the UI. Set the license key via environment variable. Alternatively, set the NEW_RELIC_LICENSE_KEY environment variable in the application's environment. NEW_RELIC_LICENSE_KEY=XXXXXXXX Copy sendEnvironmentInfo Type Boolean Default true Instructs the agent to record execution environment information. Environment information includes operating system, agent version, and which assemblies are available. syncStartup Type Boolean Default false Block application startup until the agent connects to New Relic. If set to true, the first transaction may take substantially longer to complete, because it is blocked until the connection to New Relic is finished. sendDataOnExit Type Boolean Default false Block application shutdown until the agent sends all data from the latest harvest cycle. sendDataOnExitThreshold Type Integer Default 60000 Unit Milliseconds The minimum amount of time the process must run before the agent blocks it from shutting down. This setting only applies when sendDataOnExit is true. completeTransactionsOnThread Type Boolean Default false If false, the agent uses a pool thread to complete the transaction processing. If true, the agent will complete transaction processing on the request thread. requestTimeout Type Integer Default 2000 (sendDataOnExit enabled) 120000 (sendDataOnExit disabled) Unit Milliseconds The agent's request timeout when communicating with New Relic. autoStart Type Boolean Default True Automatically start the .NET agent when the first instrumented method is hit. ssl (DEPRECATED) Type Boolean Default true The option to disable SSL is valid only for .NET agent versions 7.x and earlier. .NET agent version 8.x and higher communicate only via SSL. The agent communicates with New Relic via HTTPS by default, and New Relic requires HTTPS for all traffic to APM and the New Relic REST API. Obscuring key element The obscuringKey element is an optional child of the service element. The .NET Agent uses this value to deobfuscate supported configuration values. For example, when an obfuscated proxy password is supplied, it will be deobfuscated using this key. <service licenseKey=\"YOUR_LICENSE_KEY\"> <obscuringKey>OBSCURING_KEY</obscuringKey> </service> Copy The obscuring key may also be configured by setting the NEW_RELIC_CONFIG_OBSCURING_KEY environment variable. Caution Security recommendation: The placement of the obscuring Key in the same configuration file as an obfuscated value may pose a security risk. Consider placing the obscuring key in an environment variable and limiting access to environment variables within your environment. Proxy element The proxy element is an optional child of the service element. The proxy element is used when the agent communicates to the New Relic back-end service via a proxy. <service licenseKey=\"YOUR_LICENSE_KEY\"> <proxy host=\"hostname\" port=\"PROXY_PORT\" uriPath=\"path/to/something.aspx\" domain=\"mydomain.com\" user=\"PROXY_USERNAME\" password=\"PROXY_PASSWORD\" passwordObfuscated=\"OBFUSCATED_PROXY_PASSWORD\"/> </service> Copy The proxy element supports the following attributes: host Type String Default (none) Defines the proxy host. port Type Integer Default 8080 Defines the proxy port. uriPath Type String Default (none) Optionally define a proxy URI path. domain Type String Default (none) Optionally define a domain to use when authenticating with the proxy server. user Type String Default (none) Optionally define a user name for authentication. password Type String Default (none) Optionally define a password for authentication. passwordObfuscated Type String Default (none) For additional security, the .NET Agent supports the use of an obfuscated proxy password with the passwordObfuscated attribute. The obfuscated proxy password is generated using the following New Relic CLI command: newrelic agent config obfuscate --key OBSCURING_KEY --value \"CLEAR_TEXT_PROXY_PASSWORD\" Copy Important When using an obfuscated proxy password, the obscuring key must also be configured. Log element The log element is a child of the configuration element. The log element configures New Relic's logging . The agent generates its own log file to keep its logging information separate from your application's logs. <log level=\"info\" auditLog=\"false\" console=\"false\" directory=\"PATH\\TO\\LOG\\DIRECTORY\" fileName=\"FILENAME.log\" /> Copy The log element supports the following attributes: level Type String Default info Defines the level of detail recorded in the log file. Possible values, in increasing order of detail, are: off error warn info debug finest all Important Increasing the log level will increase New Relic's performance impact. auditLog Type Boolean Default false Records all data sent to and received from New Relic in both an auditlog log file and the standard log file. console Type Boolean Default false Send log messages to the console, in addition to the log file. directory Type String Default C:\\ProgramData\\New Relic\\.NET Agent\\Logs The directory to hold log files generated by the agent. If this is omitted, then a directory named logs in the New Relic agent install area will be used by default. fileName Type String Default (none) Defines a name for the log file. If you do not define a fileName, the name is derived from the name of the monitored process. Alternatively, set the NEW_RELIC_LOG environment variable in the application's environment. NEW_RELIC_LOG=MyApp.log Copy Application element (required) The application element is a child of the configuration element. This required element defines your application name, and disables or enables sampling. name Type String Default My Application The name of your .NET application is a child of the application element. New Relic will aggregate your data according to this name. For example, if you have two running applications named AppA and AppB, you will see two applications in the New Relic interface: AppA and AppB. You can also assign up to three names to your app. The first name is the primary name. For example: <application> <name>MY APPLICATION PRIMARY</name> <name>SECOND APP NAME</name> <name>THIRD APP NAME</name> </application> Copy Alternatively, set the NEW_RELIC_APP_NAME environment variable in the application's environment. NEW_RELIC_APP_NAME=Descriptive Name Copy disableSamplers Type Boolean Default false Samplers collect information about memory and CPU consumption. Set this to true to disable sampling. Alternatively, set the NEW_RELIC_DISABLE_SAMPLERS environment variable in the application's environment. NEW_RELIC_DISABLE_SAMPLERS=true Copy Data transmission element The dataTransmission element is a child of the configuration element. This element affects how data is sent to New Relic and can be used if you have specific data transmission requirements. <dataTransmission putForDataSend=\"false\" compressedContentEncoding=\"deflate\"/> Copy The dataTransmission element supports the following attributes: putForDataSend Type Boolean Default false Defines the HTTP method used when sending data to New Relic. Set this to true to enable using the PUT method when sending data. The POST method is used by default. Host name If the default host name label in the APM UI is not useful, you can decorate that name in the New Relic UI with a display name. After the application process is restarted and the .NET agent is reporting again, the display name will appear in the Servers drop-down list. This host name setting does not affect the list of hosts on your application's Summary page. To set a display name, choose one of the following options. The environment variable takes precedence over the config file value. Then restart your application to see your changes in the New Relic UI. Set using config file Set the displayName attribute in the processHost element in newrelic.config. The processHost element is a child of the configuration element. <configuration . . . > <processHost displayName=\"CUSTOM_NAME\" /> </configuration> Copy Set using environment variable Set the NEW_RELIC_PROCESS_HOST_DISPLAY_NAME environment variable: NEW_RELIC_PROCESS_HOST_DISPLAY_NAME = \"CUSTOM_NAME\" Copy Cloud platform utilization Configures the utilization configuration element to control how the agent collects utilization information and sends it to the New Relic service to determine pricing. The agent can collect information from Amazon Web Services (AWS) EC2 instances, Docker containers, Azure, Google Cloud Platform, Pivotal Cloud Foundry, and Kubernetes. detectAws Type Boolean Default true Determines whether the agent polls AWS metadata API. detectAzure Type Boolean Default true Determines whether the agent polls Azure metadata API. detectGcp Type Boolean Default true Determines whether the agent polls GCP metadata API. detectPcf Type Boolean Default true Determines whether the agent polls PCF information from environment variables. detectDocker Type Boolean Default true Determines whether the agent reads Docker information from the file system. detectKubernetes Type Boolean Default true Determines whether the agent polls Kubernetes information from environment variables. Instrumentation options Use these options to configure which elements of your application and environment to instrument. New Relic for .NET supports the following categories of instrumentation options: Instrumentation element Applications element (instrumentation) Attributes element Instrumentation element The instrumentation element is a child of the configuration element. By default, the .NET agent instruments IIS asp worker processes and Azure web and worker roles. To instrument other processes, see Instrumenting custom applications. Applications element (instrumentation) The applications element is a child of the instrumentation element. The applications element specifies which non-web apps to instrument. It contains a name attribute. Important This is not the same as the application (configuration) element, which is a child of the configuration element. <instrumentation> <applications> <application name=\"MyService1.exe\" /> <application name=\"MyService2.exe\" /> <application name=\"MyService3.exe\" /> </applications> </instrumentation> Copy Attributes element An attribute is a key/value pair that determines the properties of an event or transaction. Each attribute is sent to APM transaction traces, APM error traces, Transaction events, TransactionError events, or PageView events. The primary attributes element enables or disables attribute collection for the .NET agent, and defines specific attributes to collect or exclude. You can also configure attribute settings based on their destination: Error collection, transaction traces, Browser instrumentation, and transaction events. In this example, the agent excludes all attributes whose key begins with myApiKey (myApiKey.bar, myApiKey.value), but collects the custom attribute myApiKey.foo. <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> Copy You can view the .NET APM attributes on the .NET agent attributes page. You can also define custom attributes with the agent API call AddCustomParameter. enabled Type Boolean Default true Enable or disable attribute collection. When set to false in the primary attribute element, this setting overrides all attribute settings for individual destinations. include Type String Default (none) If attributes are enabled, the agent will collect all attribute keys specified in this list. To specify multiple attribute keys, specify each individually. You can also use a * wildcard character at the end of a key to match multiple attributes (for example, myApiKey.*). For more information, see Attribute rules. exclude Type String Default (none) If attributes are enabled, the agent will not collect attribute keys specified in this list. To specify multiple attribute keys, specify each individually. You can also use a * wildcard character at the end of a key to match multiple attributes (for example, myApiKey.*). For more information, see Attribute rules. Feature options Use these options to enable, disable, and configure New Relic features. New Relic for .NET allows you to configure the following features: App pools Cross application traces Error collection High security mode Strip exception messages Transaction events Custom events Custom parameters Tags/labels Browser instrumentation Slow Queries Transaction traces Datastore tracer Distributed tracing Span events Capture HTTP Request Headers App pools Important This is only applicable to a system's global config file. The applicationPools element is a child of the configuration element. The applicationPools element specifies for the profiler exactly which application pools to instrument and uses the same name as the IIS application pool name. This configuration element is useful when you may need to instrument only a small subset of your app pools. For example, a given server might have several hundred application pools, but only a few of those pools need to be instrumented by the .NET agent. Here is an example of disabling instrumentation for specific application pools: <applicationPools> <applicationPool name=\"Foo\" instrument=\"false\"/> <applicationPool name=\"Bar\" instrument=\"false\"/> </applicationPools> Copy Here is an example of disabling instrumentation for all application pools currently executing on the server and enabling instrumentation for specific application pools: <applicationPools> <defaultBehavior instrument=\"false\"/> <applicationPool name=\"Foo\" instrument=\"true\"/> <applicationPool name=\"Bar\" instrument=\"true\"/> </applicationPools> Copy The applicationPools element supports the following elements: defaultBehavior Type Boolean Default false Defines how the .NET agent will behave on a \"global\" level for application pools served via IIS. The .NET agent instruments all application pools by default. When true, application pools listed under applicationPool with an instrument attribute set to false will not be instrumented. Essentially, when set to false, the application pool list acts as an allow list. When set to true, the application pool list acts as a deny list. applicationPool Defines instrumentation behavior for a specific application pool. The name attribute is the name of an application pool. Enable or disable profiling in the instrument attribute. Define this application in the name attribute. Cross application traces The crossApplicationTracer element is a child of the configuration element. crossApplicationTracer links transaction traces across applications. When linked in a service-oriented architecture, all instrumented applications that communicate with each other via HTTP will now \"link\" transaction traces with the applications that they call and the applications they are called by. Cross application tracing makes it easier to understand the performance relationship between services and applications. <crossApplicationTracer enabled=\"true\"/> Copy The crossApplicationTracer element supports the following attribute: enabled Type Boolean Default true Enable or disable cross application tracing Error collection The errorCollector element is a child of the configuration element. errorCollector configures error collection, which captures information about uncaught exceptions and sends them to New Relic. <errorCollector enabled=\"true\" captureEvents=\"true\" maxEventSamplesStored=\"100\"> <ignoreClasses> <errorClass>System.IO.FileNotFoundException</errorClass> <errorClass>System.Threading.ThreadAbortException</errorClass> </ignoreClasses> <ignoreMessages> <errorClass name=\"System.Exception\"> <message>Ignore message</message> <message>Ignore too</message> </errorClass> </ignoreMessages> <ignoreStatusCodes> <code>401</code> <code>404</code> </ignoreStatusCodes> <expectedClasses> <errorClass>System.ArgumentNullException</errorClass> <errorClass>System.ArgumentOutOfRangeException</errorClass> </expectedClasses> <expectedMessages> <errorClass name=\"System.Exception\"> <message>Expected message</message> <message>Expected too</message> </errorClass> </expectedMessages> <expectedStatusCodes>403,500-505</expectedStatusCodes> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </errorCollector> Copy Tip For an overview of error configuration in APM, see Manage errors in APM. The errorCollector element supports the following elements and attributes: enabled Type Boolean Default true Enable or disable the error collector. captureEvents Type Boolean Default true Enable or disable the capturing of error events. maxEventSamplesStored Type Integer Default 100 Reservoir limit for error events. ignoreClasses A list of fully qualified class names to be ignored. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used ignoreMessages An optional map of fully qualified class names to list of strings matching a substring of the message of an error. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used ignoreErrors (DEPRECATED) Type String Default (none) Lists specific exceptions to not report to New Relic. The full name of the exception should be used, such as System.IO.FileNotFoundException. ignoreStatusCodes Type String Default (none) Lists specific HTTP error codes to not report to New Relic. You can use standard integral HTTP error codes, such as just 401, or you may use Microsoft full status codes with decimal points, such as 401.4 or 403.18. The status codes should be equal to or greater than 400. expectedClasses A list of fully qualified class names to be marked as expected. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used expectedMessages An optional map of fully qualified class names to list of strings matching a substring of the message of an error. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used expectedStatusCodes A comma separated list of status codes. The list may include integer ranges, using a single dash (-) and will be inclusive of both the starting and ending integer in the range. attributes Use this sub-element to customize your agent attribute settings for error traces. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. High security mode The highSecurity element is a child of the configuration element. To enable high security mode, set this property to true and enable the high security property in the New Relic user interface. Enabling high security turns SSL on; request parameters, custom parameters and HTTP request headers are not collected; strip exception messages is enabled; and queries can't be sent to New Relic in their raw form. enabled Type Boolean Default false Enable or disable high security mode. Example: <highSecurity enabled=\"true\"/> Copy Strip exception messages The stripExceptionMessages element is a child of the configuration element. To enable strip exception messages, set this property to true. By default, this is set to false, which means that the agent sends messages from all exceptions to the New Relic collector. If you enable high security mode, this is automatically changed to true, and the agent strips the messages from exceptions. enabled Type Boolean Default false Enable or disable strip exception messages. Example: <stripExceptionMessages enabled=\"true\"/> Copy Transaction events The transactionEvents element is a child of the configuration element. Use transactionEvents to configure transaction events. <transactionEvents enabled=\"true\" maximumSamplesStored=\"10000\"> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </transactionEvents> Copy The transactionEvents element supports the following attributes: enabled Type Boolean Default true Enable or disable the event recorder. maximumSamplesStored Type Integer Default 10000 The maximum number of samples to store in memory at once. Alternatively, set the MAX_TRANSACTION_SAMPLES_STORED environment variable in the application's environment. MAX_TRANSACTION_SAMPLES_STORED=500 Copy attributes Use this sub-element to customize your agent attribute settings for transaction events. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. Tip These attribute settings are specific to transaction events. Attribute settings can be applied globally to all event types to with this configuration setting. Caution When distributed tracing and/or Infinite Tracing are enabled, information from transaction events is applied to the root Span Event of the transaction. Consider applying any attribute settings for transaction events to span events and/or apply them as Global Attribute settings. Custom events The customEvents element is a child of the configuration element. Use customEvents to configure custom events. <customEvents enabled=\"true\" maximumSamplesStored=\"10000\"/> Copy The CustomEvents element supports the following attributes: enabled Type Boolean Default true Enable or disable the event recorder. maximumSamplesStored Type Integer Default 10000 The maximum number of samples to store in memory at once. Alternatively, set the MAX_EVENT_SAMPLES_STORED environment variable in the application's environment. MAX_EVENT_SAMPLES_STORED=500 Copy Custom parameters The customParameters element is a child of the configuration element. Use customParameters to configure custom parameters. <customParameters enabled=\"true\" /> Copy The CustomParameters element supports the following attributes: enabled Type Boolean Default true Enable or disable the capture of custom parameters. Labels (tags) The labels element is a child of the configuration element. This sets tag names and values. The list is a semicolon delimited list of colon-separated name and value pairs. You can also use with the NEW_RELIC_LABELS environment variable. Example: <labels>foo:bar;zip:zap</labels> Copy Browser instrumentation The browserMonitoring element is a child of the configuration element. browserMonitoring configures Browser monitoring in your .NET application. Browser gives you insight your end users' performance experience. This is accomplished by measuring the time it takes for your users' browsers to download and render your webpages by injecting a small amount of JavaScript code into the header and footer of each page. // If you use both the Exclude and Attribute elements // the Exclude element must be listed first. <browserMonitoring autoInstrument=\"true\"> <requestPathsExcluded> <path regex=\"url-regex-1\"/> <path regex=\"url-regex-2\"/> ... <path regex=\"url-regex-n\"/> </requestPathsExcluded> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </browserMonitoring> Copy The browserMonitoring element supports the following attributes: autoInstrument Type Boolean Default true By default the agent automatically injects the Browser agent JavaScript. To turn off automatic injection, set this attribute to false. attributes Use this sub-element to customize your agent attribute settings for Browser. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. requestPathsExcluded Use this sub-element to prevent the Browser agent from being injected in specific pages. The element is used as follows: <requestPathsExcluded> <path regex=\"url-regex-1\"/> <path regex=\"url-regex-2\"/> ... <path regex=\"url-regex-n\"/> </requestPathsExcluded> Copy The agent will not inject the Browser agent into pages whose URL matches one of the specified regular expressions. The regular expression should follow Microsoft guidelines for the Regex class. It is a reference to the virtual directory of the path in your application and not the full URL of the path you wish to exclude. For example, to exclude the pages in https://www.mywebsite.com/mywebpages/ you would simply insert /mywebpages/ as the path regex value. The requestPathsExcluded element should be used in cases where it is impossible or undesirable to use the DisableBrowserMonitoring() call. To minimize a possible performance impact try to use as few regular expressions as possible and keep them as simple as possible. Slow queries The slowSql element is a child of the configuration element. slowSql configures capturing information about slow query executions, and captures and obfuscates explain plans for these queries. <slowSql enabled=\"true\"/> Copy The slowSql element supports the following attribute: enabled Type Boolean Default true Enable or disable slow query tracing. Transaction traces The transactionTracer element is a child of the configuration element. transactionTracer configures transaction traces. Included in the trace is the exact call sequence of the transactions, including any query statements issued. <transactionTracer enabled=\"true\" transactionThreshold=\"apdex_f\" recordSql=\"obfuscated\" explainEnabled=\"true\" explainThreshold=\"500\" maxSegments=\"3000\" maxExplainPlans=\"20\"> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </transactionTracer> Copy The transactionTracer element supports the following attributes: enabled Type Boolean Default true Enable or disable transaction traces. transactionThreshold Type String Default apdex_f Defines the threshold for transaction traces. If a transaction takes longer than the threshold, it is eligible for being traced. See transaction trace basics for more about the rules governing traces. The default value is apdex_f, which sets the threshold to four times the application's apdex_t value. For more information about apdex_t, see Apdex. You can also set the threshold to be a specific time value in milliseconds. recordSql Type String Default obfuscated Select a query tracing policy. Options are off, which records nothing; obfuscated, which records an obfuscated version of the query; or raw, which records the query exactly as it is issued to the database. Caution Recording raw queries may capture sensitive information. explainEnabled Type Boolean Default false When true, the agent captures EXPLAIN statements for slow queries. explainThreshold Type Integer Default 500 Unit Milliseconds The agent collects slow query data for queries that exceed this threshold, along with any available explain plans, as part of transaction traces. maxSegments Type Integer Default 3000 The maximum number of segments to collect in a transaction trace. maxExplainPlans Type Integer Default 20 The maximum number of explain plans to collect during a harvest cycle. attributes Use this sub-element to customize your agent attribute settings for transaction traces. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. Datastore tracer The datastoreTracer element is a child of the configuration element. <datastoreTracer> <instanceReporting enabled=\"true\" /> <databaseNameReporting enabled=\"true\" /> <queryParameters enabled=\"false\" /> </datastoreTracer> Copy The datastoreTracer element supports the following sub-elements: instanceReporting Use this sub-element to enable collection of datastore instance metrics (such as the host and port) for some database drivers. These are reported on slow query traces and transaction traces. The default value of attribute enabled is true. databaseNameReporting Use this sub-element to enable collection of the database name on slow query traces and transaction traces for some database drivers. The default value of attribute enabled is true. queryParameters Use this sub-element to enable collection of the SQL query parameters on slow query traces. The default value of attribute enabled is false. Caution Recording query parameters may capture sensitive information. The transactionTracer.recordSql configuration option must be set to raw or this option is ignored. Distributed tracing The distributedTracing element is a child of the configuration element. <distributedTracing enabled=\"false\" excludeNewrelicHeader=\"false\"/> Copy Distributed tracing lets you see the path that a request takes as it travels through a distributed system. Enabling distributed tracing disables cross application tracing, and has other effects on APM features. Before enabling, read the planning guide. Important Requires .NET agent version 8.6.45.0 or higher. The distributedTracing element supports the following attributes: To enable or disable, see Enable distributed tracing. enabled Type Boolean Default false Alternatively, enable distributed tracing via the NEW_RELIC_DISTRIBUTED_TRACING_ENABLED environment variable in the application's environment. NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy excludeNewrelicHeader Type Boolean Default false By default, supported versions of the agent utilize both the newrelic header and W3C Trace Context headers for distributed tracing. The newrelic distributed tracing header allows interoperability with older agents that don't support W3C Trace Context headers. Agent versions that support W3C Trace Context headers will prioritize them over newrelic headers for distributed tracing. If you do not want to utilize the newrelic header, setting this to true will result in the agent excluding the newrelic header and only using W3C Trace Context headers for distributed tracing. Distributed tracing reports span events. Span event reporting is enabled by default, but distributed tracing must be enabled for spans to be reported. To disable span events, choose one of the following options: Disable span events via config file Set the <spanEvents> element to false to disable via the newrelic.config file. This element is a child of the <configuration> element. <configuration . . . > <spanEvents enabled=\"false\" /> </configuration> Copy Disable span events via environment variable Set the NEW_RELIC_SPAN_EVENTS_ENABLED environment variable in the application's environment. NEW_RELIC_SPAN_EVENTS_ENABLED=false Copy Infinite Tracing Infinite Tracing extends the distributed tracing service by employing a trace observer that is external to the agent. It observes 100% of your application traces across various services and provides actionable data so you can solve issues faster. Important Infinite Tracing requires .NET Agent version 8.30 or higher. To turn on Infinite Tracing, enable distributed tracing and add the additional settings below <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy The infiniteTracing element supports the following elements: trace_observer The trace_observer element identifies an observer host that is independent from the agent. For help getting a valid Infinite Tracing trace observer host entry, see Find or create a trace observer endpoint. The trace observer may be configured using the NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST environment variable as well. Important When configuring the trace observer, you should not supply the protocol as part of the host. For example, use myhost.infinitetracing.com instead of https://myhost.infinitetracing.com. Span events The spanEvents element is a child of the configuration element. Use spanEvents to configure span events. <spanEvents enabled=\"true\"> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </spanEvents> Copy The spanEvents element supports the following attributes: enabled Type Boolean Default true Enable or disable the event recorder. attributes Use this sub-element to customize your agent attribute settings for span events. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. Tip These attribute settings are specific to span events. Attribute settings may be applied globally to all event types to with this configuration setting. Capture HTTP Request Headers The allowAllHeaders element is a child of the configuration element. Set this to true to allow the .NET Agent to capture all HTTP request headers as request.headers.{http-header-name} attributes. Set this to false to only allow the .NET agent to collect the following HTTP request headers: request.headers.referer request.headers.accept request.headers.content-length request.headers.host request.headers.user-agent Copy enabled Type Boolean Default false Enable or disable HTTP request headers capture. Example: <allowAllHeaders enabled=\"true\" /> <attributes enabled=\"true\"> <include>request.headers.*</include> </attributes> Copy Important The allowAllHeaders setting is only available in the .NET Agent version 8.40.0+. When using allowAllHeaders to capture attributes, the captured request header attributes are still being controlled by the root level and destination level attributes settings. Without setting the request.header.* in the include list under the attributes element (see the following), the .NET Agent still filters out all header attributes. The default newrelic.config is set to include the request.header.*. <allowAllHeaders enabled=\"true\" /> <attributes enabled=\"true\"> <include>request.headers.*</include> ... </attributes> Copy The default newrelic.config is also set to explicitly exclude the following HTTP request headers to prevent the .NET Agent collecting unwanted data. <attributes enabled=\"true\"> <exclude>request.headers.cookie</exclude> <exclude>request.headers.authorization</exclude> <exclude>request.headers.proxy-authorization</exclude> <exclude>request.headers.x-*</exclude> </attributes> Copy Settings in app.config or web.config For ASP.NET and .NET Framework console apps you can also configure the following settings in your app's app.config or web.config, within the outermost element, <configuration>: Enable and disable the agent <appSettings> <add key = \"NewRelic.AgentEnabled\" value=\"false\" /> </appSettings> Copy Important If the agent is disabled in the local or global newrelic.config, the NewRelic.AgentEnabled settings in these files will be ignored. Application name For more information, see Name your .NET application. <appSettings> <add key = \"NewRelic.AppName\" value =\"Descriptive Name\" /> </appSettings> Copy License key <appSettings> <add key = \"NewRelic.LicenseKey\" value =\"XXXXXXXX\" /> </appSettings> Copy Change newrelic.config location Designates an alternative location for the config file outside of the local root of the app or global config location. The location entered must be an absolute path. <appSettings> <add key = \"NewRelic.ConfigFile\" value=\"C:\\Path-to-alternate-config-dir\\newrelic.config\" /> </appSettings> Copy Settings in appsettings.json For .NET Core apps, you can configure the following settings in appsettings.json if the following is true: The appsettings.json file must be located in the current working directory of the application. The application must have the following dependencies: Microsoft.Extensions.Configuration Microsoft.Extensions.Configuration.Json Microsoft.Extensions.Configuration.EnvironmentVariables Enable and disable the agent { \"NewRelic.AgentEnabled\":\"false\" } Copy Important If the agent is disabled in the local or global newrelic.config, the NewRelic.AgentEnabled setting in this file will be ignored. Application name For more information, see Name your .NET application. { \"NewRelic.AppName\": \"Descriptive Name\" } Copy License key { \"NewRelic.LicenseKey\": \"XXXXXXXX\" } Copy Change newrelic.config location Designates an alternative location for the config file outside of the local root of the app or global config location. The location entered must be an absolute path. { \"NewRelic.ConfigFile\": \"C:\\\\Path-to-alternate-config-dir\\\\newrelic.config\" } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 34.34841,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET <em>agent</em> configuration",
        "sections": ".NET <em>agent</em> configuration",
        "tags": "<em>Agents</em>",
        "body": "). Default (global) newrelic.config Default <em>source</em> and the lowest precedence. Will configure all applications on a host in the absence of other config files. The global config file is located in the New Relic <em>agent</em> home directory: %PROGRAMDATA%\\New Relic\\.NET <em>Agent</em> Required environment variables New"
      },
      "id": "60446c3b196a679d6a960f7a"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 291.1938,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": " your applications, as well as detailed information, such as distributed tracing. To <em>get</em> <em>started</em> with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - <em>OpenTelemetry</em>: Click the service you want to know more about, and if you need help understanding the data"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.6934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick <em>start</em>",
        "sections": "<em>OpenTelemetry</em> quick <em>start</em>",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": " already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with <em>OpenTelemetry</em> To <em>get</em> <em>started</em>, you instrument your service with <em>OpenTelemetry</em>. <em>OpenTelemetry</em> has language-specific products"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.03165,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "You can send <em>OpenTelemetry</em> data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to <em>get</em> <em>started</em> with <em>OpenTelemetry</em>. If you&#x27;re already familiar with <em>OpenTelemetry</em> and want to jump into the setup, go to our <em>OpenTelemetry</em> quick <em>start</em>"
      },
      "id": "603e81ba196a67304da83dab"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/istio/istio-adapter": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.4595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.28947,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to New Relic's open source telemetry integrations",
        "Tip",
        "Types of integrations",
        "How they work"
      ],
      "title": "Introduction to New Relic's open source telemetry integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "Get started"
      ],
      "external_id": "239889ec292525fcfd6b417d243943ea7b3e0529",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations/",
      "published_at": "2021-06-15T13:23:46Z",
      "updated_at": "2021-03-16T06:12:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides open source integrations that report telemetry data from telemetry tools to your New Relic account. Tip To use telemetry integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of integrations We have open source integrations that report data from OpenCensus, OpenTelemetry, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your telemetry data in one place: the New Relic platform. See our list of open source telemetry integrations (to browse all New Relic solutions, see our integrations page). How they work These integrations were built using our Telemetry SDKs, which are open-source language-specific libraries for reporting metrics, trace data, and other telemetry data to New Relic. If our pre-built integrations don't meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest APIs. For example, metrics reported by the DropWizard exporter are ingested via the Metric API, so to understand how to query and chart that type of data, you could read Query metric data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.06618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "sections": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "New Relic provides <em>open</em> <em>source</em> <em>integrations</em> that report <em>telemetry</em> data from <em>telemetry</em> tools to your New Relic account. Tip To use <em>telemetry</em> <em>integrations</em> and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up"
      },
      "id": "603e95ab28ccbc036aeba789"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/kamon/kamon-reporter": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.04065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 150.42453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Troubleshoot the OpenTelemetry exporter",
        "Install",
        "Traces",
        "Trace sampling",
        "Metrics",
        "Caution",
        "Errors"
      ],
      "title": "Troubleshoot the OpenTelemetry exporter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "524e7f170806e42fddc8dee79c8da64b1640b8fb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/troubleshooting/troubleshoot-opentelemetry-exporter/",
      "published_at": "2021-06-15T12:05:18Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the OpenTelemetry SDK, APIs, and instrumentation are subject to change. If you're using New Relic's OpenTelemetry exporter, but you're not seeing the data you expect, this guide should help. OpenTelemetry currently supports two telemetry types: distributed traces and metrics. Through the New Relic UI, you can see your traces and metrics, as well as a view that focuses on errors. Learn more about how to find your data. Install To send your data through the OpenTelemetry collector, configure your OpenTelemetry SDK service.name as a resource and configure the SDK to send data to the collector. Then configure the collector with the New Relic exporter with your Insert API key. Consult the collector documentation if you're having trouble sending data through the collector. Once OpenTelemetry is configured with the API key and service name, you should be able to find your service in the explorer. Select your service to view its summary page. Traces When viewing your OpenTelemetry data, on the left side of the UI you can select Distributed tracing to see distributed traces. If you dont see traces: Ensure your service was reporting during the time window. Ensure you've added OpenTelemetry API calls to create trace spans. If you're using OpenTelemetry auto-instrumentation, ensure the instrumentation supports the libraries and frameworks you're using. Traces are the most mature telemetry type in OpenTelemetry, so you'll find the richest performance information from traces. Trace sampling Our trace UI will only reflect the data sent to us. This means that throughput and other counts may not reflect the unsampled data. You can configure sampling application-side using the OpenTelemetry SDKs. If you enable our Infinite Tracing feature, you have the option to send us all of your trace data and use New Relic sampling. Note that New Relic may rate-limit trace data. Metrics When viewing your OpenTelemetry data, on the left side of the UI you can select Metrics explorer to visualize metrics and create dashboards. If you dont see metrics, you may need to add OpenTelemetry API calls to add the metrics that you care about. Caution The OpenTelemetry standard for metric naming is still being defined and to date most instrumentation includes trace spans but not metrics. We expect that more instrumentation will include metrics in the coming months. Errors When viewing your OpenTelemetry data, on the left side of the UI you can select Errors to understand what errors your service is generating. The count of errors is based on how many traces have a span with the attribute error.stack. If you dont see the errors listed that you expect to see, check that your instrumentation sets the following three attributes: error.stack error.msg error.type In order for the error to be listed, a span must have an attribute that starts with error. Caution The OpenTelemetry standard for representing errors in traces and metrics is still being defined so these attribute names are subject to change. We expect the specification to be frozen very soon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.55174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "sections": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the <em>OpenTelemetry</em> SDK, APIs, and instrumentation are subject to change. If you&#x27;re using New Relic&#x27;s <em>OpenTelemetry</em> exporter, but you&#x27;re not seeing the data you expect"
      },
      "id": "603e897de7b9d2ca9b2a07d6"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/micrometer/micrometer-metrics-registry": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.4593,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 141.28946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to New Relic's open source telemetry integrations",
        "Tip",
        "Types of integrations",
        "How they work"
      ],
      "title": "Introduction to New Relic's open source telemetry integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "Get started"
      ],
      "external_id": "239889ec292525fcfd6b417d243943ea7b3e0529",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations/",
      "published_at": "2021-06-15T13:23:46Z",
      "updated_at": "2021-03-16T06:12:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides open source integrations that report telemetry data from telemetry tools to your New Relic account. Tip To use telemetry integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of integrations We have open source integrations that report data from OpenCensus, OpenTelemetry, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your telemetry data in one place: the New Relic platform. See our list of open source telemetry integrations (to browse all New Relic solutions, see our integrations page). How they work These integrations were built using our Telemetry SDKs, which are open-source language-specific libraries for reporting metrics, trace data, and other telemetry data to New Relic. If our pre-built integrations don't meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest APIs. For example, metrics reported by the DropWizard exporter are ingested via the Metric API, so to understand how to query and chart that type of data, you could read Query metric data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 137.06618,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "sections": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "New Relic provides <em>open</em> <em>source</em> <em>integrations</em> that report <em>telemetry</em> data from <em>telemetry</em> tools to your New Relic account. Tip To use <em>telemetry</em> <em>integrations</em> and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up"
      },
      "id": "603e95ab28ccbc036aeba789"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/opencensus/opencensus-exporter": [
    {
      "sections": [
        "Introduction to New Relic's open source telemetry integrations",
        "Tip",
        "Types of integrations",
        "How they work"
      ],
      "title": "Introduction to New Relic's open source telemetry integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "Get started"
      ],
      "external_id": "239889ec292525fcfd6b417d243943ea7b3e0529",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/get-started/introduction-new-relics-open-source-telemetry-integrations/",
      "published_at": "2021-06-15T13:23:46Z",
      "updated_at": "2021-03-16T06:12:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides open source integrations that report telemetry data from telemetry tools to your New Relic account. Tip To use telemetry integrations and the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Types of integrations We have open source integrations that report data from OpenCensus, OpenTelemetry, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your telemetry data in one place: the New Relic platform. See our list of open source telemetry integrations (to browse all New Relic solutions, see our integrations page). How they work These integrations were built using our Telemetry SDKs, which are open-source language-specific libraries for reporting metrics, trace data, and other telemetry data to New Relic. If our pre-built integrations don't meet your needs, you can use the Telemetry SDKs to build your own telemetry tools. Under the hood, data reported by these solutions are ingested via our data ingest APIs. For example, metrics reported by the DropWizard exporter are ingested via the Metric API, so to understand how to query and chart that type of data, you could read Query metric data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.50522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "sections": "Introduction to New Relic&#x27;s <em>open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": " to 100GB of data for free each month. Forever. Types of <em>integrations</em> We have <em>open</em> <em>source</em> <em>integrations</em> that report data from <em>OpenCensus</em>, <em>OpenTelemetry</em>, DropWizard, Prometheus, and more. With these solutions, you can aggregate all your <em>telemetry</em> data in one place: the New Relic platform. See our list"
      },
      "id": "603e95ab28ccbc036aeba789"
    },
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.04047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 262.0149,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": ", and as more vendors move to support this <em>open</em> standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build <em>integrations</em> into <em>OpenTelemetry</em> or add instrumentation directly to <em>source</em> code, ensuring end"
      },
      "id": "603e81ba196a67304da83dab"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 389.87225,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.9709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Troubleshoot the OpenTelemetry exporter",
        "Install",
        "Traces",
        "Trace sampling",
        "Metrics",
        "Caution",
        "Errors"
      ],
      "title": "Troubleshoot the OpenTelemetry exporter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "524e7f170806e42fddc8dee79c8da64b1640b8fb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/troubleshooting/troubleshoot-opentelemetry-exporter/",
      "published_at": "2021-06-15T12:05:18Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the OpenTelemetry SDK, APIs, and instrumentation are subject to change. If you're using New Relic's OpenTelemetry exporter, but you're not seeing the data you expect, this guide should help. OpenTelemetry currently supports two telemetry types: distributed traces and metrics. Through the New Relic UI, you can see your traces and metrics, as well as a view that focuses on errors. Learn more about how to find your data. Install To send your data through the OpenTelemetry collector, configure your OpenTelemetry SDK service.name as a resource and configure the SDK to send data to the collector. Then configure the collector with the New Relic exporter with your Insert API key. Consult the collector documentation if you're having trouble sending data through the collector. Once OpenTelemetry is configured with the API key and service name, you should be able to find your service in the explorer. Select your service to view its summary page. Traces When viewing your OpenTelemetry data, on the left side of the UI you can select Distributed tracing to see distributed traces. If you dont see traces: Ensure your service was reporting during the time window. Ensure you've added OpenTelemetry API calls to create trace spans. If you're using OpenTelemetry auto-instrumentation, ensure the instrumentation supports the libraries and frameworks you're using. Traces are the most mature telemetry type in OpenTelemetry, so you'll find the richest performance information from traces. Trace sampling Our trace UI will only reflect the data sent to us. This means that throughput and other counts may not reflect the unsampled data. You can configure sampling application-side using the OpenTelemetry SDKs. If you enable our Infinite Tracing feature, you have the option to send us all of your trace data and use New Relic sampling. Note that New Relic may rate-limit trace data. Metrics When viewing your OpenTelemetry data, on the left side of the UI you can select Metrics explorer to visualize metrics and create dashboards. If you dont see metrics, you may need to add OpenTelemetry API calls to add the metrics that you care about. Caution The OpenTelemetry standard for metric naming is still being defined and to date most instrumentation includes trace spans but not metrics. We expect that more instrumentation will include metrics in the coming months. Errors When viewing your OpenTelemetry data, on the left side of the UI you can select Errors to understand what errors your service is generating. The count of errors is based on how many traces have a span with the attribute error.stack. If you dont see the errors listed that you expect to see, check that your instrumentation sets the following three attributes: error.stack error.msg error.type In order for the error to be listed, a span must have an attribute that starts with error. Caution The OpenTelemetry standard for representing errors in traces and metrics is still being defined so these attribute names are subject to change. We expect the specification to be frozen very soon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.71103,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "sections": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the <em>OpenTelemetry</em> SDK, APIs, and instrumentation are subject to change. If you&#x27;re using New Relic&#x27;s <em>OpenTelemetry</em> exporter, but you&#x27;re not seeing the data you expect"
      },
      "id": "603e897de7b9d2ca9b2a07d6"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-advanced-configuration": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 389.87198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.9143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": ", and as more vendors move to support this <em>open</em> standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build <em>integrations</em> into <em>OpenTelemetry</em> or add instrumentation directly to <em>source</em> code, ensuring end"
      },
      "id": "603e81ba196a67304da83dab"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-architecture-recipes": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 389.87198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.9143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": ", and as more vendors move to support this <em>open</em> standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build <em>integrations</em> into <em>OpenTelemetry</em> or add instrumentation directly to <em>source</em> code, ensuring end"
      },
      "id": "603e81ba196a67304da83dab"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 389.87198,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.9143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": ", and as more vendors move to support this <em>open</em> standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build <em>integrations</em> into <em>OpenTelemetry</em> or add instrumentation directly to <em>source</em> code, ensuring end"
      },
      "id": "603e81ba196a67304da83dab"
    },
    {
      "sections": [
        "Troubleshoot the OpenTelemetry exporter",
        "Install",
        "Traces",
        "Trace sampling",
        "Metrics",
        "Caution",
        "Errors"
      ],
      "title": "Troubleshoot the OpenTelemetry exporter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "524e7f170806e42fddc8dee79c8da64b1640b8fb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/troubleshooting/troubleshoot-opentelemetry-exporter/",
      "published_at": "2021-06-15T12:05:18Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the OpenTelemetry SDK, APIs, and instrumentation are subject to change. If you're using New Relic's OpenTelemetry exporter, but you're not seeing the data you expect, this guide should help. OpenTelemetry currently supports two telemetry types: distributed traces and metrics. Through the New Relic UI, you can see your traces and metrics, as well as a view that focuses on errors. Learn more about how to find your data. Install To send your data through the OpenTelemetry collector, configure your OpenTelemetry SDK service.name as a resource and configure the SDK to send data to the collector. Then configure the collector with the New Relic exporter with your Insert API key. Consult the collector documentation if you're having trouble sending data through the collector. Once OpenTelemetry is configured with the API key and service name, you should be able to find your service in the explorer. Select your service to view its summary page. Traces When viewing your OpenTelemetry data, on the left side of the UI you can select Distributed tracing to see distributed traces. If you dont see traces: Ensure your service was reporting during the time window. Ensure you've added OpenTelemetry API calls to create trace spans. If you're using OpenTelemetry auto-instrumentation, ensure the instrumentation supports the libraries and frameworks you're using. Traces are the most mature telemetry type in OpenTelemetry, so you'll find the richest performance information from traces. Trace sampling Our trace UI will only reflect the data sent to us. This means that throughput and other counts may not reflect the unsampled data. You can configure sampling application-side using the OpenTelemetry SDKs. If you enable our Infinite Tracing feature, you have the option to send us all of your trace data and use New Relic sampling. Note that New Relic may rate-limit trace data. Metrics When viewing your OpenTelemetry data, on the left side of the UI you can select Metrics explorer to visualize metrics and create dashboards. If you dont see metrics, you may need to add OpenTelemetry API calls to add the metrics that you care about. Caution The OpenTelemetry standard for metric naming is still being defined and to date most instrumentation includes trace spans but not metrics. We expect that more instrumentation will include metrics in the coming months. Errors When viewing your OpenTelemetry data, on the left side of the UI you can select Errors to understand what errors your service is generating. The count of errors is based on how many traces have a span with the attribute error.stack. If you dont see the errors listed that you expect to see, check that your instrumentation sets the following three attributes: error.stack error.msg error.type In order for the error to be listed, a span must have an attribute that starts with error. Caution The OpenTelemetry standard for representing errors in traces and metrics is still being defined so these attribute names are subject to change. We expect the specification to be frozen very soon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.71101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "sections": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the <em>OpenTelemetry</em> SDK, APIs, and instrumentation are subject to change. If you&#x27;re using New Relic&#x27;s <em>OpenTelemetry</em> exporter, but you&#x27;re not seeing the data you expect"
      },
      "id": "603e897de7b9d2ca9b2a07d6"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic": [
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.9143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": ", and as more vendors move to support this <em>open</em> standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build <em>integrations</em> into <em>OpenTelemetry</em> or add instrumentation directly to <em>source</em> code, ensuring end"
      },
      "id": "603e81ba196a67304da83dab"
    },
    {
      "sections": [
        "Troubleshoot the OpenTelemetry exporter",
        "Install",
        "Traces",
        "Trace sampling",
        "Metrics",
        "Caution",
        "Errors"
      ],
      "title": "Troubleshoot the OpenTelemetry exporter",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "524e7f170806e42fddc8dee79c8da64b1640b8fb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/troubleshooting/troubleshoot-opentelemetry-exporter/",
      "published_at": "2021-06-15T12:05:18Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the OpenTelemetry SDK, APIs, and instrumentation are subject to change. If you're using New Relic's OpenTelemetry exporter, but you're not seeing the data you expect, this guide should help. OpenTelemetry currently supports two telemetry types: distributed traces and metrics. Through the New Relic UI, you can see your traces and metrics, as well as a view that focuses on errors. Learn more about how to find your data. Install To send your data through the OpenTelemetry collector, configure your OpenTelemetry SDK service.name as a resource and configure the SDK to send data to the collector. Then configure the collector with the New Relic exporter with your Insert API key. Consult the collector documentation if you're having trouble sending data through the collector. Once OpenTelemetry is configured with the API key and service name, you should be able to find your service in the explorer. Select your service to view its summary page. Traces When viewing your OpenTelemetry data, on the left side of the UI you can select Distributed tracing to see distributed traces. If you dont see traces: Ensure your service was reporting during the time window. Ensure you've added OpenTelemetry API calls to create trace spans. If you're using OpenTelemetry auto-instrumentation, ensure the instrumentation supports the libraries and frameworks you're using. Traces are the most mature telemetry type in OpenTelemetry, so you'll find the richest performance information from traces. Trace sampling Our trace UI will only reflect the data sent to us. This means that throughput and other counts may not reflect the unsampled data. You can configure sampling application-side using the OpenTelemetry SDKs. If you enable our Infinite Tracing feature, you have the option to send us all of your trace data and use New Relic sampling. Note that New Relic may rate-limit trace data. Metrics When viewing your OpenTelemetry data, on the left side of the UI you can select Metrics explorer to visualize metrics and create dashboards. If you dont see metrics, you may need to add OpenTelemetry API calls to add the metrics that you care about. Caution The OpenTelemetry standard for metric naming is still being defined and to date most instrumentation includes trace spans but not metrics. We expect that more instrumentation will include metrics in the coming months. Errors When viewing your OpenTelemetry data, on the left side of the UI you can select Errors to understand what errors your service is generating. The count of errors is based on how many traces have a span with the attribute error.stack. If you dont see the errors listed that you expect to see, check that your instrumentation sets the following three attributes: error.stack error.msg error.type In order for the error to be listed, a span must have an attribute that starts with error. Caution The OpenTelemetry standard for representing errors in traces and metrics is still being defined so these attribute names are subject to change. We expect the specification to be frozen very soon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.71101,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "sections": "Troubleshoot the <em>OpenTelemetry</em> exporter",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is an emerging standard for service-level instrumentation. Because it has not yet reached 1.0 for any language, the <em>OpenTelemetry</em> SDK, APIs, and instrumentation are subject to change. If you&#x27;re using New Relic&#x27;s <em>OpenTelemetry</em> exporter, but you&#x27;re not seeing the data you expect"
      },
      "id": "603e897de7b9d2ca9b2a07d6"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/roku/roku-open-source-video-agent": [
    {
      "sections": [
        "Elixir open-source agent",
        "Tip",
        "Get started",
        "For more help"
      ],
      "title": "Elixir open-source agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Open-source licensed agents",
        "Open-source licensed agents"
      ],
      "external_id": "aa03e1693b6ecdd06fa2940ddb99187247743772",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/elixir/elixir-open-source-agent/",
      "published_at": "2021-06-15T13:24:35Z",
      "updated_at": "2021-04-27T11:09:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Monitor Elixir behavior with New Relic using the Elixir open-source agent. The agent: Helps you track transactions, distributed traces, and other parts of your applications behavior Provides an overview of underlying BEAM activity Tip This agent is released as open source on GitHub. A change log is also available there for the latest updates. Get started For requirements, installation, and configuration information, see the Open Source Elixir Agent README on GitHub. Visit New Relics Elixir repository on GitHub for questions about installation, usage, or other topics. Report issues or bugs as an issue in the GitHub repository. For more help Recommendations for learning more: Browse New Relic's Explorers Hub for community discussions about the open-source Elixir agent. Review New Relic's licenses, attributions, data usage limits, and other notices.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 396.90393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Elixir <em>open</em>-<em>source</em> <em>agent</em>",
        "sections": "Elixir <em>open</em>-<em>source</em> <em>agent</em>",
        "tags": "<em>Open</em>-<em>source</em> <em>licensed</em> <em>agents</em>",
        "body": "Monitor Elixir behavior with New Relic using the Elixir <em>open</em>-<em>source</em> <em>agent</em>. The <em>agent</em>: Helps you track transactions, distributed traces, and other parts of your applications behavior Provides an overview of underlying BEAM activity Tip This <em>agent</em> is released as <em>open</em> <em>source</em> on GitHub. A change log"
      },
      "id": "6087f0ff28ccbceab351c13f"
    },
    {
      "sections": [
        "Java agent configuration: Config file",
        "Configuration file structure",
        "Tip",
        "Configuration settings precedence",
        "Configuring the Java extensions directory",
        "Create an extensions directory",
        "Specify an existing extensions directory",
        "General configuration settings",
        "license_key (REQUIRED)",
        "app_name (REQUIRED)",
        "agent_enabled",
        "apdex_t (DEPRECATED)",
        "appserver_port",
        "Important",
        "audit_mode",
        "ca_bundle_path",
        "use_private_ssl",
        "enable_auto_app_naming",
        "enable_auto_transaction_naming",
        "Caution",
        "enable_custom_tracing",
        "event_ingest_uri",
        "extensions.dir",
        "high_security",
        "insert_api_key",
        "labels",
        "max_stack_trace_lines",
        "metric_ingest_uri",
        "proxy_host",
        "proxy_password",
        "proxy_port",
        "proxy_user",
        "proxy_scheme",
        "reactor-netty.errors.enabled",
        "send_data_on_exit",
        "send_data_on_exit_threshold",
        "send_environment_info",
        "send_jvm_props",
        "ssl (DEPRECATED)",
        "sync_startup",
        "scala_futures_as_segments",
        "Logging configuration",
        "log_daily",
        "log_file_count",
        "log_file_name",
        "log_file_path",
        "log_level",
        "log_limit_in_kbytes",
        "JMX",
        "enabled",
        "linkingMetadataMBean",
        "JFR (Real-time profiling)",
        "audit_logging",
        "Attributes",
        "include",
        "exclude",
        "Transaction tracer",
        "explain_enabled",
        "explain_threshold",
        "insert_sql_max_length",
        "log_sql",
        "record_sql",
        "stack_based_naming (Play 2.x+ only)",
        "stack_trace_threshold",
        "top_n",
        "transaction_threshold",
        "slow_query_whitelist (DEPRECATED)",
        "collect_slow_queries_from",
        "attributes.enabled",
        "attributes.include",
        "attributes.exclude",
        "token_limit",
        "segment_limit",
        "Transaction segments",
        "Browser monitoring",
        "auto_instrument",
        "disabled_auto_pages",
        "External tracer",
        "exclude_request_uri",
        "Cross application tracer",
        "Error collector",
        "ignore_classes",
        "ignore_messages",
        "ignore_status_codes",
        "ignoreErrorPriority",
        "expected_classes",
        "expected_messages",
        "expected_status_codes",
        "ignore_errors (DEPRECATED)",
        "Strip exceptions",
        "whitelist (DEPRECATED)",
        "allowed_classes",
        "Thread profiler",
        "Transaction events",
        "max_samples_stored",
        "custom_request_headers",
        "Custom events",
        "Hostname configuration",
        "display_name",
        "ipv_preference",
        "Custom instrumentation",
        "trace_annotation_class_name",
        "com.newrelic.instrumentation.servlet-user",
        "System properties",
        "newrelic.config.process_host.display_name",
        "newrelic.config.file",
        "newrelic.debug",
        "newrelic.environment",
        "newrelic.home",
        "newrelic.logfile",
        "Environment variables",
        "NEW_RELIC_APP_NAME (REQUIRED)",
        "NEW_RELIC_DISTRIBUTED_TRACING_ENABLED",
        "NEW_RELIC_PROCESS_HOST_DISPLAY_NAME",
        "NEW_RELIC_LICENSE_KEY (REQUIRED)",
        "NEW_RELIC_LOG",
        "Cloud platform utilization",
        "detect_aws",
        "detect_docker",
        "Async instrumentation",
        "token_timeout",
        "segment_timeout",
        "Circuit breaker",
        "memory_threshold",
        "gc_cpu_threshold",
        "Message tracer",
        "segment_parameters.enabled",
        "Distributed tracing",
        "exclude_newrelic_header",
        "Infinite Tracing",
        "trace_observer.host",
        "Span events",
        "Jar collector",
        "skip_temp_jars",
        "jars_per_second"
      ],
      "title": "Java agent configuration: Config file",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Configuration"
      ],
      "external_id": "1d61f848fa192438225eae269421b8d384915c8b",
      "image": "https://docs.newrelic.com/static/60ca967eab99ca225186310913ae2de6/8c557/java-config-cascade.png",
      "url": "https://docs.newrelic.com/docs/agents/java-agent/configuration/java-agent-configuration-config-file/",
      "published_at": "2021-06-15T00:58:19Z",
      "updated_at": "2021-06-15T00:58:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Java agent reads its configuration from the newrelic.yml file. By default the agent looks for this file in the directory that contains newrelic.jar. You can override the config file's location by setting the newrelic.config.file system property to a fully qualified file name. Configuration file structure The newrelic.yml file is split into stanzas corresponding to different environments: Test Development Staging Production (default) New Relic applies settings in the common stanza to each of these environments. You can select other environments as the default by setting the newrelic.environment system property to the environment name. Tip A newrelic.yml template is available. If you edit newrelic.yml, be careful to conform to the YAML format. Use a YAML validator to ensure the syntax is accurate before using the file with New Relic's Java agent, and follow these rules: Java agent newrelic.yml Requirements Format YML files are case sensitive. Indentations All indentations must be in increments of two characters. Other indentations will result in an Unable to parse configuration file error upon agent startup. Use the same level of indentation for data in the same stanza of the file. Indent any sub-stanzas by an additional two spaces. Changes to file You must restart your JVM host process for changes to take effect. Exception: Property changes to log_level and audit_mode do not require a restart. Property changes under circuit breaker don't require a restart. Configuration settings precedence To override any setting in the config file, use a system property override. In certain environments, environment variables can also be used to override both the config file and the system properties. The environment variables primarily exist to support Heroku. When used, server-side configuration overrides all other configuration settings. With the Java agent, server-side configuration overrides all other settings. Environment variables override Java system properties. Java properties override user configuration settings in your newrelic.yml file. User settings override the newrelic.yml default settings. Configuring the Java extensions directory The Java agent reads the configuration files on process startup. To identify the directory where the files are located, either create a new or specify an existing extensions directory: Create an extensions directory To create the extensions directory: Navigate to the directory where newrelic.jar and newrelic.yml are located. Create a directory named extensions. In newrelic.yml, check that the property extensions.dir is not set. Specify an existing extensions directory To use an existing Java extensions directory: In your newrelic.yml file, locate the common section. Use the property extensions.dir to specify the location of the file. General configuration settings Set these options in the common stanza. To override any of these options, use a newrelic.config prefixed system property. license_key (REQUIRED) Type String Default (none) This setting is required. You must specify the license key associated with your New Relic account. This key binds your agent's data to your account in the New Relic service. app_name (REQUIRED) Type String Default (none) This setting is required. Defines the application name used to report data to New Relic. If enable_auto_app_naming is false, the agent reports all data to this application. Otherwise, the agent reports only background tasks (transactions for non-web applications) to this application. To report data to more than one application, separate the application names with a semicolon. For example, to report data to My Application and My Application 2 use this: app_name: My Application;My Application 2 Copy For more methods of naming your application, see Name your Java application. agent_enabled Type Boolean Default true Flag to enable the agent. Use this setting to force the agent to run or not run. apdex_t (DEPRECATED) Type Float Default 1.0 The apdex_t threshold in seconds for the application's Apdex score. For Java agent versions 1.2.008 or higher, the apdex_t value is set in the UI and the value in newrelic.yml is ignored. appserver_port Type Integer Default (none) Number to differentiate JVMs for the same app on the same machine. New Relic uses host/port for uniqueness, so you can distinguish the JVMs by putting a switch like this into the startup arguments for each JVM: -Dnewrelic.config.appserver_port=8081 Copy Once you have used appserver_port to name the JVMs and restart them, you should be able to see them individually in the dropdown and in the profiling interface. Important This is only a change for New Relic; it doesn't actually affect the port on which the host communicates in any way. audit_mode Type Boolean Default false Enables plain text logging of all data sent to New Relic to the agent logfile. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. ca_bundle_path Type String Value Format /path/to/ca/cert/bundle.pem Specifies a path to a custom SSL certificate bundle that will be used by the agent to establish a secure connection to New Relic. If your custom SSL certificate bundle doesn't include certificates that are sufficient to connect to New Relic then you'll need to merge the required certs into your custom certificate bundle. use_private_ssl Type Boolean Default false The following SSL certificates are bundled into the agent jar: META-INF/certs/eu-newrelic-com.pem META-INF/certs/eu01-nr-data-net.pem META-INF/certs/newrelic-com.pem Copy By default (use_private_ssl: false) the agent will use the SSL certificates bundled into the JDK to establish a secure connection to New Relic or the custom SSL certificates bundle specified by ca_bundle_path. If you want to use the SSL certificates bundled with the agent, set use_private_ssl: true. Note: use_private_ssl will be ignored if ca_bundle_path is set. enable_auto_app_naming Type Boolean Default false Enables the reporting of data separately for each web app. Set to true to enable support for auto app naming. The name of each web app is detected automatically and the agent reports data separately for each one. This provides a finer-grained performance breakdown for web apps in New Relic. For more information, see Automatic application naming. For more methods of naming your application, see Name your Java application. enable_auto_transaction_naming Type Boolean Default true Enables component-based transaction naming. Set to true to enable component-based transaction naming. Set to false to use the URI of a web request as the name of the transaction. For more information, see Naming web transactions. Caution Unless you implement API calls to name your transactions, disabling auto-transaction naming is very likely to cause Metric grouping issues. enable_custom_tracing Type Boolean Default true Enables all instrumentation using an @Trace annotation. Disabling this causes @Trace annotations to be ignored. event_ingest_uri Type String Default https://insights-collector.newrelic.com/v1/accounts/events Event ingest URI used by some agent features. Defaults to the US production ingest endpoint. Can be manually configured to send events to other ingest endpoints (for example, EU production: https://insights-collector.eu01.nr-data.net/v1/accounts/events). extensions.dir Type String Default (none) Defines the location of the optional extensions directory. If this property is not set, the agent will look for a subdirectory named extensions in the same directory as newrelic.jar and newrelic.yml. high_security Type Boolean Default false In order for high security to be enabled, this property must be set to true and the high security property in the New Relic user interface must be enabled. Enabling high security means SSL is turned on, request and message queue parameters are not collected, and queries cannot be sent to New Relic in their raw form. Important As of Java agent 3.48.0, SSL is enabled by default and the config option to disable it has been deprecated. As of Java agent 4.0.0, the ability to disable SSL has been removed. insert_api_key Type String Default (none) A valid Insert API Key for your account. This is not currently used by the agent. labels Type String Default \"\" Attach tags to this app. Note that this option now enables tags, which replaced the label feature. You can still query your historical labels. max_stack_trace_lines Type Integer Default 30 Limits the number of lines the agent collects from each stack trace. Increasing this value may impact performance, because it increases the amount of memory the agent uses and the amount of data sent to New Relic. metric_ingest_uri Type String Default https://metric-api.newrelic.com/metric/v1 Metric ingest URI used by some agent features. Defaults to the US production ingest endpoint. Can be manually configured to send metrics to other ingest endpoints (for example EU production: https://metric-api.eu.newrelic.com/metric/v1). proxy_host Type String Default (none) The proxy host through which to connect to the New Relic collector. If a proxy is used, the host setting is required. Other proxy settings are optional. proxy_password Type String Default (none) The password for proxy authentication. If a proxy is used, the host setting is required. Other proxy settings are optional. The username and password settings will be used to authenticate to Basic Auth challenges from a proxy server. Important The Java agent supports Basic (clear text) authentication. proxy_port Type String Default 8080 The proxy host port number. If a proxy is used, the host setting is required. Other proxy settings are optional. proxy_user Type String Default (none) The username for proxy authentication, such as Basic (clear text) authentication. If a proxy is used, the host setting is required. Other proxy settings are optional. The username and password settings will be used to authenticate to Basic Auth challenges from a proxy server. proxy_scheme Type String Default (none) The proxy scheme used. Setting proxy_scheme: \"https\" will allow the agent to connect through proxies using the HTTPS scheme. reactor-netty.errors.enabled Type Boolean Default false Whether errors are reported for Reactor Netty. Default is false. If set to true, Reactor Netty errors will be reported. Important Only available in Java agent 6.3.0 and above. Notice, default was changed to false as of Java agent 6.5.0. send_data_on_exit Type Boolean Default false Enable delayed JVM shutdown to give the agent a chance to send latest metric data to New Relic before JVM shutdown. send_data_on_exit_threshold Type Integer Default 60 The number of seconds after which the agent will use the send_data_on_exit setting. send_environment_info Type Boolean Default true Enable reporting of JVM settings to New Relic. send_jvm_props Type Boolean Default true When set to true, JVM properties will be sent to New Relic. ssl (DEPRECATED) Type Boolean Default true Requires connections to the New Relic collector to go over SSL. The agent communicates with New Relic via HTTPS by default, and New Relic requires HTTPS for all traffic to APM and the New Relic REST API. This work is done asynchronously to the threads that process your application code, so response times will not be directly affected by this change. Important As of Java agent 3.48.0, SSL is enabled by default and the config option to disable it has been deprecated. As of Java agent 4.0.0, the ability to disable SSL has been removed. sync_startup Type Boolean Default false Enable the agent to connect the New Relic collector immediately upon app startup. scala_futures_as_segments Important This applies to Java agent version 3.44.0 or higher. Type Boolean Default false For more concise transaction trace details, the agent does not report Scala Futures as transaction segments, and those Futures do not contribute to the transactions total time. Enabling scala_futures_as_segments increases your overhead. If you want Scala Futures to report as transaction segments so you can view them in a transaction trace, you can enable it: scala_futures_as_segments: enabled: true Copy Logging configuration These are part of the general configuration variables. They are broken out here because they are frequently tweaked for debugging. Some of the logging configuration variables are dynamic and do not need a host restart for them to take effect. For instance, if log files are growing too quickly, log_level can be set to a less verbose setting to reduce the reporting rate. Here is the order of precedence for configuration variables affecting log rotation. If log_daily is true, other log rotation settings are ignored. If log_file_count is 1 or 0, the size limit is ignored. Finally, the agent applies log_limit_in_kbytes. Depending on the growth rate, it is possible for the log file size to exceed the configured value by a small amount. log_daily Type Boolean Default false Set to true to roll the logs daily. Overrides the other configuration variables that affect log rotation. log_file_count Type Integer Default 1 The maximum number of log files to keep when using log rotation. log_file_name Type String Default newrelic_agent.log The unqualified log file name or the string STDOUT which will log to standard out. log_file_path Type String Default logs subdirectory where newrelic.jar is located The log file path. Tip If log_file_path is specified, the directory must already exist. If the default value is used, the agent will attempt to create the directory. log_level Type String Default info The log verbosity level. The agent uses its own log file to keep its logging separate from that of your application. Valid options, in order of verboseness, are: off severe warning info fine finer finest This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. log_limit_in_kbytes Type Integer Default 0 The log file size in kilobytes at which log files are rotated. Set to 0 for no limit. JMX To set these options, use the jmx stanza. To override them, use a newrelic.config.jmx prefixed system property. The Java agent uses JMX to collect JVM data. Additionally the agent can expose linking metadata over JMX that can be used by other tracing systems. enabled Type Boolean Default true This setting can be used to turn on or off all JMX functionality. linkingMetadataMBean Type Boolean Default false This setting can be enabled to allow the Java agent to expose linking metadata over remote JMX. Important This applies to Java agent version 6.1.0 or higher. JFR (Real-time profiling) The Java agent uses Java Flight Recorder (JFR) to collect high fidelity JVM data for Real-time profiling. Real-time profiling can be configured in the jfr stanza in the agent yaml, with system properties prefixed by newrelic.config.jfr., or with environment variables prefixed with NEW_RELIC_JFR_. enabled Type Boolean Default false Set to true to enable Real-time profiling with JFR. Important This applies to Java agent version 7.0.0 or higher. audit_logging Type Boolean Default false Set to true to enable audit logging which will display all JFR metrics and events in each harvest batch. Audit logging is extremely verbose and should only be used for troubleshooting purposes. Important This applies to Java agent version 7.0.0 or higher. Attributes To set these options, use the attributes stanza. To override them, use a newrelic.config.attributes prefixed system property. Attributes are key-value pairs that provide information for transaction traces, traced errors, browser monitoring, and transaction events. There is also an attribute stanza under each destination. For more information, see Java agent attributes, Enabling and disabling attributes and Attribute examples. enabled Type Boolean Default true This setting can be used to turn on or off all attributes. Important For security reasons, capturing custom attributes using the Custom Instrumentation Editor is set to false by default. include Type List of Strings Default (none) If attributes are enabled, attribute keys found in this list will be sent to New Relic. Separate the keys in the list with a comma; for example: key1, key2, key3 Copy Also refer to the agent attribute rules. exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic. Separate the keys in the list with a comma; for example: key1, key2, key3 Copy Also refer to the agent attribute rules. Transaction tracer These options are set in the transaction_tracer stanza and can be overridden by using a newrelic.config.transaction_tracer prefixed system property. Transaction tracing captures deep information about slow transactions and sends this to the New Relic service. The transaction includes the exact call sequence of the transactions, including any query statements issued. Important Do not use brackets [suffix] at the end of your transaction name. New Relic automatically strips brackets from the name. Instead, use parentheses (suffix) or other symbols if needed. enabled Type Boolean Default true The transaction tracer is enabled by default. Set this to false to turn it off. explain_enabled Type Boolean Default true Determines whether the agent will capture the EXPLAIN plan for slow queries. Only supported for MySQL and PostgreSQL. explain_threshold Type Float Default 0.5 Threshold in seconds for query execution time below which the slow query and the EXPLAIN plan (if supported) will not be captured. Relevant to slow queries only when record_sql is set to raw or obfuscated. Relevant to EXPLAIN plans only when explain_enabled is set to true. insert_sql_max_length Type Integer Default 2000 The character limit for the SQL query string. If you have many slow SQL queries with large chunks of information, this could negatively affect performance or how quickly you see your data in New Relic. Increase the value gradually until you find the right balance of information and performance. log_sql Type Boolean Default false Set to true to enable logging of queries to the agent log file instead of uploading to New Relic. Queries are logged using the record_sql mode. record_sql Type String Default obfuscated When the transaction tracer is on, query statements can optionally be recorded. The recorder has three modes: off: Send no queries. raw: Send the query statement in its original form. obfuscated: Strips out numeric and string literals. stack_based_naming (Play 2.x+ only) Type Boolean Default False Defaulted to true until Java agent version 3.12.1, when it was changed to false. This option is for Play 2.x+ only. Play/Scala instrumentation can use Thread.getStackTrace() to improve tracer naming, but at the cost of increased overhead. stack_trace_threshold Type Integer Default 0.5 Defines a threshold (in seconds) for collecting stack traces from an SQL call. When SQL statements exceed this threshold, the agent will capture the current stack trace. This is useful for pinpointing where long SQL calls originate from. top_n Type Integer Default 20 Use this setting to control the variety of your transaction traces. top_n is an integer that represents the number of unique, slow transactions that traces will be created for. If you want transaction traces to more accurately reflect the actual slowest transactions in your app, make this value lower. If you want to sample a more diverse array of transactions, make the value higher. A value of 0 would mean that only the slowest transaction is always traced. This is considered not to be optimal, though, because you may have one or two transactions that are always the slowest, and repeatedly seeing those same transaction traces will probably not give you much value. If the same transaction is often the slowest, the top_n setting allows the Java agent (over time) to sample the slowest n transactions. This gives you greater variety and more insight into your application. transaction_threshold Type String (float) Default apdex_f The time threshold used to determine when a transaction is eligible to be traced. When the transaction's response time exceeds this threshold, a transaction trace will be recorded and sent to New Relic. The default is apdex_f (default), which sets the threshold to be the \"Frustrated\" Apdex level (four times the apdex_t value). You can also set a specific time threshold by entering a float value that represents a number of seconds. slow_query_whitelist (DEPRECATED) Type String Default (none) Important This config has been deprecated as of agent version 5.10.0 and will be removed in a future agent version. Instead use collect_slow_queries_from. By default, high security mode does not allow the agent to collect slow queries. Enable this option to collect Cassandra queries from the DataStax driver, even with high security enabled. If you don't use high security, the agent collects slow queries automatically. For DataStax driver 2.1.2, add this rule to your allow list: transaction_tracer: slow_query_whitelist: 'com.newrelic.instrumentation.cassandra-datastax-2.1.2' Copy For DataStax driver 3.0.0, add this rule to your allow list: transaction_tracer: slow_query_whitelist: 'com.newrelic.instrumentation.cassandra-datastax-3.0.0' Copy collect_slow_queries_from Type String Default (none) By default, high security mode does not allow the agent to collect slow queries. Enable this option to collect Cassandra queries from the DataStax driver, even with high security enabled. If you don't use high security, the agent collects slow queries automatically. For DataStax driver 2.1.2, add this rule to your allow list: transaction_tracer: collect_slow_queries_from: 'com.newrelic.instrumentation.cassandra-datastax-2.1.2' Copy For DataStax driver 3.0.0, add this rule to your allow list: transaction_tracer: collect_slow_queries_from: 'com.newrelic.instrumentation.cassandra-datastax-3.0.0' Copy attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for transaction traces. If attributes.enabled at the root level is false, no attributes will be sent to transaction traces regardless on how this property (transaction_tracer.attributes.enabled) is set. attributes.include Type List of strings Default (none) If attributes are enabled for transaction traces, all attribute keys found in this list will be sent to New Relic in transaction traces. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in transaction traces. For more information, see the agent attribute rules. token_limit Type Integer Default 3000 Limits the number of Tokens that can be created per Transaction. Increasing this value may impact performance, because it increases the amount of memory the agent uses and the amount of data sent to New Relic. segment_limit Type Integer Default 3000 Limits the number of segments that can be created per transaction. Increasing this value may impact performance, because it increases the amount of memory the agent uses and the amount of data sent to New Relic. Transaction segments These options are set in the transaction_segments stanza and can be overridden by using a newrelic.config.transaction_segments prefixed system property. Transaction segments represent discrete pieces of work (generally method calls) and are displayed within transaction traces. Important Transaction segment attribute filtering requires Java agent version 4.10.0 or higher. attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for transaction segments. If attributes.enabled at the root level is false, no attributes will be sent to transaction segments regardless on how this property (transaction_segments.attributes.enabled) is set. attributes.include Type List of strings Default (none) If attributes are enabled for transaction segments, all attribute keys found in this list will be sent to New Relic in transaction segments. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in transaction segments. For more information, see the agent attribute rules. Browser monitoring These options are set in the browser_monitoring stanza and can be overridden by using a newrelic.config.browser_monitoring prefixed system property. Browser monitoring gives you insight into the performance real users are experiencing with your website. This is accomplished by measuring the time it takes for your users' browsers to download and render your web pages by injecting a small amount of JavaScript code into the header and footer of each page. auto_instrument Type Boolean Default true By default the agent automatically inserts API calls in compiled JSPs to inject the monitoring JavaScript into web pages. Set this attribute to false to turn off this behavior. disabled_auto_pages Type Comma-separated list of strings Default (none) When auto_instrument is true, by default all pages are instrumented. List all pages that you want the auto instrumentation to skip here. You can still use manual instrumentation on these pages. For example: browser_monitoring: disabled_auto_pages: /WEB-INF/jsp/testpage_1.jsp, /WEB-INF/jsp/testpage_2.jsp Copy attributes.enabled Type Boolean Default false This setting can be used to turn on or off all attributes for browser monitoring. This is the data you can query. If attributes.enabled is false at the root level, no attributes will be sent up in browser monitoring regardless on how this property under browser_monitoring is set. attributes.include Type List of Strings Default (none) If attributes are enabled for browser_monitoring, all attribute keys found in this list will be sent to New Relic in page views. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in page views. For more information, see the agent attribute rules. External tracer The external tracing options are set in the external_tracer stanza and can be overridden by using a newrelic.config.external_tracer prefixed system property. exclude_request_uri Type Boolean Default false This setting can be used to control the collection of outgoing request URIs for errors and transaction traces. Set this to true to disable collecting this information. Cross application tracer The cross application tracing options are set in the cross_application_tracer stanza and can be overridden by using a newrelic.config.cross_application_tracer prefixed system property. Cross application tracing adds request and response headers to external calls using the Apache HttpClient libraries. This provides better performance data when calling applications monitored by other New Relic Agents. enabled Type Boolean Default true Cross application tracing is enabled by default. Set this to false to turn it off. Error collector These options are set in the error_collector stanza and unless noted otherwise can be overridden by using a newrelic.config.error_collector prefixed system property. The error collector captures information about uncaught exceptions and sends them to New Relic for viewing. Tip For how to configure errors for the Java agent, including how to configure errors via the UI, see Java agent error configuration. enabled Type Boolean Default true Enable error collection. ignore_classes Type Stanza containing a list of fully qualified class_name strings Default (none) Specified exception class names will be ignored and will not affect error rate or Apdex score, or be reported to APM. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: ignore_classes: - \"com.example.MyException\" - \"com.example.DifferentException\" Copy ignore_messages Type Stanza containing a fully qualified class_name and a list of messages per error class Default (none) Specify exception class names the agent should ignore. Ignored messages will not affect error rate or Apdex score, or be reported to APM. Contains yaml pairs consisting of: A fully qualified exception class name that should not be reported to APM AND A list of exception messages to match against (at least one is required) If the exception class name matches an error but the message does not, then that error will not be ignored. Message strings use contains for matching. A message cannot be provided on its own and must always be paired with a fully qualified class name. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: ignore_messages: com.example.MyException: - \"Some error message to ignore\" - \"Some other error message to ignore\" com.example.DifferentException: - \"Some different error message to ignore\" Copy ignore_status_codes Type Comma-separated list of strings and ranges Default 404 A comma-separated list comprised of individual and dashed ranges of HTTP status codes that should not be treated as errors. If this property is commented out in the newrelic.yml configuration file, then the 404 status code will automatically be ignored. When using server-side configuration, the status code 404 must be specified in order for it to be ignored. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: ignore_status_codes: 404,507-511 Copy ignoreErrorPriority Type Boolean Default false With default ignoreErrorPriority as false, the agent reports the last error noticed if noticeError() is called multiple times in a transaction. If set to true, the agent reports the first error noticed if noticeError() is called multiple times in a transaction. For example: error_collector: ignoreErrorPriority: true Copy expected_classes Type Stanza containing a List of fully qualified class_name strings Default (none) Prevents specified exception classes from affecting error rate or Apdex score while still reporting the errors to APM. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: expected_classes: - \"com.example.MyException\" - \"com.example.DifferentException\" Copy expected_messages Type Stanza containing a fully qualified class_name and a List of messages per error class Default (none) Contains yaml pairs consisting of a fully qualified exception class name that should be marked as expected and thus prevented from affecting error rate or Apdex score and a List of exception messages to match against, the latter of which at least one is required. If the exception class name matches an error but the message does not, then that error will not be marked as expected and therefore will affect error rate and Apdex score. Message strings use contains for matching. A message cannot be provided on its own and must always be paired with a fully qualified class name. Cannot be specified by system property. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: expected_messages: com.example.MyException: - \"Some expected error message\" - \"Some other expected error message\" com.example.DifferentException: - \"Some different expected error message\" Copy expected_status_codes Type Comma-separated list of strings and ranges Default (none) A comma-separated list comprised of individual and dashed ranges of HTTP status codes to be marked as expected and thus prevented from affecting error rate or Apdex score. This setting is dynamic, so running agents will notice changes to newrelic.yml without a JVM restart. For example: error_collector: expected_status_codes: 415,500-506 Copy attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for traced errors. If attributes.enabled is false at the root level, then no attributes will be sent to traced errors regardless of how this property is set under error_collector. attributes.include Type List of strings Default (none) If attributes are enabled for traced errors, all attribute keys found in this list will be sent to New Relic in traced errors. For more information, see the agent attribute rules. attributes.exclude Type List of strings Default (none) Attribute keys found in this list will not be sent to New Relic in traced errors. For more information, see the agent attribute rules. ignoreErrorPriority Type Boolean Default true When multiple errors are noticed in a transaction, only the last error will be reported by default. Setting this property to false will instead report only the first error that is noticed. For more information, see the noticeError API. For example: error_collector: ignoreErrorPriority: false Copy ignore_errors (DEPRECATED) Type Comma-separated list of Strings Default (none) All specified exception class names specified will not be treated as errors. Deprecated as of Java agent 3.40.0 and replaced by ignore_classes. For example: error_collector: ignore_errors: some.other.MyException Copy Strip exceptions These options are set in the strip_exception_messages stanza and unless noted otherwise can be overridden by using a newrelic.config.strip_exception_messagesprefixed system property. This configuration can be enabled to control whether Java exception messages are reported to New Relic. enabled Type Boolean Default false By default, this is set to false, which means that the agent sends messages from all exceptions to the New Relic collector. If you set this to true, the agent strips the messages from exceptions in order to prevent it from inadvertently capturing sensitive information. If you enable high security mode, this is automatically set to true. If you set enabled to true but you want the agent to capture messages from specific exceptions, add the exceptions to your allow list. whitelist (DEPRECATED) Type String Default (none) Important This config has been deprecated as of agent version 5.10.0 and will be removed in a future agent version. Instead use allowed_classes. If you set enabled to true but you want the agent to capture messages for specific exceptions, add each exception to the whitelist, separated by a comma. allowed_classes Type String Default (none) If you set enabled to true but you want the agent to capture messages for specific exceptions, add each exception to allowed_classes, separated by a comma. Thread profiler These options are set in the thread_profiler stanza and can be overridden by using a newrelic.config.thread_profiler prefixed system property. Thread profiler measures wall clock time, CPU time, and method call counts in your application's threads as they run. enabled Type Boolean Default true Enable the thread profiler. Transaction events These options are set in the transaction_events stanza and can be overridden by using a newrelic.config.transaction_events prefixed system property. Transaction events provide the data for displaying histograms and percentiles in the UI. Important Previously this stanza was called analytics_events. If your configuration file still uses analytics_events, update your agent to use transaction_events. enabled Type Boolean Default true Enable the transaction events service. max_samples_stored Type Integer Default 2000 Max 10000 The maximum number of sampled transaction events reported every 60 seconds. custom_request_headers Type List of maps Default None Important Unlike other settings, custom_request_headers have to be paired together and must be set in the newrelic.yml file. They can't be overwritten by Java virtual machine arguments (system property) or environment variables. A list of maps with the paired keys header_name and the optional header_alias. Choose one or more custom HTTP request headers to add as transaction attributes. You can list multiple header configurations: transaction_events: custom_request_headers: - header_name: \"X-Custom-Header-1\" - header_name: \"X-Custom-Header-2\" header_alias: \"CustomHeader2alias\" Copy In the first map set, X-Custom-Header-1 is captured and reported by the agent as the header name for a corresponding value from the request object. The header_name will also be the name of the attribute sent to New Relic. In the second map set, the request header is X-Custom-Header-2, but the CustomHeader2alias is the name sent to New Relic. attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for transaction events. If attributes.enabled is false at the root level, then no attributes will be sent to transaction events regardless of how this property is set under transaction_events. attributes.include Type List of Strings Default (none) If attributes are enabled for transaction events, all attribute keys found in this list will be sent to New Relic in transaction events. For more information, see the agent attribute rules. attributes.exclude Type List of Strings Default (none) All attribute keys found in this list will not be sent to New Relic in transaction events. For more information, see the agent attribute rules. Custom events Custom events are set in the custom_insights_events stanza and can be overridden by using a newrelic.config.custom_insights_events prefixed system property. APM lets you record custom event data via the New Relic language agent APIs, which you can then query. Important For Java agent versions prior to 4.1.0, the following YAML configuration is recognized: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy For agent versions 4.1.0 and above, the YAML configuration uses the nested stanza formatting: custom_insights_events: enabled: false max_samples_stored: 5000 Copy enabled Type Boolean Default true This enables the custom event service. max_samples_stored Type Integer Default/Max 10000 The maximum number of sampled custom events reported every 60 seconds. Hostname configuration These options are set in the process_host stanza and can be overridden by using a newrelic.config.process_host prefixed system property. These properties are used for configuring the hostname displayed in the UI: display_name Type String Default (none) Set a display name to decorate the \"host:port\" label in the New Relic UI. ipv_preference Type String Default 4 If the hostname cannot be determined, then the IP address of the host will be used. This property determines whether the IPv4 or IPv6 address should be used. The default is IPv4. Custom instrumentation These options set in the class_transformer stanza and can be overridden by using a newrelic.config.class_transformer prefixed system property. trace_annotation_class_name Type String Default (none) String containing the full class name of the annotation class the agent uses to determine which user-specified methods to instrument. For more information about custom annotations, see Java custom metric collection. com.newrelic.instrumentation.servlet-user Type Boolean Default false Enable this option to capture the userPrincipal name. This name is included as a transaction trace attribute, and can be queried. System properties You can override any setting in the newrelic.yml file by setting a system property. The system property corresponding to a given setting in the config file is the setting name prefixed by newrelic.config. For example, the system property for the log_level setting is newrelic.config.log_level. For settings nested in stanzas, prepend the stanza name to the setting name. For example, the system property for the enabled setting in the transaction_tracer stanza is newrelic.config.transaction_tracer.enabled. In addition to overriding configuration settings, the following system properties are recognized by the agent: newrelic.config.process_host.display_name Type String Default (none) Set a display name to decorate the \"host:port\" label in the New Relic UI. Requires Java agent 3.17 or higher. newrelic.config.file Type String Default (none) String containing a fully qualified path to the newrelic configuration file. If empty, the agent assumes newrelic.yml is in the same directory as newrelic.jar. newrelic.debug Type Boolean Default (none) Enable debug logging. newrelic.environment Type String Default (none) String containing the environment configuration for the agent to use. newrelic.home Type String Default (none) String containing the home directory of agent. This defaults to the same directory as the agent jarfile. newrelic.logfile Type String Default newrelic_agent.log String containing the name of the agent log file. Environment variables Environment variables take the highest precedence and override the system properties and yml config settings. To set environment variables, use the export VARNAME=value command. To permanently set environment variables, add the export line to a file such as ~/.bashrc or ~/.bash_profile. You can override any setting from a system property or in the newrelic.yml by setting an environment variable. The environment variable corresponding to a given setting in the config file is the setting name prefixed by NEW_RELIC with all dots (.) and dashes (-) replaced by underscores (_). For example, the environment variable for the log_level setting is NEW_RELIC_LOG_LEVEL. For settings nested in stanzas, prepend the stanza name to the setting name. For example, the environment variable for the enabled setting in the transaction_tracer stanza is NEW_RELIC_TRANSACTION_TRACER_ENABLED. Important Agent configuration via environment variables requires Java agent version 4.10.0 or higher. For agent versions older than 4.10.0 the following environment variables are available: NEW_RELIC_APP_NAME (REQUIRED) Type String Default (none) This setting is required. Contains the application name under which to report data to New Relic. Set the name of your application as you want it to appear in New Relic. If enable_auto_app_naming is false, the agent reports all data to this application. Otherwise, the agent reports only background tasks (transactions for non-web applications) to this application. To report data to more than one application, separate the application names with a semicolon ;. For example, to report data to My Application and My Application 2: app_name: My Application;My Application 2 Copy For more methods of naming your application, see Name your Java application. NEW_RELIC_DISTRIBUTED_TRACING_ENABLED Type String Default false Enables distributed tracing. Case sensitive: use true or false. For more information, see the distributed tracing section. NEW_RELIC_PROCESS_HOST_DISPLAY_NAME Type String Default (none) Set a display name to decorate the \"host:port\" label in the New Relic UI. NEW_RELIC_LICENSE_KEY (REQUIRED) Type String Default (none) This setting is required. Contains your New Relic account license. You must specify the license key associated with your New Relic account. This key binds your agent's data to your account in the New Relic service. NEW_RELIC_LOG Type String Default newrelic_agent.log The unqualified log file name or the string STDOUT which will log to standard out. Cloud platform utilization These options are set in the utilization stanza and can be overridden by using a newrelic.config.utilization prefixed system property. The agent collects utilization information and sends it to the New Relic service. The agent can collect information from Amazon Web Services (AWS) EC2 instances and Docker containers. detect_aws Type Boolean Default true Determines whether the agent polls AWS metadata API. detect_docker Type Boolean Default true Determines whether the agent reads Docker information from the file system. Async instrumentation These options are set directly in the common stanza and can be overridden by using a prefixed system property. token_timeout Type Integer Default (seconds) 180 The number of seconds after which the agent will automatically expire an async token that has not been explicitly expired with token.expire(). For usage instructions, see Tokens: Connect async threads. Important Increasing this value may impact performance, because it increases the amount of memory the agent uses and prevents transactions from being reported due to unexpired tokens. segment_timeout Type Integer Default (seconds) 600 The number of seconds after which the agent will automatically end a segment that has not been explicitly ended with segment.end() or segment.ignore(). For usage instructions, see Segments: Time arbitrary async activity. Important Increasing this value may impact performance, because it increases the amount of memory the agent uses and prevents transactions from being reported due to un-ended segments. Circuit breaker These settings customize the behavior of the Java circuit breaker. These settings are not included in newrelic.yml by default. You do not need to restart your JVM after changing them. If you want to customize the circuit breaker, add the stanza under the common stanza: common: &default_settings  OTHER_CONFIG_SETTINGS circuitbreaker: enabled: true memory_threshold: 20 gc_cpu_threshold: 10 Copy enabled Type Boolean Default true If your application is behaving as expected, you may want to disable the circuit breaker. memory_threshold Type Integer (0 to 100) Default 20 Customize the precentage of free heap memory below which the circuit breaker should trip. When the percentage of free heap memory is less than memory_threshold, and the CPU time spent doing garbage collection is greater than gc_cpu_threshold, the circuit breaker trips. In order to make the circuit breaker less likely to trip, decrease memory_threshold and/or increase gc_cpu_threshold. Adjust these values as needed, based on your application's operating performance and behavior. gc_cpu_threshold Type Integer (0 to 100) Default 10 Customize the precentage of garbage collection CPU time above which the circuit breaker should trip. When the percentage of free heap memory is less than memory_threshold, and the CPU time spent doing garbage collection is greater than gc_cpu_threshold, the circuit breaker trips. In order to make the circuit breaker less likely to trip, decrease memory_threshold and/or increase gc_cpu_threshold. Adjust these values as needed, based on your application's operating performance and behavior. Message tracer These options are set in the message_tracer stanza and can be overridden by using a newrelic.config.message_tracer prefixed system property. segment_parameters.enabled Type Boolean Default true Adds message properties to tracer attributes. Set this to false to turn it off. Distributed tracing Important Enabling distributed tracing disables cross application tracing, and has other effects on APM features. Before enabling, read the transition guide. Requires Java agent version 4.3.0 or higher. Distributed tracing lets you see the path that a request takes as it travels through a distributed system. In the config file, it can be set in the distributed_tracing stanza. It can be overridden using a newrelic.config.distributed_tracing prefixed system property. enabled Type Boolean Default false Set this to true to enable distributed tracing. For example, to enable this in the config file, you would use: distributed_tracing: enabled: true Copy To enable this using a system property, you would use: -Dnewrelic.config.distributed_tracing.enabled=true Copy exclude_newrelic_header Type Boolean Default false By default, supported versions of the agent utilize both the newrelic header and W3C Trace Context headers for distributed tracing. The newrelic distributed tracing header allows interoperability with older agents that don't support W3C Trace Context headers. Agent versions that support W3C Trace Context headers will prioritize them over newrelic headers for distributed tracing. If you do not want to utilize the newrelic header, setting this to true will result in the agent excluding the newrelic header and only using W3C Trace Context headers for distributed tracing. For example, to exclude newrelic headers in the config file, you would use: distributed_tracing: exclude_newrelic_header: true Copy To exclude newrelic headers using a system property, you would use: -Dnewrelic.config.distributed_tracing.exclude_newrelic_header=true Copy Infinite Tracing Important Requirements: Java Agent 5.12.1 or higher. Infinite Tracing does not work if enable_auto_app_naming is enabled. To turn on Infinite Tracing, enable distributed tracing and add the additional setting below. For an example, see Language Agents: Configure Distributed Tracing. trace_observer.host Type String Default None For help getting a valid Infinite Tracing trace observer host entry, see find or create a Trace Observer. You can configure this via YAML: infinite_tracing: trace_observer: host: YOUR_TRACE_OBSERVER_HOST Copy You can also use the system property newrelic.config.infinite_tracing.trace_observer.host or the environment variable NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST. Span events Span events are reported for distributed tracing. Distributed tracing must be enabled to report span events. Span configuration is set in the span_events stanza and can be overridden by using a newrelic.config.span_events prefixed system property. Options include: enabled Type Boolean Default true Used to enable/disable span event reporting. attributes.enabled Type Boolean Default true This setting can be used to turn on or off all attributes for span events. If attributes.enabled at the root level is false, no attributes will be sent to span events regardless on how this property (span_events.attributes.enabled) is set. attributes.include Type List of strings Default (none) If attributes are enabled for span events, all attribute keys found in this list will be sent to New Relic in span_events. For more information, see the agent attribute rules. attributes.exclude Type List of strings Default (none) All attribute keys found in this list will not be sent to New Relic in span events. For more information, see the agent attribute rules. Important Span event attribute filtering requires Java agent version 4.10.0 or higher. Jar collector The Java agent collects and information about jars and their versions on the application classpath. Jar collection configuration is set in the jar_collector stanza and can be overridden by using a newrelic.config.jar_collector prefixed system property. Options include: enabled Type Boolean Default true Used to enable/disable jar collection and reporting. skip_temp_jars Type Boolean Default true Used to enable/disable collection of temporary jars. Temporary jars are those residing in the directory specified by the system property java.io.tmpdir. jars_per_second Type Integer Default 10 The maximum number of jars to process per second. Must be positive.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 34.348297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java <em>agent</em> configuration: Config file",
        "sections": "Java <em>agent</em> configuration: Config file",
        "tags": "<em>Agents</em>",
        "body": " false Enables plain text logging of all data sent to New Relic to the <em>agent</em> logfile. This setting is dynamic, so running <em>agents</em> will notice changes to newrelic.yml without a JVM restart. ca_bundle_path Type String Value Format &#x2F;path&#x2F;to&#x2F;ca&#x2F;cert&#x2F;bundle.pem Specifies a path to a custom SSL certificate"
      },
      "id": "603eb739e7b9d2a2432a07e0"
    },
    {
      "sections": [
        ".NET agent configuration",
        "Configuration overview",
        "Important",
        "Configuration methods and precedence levels",
        "Required environment variables",
        "Caution",
        ".NET Framework environment variables",
        ".NET Core environment variables",
        "Profiler conflict explanation",
        "Optional environment variables",
        "Setup options, newrelic.config",
        "Configuration element",
        "agentEnabled",
        "maxStackTraceLines",
        "timingPrecision",
        "Service element",
        "licenseKey (required)",
        "sendEnvironmentInfo",
        "syncStartup",
        "sendDataOnExit",
        "sendDataOnExitThreshold",
        "completeTransactionsOnThread",
        "requestTimeout",
        "autoStart",
        "ssl (DEPRECATED)",
        "Obscuring key element",
        "Proxy element",
        "host",
        "port",
        "uriPath",
        "domain",
        "user",
        "password",
        "passwordObfuscated",
        "Log element",
        "level",
        "auditLog",
        "console",
        "directory",
        "fileName",
        "Application element (required)",
        "name",
        "disableSamplers",
        "Data transmission element",
        "putForDataSend",
        "Host name",
        "Set using config file",
        "Set using environment variable",
        "Cloud platform utilization",
        "detectAws",
        "detectAzure",
        "detectGcp",
        "detectPcf",
        "detectDocker",
        "detectKubernetes",
        "Instrumentation options",
        "Instrumentation element",
        "Applications element (instrumentation)",
        "Attributes element",
        "enabled",
        "include",
        "exclude",
        "Feature options",
        "App pools",
        "defaultBehavior",
        "applicationPool",
        "Cross application traces",
        "Error collection",
        "Tip",
        "captureEvents",
        "maxEventSamplesStored",
        "ignoreClasses",
        "ignoreMessages",
        "ignoreErrors (DEPRECATED)",
        "ignoreStatusCodes",
        "expectedClasses",
        "expectedMessages",
        "expectedStatusCodes",
        "attributes",
        "High security mode",
        "Strip exception messages",
        "Transaction events",
        "maximumSamplesStored",
        "Custom events",
        "Custom parameters",
        "Labels (tags)",
        "Browser instrumentation",
        "autoInstrument",
        "requestPathsExcluded",
        "Slow queries",
        "Transaction traces",
        "transactionThreshold",
        "recordSql",
        "explainEnabled",
        "explainThreshold",
        "maxSegments",
        "maxExplainPlans",
        "Datastore tracer",
        "instanceReporting",
        "databaseNameReporting",
        "queryParameters",
        "Distributed tracing",
        "excludeNewrelicHeader",
        "Disable span events via config file",
        "Disable span events via environment variable",
        "Infinite Tracing",
        "trace_observer",
        "Span events",
        "Capture HTTP Request Headers",
        "Settings in app.config or web.config",
        "Enable and disable the agent",
        "Application name",
        "License key",
        "Change newrelic.config location",
        "Settings in appsettings.json"
      ],
      "title": ".NET agent configuration",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Configuration"
      ],
      "external_id": "b89fa7fc399f2729bfee8f5106e777798a73177a",
      "image": "https://docs.newrelic.com/static/cffd7eb2d22c8e338531c38f35208c7c/c1b63/net-agent-config-settings-precedence_0.png",
      "url": "https://docs.newrelic.com/docs/agents/net-agent/configuration/net-agent-configuration/",
      "published_at": "2021-06-15T00:58:19Z",
      "updated_at": "2021-06-15T00:58:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains the configuration options for the APM .NET agent. Configuration overview APM agent configuration options allow you to control some aspects of how the agent behaves. Some of these config options are part of the basic install process (like setting your license key and app name), but most are more advanced settings, such as: setting a log level, setting up proxy host access, excluding certain attributes, and enabling distributed tracing. The .NET agent gets its configuration from the newrelic.config file, which is generated as part of the install process. By default, only a global newrelic.config file is created, but you can also create app-local newrelic.config files for finer control over a multi-app system. Other ways to set config options include: using environment variables, or setting server-side configuration from the UI. For more on the various config options and what overrides what, see Config settings precedence. Support for both .NET Framework and .NET Core use the same configuration options and have the same APM features, unless otherwise stated. If you make changes to the config file and want to validate that it's in the right format, you can check it against the XSD file (for example, at C:\\ProgramData\\New Relic\\.NET Agent\\newrelic.xsd for Windows) with any XSD validator. Important For IIS: after you change your newrelic.config or app.config file, perform an IISRESET from an administrative command prompt. Log level adjustments do not require a reset. Configuration methods and precedence levels Upon installation, the .NET agent's configuration file (newrelic.config) applies to all monitored applications, but you can configure the agent in other ways. Here's a diagram showing how different configuration options take precedence over one another: This diagram explains the order of precedence for different ways you might configure the .NET agent. Here are details about the configuration methods shown in the diagram, and their precedence levels: .NET configuration Details and precedence web.config or app.config or appsettings.json Configuration settings set in these files take highest precedence. However, if the agent is disabled in the local or global newrelic.config, the NewRelic.AgentEnabled settings in these files will be ignored. Environment variables Second-highest precedence. For more about these, see .NET environment variables. Server-side configuration Third-highest precedence. A limited number of server-side configuration settings are available; the other settings will come from other configuration sources. App-local newrelic.config Fourth-highest precedence. You can create app-local newrelic.config files to configure individual apps on a multi-app system. These local configuration files override settings in the global newrelic.config file. The agent looks for app-local config files in the following directories, in this order: A directory specified in your web.config or app.config file with the NewRelic.ConfigFile property The web app's root directory (with the app.config or web.config) The directory containing your app's executable file Note that the app-local config file must be complete and validate against the XSD file (for example, at C:\\ProgramData\\New Relic\\.NET Agent\\newrelic.xsd for Windows). Default (global) newrelic.config Default source and the lowest precedence. Will configure all applications on a host in the absence of other config files. The global config file is located in the New Relic agent home directory: %PROGRAMDATA%\\New Relic\\.NET Agent Required environment variables New Relic's .NET agent relies on environment variables to tell the .NET Common Language Runtime (CLR) to attach New Relic to your processes. Some .NET agent install procedures (like the MSI installer) will automatically set these variables for you; some procedures will require you to manually set them. Caution Security recommendation: You should consider what users can set system environment variables. You should also secure the accounts under which your applications execute to prevent user environment variables overriding system environment variables .NET Framework environment variables For .NET Framework, the following variables are required: COR_ENABLE_PROFILING=1 COR_PROFILER={71DA0A04-7777-4EC6-9643-7D28B46A8A41} NEWRELIC_INSTALL_PATH=path\\to\\agent\\directory Copy The .NET agent installer will add these to IIS or as system-wide environment variables. .NET Core environment variables For .NET Core, the following variables are required: Linux: CORECLR_ENABLE_PROFILING=1 CORECLR_PROFILER={36032161-FFC0-4B61-B559-F6C5D41BAE5A} CORECLR_NEWRELIC_HOME=path/to/agent/directory CORECLR_PROFILER_PATH=\"${CORECLR_NEWRELIC_HOME}/libNewRelicProfiler.so\" Copy Windows: CORECLR_ENABLE_PROFILING=1 CORECLR_PROFILER={36032161-FFC0-4B61-B559-F6C5D41BAE5A} NEWRELIC_INSTALL_PATH=path\\to\\agent\\directory CORECLR_NEWRELIC_HOME=path\\to\\agent\\directory Copy The .NET agent installer will add these to IIS or as system-wide environment variables. If your system has previously used monitoring services (non-New Relic), you may have a \"profiler conflict\" when trying to install and use the New Relic agent. More details: Profiler conflict explanation New Relics .NET agents rely on environment variables to tell the .NET Common Language Runtime (CLR) to load New Relic into your processes. The install-related environment variables are Microsoft variables, not New Relic variables. They can be used by other .NET profilers, and only one profiler can be attached to a process at a time. For this reason, if you have used previous application monitoring products, you may have profiler conflicts. For specific install instructions, see the .NET agent install documentation. Optional environment variables Some configuration options in New Relic's .NET agent can be set via environment variables as an alternative to setting them in a config file. Below is a list of environment variables recognized by the .NET agent with example values. NEW_RELIC_LICENSE_KEY=XXXXXXXX NEW_RELIC_LOG=MyApp.log NEW_RELIC_APP_NAME=Descriptive Name MAX_TRANSACTION_SAMPLES_STORED=500 MAX_EVENT_SAMPLES_STORED=500 NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true NEW_RELIC_SPAN_EVENTS_ENABLED=false NEW_RELIC_LABELS=foo:bar;zip:zap NEW_RELIC_CONFIG_OBSCURING_KEY=XXXXXXXX NEW_RELIC_DISABLE_SAMPLERS=true NEWRELIC_PROFILER_LOG_DIRECTORY=path\\to\\agent\\directory (not configurable via config file) Copy Setup options, newrelic.config Use these options to setup and configure your agent via the newrelic.config file. The New Relic .NET agent supports the following categories of setup options: Configuration element Service element Obscuring key element Proxy element Log element Application element (configuration) Data transmission element Host name Configuration element The root element of the configuration document is a configuration element. <configuration xmlns=\"urn:newrelic-config\" agentEnabled=\"true\" maxStackTraceLines=\"50\" timingPrecision=\"low\"> Copy The configuration element supports the following attributes: agentEnabled Type Boolean Default true Enable or disable the New Relic agent. maxStackTraceLines Type Integer Default 80 The maximum number of stack frames to trace in any stack dump. timingPrecision Type String Default low Controls the precision of the timers. High precision will provide better data, but at a lower execution speed. Possible values are high and low. Service element The first child of the configuration element is a service element. The service element configures the agent's connection to the New Relic service. <service licenseKey=\"YOUR_LICENSE_KEY\" sendEnvironmentInfo=\"true\" syncStartup=\"false\" sendDataOnExit=\"false\" sendDataOnExitThreshold=\"60000\" autoStart=\"true\"/> Copy The service element supports the following attributes: licenseKey (required) Type String Default (none) Your New Relic license key. New Relic uses the license key to match your app's data to the correct account in the UI. Set the license key via environment variable. Alternatively, set the NEW_RELIC_LICENSE_KEY environment variable in the application's environment. NEW_RELIC_LICENSE_KEY=XXXXXXXX Copy sendEnvironmentInfo Type Boolean Default true Instructs the agent to record execution environment information. Environment information includes operating system, agent version, and which assemblies are available. syncStartup Type Boolean Default false Block application startup until the agent connects to New Relic. If set to true, the first transaction may take substantially longer to complete, because it is blocked until the connection to New Relic is finished. sendDataOnExit Type Boolean Default false Block application shutdown until the agent sends all data from the latest harvest cycle. sendDataOnExitThreshold Type Integer Default 60000 Unit Milliseconds The minimum amount of time the process must run before the agent blocks it from shutting down. This setting only applies when sendDataOnExit is true. completeTransactionsOnThread Type Boolean Default false If false, the agent uses a pool thread to complete the transaction processing. If true, the agent will complete transaction processing on the request thread. requestTimeout Type Integer Default 2000 (sendDataOnExit enabled) 120000 (sendDataOnExit disabled) Unit Milliseconds The agent's request timeout when communicating with New Relic. autoStart Type Boolean Default True Automatically start the .NET agent when the first instrumented method is hit. ssl (DEPRECATED) Type Boolean Default true The option to disable SSL is valid only for .NET agent versions 7.x and earlier. .NET agent version 8.x and higher communicate only via SSL. The agent communicates with New Relic via HTTPS by default, and New Relic requires HTTPS for all traffic to APM and the New Relic REST API. Obscuring key element The obscuringKey element is an optional child of the service element. The .NET Agent uses this value to deobfuscate supported configuration values. For example, when an obfuscated proxy password is supplied, it will be deobfuscated using this key. <service licenseKey=\"YOUR_LICENSE_KEY\"> <obscuringKey>OBSCURING_KEY</obscuringKey> </service> Copy The obscuring key may also be configured by setting the NEW_RELIC_CONFIG_OBSCURING_KEY environment variable. Caution Security recommendation: The placement of the obscuring Key in the same configuration file as an obfuscated value may pose a security risk. Consider placing the obscuring key in an environment variable and limiting access to environment variables within your environment. Proxy element The proxy element is an optional child of the service element. The proxy element is used when the agent communicates to the New Relic back-end service via a proxy. <service licenseKey=\"YOUR_LICENSE_KEY\"> <proxy host=\"hostname\" port=\"PROXY_PORT\" uriPath=\"path/to/something.aspx\" domain=\"mydomain.com\" user=\"PROXY_USERNAME\" password=\"PROXY_PASSWORD\" passwordObfuscated=\"OBFUSCATED_PROXY_PASSWORD\"/> </service> Copy The proxy element supports the following attributes: host Type String Default (none) Defines the proxy host. port Type Integer Default 8080 Defines the proxy port. uriPath Type String Default (none) Optionally define a proxy URI path. domain Type String Default (none) Optionally define a domain to use when authenticating with the proxy server. user Type String Default (none) Optionally define a user name for authentication. password Type String Default (none) Optionally define a password for authentication. passwordObfuscated Type String Default (none) For additional security, the .NET Agent supports the use of an obfuscated proxy password with the passwordObfuscated attribute. The obfuscated proxy password is generated using the following New Relic CLI command: newrelic agent config obfuscate --key OBSCURING_KEY --value \"CLEAR_TEXT_PROXY_PASSWORD\" Copy Important When using an obfuscated proxy password, the obscuring key must also be configured. Log element The log element is a child of the configuration element. The log element configures New Relic's logging . The agent generates its own log file to keep its logging information separate from your application's logs. <log level=\"info\" auditLog=\"false\" console=\"false\" directory=\"PATH\\TO\\LOG\\DIRECTORY\" fileName=\"FILENAME.log\" /> Copy The log element supports the following attributes: level Type String Default info Defines the level of detail recorded in the log file. Possible values, in increasing order of detail, are: off error warn info debug finest all Important Increasing the log level will increase New Relic's performance impact. auditLog Type Boolean Default false Records all data sent to and received from New Relic in both an auditlog log file and the standard log file. console Type Boolean Default false Send log messages to the console, in addition to the log file. directory Type String Default C:\\ProgramData\\New Relic\\.NET Agent\\Logs The directory to hold log files generated by the agent. If this is omitted, then a directory named logs in the New Relic agent install area will be used by default. fileName Type String Default (none) Defines a name for the log file. If you do not define a fileName, the name is derived from the name of the monitored process. Alternatively, set the NEW_RELIC_LOG environment variable in the application's environment. NEW_RELIC_LOG=MyApp.log Copy Application element (required) The application element is a child of the configuration element. This required element defines your application name, and disables or enables sampling. name Type String Default My Application The name of your .NET application is a child of the application element. New Relic will aggregate your data according to this name. For example, if you have two running applications named AppA and AppB, you will see two applications in the New Relic interface: AppA and AppB. You can also assign up to three names to your app. The first name is the primary name. For example: <application> <name>MY APPLICATION PRIMARY</name> <name>SECOND APP NAME</name> <name>THIRD APP NAME</name> </application> Copy Alternatively, set the NEW_RELIC_APP_NAME environment variable in the application's environment. NEW_RELIC_APP_NAME=Descriptive Name Copy disableSamplers Type Boolean Default false Samplers collect information about memory and CPU consumption. Set this to true to disable sampling. Alternatively, set the NEW_RELIC_DISABLE_SAMPLERS environment variable in the application's environment. NEW_RELIC_DISABLE_SAMPLERS=true Copy Data transmission element The dataTransmission element is a child of the configuration element. This element affects how data is sent to New Relic and can be used if you have specific data transmission requirements. <dataTransmission putForDataSend=\"false\" compressedContentEncoding=\"deflate\"/> Copy The dataTransmission element supports the following attributes: putForDataSend Type Boolean Default false Defines the HTTP method used when sending data to New Relic. Set this to true to enable using the PUT method when sending data. The POST method is used by default. Host name If the default host name label in the APM UI is not useful, you can decorate that name in the New Relic UI with a display name. After the application process is restarted and the .NET agent is reporting again, the display name will appear in the Servers drop-down list. This host name setting does not affect the list of hosts on your application's Summary page. To set a display name, choose one of the following options. The environment variable takes precedence over the config file value. Then restart your application to see your changes in the New Relic UI. Set using config file Set the displayName attribute in the processHost element in newrelic.config. The processHost element is a child of the configuration element. <configuration . . . > <processHost displayName=\"CUSTOM_NAME\" /> </configuration> Copy Set using environment variable Set the NEW_RELIC_PROCESS_HOST_DISPLAY_NAME environment variable: NEW_RELIC_PROCESS_HOST_DISPLAY_NAME = \"CUSTOM_NAME\" Copy Cloud platform utilization Configures the utilization configuration element to control how the agent collects utilization information and sends it to the New Relic service to determine pricing. The agent can collect information from Amazon Web Services (AWS) EC2 instances, Docker containers, Azure, Google Cloud Platform, Pivotal Cloud Foundry, and Kubernetes. detectAws Type Boolean Default true Determines whether the agent polls AWS metadata API. detectAzure Type Boolean Default true Determines whether the agent polls Azure metadata API. detectGcp Type Boolean Default true Determines whether the agent polls GCP metadata API. detectPcf Type Boolean Default true Determines whether the agent polls PCF information from environment variables. detectDocker Type Boolean Default true Determines whether the agent reads Docker information from the file system. detectKubernetes Type Boolean Default true Determines whether the agent polls Kubernetes information from environment variables. Instrumentation options Use these options to configure which elements of your application and environment to instrument. New Relic for .NET supports the following categories of instrumentation options: Instrumentation element Applications element (instrumentation) Attributes element Instrumentation element The instrumentation element is a child of the configuration element. By default, the .NET agent instruments IIS asp worker processes and Azure web and worker roles. To instrument other processes, see Instrumenting custom applications. Applications element (instrumentation) The applications element is a child of the instrumentation element. The applications element specifies which non-web apps to instrument. It contains a name attribute. Important This is not the same as the application (configuration) element, which is a child of the configuration element. <instrumentation> <applications> <application name=\"MyService1.exe\" /> <application name=\"MyService2.exe\" /> <application name=\"MyService3.exe\" /> </applications> </instrumentation> Copy Attributes element An attribute is a key/value pair that determines the properties of an event or transaction. Each attribute is sent to APM transaction traces, APM error traces, Transaction events, TransactionError events, or PageView events. The primary attributes element enables or disables attribute collection for the .NET agent, and defines specific attributes to collect or exclude. You can also configure attribute settings based on their destination: Error collection, transaction traces, Browser instrumentation, and transaction events. In this example, the agent excludes all attributes whose key begins with myApiKey (myApiKey.bar, myApiKey.value), but collects the custom attribute myApiKey.foo. <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> Copy You can view the .NET APM attributes on the .NET agent attributes page. You can also define custom attributes with the agent API call AddCustomParameter. enabled Type Boolean Default true Enable or disable attribute collection. When set to false in the primary attribute element, this setting overrides all attribute settings for individual destinations. include Type String Default (none) If attributes are enabled, the agent will collect all attribute keys specified in this list. To specify multiple attribute keys, specify each individually. You can also use a * wildcard character at the end of a key to match multiple attributes (for example, myApiKey.*). For more information, see Attribute rules. exclude Type String Default (none) If attributes are enabled, the agent will not collect attribute keys specified in this list. To specify multiple attribute keys, specify each individually. You can also use a * wildcard character at the end of a key to match multiple attributes (for example, myApiKey.*). For more information, see Attribute rules. Feature options Use these options to enable, disable, and configure New Relic features. New Relic for .NET allows you to configure the following features: App pools Cross application traces Error collection High security mode Strip exception messages Transaction events Custom events Custom parameters Tags/labels Browser instrumentation Slow Queries Transaction traces Datastore tracer Distributed tracing Span events Capture HTTP Request Headers App pools Important This is only applicable to a system's global config file. The applicationPools element is a child of the configuration element. The applicationPools element specifies for the profiler exactly which application pools to instrument and uses the same name as the IIS application pool name. This configuration element is useful when you may need to instrument only a small subset of your app pools. For example, a given server might have several hundred application pools, but only a few of those pools need to be instrumented by the .NET agent. Here is an example of disabling instrumentation for specific application pools: <applicationPools> <applicationPool name=\"Foo\" instrument=\"false\"/> <applicationPool name=\"Bar\" instrument=\"false\"/> </applicationPools> Copy Here is an example of disabling instrumentation for all application pools currently executing on the server and enabling instrumentation for specific application pools: <applicationPools> <defaultBehavior instrument=\"false\"/> <applicationPool name=\"Foo\" instrument=\"true\"/> <applicationPool name=\"Bar\" instrument=\"true\"/> </applicationPools> Copy The applicationPools element supports the following elements: defaultBehavior Type Boolean Default false Defines how the .NET agent will behave on a \"global\" level for application pools served via IIS. The .NET agent instruments all application pools by default. When true, application pools listed under applicationPool with an instrument attribute set to false will not be instrumented. Essentially, when set to false, the application pool list acts as an allow list. When set to true, the application pool list acts as a deny list. applicationPool Defines instrumentation behavior for a specific application pool. The name attribute is the name of an application pool. Enable or disable profiling in the instrument attribute. Define this application in the name attribute. Cross application traces The crossApplicationTracer element is a child of the configuration element. crossApplicationTracer links transaction traces across applications. When linked in a service-oriented architecture, all instrumented applications that communicate with each other via HTTP will now \"link\" transaction traces with the applications that they call and the applications they are called by. Cross application tracing makes it easier to understand the performance relationship between services and applications. <crossApplicationTracer enabled=\"true\"/> Copy The crossApplicationTracer element supports the following attribute: enabled Type Boolean Default true Enable or disable cross application tracing Error collection The errorCollector element is a child of the configuration element. errorCollector configures error collection, which captures information about uncaught exceptions and sends them to New Relic. <errorCollector enabled=\"true\" captureEvents=\"true\" maxEventSamplesStored=\"100\"> <ignoreClasses> <errorClass>System.IO.FileNotFoundException</errorClass> <errorClass>System.Threading.ThreadAbortException</errorClass> </ignoreClasses> <ignoreMessages> <errorClass name=\"System.Exception\"> <message>Ignore message</message> <message>Ignore too</message> </errorClass> </ignoreMessages> <ignoreStatusCodes> <code>401</code> <code>404</code> </ignoreStatusCodes> <expectedClasses> <errorClass>System.ArgumentNullException</errorClass> <errorClass>System.ArgumentOutOfRangeException</errorClass> </expectedClasses> <expectedMessages> <errorClass name=\"System.Exception\"> <message>Expected message</message> <message>Expected too</message> </errorClass> </expectedMessages> <expectedStatusCodes>403,500-505</expectedStatusCodes> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </errorCollector> Copy Tip For an overview of error configuration in APM, see Manage errors in APM. The errorCollector element supports the following elements and attributes: enabled Type Boolean Default true Enable or disable the error collector. captureEvents Type Boolean Default true Enable or disable the capturing of error events. maxEventSamplesStored Type Integer Default 100 Reservoir limit for error events. ignoreClasses A list of fully qualified class names to be ignored. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used ignoreMessages An optional map of fully qualified class names to list of strings matching a substring of the message of an error. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used ignoreErrors (DEPRECATED) Type String Default (none) Lists specific exceptions to not report to New Relic. The full name of the exception should be used, such as System.IO.FileNotFoundException. ignoreStatusCodes Type String Default (none) Lists specific HTTP error codes to not report to New Relic. You can use standard integral HTTP error codes, such as just 401, or you may use Microsoft full status codes with decimal points, such as 401.4 or 403.18. The status codes should be equal to or greater than 400. expectedClasses A list of fully qualified class names to be marked as expected. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used expectedMessages An optional map of fully qualified class names to list of strings matching a substring of the message of an error. The maximum number of error class and message combinations that SHOULD be reported is 50. If more than 50 are listed, then only the first 50 SHOULD be used expectedStatusCodes A comma separated list of status codes. The list may include integer ranges, using a single dash (-) and will be inclusive of both the starting and ending integer in the range. attributes Use this sub-element to customize your agent attribute settings for error traces. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. High security mode The highSecurity element is a child of the configuration element. To enable high security mode, set this property to true and enable the high security property in the New Relic user interface. Enabling high security turns SSL on; request parameters, custom parameters and HTTP request headers are not collected; strip exception messages is enabled; and queries can't be sent to New Relic in their raw form. enabled Type Boolean Default false Enable or disable high security mode. Example: <highSecurity enabled=\"true\"/> Copy Strip exception messages The stripExceptionMessages element is a child of the configuration element. To enable strip exception messages, set this property to true. By default, this is set to false, which means that the agent sends messages from all exceptions to the New Relic collector. If you enable high security mode, this is automatically changed to true, and the agent strips the messages from exceptions. enabled Type Boolean Default false Enable or disable strip exception messages. Example: <stripExceptionMessages enabled=\"true\"/> Copy Transaction events The transactionEvents element is a child of the configuration element. Use transactionEvents to configure transaction events. <transactionEvents enabled=\"true\" maximumSamplesStored=\"10000\"> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </transactionEvents> Copy The transactionEvents element supports the following attributes: enabled Type Boolean Default true Enable or disable the event recorder. maximumSamplesStored Type Integer Default 10000 The maximum number of samples to store in memory at once. Alternatively, set the MAX_TRANSACTION_SAMPLES_STORED environment variable in the application's environment. MAX_TRANSACTION_SAMPLES_STORED=500 Copy attributes Use this sub-element to customize your agent attribute settings for transaction events. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. Tip These attribute settings are specific to transaction events. Attribute settings can be applied globally to all event types to with this configuration setting. Caution When distributed tracing and/or Infinite Tracing are enabled, information from transaction events is applied to the root Span Event of the transaction. Consider applying any attribute settings for transaction events to span events and/or apply them as Global Attribute settings. Custom events The customEvents element is a child of the configuration element. Use customEvents to configure custom events. <customEvents enabled=\"true\" maximumSamplesStored=\"10000\"/> Copy The CustomEvents element supports the following attributes: enabled Type Boolean Default true Enable or disable the event recorder. maximumSamplesStored Type Integer Default 10000 The maximum number of samples to store in memory at once. Alternatively, set the MAX_EVENT_SAMPLES_STORED environment variable in the application's environment. MAX_EVENT_SAMPLES_STORED=500 Copy Custom parameters The customParameters element is a child of the configuration element. Use customParameters to configure custom parameters. <customParameters enabled=\"true\" /> Copy The CustomParameters element supports the following attributes: enabled Type Boolean Default true Enable or disable the capture of custom parameters. Labels (tags) The labels element is a child of the configuration element. This sets tag names and values. The list is a semicolon delimited list of colon-separated name and value pairs. You can also use with the NEW_RELIC_LABELS environment variable. Example: <labels>foo:bar;zip:zap</labels> Copy Browser instrumentation The browserMonitoring element is a child of the configuration element. browserMonitoring configures Browser monitoring in your .NET application. Browser gives you insight your end users' performance experience. This is accomplished by measuring the time it takes for your users' browsers to download and render your webpages by injecting a small amount of JavaScript code into the header and footer of each page. // If you use both the Exclude and Attribute elements // the Exclude element must be listed first. <browserMonitoring autoInstrument=\"true\"> <requestPathsExcluded> <path regex=\"url-regex-1\"/> <path regex=\"url-regex-2\"/> ... <path regex=\"url-regex-n\"/> </requestPathsExcluded> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </browserMonitoring> Copy The browserMonitoring element supports the following attributes: autoInstrument Type Boolean Default true By default the agent automatically injects the Browser agent JavaScript. To turn off automatic injection, set this attribute to false. attributes Use this sub-element to customize your agent attribute settings for Browser. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. requestPathsExcluded Use this sub-element to prevent the Browser agent from being injected in specific pages. The element is used as follows: <requestPathsExcluded> <path regex=\"url-regex-1\"/> <path regex=\"url-regex-2\"/> ... <path regex=\"url-regex-n\"/> </requestPathsExcluded> Copy The agent will not inject the Browser agent into pages whose URL matches one of the specified regular expressions. The regular expression should follow Microsoft guidelines for the Regex class. It is a reference to the virtual directory of the path in your application and not the full URL of the path you wish to exclude. For example, to exclude the pages in https://www.mywebsite.com/mywebpages/ you would simply insert /mywebpages/ as the path regex value. The requestPathsExcluded element should be used in cases where it is impossible or undesirable to use the DisableBrowserMonitoring() call. To minimize a possible performance impact try to use as few regular expressions as possible and keep them as simple as possible. Slow queries The slowSql element is a child of the configuration element. slowSql configures capturing information about slow query executions, and captures and obfuscates explain plans for these queries. <slowSql enabled=\"true\"/> Copy The slowSql element supports the following attribute: enabled Type Boolean Default true Enable or disable slow query tracing. Transaction traces The transactionTracer element is a child of the configuration element. transactionTracer configures transaction traces. Included in the trace is the exact call sequence of the transactions, including any query statements issued. <transactionTracer enabled=\"true\" transactionThreshold=\"apdex_f\" recordSql=\"obfuscated\" explainEnabled=\"true\" explainThreshold=\"500\" maxSegments=\"3000\" maxExplainPlans=\"20\"> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </transactionTracer> Copy The transactionTracer element supports the following attributes: enabled Type Boolean Default true Enable or disable transaction traces. transactionThreshold Type String Default apdex_f Defines the threshold for transaction traces. If a transaction takes longer than the threshold, it is eligible for being traced. See transaction trace basics for more about the rules governing traces. The default value is apdex_f, which sets the threshold to four times the application's apdex_t value. For more information about apdex_t, see Apdex. You can also set the threshold to be a specific time value in milliseconds. recordSql Type String Default obfuscated Select a query tracing policy. Options are off, which records nothing; obfuscated, which records an obfuscated version of the query; or raw, which records the query exactly as it is issued to the database. Caution Recording raw queries may capture sensitive information. explainEnabled Type Boolean Default false When true, the agent captures EXPLAIN statements for slow queries. explainThreshold Type Integer Default 500 Unit Milliseconds The agent collects slow query data for queries that exceed this threshold, along with any available explain plans, as part of transaction traces. maxSegments Type Integer Default 3000 The maximum number of segments to collect in a transaction trace. maxExplainPlans Type Integer Default 20 The maximum number of explain plans to collect during a harvest cycle. attributes Use this sub-element to customize your agent attribute settings for transaction traces. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. Datastore tracer The datastoreTracer element is a child of the configuration element. <datastoreTracer> <instanceReporting enabled=\"true\" /> <databaseNameReporting enabled=\"true\" /> <queryParameters enabled=\"false\" /> </datastoreTracer> Copy The datastoreTracer element supports the following sub-elements: instanceReporting Use this sub-element to enable collection of datastore instance metrics (such as the host and port) for some database drivers. These are reported on slow query traces and transaction traces. The default value of attribute enabled is true. databaseNameReporting Use this sub-element to enable collection of the database name on slow query traces and transaction traces for some database drivers. The default value of attribute enabled is true. queryParameters Use this sub-element to enable collection of the SQL query parameters on slow query traces. The default value of attribute enabled is false. Caution Recording query parameters may capture sensitive information. The transactionTracer.recordSql configuration option must be set to raw or this option is ignored. Distributed tracing The distributedTracing element is a child of the configuration element. <distributedTracing enabled=\"false\" excludeNewrelicHeader=\"false\"/> Copy Distributed tracing lets you see the path that a request takes as it travels through a distributed system. Enabling distributed tracing disables cross application tracing, and has other effects on APM features. Before enabling, read the planning guide. Important Requires .NET agent version 8.6.45.0 or higher. The distributedTracing element supports the following attributes: To enable or disable, see Enable distributed tracing. enabled Type Boolean Default false Alternatively, enable distributed tracing via the NEW_RELIC_DISTRIBUTED_TRACING_ENABLED environment variable in the application's environment. NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true Copy excludeNewrelicHeader Type Boolean Default false By default, supported versions of the agent utilize both the newrelic header and W3C Trace Context headers for distributed tracing. The newrelic distributed tracing header allows interoperability with older agents that don't support W3C Trace Context headers. Agent versions that support W3C Trace Context headers will prioritize them over newrelic headers for distributed tracing. If you do not want to utilize the newrelic header, setting this to true will result in the agent excluding the newrelic header and only using W3C Trace Context headers for distributed tracing. Distributed tracing reports span events. Span event reporting is enabled by default, but distributed tracing must be enabled for spans to be reported. To disable span events, choose one of the following options: Disable span events via config file Set the <spanEvents> element to false to disable via the newrelic.config file. This element is a child of the <configuration> element. <configuration . . . > <spanEvents enabled=\"false\" /> </configuration> Copy Disable span events via environment variable Set the NEW_RELIC_SPAN_EVENTS_ENABLED environment variable in the application's environment. NEW_RELIC_SPAN_EVENTS_ENABLED=false Copy Infinite Tracing Infinite Tracing extends the distributed tracing service by employing a trace observer that is external to the agent. It observes 100% of your application traces across various services and provides actionable data so you can solve issues faster. Important Infinite Tracing requires .NET Agent version 8.30 or higher. To turn on Infinite Tracing, enable distributed tracing and add the additional settings below <configuration . . . > <distributedTracing enabled=\"true\" /> <infiniteTracing> <trace_observer host=\"YOUR_TRACE_OBSERVER_HOST\" /> </infiniteTracing> </configuration> Copy The infiniteTracing element supports the following elements: trace_observer The trace_observer element identifies an observer host that is independent from the agent. For help getting a valid Infinite Tracing trace observer host entry, see Find or create a trace observer endpoint. The trace observer may be configured using the NEW_RELIC_INFINITE_TRACING_TRACE_OBSERVER_HOST environment variable as well. Important When configuring the trace observer, you should not supply the protocol as part of the host. For example, use myhost.infinitetracing.com instead of https://myhost.infinitetracing.com. Span events The spanEvents element is a child of the configuration element. Use spanEvents to configure span events. <spanEvents enabled=\"true\"> <attributes enabled=\"true\"> <exclude>myApiKey.*</exclude> <include>myApiKey.foo</include> </attributes> </spanEvents> Copy The spanEvents element supports the following attributes: enabled Type Boolean Default true Enable or disable the event recorder. attributes Use this sub-element to customize your agent attribute settings for span events. This sub-element uses the same settings as the primary attributes element: enabled, include, and exclude. Tip These attribute settings are specific to span events. Attribute settings may be applied globally to all event types to with this configuration setting. Capture HTTP Request Headers The allowAllHeaders element is a child of the configuration element. Set this to true to allow the .NET Agent to capture all HTTP request headers as request.headers.{http-header-name} attributes. Set this to false to only allow the .NET agent to collect the following HTTP request headers: request.headers.referer request.headers.accept request.headers.content-length request.headers.host request.headers.user-agent Copy enabled Type Boolean Default false Enable or disable HTTP request headers capture. Example: <allowAllHeaders enabled=\"true\" /> <attributes enabled=\"true\"> <include>request.headers.*</include> </attributes> Copy Important The allowAllHeaders setting is only available in the .NET Agent version 8.40.0+. When using allowAllHeaders to capture attributes, the captured request header attributes are still being controlled by the root level and destination level attributes settings. Without setting the request.header.* in the include list under the attributes element (see the following), the .NET Agent still filters out all header attributes. The default newrelic.config is set to include the request.header.*. <allowAllHeaders enabled=\"true\" /> <attributes enabled=\"true\"> <include>request.headers.*</include> ... </attributes> Copy The default newrelic.config is also set to explicitly exclude the following HTTP request headers to prevent the .NET Agent collecting unwanted data. <attributes enabled=\"true\"> <exclude>request.headers.cookie</exclude> <exclude>request.headers.authorization</exclude> <exclude>request.headers.proxy-authorization</exclude> <exclude>request.headers.x-*</exclude> </attributes> Copy Settings in app.config or web.config For ASP.NET and .NET Framework console apps you can also configure the following settings in your app's app.config or web.config, within the outermost element, <configuration>: Enable and disable the agent <appSettings> <add key = \"NewRelic.AgentEnabled\" value=\"false\" /> </appSettings> Copy Important If the agent is disabled in the local or global newrelic.config, the NewRelic.AgentEnabled settings in these files will be ignored. Application name For more information, see Name your .NET application. <appSettings> <add key = \"NewRelic.AppName\" value =\"Descriptive Name\" /> </appSettings> Copy License key <appSettings> <add key = \"NewRelic.LicenseKey\" value =\"XXXXXXXX\" /> </appSettings> Copy Change newrelic.config location Designates an alternative location for the config file outside of the local root of the app or global config location. The location entered must be an absolute path. <appSettings> <add key = \"NewRelic.ConfigFile\" value=\"C:\\Path-to-alternate-config-dir\\newrelic.config\" /> </appSettings> Copy Settings in appsettings.json For .NET Core apps, you can configure the following settings in appsettings.json if the following is true: The appsettings.json file must be located in the current working directory of the application. The application must have the following dependencies: Microsoft.Extensions.Configuration Microsoft.Extensions.Configuration.Json Microsoft.Extensions.Configuration.EnvironmentVariables Enable and disable the agent { \"NewRelic.AgentEnabled\":\"false\" } Copy Important If the agent is disabled in the local or global newrelic.config, the NewRelic.AgentEnabled setting in this file will be ignored. Application name For more information, see Name your .NET application. { \"NewRelic.AppName\": \"Descriptive Name\" } Copy License key { \"NewRelic.LicenseKey\": \"XXXXXXXX\" } Copy Change newrelic.config location Designates an alternative location for the config file outside of the local root of the app or global config location. The location entered must be an absolute path. { \"NewRelic.ConfigFile\": \"C:\\\\Path-to-alternate-config-dir\\\\newrelic.config\" } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 34.348297,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET <em>agent</em> configuration",
        "sections": ".NET <em>agent</em> configuration",
        "tags": "<em>Agents</em>",
        "body": "). Default (global) newrelic.config Default <em>source</em> and the lowest precedence. Will configure all applications on a host in the absence of other config files. The global config file is located in the New Relic <em>agent</em> home directory: %PROGRAMDATA%\\New Relic\\.NET <em>Agent</em> Required environment variables New"
      },
      "id": "60446c3b196a679d6a960f7a"
    }
  ],
  "/docs/integrations/open-source-telemetry-integrations/troubleshooting/troubleshoot-opentelemetry-exporter": [
    {
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "Explorer: Get the big picture along with the details",
        "Summary page",
        "Distributed Tracing",
        "Tip",
        "Transactions",
        "Databases",
        "Externals",
        "Errors",
        "Metrics Explorer",
        "Data explorer and query builder"
      ],
      "title": "View your OpenTelemetry data in New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "a5213cb2206f4c161dd97c015a7c6679b08e867b",
      "image": "https://docs.newrelic.com/static/2f8a3baa6793edf958ecb9db5346efa7/c1b63/explorer_otel_services.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/view-your-opentelemetry-data-new-relic/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-06-15T13:27:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "After you import OpenTelemetry data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about your applications, as well as detailed information, such as distributed tracing. To get started with the explorer: Go to one.newrelic.com and click Explorer. In the left sidebar, click Services - OpenTelemetry: Click the service you want to know more about, and if you need help understanding the data, see the explanations below. Summary page The opening page of the explorer is the Summary page listing various golden signals about your entity. Golden signals are key monitoring details such as response time, throughput, and error rate. By using this information, you can quickly decide if you need to dig deeper. Distributed Tracing When you access distributed tracing through the explorer, you are looking at traces that include that service. Once youre in that service, you can filter spans to find the ones you want. For example, to query service.name or trace.id, you can use the following: service.name = YOUR_SERVICE_NAME trace.id = YOUR_TRACE_ID For more ways to filter and analyze your spans, see our distributed tracing UI page. Tip If you prefer to search traces across all New Relic accounts in your organization, you can go outside explorer: one.newrelic.com > Apps > Favorites > Distributed tracing. Transactions Use Transactions to identify slow or error transactions that might be causing a spike in the response time of your application. From the transaction summary page, you can get a list of transactions by selecting See transactions table. Databases The Databases page shows an application's database and cache data. The page shows individual database transactions as a sortable table, and shows operations, throughput, and response time as charts. Externals Externals captures calls to out-of-process services such as web services, resources in the cloud, and other network entities. Errors On this page, you can see total errors, as well as charts showing error count and error rate. Metrics Explorer For selected OpenTelemetry languages, you can see information about your metrics in this section. Also, if you are using the Prometheus exporter with OpenTelemetry, you can view your metric data here. Data explorer and query builder Explore your metrics and traces using the data explorer, or write your own queries in query builder using NRQL. For more on how to query your data once it's in New Relic, see Query your data and Introduction to NRQL.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 389.8714,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View your <em>OpenTelemetry</em> data in New Relic",
        "sections": "View your <em>OpenTelemetry</em> data in New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "After you import <em>OpenTelemetry</em> data into New Relic, you can use a variety of tools to analyze it. Take a look at these UI options: Explorer Data explorer and query builder Explorer: Get the big picture along with the details The New Relic explorer is a good place to get overview information about"
      },
      "id": "6044e5dfe7b9d283d3579a04"
    },
    {
      "sections": [
        "OpenTelemetry quick start",
        "Step 1. Prerequisites",
        "Step 2. Instrument your service with OpenTelemetry",
        "Tip",
        "Step 3. Send your telemetry data to New Relic",
        "Important",
        "Use the OpenTelemetry collector (recommended)",
        "Use the native OTLP endpoint (pre-release)",
        "Step 4. View your data in the New Relic UI"
      ],
      "title": "OpenTelemetry quick start",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "1b846417a2958b61b047c838db49aea06f09a2a8",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-quick-start/",
      "published_at": "2021-06-15T13:27:17Z",
      "updated_at": "2021-05-09T18:01:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "OpenTelemetry is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up OpenTelemetry with New Relic. Here's an overview of the process, followed by details for each step. Prerequisites Instrument your service with OpenTelemetry Send your telemetry data to New Relic View your data in the New Relic UI In the following sections, we explain some basic architectural approaches, but if you want to explore other implementation options, check out OpenTelemetry architecture recipes. Step 1. Prerequisites First things first: If we dont already know you, sign up for a free New Relic account. Make sure you have an Insights insert key to send spans and metrics to New Relic. Step 2. Instrument your service with OpenTelemetry To get started, you instrument your service with OpenTelemetry. OpenTelemetry has language-specific products and SDKs to help you. Many languages offer out-the-box instrumentation for common libraries and frameworks. Each language also provides an API for further instrumenting your service manually. Tip We recommend that you instrument as many services as possible to get the most benefit from distributed tracing. Go to the repository for your language and follow the instructions to instrument your service. When you're done, return here to complete the next step of sending your telemetry data to New Relic. C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...See a complete list of languages in GitHub Step 3. Send your telemetry data to New Relic Choose how you want to export your telemetry data to New Relic: Use the OpenTelemetry collector (recommended) Use the native OTLP endpoint (pre-release) Both approaches involve configuring your service with an OTLP exporter to send data over the OpenTelemetry Protocol (OTLP). To do so, follow the documentation of the OTLP exporter for your service's language: C++ Erlang Go Java Javascript/Node.js .NET PHP Python Ruby Rust Swift ...Find additional OTLP language support in GitHub Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. If you were previously using a New Relic language-specific exporter consider signing up for the pre-release of New Relic's native OTLP endpoint. If you are interested in tracing, there are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Use the OpenTelemetry collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. The diagram below shows the flow of data with the collector. To use the collector: Configure your OpenTelemetry collector to export data to New Relic, using our example as a guide. Important The New Relic exporter for the collector will be deprecated in the future. If you are running your own collector, you will instead be able to use the OpenTelemetry Collector's OTLP exporter When we release our native OTLP endpoint (pre-release), th If you were previously using a New Relic language-specific exporter consider using the OTLP exporter for your language and send data directly to New Relic's native OTLP endpoint (pre-release). Use the native OTLP endpoint (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector or send us data directly from your service. If you are interested, let us know by completing this form. You can configure your service's OTLP exporter to send data directly to New Relic. If you're running your own OpenTelemetry collector, you can use the OTLP exporter for the collector to send data to New Relic. Step 4. View your data in the New Relic UI Once youve instrumented your service and configured it to export its data to New Relic, you can go to New Relic and view your data. The UI for OpenTelemetry has some similarities to the APM agent UI, so if you are familiar with that, you can go right to the UI. If you need help understanding your OpenTelemetry UI options, see View your OpenTelemetry data in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.97087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>OpenTelemetry</em> quick start",
        "sections": "<em>OpenTelemetry</em> quick start",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": "<em>OpenTelemetry</em> is a flexible toolkit that you can implement in a variety of ways. We recommend a basic four-step approach for setting up <em>OpenTelemetry</em> with New Relic. Here&#x27;s an overview of the process, followed by details for each step. Prerequisites Instrument your service with <em>OpenTelemetry</em> Send"
      },
      "id": "6044e5dfe7b9d2aadc5799d4"
    },
    {
      "sections": [
        "Introduction to OpenTelemetry with New Relic",
        "Benefits of OpenTelemetry",
        "Tip",
        "Should I use OpenTelemetry instrumentation or New Relic agents?",
        "OpenTelemetry: A work in progress",
        "New Relic APM agents",
        "How OpenTelemetry works with New Relic",
        "Important",
        "Collector (recommended)",
        "OTLP (pre-release)",
        "What's next?"
      ],
      "title": "Introduction to OpenTelemetry with New Relic",
      "type": "docs",
      "tags": [
        "Integrations",
        "Open source telemetry integrations",
        "OpenTelemetry"
      ],
      "external_id": "c87898d2d5835c00930c173eabd1bf93040badea",
      "image": "https://docs.newrelic.com/static/820ec30261e57dd485d471987fae4a28/0f2bc/collector_introduction_1.png",
      "url": "https://docs.newrelic.com/docs/integrations/open-source-telemetry-integrations/opentelemetry/introduction-opentelemetry-new-relic/",
      "published_at": "2021-06-15T13:25:38Z",
      "updated_at": "2021-04-28T06:50:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send OpenTelemetry data to New Relic and analyze the results in our observability platform. This introduction can help you decide if you want to get started with OpenTelemetry. If you're already familiar with OpenTelemetry and want to jump into the setup, go to our OpenTelemetry quick start. If you're just getting acquainted with OpenTelemetry, this is what we'll explore here: Benefits of OpenTelemetry Should I use OpenTelemetry or New Relic agents? How OpenTelemetry works with New Relic Benefits of OpenTelemetry OpenTelemetry provides a secure, vendor-neutral specification for service instrumentation so that you can send data to distinct backends of your choice, such as New Relic. OpenTelemetry offers a single set of APIs and libraries that standardize how you collect and transfer telemetry data for your services. The following components make up the OpenTelemetry project: Specifications for the core pillars of observability to drive consistency across all projects (initially, traces and metrics are supported, followed by logs) APIs that contain interfaces and implementations based on the specifications SDKs (reference implementations of the APIs) created specifically for languages like Java, Python, Go, Erlang, and more Collectors that offer a vendor-agnostic implementation for processing and exporting Exporters that enable you to send data to a backend of your choice The components of OpenTelemetry work together to create some distinct advantages for capturing telemetry data: Feature Description Ubiquitous instrumentation A single, open standard of instrumentation provides better coverage and flexibility as engineers from all over the world contribute to the instrumentation. Future proof As the instrumentation gets built into libraries and frameworks, and as more vendors move to support this open standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build integrations into OpenTelemetry or add instrumentation directly to source code, ensuring end users can easily monitor these new technologies. Simplified choice You dont need to decide which instrumentation option to use (a proprietary option or one of the other open standards). Cross-platform compatibility OpenTelemetry supports a variety of languages and backends. It represents a vendor-neutral path for capturing and transmitting telemetry to backends without altering existing instrumentation. Streamlined observability It is easier for vendors to support and test against a single standard as they dont need to develop their own agents or collectors. High dimensionality OpenTelemetry uses dimensional metrics, so you can filter and facet on more aspects of the data, such as AWS regions, Kubernetes clusters, or service versions. Dimensional metrics also lead to less time between occurrence and reporting. Efficiency OpenTelemetrys fire-and-forget trace-centric approach to instrumentation often has lower overhead than New Relic agents, especially for asynchronous workloads. It will also result in better handling of trace data for asynchronous requests. Tip For more, see our blog posts on OpenTelemetry. Should I use OpenTelemetry instrumentation or New Relic agents? As you consider OpenTelemetry, you may also be looking at New Relic APM agents that also capture telemetry data. As you'd expect, there is a lot of overlap between features available from OpenTelemetry agents and SDKs versus those available from New Relic APM agents. This is especially true if you're interested in distributed tracing telemetry data. The choice you make depends on what you need. We recommend that you explore both New Relic and OpenTelemetry instrumentation or discuss it directly with us at New Relic to decide what works best for you. OpenTelemetry: A work in progress OpenTelemetry is still an emerging standard, so your choices may be affected by what's available. You can check on the current state of the specification at the OpenTelemetry site. The current state of language-specific OpenTelemetry APIs and SDKs varies: some languages are still pre-alpha and may be missing instructions on how to instrument your service. Most languages have some implementation of traces that is sufficient to start sending data to New Relic. Check out this table in GitHub that provides an overview of the state of OpenTelemetry specification compliance for each language. For languages that New Relic does not currently provide an agent or SDK, OpenTelemetry may offer you a good alternative. Also, in cases where you want explicit control over sampling of your telemetry data, OpenTelemetry provides a lot of flexibility. As OpenTelemetry matures, New Relic will continue to support new OpenTelemetry data models and to provide a curated UI experience for our Full Stack Observability customers. New Relic APM agents In general, New Relic APM agents will collect more telemetry data for your services, and they offer a wide range configuration options and an extensive set of auto-instrumentation capabilities. APM agents offer detailed transaction trace visibility for individual services. They also offer predefined sampling to balance the performance impact of your instrumentation against the need to capture enough data to gain helpful insights. How OpenTelemetry works with New Relic Here are two basic ways you could set up OpenTelemetry with New Relic: use the OpenTelemetry collector (recommended), or use the native OTLP endpoint (pre-release). Each approach assumes you set up instrumentation in your code, but they differ in how the data is gathered and sent to New Relic. If you are interested in tracing, we recommend that you instrument as many services as you can so that you get the most benefit from distributed tracing. There are two main options for trace sampling: Configure the head-based, native sampling in OpenTelemetry, which means OpenTelemetry samples traces before they are sent to New Relic. Head-based sampling doesnt analyze all traces, but instead randomly samples traces up front before details about the completed traces are known. Both the OpenTelemetry collector and the native OTLP endpoint support this option. If you want New Relic to analyze all your traces, configure tail-based sampling with New Relic Infinite Tracing, which reroutes traces to our cloud-based trace observer. The trace observer accepts all your traces and sorts through them to find useful ones. If you want to know more about this option, especially if you want to use it in the EU, see Introduction to Infinite Tracing. While Infinite Tracing is not yet compatible with the native OTLP endpoint, it is still possible to configure tail-based sampling via the collector, for more information see Tail Sampling Processor. Tip We discuss some variations on these basic approaches in our OpenTelemetry architecture recipes. For a detailed discussion about the architecture of OpenTelemetry itself, see our blog. Important New Relic's language-specific exporters for OpenTelemetry are now deprecated in favor of the OpenTelemetry collector and native OTLP endpoint options described here. Collector (recommended) The OpenTelemetry project provides a tool called the OpenTelemetry Collector that you can deploy and use as an intermediate data aggregator. In your service, you use the OpenTelemetry exporter to send telemetry data first to the OpenTelemetry collector. Then, in the OpenTelemetry collector, you enable the New Relic exporter to send data to New Relic. In this workflow, note the alternate path if you set up New Relic Infinite Tracing: Here are some advantages of this approach: The OpenTelemetry collector can perform processing operations on telemetry data before it is sent to the backend, including filtering attributes, excluding traces, and sampling. The OpenTelemetry collector can receive telemetry data in many formats and forward it on to New Relics backend, including Prometheus, Zipkin, Jaeger, AWS X-Ray, OpenCensus, and much more. The OpenTelemetry collector can collect system-level metrics from the host where it is running. OTLP (pre-release) The example above uses a New Relic exporter, but we have a pre-release program if you want to try out the native OTLP endpoint for sending your data to New Relic. You can either use the OTLP exporter in the OpenTelemetry collector, or send us data directly from your service. If you are interested, let us know by completing this form. Here are some advantages to operating without an OpenTelemetry collector: There is no need to deploy a collector alongside your service. Telemetry data is sent directly from the instrumented service to New Relic. If something goes wrong, and telemetry data does not arrive, there is one less component to debug. What's next? If you want to set up OpenTelemetry with New Relic, the next step is to check out our OpenTelemetry quick start. If you prefer to use a New Relic APM agent, go to Introduction to APM.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 208.91429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "sections": "Introduction to <em>OpenTelemetry</em> with New Relic",
        "tags": "<em>Open</em> <em>source</em> <em>telemetry</em> <em>integrations</em>",
        "body": ", and as more vendors move to support this <em>open</em> standard, you can be confident that you wont need to change your instrumentation. Support for newer technologies When new technologies emerge, contributors can build <em>integrations</em> into <em>OpenTelemetry</em> or add instrumentation directly to <em>source</em> code, ensuring end"
      },
      "id": "603e81ba196a67304da83dab"
    }
  ],
  "/docs/integrations/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic": [
    {
      "sections": [
        "Kubernetes integration: compatibility and requirements",
        "Compatibility",
        "Requirements",
        "Install using Helm"
      ],
      "title": "Kubernetes integration: compatibility and requirements",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Get started"
      ],
      "external_id": "e9bbd729904fa01739eb91e4f3c74561b51c2ba1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/get-started/kubernetes-integration-compatibility-requirements/",
      "published_at": "2021-06-15T13:04:07Z",
      "updated_at": "2021-06-15T13:04:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Kubernetes integration can be installed directly on a server or VM, or through several cloud platforms, such as GKE, EKS, AKS, or OpenShift. Each has a different compatibility with our integration. Compatibility Our Kubernetes integration is compatible with the following versions, depending on the installation mode: Install mode or feature Kubernetes versions Kubernetes cluster Currently tested with versions 1.10 to 1.21 Kubernetes cluster GKE Currently tested with versions 1.10 and 1.17 Kubernetes cluster EKS (EC2 nodes or Fargate) Compatible with version 1.11 or higher Kubernetes cluster AKS Compatible with version 1.11 or higher Kubernetes cluster OpenShift Currently tested with versions 3.7, 3.9, 4.2, 4.3, 4.4, 4.5 and 4.6 Control plane monitoring Compatible with version 1.11 or higher Service monitoring Compatible with version 1.13 or higher Requirements The New Relic Kubernetes integration has the following requirements: Linux distribution compatible with New Relic infrastructure agent. kube-state-metrics version 1.9.5 running on the cluster. When using CRI-O as the container runtime, the processes inside containers are not reported. Performance data is collected at the container level. Install using Helm For compatibility and requirements when installing the Kubernetes integration using Helm, see Alternative install using Helm.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 125.16182,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Kubernetes <em>integration</em>: compatibility and requirements",
        "sections": "Kubernetes <em>integration</em>: compatibility and requirements",
        "tags": "<em>Get</em> <em>started</em>"
      },
      "id": "603e92dc64441f3a974e8891"
    },
    {
      "sections": [
        "Requirements for the infrastructure agent",
        "Processor architectures",
        "Operating systems",
        "Unique hostname",
        "Permissions",
        "Libraries",
        "Network access",
        "Container software",
        "CPU, memory, and disk usage",
        "Configuration management tools"
      ],
      "title": "Requirements for the infrastructure agent",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Get started"
      ],
      "external_id": "517b5d94efa0139aa3ef5238569d5b04d28fb932",
      "image": "https://docs.newrelic.com/static/8de19e871ebba1c3d12258efc569dc6f/103b3/amazon-linux.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/",
      "published_at": "2021-06-14T21:07:01Z",
      "updated_at": "2021-06-14T21:07:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before installing our infrastructure agent, make sure your system and any on-host integrations you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package manager and dependencies) Windows: both 32 and 64-bit for x86 processor architectures ARM: arm64 architecture including AWS Graviton 2 processor is supported on compatible Linux operating sytems. Built-in log forwarding and on-host integrations are not yet available. Operating systems The infrastructure agent supports these operating systems up to their manufacturer's end-of-life. Operating system Supported by the infrastructure agent Amazon Linux All versions CentOS Version 7 or higher Debian Version 8 (\"Jessie\") or higher Docker Docker 1.12 Kubernetes Tested with versions 1.10 to 1.16 Red Hat Enterprise Linux (RHEL) Version 6 or higher SUSE Linux Enterprise Server (SLES) Versions 11.4, 12.1, 12.2, 12.3, and 12.4 Ubuntu LTS versions 16.04.x, 18.04.x, 20.04.x Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 (only the infrastructure agent is supported). You can also monitor Amazon BottleRocket workloads: When running EC2 instances, use the containerized agent. On EKS, install the Kubernetes integration. For ECS clusters, deploy the ECS integration. Unique hostname The infrastructure agent uses the hostname to uniquely identify each server. To avoid inaccurate metrics from combining multiple servers under a single hostname, make sure that each monitored server has a unique hostname. You can use the optional display_name setting to override the default hostname. Servers named localhost are not reported because this is a default name and inherently non-unique. Permissions The infrastructure agent requires these permissions: Linux: By default, the agent runs and installs as root. You can also select privileged or unprivileged run modes. Windows: The agent must be installed from an Administrator account and requires Administrator privileges to run. Libraries For agent versions 1.1.19 or higher, you need the libcap library in order to install Infrastructure. It's available in the official repositories of your distribution. Network access In order to report data to New Relic, our infrastructure agent must have outbound access to certain domains and ports. If your system needs a proxy to connect to these domains, use the proxy setting. Container software The infrastructure agent instruments Docker containers when installed on the host server. We support Docker versions 1.12 or higher. CPU, memory, and disk usage The infrastructure agent is fairly lightweight. For typical CPU, memory, and disk usage, see our page on agent performance overhead. For more information on supported file systems, see Storage sample attributes. Configuration management tools The infrastructure agent can be deployed programmatically using several config management and deploy tools: Ansible Chef Elastic Beanstalk Puppet",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.11418,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Get</em> <em>started</em>",
        "body": "Before installing our infrastructure agent, make sure your system and any on-host <em>integrations</em> you configure meet the requirements. Processor architectures The infrastructure agent supports these processor architectures: Linux: 64-bit for x86 processor architectures (also requires 64-bit package"
      },
      "id": "60440aca28ccbc8ce02c60cf"
    },
    {
      "sections": [
        "Introduction to New Relic integrations",
        "Tip",
        "Choose what's right for you",
        "Create your own solutions"
      ],
      "title": "Introduction to New Relic integrations",
      "type": "docs",
      "tags": [
        "Full-Stack Observability",
        "Instrument everything",
        "Get started"
      ],
      "external_id": "03217983a29af22737c1163da9ef0811b29c2bcd",
      "image": "",
      "url": "https://docs.newrelic.com/docs/full-stack-observability/instrument-everything/get-started-new-relic-instrumentation/introduction-new-relic-integrations/",
      "published_at": "2021-06-14T21:34:14Z",
      "updated_at": "2021-03-16T07:30:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We provide hundreds of solutions to get your data into New Relic so you can analyze the data in one place. They give you a steady flow of useful data to fix problems quickly, maintain complex systems, improve your code, and accelerate your digital transformation. You can bring in data from hundreds of applications, frameworks, services, operating systems, and other technologies. Our integrations gather the data, and the agents send it to New Relic. The solution you need may require you to install both an integration and an agent. In some cases, you can just install our agents that contain integrations, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to get you started. Tip To use integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Choose what's right for you We offer a wide range of solutions so you can easily collect data across your environment. You may only need one of our solutions to get the data you need, or you can choose a variety of options to capture a broader range of data types. Go to New Relic Integrations to find solutions that fit your environment. Here is a sample of what youll find there: Application performance monitoring (APM): C, Go, Java, Node, .NET, PHP, Python, and Ruby Mobile apps: Android and iOS Browser monitoring: Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Apple Safari Host monitoring: Linux and Microsoft Windows Cloud platform monitoring: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) Core infrastructure services: Kubernetes, NGINX, MySQL, and more Open source telemetry integrations: Prometheus, Micrometer, OpenTelemetry, and more Create your own solutions If you are looking for custom options, we have tools to help you create your own: Use New Relic Flex to create lightweight monitoring solutions using infrastructure monitoring. Use New Relic Telemetry SDKs to build custom solutions for sending metrics, traces, and more. Build your own New Relic One applications that you can share with your colleagues, or edit open source applications in our catalog.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.882034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to New Relic <em>integrations</em>",
        "sections": "Introduction to New Relic <em>integrations</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": " <em>integrations</em>, such as our APM agents. Whatever data you need to bring in, chances are that we have options for your environment. If you prefer to make your own solutions, we also offer tools to <em>get</em> you <em>started</em>. Tip To use <em>integrations</em> and infrastructure monitoring, as well as the rest of our"
      },
      "id": "603e817f28ccbc4857eba798"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure/prometheus-high-availability-ha": [
    {
      "sections": [
        "Set up your Prometheus remote write integration",
        "Tip",
        "Set up the integration",
        "Mapping of Prometheus metric types",
        "Override metric type mappings",
        "Customize remote write behavior",
        "X-License Key",
        "prometheus_server URL parameter",
        "Optimize throughput and memory consumption",
        "Troubleshoot error messages",
        "Remove the integration"
      ],
      "title": "Set up your Prometheus remote write integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "e2a503880e8e1c38284434d5829fad3f48dc7abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration/",
      "published_at": "2021-06-15T12:08:02Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can get Prometheus data flowing in New Relic with just a few simple steps. This page covers basic setup for the remote write integration, as well as a few common troubleshooting topics. For information on integrating Prometheus servers in a high availability (HA) configuration, see our Prometheus high availability documentation. Tip To use Prometheus integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up the integration Go to the Prometheus remote write setup launcher in New Relic One, then complete these steps. Add Prometheus data Enter a name for the Prometheus server to be connected and your remote_write URL. Important: The name you enter for the server will create an attribute on your data. It will also be the name that identifies which Prometheus server is sending data to New Relic. Add a new remote_write URL to your Prometheus YML file. Add this information under global_config in the file, at the same indentation level as the global section. Use the following syntax: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=YOUR_DATA_SOURCE_NAME bearer_token:YOUR_LICENSE_KEY Copy OR remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=YOUR_LICENSE_KEY&prometheus_server=YOUR_DATA_SOURCE_NAME Copy European Union accounts: If you're connecting from the EU, use the following URL: https://metric-api.eu.newrelic.com/prometheus/v1/write Copy Kubernetes and Helm remote write integrations: Add the remote write URL to your Helm values.yaml file. Replace remoteWrite: [] with two lines similar to the following example. Be sure to use your remote write URL and use indentation that matches the rest of the file: remoteWrite: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=YOUR_DATA_SOURCE_NAME bearer_token:YOUR_LICENSE_KEY Copy Restart your Prometheus server. View your data in the New Relic UI. For example, use the remote write dashboard we automatically create when you set up your integration. Mapping of Prometheus metric types The Prometheus remote write protocol does not include metric type information or other helpful metric metadata when sending metrics to New Relic. Because the remote write protocol doesn't include this information, New Relic infers the metric type based on Prometheus naming conventions. Metrics not following these naming conventions may not be mapped correctly. New Relic maps Prometheus metrics types into New Relic metric types based on Prometheus metric naming conventions as follows: metricName_bucket is stored as a New Relic count metric type. metricName_count is stored as a New Relic count metric type. metricName_total is stored as a New Relic count metric type. metricName_sum is stored as a New Relic summary metric type. Everything else is stored as a New Relic gauge metric type. Override metric type mappings If you have metrics that don't follow Prometheus naming conventions, you can configure remote-write to tag the metric with a newrelic_metric_type label that indicates the metric type. This label is stripped when received by New Relic. Example: You have a counter metric named my_counter, which does not have our naming convention suffix of _bucket, _count or _total. In this situation, your metric would be identified as a gauge rather than a counter. To correct this, add the following relabel configuration to your prometheus.yml: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=... write_relabel_configs: - source_labels: [__name__] regex: ^my_counter$ target_label: newrelic_metric_type replacement: \"counter\" action: replace Copy This rule matches any metric with the name my_counter and adds a newrelic_metric_type label that identifies it as a counter. You can use the following (case sensitive) values as the replacement value: counter gauge summary When a newrelic_metric_type label is present on a metric received and set to one of the valid values, New Relic will assign the indicated type to the metric (and strip the label) before downstream consumption in the data pipeline. If you have multiple metrics that don't follow the above naming conventions, you can add multiple rules with each rule matching different source labels. Customize remote write behavior You can customize the following parameters if you are writing to more than one account in New Relic or are connecting more than one Prometheus data source to the same account in New Relic. For more information, see the docs on remote write tuning. X-License Key Your account's license key is not an API key. The license key is used for authentication and to identify which account to write data into. If you are configuring Prometheus to write into different New Relic accounts or sub-accounts, use a different key on each remote write URL. prometheus_server URL parameter The prometheus_server parameter is a label or attribute used to add to stats that are written to NRDB. Use this same label when configuring your Grafana data source to limit results to just those from a particular prometheus_server. Optimize throughput and memory consumption Remote write increases the total memory consumption of your Prometheus servers. If you're experiencing issues we recommend the following: Increase max_samples_per_send for higher throughput workloads, along a proportional increase in capacity. If memory consumption is still a problem, try limiting the number of max_shards per server. Troubleshoot error messages If you receive an integration error message from New Relic or error messages in your Prometheus server logs after restarting your Prometheus server, review our remote write troubleshooting documentation. This includes fixing common errors, such as missing or incorrect characters, bad requests, request entity too large, and rate limit errors. Remove the integration When you remove the Prometheus remote write integration, this stops new data from flowing, but it will not purge or remove any historical data. To remove the integration, remove the configuration code snippet from your Prometheus YML file, then restart the server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.05444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up your <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "sections": "Set up your <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " Union accounts: If you&#x27;re connecting from the EU, use the following URL: https:&#x2F;&#x2F;metric-api.eu.newrelic.com&#x2F;<em>prometheus</em>&#x2F;v1&#x2F;<em>write</em> Copy Kubernetes and Helm <em>remote</em> <em>write</em> <em>integrations</em>: Add the <em>remote</em> <em>write</em> URL to your Helm values.yaml file. Replace <em>remoteWrite</em>: [] with two lines similar to the following"
      },
      "id": "603e94de196a674e6ca83def"
    },
    {
      "sections": [
        "Remote write errors and error messages",
        "Common errors and issues",
        "Configuration errors",
        "400: bad request error",
        "413: request entity too large error",
        "429: rate limit error",
        "Investigate error messages"
      ],
      "title": "Remote write errors and error messages",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "0d190be5dc4fd91ce6bbcef7343d01f75670ca51",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/remote-write-errors-error-messages/",
      "published_at": "2021-06-15T12:08:02Z",
      "updated_at": "2021-03-13T03:46:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This resource contains information about common errors and error messages that may alert you to issues with data visibility and availability, as well as information about how to respond. Common errors and issues If you receive an integration error message from New Relic or error messages in your Prometheus server logs after restarting your Prometheus server, there are several actions you can take to troubleshoot and get data flowing properly. Below are a few tips regarding common issues and error messages. For specific information on how to query for NrIntegrationError events, see Investigate error messages below. Configuration errors Missing or incorrect characters in the remote write URL in the config file (for example the endpoint, license key, or prometheus_server name) or incorrect placement of the information in the file will result in the Prometheus server not starting, remote write not working properly, or errors appearing in Prometheus server logs. 400: bad request error If no data appears with a bad request error, check your configuration file to confirm that the placement of the remote write information is correct, and that there are no missing or incorrect characters. 413: request entity too large error This means you have sent a request in which one or more fields, or the entire payload, has exceeded our limits. 429: rate limit error This means you have hit a rate limit on the amount of data being sent at one time (for example cardinality or data points per minute). You can troubleshoot by reducing the amount of Prometheus or general metric data you are sending, or by requesting a rate-limit increase. Investigate error messages You can investigate error messages in New Relic by doing either or both of the following. Run a NrIntegrationError query on the error message using NRQL, then look at the Message field in the UI to see a description of what went wrong. For example: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' Copy Investigate individual errors in time to see when and where they occur and any simultaneously occurring issues, and perform targeted troubleshooting based on what you find out. For example: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' TIMESERIES Copy If youve validated that you can send data successfully but are unable to query it, you may be running into other kinds of limits, like the inspected count limit. This may manifest itself as an error message during the integration process that says: Unable to retrieve data for Prometheus data source <name>.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.49146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Remote</em> <em>write</em> errors <em>and</em> error messages",
        "sections": "<em>Remote</em> <em>write</em> errors <em>and</em> error messages",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " error messages below. Configuration errors Missing or incorrect characters in the <em>remote</em> <em>write</em> URL in the config file (for example the endpoint, license key, or <em>prometheus</em>_server name) or incorrect placement of the information in the file will result in the <em>Prometheus</em> server not starting, <em>remote</em>"
      },
      "id": "6044e65d196a67914a960f6b"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.81399,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-openmetrics/add-mutual-tls-prometheus-endpoints": [
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations",
        "Configure nri-prometheus-latest.yaml",
        "Example configuration file",
        "Key names and definitions",
        "Configure objects in target key",
        "Kubernetes port and endpoint path",
        "Example: Labels for Kubernetes port and path",
        "Services and Endpoints scrape behaviour",
        "Reload the configuration",
        "Docker: Run previous config file"
      ],
      "title": "Configure Prometheus OpenMetrics integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "12be9e8bb8c03ca3f0eed948d0bc6e863b60efef",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/",
      "published_at": "2021-06-15T12:07:04Z",
      "updated_at": "2021-05-11T06:21:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Unless otherwise noted, configuration options for your Prometheus OpenMetrics integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: Configure your New Relic license key as an environment variable named LICENSE_KEY. This provides a more secure environment, as New Relic can load your environment variable from a mutual TLS authentication secret. Configure nri-prometheus-latest.yaml The nri-prometheus-latest.yaml manifest file includes the nri-prometheus-cfg map showing an example configuration. Use the manifest file to configure the following parameters. Example configuration file The following is an example configuration file that you can save and modify to fit your needs. For more information, see the documentation about mutual TLS authentication and translating PromQL to NRQL. # The name of your cluster. It's important to match other New Relic products to relate the data. cluster_name: \"<YOUR_CLUSTER_NAME>\" # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true # standalone: true # How often the integration should run. Defaults to 30s. # scrape_duration: \"30s\" # The HTTP client timeout when fetching data from targets. Defaults to 5s. # scrape_timeout: \"5s\" # How old must the entries used for calculating the counters delta be # before the telemetry emitter expires them. Defaults to 5m. # telemetry_emitter_delta_expiration_age: \"5m\" # How often must the telemetry emitter check for expired delta entries. # Defaults to 5m. # telemetry_emitter_delta_expiration_check_interval: \"5m\" # Wether the integration should run in verbose mode or not. Defaults to false. verbose: false # Whether the integration should run in audit mode or not. Defaults to false. # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent. # It does not include verbose mode. This can lead to a high log volume, use with care. audit: false # Wether the integration should skip TLS verification or not. Defaults to false. insecure_skip_verify: false # The label used to identify scrapable targets. Defaults to \"prometheus.io/scrape\". scrape_enabled_label: \"prometheus.io/scrape\" # scrape_services Allows to enable scraping the service and not the endpoints behind. # When endpoints are scraped this is no longer needed scrape_services: true # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does. # Please notice that depending on the number of endpoints behind a service the load can increase considerably scrape_endpoints: false # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true. require_scrape_enabled_label_for_nodes: true # Number of worker threads used for scraping targets. # For large clusters with many (>400) targets, slowly increase until scrape # time falls between the desired `scrape_duration`. # Increasing this value too much will result in huge memory consumption if too # many metrics are being scraped. # Default: 4 # worker_threads: 4 # Maximum number of metrics to keep in memory until a report is triggered. # Changing this value is not recommended unless instructed by the New Relic support team. # max_stored_metrics: 10000 # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms. # Changing this value is not recommended unless instructed by the New Relic support team. # min_emitter_harvest_period: 200ms # targets: # - description: Secure etcd example # urls: [\"https://192.168.3.1:2379\", \"https://192.168.3.2:2379\", \"https://192.168.3.3:2379\"] # tls_config: # ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" # cert_file_path: \"/etc/etcd/etcd-client.crt\" # key_file_path: \"/etc/etcd/etcd-client.key\" # Proxy to be used by the emitters when submitting metrics. It should be # in the format [scheme]://[domain]:[port]. # The emitter is the component in charge of sending the scraped metrics. # This proxy won't be used when scraping metrics from the targets. # By default it's empty, meaning that no proxy will be used. # emitter_proxy: \"http://localhost:8888\" # Certificate to add to the root CA that the emitter will use when # verifying server certificates. # If left empty, TLS uses the host's root CA set. # emitter_ca_file: \"/path/to/cert/server.pem\" # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account # having limited privileges. Defaults to false. # disable_autodiscovery: false # Whether the emitter should skip TLS verification when submitting data. # Defaults to false. # emitter_insecure_skip_verify: false # Histogram support is based on New Relic's guidelines for higher # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md. # To better support visualization of this data, percentiles are calculated # based on the histogram metrics and sent to New Relic. # By default, the following percentiles are calculated: 50, 95 and 99. # # percentiles: # - 50 # - 95 # - 99 # transformations: # - description: \"General processing rules\" # rename_attributes: # - metric_prefix: \"\" # attributes: # container_name: \"containerName\" # pod_name: \"podName\" # namespace: \"namespaceName\" # node: \"nodeName\" # container: \"containerName\" # pod: \"podName\" # deployment: \"deploymentName\" # ignore_metrics: # # Ignore all the metrics except the ones listed below. # # This is a list that complements the data retrieved by the New # # Relic Kubernetes Integration, that's why Pods and containers are # # not included, because they are already collected by the # # Kubernetes Integration. # - except: # - kube_hpa_ # - kube_daemonset_ # - kube_statefulset_ # - kube_endpoint_ # - kube_service_ # - kube_limitrange # - kube_node_ # - kube_poddisruptionbudget_ # - kube_resourcequota # - nr_stats # copy_attributes: # # Copy all the labels from the timeseries with metric name # # `kube_hpa_labels` into every timeseries with a metric name that # # starts with `kube_hpa_` only if they share the same `namespace` # # and `hpa` labels. # - from_metric: \"kube_hpa_labels\" # to_metrics: \"kube_hpa_\" # match_by: # - namespace # - hpa # - from_metric: \"kube_daemonset_labels\" # to_metrics: \"kube_daemonset_\" # match_by: # - namespace # - daemonset # - from_metric: \"kube_statefulset_labels\" # to_metrics: \"kube_statefulset_\" # match_by: # - namespace # - statefulset # - from_metric: \"kube_endpoint_labels\" # to_metrics: \"kube_endpoint_\" # match_by: # - namespace # - endpoint # - from_metric: \"kube_service_labels\" # to_metrics: \"kube_service_\" # match_by: # - namespace # - service # - from_metric: \"kube_node_labels\" # to_metrics: \"kube_node_\" # match_by: # - namespace # - node # integration definition files required to map metrics to entities # definition_files_path: /etc/newrelic-infra/definition-files Copy Key names and definitions Here are some key names and definitions for your Prometheus OpenMetrics config file. Key name Description cluster_name Required. The name of the cluster. This value will be included as the clusterName attribute for all metrics. verbose Stringified boolean. true (default): Logs debugging information. false: Only logs error messages. targets Configuration of static endpoints to be scraped by the integration. It contains a list of objects. For more information about this structure, see the documentation about target configuration. scrape_enabled_label Kubernetes String. The integration will check if the Kubernetes pod and service are annotated or have a label with this value to decide if it has to be scraped. This is particularly useful when you want to limit the amount of data by ignoring metrics or including specific metrics that are sent to New Relic. Since by default we use the same label Prometheus uses to discover targets that can be scraped, most exporters that you install automatically set this label. To keep a fine-grained control on the targets you want the integration to scrape, you can set this option to some other value (such as newrelic/scrape) and then add the annotation or label newrelic/scrape: \"true\" to your Kubernetes objects. If both are set, annotations take precedence over labels. Default: \"prometheus.io/scrape\" scrape_duration How often should the scraper run. To lower memory usage, increase this value. To raise memory usage, decrease this value. The impact on memory usage is due to distributing target fetching over the scrape interval to avoid querying (and buffering) all the data at once. Default is 30s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. scrape_timeout The HTTP client timeout when fetching data from endpoints. Default: 5s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. worker_threads Number of worker threads used for scraping targets. Can be increased on environments with a high number of targets or targets with high latency, but might increase memory consumption. Default: 4. It is not recommended to use more than 10. require_scrape_enabled_label_for_nodes Kubernetes Whether or not Kubernetes nodes need labels to be scraped. Default: true. percentiles Histogram support is based on New Relic's guidelines for higher level metrics abstractions. To better support visualization of this data, percentiles are calculated based on the histogram metrics and sent to New Relic. Valid values include 50, 95, and 99. emitter_proxy Proxy used by the integration when submitting metrics: [scheme]://[domain]:[port] This proxy won't be used when fetching metrics from the targets. By default this is empty, and no proxy will be used. emitter_ca_file Certificate to add to the root CA that the emitter will use when verifying server certificates. If left empty, TLS uses the host's root CA set. emitter_insecure_skip_verify Whether the emitter should skip TLS verification when submitting data. Default: false. disable_autodiscovery Set to true in order to disable autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account having limited privileges. Default: false. Configure objects in target key If you want the target key in the configuration file to contain one or more objects, use the following structure in the YAML list: Key name Description description A description for the URLs in this target. urls A list of strings with the URLs to be scraped. tls_config Authentication configuration used to send requests. It supports TLS and Mutual TLS. For more information, see the documentation about mutual TLS authentication. Kubernetes port and endpoint path New Relic's Prometheus OpenMetrics integration automatically discovers which targets to scrape. To specify the port and endpoint path to be used when constructing the target, you can use the prometheus.io/port and prometheus.io/path annotations or label in your Kubernetes pods and services. Annotations take precedence over labels. If prometheus.io/port is not present, the integration will try to scrape each port or ContainerPort defined for the service. If prometheus.io/path is not present, the integration will default to /metrics. If a service is not running on the default /my-metrics-path path, add a label to the pod prometheus.io/path=my-metrics-path. If the path to the metrics endpoint is more complex and cannot be a valid label value (for example, foo/bar), use annotations instead. Example: Labels for Kubernetes port and path In this example, you have a deployment in your cluster, and the pods expose Prometheus metrics on port 8080 and in the path my-metrics. In the PodSpec metadata of the deployment manifest, set the labels prometheus.io/port: \"8080\" and prometheus.io/path: \"my-metrics\". When the integration tries to retrieve the metrics from your pods, it will send a request to http://<pod-ip>:8080/my-metrics. apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment spec: replicas: 2 selector: matchLabels: app: my-app template: metadata: labels: app: my-app prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"my-metrics\" Copy Services and Endpoints scrape behaviour By default, services are scraped directly instead of the underlying endpoints since scrape_services is set to true and scrape_endpoints to false. In order to change this behaviour set scrape_endpoints to true configuring Prometheus OpenMetrics integrations to scrape the underlying endpoints, as Prometheus server natively does, instead of directly the services. Please notice that depending on the number of endpoints behind the services in the cluster the load and the data injested can increase considerably, monitor and, if needed, increase resource requirements. Moreover, even if it is possible to set both scrape_services and scrape_endpoints to true to assure retrocompatibility, it would lead to duplicate data. Reload the configuration The Prometheus OpenMetrics integration does not automatically reload the configuration when you make changes to the configuration file. Docker: To reload the configuration, restart the container running the integration: docker restart nri-prometheus Copy Kubernetes: To reload the configuration, restart the integration. Recommendation: Scale the deployment down to zero replicas, and then scale it back to one replica: kubectl scale deployment nri-prometheus --replicas=0 kubectl scale deployment nri-prometheus --replicas=1 Copy Docker: Run previous config file Docker: To run the integration with the previous configuration file: Copy the content and save it to a config.yaml file. From within the same directory, run the command: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e CLUSTER_NAME=\"YOUR_CLUSTER_NAME\" \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:latest --configfile=/config.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.84927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "Unless otherwise noted, configuration options for your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: <em>Configure</em> your New Relic license key"
      },
      "id": "603e830964441f85a04e8877"
    },
    {
      "sections": [
        "Install, update, or uninstall your Prometheus OpenMetrics integration",
        "Install the integration",
        "Docker installation",
        "Kubernetes installation",
        "Important",
        "Update the integration",
        "Docker update procedures",
        "Kubernetes update procedures",
        "Uninstall"
      ],
      "title": "Install, update, or uninstall your Prometheus OpenMetrics integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "89b53bf5ac9ce6c14663eca2ab44d96cfe897bc8",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration/",
      "published_at": "2021-06-15T12:07:03Z",
      "updated_at": "2021-03-16T06:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Prometheus OpenMetrics integration, review the requirements for your environment: Docker requirements Kubernetes requirements Install the integration To install the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker installation To install the New Relic Prometheus OpenMetrics integration in a Docker environment: Create a configuration file config.yaml. Use the example configuration file, or look at the nri-prometheus-latest.yaml manifest file, which includes the nri-prometheus-cfg config map and an example configuration. Required: Add your New Relic license key and a cluster name to identify your Docker container. Add the endpoints to scrape; for example, add the http://localhost:8080/metrics endpoint to collect metrics about the integration itself. Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. For more information, see the metrics filtering documentation. Start the integration in the background: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:1.5 Copy Confirm the container is running properly: docker ps -f \"name=nri-prometheus\" Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Kubernetes installation Important To prevent your data from being duplicated, configure your New Relic Prometheus OpenMetrics integration only with one replica. Running two or more replicas will result in duplicated data. For more information, see the troubleshooting procedures for restarts and gaps in data. To install the New Relic Prometheus OpenMetrics integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml Copy Edit the nri-prometheus-latest.yaml manifest file: Required: Add your New Relic license key and a cluster name to identify your Kubernetes cluster. env: - name: LICENSE_KEY value: \"<YOUR_LICENSE_KEY>\" [...] config.yaml: | cluster_name: \"<YOUR_CLUSTER_NAME>\" Copy Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. By default, the New Relic Prometheus OpenMetrics integration uses the same labels as Prometheus to discover targets. For more information, see the metrics filtering documentation. Deploy the integration in your Kubernetes cluster: kubectl apply -f nri-prometheus-latest.yaml Copy To confirm that the deployment has been created successfully, look at the CURRENT replicas in the results generated by this command: kubectl get deployments nri-prometheus Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Update the integration To update the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker update procedures Remove the Docker container. Follow standard installation procedures to start a new Docker container. The integration logs its current version when it starts up. To determine the running version: docker logs nri-prometheus 2>&1 | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Kubernetes update procedures Follow standard installation procedures. Reapply the nri-prometheus-latest.yaml manifest file. The integration logs its version when it starts up. To determine the running version: kubectl logs deploy/nri-prometheus | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Uninstall To uninstall the Prometheus OpenMetrics integration for Docker or Kubernetes, execute the following command: Docker: docker rm -f nri-prometheus Copy Kubernetes: kubectl delete -f nri-prometheus-latest.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.09126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "sections": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": " information, see the troubleshooting procedures for restarts and gaps in data. To <em>install</em> the New Relic <em>Prometheus</em> <em>OpenMetrics</em> integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;<em>integrations</em>&#x2F;kubernetes&#x2F;nri"
      },
      "id": "603e8309e7b9d2d69d2a07cc"
    },
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations in large Kubernetes environments",
        "Configure the integration for large environments"
      ],
      "title": "Configure Prometheus OpenMetrics integrations in large  Kubernetes environments",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "84e7d3b803e614a6362e0246a58b48e3209094ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments/",
      "published_at": "2021-06-15T10:12:30Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of metrics exposed by each target. For example, a Prometheus OpenMetrics integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30 seconds, consumes 2.5CPU and 700MB of RAM. Configure the integration for large environments To estimate the size of the environment you are monitoring, run the following query to see how many targets are being scraped: SELECT latest(nr_stats_targets) FROM Metric where clusterName=clusterName SINCE 30 MINUTES AGO TIMESERIES Copy In huge environments with hundreds of targets to be scraped, the latency on the /metrics endpoints must be below 1 second. Run this query to check the latency of the different targets. This query retrieves the data exposed by the Prometheus OpenMetrics integration, and shows the time required to fetch each endpoint. SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy In order to keep the time needed to scrape all the targets below 30 seconds, use the following configurations: Targets Configuration Targets < 400, with 1000 metrics each No modification is required. CPU ranges roughly between 0.1 and 1.5 cores, and the memory required should be no more than 256MB. 400 < targets < 1000, with 1000 metrics each The number of workers should be increased to 6-8. CPU ranges roughly between 1.5 and 3.5 cores, and the memory required is around 100MB. Targets > 1000, with 1000 metrics each The number of workers should be increased to 10 or more. CPU is over 3.5 cores, and the memory required is around 1GB or more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.07805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large  Kubernetes environments",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large Kubernetes environments",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of <em>metrics</em> exposed by each target. For example, a <em>Prometheus</em> <em>OpenMetrics</em> integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30"
      },
      "id": "603e9b3b196a676cd0a83d81"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-openmetrics/add-rename-or-copy-prometheus-attributes": [
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations",
        "Configure nri-prometheus-latest.yaml",
        "Example configuration file",
        "Key names and definitions",
        "Configure objects in target key",
        "Kubernetes port and endpoint path",
        "Example: Labels for Kubernetes port and path",
        "Services and Endpoints scrape behaviour",
        "Reload the configuration",
        "Docker: Run previous config file"
      ],
      "title": "Configure Prometheus OpenMetrics integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "12be9e8bb8c03ca3f0eed948d0bc6e863b60efef",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/",
      "published_at": "2021-06-15T12:07:04Z",
      "updated_at": "2021-05-11T06:21:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Unless otherwise noted, configuration options for your Prometheus OpenMetrics integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: Configure your New Relic license key as an environment variable named LICENSE_KEY. This provides a more secure environment, as New Relic can load your environment variable from a mutual TLS authentication secret. Configure nri-prometheus-latest.yaml The nri-prometheus-latest.yaml manifest file includes the nri-prometheus-cfg map showing an example configuration. Use the manifest file to configure the following parameters. Example configuration file The following is an example configuration file that you can save and modify to fit your needs. For more information, see the documentation about mutual TLS authentication and translating PromQL to NRQL. # The name of your cluster. It's important to match other New Relic products to relate the data. cluster_name: \"<YOUR_CLUSTER_NAME>\" # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true # standalone: true # How often the integration should run. Defaults to 30s. # scrape_duration: \"30s\" # The HTTP client timeout when fetching data from targets. Defaults to 5s. # scrape_timeout: \"5s\" # How old must the entries used for calculating the counters delta be # before the telemetry emitter expires them. Defaults to 5m. # telemetry_emitter_delta_expiration_age: \"5m\" # How often must the telemetry emitter check for expired delta entries. # Defaults to 5m. # telemetry_emitter_delta_expiration_check_interval: \"5m\" # Wether the integration should run in verbose mode or not. Defaults to false. verbose: false # Whether the integration should run in audit mode or not. Defaults to false. # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent. # It does not include verbose mode. This can lead to a high log volume, use with care. audit: false # Wether the integration should skip TLS verification or not. Defaults to false. insecure_skip_verify: false # The label used to identify scrapable targets. Defaults to \"prometheus.io/scrape\". scrape_enabled_label: \"prometheus.io/scrape\" # scrape_services Allows to enable scraping the service and not the endpoints behind. # When endpoints are scraped this is no longer needed scrape_services: true # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does. # Please notice that depending on the number of endpoints behind a service the load can increase considerably scrape_endpoints: false # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true. require_scrape_enabled_label_for_nodes: true # Number of worker threads used for scraping targets. # For large clusters with many (>400) targets, slowly increase until scrape # time falls between the desired `scrape_duration`. # Increasing this value too much will result in huge memory consumption if too # many metrics are being scraped. # Default: 4 # worker_threads: 4 # Maximum number of metrics to keep in memory until a report is triggered. # Changing this value is not recommended unless instructed by the New Relic support team. # max_stored_metrics: 10000 # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms. # Changing this value is not recommended unless instructed by the New Relic support team. # min_emitter_harvest_period: 200ms # targets: # - description: Secure etcd example # urls: [\"https://192.168.3.1:2379\", \"https://192.168.3.2:2379\", \"https://192.168.3.3:2379\"] # tls_config: # ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" # cert_file_path: \"/etc/etcd/etcd-client.crt\" # key_file_path: \"/etc/etcd/etcd-client.key\" # Proxy to be used by the emitters when submitting metrics. It should be # in the format [scheme]://[domain]:[port]. # The emitter is the component in charge of sending the scraped metrics. # This proxy won't be used when scraping metrics from the targets. # By default it's empty, meaning that no proxy will be used. # emitter_proxy: \"http://localhost:8888\" # Certificate to add to the root CA that the emitter will use when # verifying server certificates. # If left empty, TLS uses the host's root CA set. # emitter_ca_file: \"/path/to/cert/server.pem\" # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account # having limited privileges. Defaults to false. # disable_autodiscovery: false # Whether the emitter should skip TLS verification when submitting data. # Defaults to false. # emitter_insecure_skip_verify: false # Histogram support is based on New Relic's guidelines for higher # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md. # To better support visualization of this data, percentiles are calculated # based on the histogram metrics and sent to New Relic. # By default, the following percentiles are calculated: 50, 95 and 99. # # percentiles: # - 50 # - 95 # - 99 # transformations: # - description: \"General processing rules\" # rename_attributes: # - metric_prefix: \"\" # attributes: # container_name: \"containerName\" # pod_name: \"podName\" # namespace: \"namespaceName\" # node: \"nodeName\" # container: \"containerName\" # pod: \"podName\" # deployment: \"deploymentName\" # ignore_metrics: # # Ignore all the metrics except the ones listed below. # # This is a list that complements the data retrieved by the New # # Relic Kubernetes Integration, that's why Pods and containers are # # not included, because they are already collected by the # # Kubernetes Integration. # - except: # - kube_hpa_ # - kube_daemonset_ # - kube_statefulset_ # - kube_endpoint_ # - kube_service_ # - kube_limitrange # - kube_node_ # - kube_poddisruptionbudget_ # - kube_resourcequota # - nr_stats # copy_attributes: # # Copy all the labels from the timeseries with metric name # # `kube_hpa_labels` into every timeseries with a metric name that # # starts with `kube_hpa_` only if they share the same `namespace` # # and `hpa` labels. # - from_metric: \"kube_hpa_labels\" # to_metrics: \"kube_hpa_\" # match_by: # - namespace # - hpa # - from_metric: \"kube_daemonset_labels\" # to_metrics: \"kube_daemonset_\" # match_by: # - namespace # - daemonset # - from_metric: \"kube_statefulset_labels\" # to_metrics: \"kube_statefulset_\" # match_by: # - namespace # - statefulset # - from_metric: \"kube_endpoint_labels\" # to_metrics: \"kube_endpoint_\" # match_by: # - namespace # - endpoint # - from_metric: \"kube_service_labels\" # to_metrics: \"kube_service_\" # match_by: # - namespace # - service # - from_metric: \"kube_node_labels\" # to_metrics: \"kube_node_\" # match_by: # - namespace # - node # integration definition files required to map metrics to entities # definition_files_path: /etc/newrelic-infra/definition-files Copy Key names and definitions Here are some key names and definitions for your Prometheus OpenMetrics config file. Key name Description cluster_name Required. The name of the cluster. This value will be included as the clusterName attribute for all metrics. verbose Stringified boolean. true (default): Logs debugging information. false: Only logs error messages. targets Configuration of static endpoints to be scraped by the integration. It contains a list of objects. For more information about this structure, see the documentation about target configuration. scrape_enabled_label Kubernetes String. The integration will check if the Kubernetes pod and service are annotated or have a label with this value to decide if it has to be scraped. This is particularly useful when you want to limit the amount of data by ignoring metrics or including specific metrics that are sent to New Relic. Since by default we use the same label Prometheus uses to discover targets that can be scraped, most exporters that you install automatically set this label. To keep a fine-grained control on the targets you want the integration to scrape, you can set this option to some other value (such as newrelic/scrape) and then add the annotation or label newrelic/scrape: \"true\" to your Kubernetes objects. If both are set, annotations take precedence over labels. Default: \"prometheus.io/scrape\" scrape_duration How often should the scraper run. To lower memory usage, increase this value. To raise memory usage, decrease this value. The impact on memory usage is due to distributing target fetching over the scrape interval to avoid querying (and buffering) all the data at once. Default is 30s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. scrape_timeout The HTTP client timeout when fetching data from endpoints. Default: 5s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. worker_threads Number of worker threads used for scraping targets. Can be increased on environments with a high number of targets or targets with high latency, but might increase memory consumption. Default: 4. It is not recommended to use more than 10. require_scrape_enabled_label_for_nodes Kubernetes Whether or not Kubernetes nodes need labels to be scraped. Default: true. percentiles Histogram support is based on New Relic's guidelines for higher level metrics abstractions. To better support visualization of this data, percentiles are calculated based on the histogram metrics and sent to New Relic. Valid values include 50, 95, and 99. emitter_proxy Proxy used by the integration when submitting metrics: [scheme]://[domain]:[port] This proxy won't be used when fetching metrics from the targets. By default this is empty, and no proxy will be used. emitter_ca_file Certificate to add to the root CA that the emitter will use when verifying server certificates. If left empty, TLS uses the host's root CA set. emitter_insecure_skip_verify Whether the emitter should skip TLS verification when submitting data. Default: false. disable_autodiscovery Set to true in order to disable autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account having limited privileges. Default: false. Configure objects in target key If you want the target key in the configuration file to contain one or more objects, use the following structure in the YAML list: Key name Description description A description for the URLs in this target. urls A list of strings with the URLs to be scraped. tls_config Authentication configuration used to send requests. It supports TLS and Mutual TLS. For more information, see the documentation about mutual TLS authentication. Kubernetes port and endpoint path New Relic's Prometheus OpenMetrics integration automatically discovers which targets to scrape. To specify the port and endpoint path to be used when constructing the target, you can use the prometheus.io/port and prometheus.io/path annotations or label in your Kubernetes pods and services. Annotations take precedence over labels. If prometheus.io/port is not present, the integration will try to scrape each port or ContainerPort defined for the service. If prometheus.io/path is not present, the integration will default to /metrics. If a service is not running on the default /my-metrics-path path, add a label to the pod prometheus.io/path=my-metrics-path. If the path to the metrics endpoint is more complex and cannot be a valid label value (for example, foo/bar), use annotations instead. Example: Labels for Kubernetes port and path In this example, you have a deployment in your cluster, and the pods expose Prometheus metrics on port 8080 and in the path my-metrics. In the PodSpec metadata of the deployment manifest, set the labels prometheus.io/port: \"8080\" and prometheus.io/path: \"my-metrics\". When the integration tries to retrieve the metrics from your pods, it will send a request to http://<pod-ip>:8080/my-metrics. apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment spec: replicas: 2 selector: matchLabels: app: my-app template: metadata: labels: app: my-app prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"my-metrics\" Copy Services and Endpoints scrape behaviour By default, services are scraped directly instead of the underlying endpoints since scrape_services is set to true and scrape_endpoints to false. In order to change this behaviour set scrape_endpoints to true configuring Prometheus OpenMetrics integrations to scrape the underlying endpoints, as Prometheus server natively does, instead of directly the services. Please notice that depending on the number of endpoints behind the services in the cluster the load and the data injested can increase considerably, monitor and, if needed, increase resource requirements. Moreover, even if it is possible to set both scrape_services and scrape_endpoints to true to assure retrocompatibility, it would lead to duplicate data. Reload the configuration The Prometheus OpenMetrics integration does not automatically reload the configuration when you make changes to the configuration file. Docker: To reload the configuration, restart the container running the integration: docker restart nri-prometheus Copy Kubernetes: To reload the configuration, restart the integration. Recommendation: Scale the deployment down to zero replicas, and then scale it back to one replica: kubectl scale deployment nri-prometheus --replicas=0 kubectl scale deployment nri-prometheus --replicas=1 Copy Docker: Run previous config file Docker: To run the integration with the previous configuration file: Copy the content and save it to a config.yaml file. From within the same directory, run the command: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e CLUSTER_NAME=\"YOUR_CLUSTER_NAME\" \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:latest --configfile=/config.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.84927,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "Unless otherwise noted, configuration options for your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: <em>Configure</em> your New Relic license key"
      },
      "id": "603e830964441f85a04e8877"
    },
    {
      "sections": [
        "Install, update, or uninstall your Prometheus OpenMetrics integration",
        "Install the integration",
        "Docker installation",
        "Kubernetes installation",
        "Important",
        "Update the integration",
        "Docker update procedures",
        "Kubernetes update procedures",
        "Uninstall"
      ],
      "title": "Install, update, or uninstall your Prometheus OpenMetrics integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "89b53bf5ac9ce6c14663eca2ab44d96cfe897bc8",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration/",
      "published_at": "2021-06-15T12:07:03Z",
      "updated_at": "2021-03-16T06:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Prometheus OpenMetrics integration, review the requirements for your environment: Docker requirements Kubernetes requirements Install the integration To install the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker installation To install the New Relic Prometheus OpenMetrics integration in a Docker environment: Create a configuration file config.yaml. Use the example configuration file, or look at the nri-prometheus-latest.yaml manifest file, which includes the nri-prometheus-cfg config map and an example configuration. Required: Add your New Relic license key and a cluster name to identify your Docker container. Add the endpoints to scrape; for example, add the http://localhost:8080/metrics endpoint to collect metrics about the integration itself. Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. For more information, see the metrics filtering documentation. Start the integration in the background: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:1.5 Copy Confirm the container is running properly: docker ps -f \"name=nri-prometheus\" Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Kubernetes installation Important To prevent your data from being duplicated, configure your New Relic Prometheus OpenMetrics integration only with one replica. Running two or more replicas will result in duplicated data. For more information, see the troubleshooting procedures for restarts and gaps in data. To install the New Relic Prometheus OpenMetrics integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml Copy Edit the nri-prometheus-latest.yaml manifest file: Required: Add your New Relic license key and a cluster name to identify your Kubernetes cluster. env: - name: LICENSE_KEY value: \"<YOUR_LICENSE_KEY>\" [...] config.yaml: | cluster_name: \"<YOUR_CLUSTER_NAME>\" Copy Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. By default, the New Relic Prometheus OpenMetrics integration uses the same labels as Prometheus to discover targets. For more information, see the metrics filtering documentation. Deploy the integration in your Kubernetes cluster: kubectl apply -f nri-prometheus-latest.yaml Copy To confirm that the deployment has been created successfully, look at the CURRENT replicas in the results generated by this command: kubectl get deployments nri-prometheus Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Update the integration To update the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker update procedures Remove the Docker container. Follow standard installation procedures to start a new Docker container. The integration logs its current version when it starts up. To determine the running version: docker logs nri-prometheus 2>&1 | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Kubernetes update procedures Follow standard installation procedures. Reapply the nri-prometheus-latest.yaml manifest file. The integration logs its version when it starts up. To determine the running version: kubectl logs deploy/nri-prometheus | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Uninstall To uninstall the Prometheus OpenMetrics integration for Docker or Kubernetes, execute the following command: Docker: docker rm -f nri-prometheus Copy Kubernetes: kubectl delete -f nri-prometheus-latest.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.09126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "sections": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": " information, see the troubleshooting procedures for restarts and gaps in data. To <em>install</em> the New Relic <em>Prometheus</em> <em>OpenMetrics</em> integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;<em>integrations</em>&#x2F;kubernetes&#x2F;nri"
      },
      "id": "603e8309e7b9d2d69d2a07cc"
    },
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations in large Kubernetes environments",
        "Configure the integration for large environments"
      ],
      "title": "Configure Prometheus OpenMetrics integrations in large  Kubernetes environments",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "84e7d3b803e614a6362e0246a58b48e3209094ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments/",
      "published_at": "2021-06-15T10:12:30Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of metrics exposed by each target. For example, a Prometheus OpenMetrics integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30 seconds, consumes 2.5CPU and 700MB of RAM. Configure the integration for large environments To estimate the size of the environment you are monitoring, run the following query to see how many targets are being scraped: SELECT latest(nr_stats_targets) FROM Metric where clusterName=clusterName SINCE 30 MINUTES AGO TIMESERIES Copy In huge environments with hundreds of targets to be scraped, the latency on the /metrics endpoints must be below 1 second. Run this query to check the latency of the different targets. This query retrieves the data exposed by the Prometheus OpenMetrics integration, and shows the time required to fetch each endpoint. SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy In order to keep the time needed to scrape all the targets below 30 seconds, use the following configurations: Targets Configuration Targets < 400, with 1000 metrics each No modification is required. CPU ranges roughly between 0.1 and 1.5 cores, and the memory required should be no more than 256MB. 400 < targets < 1000, with 1000 metrics each The number of workers should be increased to 6-8. CPU ranges roughly between 1.5 and 3.5 cores, and the memory required is around 100MB. Targets > 1000, with 1000 metrics each The number of workers should be increased to 10 or more. CPU is over 3.5 cores, and the memory required is around 1GB or more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.07805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large  Kubernetes environments",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large Kubernetes environments",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of <em>metrics</em> exposed by each target. For example, a <em>Prometheus</em> <em>OpenMetrics</em> integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30"
      },
      "id": "603e9b3b196a676cd0a83d81"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments": [
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations",
        "Configure nri-prometheus-latest.yaml",
        "Example configuration file",
        "Key names and definitions",
        "Configure objects in target key",
        "Kubernetes port and endpoint path",
        "Example: Labels for Kubernetes port and path",
        "Services and Endpoints scrape behaviour",
        "Reload the configuration",
        "Docker: Run previous config file"
      ],
      "title": "Configure Prometheus OpenMetrics integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "12be9e8bb8c03ca3f0eed948d0bc6e863b60efef",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/",
      "published_at": "2021-06-15T12:07:04Z",
      "updated_at": "2021-05-11T06:21:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Unless otherwise noted, configuration options for your Prometheus OpenMetrics integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: Configure your New Relic license key as an environment variable named LICENSE_KEY. This provides a more secure environment, as New Relic can load your environment variable from a mutual TLS authentication secret. Configure nri-prometheus-latest.yaml The nri-prometheus-latest.yaml manifest file includes the nri-prometheus-cfg map showing an example configuration. Use the manifest file to configure the following parameters. Example configuration file The following is an example configuration file that you can save and modify to fit your needs. For more information, see the documentation about mutual TLS authentication and translating PromQL to NRQL. # The name of your cluster. It's important to match other New Relic products to relate the data. cluster_name: \"<YOUR_CLUSTER_NAME>\" # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true # standalone: true # How often the integration should run. Defaults to 30s. # scrape_duration: \"30s\" # The HTTP client timeout when fetching data from targets. Defaults to 5s. # scrape_timeout: \"5s\" # How old must the entries used for calculating the counters delta be # before the telemetry emitter expires them. Defaults to 5m. # telemetry_emitter_delta_expiration_age: \"5m\" # How often must the telemetry emitter check for expired delta entries. # Defaults to 5m. # telemetry_emitter_delta_expiration_check_interval: \"5m\" # Wether the integration should run in verbose mode or not. Defaults to false. verbose: false # Whether the integration should run in audit mode or not. Defaults to false. # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent. # It does not include verbose mode. This can lead to a high log volume, use with care. audit: false # Wether the integration should skip TLS verification or not. Defaults to false. insecure_skip_verify: false # The label used to identify scrapable targets. Defaults to \"prometheus.io/scrape\". scrape_enabled_label: \"prometheus.io/scrape\" # scrape_services Allows to enable scraping the service and not the endpoints behind. # When endpoints are scraped this is no longer needed scrape_services: true # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does. # Please notice that depending on the number of endpoints behind a service the load can increase considerably scrape_endpoints: false # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true. require_scrape_enabled_label_for_nodes: true # Number of worker threads used for scraping targets. # For large clusters with many (>400) targets, slowly increase until scrape # time falls between the desired `scrape_duration`. # Increasing this value too much will result in huge memory consumption if too # many metrics are being scraped. # Default: 4 # worker_threads: 4 # Maximum number of metrics to keep in memory until a report is triggered. # Changing this value is not recommended unless instructed by the New Relic support team. # max_stored_metrics: 10000 # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms. # Changing this value is not recommended unless instructed by the New Relic support team. # min_emitter_harvest_period: 200ms # targets: # - description: Secure etcd example # urls: [\"https://192.168.3.1:2379\", \"https://192.168.3.2:2379\", \"https://192.168.3.3:2379\"] # tls_config: # ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" # cert_file_path: \"/etc/etcd/etcd-client.crt\" # key_file_path: \"/etc/etcd/etcd-client.key\" # Proxy to be used by the emitters when submitting metrics. It should be # in the format [scheme]://[domain]:[port]. # The emitter is the component in charge of sending the scraped metrics. # This proxy won't be used when scraping metrics from the targets. # By default it's empty, meaning that no proxy will be used. # emitter_proxy: \"http://localhost:8888\" # Certificate to add to the root CA that the emitter will use when # verifying server certificates. # If left empty, TLS uses the host's root CA set. # emitter_ca_file: \"/path/to/cert/server.pem\" # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account # having limited privileges. Defaults to false. # disable_autodiscovery: false # Whether the emitter should skip TLS verification when submitting data. # Defaults to false. # emitter_insecure_skip_verify: false # Histogram support is based on New Relic's guidelines for higher # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md. # To better support visualization of this data, percentiles are calculated # based on the histogram metrics and sent to New Relic. # By default, the following percentiles are calculated: 50, 95 and 99. # # percentiles: # - 50 # - 95 # - 99 # transformations: # - description: \"General processing rules\" # rename_attributes: # - metric_prefix: \"\" # attributes: # container_name: \"containerName\" # pod_name: \"podName\" # namespace: \"namespaceName\" # node: \"nodeName\" # container: \"containerName\" # pod: \"podName\" # deployment: \"deploymentName\" # ignore_metrics: # # Ignore all the metrics except the ones listed below. # # This is a list that complements the data retrieved by the New # # Relic Kubernetes Integration, that's why Pods and containers are # # not included, because they are already collected by the # # Kubernetes Integration. # - except: # - kube_hpa_ # - kube_daemonset_ # - kube_statefulset_ # - kube_endpoint_ # - kube_service_ # - kube_limitrange # - kube_node_ # - kube_poddisruptionbudget_ # - kube_resourcequota # - nr_stats # copy_attributes: # # Copy all the labels from the timeseries with metric name # # `kube_hpa_labels` into every timeseries with a metric name that # # starts with `kube_hpa_` only if they share the same `namespace` # # and `hpa` labels. # - from_metric: \"kube_hpa_labels\" # to_metrics: \"kube_hpa_\" # match_by: # - namespace # - hpa # - from_metric: \"kube_daemonset_labels\" # to_metrics: \"kube_daemonset_\" # match_by: # - namespace # - daemonset # - from_metric: \"kube_statefulset_labels\" # to_metrics: \"kube_statefulset_\" # match_by: # - namespace # - statefulset # - from_metric: \"kube_endpoint_labels\" # to_metrics: \"kube_endpoint_\" # match_by: # - namespace # - endpoint # - from_metric: \"kube_service_labels\" # to_metrics: \"kube_service_\" # match_by: # - namespace # - service # - from_metric: \"kube_node_labels\" # to_metrics: \"kube_node_\" # match_by: # - namespace # - node # integration definition files required to map metrics to entities # definition_files_path: /etc/newrelic-infra/definition-files Copy Key names and definitions Here are some key names and definitions for your Prometheus OpenMetrics config file. Key name Description cluster_name Required. The name of the cluster. This value will be included as the clusterName attribute for all metrics. verbose Stringified boolean. true (default): Logs debugging information. false: Only logs error messages. targets Configuration of static endpoints to be scraped by the integration. It contains a list of objects. For more information about this structure, see the documentation about target configuration. scrape_enabled_label Kubernetes String. The integration will check if the Kubernetes pod and service are annotated or have a label with this value to decide if it has to be scraped. This is particularly useful when you want to limit the amount of data by ignoring metrics or including specific metrics that are sent to New Relic. Since by default we use the same label Prometheus uses to discover targets that can be scraped, most exporters that you install automatically set this label. To keep a fine-grained control on the targets you want the integration to scrape, you can set this option to some other value (such as newrelic/scrape) and then add the annotation or label newrelic/scrape: \"true\" to your Kubernetes objects. If both are set, annotations take precedence over labels. Default: \"prometheus.io/scrape\" scrape_duration How often should the scraper run. To lower memory usage, increase this value. To raise memory usage, decrease this value. The impact on memory usage is due to distributing target fetching over the scrape interval to avoid querying (and buffering) all the data at once. Default is 30s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. scrape_timeout The HTTP client timeout when fetching data from endpoints. Default: 5s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. worker_threads Number of worker threads used for scraping targets. Can be increased on environments with a high number of targets or targets with high latency, but might increase memory consumption. Default: 4. It is not recommended to use more than 10. require_scrape_enabled_label_for_nodes Kubernetes Whether or not Kubernetes nodes need labels to be scraped. Default: true. percentiles Histogram support is based on New Relic's guidelines for higher level metrics abstractions. To better support visualization of this data, percentiles are calculated based on the histogram metrics and sent to New Relic. Valid values include 50, 95, and 99. emitter_proxy Proxy used by the integration when submitting metrics: [scheme]://[domain]:[port] This proxy won't be used when fetching metrics from the targets. By default this is empty, and no proxy will be used. emitter_ca_file Certificate to add to the root CA that the emitter will use when verifying server certificates. If left empty, TLS uses the host's root CA set. emitter_insecure_skip_verify Whether the emitter should skip TLS verification when submitting data. Default: false. disable_autodiscovery Set to true in order to disable autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account having limited privileges. Default: false. Configure objects in target key If you want the target key in the configuration file to contain one or more objects, use the following structure in the YAML list: Key name Description description A description for the URLs in this target. urls A list of strings with the URLs to be scraped. tls_config Authentication configuration used to send requests. It supports TLS and Mutual TLS. For more information, see the documentation about mutual TLS authentication. Kubernetes port and endpoint path New Relic's Prometheus OpenMetrics integration automatically discovers which targets to scrape. To specify the port and endpoint path to be used when constructing the target, you can use the prometheus.io/port and prometheus.io/path annotations or label in your Kubernetes pods and services. Annotations take precedence over labels. If prometheus.io/port is not present, the integration will try to scrape each port or ContainerPort defined for the service. If prometheus.io/path is not present, the integration will default to /metrics. If a service is not running on the default /my-metrics-path path, add a label to the pod prometheus.io/path=my-metrics-path. If the path to the metrics endpoint is more complex and cannot be a valid label value (for example, foo/bar), use annotations instead. Example: Labels for Kubernetes port and path In this example, you have a deployment in your cluster, and the pods expose Prometheus metrics on port 8080 and in the path my-metrics. In the PodSpec metadata of the deployment manifest, set the labels prometheus.io/port: \"8080\" and prometheus.io/path: \"my-metrics\". When the integration tries to retrieve the metrics from your pods, it will send a request to http://<pod-ip>:8080/my-metrics. apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment spec: replicas: 2 selector: matchLabels: app: my-app template: metadata: labels: app: my-app prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"my-metrics\" Copy Services and Endpoints scrape behaviour By default, services are scraped directly instead of the underlying endpoints since scrape_services is set to true and scrape_endpoints to false. In order to change this behaviour set scrape_endpoints to true configuring Prometheus OpenMetrics integrations to scrape the underlying endpoints, as Prometheus server natively does, instead of directly the services. Please notice that depending on the number of endpoints behind the services in the cluster the load and the data injested can increase considerably, monitor and, if needed, increase resource requirements. Moreover, even if it is possible to set both scrape_services and scrape_endpoints to true to assure retrocompatibility, it would lead to duplicate data. Reload the configuration The Prometheus OpenMetrics integration does not automatically reload the configuration when you make changes to the configuration file. Docker: To reload the configuration, restart the container running the integration: docker restart nri-prometheus Copy Kubernetes: To reload the configuration, restart the integration. Recommendation: Scale the deployment down to zero replicas, and then scale it back to one replica: kubectl scale deployment nri-prometheus --replicas=0 kubectl scale deployment nri-prometheus --replicas=1 Copy Docker: Run previous config file Docker: To run the integration with the previous configuration file: Copy the content and save it to a config.yaml file. From within the same directory, run the command: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e CLUSTER_NAME=\"YOUR_CLUSTER_NAME\" \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:latest --configfile=/config.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.84926,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "Unless otherwise noted, configuration options for your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: <em>Configure</em> your New Relic license key"
      },
      "id": "603e830964441f85a04e8877"
    },
    {
      "sections": [
        "Install, update, or uninstall your Prometheus OpenMetrics integration",
        "Install the integration",
        "Docker installation",
        "Kubernetes installation",
        "Important",
        "Update the integration",
        "Docker update procedures",
        "Kubernetes update procedures",
        "Uninstall"
      ],
      "title": "Install, update, or uninstall your Prometheus OpenMetrics integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "89b53bf5ac9ce6c14663eca2ab44d96cfe897bc8",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration/",
      "published_at": "2021-06-15T12:07:03Z",
      "updated_at": "2021-03-16T06:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Prometheus OpenMetrics integration, review the requirements for your environment: Docker requirements Kubernetes requirements Install the integration To install the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker installation To install the New Relic Prometheus OpenMetrics integration in a Docker environment: Create a configuration file config.yaml. Use the example configuration file, or look at the nri-prometheus-latest.yaml manifest file, which includes the nri-prometheus-cfg config map and an example configuration. Required: Add your New Relic license key and a cluster name to identify your Docker container. Add the endpoints to scrape; for example, add the http://localhost:8080/metrics endpoint to collect metrics about the integration itself. Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. For more information, see the metrics filtering documentation. Start the integration in the background: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:1.5 Copy Confirm the container is running properly: docker ps -f \"name=nri-prometheus\" Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Kubernetes installation Important To prevent your data from being duplicated, configure your New Relic Prometheus OpenMetrics integration only with one replica. Running two or more replicas will result in duplicated data. For more information, see the troubleshooting procedures for restarts and gaps in data. To install the New Relic Prometheus OpenMetrics integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml Copy Edit the nri-prometheus-latest.yaml manifest file: Required: Add your New Relic license key and a cluster name to identify your Kubernetes cluster. env: - name: LICENSE_KEY value: \"<YOUR_LICENSE_KEY>\" [...] config.yaml: | cluster_name: \"<YOUR_CLUSTER_NAME>\" Copy Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. By default, the New Relic Prometheus OpenMetrics integration uses the same labels as Prometheus to discover targets. For more information, see the metrics filtering documentation. Deploy the integration in your Kubernetes cluster: kubectl apply -f nri-prometheus-latest.yaml Copy To confirm that the deployment has been created successfully, look at the CURRENT replicas in the results generated by this command: kubectl get deployments nri-prometheus Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Update the integration To update the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker update procedures Remove the Docker container. Follow standard installation procedures to start a new Docker container. The integration logs its current version when it starts up. To determine the running version: docker logs nri-prometheus 2>&1 | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Kubernetes update procedures Follow standard installation procedures. Reapply the nri-prometheus-latest.yaml manifest file. The integration logs its version when it starts up. To determine the running version: kubectl logs deploy/nri-prometheus | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Uninstall To uninstall the Prometheus OpenMetrics integration for Docker or Kubernetes, execute the following command: Docker: docker rm -f nri-prometheus Copy Kubernetes: kubectl delete -f nri-prometheus-latest.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.09126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "sections": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": " information, see the troubleshooting procedures for restarts and gaps in data. To <em>install</em> the New Relic <em>Prometheus</em> <em>OpenMetrics</em> integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;<em>integrations</em>&#x2F;kubernetes&#x2F;nri"
      },
      "id": "603e8309e7b9d2d69d2a07cc"
    },
    {
      "sections": [
        "Add mutual TLS to Prometheus endpoints",
        "Add secret to config file"
      ],
      "title": "Add mutual TLS to Prometheus endpoints",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "707c96de26f106ddeaea4e18d5b71290170fea90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/add-mutual-tls-prometheus-endpoints/",
      "published_at": "2021-06-15T12:06:10Z",
      "updated_at": "2021-03-13T03:34:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure mutual TLS authentication when needed for the endpoints in your Prometheus OpenMetrics integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key, and cert files in a secret, and include them in the Prometheus OpenMetrics integration's container. Mutual TLS authentication is limited to a static list of URLs. To configure endpoints that require MTLS authentication, follow this example: targets: - description: \"Secure etcd example\" urls: [\"https://123.456.7.1:2379\", \"https://123.456.7.2:2379\"] tls_config: ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" cert_file_path: \"/etc/etcd/etcd-client.crt\" key_file_path: \"/etc/etcd/etcd-client.key\" transformations: ... Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.59848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "sections": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "You can <em>configure</em> mutual TLS authentication when needed for the endpoints in your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key"
      },
      "id": "6044e621196a67efb9960f37"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations": [
    {
      "sections": [
        "Install, update, or uninstall your Prometheus OpenMetrics integration",
        "Install the integration",
        "Docker installation",
        "Kubernetes installation",
        "Important",
        "Update the integration",
        "Docker update procedures",
        "Kubernetes update procedures",
        "Uninstall"
      ],
      "title": "Install, update, or uninstall your Prometheus OpenMetrics integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "89b53bf5ac9ce6c14663eca2ab44d96cfe897bc8",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration/",
      "published_at": "2021-06-15T12:07:03Z",
      "updated_at": "2021-03-16T06:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Prometheus OpenMetrics integration, review the requirements for your environment: Docker requirements Kubernetes requirements Install the integration To install the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker installation To install the New Relic Prometheus OpenMetrics integration in a Docker environment: Create a configuration file config.yaml. Use the example configuration file, or look at the nri-prometheus-latest.yaml manifest file, which includes the nri-prometheus-cfg config map and an example configuration. Required: Add your New Relic license key and a cluster name to identify your Docker container. Add the endpoints to scrape; for example, add the http://localhost:8080/metrics endpoint to collect metrics about the integration itself. Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. For more information, see the metrics filtering documentation. Start the integration in the background: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:1.5 Copy Confirm the container is running properly: docker ps -f \"name=nri-prometheus\" Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Kubernetes installation Important To prevent your data from being duplicated, configure your New Relic Prometheus OpenMetrics integration only with one replica. Running two or more replicas will result in duplicated data. For more information, see the troubleshooting procedures for restarts and gaps in data. To install the New Relic Prometheus OpenMetrics integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml Copy Edit the nri-prometheus-latest.yaml manifest file: Required: Add your New Relic license key and a cluster name to identify your Kubernetes cluster. env: - name: LICENSE_KEY value: \"<YOUR_LICENSE_KEY>\" [...] config.yaml: | cluster_name: \"<YOUR_CLUSTER_NAME>\" Copy Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. By default, the New Relic Prometheus OpenMetrics integration uses the same labels as Prometheus to discover targets. For more information, see the metrics filtering documentation. Deploy the integration in your Kubernetes cluster: kubectl apply -f nri-prometheus-latest.yaml Copy To confirm that the deployment has been created successfully, look at the CURRENT replicas in the results generated by this command: kubectl get deployments nri-prometheus Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Update the integration To update the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker update procedures Remove the Docker container. Follow standard installation procedures to start a new Docker container. The integration logs its current version when it starts up. To determine the running version: docker logs nri-prometheus 2>&1 | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Kubernetes update procedures Follow standard installation procedures. Reapply the nri-prometheus-latest.yaml manifest file. The integration logs its version when it starts up. To determine the running version: kubectl logs deploy/nri-prometheus | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Uninstall To uninstall the Prometheus OpenMetrics integration for Docker or Kubernetes, execute the following command: Docker: docker rm -f nri-prometheus Copy Kubernetes: kubectl delete -f nri-prometheus-latest.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.09126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "sections": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": " information, see the troubleshooting procedures for restarts and gaps in data. To <em>install</em> the New Relic <em>Prometheus</em> <em>OpenMetrics</em> integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;<em>integrations</em>&#x2F;kubernetes&#x2F;nri"
      },
      "id": "603e8309e7b9d2d69d2a07cc"
    },
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations in large Kubernetes environments",
        "Configure the integration for large environments"
      ],
      "title": "Configure Prometheus OpenMetrics integrations in large  Kubernetes environments",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "84e7d3b803e614a6362e0246a58b48e3209094ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments/",
      "published_at": "2021-06-15T10:12:30Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of metrics exposed by each target. For example, a Prometheus OpenMetrics integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30 seconds, consumes 2.5CPU and 700MB of RAM. Configure the integration for large environments To estimate the size of the environment you are monitoring, run the following query to see how many targets are being scraped: SELECT latest(nr_stats_targets) FROM Metric where clusterName=clusterName SINCE 30 MINUTES AGO TIMESERIES Copy In huge environments with hundreds of targets to be scraped, the latency on the /metrics endpoints must be below 1 second. Run this query to check the latency of the different targets. This query retrieves the data exposed by the Prometheus OpenMetrics integration, and shows the time required to fetch each endpoint. SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy In order to keep the time needed to scrape all the targets below 30 seconds, use the following configurations: Targets Configuration Targets < 400, with 1000 metrics each No modification is required. CPU ranges roughly between 0.1 and 1.5 cores, and the memory required should be no more than 256MB. 400 < targets < 1000, with 1000 metrics each The number of workers should be increased to 6-8. CPU ranges roughly between 1.5 and 3.5 cores, and the memory required is around 100MB. Targets > 1000, with 1000 metrics each The number of workers should be increased to 10 or more. CPU is over 3.5 cores, and the memory required is around 1GB or more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.07805,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large  Kubernetes environments",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large Kubernetes environments",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of <em>metrics</em> exposed by each target. For example, a <em>Prometheus</em> <em>OpenMetrics</em> integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30"
      },
      "id": "603e9b3b196a676cd0a83d81"
    },
    {
      "sections": [
        "Add mutual TLS to Prometheus endpoints",
        "Add secret to config file"
      ],
      "title": "Add mutual TLS to Prometheus endpoints",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "707c96de26f106ddeaea4e18d5b71290170fea90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/add-mutual-tls-prometheus-endpoints/",
      "published_at": "2021-06-15T12:06:10Z",
      "updated_at": "2021-03-13T03:34:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure mutual TLS authentication when needed for the endpoints in your Prometheus OpenMetrics integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key, and cert files in a secret, and include them in the Prometheus OpenMetrics integration's container. Mutual TLS authentication is limited to a static list of URLs. To configure endpoints that require MTLS authentication, follow this example: targets: - description: \"Secure etcd example\" urls: [\"https://123.456.7.1:2379\", \"https://123.456.7.2:2379\"] tls_config: ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" cert_file_path: \"/etc/etcd/etcd-client.crt\" key_file_path: \"/etc/etcd/etcd-client.key\" transformations: ... Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.59848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "sections": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "You can <em>configure</em> mutual TLS authentication when needed for the endpoints in your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key"
      },
      "id": "6044e621196a67efb9960f37"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-openmetrics/ignore-or-include-prometheus-metrics": [
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations",
        "Configure nri-prometheus-latest.yaml",
        "Example configuration file",
        "Key names and definitions",
        "Configure objects in target key",
        "Kubernetes port and endpoint path",
        "Example: Labels for Kubernetes port and path",
        "Services and Endpoints scrape behaviour",
        "Reload the configuration",
        "Docker: Run previous config file"
      ],
      "title": "Configure Prometheus OpenMetrics integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "12be9e8bb8c03ca3f0eed948d0bc6e863b60efef",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/",
      "published_at": "2021-06-15T12:07:04Z",
      "updated_at": "2021-05-11T06:21:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Unless otherwise noted, configuration options for your Prometheus OpenMetrics integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: Configure your New Relic license key as an environment variable named LICENSE_KEY. This provides a more secure environment, as New Relic can load your environment variable from a mutual TLS authentication secret. Configure nri-prometheus-latest.yaml The nri-prometheus-latest.yaml manifest file includes the nri-prometheus-cfg map showing an example configuration. Use the manifest file to configure the following parameters. Example configuration file The following is an example configuration file that you can save and modify to fit your needs. For more information, see the documentation about mutual TLS authentication and translating PromQL to NRQL. # The name of your cluster. It's important to match other New Relic products to relate the data. cluster_name: \"<YOUR_CLUSTER_NAME>\" # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true # standalone: true # How often the integration should run. Defaults to 30s. # scrape_duration: \"30s\" # The HTTP client timeout when fetching data from targets. Defaults to 5s. # scrape_timeout: \"5s\" # How old must the entries used for calculating the counters delta be # before the telemetry emitter expires them. Defaults to 5m. # telemetry_emitter_delta_expiration_age: \"5m\" # How often must the telemetry emitter check for expired delta entries. # Defaults to 5m. # telemetry_emitter_delta_expiration_check_interval: \"5m\" # Wether the integration should run in verbose mode or not. Defaults to false. verbose: false # Whether the integration should run in audit mode or not. Defaults to false. # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent. # It does not include verbose mode. This can lead to a high log volume, use with care. audit: false # Wether the integration should skip TLS verification or not. Defaults to false. insecure_skip_verify: false # The label used to identify scrapable targets. Defaults to \"prometheus.io/scrape\". scrape_enabled_label: \"prometheus.io/scrape\" # scrape_services Allows to enable scraping the service and not the endpoints behind. # When endpoints are scraped this is no longer needed scrape_services: true # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does. # Please notice that depending on the number of endpoints behind a service the load can increase considerably scrape_endpoints: false # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true. require_scrape_enabled_label_for_nodes: true # Number of worker threads used for scraping targets. # For large clusters with many (>400) targets, slowly increase until scrape # time falls between the desired `scrape_duration`. # Increasing this value too much will result in huge memory consumption if too # many metrics are being scraped. # Default: 4 # worker_threads: 4 # Maximum number of metrics to keep in memory until a report is triggered. # Changing this value is not recommended unless instructed by the New Relic support team. # max_stored_metrics: 10000 # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms. # Changing this value is not recommended unless instructed by the New Relic support team. # min_emitter_harvest_period: 200ms # targets: # - description: Secure etcd example # urls: [\"https://192.168.3.1:2379\", \"https://192.168.3.2:2379\", \"https://192.168.3.3:2379\"] # tls_config: # ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" # cert_file_path: \"/etc/etcd/etcd-client.crt\" # key_file_path: \"/etc/etcd/etcd-client.key\" # Proxy to be used by the emitters when submitting metrics. It should be # in the format [scheme]://[domain]:[port]. # The emitter is the component in charge of sending the scraped metrics. # This proxy won't be used when scraping metrics from the targets. # By default it's empty, meaning that no proxy will be used. # emitter_proxy: \"http://localhost:8888\" # Certificate to add to the root CA that the emitter will use when # verifying server certificates. # If left empty, TLS uses the host's root CA set. # emitter_ca_file: \"/path/to/cert/server.pem\" # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account # having limited privileges. Defaults to false. # disable_autodiscovery: false # Whether the emitter should skip TLS verification when submitting data. # Defaults to false. # emitter_insecure_skip_verify: false # Histogram support is based on New Relic's guidelines for higher # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md. # To better support visualization of this data, percentiles are calculated # based on the histogram metrics and sent to New Relic. # By default, the following percentiles are calculated: 50, 95 and 99. # # percentiles: # - 50 # - 95 # - 99 # transformations: # - description: \"General processing rules\" # rename_attributes: # - metric_prefix: \"\" # attributes: # container_name: \"containerName\" # pod_name: \"podName\" # namespace: \"namespaceName\" # node: \"nodeName\" # container: \"containerName\" # pod: \"podName\" # deployment: \"deploymentName\" # ignore_metrics: # # Ignore all the metrics except the ones listed below. # # This is a list that complements the data retrieved by the New # # Relic Kubernetes Integration, that's why Pods and containers are # # not included, because they are already collected by the # # Kubernetes Integration. # - except: # - kube_hpa_ # - kube_daemonset_ # - kube_statefulset_ # - kube_endpoint_ # - kube_service_ # - kube_limitrange # - kube_node_ # - kube_poddisruptionbudget_ # - kube_resourcequota # - nr_stats # copy_attributes: # # Copy all the labels from the timeseries with metric name # # `kube_hpa_labels` into every timeseries with a metric name that # # starts with `kube_hpa_` only if they share the same `namespace` # # and `hpa` labels. # - from_metric: \"kube_hpa_labels\" # to_metrics: \"kube_hpa_\" # match_by: # - namespace # - hpa # - from_metric: \"kube_daemonset_labels\" # to_metrics: \"kube_daemonset_\" # match_by: # - namespace # - daemonset # - from_metric: \"kube_statefulset_labels\" # to_metrics: \"kube_statefulset_\" # match_by: # - namespace # - statefulset # - from_metric: \"kube_endpoint_labels\" # to_metrics: \"kube_endpoint_\" # match_by: # - namespace # - endpoint # - from_metric: \"kube_service_labels\" # to_metrics: \"kube_service_\" # match_by: # - namespace # - service # - from_metric: \"kube_node_labels\" # to_metrics: \"kube_node_\" # match_by: # - namespace # - node # integration definition files required to map metrics to entities # definition_files_path: /etc/newrelic-infra/definition-files Copy Key names and definitions Here are some key names and definitions for your Prometheus OpenMetrics config file. Key name Description cluster_name Required. The name of the cluster. This value will be included as the clusterName attribute for all metrics. verbose Stringified boolean. true (default): Logs debugging information. false: Only logs error messages. targets Configuration of static endpoints to be scraped by the integration. It contains a list of objects. For more information about this structure, see the documentation about target configuration. scrape_enabled_label Kubernetes String. The integration will check if the Kubernetes pod and service are annotated or have a label with this value to decide if it has to be scraped. This is particularly useful when you want to limit the amount of data by ignoring metrics or including specific metrics that are sent to New Relic. Since by default we use the same label Prometheus uses to discover targets that can be scraped, most exporters that you install automatically set this label. To keep a fine-grained control on the targets you want the integration to scrape, you can set this option to some other value (such as newrelic/scrape) and then add the annotation or label newrelic/scrape: \"true\" to your Kubernetes objects. If both are set, annotations take precedence over labels. Default: \"prometheus.io/scrape\" scrape_duration How often should the scraper run. To lower memory usage, increase this value. To raise memory usage, decrease this value. The impact on memory usage is due to distributing target fetching over the scrape interval to avoid querying (and buffering) all the data at once. Default is 30s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. scrape_timeout The HTTP client timeout when fetching data from endpoints. Default: 5s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. worker_threads Number of worker threads used for scraping targets. Can be increased on environments with a high number of targets or targets with high latency, but might increase memory consumption. Default: 4. It is not recommended to use more than 10. require_scrape_enabled_label_for_nodes Kubernetes Whether or not Kubernetes nodes need labels to be scraped. Default: true. percentiles Histogram support is based on New Relic's guidelines for higher level metrics abstractions. To better support visualization of this data, percentiles are calculated based on the histogram metrics and sent to New Relic. Valid values include 50, 95, and 99. emitter_proxy Proxy used by the integration when submitting metrics: [scheme]://[domain]:[port] This proxy won't be used when fetching metrics from the targets. By default this is empty, and no proxy will be used. emitter_ca_file Certificate to add to the root CA that the emitter will use when verifying server certificates. If left empty, TLS uses the host's root CA set. emitter_insecure_skip_verify Whether the emitter should skip TLS verification when submitting data. Default: false. disable_autodiscovery Set to true in order to disable autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account having limited privileges. Default: false. Configure objects in target key If you want the target key in the configuration file to contain one or more objects, use the following structure in the YAML list: Key name Description description A description for the URLs in this target. urls A list of strings with the URLs to be scraped. tls_config Authentication configuration used to send requests. It supports TLS and Mutual TLS. For more information, see the documentation about mutual TLS authentication. Kubernetes port and endpoint path New Relic's Prometheus OpenMetrics integration automatically discovers which targets to scrape. To specify the port and endpoint path to be used when constructing the target, you can use the prometheus.io/port and prometheus.io/path annotations or label in your Kubernetes pods and services. Annotations take precedence over labels. If prometheus.io/port is not present, the integration will try to scrape each port or ContainerPort defined for the service. If prometheus.io/path is not present, the integration will default to /metrics. If a service is not running on the default /my-metrics-path path, add a label to the pod prometheus.io/path=my-metrics-path. If the path to the metrics endpoint is more complex and cannot be a valid label value (for example, foo/bar), use annotations instead. Example: Labels for Kubernetes port and path In this example, you have a deployment in your cluster, and the pods expose Prometheus metrics on port 8080 and in the path my-metrics. In the PodSpec metadata of the deployment manifest, set the labels prometheus.io/port: \"8080\" and prometheus.io/path: \"my-metrics\". When the integration tries to retrieve the metrics from your pods, it will send a request to http://<pod-ip>:8080/my-metrics. apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment spec: replicas: 2 selector: matchLabels: app: my-app template: metadata: labels: app: my-app prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"my-metrics\" Copy Services and Endpoints scrape behaviour By default, services are scraped directly instead of the underlying endpoints since scrape_services is set to true and scrape_endpoints to false. In order to change this behaviour set scrape_endpoints to true configuring Prometheus OpenMetrics integrations to scrape the underlying endpoints, as Prometheus server natively does, instead of directly the services. Please notice that depending on the number of endpoints behind the services in the cluster the load and the data injested can increase considerably, monitor and, if needed, increase resource requirements. Moreover, even if it is possible to set both scrape_services and scrape_endpoints to true to assure retrocompatibility, it would lead to duplicate data. Reload the configuration The Prometheus OpenMetrics integration does not automatically reload the configuration when you make changes to the configuration file. Docker: To reload the configuration, restart the container running the integration: docker restart nri-prometheus Copy Kubernetes: To reload the configuration, restart the integration. Recommendation: Scale the deployment down to zero replicas, and then scale it back to one replica: kubectl scale deployment nri-prometheus --replicas=0 kubectl scale deployment nri-prometheus --replicas=1 Copy Docker: Run previous config file Docker: To run the integration with the previous configuration file: Copy the content and save it to a config.yaml file. From within the same directory, run the command: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e CLUSTER_NAME=\"YOUR_CLUSTER_NAME\" \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:latest --configfile=/config.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.84924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "Unless otherwise noted, configuration options for your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: <em>Configure</em> your New Relic license key"
      },
      "id": "603e830964441f85a04e8877"
    },
    {
      "sections": [
        "Install, update, or uninstall your Prometheus OpenMetrics integration",
        "Install the integration",
        "Docker installation",
        "Kubernetes installation",
        "Important",
        "Update the integration",
        "Docker update procedures",
        "Kubernetes update procedures",
        "Uninstall"
      ],
      "title": "Install, update, or uninstall your Prometheus OpenMetrics integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "89b53bf5ac9ce6c14663eca2ab44d96cfe897bc8",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration/",
      "published_at": "2021-06-15T12:07:03Z",
      "updated_at": "2021-03-16T06:17:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before you install New Relic's Prometheus OpenMetrics integration, review the requirements for your environment: Docker requirements Kubernetes requirements Install the integration To install the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker installation To install the New Relic Prometheus OpenMetrics integration in a Docker environment: Create a configuration file config.yaml. Use the example configuration file, or look at the nri-prometheus-latest.yaml manifest file, which includes the nri-prometheus-cfg config map and an example configuration. Required: Add your New Relic license key and a cluster name to identify your Docker container. Add the endpoints to scrape; for example, add the http://localhost:8080/metrics endpoint to collect metrics about the integration itself. Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. For more information, see the metrics filtering documentation. Start the integration in the background: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:1.5 Copy Confirm the container is running properly: docker ps -f \"name=nri-prometheus\" Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Kubernetes installation Important To prevent your data from being duplicated, configure your New Relic Prometheus OpenMetrics integration only with one replica. Running two or more replicas will result in duplicated data. For more information, see the troubleshooting procedures for restarts and gaps in data. To install the New Relic Prometheus OpenMetrics integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml Copy Edit the nri-prometheus-latest.yaml manifest file: Required: Add your New Relic license key and a cluster name to identify your Kubernetes cluster. env: - name: LICENSE_KEY value: \"<YOUR_LICENSE_KEY>\" [...] config.yaml: | cluster_name: \"<YOUR_CLUSTER_NAME>\" Copy Specify which metrics you want to ignore or include according to the prefixes for the metrics and labels. By default, the New Relic Prometheus OpenMetrics integration uses the same labels as Prometheus to discover targets. For more information, see the metrics filtering documentation. Deploy the integration in your Kubernetes cluster: kubectl apply -f nri-prometheus-latest.yaml Copy To confirm that the deployment has been created successfully, look at the CURRENT replicas in the results generated by this command: kubectl get deployments nri-prometheus Copy Confirm that the integration has been configured correctly: Wait a few minutes, then go to the New Relic UI, and run this NRQL query to see if data has been reported: FROM Metric SELECT count(*) WHERE clusterName = 'YOUR_CLUSTER_NAME' since 1 hour ago Copy Update the integration To update the Prometheus OpenMetrics integration, follow the procedures for Docker or Kubernetes as applicable: Docker update procedures Remove the Docker container. Follow standard installation procedures to start a new Docker container. The integration logs its current version when it starts up. To determine the running version: docker logs nri-prometheus 2>&1 | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Kubernetes update procedures Follow standard installation procedures. Reapply the nri-prometheus-latest.yaml manifest file. The integration logs its version when it starts up. To determine the running version: kubectl logs deploy/nri-prometheus | grep \"Integration version\" Copy Example output: time=\"2019-02-26T09:21:21Z\" level=info msg=\"Starting New Relic's Prometheus OpenMetrics Integration version 1.0.0 \" Copy Uninstall To uninstall the Prometheus OpenMetrics integration for Docker or Kubernetes, execute the following command: Docker: docker rm -f nri-prometheus Copy Kubernetes: kubectl delete -f nri-prometheus-latest.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.09126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "sections": "<em>Install</em>, update, or uninstall your <em>Prometheus</em> <em>OpenMetrics</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": " information, see the troubleshooting procedures for restarts and gaps in data. To <em>install</em> the New Relic <em>Prometheus</em> <em>OpenMetrics</em> integration in a Kubernetes environment: Download the integration manifest .yaml file: curl -O https:&#x2F;&#x2F;download.newrelic.com&#x2F;infrastructure_agent&#x2F;<em>integrations</em>&#x2F;kubernetes&#x2F;nri"
      },
      "id": "603e8309e7b9d2d69d2a07cc"
    },
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations in large Kubernetes environments",
        "Configure the integration for large environments"
      ],
      "title": "Configure Prometheus OpenMetrics integrations in large  Kubernetes environments",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "84e7d3b803e614a6362e0246a58b48e3209094ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments/",
      "published_at": "2021-06-15T10:12:30Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of metrics exposed by each target. For example, a Prometheus OpenMetrics integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30 seconds, consumes 2.5CPU and 700MB of RAM. Configure the integration for large environments To estimate the size of the environment you are monitoring, run the following query to see how many targets are being scraped: SELECT latest(nr_stats_targets) FROM Metric where clusterName=clusterName SINCE 30 MINUTES AGO TIMESERIES Copy In huge environments with hundreds of targets to be scraped, the latency on the /metrics endpoints must be below 1 second. Run this query to check the latency of the different targets. This query retrieves the data exposed by the Prometheus OpenMetrics integration, and shows the time required to fetch each endpoint. SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy In order to keep the time needed to scrape all the targets below 30 seconds, use the following configurations: Targets Configuration Targets < 400, with 1000 metrics each No modification is required. CPU ranges roughly between 0.1 and 1.5 cores, and the memory required should be no more than 256MB. 400 < targets < 1000, with 1000 metrics each The number of workers should be increased to 6-8. CPU ranges roughly between 1.5 and 3.5 cores, and the memory required is around 100MB. Targets > 1000, with 1000 metrics each The number of workers should be increased to 10 or more. CPU is over 3.5 cores, and the memory required is around 1GB or more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.07803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large  Kubernetes environments",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large Kubernetes environments",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of <em>metrics</em> exposed by each target. For example, a <em>Prometheus</em> <em>OpenMetrics</em> integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30"
      },
      "id": "603e9b3b196a676cd0a83d81"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration": [
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations",
        "Configure nri-prometheus-latest.yaml",
        "Example configuration file",
        "Key names and definitions",
        "Configure objects in target key",
        "Kubernetes port and endpoint path",
        "Example: Labels for Kubernetes port and path",
        "Services and Endpoints scrape behaviour",
        "Reload the configuration",
        "Docker: Run previous config file"
      ],
      "title": "Configure Prometheus OpenMetrics integrations",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "12be9e8bb8c03ca3f0eed948d0bc6e863b60efef",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/",
      "published_at": "2021-06-15T12:07:04Z",
      "updated_at": "2021-05-11T06:21:13Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Unless otherwise noted, configuration options for your Prometheus OpenMetrics integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: Configure your New Relic license key as an environment variable named LICENSE_KEY. This provides a more secure environment, as New Relic can load your environment variable from a mutual TLS authentication secret. Configure nri-prometheus-latest.yaml The nri-prometheus-latest.yaml manifest file includes the nri-prometheus-cfg map showing an example configuration. Use the manifest file to configure the following parameters. Example configuration file The following is an example configuration file that you can save and modify to fit your needs. For more information, see the documentation about mutual TLS authentication and translating PromQL to NRQL. # The name of your cluster. It's important to match other New Relic products to relate the data. cluster_name: \"<YOUR_CLUSTER_NAME>\" # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true # standalone: true # How often the integration should run. Defaults to 30s. # scrape_duration: \"30s\" # The HTTP client timeout when fetching data from targets. Defaults to 5s. # scrape_timeout: \"5s\" # How old must the entries used for calculating the counters delta be # before the telemetry emitter expires them. Defaults to 5m. # telemetry_emitter_delta_expiration_age: \"5m\" # How often must the telemetry emitter check for expired delta entries. # Defaults to 5m. # telemetry_emitter_delta_expiration_check_interval: \"5m\" # Wether the integration should run in verbose mode or not. Defaults to false. verbose: false # Whether the integration should run in audit mode or not. Defaults to false. # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent. # It does not include verbose mode. This can lead to a high log volume, use with care. audit: false # Wether the integration should skip TLS verification or not. Defaults to false. insecure_skip_verify: false # The label used to identify scrapable targets. Defaults to \"prometheus.io/scrape\". scrape_enabled_label: \"prometheus.io/scrape\" # scrape_services Allows to enable scraping the service and not the endpoints behind. # When endpoints are scraped this is no longer needed scrape_services: true # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does. # Please notice that depending on the number of endpoints behind a service the load can increase considerably scrape_endpoints: false # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true. require_scrape_enabled_label_for_nodes: true # Number of worker threads used for scraping targets. # For large clusters with many (>400) targets, slowly increase until scrape # time falls between the desired `scrape_duration`. # Increasing this value too much will result in huge memory consumption if too # many metrics are being scraped. # Default: 4 # worker_threads: 4 # Maximum number of metrics to keep in memory until a report is triggered. # Changing this value is not recommended unless instructed by the New Relic support team. # max_stored_metrics: 10000 # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms. # Changing this value is not recommended unless instructed by the New Relic support team. # min_emitter_harvest_period: 200ms # targets: # - description: Secure etcd example # urls: [\"https://192.168.3.1:2379\", \"https://192.168.3.2:2379\", \"https://192.168.3.3:2379\"] # tls_config: # ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" # cert_file_path: \"/etc/etcd/etcd-client.crt\" # key_file_path: \"/etc/etcd/etcd-client.key\" # Proxy to be used by the emitters when submitting metrics. It should be # in the format [scheme]://[domain]:[port]. # The emitter is the component in charge of sending the scraped metrics. # This proxy won't be used when scraping metrics from the targets. # By default it's empty, meaning that no proxy will be used. # emitter_proxy: \"http://localhost:8888\" # Certificate to add to the root CA that the emitter will use when # verifying server certificates. # If left empty, TLS uses the host's root CA set. # emitter_ca_file: \"/path/to/cert/server.pem\" # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account # having limited privileges. Defaults to false. # disable_autodiscovery: false # Whether the emitter should skip TLS verification when submitting data. # Defaults to false. # emitter_insecure_skip_verify: false # Histogram support is based on New Relic's guidelines for higher # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md. # To better support visualization of this data, percentiles are calculated # based on the histogram metrics and sent to New Relic. # By default, the following percentiles are calculated: 50, 95 and 99. # # percentiles: # - 50 # - 95 # - 99 # transformations: # - description: \"General processing rules\" # rename_attributes: # - metric_prefix: \"\" # attributes: # container_name: \"containerName\" # pod_name: \"podName\" # namespace: \"namespaceName\" # node: \"nodeName\" # container: \"containerName\" # pod: \"podName\" # deployment: \"deploymentName\" # ignore_metrics: # # Ignore all the metrics except the ones listed below. # # This is a list that complements the data retrieved by the New # # Relic Kubernetes Integration, that's why Pods and containers are # # not included, because they are already collected by the # # Kubernetes Integration. # - except: # - kube_hpa_ # - kube_daemonset_ # - kube_statefulset_ # - kube_endpoint_ # - kube_service_ # - kube_limitrange # - kube_node_ # - kube_poddisruptionbudget_ # - kube_resourcequota # - nr_stats # copy_attributes: # # Copy all the labels from the timeseries with metric name # # `kube_hpa_labels` into every timeseries with a metric name that # # starts with `kube_hpa_` only if they share the same `namespace` # # and `hpa` labels. # - from_metric: \"kube_hpa_labels\" # to_metrics: \"kube_hpa_\" # match_by: # - namespace # - hpa # - from_metric: \"kube_daemonset_labels\" # to_metrics: \"kube_daemonset_\" # match_by: # - namespace # - daemonset # - from_metric: \"kube_statefulset_labels\" # to_metrics: \"kube_statefulset_\" # match_by: # - namespace # - statefulset # - from_metric: \"kube_endpoint_labels\" # to_metrics: \"kube_endpoint_\" # match_by: # - namespace # - endpoint # - from_metric: \"kube_service_labels\" # to_metrics: \"kube_service_\" # match_by: # - namespace # - service # - from_metric: \"kube_node_labels\" # to_metrics: \"kube_node_\" # match_by: # - namespace # - node # integration definition files required to map metrics to entities # definition_files_path: /etc/newrelic-infra/definition-files Copy Key names and definitions Here are some key names and definitions for your Prometheus OpenMetrics config file. Key name Description cluster_name Required. The name of the cluster. This value will be included as the clusterName attribute for all metrics. verbose Stringified boolean. true (default): Logs debugging information. false: Only logs error messages. targets Configuration of static endpoints to be scraped by the integration. It contains a list of objects. For more information about this structure, see the documentation about target configuration. scrape_enabled_label Kubernetes String. The integration will check if the Kubernetes pod and service are annotated or have a label with this value to decide if it has to be scraped. This is particularly useful when you want to limit the amount of data by ignoring metrics or including specific metrics that are sent to New Relic. Since by default we use the same label Prometheus uses to discover targets that can be scraped, most exporters that you install automatically set this label. To keep a fine-grained control on the targets you want the integration to scrape, you can set this option to some other value (such as newrelic/scrape) and then add the annotation or label newrelic/scrape: \"true\" to your Kubernetes objects. If both are set, annotations take precedence over labels. Default: \"prometheus.io/scrape\" scrape_duration How often should the scraper run. To lower memory usage, increase this value. To raise memory usage, decrease this value. The impact on memory usage is due to distributing target fetching over the scrape interval to avoid querying (and buffering) all the data at once. Default is 30s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. scrape_timeout The HTTP client timeout when fetching data from endpoints. Default: 5s. Valid values include 1s, 15s, 30s, 1m, 5m, etc. worker_threads Number of worker threads used for scraping targets. Can be increased on environments with a high number of targets or targets with high latency, but might increase memory consumption. Default: 4. It is not recommended to use more than 10. require_scrape_enabled_label_for_nodes Kubernetes Whether or not Kubernetes nodes need labels to be scraped. Default: true. percentiles Histogram support is based on New Relic's guidelines for higher level metrics abstractions. To better support visualization of this data, percentiles are calculated based on the histogram metrics and sent to New Relic. Valid values include 50, 95, and 99. emitter_proxy Proxy used by the integration when submitting metrics: [scheme]://[domain]:[port] This proxy won't be used when fetching metrics from the targets. By default this is empty, and no proxy will be used. emitter_ca_file Certificate to add to the root CA that the emitter will use when verifying server certificates. If left empty, TLS uses the host's root CA set. emitter_insecure_skip_verify Whether the emitter should skip TLS verification when submitting data. Default: false. disable_autodiscovery Set to true in order to disable autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account having limited privileges. Default: false. Configure objects in target key If you want the target key in the configuration file to contain one or more objects, use the following structure in the YAML list: Key name Description description A description for the URLs in this target. urls A list of strings with the URLs to be scraped. tls_config Authentication configuration used to send requests. It supports TLS and Mutual TLS. For more information, see the documentation about mutual TLS authentication. Kubernetes port and endpoint path New Relic's Prometheus OpenMetrics integration automatically discovers which targets to scrape. To specify the port and endpoint path to be used when constructing the target, you can use the prometheus.io/port and prometheus.io/path annotations or label in your Kubernetes pods and services. Annotations take precedence over labels. If prometheus.io/port is not present, the integration will try to scrape each port or ContainerPort defined for the service. If prometheus.io/path is not present, the integration will default to /metrics. If a service is not running on the default /my-metrics-path path, add a label to the pod prometheus.io/path=my-metrics-path. If the path to the metrics endpoint is more complex and cannot be a valid label value (for example, foo/bar), use annotations instead. Example: Labels for Kubernetes port and path In this example, you have a deployment in your cluster, and the pods expose Prometheus metrics on port 8080 and in the path my-metrics. In the PodSpec metadata of the deployment manifest, set the labels prometheus.io/port: \"8080\" and prometheus.io/path: \"my-metrics\". When the integration tries to retrieve the metrics from your pods, it will send a request to http://<pod-ip>:8080/my-metrics. apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment spec: replicas: 2 selector: matchLabels: app: my-app template: metadata: labels: app: my-app prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"my-metrics\" Copy Services and Endpoints scrape behaviour By default, services are scraped directly instead of the underlying endpoints since scrape_services is set to true and scrape_endpoints to false. In order to change this behaviour set scrape_endpoints to true configuring Prometheus OpenMetrics integrations to scrape the underlying endpoints, as Prometheus server natively does, instead of directly the services. Please notice that depending on the number of endpoints behind the services in the cluster the load and the data injested can increase considerably, monitor and, if needed, increase resource requirements. Moreover, even if it is possible to set both scrape_services and scrape_endpoints to true to assure retrocompatibility, it would lead to duplicate data. Reload the configuration The Prometheus OpenMetrics integration does not automatically reload the configuration when you make changes to the configuration file. Docker: To reload the configuration, restart the container running the integration: docker restart nri-prometheus Copy Kubernetes: To reload the configuration, restart the integration. Recommendation: Scale the deployment down to zero replicas, and then scale it back to one replica: kubectl scale deployment nri-prometheus --replicas=0 kubectl scale deployment nri-prometheus --replicas=1 Copy Docker: Run previous config file Docker: To run the integration with the previous configuration file: Copy the content and save it to a config.yaml file. From within the same directory, run the command: docker run -d --restart unless-stopped \\ --name nri-prometheus \\ -e CLUSTER_NAME=\"YOUR_CLUSTER_NAME\" \\ -e LICENSE_KEY=\"YOUR_LICENSE_KEY\" \\ -v \"$(pwd)/config.yaml:/config.yaml\" \\ newrelic/nri-prometheus:latest --configfile=/config.yaml Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.84924,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "Unless otherwise noted, configuration options for your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic apply to both Docker and Kubernetes environments. At a minimum, the following configuration values are required: License key Cluster name Recommendation: <em>Configure</em> your New Relic license key"
      },
      "id": "603e830964441f85a04e8877"
    },
    {
      "sections": [
        "Configure Prometheus OpenMetrics integrations in large Kubernetes environments",
        "Configure the integration for large environments"
      ],
      "title": "Configure Prometheus OpenMetrics integrations in large  Kubernetes environments",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "84e7d3b803e614a6362e0246a58b48e3209094ad",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations-large-kubernetes-environments/",
      "published_at": "2021-06-15T10:12:30Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of metrics exposed by each target. For example, a Prometheus OpenMetrics integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30 seconds, consumes 2.5CPU and 700MB of RAM. Configure the integration for large environments To estimate the size of the environment you are monitoring, run the following query to see how many targets are being scraped: SELECT latest(nr_stats_targets) FROM Metric where clusterName=clusterName SINCE 30 MINUTES AGO TIMESERIES Copy In huge environments with hundreds of targets to be scraped, the latency on the /metrics endpoints must be below 1 second. Run this query to check the latency of the different targets. This query retrieves the data exposed by the Prometheus OpenMetrics integration, and shows the time required to fetch each endpoint. SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy In order to keep the time needed to scrape all the targets below 30 seconds, use the following configurations: Targets Configuration Targets < 400, with 1000 metrics each No modification is required. CPU ranges roughly between 0.1 and 1.5 cores, and the memory required should be no more than 256MB. 400 < targets < 1000, with 1000 metrics each The number of workers should be increased to 6-8. CPU ranges roughly between 1.5 and 3.5 cores, and the memory required is around 100MB. Targets > 1000, with 1000 metrics each The number of workers should be increased to 10 or more. CPU is over 3.5 cores, and the memory required is around 1GB or more.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.07803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large  Kubernetes environments",
        "sections": "<em>Configure</em> <em>Prometheus</em> <em>OpenMetrics</em> <em>integrations</em> in large Kubernetes environments",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "CPU and memory limits and requests can vary according to the number of targets monitored, and the number of <em>metrics</em> exposed by each target. For example, a <em>Prometheus</em> <em>OpenMetrics</em> integration which scrapes 800 targets, exposing 1000 timeseries each, with a latency of 150ms and a scrape_duration of 30"
      },
      "id": "603e9b3b196a676cd0a83d81"
    },
    {
      "sections": [
        "Add mutual TLS to Prometheus endpoints",
        "Add secret to config file"
      ],
      "title": "Add mutual TLS to Prometheus endpoints",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure OpenMetrics"
      ],
      "external_id": "707c96de26f106ddeaea4e18d5b71290170fea90",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-openmetrics/add-mutual-tls-prometheus-endpoints/",
      "published_at": "2021-06-15T12:06:10Z",
      "updated_at": "2021-03-13T03:34:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can configure mutual TLS authentication when needed for the endpoints in your Prometheus OpenMetrics integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key, and cert files in a secret, and include them in the Prometheus OpenMetrics integration's container. Mutual TLS authentication is limited to a static list of URLs. To configure endpoints that require MTLS authentication, follow this example: targets: - description: \"Secure etcd example\" urls: [\"https://123.456.7.1:2379\", \"https://123.456.7.2:2379\"] tls_config: ca_file_path: \"/etc/etcd/etcd-client-ca.crt\" cert_file_path: \"/etc/etcd/etcd-client.crt\" key_file_path: \"/etc/etcd/etcd-client.key\" transformations: ... Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.59848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "sections": "Add mutual TLS to <em>Prometheus</em> endpoints",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>OpenMetrics</em>",
        "body": "You can <em>configure</em> mutual TLS authentication when needed for the endpoints in your <em>Prometheus</em> <em>OpenMetrics</em> integration with New Relic. Add tls_config to your configuration file for Docker or Kubernetes, as explained in this example. Add secret to config file Recommendation: Put the CA bundle, key"
      },
      "id": "6044e621196a67efb9960f37"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-remote-write/remote-write-errors-error-messages": [
    {
      "sections": [
        "Set up your Prometheus remote write integration",
        "Tip",
        "Set up the integration",
        "Mapping of Prometheus metric types",
        "Override metric type mappings",
        "Customize remote write behavior",
        "X-License Key",
        "prometheus_server URL parameter",
        "Optimize throughput and memory consumption",
        "Troubleshoot error messages",
        "Remove the integration"
      ],
      "title": "Set up your Prometheus remote write integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "e2a503880e8e1c38284434d5829fad3f48dc7abf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration/",
      "published_at": "2021-06-15T12:08:02Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can get Prometheus data flowing in New Relic with just a few simple steps. This page covers basic setup for the remote write integration, as well as a few common troubleshooting topics. For information on integrating Prometheus servers in a high availability (HA) configuration, see our Prometheus high availability documentation. Tip To use Prometheus integrations and infrastructure monitoring, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Set up the integration Go to the Prometheus remote write setup launcher in New Relic One, then complete these steps. Add Prometheus data Enter a name for the Prometheus server to be connected and your remote_write URL. Important: The name you enter for the server will create an attribute on your data. It will also be the name that identifies which Prometheus server is sending data to New Relic. Add a new remote_write URL to your Prometheus YML file. Add this information under global_config in the file, at the same indentation level as the global section. Use the following syntax: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=YOUR_DATA_SOURCE_NAME bearer_token:YOUR_LICENSE_KEY Copy OR remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=YOUR_LICENSE_KEY&prometheus_server=YOUR_DATA_SOURCE_NAME Copy European Union accounts: If you're connecting from the EU, use the following URL: https://metric-api.eu.newrelic.com/prometheus/v1/write Copy Kubernetes and Helm remote write integrations: Add the remote write URL to your Helm values.yaml file. Replace remoteWrite: [] with two lines similar to the following example. Be sure to use your remote write URL and use indentation that matches the rest of the file: remoteWrite: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=YOUR_DATA_SOURCE_NAME bearer_token:YOUR_LICENSE_KEY Copy Restart your Prometheus server. View your data in the New Relic UI. For example, use the remote write dashboard we automatically create when you set up your integration. Mapping of Prometheus metric types The Prometheus remote write protocol does not include metric type information or other helpful metric metadata when sending metrics to New Relic. Because the remote write protocol doesn't include this information, New Relic infers the metric type based on Prometheus naming conventions. Metrics not following these naming conventions may not be mapped correctly. New Relic maps Prometheus metrics types into New Relic metric types based on Prometheus metric naming conventions as follows: metricName_bucket is stored as a New Relic count metric type. metricName_count is stored as a New Relic count metric type. metricName_total is stored as a New Relic count metric type. metricName_sum is stored as a New Relic summary metric type. Everything else is stored as a New Relic gauge metric type. Override metric type mappings If you have metrics that don't follow Prometheus naming conventions, you can configure remote-write to tag the metric with a newrelic_metric_type label that indicates the metric type. This label is stripped when received by New Relic. Example: You have a counter metric named my_counter, which does not have our naming convention suffix of _bucket, _count or _total. In this situation, your metric would be identified as a gauge rather than a counter. To correct this, add the following relabel configuration to your prometheus.yml: - url: https://metric-api.newrelic.com/prometheus/v1/write?X-License-Key=... write_relabel_configs: - source_labels: [__name__] regex: ^my_counter$ target_label: newrelic_metric_type replacement: \"counter\" action: replace Copy This rule matches any metric with the name my_counter and adds a newrelic_metric_type label that identifies it as a counter. You can use the following (case sensitive) values as the replacement value: counter gauge summary When a newrelic_metric_type label is present on a metric received and set to one of the valid values, New Relic will assign the indicated type to the metric (and strip the label) before downstream consumption in the data pipeline. If you have multiple metrics that don't follow the above naming conventions, you can add multiple rules with each rule matching different source labels. Customize remote write behavior You can customize the following parameters if you are writing to more than one account in New Relic or are connecting more than one Prometheus data source to the same account in New Relic. For more information, see the docs on remote write tuning. X-License Key Your account's license key is not an API key. The license key is used for authentication and to identify which account to write data into. If you are configuring Prometheus to write into different New Relic accounts or sub-accounts, use a different key on each remote write URL. prometheus_server URL parameter The prometheus_server parameter is a label or attribute used to add to stats that are written to NRDB. Use this same label when configuring your Grafana data source to limit results to just those from a particular prometheus_server. Optimize throughput and memory consumption Remote write increases the total memory consumption of your Prometheus servers. If you're experiencing issues we recommend the following: Increase max_samples_per_send for higher throughput workloads, along a proportional increase in capacity. If memory consumption is still a problem, try limiting the number of max_shards per server. Troubleshoot error messages If you receive an integration error message from New Relic or error messages in your Prometheus server logs after restarting your Prometheus server, review our remote write troubleshooting documentation. This includes fixing common errors, such as missing or incorrect characters, bad requests, request entity too large, and rate limit errors. Remove the integration When you remove the Prometheus remote write integration, this stops new data from flowing, but it will not purge or remove any historical data. To remove the integration, remove the configuration code snippet from your Prometheus YML file, then restart the server.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.05444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set up your <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "sections": "Set up your <em>Prometheus</em> <em>remote</em> <em>write</em> <em>integration</em>",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " Union accounts: If you&#x27;re connecting from the EU, use the following URL: https:&#x2F;&#x2F;metric-api.eu.newrelic.com&#x2F;<em>prometheus</em>&#x2F;v1&#x2F;<em>write</em> Copy Kubernetes and Helm <em>remote</em> <em>write</em> <em>integrations</em>: Add the <em>remote</em> <em>write</em> URL to your Helm values.yaml file. Replace <em>remoteWrite</em>: [] with two lines similar to the following"
      },
      "id": "603e94de196a674e6ca83def"
    },
    {
      "sections": [
        "Prometheus High Availability (HA)",
        "Tip",
        "External labels",
        "Prometheus Operator",
        "Standalone Prometheus"
      ],
      "title": "Prometheus High Availability (HA)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "3c0fddd6e878f30f8ba4c132f537b88cd47f2eba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/prometheus-high-availability-ha/",
      "published_at": "2021-06-15T12:06:10Z",
      "updated_at": "2021-03-13T02:41:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are using our Prometheus remote write integration in a high-availability (HA) configuration, you need to make sure your Prometheus servers aren't sending multiple copies of the same metrics to New Relic. This document describes how you can configure your remote write integration so that New Relic does not keep duplicated metrics. Tip For information on standard Prometheus remote write integration without using a high-availability configuration, see Set up your Prometheus remote write integration. External labels New Relic requires two external labels to deduplicate data from replicas in a high-availability configuration: Label name Description Example value prometheus A label whose value identifies the name of a high-availability cluster or group of Prometheus servers. monitoring-cluster prometheus_replica A label whose value identifies the unique replica sending this data. replica-1 The remaining sections explain how labels work with Prometheus Operator and standalone Prometheus. Prometheus Operator These external labels are added by default if you use Prometheus Operator version 0.19.0 (or higher). This applies whether you use Prometheus Operator directly or via the helm chart. The operator sets the value of the prometheus label (the one identifying a cluster) as <prometheus deployment namespace>/<prometheus deployment name>. For example, if your namespace for the Prometheus deployment is monitoring and the name of the deployment is prometheus-cluster1, the value is monitoring/prometheus-cluster1. The operator sets the value of the prometheus_replica label as the name of the pod for each replica. This follows the format replica-<replica number>, where the number is the ordinal of that replica (for example, the first replica is named replica-1). Tip If you still see duplicate copies of replica data, make sure you do not have replicaExternalLabelName or prometheusExternalLabelName in your Prometheus spec or chart configuration because these overrides change the label name. Standalone Prometheus When deploying a Prometheus server directly, you need to add the external labels to the configuration file. Here are two different example configurations for replicas within the same high-availability cluster: Replica 1 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-1 Copy Replica 2 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-2 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.48355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Prometheus</em> High Availability (HA)",
        "sections": "<em>Prometheus</em> High Availability (HA)",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": "If you are using our <em>Prometheus</em> <em>remote</em> <em>write</em> integration in a high-availability (HA) configuration, you need to make sure your <em>Prometheus</em> servers aren&#x27;t sending multiple copies of the same metrics to New Relic. This document describes how you can <em>configure</em> your <em>remote</em> <em>write</em> integration so that New"
      },
      "id": "6044e621196a67b846960f6b"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.81399,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration": [
    {
      "sections": [
        "Remote write errors and error messages",
        "Common errors and issues",
        "Configuration errors",
        "400: bad request error",
        "413: request entity too large error",
        "429: rate limit error",
        "Investigate error messages"
      ],
      "title": "Remote write errors and error messages",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "0d190be5dc4fd91ce6bbcef7343d01f75670ca51",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/remote-write-errors-error-messages/",
      "published_at": "2021-06-15T12:08:02Z",
      "updated_at": "2021-03-13T03:46:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This resource contains information about common errors and error messages that may alert you to issues with data visibility and availability, as well as information about how to respond. Common errors and issues If you receive an integration error message from New Relic or error messages in your Prometheus server logs after restarting your Prometheus server, there are several actions you can take to troubleshoot and get data flowing properly. Below are a few tips regarding common issues and error messages. For specific information on how to query for NrIntegrationError events, see Investigate error messages below. Configuration errors Missing or incorrect characters in the remote write URL in the config file (for example the endpoint, license key, or prometheus_server name) or incorrect placement of the information in the file will result in the Prometheus server not starting, remote write not working properly, or errors appearing in Prometheus server logs. 400: bad request error If no data appears with a bad request error, check your configuration file to confirm that the placement of the remote write information is correct, and that there are no missing or incorrect characters. 413: request entity too large error This means you have sent a request in which one or more fields, or the entire payload, has exceeded our limits. 429: rate limit error This means you have hit a rate limit on the amount of data being sent at one time (for example cardinality or data points per minute). You can troubleshoot by reducing the amount of Prometheus or general metric data you are sending, or by requesting a rate-limit increase. Investigate error messages You can investigate error messages in New Relic by doing either or both of the following. Run a NrIntegrationError query on the error message using NRQL, then look at the Message field in the UI to see a description of what went wrong. For example: SELECT * FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' Copy Investigate individual errors in time to see when and where they occur and any simultaneously occurring issues, and perform targeted troubleshooting based on what you find out. For example: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' TIMESERIES Copy If youve validated that you can send data successfully but are unable to query it, you may be running into other kinds of limits, like the inspected count limit. This may manifest itself as an error message during the integration process that says: Unable to retrieve data for Prometheus data source <name>.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.49144,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Remote</em> <em>write</em> errors <em>and</em> error messages",
        "sections": "<em>Remote</em> <em>write</em> errors <em>and</em> error messages",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": " error messages below. Configuration errors Missing or incorrect characters in the <em>remote</em> <em>write</em> URL in the config file (for example the endpoint, license key, or <em>prometheus</em>_server name) or incorrect placement of the information in the file will result in the <em>Prometheus</em> server not starting, <em>remote</em>"
      },
      "id": "6044e65d196a67914a960f6b"
    },
    {
      "sections": [
        "Prometheus High Availability (HA)",
        "Tip",
        "External labels",
        "Prometheus Operator",
        "Standalone Prometheus"
      ],
      "title": "Prometheus High Availability (HA)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "3c0fddd6e878f30f8ba4c132f537b88cd47f2eba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/prometheus-high-availability-ha/",
      "published_at": "2021-06-15T12:06:10Z",
      "updated_at": "2021-03-13T02:41:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you are using our Prometheus remote write integration in a high-availability (HA) configuration, you need to make sure your Prometheus servers aren't sending multiple copies of the same metrics to New Relic. This document describes how you can configure your remote write integration so that New Relic does not keep duplicated metrics. Tip For information on standard Prometheus remote write integration without using a high-availability configuration, see Set up your Prometheus remote write integration. External labels New Relic requires two external labels to deduplicate data from replicas in a high-availability configuration: Label name Description Example value prometheus A label whose value identifies the name of a high-availability cluster or group of Prometheus servers. monitoring-cluster prometheus_replica A label whose value identifies the unique replica sending this data. replica-1 The remaining sections explain how labels work with Prometheus Operator and standalone Prometheus. Prometheus Operator These external labels are added by default if you use Prometheus Operator version 0.19.0 (or higher). This applies whether you use Prometheus Operator directly or via the helm chart. The operator sets the value of the prometheus label (the one identifying a cluster) as <prometheus deployment namespace>/<prometheus deployment name>. For example, if your namespace for the Prometheus deployment is monitoring and the name of the deployment is prometheus-cluster1, the value is monitoring/prometheus-cluster1. The operator sets the value of the prometheus_replica label as the name of the pod for each replica. This follows the format replica-<replica number>, where the number is the ordinal of that replica (for example, the first replica is named replica-1). Tip If you still see duplicate copies of replica data, make sure you do not have replicaExternalLabelName or prometheusExternalLabelName in your Prometheus spec or chart configuration because these overrides change the label name. Standalone Prometheus When deploying a Prometheus server directly, you need to add the external labels to the configuration file. Here are two different example configurations for replicas within the same high-availability cluster: Replica 1 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-1 Copy Replica 2 (prometheus.yml) global: external_labels: prometheus: monitoring-cluster prometheus_replica: replica-2 Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.48355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Prometheus</em> High Availability (HA)",
        "sections": "<em>Prometheus</em> High Availability (HA)",
        "tags": "<em>Install</em> <em>and</em> <em>configure</em> <em>remote</em> <em>write</em>",
        "body": "If you are using our <em>Prometheus</em> <em>remote</em> <em>write</em> integration in a high-availability (HA) configuration, you need to make sure your <em>Prometheus</em> servers aren&#x27;t sending multiple copies of the same metrics to New Relic. This document describes how you can <em>configure</em> your <em>remote</em> <em>write</em> integration so that New"
      },
      "id": "6044e621196a67b846960f6b"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.81399,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/debug-issues-data-sent-metric-api-prometheus-integration": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.538826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    },
    {
      "sections": [
        "Sparse data, missing metrics, and data gaps",
        "Problem",
        "Solution"
      ],
      "title": "Sparse data, missing metrics, and data gaps",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "0389b736613331d774daf3c3643ca8362fd4babb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/sparse-data-missing-metrics-data-gaps/",
      "published_at": "2021-06-15T13:28:43Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but you notice sparse data, missing metrics, and data gaps in New Relic's UI. Solution If some metrics are not being collected regularly, do the following: Check if the CPU is being throttled, and if the memory allocated to the container is enough. In case the container doesn't have enough resources available, it may send data with a longer interval between samples. Low memory limit may cause the integration to be killed and restarted. The correct limits and requests of resources can vary according to the number of targets monitored, and the number of metrics exposed by each target.For more information, see the guidelines in the large environment configuration documentation. Check for the following error message in the logs of the integration: {\"err\":\"unexpected post response code: 413: Request Entity Too Large\"} Copy This issue causes some payloads to be dropped, and it is currently fixed in new releases. If present, update the image to the most recent version. If some /metrics endpoints that are monitored by the integration time out or take several seconds to answer, they may slow down the scraping of data. The integration's performance can degrade if multiple endpoints take a huge amount of time to answer. This leads to intermittent and missing data. To detect those endpoints, run: SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy This query retrieves the data exposed by the Prometheus OpenMetrics integration, and it shows the time required to fetch each endpoint. Fix the endpoints with a latency above 1s, or exclude them from the monitoring removing the Prometheus scraping label. If it's not feasible to remove these endpoints, and the latency in the answer can't be avoided, configure the integration to run more workers in parallel. This allows the integration to fetch more endpoints at the same time. To do so, update the integration to the most recent version, and apply the new configuration option worker_threads. We advise to do it gradually, from 4, 6, 8 and up to 16. This workaround only minimizes the issue, and if multiple endpoints are misbehaving, performances will still be degraded. Moreover, memory and CPU consumption will increase with the number of workers, so memory and CPU must be increased accordingly. In case all the endpoints monitored have a low latency, and the container is not being throttled, run the following query. This helps you verify how much time the integration is taking to scrape all the targets, and to send the data if it's exceeding the configured scrape_duration. SELECT latest(nr_stats_integration_process_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO TIMESERIES Copy First, update the integration to the latest image published. Then, to reduce the time needed to scrape all the targets, increase the number of workers with the configuration option worker_threads. We advise is to do it gradually, from 4 to 6, 8, and up to 16 until r_stats_integration_process_duration_seconds approaches the defined scrape_duration. Note that memory consumption and CPU usage will increase.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but you notice sparse data, missing metrics, and data gaps in New Relic&#x27;s UI. Solution If some metrics are not being collected regularly, do the following: Check if the CPU is being throttled"
      },
      "id": "603e9b8228ccbc95f4eba75b"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/get-logs-prometheus-integration": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.538826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/get-scraper-metrics-prometheus-integration": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.538826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration": [
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.538826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    },
    {
      "sections": [
        "Sparse data, missing metrics, and data gaps",
        "Problem",
        "Solution"
      ],
      "title": "Sparse data, missing metrics, and data gaps",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "0389b736613331d774daf3c3643ca8362fd4babb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/sparse-data-missing-metrics-data-gaps/",
      "published_at": "2021-06-15T13:28:43Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but you notice sparse data, missing metrics, and data gaps in New Relic's UI. Solution If some metrics are not being collected regularly, do the following: Check if the CPU is being throttled, and if the memory allocated to the container is enough. In case the container doesn't have enough resources available, it may send data with a longer interval between samples. Low memory limit may cause the integration to be killed and restarted. The correct limits and requests of resources can vary according to the number of targets monitored, and the number of metrics exposed by each target.For more information, see the guidelines in the large environment configuration documentation. Check for the following error message in the logs of the integration: {\"err\":\"unexpected post response code: 413: Request Entity Too Large\"} Copy This issue causes some payloads to be dropped, and it is currently fixed in new releases. If present, update the image to the most recent version. If some /metrics endpoints that are monitored by the integration time out or take several seconds to answer, they may slow down the scraping of data. The integration's performance can degrade if multiple endpoints take a huge amount of time to answer. This leads to intermittent and missing data. To detect those endpoints, run: SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy This query retrieves the data exposed by the Prometheus OpenMetrics integration, and it shows the time required to fetch each endpoint. Fix the endpoints with a latency above 1s, or exclude them from the monitoring removing the Prometheus scraping label. If it's not feasible to remove these endpoints, and the latency in the answer can't be avoided, configure the integration to run more workers in parallel. This allows the integration to fetch more endpoints at the same time. To do so, update the integration to the most recent version, and apply the new configuration option worker_threads. We advise to do it gradually, from 4, 6, 8 and up to 16. This workaround only minimizes the issue, and if multiple endpoints are misbehaving, performances will still be degraded. Moreover, memory and CPU consumption will increase with the number of workers, so memory and CPU must be increased accordingly. In case all the endpoints monitored have a low latency, and the container is not being throttled, run the following query. This helps you verify how much time the integration is taking to scrape all the targets, and to send the data if it's exceeding the configured scrape_duration. SELECT latest(nr_stats_integration_process_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO TIMESERIES Copy First, update the integration to the latest image published. Then, to reduce the time needed to scrape all the targets, increase the number of workers with the configuration option worker_threads. We advise is to do it gradually, from 4 to 6, 8, and up to 16 until r_stats_integration_process_duration_seconds approaches the defined scrape_duration. Note that memory consumption and CPU usage will increase.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but you notice sparse data, missing metrics, and data gaps in New Relic&#x27;s UI. Solution If some metrics are not being collected regularly, do the following: Check if the CPU is being throttled"
      },
      "id": "603e9b8228ccbc95f4eba75b"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Sparse data, missing metrics, and data gaps",
        "Problem",
        "Solution"
      ],
      "title": "Sparse data, missing metrics, and data gaps",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "0389b736613331d774daf3c3643ca8362fd4babb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/sparse-data-missing-metrics-data-gaps/",
      "published_at": "2021-06-15T13:28:43Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but you notice sparse data, missing metrics, and data gaps in New Relic's UI. Solution If some metrics are not being collected regularly, do the following: Check if the CPU is being throttled, and if the memory allocated to the container is enough. In case the container doesn't have enough resources available, it may send data with a longer interval between samples. Low memory limit may cause the integration to be killed and restarted. The correct limits and requests of resources can vary according to the number of targets monitored, and the number of metrics exposed by each target.For more information, see the guidelines in the large environment configuration documentation. Check for the following error message in the logs of the integration: {\"err\":\"unexpected post response code: 413: Request Entity Too Large\"} Copy This issue causes some payloads to be dropped, and it is currently fixed in new releases. If present, update the image to the most recent version. If some /metrics endpoints that are monitored by the integration time out or take several seconds to answer, they may slow down the scraping of data. The integration's performance can degrade if multiple endpoints take a huge amount of time to answer. This leads to intermittent and missing data. To detect those endpoints, run: SELECT average(nr_stats_integration_fetch_target_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30 Copy This query retrieves the data exposed by the Prometheus OpenMetrics integration, and it shows the time required to fetch each endpoint. Fix the endpoints with a latency above 1s, or exclude them from the monitoring removing the Prometheus scraping label. If it's not feasible to remove these endpoints, and the latency in the answer can't be avoided, configure the integration to run more workers in parallel. This allows the integration to fetch more endpoints at the same time. To do so, update the integration to the most recent version, and apply the new configuration option worker_threads. We advise to do it gradually, from 4, 6, 8 and up to 16. This workaround only minimizes the issue, and if multiple endpoints are misbehaving, performances will still be degraded. Moreover, memory and CPU consumption will increase with the number of workers, so memory and CPU must be increased accordingly. In case all the endpoints monitored have a low latency, and the container is not being throttled, run the following query. This helps you verify how much time the integration is taking to scrape all the targets, and to send the data if it's exceeding the configured scrape_duration. SELECT latest(nr_stats_integration_process_duration_seconds) FROM Metric where clusterName=clustername' SINCE 30 MINUTES AGO TIMESERIES Copy First, update the integration to the latest image published. Then, to reduce the time needed to scrape all the targets, increase the number of workers with the configuration option worker_threads. We advise is to do it gradually, from 4 to 6, 8, and up to 16 until r_stats_integration_process_duration_seconds approaches the defined scrape_duration. Note that memory consumption and CPU usage will increase.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but you notice sparse data, missing metrics, and data gaps in New Relic&#x27;s UI. Solution If some metrics are not being collected regularly, do the following: Check if the CPU is being throttled"
      },
      "id": "603e9b8228ccbc95f4eba75b"
    }
  ],
  "/docs/integrations/prometheus-integrations/troubleshooting/sparse-data-missing-metrics-data-gaps": [
    {
      "sections": [
        "No data appears (Prometheus integration)",
        "Problem",
        "Solution",
        "Docker troubleshooting",
        "Kubernetes troubleshooting"
      ],
      "title": "No data appears (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "1e21826044fef6dc088721c30a0fb6d61636919a",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/no-data-appears-prometheus-integration/",
      "published_at": "2021-06-15T12:09:30Z",
      "updated_at": "2021-03-13T02:21:01Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic's UI. Solution Follow these troubleshooting tips for Docker or Kubernetes as applicable: Docker troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: docker ps -f \"name=nri-prometheus\" Copy Check the Status field for the container: docker inspect nri-prometheus Copy For more detailed information, use Docker inspect. If no data appears in New Relic's UI: Run this NRQL query: docker logs nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your Docker config file. Kubernetes troubleshooting If you are having problems with the integration: Check if the Prometheus OpenMetrics integration is running: kubectl describe pod -l \"app=nri-prometheus\" Copy Check the Ready field for the pod. If the pod is not ready, check the Events. If no data appears in New Relic's UI: Run this NRQL query: kubectl logs deploy/nri-prometheus | grep \"error emitting metrics\" Copy Check whether the log contains this message: metrics api responded with status code 403 Copy If yes, check the LICENSE_KEY in your nri-prometheus-latest.yaml manifest file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 102.25251,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "sections": "No data appears (<em>Prometheus</em> <em>integration</em>)",
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, but no data appears in New Relic&#x27;s UI. Solution Follow these <em>troubleshooting</em> tips for Docker or Kubernetes as applicable: Docker <em>troubleshooting</em> If you are having problems with the integration: Check"
      },
      "id": "6044e6a128ccbc64f22c6068"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    },
    {
      "sections": [
        "Restarts and gaps in data (Kubernetes)",
        "Problem",
        "Solution"
      ],
      "title": "Restarts and gaps in data (Kubernetes)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "215253af52dea03f816c3864e0f10911ae960897",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/restarts-gaps-data-kubernetes/",
      "published_at": "2021-06-15T13:28:00Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When running the Prometheus OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the Prometheus OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory limit: 1Gb Recommendation: Always run the Kubernetes scraper with one replica. Adding more replicas will result in duplicated data. If the CPU and memory limits are not sufficient, this can result in restarts and gaps in the data. To check the status and restart events for the scraper: kubectl describe pod -l \"app=nri-prometheus\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 95.53256,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes, you notice restarts and gaps in data sent to New Relic. Solution When running the <em>Prometheus</em> OpenMetrics integration for Kubernetes with 500K data points per minute, be sure to set these limits: CPU limit: 1 core Memory"
      },
      "id": "603ea39964441f1da84e884f"
    }
  ],
  "/docs/integrations/prometheus-integrations/view-query-data/supported-promql-features": [
    {
      "sections": [
        "View and query your Prometheus data",
        "Default attributes for the OpenMetrics integration",
        "Default attributes for the remote write integration",
        "NRQL query examples",
        "Get metric names",
        "Get the attributes for a metric",
        "Get the values for an attribute in OpenMetrics",
        "Build the query",
        "Get metric values",
        "Get a chart of the metric",
        "Query counter metrics (deltas)",
        "View connected Redis clients per pod with OpenMetrics",
        "Docker: View average memory free for scraped endpoints",
        "Kubernetes: View average memory usage for pods in a deployment",
        "View data in New Relic",
        "Create histograms and summaries"
      ],
      "title": "View and query your Prometheus data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "91a0388492ae73a9ddb8a1701b639a6b6a71822a",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/view-query-your-prometheus-data/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T04:13:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To query and visualize the metrics collected for your Prometheus OpenMetrics or remote write integration with New Relic, you can use NRQL. You can also translate your PromQL-style queries to NRQL using either Grafana or the query builder. All metrics for Docker and Kubernetes are stored in the Metric type. Default attributes for the OpenMetrics integration By default, the following attributes will be added to all metrics for Docker and Kubernetes integrations: Default attributes (all integrations) Description clusterName The name of the cluster provided in the scraper configuration. integrationName The name of this integration (nri-prometheus). integrationVersion The version of the integration; for example, 0.2.0. metricName The name of the metric itself. nrMetricType The type of the New Relic Metric type; for example, Gauges. promMetricType The metric type of the Prometheus metric scrapedEndpoint The URL of the endpoint is being scraped. Kubernetes: If the scraper is running in Kubernetes, New Relic also adds the following attributes to all the metrics: Additional Kubernetes attributes Description deploymentName Name of the deployment, if scraping a pod. label The Kubernetes labels of the object being scraped, prefixed by \"label\". namespaceName Name of the namespace. nodeName Name of the node where the pod being scraped is running, if applicable. podName Name of the pod being scraped, if applicable. serviceName Name of the service being scraped, if applicable Default attributes for the remote write integration By default, the following attributes will be added to Prometheus remote write metrics: Default attributes (all integrations) Description prometheus_server A user supplied label specified as a Prometheus remote write URL parameter. The value supplied should be unique as it is intended to differentiate between source Prometheus servers at query time. Unspecified by default. newrelic.source The name of the New Relic ingest point (prometheusAPI). instrumentation.provider prometheus instrumentation.name remote-write instrumentation.source A user supplied identifier for the source of the Prometheus data that matches the value of prometheus_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL query examples When you build queries, be aware that there is no linking between the metrics, entities, and attributes. Use the following NRQL queries to find out which metrics are available and which attributes are present on these metrics: Get metric names To get all metric names for OpenMetrics: FROM Metric SELECT uniques(metricName) Copy To get metric names for a remote write integration: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' Copy To get metric names for a remote write integration from a single Prometheus source: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' AND instrumentation.source='<ds>' Copy To get metric names for a specific OpenMetrics endpoint: FROM Metric SELECT uniques(metricName) WHERE scrapedEndpoint='<ep>' Copy To get metric names for a specific OpenMetrics cluster, namespace, or pod: FROM Metric SELECT uniques(metricName) WHERE clusterName='<cn>' Copy FROM Metric SELECT uniques(metricName) WHERE namespaceName='<ns>' Copy FROM Metric SELECT uniques(metricName) WHERE podName='<pod>' Copy Get the attributes for a metric To get all attributes for the selected metric: FROM Metric SELECT keyset() WHERE metricName='<mn>' Copy Get the values for an attribute in OpenMetrics The autocomplete will show all values of the attribute, regardless of the pod. To determine the attribute values for a specific pod: FROM Metric SELECT uniques(<attribute>) WHERE metricName='<mn>' AND podName='<pod>' Copy Build the query Using metric name and attributes, you can query your data. For more information about facets, time series, and time selection, see the NRQL documentation. To build PromQL-style queries, see our docs. Get metric values To get raw metric values: FROM Metric SELECT <metricName> WHERE <attribute>='<value>' Copy Get a chart of the metric To get a chart of the metric with an aggregator of average, min, max, or sum: FROM Metric SELECT <aggregator>(<metricname>) WHERE <attribute>='<value>' TIMESERIES Copy Query counter metrics (deltas) Currently the integration calculates the deltas for counter metrics. This is why queries on counter metrics will show the deltas of the counter instead of the absolute value of the counter. View connected Redis clients per pod with OpenMetrics Docker: This example assumes you are scraping Redis exporters. To view the number of connected Redis clients per endpoint in a cluster: FROM Metric SELECT latest(redis_connected_clients) WHERE clusterName='my-cluster' FACET scrapedEndpoint TIMESERIES Copy Kubernetes: This example assumes that you have Redis pods with the Redis exporter installed. To view the number of connected Redis clients per pod in the default namespace: FROM Metric SELECT latest(redis_connected_clients) WHERE namespaceName='default' FACET podName TIMESERIES Copy Docker: View average memory free for scraped endpoints This example assumes you are scraping node exporters for Docker and want to use OpenMetrics. To view average memory free for all scraped endpoints in a cluster: FROM Metric SELECT average(node_memory_MemFree_bytes) WHERE clusterName='my-cluster' Copy Kubernetes: View average memory usage for pods in a deployment To view average memory usage for all pods in a Kubernetes deployment using OpenMetrics: FROM Metric SELECT average(container_memory_usage_bytes) WHERE deploymentName='my-app-deployment' AND namespaceName='default' Copy View data in New Relic When you query the data, you can view the results in the New Relic UI. You can also visualize the data as charts, histograms, etc. To view the NRQL query results for your Prometheus integration's data: Go to one.newrelic.com > Query your data. For more information, see New Relic's query builder documentation. Create histograms and summaries With remote write or version 1.2.0 or higher of the Prometheus OpenMetrics integration, you can create histograms and percentiles (summaries) of your data. The OpenMetrics data is based on New Relic's guidelines in GitHub for higher level metric abstractions, while the remote write data closely matches the schema of the original Prometheus data. Data presentation Comments Histograms A bucket <basename>_bucket{le=\"42\"} will be sent as this: For OpenMetrics: <basename>_buckets For remote write: <basename>_bucket The dimension will be this: For OpenMetrics: {histogram.bucket.upperBound=\"42\"} For remote write: {histogram.bucket.le=\"42\"} Percentiles Quantiles (summaries) are transformed into percentiles. A metric <basename>{quantile=\"0.3\"} will be sent to New Relic as <basename>.percentiles. The dimension will be this: {percentile=\"30\"} NRQL has two functions that work on remote write ingested PromQL: bucketPercentile() and histogram(). The links include query examples.These two functions don't work on OpenMetrics ingested buckets. To better support visualization of histograms, percentiles are calculated based on the histogram metrics and sent to New Relic. To configure the calculated percentiles for OpenMetrics, use the percentiles configuration option.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.78322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "sections": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " identifier for the source of the <em>Prometheus</em> <em>data</em> that matches the value of <em>prometheus</em>_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL <em>query</em> examples When you build queries, be aware that there is no linking between the metrics, entities"
      },
      "id": "603eb04be7b9d20f9d2a07eb"
    },
    {
      "sections": [
        "Translate PromQL queries to NRQL",
        "Tip",
        "Prometheus and New Relic metric types",
        "Mapping between NRQL and our PromQL-style queries",
        "PromQL-style query example",
        "NRQL query example",
        "Filter examples",
        "PromQL-style to NRQL query examples",
        "For more help"
      ],
      "title": "Translate PromQL queries to NRQL",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "fcf45fb8fb49f9d22f74574c2e7032533377e584",
      "image": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/images/PROMQL-query-2.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do you have a PromQL query youd like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style query language to explore your Prometheus OpenMetrics integration data along with other data sent to New Relic. Tip To run PromQL-style queries in New Relic One, go to the query builder advanced PromQL-style mode. Prometheus and New Relic metric types The different metric types supported by Prometheus and New Relic are related to each other: New Relic Prometheus Description Count Counter The Prometheus counter is a cumulative sum while the New Relic count is a delta sum. For example, if you see 2 requests in the first reporting period and 3 requests in the second reporting period. The Prometheus counter will report 2 and then 5, while the New Relic count will report 2 and then 3. Gauge Gauge A Prometheus gauge is similar to a New Relic gauge. Multiple counts Histogram Prometheus automatically maps a histogram to a set of counters. In New Relic, these counters should be changed to deltas and reported as counts. Gauges and counts Summary Prometheus represents a Summary with a given basename as the following time series: a basename_sum a basename_count and 0 or more of basename{quantile=\".xx\"...} metrics New Relic maps the _sum as a Summary, the _count as a Counter, and each quantile metric as a Gauge. Summary (No equivalent in Prometheus) New Relic has a distinct metric type called a summary that is different than the Prometheus summary. It is designed for reporting aggregated discrete events so that you can query the count, sum, min, max, and average values. Mapping between NRQL and our PromQL-style queries Tip To see how New Relic translates PromQL-style queries to NRQL, write a query in the query builder PromQL-style tab, then switch to the NRQL tab. This table shows the mapping between NRQL and our PromQL-style queries when exploring data. For more contextual information, see the examples. Description Mapping between NRQL and PromQL-style queries Search for attributes: Explore the attributes on the container_memory_usage_bytes metric. PromQL: container_memory_usage_bytes Copy NRQL: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy Find attribute's value: Explore the current value of the container_memory_usage_bytes metric for unique id attributes. PromQL: sum(container_memory_usage_bytes) by (id) Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy Visualize the attribute's value: Chart the value of the container_memory_usage_bytes metric with the given id attribute value. PromQL: container_memory_usage_bytes{id=\"/\"} Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = '/' TIMESERIES Copy PromQL-style query example 1. Start your query. When exploring your data for a particular metric in PromQL, such as memory by container usage in bytes, you can start with a query such as: container_memory_usage_bytes Copy This will chart all the unique metric timeseries for the input metric. 2. Filter the query results. Looking at the data, you can add more query parameters to filter down the number of metric timeseries. For example, if you only want timeseries where the id is /, the PromQL-style query will be: container_memory_usage_bytes{id=\"/\"} Copy PromQL-style example: To filter the data, run this PromQL-style query: container_memory_usage_bytes { id=\"/\"}. NRQL query example 1. Query available metrics. To explore your data, start by looking at all the available metrics. Use the following NRQL query: FROM Metric SELECT uniques(metricName) Copy 2. Find unique attributes. Once you have found the metric you want to review, such as container_memory_usage_bytes, you can find the unique attributes with the following query: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy The results will show each available attribute key and the value type (string, boolean, or number). 3. Aggregate and chart the metrics. To chart metrics using NRQL, you first need an aggregation function. For example, you can use latest for gauges, sum for counts, and average for summaries. As the following chart shows, all the unique timeseries are aggregated into one unique timeseries by default: one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes'. 4. View metrics by ID. To view the unique metric timeseries with various id values, run the following query: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT latest(container_memory_usage_bytes) FACET id. 5. Add the selected ID to the query. Next you can select an id value and put it in the NRQL where clause. FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = \"/\" timeseries Copy one.newrelic.com > Query your data: This example shows the data displayed after running From Metric select latest(container_memory_usage_bytes) where id = \"/\" timeseries. Filter examples Both our PromQL-style query language and NRQL provide syntax to filter down the number of unique metric timeseries. PromQL-style uses brackets to filter. NRQL uses a WHERE clause. Here are some example queries: Description PromQL-style and NRQL queries Select data with specific values. PromQL: go_memstats_heap_alloc_bytes{job=\"apiserver\", instance=\"1234\"}) Copy NRQL: To only select data with specific values in NRQL, use the WHERE clause with =. In this example, all data must have the selected value for job and handler. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE job = 'apiserver' AND instance = '1234' TIMESERIES Copy Select data with multiple values. PromQL: go_memstats_heap_alloc_bytes{environment=~\"staging|testing|development\",method!=\"GET\"} Copy NRQL: In NRQL use the in clause to select multiple values for an attribute and the != sign to select all values but the one listed. In this example, the environment can be staging, testing, or development, and the method cannot be GET. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE environment IN ('staging', 'testing', 'development') AND method != 'GET' TIMESERIES Copy Select data using partial string values. PromQL: go_memstats_heap_alloc_bytes{job=~\"api.*\"} Copy NRQL: In NRQL use the LIKE clause to match part of a string value. In this example, all data will be returned where the job attributes start with api. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHEREe job LIKE 'api%' TIMESERIES Copy PromQL-style to NRQL query examples You can simulate the following PromQL-style queries with NRQL queries: Description PromQL-style and NRQL queries Measure the per second rate over the last minute of the http_request_total metric. PromQL: sum(rate(http_requests_total[1m])) Copy NRQL: FROM Metric SELECT rate(sum(http_request_total), 1 second) TIMESERIES 1 minute Copy Chart the difference of the two metrics, then divide by 1024. PromQL: (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 Copy NRQL: FROM Metric SELECT (latest(instance_memory_limit_bytes) - latest(instance_memory_usage_bytes)) / 1024 TIMESERIES Copy Provide the summed rate per 30-second interval by each handler. PromQL: sum(rate(http_requests_total[30s])) by (handler) Copy NRQL: FROM Metric SELECT rate(sum(http_requests_total), 30 seconds) FACET handler TIMESERIES Copy Chart the difference in the two metrics where the instance is named foo and the fstype is either ext4 or xfs. PromQL: (node_filesystem_free_bytes{instance='foo',fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{instance='foo',fstype=~\"ext4|xfs\"}) Copy NRQL: FROM Metric SELECT latest(node_filesystem_free_bytes) / latest(node_filesystem_size_bytes) WHERE instance = 'foo' AND fstype IN ('ext4', 'xfs') Copy For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.1839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Translate PromQL <em>queries</em> to NRQL",
        "sections": "<em>Prometheus</em> <em>and</em> New Relic metric types",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Do you have a PromQL <em>query</em> youd like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style <em>query</em> language to explore your <em>Prometheus</em> OpenMetrics integration <em>data</em> along with other <em>data</em> sent to New"
      },
      "id": "603ead4528ccbcbecfeba77b"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.81398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql": [
    {
      "sections": [
        "View and query your Prometheus data",
        "Default attributes for the OpenMetrics integration",
        "Default attributes for the remote write integration",
        "NRQL query examples",
        "Get metric names",
        "Get the attributes for a metric",
        "Get the values for an attribute in OpenMetrics",
        "Build the query",
        "Get metric values",
        "Get a chart of the metric",
        "Query counter metrics (deltas)",
        "View connected Redis clients per pod with OpenMetrics",
        "Docker: View average memory free for scraped endpoints",
        "Kubernetes: View average memory usage for pods in a deployment",
        "View data in New Relic",
        "Create histograms and summaries"
      ],
      "title": "View and query your Prometheus data",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "91a0388492ae73a9ddb8a1701b639a6b6a71822a",
      "image": "https://docs.newrelic.com/static/ed6795cfdb010c5eabb1cfe9c83a82a9/69538/img-integration-k8.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/view-query-your-prometheus-data/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T04:13:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To query and visualize the metrics collected for your Prometheus OpenMetrics or remote write integration with New Relic, you can use NRQL. You can also translate your PromQL-style queries to NRQL using either Grafana or the query builder. All metrics for Docker and Kubernetes are stored in the Metric type. Default attributes for the OpenMetrics integration By default, the following attributes will be added to all metrics for Docker and Kubernetes integrations: Default attributes (all integrations) Description clusterName The name of the cluster provided in the scraper configuration. integrationName The name of this integration (nri-prometheus). integrationVersion The version of the integration; for example, 0.2.0. metricName The name of the metric itself. nrMetricType The type of the New Relic Metric type; for example, Gauges. promMetricType The metric type of the Prometheus metric scrapedEndpoint The URL of the endpoint is being scraped. Kubernetes: If the scraper is running in Kubernetes, New Relic also adds the following attributes to all the metrics: Additional Kubernetes attributes Description deploymentName Name of the deployment, if scraping a pod. label The Kubernetes labels of the object being scraped, prefixed by \"label\". namespaceName Name of the namespace. nodeName Name of the node where the pod being scraped is running, if applicable. podName Name of the pod being scraped, if applicable. serviceName Name of the service being scraped, if applicable Default attributes for the remote write integration By default, the following attributes will be added to Prometheus remote write metrics: Default attributes (all integrations) Description prometheus_server A user supplied label specified as a Prometheus remote write URL parameter. The value supplied should be unique as it is intended to differentiate between source Prometheus servers at query time. Unspecified by default. newrelic.source The name of the New Relic ingest point (prometheusAPI). instrumentation.provider prometheus instrumentation.name remote-write instrumentation.source A user supplied identifier for the source of the Prometheus data that matches the value of prometheus_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL query examples When you build queries, be aware that there is no linking between the metrics, entities, and attributes. Use the following NRQL queries to find out which metrics are available and which attributes are present on these metrics: Get metric names To get all metric names for OpenMetrics: FROM Metric SELECT uniques(metricName) Copy To get metric names for a remote write integration: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' Copy To get metric names for a remote write integration from a single Prometheus source: FROM Metric SELECT uniques(metricName) WHERE instrumentation.provider='prometheus' AND instrumentation.name='remote-write' AND instrumentation.source='<ds>' Copy To get metric names for a specific OpenMetrics endpoint: FROM Metric SELECT uniques(metricName) WHERE scrapedEndpoint='<ep>' Copy To get metric names for a specific OpenMetrics cluster, namespace, or pod: FROM Metric SELECT uniques(metricName) WHERE clusterName='<cn>' Copy FROM Metric SELECT uniques(metricName) WHERE namespaceName='<ns>' Copy FROM Metric SELECT uniques(metricName) WHERE podName='<pod>' Copy Get the attributes for a metric To get all attributes for the selected metric: FROM Metric SELECT keyset() WHERE metricName='<mn>' Copy Get the values for an attribute in OpenMetrics The autocomplete will show all values of the attribute, regardless of the pod. To determine the attribute values for a specific pod: FROM Metric SELECT uniques(<attribute>) WHERE metricName='<mn>' AND podName='<pod>' Copy Build the query Using metric name and attributes, you can query your data. For more information about facets, time series, and time selection, see the NRQL documentation. To build PromQL-style queries, see our docs. Get metric values To get raw metric values: FROM Metric SELECT <metricName> WHERE <attribute>='<value>' Copy Get a chart of the metric To get a chart of the metric with an aggregator of average, min, max, or sum: FROM Metric SELECT <aggregator>(<metricname>) WHERE <attribute>='<value>' TIMESERIES Copy Query counter metrics (deltas) Currently the integration calculates the deltas for counter metrics. This is why queries on counter metrics will show the deltas of the counter instead of the absolute value of the counter. View connected Redis clients per pod with OpenMetrics Docker: This example assumes you are scraping Redis exporters. To view the number of connected Redis clients per endpoint in a cluster: FROM Metric SELECT latest(redis_connected_clients) WHERE clusterName='my-cluster' FACET scrapedEndpoint TIMESERIES Copy Kubernetes: This example assumes that you have Redis pods with the Redis exporter installed. To view the number of connected Redis clients per pod in the default namespace: FROM Metric SELECT latest(redis_connected_clients) WHERE namespaceName='default' FACET podName TIMESERIES Copy Docker: View average memory free for scraped endpoints This example assumes you are scraping node exporters for Docker and want to use OpenMetrics. To view average memory free for all scraped endpoints in a cluster: FROM Metric SELECT average(node_memory_MemFree_bytes) WHERE clusterName='my-cluster' Copy Kubernetes: View average memory usage for pods in a deployment To view average memory usage for all pods in a Kubernetes deployment using OpenMetrics: FROM Metric SELECT average(container_memory_usage_bytes) WHERE deploymentName='my-app-deployment' AND namespaceName='default' Copy View data in New Relic When you query the data, you can view the results in the New Relic UI. You can also visualize the data as charts, histograms, etc. To view the NRQL query results for your Prometheus integration's data: Go to one.newrelic.com > Query your data. For more information, see New Relic's query builder documentation. Create histograms and summaries With remote write or version 1.2.0 or higher of the Prometheus OpenMetrics integration, you can create histograms and percentiles (summaries) of your data. The OpenMetrics data is based on New Relic's guidelines in GitHub for higher level metric abstractions, while the remote write data closely matches the schema of the original Prometheus data. Data presentation Comments Histograms A bucket <basename>_bucket{le=\"42\"} will be sent as this: For OpenMetrics: <basename>_buckets For remote write: <basename>_bucket The dimension will be this: For OpenMetrics: {histogram.bucket.upperBound=\"42\"} For remote write: {histogram.bucket.le=\"42\"} Percentiles Quantiles (summaries) are transformed into percentiles. A metric <basename>{quantile=\"0.3\"} will be sent to New Relic as <basename>.percentiles. The dimension will be this: {percentile=\"30\"} NRQL has two functions that work on remote write ingested PromQL: bucketPercentile() and histogram(). The links include query examples.These two functions don't work on OpenMetrics ingested buckets. To better support visualization of histograms, percentiles are calculated based on the histogram metrics and sent to New Relic. To configure the calculated percentiles for OpenMetrics, use the percentiles configuration option.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.78322,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "sections": "<em>View</em> <em>and</em> <em>query</em> your <em>Prometheus</em> <em>data</em>",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " identifier for the source of the <em>Prometheus</em> <em>data</em> that matches the value of <em>prometheus</em>_server. instrumentation.version Used to identify the version of the remote write API; for example, 0.0.1. NRQL <em>query</em> examples When you build queries, be aware that there is no linking between the metrics, entities"
      },
      "id": "603eb04be7b9d20f9d2a07eb"
    },
    {
      "sections": [
        "Supported PromQL Features",
        "Important",
        "Supported features",
        "Aggregation operators and functions",
        "Arithmetic binary operators",
        "Logical operators",
        "Date/time functions",
        "Mathematical functions",
        "Rate-like functions",
        "Predictive functions",
        "Time-series selectors",
        "PromQL troubleshooting",
        "Metric types",
        "Limits",
        "Range vector selectors (sliding windows and smoothing behavior)",
        "Query range and data scraping intervals"
      ],
      "title": "Supported PromQL Features",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "d4a93b9db3bfe5639ed01968b6e55a8e0aaa9389",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/supported-promql-features/",
      "published_at": "2021-06-15T13:28:44Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports PromQL-style queries, and our query builder offers a PromQL-style query mode that translates PromQL syntax queries into the closest NRQL approximation. Although the method of approximation means that a handful of edge cases are not fully supported, it provides coverage for an overwhelming majority of queries, supporting over 99.5% of queries across the 7.8 million top Grafana dashboard downloads. Read on to learn about how we work with PromQL queries, as well as differences between standard PromQL and our PromQL-like query language we want you to be aware of. Important For general information about Prometheus queries and operators, see the Prometheus.io documentation. Supported features We support the following aggregation, arithmetic, mathematical, and rate-like functions. As we continue to expand support for Prometheus and PromQL, this list will be updated. Aggregation operators and functions Aggregation operators: avg() count() min() max() quantile() stddev() stdvar() sum() topk() Aggregation functions: histogram_quantile() <aggregation>_over_time() functions: avg_over_time count_over_time min_over_time max_over_time quantile_over_time stdev_over_time stvar_over_time sum_over_time Arithmetic binary operators + (addition) - (subtraction) * (multiplication) / (division) % (percent) ^ (power/exponents) Logical operators and or Date/time functions day_of_month() day_of_week() days_in_month() hour() minute() month() time() timestamp() year() Mathematical functions abs() ceil() clamp_max() clamp_min() exp() floor() ln() log10() log2() round() sqrt() Rate-like functions delta() deriv() idelta() increase() irate() rate() Predictive functions predict_linear Time-series selectors We offer support for PromQL time-series selectors including the following: instant vector selectors range series selectors offset modifier Important We only support offset queries if every vector in the query has the same offset value. PromQL troubleshooting This section describes differences in behavior between PromQL and our PromQL-style query behavior and how to work with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the query builder. Metric types Prometheus recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase() on counters, but queries in Prometheus still work most of the time even if they dont follow those instructions. However, because NRDB converts PromQL-style accumulating counters to delta counters, our implementation is unforgiving when using these functions on the wrong data type and will produce different or incorrect answers. For this reason, it's best to follow all Prometheus recommendations when working with our PromQL-style queries, even if you don't follow these recommendations in Prometheus. Limits In order to ensure the stability and performance of our system for all users, we place some limits on what queries can be run. In all cases, we enforce a limit of 366 steps in range queries. We also default to only returning 100 timeseries from queries by default. If you want to see more (or fewer), you need to explicitly add a topk() to your query. (Note that the topk() implementation in our PromQL-style query is different from that of Prometheus.) We limit the total memory a query can use. This means that requests for large numbers of time steps or large numbers of time series may be rejected, particularly if they are combined with an aggregation like unique count or quantile which require significantly more memory to compute than simple arithmetic aggregations. Range vector selectors (sliding windows and smoothing behavior) We provide support for sliding window timeseries aggregations. For more information, see our NRQL syntax, clauses, and functions resource and our sliding windows deep dive. For information on translating between NRQL and our PromQL-style language, see Translate PromQL queries to NRQL. Query range and data scraping intervals The range of your query in PromQL must be larger than the duration of the step size of the query to avoid the error \"TIMESERIES bucket size is larger than the current time window\". We inspect data up to one minute old when servicing instant queries. If your scrape interval is greater than 1 minute, some queries may result in No data found. Avoid this by sending data at least once per minute. If the timeseries unit for your NRQL query is less than the scrape interval for your application, some periods will lack data, and the resulting graph may be jagged or contain peaks and valleys. In general, set the step size to your scrape interval, or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.18646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Query</em> range <em>and</em> <em>data</em> scraping intervals",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the <em>query</em> builder. Metric types <em>Prometheus</em> recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase"
      },
      "id": "603e9523e7b9d292ec2a07ce"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.81398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/integrations/prometheus-integrations/view-query-data/view-query-your-prometheus-data": [
    {
      "sections": [
        "Supported PromQL Features",
        "Important",
        "Supported features",
        "Aggregation operators and functions",
        "Arithmetic binary operators",
        "Logical operators",
        "Date/time functions",
        "Mathematical functions",
        "Rate-like functions",
        "Predictive functions",
        "Time-series selectors",
        "PromQL troubleshooting",
        "Metric types",
        "Limits",
        "Range vector selectors (sliding windows and smoothing behavior)",
        "Query range and data scraping intervals"
      ],
      "title": "Supported PromQL Features",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "d4a93b9db3bfe5639ed01968b6e55a8e0aaa9389",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/supported-promql-features/",
      "published_at": "2021-06-15T13:28:44Z",
      "updated_at": "2021-03-16T04:42:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic supports PromQL-style queries, and our query builder offers a PromQL-style query mode that translates PromQL syntax queries into the closest NRQL approximation. Although the method of approximation means that a handful of edge cases are not fully supported, it provides coverage for an overwhelming majority of queries, supporting over 99.5% of queries across the 7.8 million top Grafana dashboard downloads. Read on to learn about how we work with PromQL queries, as well as differences between standard PromQL and our PromQL-like query language we want you to be aware of. Important For general information about Prometheus queries and operators, see the Prometheus.io documentation. Supported features We support the following aggregation, arithmetic, mathematical, and rate-like functions. As we continue to expand support for Prometheus and PromQL, this list will be updated. Aggregation operators and functions Aggregation operators: avg() count() min() max() quantile() stddev() stdvar() sum() topk() Aggregation functions: histogram_quantile() <aggregation>_over_time() functions: avg_over_time count_over_time min_over_time max_over_time quantile_over_time stdev_over_time stvar_over_time sum_over_time Arithmetic binary operators + (addition) - (subtraction) * (multiplication) / (division) % (percent) ^ (power/exponents) Logical operators and or Date/time functions day_of_month() day_of_week() days_in_month() hour() minute() month() time() timestamp() year() Mathematical functions abs() ceil() clamp_max() clamp_min() exp() floor() ln() log10() log2() round() sqrt() Rate-like functions delta() deriv() idelta() increase() irate() rate() Predictive functions predict_linear Time-series selectors We offer support for PromQL time-series selectors including the following: instant vector selectors range series selectors offset modifier Important We only support offset queries if every vector in the query has the same offset value. PromQL troubleshooting This section describes differences in behavior between PromQL and our PromQL-style query behavior and how to work with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the query builder. Metric types Prometheus recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase() on counters, but queries in Prometheus still work most of the time even if they dont follow those instructions. However, because NRDB converts PromQL-style accumulating counters to delta counters, our implementation is unforgiving when using these functions on the wrong data type and will produce different or incorrect answers. For this reason, it's best to follow all Prometheus recommendations when working with our PromQL-style queries, even if you don't follow these recommendations in Prometheus. Limits In order to ensure the stability and performance of our system for all users, we place some limits on what queries can be run. In all cases, we enforce a limit of 366 steps in range queries. We also default to only returning 100 timeseries from queries by default. If you want to see more (or fewer), you need to explicitly add a topk() to your query. (Note that the topk() implementation in our PromQL-style query is different from that of Prometheus.) We limit the total memory a query can use. This means that requests for large numbers of time steps or large numbers of time series may be rejected, particularly if they are combined with an aggregation like unique count or quantile which require significantly more memory to compute than simple arithmetic aggregations. Range vector selectors (sliding windows and smoothing behavior) We provide support for sliding window timeseries aggregations. For more information, see our NRQL syntax, clauses, and functions resource and our sliding windows deep dive. For information on translating between NRQL and our PromQL-style language, see Translate PromQL queries to NRQL. Query range and data scraping intervals The range of your query in PromQL must be larger than the duration of the step size of the query to avoid the error \"TIMESERIES bucket size is larger than the current time window\". We inspect data up to one minute old when servicing instant queries. If your scrape interval is greater than 1 minute, some queries may result in No data found. Avoid this by sending data at least once per minute. If the timeseries unit for your NRQL query is less than the scrape interval for your application, some periods will lack data, and the resulting graph may be jagged or contain peaks and valleys. In general, set the step size to your scrape interval, or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.18646,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Query</em> range <em>and</em> <em>data</em> scraping intervals",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " with and around these differences. This is particularly relevant if you want to use advanced queries and our PromQL-style mode in the <em>query</em> builder. Metric types <em>Prometheus</em> recommendations note that you should only use some functions, like delta(), on gauges, and only use others like rate() and increase"
      },
      "id": "603e9523e7b9d292ec2a07ce"
    },
    {
      "sections": [
        "Translate PromQL queries to NRQL",
        "Tip",
        "Prometheus and New Relic metric types",
        "Mapping between NRQL and our PromQL-style queries",
        "PromQL-style query example",
        "NRQL query example",
        "Filter examples",
        "PromQL-style to NRQL query examples",
        "For more help"
      ],
      "title": "Translate PromQL queries to NRQL",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "fcf45fb8fb49f9d22f74574c2e7032533377e584",
      "image": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/images/PROMQL-query-2.png",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do you have a PromQL query youd like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style query language to explore your Prometheus OpenMetrics integration data along with other data sent to New Relic. Tip To run PromQL-style queries in New Relic One, go to the query builder advanced PromQL-style mode. Prometheus and New Relic metric types The different metric types supported by Prometheus and New Relic are related to each other: New Relic Prometheus Description Count Counter The Prometheus counter is a cumulative sum while the New Relic count is a delta sum. For example, if you see 2 requests in the first reporting period and 3 requests in the second reporting period. The Prometheus counter will report 2 and then 5, while the New Relic count will report 2 and then 3. Gauge Gauge A Prometheus gauge is similar to a New Relic gauge. Multiple counts Histogram Prometheus automatically maps a histogram to a set of counters. In New Relic, these counters should be changed to deltas and reported as counts. Gauges and counts Summary Prometheus represents a Summary with a given basename as the following time series: a basename_sum a basename_count and 0 or more of basename{quantile=\".xx\"...} metrics New Relic maps the _sum as a Summary, the _count as a Counter, and each quantile metric as a Gauge. Summary (No equivalent in Prometheus) New Relic has a distinct metric type called a summary that is different than the Prometheus summary. It is designed for reporting aggregated discrete events so that you can query the count, sum, min, max, and average values. Mapping between NRQL and our PromQL-style queries Tip To see how New Relic translates PromQL-style queries to NRQL, write a query in the query builder PromQL-style tab, then switch to the NRQL tab. This table shows the mapping between NRQL and our PromQL-style queries when exploring data. For more contextual information, see the examples. Description Mapping between NRQL and PromQL-style queries Search for attributes: Explore the attributes on the container_memory_usage_bytes metric. PromQL: container_memory_usage_bytes Copy NRQL: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy Find attribute's value: Explore the current value of the container_memory_usage_bytes metric for unique id attributes. PromQL: sum(container_memory_usage_bytes) by (id) Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy Visualize the attribute's value: Chart the value of the container_memory_usage_bytes metric with the given id attribute value. PromQL: container_memory_usage_bytes{id=\"/\"} Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = '/' TIMESERIES Copy PromQL-style query example 1. Start your query. When exploring your data for a particular metric in PromQL, such as memory by container usage in bytes, you can start with a query such as: container_memory_usage_bytes Copy This will chart all the unique metric timeseries for the input metric. 2. Filter the query results. Looking at the data, you can add more query parameters to filter down the number of metric timeseries. For example, if you only want timeseries where the id is /, the PromQL-style query will be: container_memory_usage_bytes{id=\"/\"} Copy PromQL-style example: To filter the data, run this PromQL-style query: container_memory_usage_bytes { id=\"/\"}. NRQL query example 1. Query available metrics. To explore your data, start by looking at all the available metrics. Use the following NRQL query: FROM Metric SELECT uniques(metricName) Copy 2. Find unique attributes. Once you have found the metric you want to review, such as container_memory_usage_bytes, you can find the unique attributes with the following query: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy The results will show each available attribute key and the value type (string, boolean, or number). 3. Aggregate and chart the metrics. To chart metrics using NRQL, you first need an aggregation function. For example, you can use latest for gauges, sum for counts, and average for summaries. As the following chart shows, all the unique timeseries are aggregated into one unique timeseries by default: one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes'. 4. View metrics by ID. To view the unique metric timeseries with various id values, run the following query: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT latest(container_memory_usage_bytes) FACET id. 5. Add the selected ID to the query. Next you can select an id value and put it in the NRQL where clause. FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = \"/\" timeseries Copy one.newrelic.com > Query your data: This example shows the data displayed after running From Metric select latest(container_memory_usage_bytes) where id = \"/\" timeseries. Filter examples Both our PromQL-style query language and NRQL provide syntax to filter down the number of unique metric timeseries. PromQL-style uses brackets to filter. NRQL uses a WHERE clause. Here are some example queries: Description PromQL-style and NRQL queries Select data with specific values. PromQL: go_memstats_heap_alloc_bytes{job=\"apiserver\", instance=\"1234\"}) Copy NRQL: To only select data with specific values in NRQL, use the WHERE clause with =. In this example, all data must have the selected value for job and handler. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE job = 'apiserver' AND instance = '1234' TIMESERIES Copy Select data with multiple values. PromQL: go_memstats_heap_alloc_bytes{environment=~\"staging|testing|development\",method!=\"GET\"} Copy NRQL: In NRQL use the in clause to select multiple values for an attribute and the != sign to select all values but the one listed. In this example, the environment can be staging, testing, or development, and the method cannot be GET. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE environment IN ('staging', 'testing', 'development') AND method != 'GET' TIMESERIES Copy Select data using partial string values. PromQL: go_memstats_heap_alloc_bytes{job=~\"api.*\"} Copy NRQL: In NRQL use the LIKE clause to match part of a string value. In this example, all data will be returned where the job attributes start with api. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHEREe job LIKE 'api%' TIMESERIES Copy PromQL-style to NRQL query examples You can simulate the following PromQL-style queries with NRQL queries: Description PromQL-style and NRQL queries Measure the per second rate over the last minute of the http_request_total metric. PromQL: sum(rate(http_requests_total[1m])) Copy NRQL: FROM Metric SELECT rate(sum(http_request_total), 1 second) TIMESERIES 1 minute Copy Chart the difference of the two metrics, then divide by 1024. PromQL: (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 Copy NRQL: FROM Metric SELECT (latest(instance_memory_limit_bytes) - latest(instance_memory_usage_bytes)) / 1024 TIMESERIES Copy Provide the summed rate per 30-second interval by each handler. PromQL: sum(rate(http_requests_total[30s])) by (handler) Copy NRQL: FROM Metric SELECT rate(sum(http_requests_total), 30 seconds) FACET handler TIMESERIES Copy Chart the difference in the two metrics where the instance is named foo and the fstype is either ext4 or xfs. PromQL: (node_filesystem_free_bytes{instance='foo',fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{instance='foo',fstype=~\"ext4|xfs\"}) Copy NRQL: FROM Metric SELECT latest(node_filesystem_free_bytes) / latest(node_filesystem_size_bytes) WHERE instance = 'foo' AND fstype IN ('ext4', 'xfs') Copy For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 169.1839,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Translate PromQL <em>queries</em> to NRQL",
        "sections": "<em>Prometheus</em> <em>and</em> New Relic metric types",
        "tags": "<em>View</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Do you have a PromQL <em>query</em> youd like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style <em>query</em> language to explore your <em>Prometheus</em> OpenMetrics integration <em>data</em> along with other <em>data</em> sent to New"
      },
      "id": "603ead4528ccbcbecfeba77b"
    },
    {
      "sections": [
        "Excessive CPU or memory consumption",
        "Problem",
        "Solution"
      ],
      "title": "Excessive CPU or memory consumption",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "130c15368dcecaeb128789171b818014d112919d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/excessive-cpu-or-memory-consumption/",
      "published_at": "2021-06-15T12:08:44Z",
      "updated_at": "2021-03-16T06:18:08Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You have installed the Prometheus OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect scrape_duration. For example, a Prometheus OpenMetrics integration consumes 2.5 CPU and 700Mb of RAM because: It scrapes 800 targets, exposing 1000 timeseries each. Each one has a latency of 150ms with a scrape_duration of 30 seconds. To reduce resource consumption: Update the integration to the latest available image. Reduce harvest time by lowering emitter_harvest_period. (The default value is 1s, and the interval cannot be smaller than 200ms.) Since metrics are sent more often, memory consumption is reduced. Collect metrics less frequently by increasing scrape_duration to reduce both memory consumption and CPU usage. Reduce the number of workers to reduce both memory consumption and CPU usage. Scraping will slow down and could exceed scrape_duration. To do so: Update the integration to the latest version available of the image. Decrease worker_threads from the default value of 4 to your preferred value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.81398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Prometheus</em> <em>integrations</em>",
        "body": "Problem You have installed the <em>Prometheus</em> OpenMetrics integration for Docker or Kubernetes, and it consumes too much memory or CPU. Solution When running the integration in a huge cluster scraping hundreds of targets, CPU and memory consumption will increase, and the number of workers could affect"
      },
      "id": "603e9b3b28ccbcaae3eba790"
    }
  ],
  "/docs/introduction-new-relic-agent-sdk": [
    {
      "sections": [
        "Introduction to .NET agent install",
        "Tip",
        "Compatibility and requirements",
        "Install the .NET agent"
      ],
      "title": "Introduction to .NET agent install",
      "type": "docs",
      "tags": [
        "Agents",
        "NET agent",
        "Installation"
      ],
      "external_id": "541834d75a01dc99a4fdd2d3cfa64cae418429ee",
      "image": "",
      "url": "https://docs.newrelic.com/docs/agents/net-agent/installation/introduction-net-agent-install/",
      "published_at": "2021-06-14T20:00:09Z",
      "updated_at": "2021-06-14T20:00:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our .NET agent auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic .NET agent installation. To learn more about what APM for .NET does, see Introduction to New Relic for .NET. Tip To use .NET or any other agent, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Add .NET data Compatibility and requirements Compatibility and requirements: .NET Framework .NET Core Install the .NET agent See the appropriate install instructions for your operating system and find the download link: Windows For Windows .NET applications on IIS or .NET Core applications on Linux, use our guided install to get started with APM. If you're on an EU server, use this link instead. Linux Tip Find all binaries and packages for the .NET Agent in our latest releases. Historical releases can be found in our previous releases.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.203064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> .NET <em>agent</em> install",
        "sections": "<em>Introduction</em> <em>to</em> .NET <em>agent</em> install",
        "tags": "<em>Agents</em>",
        "body": "Our .NET <em>agent</em> auto-instruments your code so you can start monitoring applications. You can use our launcher, or follow the instructions in this document to complete a basic .NET <em>agent</em> installation. To learn more about what APM for .NET does, see <em>Introduction</em> to <em>New</em> <em>Relic</em> for .NET. Tip To use .NET"
      },
      "id": "604411b6e7b9d2cf7c5799f8"
    },
    {
      "sections": [
        "What is an entity in New Relic?",
        "What is an entity?",
        "Find and explore entities",
        "Tip",
        "Entity synthesis",
        "Reserved attributes for synthesized entities",
        "Entity relationships",
        "Important",
        "Which relationships are created?",
        "Source: New Relic agent",
        "Source: Infrastructure",
        "Source: Synthetics monitor",
        "Source: Kubernetes",
        "External services",
        "Group and organize entities"
      ],
      "title": "What is an entity in New Relic?",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Core concepts"
      ],
      "external_id": "52a3e08bc9103c717d27b153e4fd4f547d6ecc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/",
      "published_at": "2021-06-15T10:28:05Z",
      "updated_at": "2021-06-15T10:28:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic monitoring is built around the concept of the entity. An entity is anything that reports data to New Relic. This document explains: What entities are How to find entity data How to modify existing entity types or create new ones How entities are related to one another How to organize them into groups for easier analysis What is an entity? From a New Relic product perspective, entity is a broad concept. An entity is anything we can identify that has data you can monitor. \"Entity\" can refer to fundamental data-reporting components like applications, hosts, and database services, but it can also refer to larger groupings of those components. For example, to monitor a data center, you could aggregate those hosts in New Relic to be a workload (a custom grouping of entities). That workload is, itself, also an entity. This conceptual definition of \"entity\" is important because New Relic's goal is to give you practical information about the status of your business-important entities (and not just give you an unhelpfully large stream of assorted metrics and data). Our focus on entities, and the relationships between them, helps us optimize monitoring and troubleshooting of complex, modern systems. Find and explore entities You'll find your entities wherever you see your data reporting in New Relic. Tip You can create new entity types to monitor any data source. Learn more about entity synthesis. Some tips for finding and understanding entity data: To find an entity's unique global identifier (GUID): from any list of monitored entities in the New Relic Explorer, hover over a specific entity and click the icon to see the GUID and other metadata. An entity's GUID is reported as the attribute entityGuid. You can query for an entity using this attribute in the query builder. Use the Related Entities view in the New Relic Explorer, service maps, distributed tracing, and our relationships API in GraphQL to see connections between entities. Explore entity data using our NerdGraph GraphiQL explorer (api.newrelic.com/graphiql). Entity synthesis If you have telemetry from any source that's not supported by New Relic out of the box, you can propose a mapping for it. Once approved, any telemetry received by New Relic which matches your definition file will be synthesized into an entity. Tip For more information on how to modify existing entity types or create new ones please refer to our Entity Synthesis documentation. Reserved attributes for synthesized entities These attributes are meant to be synthesized from the telemetry we receive. Do not set them unless you are aware of the implications and consequences. Attribute Description entity.guid Generally, you should not set this attribute field on your telemetry data. New Relic may add this field to ingested data to store a unique identifier for the entity associated with the data point. If telemetry arrives with the entity.guid attribute already present, then New Relic will not change the value. However, it may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. One use case for passing this attribute is to associate ingested telemetry with an entity already created by New Relic. When the entity.guid attribute is sent, the value will override New Relics entity identification system (such as entity synthesis definitions) and instead will use the attribute as the data. entity.name This attribute shouldn't be put on ingested telemetry data unless you're trying to override the entity name that would have been selected by New Relics entity identification system. While New Relic won't change the value if it's already present on the data, New Relic may add the attribute to your data. Therefore invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. If this field is present on ingested telemetry, its value will be used to name the entity associated with the data point. This name will be used instead of the name selected by New Relics entity identification system (for example, entity synthesis definitions). Note that many entities use the name as part of their identification, so changing this field may result in the generation of a new entity. entity.type This attribute shouldn't be put on ingested telemetry data except for certain legacy cases where it's required to distinguish entity types. Passing this field may interfere with entity detection, particularly if unrecognized values are sent in this field. While New Relic won't change the value if already present on the data, the field is not guaranteed to provide unambiguous filtering of telemetry at query-time. Existing entity definitions already have overlapping values, and we recommend avoiding entity.type in favor of other fields for filtering telemetry queries. This field is used by New Relic, meaning that invalid or unexpected values may cause undefined behavior such as missing entities in the UI, or telemetry not associating with the expected entities. Entity relationships Connections between entities are automatically created by New Relic based on what we can infer from your telemetry. For example, when two services that communicate using HTTP are instrumented with New Relic, we infer a \"calls/called-by\" relationship between them. When viewing a single entity in either the New Relic Explorer, Navigator, or Lookout, you can see its Related Entities in the entity's mini overview. Related Entities is a visualization of the various entities connected directly to the current entity in focus. You can quickly view important metrics for these related entities and navigate from one entity to another, through all the connected parts of your stack. Tip You can learn more about how entities are related using our NerdGraph API. When relationships are not automatically detected, you can manually create them using the \"Add/edit related entities\" link in Related Entities. Important Currently, you can only manually create calls/called-by relationships between service entities. Tip To manage manual relationships, you need to have modify and delete capabilities on entity relationships. If you dont see the edit relationships button, contact your account admin. Which relationships are created? These are the relationships created between entities: Source: New Relic agent Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a New Relic agent CALLS Application instrumented with a New Relic agent Relationships between applications monitored by New Relic agents are reported using the DurationByCaller metric. The callee reports the metric. For example, the metric DurationByCaller/Mobile/100/1234/HTTP/all indicates that the caller is APPLICATION 1234 for account 100. Application instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent An application (caller) that calls a service (callee) monitored by New Relic creates a relationship that's reported by the caller using the ExternalApp metric. For example, the metric ExternalApp/dirac.vips.net/100#1234/all indicates that the callee is APPLICATION 1234 for account 100. The metric is reported if the callee successfully responds to the caller. Service instrumented with a New Relic agent CALLS Service instrumented with a New Relic agent When a New Relic agent detects that a service (caller) calls another service (callee) instrumented by New Relic, the callee reports the metric ClientApplication. For example, the metric ClientApplication/100#1234/all indicates that the caller is APPLICATION 1234 for account 100. Service instrumented with a New Relic agent CALLS A datastore instance When an application calls a datastore instance it creates a relationship reported with the DatastoreInstance metric. For example, the metric Datastore/instance/MySQL/172.16.16.3/3306 indicates the datastore instance is vendor: MySQL, host: 172.16.16.3, port: 3306. This metric also supports the legacy datastore instance format Datastore/instance/MySQL/172.16.16.3:3306. Currently we cannot determine whether the datastore instance is instrumented by New Relic and has an entity associated to it. APM agent SERVES Browser agent This relationship is created when an APM agent injects the Browser agent into a page. Workload entity CONTAINS Any entity When a workload is created or updated, relationships for each of the entities that belong to the workload are created. Because some workloads are dynamic (defined by tags), relationships are re-created every 5 minutes. This way entities can join or leave the workload. Source: Infrastructure Relationship source Relationship type Relationship target Why is the relationship created? Infrastructure host HOSTS Application This relationship is created when an application is running in one or more hosts, and the infra agent is running in those hosts. Infrastructure host HOSTS Container This relationship is created when containers are running in one or more hosts, and the host is instrumented with the infra agent. Source: Synthetics monitor Relationship source Relationship type Relationship target Why is the relationship created? Synthetics Monitor CALLS Browser agent This relationship is created when a synthetics monitor checks a page instrumented with the Browser agent. Synthetics Monitor CALLS APM application Agent events that contain the attribute nr.syntheticsMonitorId have been described as synthetics monitors (the source) interacting with an APM application (the target). If the header exists and the APM application Id exists, a relationship is created between the monitor and the app. Source: Kubernetes Relationship source Relationship type Relationship target Why is the relationship created? Cluster CONTAINS Pod This relationship is created when a pod is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Deployment This relationship is created when a deployment is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS DaemonSet This relationship is created when a DaemonSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS StatefulSet This relationship is created when a StatefulSet is created in a cluster instrumented with the New Relic Kubernetes integration. Cluster CONTAINS Host This relationship is created when a host that's part of a cluster is instrumented with the New Relic Kubernetes integration. Deployment CONTAINS Pod This relationship is created when a deployment creates a pod in a cluster instrumented with the New Relic Kubernetes integration. DaemonSet CONTAINS Pod This relationship is created when a DaemonSet is created a pod in a cluster instrumented with the New Relic Kubernetes integration. StatefulSet CONTAINS Pod This relationship is created when a StatefulSet creates a pod in a cluster instrumented with the New Relic Kubernetes integration. Pod CONTAINS Container This relationship is created when a pod creates a container in a cluster instrumented with the New Relic Kubernetes integration. Host HOSTS Pod This relationship is created when a pod is running in a host that's part of a cluster instrumented with the New Relic Kubernetes integration. Container HOSTS Application This relationship is created when an application is running in docker, and the hosts where docker is running are instrumented by the the infra agent. External services Relationship source Relationship type Relationship target Why is the relationship created? External service CALLS External service When the relationship is created, the external service reports a span with its name on the service.name attribute and the name of the service that initiates the call in the parent.service.name attribute. Application IS External service A relationship between an application and an external service is created so that users can navigate between them using the related entities component. Browser application instrumented with a New Relic agent CALLS External service A Browser application reports an Ajax/HostTransaction metric when calling an external service (URL). Example metric: Ajax/HostTransaction/api.segment.io:443/CallbackTime' Cluster CONTAINS External service When the relationship is created, the external service reports a span with the attribute k8s.cluster.name, the name of the cluster. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Pod HOSTS External service When the relationship is created, the external service reports a span with the following attributes: service.name: The name of the service. k8s.cluster.name: The name of the cluster. k8s.pod.name: The name of the pod thats running the service. k8s.namespace.name: The namespace where the pod was created. The cluster must be instrumented with the New Relic Kubernetes integration and the cluster name set for the integration must match the one reported in the span. Group and organize entities You can place entities into groups that reflect business-important relationships in your organization. For example, you might group all entities related to a specific team or department, or related to a specific service. Or you might group multiple hosts together to reflect their grouping in a data center. To group your entities, see: How to tag entities Create workloads (groups of related entities)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 75.83134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "What is an entity in <em>New</em> <em>Relic</em>?",
        "sections": "Source: <em>New</em> <em>Relic</em> <em>agent</em>",
        "tags": "<em>New</em> <em>Relic</em> One",
        "body": " account admin. Which relationships are created? These are the relationships created between entities: Source: <em>New</em> <em>Relic</em> <em>agent</em> Relationship source Relationship type Relationship target Why is the relationship created? Application instrumented with a <em>New</em> <em>Relic</em> <em>agent</em> CALLS Application instrumented"
      },
      "id": "603ec160e7b9d295f72a07fc"
    },
    {
      "sections": [
        "Introduction to New Relic APIs",
        "Tip",
        "NerdGraph (GraphQL)",
        "REST APIs by capability",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Telemetry APIs for core data types",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights",
        "Plugins",
        "See APIs in action"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-06-14T18:02:47Z",
      "updated_at": "2021-06-02T16:33:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Retrieve data from New Relic. Send data to New Relic. Adjust settings. This document provides examples and reference information for our API endpoints. For developer-focused content on how to use and customize New Relic, see developer.newrelic.com. Tip To use APIs and SDKs, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. NerdGraph (GraphQL) NerdGraph is New Relic's GraphQL-format API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To get started, see Introduction to NerdGraph. REST APIs by capability New Relic capabilities, like APM, infrastructure monitoring, or alerts, are often used together, and sometimes they overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Tip To learn more about different API key types, see Understand New Relic API keys. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The Browser API resources include: Resource Details Browser agent API Use the Browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To retrieve browser monitoring data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To retrieve infrastructure data, use the Query API. This API can also be used to retrieve subscription usage data. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android Unity REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To retrieve Mobile data from New Relic, use the Query API. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To retrieve synthetics event data, use the Query API. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Telemetry APIs for core data types We offer several APIs that allow you to get our core data types (metrics, logs, traces, and events) into New Relic without the use of an installed agent. Data type Description Trace API Send distributed tracing data to New Relic. Event API Send event data to New Relic. Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Log API Send your log data to New Relic. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage You can use the Query API to retrieve subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API To retrieve information about your New Relic partner account, sub-accounts, and users, use the Partner API. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing plans that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API To query your data using NRQL-format queries, you can use the Query API. Note that this API is deprecated and NerdGraph is preferred for querying your data. Dashboard API See the Insights Dashboard API. Plugins Use the REST API for New Relic plugins and the API Explorer to: Get a list of plugins, including their names, IDs, and GUIDs. List one or more plugin components, their output, and their metric timeslice data. Developers and New Relic partners can also use New Relic's Plugin API to write an agent in any language that can work directly with the API for plugins. This allows you to send your own metric data to our plugins and view data received from the API in New Relic. See APIs in action For more on how you as a developer can optimize your ability to solve problems using New Relic, go to developer.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 74.13632,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> <em>New</em> <em>Relic</em> APIs",
        "sections": "<em>Introduction</em> <em>to</em> <em>New</em> <em>Relic</em> APIs",
        "tags": "Intro <em>to</em> APIs",
        "body": ", an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying <em>New</em> <em>Relic</em> data and making a range of feature configurations. To get started, see <em>Introduction</em> to NerdGraph. REST APIs"
      },
      "id": "609fa5cf196a67066022b194"
    }
  ],
  "/docs/introduction-new-relic-mobile-unity": [
    {
      "sections": [
        "Introduction to New Relic APIs",
        "Tip",
        "NerdGraph (GraphQL)",
        "REST APIs by capability",
        "Alerts",
        "APM",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Synthetic monitoring",
        "Telemetry APIs for core data types",
        "Account management, admin, and usage APIs",
        "Other APIs",
        "Insights",
        "Plugins",
        "See APIs in action"
      ],
      "title": "Introduction to New Relic APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Get started",
        "Intro to APIs"
      ],
      "external_id": "01e9799a214baad5de04de6146483f6dbbc198aa",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/intro-apis/introduction-new-relic-apis/",
      "published_at": "2021-06-14T18:02:47Z",
      "updated_at": "2021-06-02T16:33:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic offers a variety of APIs and SDKs you can use to: Retrieve data from New Relic. Send data to New Relic. Adjust settings. This document provides examples and reference information for our API endpoints. For developer-focused content on how to use and customize New Relic, see developer.newrelic.com. Tip To use APIs and SDKs, as well as the rest of our observability platform, join the New Relic family! Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. NerdGraph (GraphQL) NerdGraph is New Relic's GraphQL-format API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph is the preferred API for querying New Relic data and making a range of feature configurations. To get started, see Introduction to NerdGraph. REST APIs by capability New Relic capabilities, like APM, infrastructure monitoring, or alerts, are often used together, and sometimes they overlap in functionality. This is why multiple APIs may be relevant to each area. Some API functionality will depend on your access to features and data. Tip To learn more about different API key types, see Understand New Relic API keys. Alerts Use the REST API for alerts and the API Explorer to: Create and manage policies, conditions, and notification channels. Create alert conditions based on NRQL queries. Create alert conditions based on data from other New Relic capabilities. APM API resources for application monitoring include: Resource Details REST API REST API features include: Retrieve APM data, including metrics, Apdex, error rates, and host data. Report deployments. Change the app name in the UI. Agent APIs Every APM language agent has an API that lets you customize the agent's default behavior, including reporting custom data. APM agent APIs include: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Python agent API Ruby agent API Query API To query APM data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Browser monitoring The Browser API resources include: Resource Details Browser agent API Use the Browser agent API for tasks such as: Report custom end user data to browser monitoring. Monitor asynchronous browser activity using SPA API calls. Insert custom data into New Relic dashboards . Manage source maps. REST API With the REST API you can: Retrieve page load timing data and throughput. Add or list apps monitored by browser monitoring. Manage alerts conditions for your browser data. Query API To retrieve browser monitoring data, use the Query API. Account management APIs For APIs related to accounts and subscription usage, see the account-related APIs. Infrastructure monitoring The Infrastructure API resources include: Resource Details Query API To retrieve infrastructure data, use the Query API. This API can also be used to retrieve subscription usage data. Infrastructure alert API To manage your infrastructure alerts, use the Infrastructure alert API. Integrations SDK To make your own custom integrations for reporting data to infrastructure monitoring, use the Integrations SDK. NerdGraph You can use NerdGraph (our GraphQL API) to query your cloud integration data and make changes to cloud integration settings. Mobile monitoring Mobile API resources include: Resource Details Mobile agent APIs Mobile APIs let you custom instrument your own code and send events to New Relic. See the platform-specific documentation: iOS Android Unity REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage New Relic alerts conditions for your mobile apps. Query API To retrieve Mobile data from New Relic, use the Query API. Account management APIs For account-related APIs, see Account APIs. Synthetic monitoring Synthetics API resources include: Resource Details Synthetics REST API The Synthetics REST API functionality includes: Create and manage synthetics monitors. Manage synthetics alert notifications. Add labels to monitors, and retrieve monitors with specific labels. Query API To retrieve synthetics event data, use the Query API. Alerts API To create and manage alert conditions that target synthetics monitors, use the Alerts API. Telemetry APIs for core data types We offer several APIs that allow you to get our core data types (metrics, logs, traces, and events) into New Relic without the use of an installed agent. Data type Description Trace API Send distributed tracing data to New Relic. Event API Send event data to New Relic. Metric API Send metrics to New Relic from any source (including other telemetry monitoring services). Log API Send your log data to New Relic. Account management, admin, and usage APIs Like any other New Relic product or service, you want to be confident that your APIs protect you and your customers' data privacy. The following are API resources related to New Relic account administration and usage. For more information about API capabilities, see the specific New Relic API. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. Resource Details REST API REST API features include: Find your API keys, account ID, and information needed to use the REST API. Return a list of account users (original user model only). Get SLA report data for browser and application monitoring. Subscription usage You can use the Query API to retrieve subscription usage data. This can be helpful to see how usage compares to your current subscription level, or for doing departmental chargebacks. Partner API To retrieve information about your New Relic partner account, sub-accounts, and users, use the Partner API. Other APIs Insights New Relic Insights was the name of our original product that governed custom event reporting and querying. The features associated with Insights have been rolled into our New Relic One platform (learn more), but there are still some APIs and original pricing plans that use the term \"Insights\" for these historical reasons. Insights-related APIs include: Resource Details Event API To report custom events, use the Event API. Query API To query your data using NRQL-format queries, you can use the Query API. Note that this API is deprecated and NerdGraph is preferred for querying your data. Dashboard API See the Insights Dashboard API. Plugins Use the REST API for New Relic plugins and the API Explorer to: Get a list of plugins, including their names, IDs, and GUIDs. List one or more plugin components, their output, and their metric timeslice data. Developers and New Relic partners can also use New Relic's Plugin API to write an agent in any language that can work directly with the API for plugins. This allows you to send your own metric data to our plugins and view data received from the API in New Relic. See APIs in action For more on how you as a developer can optimize your ability to solve problems using New Relic, go to developer.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 90.628944,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> <em>to</em> <em>New</em> <em>Relic</em> APIs",
        "sections": "<em>Introduction</em> <em>to</em> <em>New</em> <em>Relic</em> APIs",
        "tags": "Intro <em>to</em> APIs",
        "body": " documentation: iOS Android <em>Unity</em> REST API Use the REST API for such tasks as: Retrieve a list of monitored apps. Get subscription usage data. Get metric names and data. Get crash count and crash rate data. Manage <em>New</em> <em>Relic</em> alerts conditions for your <em>mobile</em> apps. Query API To retrieve <em>Mobile</em> data from"
      },
      "id": "609fa5cf196a67066022b194"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "fe6ba3196a927fb8dee72f8bf777461c95f7505c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-sdk-api-guide/",
      "published_at": "2021-06-14T21:38:56Z",
      "updated_at": "2021-06-03T12:15:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API for New Relic Mobile to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest New Relic Mobile SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges New Relic Mobile aggregates performance for various methods into summary metrics that appear in New Relic Mobile's Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic Mobile. - (void)myMethod { NR_TRACE_METHOD_START(0); //  existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your methods performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) //  existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your methods performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.13328,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> iOS",
        "body": "Use the iOS SDK API for <em>New</em> <em>Relic</em> <em>Mobile</em> to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your <em>mobile</em> app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically"
      },
      "id": "603eb3a2e7b9d264f02a07a8"
    },
    {
      "sections": [
        "iOS agent configuration and feature flags",
        "Tip",
        "Enable or disable feature flags",
        "Crash and error reporting feature flag",
        "NRFeatureFlag_CrashReporting",
        "NRFeatureFlag_HandledExceptionEvents",
        "Distributed tracing",
        "NRFeatureFlag_DistributedTracing",
        "Interactions feature flags",
        "NRFeatureFlag_DefaultInteractions",
        "NRFeatureFlag_InteractionTracing",
        "NRFeatureFlag_SwiftInteractionTracing",
        "Caution",
        "Networking feature flags",
        "NRFeatureFlag_ExperimentalNetworkingInstrumentation",
        "NRFeatureFlag_NSURLSessionInstrumentation",
        "NRFeatureFlag_NetworkRequestEvents",
        "NRFeatureFlag_RequestErrorEvents",
        "NRFeatureFlag_HttpResponseBodyCapture"
      ],
      "title": "iOS agent configuration and feature flags",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "8ced2dac1fbc45a65d6cdca6b27a4db001d6a4db",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-agent-configuration-feature-flags/",
      "published_at": "2021-06-14T21:39:52Z",
      "updated_at": "2021-06-03T12:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Mobile's iOS agent provides configuration settings to change the default behavior of the agent. If used, implement these flags just before calling: Objective-C: +[NewRelic startWithApplicationToken:] Swift: NewRelic.start(withApplicationToken:) Tip For an explanation of Mobile custom data types, see Add custom data to New Relic Mobile. Enable or disable feature flags To configure feature flags, use the following method defined in NewRelic.h: iOS language Procedure Objective-C In Objective-C, these features are bitmasked, so you can use a | to enable or disable multiple features at the same time. Enable a feature flag: +[NewRelic enableFeatures:(NRMAFeatureFlags)flags]; Copy Disable a feature flag: +[NewRelic disableFeatures:(NRMAFeatureFlags)flags]; Copy Here is an example where: Interaction tracing and experimental networking instrumentation are enabled. NSURLSession instrumentation and crash reporting are disabled. [NewRelic enableFeatures:NRFeatureFlag_SwiftInteractionTracing | NRFeatureFlag_ExperimentalNetworkingInstrumentation]; [NewRelic disableFeatures:NRFeatureFlag_NSURLSessionInstrumentation | NRFeatureFlag_CrashReporting]; [NewRelic startWithApplicationToken:...]; Copy Swift Enable a feature flag: NewRelic.enableFeatures(NRMAFeatureFlags.[NRMAFeatureFlag]) Copy Disable a feature flag: NewRelic.disableFeatures(NRMAFeatureFlags.[NRMAFeatureFlag]) Copy Example to disable interaction tracing: NewRelic.disableFeatures(NRMAFeatureFlags.NRFeatureFlag_DefaultInteractions) Copy Crash and error reporting feature flag If used, be sure to call the feature flag before the New Relic iOS agent start call. NRFeatureFlag_CrashReporting Enable (default) or disable crash reporting, which appears on New Relic Mobile's Crash analysis page. Type Boolean Default true NRFeatureFlag_HandledExceptionEvents Globally enable (default) or disable recording handled exceptions events, which appear on the Handled exception page. Type Boolean Default true Distributed tracing NRFeatureFlag_DistributedTracing Enable or disable the adding of distributed tracing headers to network requests. Refer to How New Relic distributed tracing works for more information on distributed tracing in mobile apps. Type Boolean Default true Interactions feature flags If used, be sure to call the feature flag before the New Relic iOS agent start call. NRFeatureFlag_DefaultInteractions Enable (default) or disable interaction tracing only for default instrumented classes and methods. Custom interactions will be reported. The traces will appear on the Mobile Interactions page. Type Boolean Default true NRFeatureFlag_InteractionTracing Globally enable (default) or disable interaction traces, which appear on the Mobile Interactions page. Interaction tracing will be disabled after the agent has started. Interactions for any activity or methods executed prior to starting the agent may still appear on the Interactions page. Type Boolean Default true NRFeatureFlag_SwiftInteractionTracing Caution Before enabling this feature, see Enable Swift interaction traces. If proper steps are not taken, enabling this feature may cause instability. Enable or disable (default) interaction tracing for Swift code. The traces appear on the Mobile Interactions page. This feature will always be disabled if NRFeatureFlag_InteractionTracing is disabled. Type Boolean Default false Networking feature flags If used, be sure to call the feature flag before the New Relic iOS agent start call. NRFeatureFlag_ExperimentalNetworkingInstrumentation Caution Enabling this feature flag call may decrease the stability of applications. Avoid using unless instructed by New Relic. Enable or disable (default) experimental networking instrumentation. This forces all NSURLConnection network requests through the NRMAURProtocol. Type Boolean Default false NRFeatureFlag_NSURLSessionInstrumentation Enable (default) or disable networking instrumentation for NSURLSession. These URL traces are sent to the HTTP Requests page. Type Boolean Default true NRFeatureFlag_NetworkRequestEvents Enable or disable (default) networking instrumentation. This sends the HTTP response data as MobileRequest events. Available for iOS Agent version 5.14.0 and higher Type Boolean Default true - Enabled by default as of 6.0.0 NRFeatureFlag_RequestErrorEvents Enable (default) or disable HTTP request error event generation of instrumented network calls that result in an error or failure. These events are reported as MobileRequestError events. Available for iOS Agent version 5.11.0 and higher Type Boolean Default true NRFeatureFlag_HttpResponseBodyCapture Enable or disable capture of HTTP response bodies for HTTP error traces, and MobileRequestError events. Type Boolean Default true",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.13326,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> iOS",
        "body": "<em>New</em> <em>Relic</em> <em>Mobile</em>&#x27;s iOS agent provides configuration settings to change the default behavior of the agent. If used, implement these flags just before calling: Objective-C: +[<em>NewRelic</em> startWithApplicationToken:] Swift: <em>NewRelic</em>.start(withApplicationToken:) Tip For an explanation of <em>Mobile</em> custom data"
      },
      "id": "60441925196a67324d960f1b"
    }
  ],
  "/docs/ios-device-id-obfuscation": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/attribute-dictionary/",
      "sections": [
        "New Relic data dictionary",
        "AjaxRequest",
        "AwsLambdaInvocation",
        "AwsLambdaInvocationError",
        "BrowserInteraction",
        "BrowserTiming",
        "ContainerSample",
        "DistributedTraceSummary",
        "InfrastructureEvent",
        "JavaScriptError",
        "Metric",
        "Mobile",
        "MobileCrash",
        "MobileHandledException",
        "MobileRequest",
        "MobileRequestError",
        "MobileSession",
        "NetworkSample",
        "NrAuditEvent",
        "NrConsumption",
        "NrDailyUsage",
        "NrIntegrationError",
        "NrMTDConsumption",
        "NrUsage",
        "PageAction",
        "PageView",
        "PageViewTiming",
        "ProcessSample",
        "Span",
        "StorageSample",
        "SyntheticCheck",
        "SyntheticRequest",
        "SyntheticsPrivateLocationStatus",
        "SyntheticsPrivateMinion",
        "SystemSample",
        "Transaction",
        "TransactionError",
        "WorkloadStatus"
      ],
      "published_at": "2021-06-16T01:47:26Z",
      "title": "New Relic data dictionary",
      "updated_at": "2021-06-16T01:47:25Z",
      "type": "docs",
      "external_id": "cbca3a897621bcbb31159067d6d4ec27c5178fe4",
      "document_type": "views_page_content",
      "popularity": 1,
      "body": "Displaying 0 of 37 results Clear AjaxRequest Data source : Browser agent An AjaxRequest event is created automatically when an Ajax request occurs during a BrowserInteraction event. The event attributes track geographic and browser info. Attribute name Definition Events appId ID The ID of your application, as recorded by New Relic. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserInteractionName The name of the interaction. This is either the targetGroupedUrl or the custom name set via the API. AjaxRequest BrowserInteraction BrowserTiming city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView eventId ID A value that you can link to multiple BrowserInteraction events so you can view the interactions that occurred surrounding a specific event. For example, you can see the browser interactions that occurred prior to a JS error. AjaxRequest BrowserInteraction BrowserTiming groupedPageURL The grouped URL of the view that made the AJAX request. For example: myapp.com/acct/*/dash. AjaxRequest BrowserTiming groupedRequestUrl The grouped URL of the AJAX request. For example: myapp.com/acct/*/ajax. AjaxRequest Span hostname The fully qualified domain name (FQDN) of the request URL. AjaxRequest httpMethod enum The HTTP method of the AJAX request. Example: POST. AjaxRequest httpResponseCode enum The HTTP response code. Example: 200. AjaxRequest jsDuration seconds (s) The total duration, in seconds, spent on JavaScript execution. (This attribute doesn't exist for initial page load events.) AjaxRequest BrowserInteraction BrowserTiming pageUrl The URL of the page that was loaded for the PageView. For example: http://www.newrelic.com. This URL does not include query parameters. AjaxRequest BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError port enum The request port. AjaxRequest Span priority Likelihood this event will be saved. AjaxRequest regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming requestBodySize bytes (B) The payload size of the request body, in bytes. AjaxRequest requestUrl The URL of the AJAX request. For example: myapp.com/acct/1/ajax. AjaxRequest responseBodySize bytes (B) The payload size of the response body, in bytes. AjaxRequest session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span timeSinceBrowserInteractionStart seconds (s) The time in seconds between the start of the BrowserInteraction and the start of the request. AjaxRequest BrowserTiming timeToLastCallbackEnd seconds (s) The duration, in seconds, from the start of the request (timestamp) to the end of the last callback. This is not just an additive function; the callback time can overlap with the wait time. AjaxRequest BrowserTiming timeToLoadEventStart seconds (s) The time, in seconds, from the start of the AJAX request to the start of its load event. This value represents the duration of the AJAX request with single page app (SPA) monitoring. For more information, see the Mozilla developer documentation about XMLHttpRequest load events. AjaxRequest timeToSettle seconds (s) The time, in seconds, from the start of the request to when all resulting callbacks (including callbacks of subsequent AJAX requests) are complete. AjaxRequest BrowserTiming timestamp The time (date, hour, minute, second) at which the interaction occurred. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming Span userAgentName The browsers name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browsers reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browsers reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming AwsLambdaInvocation Data source : AWS Lambda This event is reported by New Relic monitoring for AWS Lambda. This event captures overall function timing and associated metadata. A single AwsLambdaInvocation event is generated for each invocation. Attribute name Definition Events aws.lambda.arn The Amazon Resource Name (ARN) of the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.coldStart A Boolean indicating if the AWS Lambda invocation is a cold start. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.eventSource.arn The Amazon Resource Name (ARN) of the entity that invoked the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.requestId ID AWS identifier of the invocation. AwsLambdaInvocation AwsLambdaInvocationError databaseCallCount count The number of database calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError databaseDuration seconds (s) The database response time in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError duration seconds (s) The total invocation time for the transaction, in seconds. (Data source: AWS Lambda) AwsLambdaInvocation AwsLambdaInvocationError externalCallCount count The number of external calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError externalDuration seconds (s) The total response time of all external (out-of-process) services, in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError newRelic.ingestPoint Where the data point entered the platform (such as browser.spans, or api.traces). AwsLambdaInvocation AwsLambdaInvocationError Span parent.account ID If a distributed tracing payload is received, this is the account identifier for the transaction's upstream caller. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.app ID If a distributed tracing payload is received, this is the application identifier. APM agents retrieve this value in the connect response under the key primary_application_id. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.transportType When a distributed tracing payload is received, the method of transport for the payload. Example values: Unknown, HTTP, HTTPS, Kafka, JMS, IronMQ, AMQP, Queue, or Other. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.type If a distributed trace payload was received, the parent's data source type. Example values: App, Browser, Mobile. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.accept The types as read from the HTTP Accept request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentLength bytes (B) Incoming request size in bytes as read from the Content-Length HTTP request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentType Incoming request content-type as read from the HTTP request header Content-Type. Example value: application/octet-stream. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.host The name from the HTTP host request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.referer The incoming request referer as read from the Referer request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.userAgent The contents of the User-Agent HTTP header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.method The HTTP request method used. Example values: POST, GET. AwsLambdaInvocation AwsLambdaInvocationError Span Transaction TransactionError response.headers.contentLength bytes (B) The outgoing response size in bytes as read from the Content-Length response header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError response.headers.contentType For an HTTP response, the data type of the returned response. Example values: text/html, application/json. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError response.status bytes (B) The response code for an HTTP request AwsLambdaInvocation totalTime seconds (s) The sum of all async components' duration, in seconds. An async component is a method or function where there is no instrumented encapsulating method or function. AwsLambdaInvocation Transaction traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span type The New Relic event type. Example values: Transaction, Span. AwsLambdaInvocation AwsLambdaInvocationError AwsLambdaInvocationError Data source : AWS Lambda This event is reported by New Relic monitoring for AWS Lambda. It's generated when an error occurs during a Lambda function invocation. Attribute name Definition Events aws.lambda.arn The Amazon Resource Name (ARN) of the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.coldStart A Boolean indicating if the AWS Lambda invocation is a cold start. AwsLambdaInvocation AwsLambdaInvocationError aws.lambda.eventSource.arn The Amazon Resource Name (ARN) of the entity that invoked the instrumented Lambda function. AwsLambdaInvocation AwsLambdaInvocationError aws.requestId ID AWS identifier of the invocation. AwsLambdaInvocation AwsLambdaInvocationError databaseCallCount count The number of database calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError databaseDuration seconds (s) The database response time in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError duration seconds (s) The total invocation time for the transaction, in seconds. (Data source: AWS Lambda) AwsLambdaInvocation AwsLambdaInvocationError error.class The class name or type for the error. This will be server and platform specific. AwsLambdaInvocationError TransactionError error.message The error message for the transaction. This will be server and platform specific. AwsLambdaInvocationError TransactionError externalCallCount count The number of external calls made by this transaction. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError externalDuration seconds (s) The total response time of all external (out-of-process) services, in seconds. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError newRelic.ingestPoint Where the data point entered the platform (such as browser.spans, or api.traces). AwsLambdaInvocation AwsLambdaInvocationError Span parent.account ID If a distributed tracing payload is received, this is the account identifier for the transaction's upstream caller. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.app ID If a distributed tracing payload is received, this is the application identifier. APM agents retrieve this value in the connect response under the key primary_application_id. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.transportType When a distributed tracing payload is received, the method of transport for the payload. Example values: Unknown, HTTP, HTTPS, Kafka, JMS, IronMQ, AMQP, Queue, or Other. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError parent.type If a distributed trace payload was received, the parent's data source type. Example values: App, Browser, Mobile. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.accept The types as read from the HTTP Accept request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentLength bytes (B) Incoming request size in bytes as read from the Content-Length HTTP request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.contentType Incoming request content-type as read from the HTTP request header Content-Type. Example value: application/octet-stream. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.host The name from the HTTP host request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.referer The incoming request referer as read from the Referer request header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.headers.userAgent The contents of the User-Agent HTTP header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError request.method The HTTP request method used. Example values: POST, GET. AwsLambdaInvocation AwsLambdaInvocationError Span Transaction TransactionError response.headers.contentLength bytes (B) The outgoing response size in bytes as read from the Content-Length response header. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError response.headers.contentType For an HTTP response, the data type of the returned response. Example values: text/html, application/json. AwsLambdaInvocation AwsLambdaInvocationError Transaction TransactionError stackTrace The error stack trace. The format will be different depending on the agent language. AwsLambdaInvocationError traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span transactionName Name of the transaction in which the error occurred. Example value: Controller/customers/show. Value may be 'Unknown' if an error occurs outside of a transaction. AwsLambdaInvocationError TransactionError type The New Relic event type. Example values: Transaction, Span. AwsLambdaInvocation AwsLambdaInvocationError BrowserInteraction Data source : Browser agent A BrowserInteraction represents a unit of work in a browser session, triggered by a user interacting with the webpage. It captures information about the session, AJAX calls and custom JavaScript timing that occurred as a result of the interaction. Initial load and route changes are captured as special types of Browser interactions, and are used for SPA monitoring. Attribute name Definition Events actionText The text of the HTML element that was clicked when a browser interaction started. BrowserInteraction ajaxCount count A count of all XHRs included in the timing of a SPA interaction. BrowserInteraction appId ID The ID of your application, as recorded by New Relic. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming backendTransactionName The name of the backend transaction that served the initial page load. BrowserInteraction browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserInteractionName The name of the interaction. This is either the targetGroupedUrl or the custom name set via the API. AjaxRequest BrowserInteraction BrowserTiming category The type of interaction; either initial page load, route change, or custom. BrowserInteraction city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView domain The domain portion of the request URL. BrowserInteraction JavaScriptError PageView PageViewTiming duration seconds (s) The total time elapsed of the interaction event BrowserInteraction eventId ID A value that you can link to multiple BrowserInteraction events so you can view the interactions that occurred surrounding a specific event. For example, you can see the browser interactions that occurred prior to a JS error. AjaxRequest BrowserInteraction BrowserTiming firstContentfulPaint firstContentfulPaint is the point when the browser renders the first bit of content from the DOM, which may be text, an image, SVG, or a <canvas> element. Google's User-centric Performance Metrics contains detailed information about its Paint Timing API and firstContentfulPaint. See Compatibility and requirements for New Relic Browser for additional information about firstContentfulPaint browser compatibility. BrowserInteraction PageView firstPaint firstPaint marks the point when the browser renders anything that is visually different from what was on the screen prior to navigation. This includes non-default background paint and the enclosing box of an iframe. Google's User-centric Performance Metrics contains detailed information about its Paint Timing API and firstPaint. See Compatibility and requirements for New Relic Browser for additional information about firstPaint browser compatibility. BrowserInteraction PageView jsDuration seconds (s) The total duration, in seconds, spent on JavaScript execution. (This attribute doesn't exist for initial page load events.) AjaxRequest BrowserInteraction BrowserTiming monitorAccountId The Synthetics account from which you are running the monitor. BrowserInteraction JavaScriptError monitorId ID A unique number identifying a particular monitor. BrowserInteraction JavaScriptError SyntheticCheck monitorJobId ID The ID of a single Synthetics monitor run, which began at a specific time and originated from a specific location. BrowserInteraction JavaScriptError parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError previousGroupedUrl The grouped version of the URL in the browser at the start of the interaction. BrowserInteraction previousRouteName The route name of the page at the start of the interaction. This is the last value passed by setCurrentRouteName before the start of the interaction. BrowserInteraction previousURL The ungrouped URL in the browser at the start of the interaction. BrowserInteraction regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span targetGroupedUrl The grouped version of the URL in the browser at the end of the interaction. BrowserInteraction targetRouteName The route name for the page at the end of the interaction. The last value passed by setCurrentRouteName before the end of the interaction. BrowserInteraction targetUrl The ungrouped URL in the browser at the end of the interaction. BrowserInteraction timeToConnectEnd seconds (s) The time, in seconds, from the start of the interaction to the connectEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToConnectStart seconds (s) The time, in seconds, from the start of the interaction to the connectStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomComplete seconds (s) The time, in seconds, from the start of the interaction to the domComplete, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomContentLoadedEventEnd seconds (s) The time, in seconds, from the start of the interaction to the domContentLoadedEventEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomContentLoadedEventStart seconds (s) The time, in seconds, from the start of the interaction to the domContentLoadedEventStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomInteractive seconds (s) The time, in seconds, from the start of the interaction to the domInteractive, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomLoading seconds (s) The time, in seconds, from the start of the interaction to the domLoading, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomainLookupEnd seconds (s) The time, in seconds, from the start of the interaction to the domainLookupEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToDomainLookupStart seconds (s) The time, in seconds, from the start of the interaction to the domainLookupStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToFetchStart seconds (s) The time, in seconds, from the start of the interaction to the fetchStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToLoadEventEnd seconds (s) The time, in seconds, from the start of the interaction to the loadEventEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToLoadEventStart seconds (s) The time, in seconds, from the start of the interaction to the loadEventStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information, see our documentation about instrumentation for the Navigation Timing API. BrowserInteraction timeToRedirectEnd seconds (s) The time, in seconds, from the start of the interaction to the redirectEnd, as defined by the Navigation Timing API. This attribute exists only for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToRedirectStart seconds (s) The time, in seconds, from the start of the interaction to the redirectStart, as defined by the Navigation Timing API. This attribute exists only for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToRequestStart seconds (s) The time, in seconds, from the start of the interaction to the requestStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToResponseEnd seconds (s) The time, in seconds, from the start of the interaction to the responseEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToResponseStart seconds (s) The time, in seconds, from the start of the interaction to the responseStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToSecureConnectionStart seconds (s) The time, in seconds, from the start of the interaction to the secureConnectionStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToUnloadEventEnd seconds (s) The time, in seconds, from the start of the interaction to the unloadEventEnd, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timeToUnloadEventStart seconds (s) The time, in seconds, from the start of the interaction to the unloadEventStart, as defined by the Navigation Timing API. This attribute exists for initial page load events, not route changes. For more information about the Navigation Timing API, see Instrumentation for Browser monitoring. BrowserInteraction timestamp The time (date, hour, minute, second) at which the interaction occurred. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming Span trigger The cause of the route change or page load. The default values are click, submit, popstate, or initial page load. For a custom event created with the API, the default value for trigger will be api. This value can also be set via the API. BrowserInteraction userAgentName The browsers name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browsers reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browsers reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming BrowserTiming Data source : Browser agent BrowserTiming is a custom event that captures SPA timing data for browser interactions started using the custom createTracer SPA API method. BrowserTiming contains many of the same attributes used by other events, especially AjaxRequest. Attribute name Definition Events appId ID The ID of your application, as recorded by New Relic. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserInteractionName The name of the interaction. This is either the targetGroupedUrl or the custom name set via the API. AjaxRequest BrowserInteraction BrowserTiming browserTimingName The name of the event. This is taken from the name argument of createTracer. BrowserTiming city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView eventId ID A value that you can link to multiple BrowserInteraction events so you can view the interactions that occurred surrounding a specific event. For example, you can see the browser interactions that occurred prior to a JS error. AjaxRequest BrowserInteraction BrowserTiming groupedPageURL The grouped URL of the view that made the AJAX request. For example: myapp.com/acct/*/dash. AjaxRequest BrowserTiming jsDuration seconds (s) The total duration, in seconds, spent on JavaScript execution. (This attribute doesn't exist for initial page load events.) AjaxRequest BrowserInteraction BrowserTiming pageUrl The URL of the page that was loaded for the PageView. For example: http://www.newrelic.com. This URL does not include query parameters. AjaxRequest BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span timeSinceBrowserInteractionStart seconds (s) The time in seconds between the start of the BrowserInteraction and the start of the request. AjaxRequest BrowserTiming timeToLastCallbackEnd seconds (s) The duration, in seconds, from the start of the request (timestamp) to the end of the last callback. This is not just an additive function; the callback time can overlap with the wait time. AjaxRequest BrowserTiming timeToSettle seconds (s) The time, in seconds, from the start of the request to when all resulting callbacks (including callbacks of subsequent AJAX requests) are complete. AjaxRequest BrowserTiming timeToTracedCallbackStart seconds (s) The time in seconds from the start of the custom tracer until the start of the traced callback. This attribute is unique to the BrowserTiming event. BrowserTiming timestamp The time (date, hour, minute, second) at which the interaction occurred. AjaxRequest BrowserInteraction BrowserTiming PageAction PageView PageViewTiming Span tracedCallbackDuration seconds (s) The duration in seconds of the traced callback. This attribute is unique to the BrowserTiming event. BrowserTiming userAgentName The browsers name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browsers reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browsers reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming ContainerSample Data source : Infrastructure This event is reported by the New Relic Infrastructure agent. It collects data from all the Docker containers on the host (which may or may not be running). It includes the container's ID, name, image, image name, and metrics about CPU, memory and networking. We take a snapshot of this data every 15 seconds for each container and package it into this event, which is then sent to New Relic. This data appears on the Containers UI page. Attribute name Definition Events StorageDataAvailableBytes bytes (B) Data space available in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageDataTotalBytes bytes (B) Total Data space in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageDataUsagePercent percentage (%) Percent of Data space used in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageDataUsedBytes bytes (B) Data space used by the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataAvailableBytes bytes (B) Metadata space available in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataTotalBytes bytes (B) Total Metadata space in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataUsagePercent percentage (%) Percent of Metadata space used in the Storage Driver. Only Device Mapper driver is supported. ContainerSample StorageMetadataUsedBytes bytes (B) Metadata space used by the Storage Driver. Only Device Mapper driver is supported. ContainerSample commandLine The command line used in the container. ContainerSample containerId ID The unique Docker container ID. ContainerSample cpuKernelPercent percentage (%) CPU time percentage used in kernel space. ContainerSample cpuLimitCores count Number of cores available for the container. ContainerSample cpuPercent percentage (%) CPU usage percentage used. ContainerSample cpuShares count Number of CPU shares assigned to the container. ContainerSample cpuThrottlePeriods count Total number of periods throttled. ContainerSample cpuThrottleTimeMs milliseconds (ms) Total throttling time in milliseconds. ContainerSample cpuUsedCores percentage (%) CPU usage per core. ContainerSample cpuUsedCoresPercent percentage (%) CPU usage percentage per core. ContainerSample cpuUserPercent percentage (%) CPU time percentage used in user space. ContainerSample criticalViolationCount count The number of times that alert conditions violated critical thresholds, causing critical violations and opening incidents. If this attribute does not exist on the sample, it has zero violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample image ID The Docker image ID for the image the container is based on. ContainerSample imageName The Docker image name for the container. ContainerSample label_KEY Docker labels associated with this container (where KEY represents a custom label's key value). ContainerSample memoryCacheBytes count The amount of memory used by the container that can be associated precisely with a block on a block device. ContainerSample memoryKernelUsageBytes bytes (B) The amount of current kernel memory allocation. ContainerSample memoryResidentSizeBytes bytes (B) The amount of memory that doesn't correspond to anything on disk: stacks, heaps, and anonymous memory maps. ContainerSample memorySizeLimitBytes bytes (B) The total amount of memory the container is allowed to use. ContainerSample memorySoftLimitBytes bytes (B) The soft limit of memory usage equivalent to the memory reservation of the container. ContainerSample memorySwapLimitBytes bytes (B) The total amount of memory the container is using, including swap. ContainerSample memorySwapLimitUsagePercent percentage (%) This metric is calculated as the percentage of memorySwapUsageBytes over memorySwapLimitBytes, if the limit exists. ContainerSample memorySwapOnlyUsageBytes bytes (B) The amount of swap memory the container is using. This memory doesn't include non-swap memory. ContainerSample memorySwapUsageBytes bytes (B) The amount of memory swap the container is using, including swap. ContainerSample memoryUsageBytes bytes (B) This metric doesn't account for swap usage. ContainerSample memoryUsageLimitPercent percentage (%) This metric is calculated as the memoryUsageBytes percentage over memorySizeLimitBytes, if the limit exists. ContainerSample name The Docker container name. ContainerSample networkRxBytes bytes (B) Total number of received bytes. ContainerSample networkRxBytesPerSecond rate Number of received bytes per second. ContainerSample networkRxDropped count Total number of received packets dropped. ContainerSample networkRxDroppedPerSecond rate Number of received packets dropped per second. ContainerSample networkRxError count Total number of received packets with error. ContainerSample networkRxErrorsPerSecond rate Number of received packets with error per second. ContainerSample networkRxPackets count Total number of received packets. ContainerSample networkRxPacketsPerSecond rate Number of received packets with error per second. ContainerSample networkTxBytesPerSecond rate Number of transmitted bytes per second. ContainerSample networkTxDropped count Total number of transmitted packets dropped. ContainerSample networkTxDroppedPerSecond rate Number of transmitted packets dropped per second. ContainerSample networkTxErrors count Total number of transmitted packets with error. ContainerSample networkTxErrorsPerSecond rate Number of transmitted packets with error per second. ContainerSample networkTxPackets count Total number of transmitted packets. ContainerSample networkTxPacketsPerSecond rate Number of transmitted packets per second. ContainerSample networksTxBytes count Total number of bytes transmitted. ContainerSample restartCount count The number of times the container was restarted. ContainerSample state It can be: created, restarting, running, removing, paused, exited, or dead. ContainerSample status Holds the current container state. ContainerSample warningViolationCount count The number of times that alert conditions violated warning thresholds, causing warning violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample DistributedTraceSummary Data source : Distributed Tracing This event contains summary data about a distributed trace and provides an aggregated view of distributed tracing data. DistributedTraceSummary events are generated by New Relic and are triggered by distributed tracing data from agents or the Trace API. Attribute name Definition Events accountIds A comma delimited list of newrelic accountIds that took part in this trace. DistributedTraceSummary backend.duration.ms milliseconds (ms) The total elapsed time in milliseconds of all backend services in this trace. DistributedTraceSummary backend.timestamp milliseconds (ms) The timestamp of the first span in this trace from a backend entity. In distributed tracing, any events that are not from client-side applications contributed to the backend duration. DistributedTraceSummary duration.ms The duration of the entire distributed trace, including both backend and client-side entities. the earliest span to the latest. DistributedTraceSummary entityCount count The number of unique entities that took part in this trace. DistributedTraceSummary entityGuids A comma delimited list of entity GUIDs for entities that participated in this trace. These GUIDs are assigned by New Relic for the New Relic-monitored entity (host, application, etc.). Each GUID is stored as a Base64 encoded value. DistributedTraceSummary errorCount count The number of events in this distributed trace that were identified as errors. DistributedTraceSummary newRelic.traceFilter.type The name of the trace filter used by the Infinite Tracing trace observer to select this trace. DistributedTraceSummary Span root.entity.accountId The New Relic account ID that the root entity of this trace reports data to. DistributedTraceSummary root.entity.guid The entity GUID associated with the root entity of this trace. DistributedTraceSummary root.entity.name The name of the root entity of this trace. DistributedTraceSummary root.span.duration.ms milliseconds (ms) The elapsed time in milliseconds of the root span of this trace. The root of a distributed trace is the first span, and will have a null value for parent.id. DistributedTraceSummary root.span.id The unique identifier of the root span of this trace. The root of a distributed trace is the first span, and it has a null value for parent.id. DistributedTraceSummary root.span.name The name of the root span of this trace. DistributedTraceSummary root.span.timestamp milliseconds (ms) The timestamp of the root span of this trace. The root of a distributed trace is the first span, and will have a null value for parent.id. DistributedTraceSummary spanCount count The number of events in this distributed trace. Events in a distributed trace can have several event types, including Span, Transaction, and TransactionError. DistributedTraceSummary timestamp milliseconds (ms) The timestamp of the root span in this distributed trace. DistributedTraceSummary trace.id ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. DistributedTraceSummary MobileRequest MobileRequestError Span Transaction TransactionError InfrastructureEvent Data sources : InfrastructureCloudTrail InfrastructureEvent describes changes (deltas) that occur in a system's live state. When an inventory or system state is added, removed, or changed, Infrastructure will produce an InfrastructureEvent that logs that activity. Attribute name Definition Events category A New Relic category used to organize events in the UI. For example: automation, notification, and service. InfrastructureEvent changeType A simple classification of the type of change made to the entity: added, modified, or removed. InfrastructureEvent changedPath The fully specified name of the item that changed. This is constructed by taking the source and adding one or more additional path elements that uniquely identify the item that changed. InfrastructureEvent deltaId Delta refers to a recorded change in the system. The deltaId is a number used by New Relic to organize incoming inventory change data. InfrastructureEvent eventId The unique ID of the event, generated by New Relic. InfrastructureEvent format The type of infrastructure event. Each format type includes attributes that may be used to render the event in the UI. InfrastructureEvent newStatus The new agent status: disconnected or connected. InfrastructureEvent newValue If a change is made to the entity, this attribute contains the new value of the inventory that was changed. This will have no value if no change has been made. The value will display approximately 4K bytes of data. InfrastructureEvent oldValue If a change is made to the entity, this attribute contains the old value of the inventory that was changed. This will be blank if no change has been made. InfrastructureEvent provider For integrations that use generic event types (like the DatastoreSample event), the provider value specifies the source of the data (the service, or a sub-category of data from that service). Some Insights events are generic and are used by several integrations. For example, the DatastoreSample event is used by several integrations, including the AWS DynamoDB integration and the AWS RDS integration. In these cases, the provider attribute value represents the source of that attribute. This will usually be the service that data comes from or, for integrations that use several provider values, a certain sub-category of data from that service. When a provider value is present for a generic event, that event will have additional integration-specific attributes attached to it. Heres an example of an Insights NRQL query that returns the attributes present for a DatastoreSample event reported by the AWS RDS integration: SELECT * from DatastoreSample where provider = 'RdsDbCluster' InfrastructureEvent source The fully specified origin of this inventory item. This is typically in the form category/plugin, where plugin is the generic word used for the tool that gathered this data. InfrastructureEvent summary A summary of the change that happened. Uses a human-friendly string, such as Agent disconnected. InfrastructureEvent violationUpdateType The type of change to the violation: For example: open or closed. InfrastructureEvent JavaScriptError Data source : Browser agent As JavaScript errors are triggered, we capture details as events. The JavaScriptError event contains information to help you segment errors to understand how they impact performance. Attribute name Definition Events appId ID The identification number for the reporting browser agent. JavaScriptError appName The name of the application that handled the request as shown in New Relic Browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnLatitude The latitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's latitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnLongitude The longitude of the geographic center of the postal code where the Autonomous System Network is registered. This is not the end user's longitude. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming asnOrganization The organization that owns the Autonomous System Number. Often an ISP, sometimes a private company or institution. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming browserInteractionId ID A unique value generated for each browser interaction captured by the New Relic agent. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError browserStackHash ID An unique identifier generated for a stack trace. The browserStackHash for a stack trace is different across different browsers. An identical stack trace will generate the same identifier. JavaScriptError city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the browser initiated the page load. For a list of country codes, see ISO 3166-1 alpha-2. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming deviceType The type of device that loaded the page: mobile, tablet, or desktop. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageView domain The domain portion of the request URL. BrowserInteraction JavaScriptError PageView PageViewTiming entityGuid The unique identifier of the monitor referenced in New Relic One. JavaScriptError SyntheticCheck SyntheticRequest errorClass The error type of the JavaScript Error object. Examples: ReferenceError, SyntaxError, and UncaughtException. JavaScriptError errorMessage The error message that was delivered. JavaScriptError firstErrorInSession A value to indicate whether or not this was the first JS error in the session. Example: true. JavaScriptError monitorAccountId The Synthetics account from which you are running the monitor. BrowserInteraction JavaScriptError monitorId ID A unique number identifying a particular monitor. BrowserInteraction JavaScriptError SyntheticCheck monitorJobId ID The ID of a single Synthetics monitor run, which began at a specific time and originated from a specific location. BrowserInteraction JavaScriptError pageUrl The URL of the page that was loaded for the PageView. For example: http://www.newrelic.com. This URL does not include query parameters. AjaxRequest BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span parentEventId ID A unique value generated for each interaction with the page. You can use this value to group interactions together. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError regionCode The specific administrative division within a country where the PageView event occurred. In the United States, regions correspond to state codes, such as WA or NY. Outside the United States, a country's regions correspond to numerical codes. In the United States, regions correspond to state codes ; for example, WA or NY. Outside the United States, a country's regions correspond to numerical codes . AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming releaseIds ID The releases in which the app was updated. Example: {\\\"jQuery\\\":\\\"v3.1.1\\\",\\\"multiverse\\\":\\\"96e9ac7\\\"}. JavaScriptError requestUri The URI of the requested resource. JavaScriptError session A unique identifier for a single session. The session cookie expires when the user closes the browser (for example, they fully exit Chrome.) A new session identifier will be assigned when the user opens up a new instance of the browser. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Span stackHash ID A unique identifier generated by the Browser agent for a stack trace. The stackHash for a stack trace is the same across different browsers. An identical stack trace will generate the same identifier. JavaScriptError stackTrace A collection of the active stack frames when the error occurred. JavaScriptError stackTraceGzip A compressed version of the stackTrace attribute. JavaScriptError timestamp The time that the error occurred, in Unix time. JavaScriptError transactionName The full metric name of the transaction in which the error occurred, or Unknown if the error occurs outside of a transaction. JavaScriptError userAgentName The browsers name, such as Chrome and Firefox, obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentOS The browsers reported operating system, such as Windows or Linux, that it is running on. This is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming userAgentVersion The browsers reported software version, which is obtained from the User-Agent header of an HTTP request. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError PageAction PageView PageViewTiming Metric Data source : Metrics Represents a metric data point (e.g., a measurement over a range of time, or a sample at a specific point in time) with multiple attributes attached, which allow for in-depth analysis and querying. This metric data comes from our Metric API, our Telemetry SDKs, and some of our open-source exporters/integrations. Attribute name Definition Events endTimestamp milliseconds (ms) The end of the time range associated with the metric, in Unix time, in milliseconds. This is calculated by adding the metric interval to the timestamp of the metric (timestamp + interval.ms). Metric interval.ms milliseconds (ms) The length of the time window. Metric metricName Name of the metric. Metric newrelic.source The source of this data. For example: metricAPI. Metric timestamp milliseconds (ms) The start time for the metric in Unix time, in milliseconds. Metric Mobile Data source : Mobile A Mobile event is created when a crash occurs, when an interaction ends or has run for 1 second, or if a session completes after the app is closed, backgrounded, or has run for 10 minutes. Mobile events were once the only event type and were generated for every event, but now there are several specialized event types. Recommendation: Upgrade to the most recent New Relic Mobile agent version to take full advantage of the new event types. Attribute name Definition Events category The type of data, either session or interaction. Mobile MobileSession interactionDuration For interaction category events only. This is the total time for the interaction to render on the device. In addition to render time, this usually includes all external calls associated with the interaction. Currently, this attribute is measured in seconds for Android devices and in milliseconds for iOS devices. Mobile name For interaction category events only. This is the label of the interaction associated with the event. It is by default assigned by New Relic. For example: ApplicationsListFragment or Display iOS_Example.MasterViewController. Mobile reportedTimestampMs For interaction category events only. The UTC based timestamp for when the event was sent to New Relic. This is different from the attribute timestamp, which is when the event began. Mobile MobileCrash Data source : Mobile The MobileCrash event is created when an app crashes. MobileCrash includes attributes such as crash line number, class, and crash message. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appToken The mobile application license token. MobileCrash appVersion The version number of the monitored app. For example: 2.2.9. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession architecture The processor architecture of the device. For example: armv7 or arm64. MobileCrash asnOwner The telecom owner of the ASN. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession bundleId ID The unique string used to identify the application. MobileCrash MobileSession carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession crashException The exception associated with the crash, if one is present. For example: java.lang.NullPointerException. MobileCrash crashFingerprint ID The New Relic-generated fingerprint used to uniquely identify the crash and other crashes identical to this one. MobileCrash crashLocationFile The file in which the crash occurred. MobileCrash crashMessage The message associated with the crash, if one is present. MobileCrash deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceName The device's name. MobileCrash deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession diskAvailable bytes (B) Space available on the device, in bytes. MobileCrash interactionHistory The client interactions with the application that led to the crash. MobileCrash isFirstOccurrence A boolean value indicating whether or not this was the first occurrence of the crash. MobileCrash lastInteraction The last interaction before a crash or harvest event, if one is present. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession modelNumber The model of the device. This is the same as the session-level deviceModel attribute. MobileCrash networkStatus The type of network that the device was on at the time of crash, such as wifi or LTE. MobileCrash newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession occurrenceId ID The ID for this instance of the crash. MobileCrash orientation The orientation of the device, such as landscape or portrait. MobileCrash osBuild For Android only. The specific build of the Android OS. MobileHandledException MobileCrash osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession parentProcess The parent process that launched the crashing process. MobileCrash parentProcessId ID The parent identification number (PID) of the parent process. MobileCrash platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession processId ID The PID of the previously running process on the device. MobileCrash processName The name of the previously running process. MobileCrash processPath The path to the binary. MobileCrash reportedTimestampMs The UTC timestamp for when the event was received by New Relic. (This is different from timestamp, which is when the MobileSession event began that crashed.) MobileCrash runTime For Android only. The Android Runtime version where the exception/crash was generated. MobileHandledException MobileCrash sessionCrashed A boolean value indicating whether or not that session crashed. MobileCrash MobileSession sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession symbolicated A boolean value indicating whether or not the crash was properly symbolicated. MobileCrash timeSinceLastInteraction milliseconds (ms) The time, in milliseconds, since the interaction before a crash event. MobileCrash userImageUuids ID The array of build UUIDs for applications and libraries. MobileCrash uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession MobileHandledException Data source : Mobile MobileHandledException is sent when an exception is caught and is used for non-fatal exceptions reported to New Relic using the recordHandledException API for Android or iOS. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession exceptionAppBuildUuid ID The build uuid of the application binary in which the exception was caught. MobileHandledException exceptionCause The unsymbolicated, platform-specific cause of the exception. MobileHandledException exceptionLocation New Relic defined location of an exception. Contains a combination of exception file name, class, line number, and method. MobileHandledException exceptionLocationClass The class that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionLocationFile The class that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionLocationLibraryOffset For XCFramework agent only. The library offset of the library that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionLocationLine Comes from the exception: The line number where the exception was generated. Only present if symbolication succeeded. MobileHandledException exceptionLocationMethod The method that generated the exception. Only present if symbolication succeeded. MobileHandledException exceptionMessage The unsymbolicated message from the exception. It can be user-generated or a generic system message. For Android, this is the Throwable message. MobileHandledException exceptionName The unsymbolicated exception type. MobileHandledException fingerprint ID The New Relic-generated identifier used to group like exceptions. MobileHandledException handledExceptionUuid ID The unique ID of the exception event. MobileHandledException lastInteraction The last interaction before a crash or harvest event, if one is present. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession libraryName For XCFramework agent only. The library name where the exception was generated. MobileHandledException libraryStartAddr For XCFramework agent only. The library start address where the exception was generated. MobileHandledException memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession occurrenceTimestamp Agent-reported epoch timestamp of the handled exception. MobileHandledException osBuild For Android only. The specific build of the Android OS. MobileHandledException MobileCrash osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession runTime For Android only. The Android Runtime version where the exception/crash was generated. MobileHandledException MobileCrash sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession timestamp Epoch timestamp of the handled exception. This exception timestamp represents the time New Relic created the event, if it's older than two days or some other unexpected time. MobileHandledException uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession MobileRequest Data source : Mobile A MobileRequest event is created when an HTTP request successfully completes, resulting in a response code below 400. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession bytesReceived bytes (B) Optional: If the application received a response from the requestUrl, the size of that response in bytes. MobileRequest MobileRequestError bytesSent bytes (B) Optional: If the application sent a request to the requestUrl, the size of that request in bytes. MobileRequest MobileRequestError carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession connectionType The type of connection which the device was using, such as 2G or 3G. MobileRequest MobileRequestError countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceGroup The category of the device, such as iPhone or Tablet. MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceSize The display size of the device: Small, normal, large, xlarge. MobileRequest MobileRequestError deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession duration seconds (s) Optional: The time to complete the request, measured in fractional seconds. MobileRequest MobileRequestError guid ID The unique identifier for the segment. This is equivalent to spanID in OpenTracing semantics. MobileRequest MobileRequestError Span lastInteraction The last interaction before a crash or harvest event, if one is present. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession requestDomain The domain that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestFingerprint ID The New Relic-generated identifier used to group like request events. MobileRequest requestMethod The REST method (GET, PUT, POST, etc.) that the application attempted when the event occurred. MobileRequest MobileRequestError requestPath The path that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUrl The URL that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUuid ID A unique identifer for the request event. MobileRequest MobileRequestError responseTime seconds (s) The time between the request and the response in fractional seconds. MobileRequest MobileRequestError sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession statusCode Optional: The HTTP status code for the HTTP event. MobileRequest MobileRequestError timestamp The UTC epoch time at which an event began. MobileRequest MobileRequestError MobileSession trace.id ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. DistributedTraceSummary MobileRequest MobileRequestError Span Transaction TransactionError traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession MobileRequestError Data source : Mobile A MobileRequestError is used for HTTP errors or network failures. HTTP errors are HTTP requests that have a status code greater than 400. A network failure is a HTTP request that results in no response. The event is sent when the HTTP request completes. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession bytesReceived bytes (B) Optional: If the application received a response from the requestUrl, the size of that response in bytes. MobileRequest MobileRequestError bytesSent bytes (B) Optional: If the application sent a request to the requestUrl, the size of that request in bytes. MobileRequest MobileRequestError carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession connectionType The type of connection which the device was using, such as 2G or 3G. MobileRequest MobileRequestError countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceGroup The category of the device, such as iPhone or Tablet. MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceSize The display size of the device: Small, normal, large, xlarge. MobileRequest MobileRequestError deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession duration seconds (s) Optional: The time to complete the request, measured in fractional seconds. MobileRequest MobileRequestError errorType Either HTTPError or NetworkFailure, depending on whether the error is a result of a failed request to a host or a failure on the cellular network. MobileRequestError guid ID The unique identifier for the segment. This is equivalent to spanID in OpenTracing semantics. MobileRequest MobileRequestError Span lastInteraction The last interaction before a crash or harvest event, if one is present. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession networkError The error message associated with the iOS NSURL Error code. See networkErrorCode for more information. MobileRequestError networkErrorCode If the error is a network error, this is the iOS network error code. For Android applications, this is the mapped value. MobileRequestError newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession requestDomain The domain that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestErrorFingerprint ID The New Relic-generated identifier used to group like request error events. MobileRequestError requestMethod The REST method (GET, PUT, POST, etc.) that the application attempted when the event occurred. MobileRequest MobileRequestError requestPath The path that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUrl The URL that the application attempted to access when the event occurred. MobileRequest MobileRequestError requestUuid ID A unique identifer for the request event. MobileRequest MobileRequestError responseBody Optional: The response that is sent from the requestDomain for the HTTP error, up to 4096 bytes. MobileRequestError responseTime seconds (s) The time between the request and the response in fractional seconds. MobileRequest MobileRequestError sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession statusCode Optional: The HTTP status code for the HTTP event. MobileRequest MobileRequestError timestamp The UTC epoch time at which an event began. MobileRequest MobileRequestError MobileSession trace.id ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. DistributedTraceSummary MobileRequest MobileRequestError Span Transaction TransactionError traceId ID The unique ID (a randomly generated string) used to identify a single request as it crosses inter- and intra- process boundaries. This ID allows the linking of spans in a distributed trace. Included when distributed tracing is enabled. AwsLambdaInvocation AwsLambdaInvocationError MobileRequest MobileRequestError Span uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession MobileSession Data source : Mobile A MobileSession event is sent when an app is closed, backgrounded, or when 10 minutes of active use has elapsed. This is the source of the general session data used by the other New Relic Mobile events. MobileSession captures attributes such as device type, device OS, and geographical information. Attribute name Definition Events appBuild Indicates the technical build number of the app binary. As a developer, you can use this attribute to identify specific builds of your app. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appId ID A unique identifier for a monitored app, based on the app token. For example: 35091. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - iOS. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersion The version number of the monitored app. For example: 2.2.9. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appVersionId ID An identifier for the specific version of the app. For example: 1713477. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession asn Autonomous System Number: a unique number identifying a group of IP networks that serves the content to the end user. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileRequest MobileRequestError MobileSession PageAction PageView PageViewTiming Span asnOwner The telecom owner of the ASN. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession bundleId ID The unique string used to identify the application. MobileCrash MobileSession carrier The network over which the app transferred data, such as Wi-Fi, Verizon, or Sprint. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession category The type of data, either session or interaction. Mobile MobileSession city The city in which the event occurred, such as Portland or Seattle. AjaxRequest BrowserInteraction BrowserTiming JavaScriptError MobileHandledException MobileSession PageAction PageView PageViewTiming countryCode The country from which the device ran the application. For a list of country codes, see ISO 3166-1 alpha-2. MobileHandledException MobileRequest MobileRequestError MobileSession device The specific type of the device: iPhone 8, iPad Pro, etc. Duplicate of deviceType. MobileHandledException MobileRequest MobileRequestError MobileSession deviceGroup The category of the device, such as iPhone or Tablet. MobileRequest MobileRequestError MobileSession deviceManufacturer The manufacturer of the device, such as Motorola or HTC. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceModel The model number of the device, such as XT1039 or SM-G900F. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession deviceType The specific type of device: iPhone 8, iPad Pro, etc. Duplicate of device. MobileHandledException MobileRequest MobileRequestError MobileSession deviceUuid ID A unique identifier assigned at the time of app installation by New Relic. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of uuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession install Indicates true only if the current session is the first session after app install. MobileSession lastInteraction The last interaction before a crash or harvest event, if one is present. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession memUsageMb megabytes (MB) The total amount of memory, in MB, used by the application. Updated every 60 seconds. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession newRelicAgent The New Relic agent running on the application. For example: the iOSAgent or the androidAgent. MobileSession newRelicVersion The version number of the agent running on the application. For example: 4.232.0. Duplicate of newRelicAgentVersion. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osMajorVersion The simplified version number of the app's host operating system, such as iOS 11, as compared to iOS 11.0.4. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osName The name of the app's host operating system, for example, iOS or Android. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession osVersion The exact version number of the app's host operating system, such as iOS 11.0.4, as compared to iOS 11. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession platform The platform type of the New Relic Mobile agent, such as native or Cordova. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession regionCode The specific region within a country where the monitored app is located. In the United States, regions are states. The regionCode is based on IP address and may not always match your region. MobileHandledException MobileRequest MobileRequestError MobileSession sessionCrashed A boolean value indicating whether or not that session crashed. MobileCrash MobileSession sessionDuration seconds (s) The length of time for which the user used the application in seconds. If the session crashes, sessionDuration is not captured (although other events and attributes are still recorded). For sessions longer than 10 minutes, events in the Interaction and Custom event categories are sent to Insights while the session is ongoing, and therefore do not have sessionDuration attributes. Events recorded near the end of the session will include the duration, as will the Session event category. MobileSession sessionId ID A unique identifier for a single user session. A new sessionId is created each time the app is brought into the foreground. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession timeSinceLoad seconds (s) The time, in seconds, from the beginning of the mobile session to the time the event occurred. MobileSession timestamp The UTC epoch time at which an event began. MobileRequest MobileRequestError MobileSession upgradeFrom Indictates previous version number only if this is the first launch after app upgrade. MobileSession uuid ID A unique identifier assigned by New Relic for a specific app on a particular device. It is only reset if a user deletes and then reinstalls the app. For example: B8B0BC30-0235-11E4-9191-0800200C9A66. Dupliate of deviceUuid. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession NetworkSample Data source : Infrastructure NetworkSample event captures the descriptive and state information for each network device associated with a server. It includes the device's interface and address information, as well as current usage data. New Relic samples this data every 10 seconds for each attached network interface and packages it into a NetworkSample event, then sends the raw data to New Relic's collectors every 60 seconds. Attribute name Definition Events agentName The name of the agent (Infrastructure). NetworkSample ProcessSample StorageSample SystemSample agentVersion The version of the New Relic Infrastructure agent. NetworkSample ProcessSample StorageSample SystemSample criticalViolationCount count The number of times that alert conditions violated critical thresholds, causing critical violations and opening incidents. If this attribute does not exist on the sample, it has zero violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample entityID ID New Relic's unique ID number for the entity that is reporting data. This is used by New Relic to distinguish between customers and their entities. NetworkSample ProcessSample StorageSample SystemSample fullHostname The fully qualified (DNS) hostname. NetworkSample ProcessSample StorageSample SystemSample hardwareAddress The unique hardware address of the interface. NetworkSample hostname The short version of the entity's name. NetworkSample ProcessSample StorageSample SystemSample interfaceName The interface name as reported by the operating system. NetworkSample ipV4Address The IP version 4 address. NetworkSample ipV6Address The IP version 6 address. NetworkSample kernelVersion The Linux kernel version, in string format. This attribute is available only for systems on a Linux platform. NetworkSample ProcessSample StorageSample SystemSample linuxDistribution The name of the Linux distribution the server is using. This attribute is available only for systems on a Linux platform. NetworkSample ProcessSample StorageSample SystemSample operatingSystem The operating system on which the agent is installed. NetworkSample ProcessSample StorageSample SystemSample receiveBytesPerSecond bytes (B) The number of bytes per second received during the sampling period. NetworkSample receiveDroppedPerSecond count The number of received packets per second dropped during the sampling period. NetworkSample receiveErrorsPerSecond count The number of receive errors per second on the interface during the sampling period. NetworkSample receivePacketsPerSecond count The number of packets per second (as defined by OS) received during the sampling period. NetworkSample state The state of the entity: either up or down. NetworkSample timestamp The time (date, hour, minute, second) at which the interaction occurred. NetworkSample ProcessSample StorageSample SystemSample transmitBytesPerSecond bytes (B) The number of bytes sent per second during the sampling period. NetworkSample transmitDroppedPerSecond count The number of dropped send packets per second during the sampling period. NetworkSample transmitErrorsPerSecond count The number of send errors per second on the interface during the sampling period. NetworkSample transmitPacketsPerSecond count The number of packets per second as defined by OS) sent during this sampling period. NetworkSample warningViolationCount count The number of times that alert conditions violated warning thresholds, causing warning violations. ContainerSample NetworkSample ProcessSample StorageSample SystemSample windowsFamily The Windows family indicates w",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 277.45184,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>InfrastructureEvent</em>",
        "body": " MobileSession app<em>Id</em> <em>ID</em> A unique identifier for a monitored app, based on the app token. For example: 35091. MobileHandledException MobileRequest MobileCrash MobileRequestError MobileSession appName The name of the monitored app. For example: My Mobile App - <em>iOS</em>. MobileHandledException MobileRequest"
      },
      "id": "603f53b164441f41894e8875"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "fe6ba3196a927fb8dee72f8bf777461c95f7505c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-sdk-api-guide/",
      "published_at": "2021-06-14T21:38:56Z",
      "updated_at": "2021-06-03T12:15:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API for New Relic Mobile to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest New Relic Mobile SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges New Relic Mobile aggregates performance for various methods into summary metrics that appear in New Relic Mobile's Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic Mobile. - (void)myMethod { NR_TRACE_METHOD_START(0); //  existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your methods performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) //  existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your methods performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in New Relic Mobile's Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it in New Relic Mobile. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, New Relic Mobile will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if New Relic Mobile records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of the codes that New Relic Mobile supports, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.75137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>iOS</em> SDK API guide",
        "sections": "<em>iOS</em> SDK API guide",
        "tags": "New Relic Mobile <em>iOS</em>",
        "body": "Use the <em>iOS</em> SDK API for New Relic Mobile to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically"
      },
      "id": "603eb3a2e7b9d264f02a07a8"
    },
    {
      "sections": [
        "iOS agent configuration and feature flags",
        "Tip",
        "Enable or disable feature flags",
        "Crash and error reporting feature flag",
        "NRFeatureFlag_CrashReporting",
        "NRFeatureFlag_HandledExceptionEvents",
        "Distributed tracing",
        "NRFeatureFlag_DistributedTracing",
        "Interactions feature flags",
        "NRFeatureFlag_DefaultInteractions",
        "NRFeatureFlag_InteractionTracing",
        "NRFeatureFlag_SwiftInteractionTracing",
        "Caution",
        "Networking feature flags",
        "NRFeatureFlag_ExperimentalNetworkingInstrumentation",
        "NRFeatureFlag_NSURLSessionInstrumentation",
        "NRFeatureFlag_NetworkRequestEvents",
        "NRFeatureFlag_RequestErrorEvents",
        "NRFeatureFlag_HttpResponseBodyCapture"
      ],
      "title": "iOS agent configuration and feature flags",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Configuration"
      ],
      "external_id": "8ced2dac1fbc45a65d6cdca6b27a4db001d6a4db",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-agent-configuration-feature-flags/",
      "published_at": "2021-06-14T21:39:52Z",
      "updated_at": "2021-06-03T12:15:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Mobile's iOS agent provides configuration settings to change the default behavior of the agent. If used, implement these flags just before calling: Objective-C: +[NewRelic startWithApplicationToken:] Swift: NewRelic.start(withApplicationToken:) Tip For an explanation of Mobile custom data types, see Add custom data to New Relic Mobile. Enable or disable feature flags To configure feature flags, use the following method defined in NewRelic.h: iOS language Procedure Objective-C In Objective-C, these features are bitmasked, so you can use a | to enable or disable multiple features at the same time. Enable a feature flag: +[NewRelic enableFeatures:(NRMAFeatureFlags)flags]; Copy Disable a feature flag: +[NewRelic disableFeatures:(NRMAFeatureFlags)flags]; Copy Here is an example where: Interaction tracing and experimental networking instrumentation are enabled. NSURLSession instrumentation and crash reporting are disabled. [NewRelic enableFeatures:NRFeatureFlag_SwiftInteractionTracing | NRFeatureFlag_ExperimentalNetworkingInstrumentation]; [NewRelic disableFeatures:NRFeatureFlag_NSURLSessionInstrumentation | NRFeatureFlag_CrashReporting]; [NewRelic startWithApplicationToken:...]; Copy Swift Enable a feature flag: NewRelic.enableFeatures(NRMAFeatureFlags.[NRMAFeatureFlag]) Copy Disable a feature flag: NewRelic.disableFeatures(NRMAFeatureFlags.[NRMAFeatureFlag]) Copy Example to disable interaction tracing: NewRelic.disableFeatures(NRMAFeatureFlags.NRFeatureFlag_DefaultInteractions) Copy Crash and error reporting feature flag If used, be sure to call the feature flag before the New Relic iOS agent start call. NRFeatureFlag_CrashReporting Enable (default) or disable crash reporting, which appears on New Relic Mobile's Crash analysis page. Type Boolean Default true NRFeatureFlag_HandledExceptionEvents Globally enable (default) or disable recording handled exceptions events, which appear on the Handled exception page. Type Boolean Default true Distributed tracing NRFeatureFlag_DistributedTracing Enable or disable the adding of distributed tracing headers to network requests. Refer to How New Relic distributed tracing works for more information on distributed tracing in mobile apps. Type Boolean Default true Interactions feature flags If used, be sure to call the feature flag before the New Relic iOS agent start call. NRFeatureFlag_DefaultInteractions Enable (default) or disable interaction tracing only for default instrumented classes and methods. Custom interactions will be reported. The traces will appear on the Mobile Interactions page. Type Boolean Default true NRFeatureFlag_InteractionTracing Globally enable (default) or disable interaction traces, which appear on the Mobile Interactions page. Interaction tracing will be disabled after the agent has started. Interactions for any activity or methods executed prior to starting the agent may still appear on the Interactions page. Type Boolean Default true NRFeatureFlag_SwiftInteractionTracing Caution Before enabling this feature, see Enable Swift interaction traces. If proper steps are not taken, enabling this feature may cause instability. Enable or disable (default) interaction tracing for Swift code. The traces appear on the Mobile Interactions page. This feature will always be disabled if NRFeatureFlag_InteractionTracing is disabled. Type Boolean Default false Networking feature flags If used, be sure to call the feature flag before the New Relic iOS agent start call. NRFeatureFlag_ExperimentalNetworkingInstrumentation Caution Enabling this feature flag call may decrease the stability of applications. Avoid using unless instructed by New Relic. Enable or disable (default) experimental networking instrumentation. This forces all NSURLConnection network requests through the NRMAURProtocol. Type Boolean Default false NRFeatureFlag_NSURLSessionInstrumentation Enable (default) or disable networking instrumentation for NSURLSession. These URL traces are sent to the HTTP Requests page. Type Boolean Default true NRFeatureFlag_NetworkRequestEvents Enable or disable (default) networking instrumentation. This sends the HTTP response data as MobileRequest events. Available for iOS Agent version 5.14.0 and higher Type Boolean Default true - Enabled by default as of 6.0.0 NRFeatureFlag_RequestErrorEvents Enable (default) or disable HTTP request error event generation of instrumented network calls that result in an error or failure. These events are reported as MobileRequestError events. Available for iOS Agent version 5.11.0 and higher Type Boolean Default true NRFeatureFlag_HttpResponseBodyCapture Enable or disable capture of HTTP response bodies for HTTP error traces, and MobileRequestError events. Type Boolean Default true",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.75134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>iOS</em> agent configuration and feature flags",
        "sections": "<em>iOS</em> agent configuration and feature flags",
        "tags": "New Relic Mobile <em>iOS</em>",
        "body": "New Relic Mobile&#x27;s <em>iOS</em> agent provides configuration settings to change the default behavior of the agent. If used, implement these flags just before calling: Objective-C: +[NewRelic startWithApplicationToken:] Swift: NewRelic.start(withApplicationToken:) Tip For an explanation of Mobile custom data"
      },
      "id": "60441925196a67324d960f1b"
    }
  ],
  "/docs/licenses/index": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-06-15T12:19:16Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0  2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0  2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0  2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0  2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0  2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright  2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright  2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright  1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright  1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 66.7043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "Licenses for plugin developers",
        "Important",
        "Limited access to legacy plugins",
        "Licenses for developing plugins"
      ],
      "title": "Licenses for plugin developers",
      "type": "docs",
      "tags": [
        "Plugins",
        "Plugin developer resources",
        "Developer reference"
      ],
      "external_id": "04388d903244009eb60f0da612f3a21d899300f0",
      "image": "",
      "url": "https://docs.newrelic.com/docs/plugins/plugin-developer-resources/developer-reference/licenses-plugin-developers/",
      "published_at": "2021-06-15T03:41:01Z",
      "updated_at": "2021-03-13T02:39:48Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important For an even better experience than plugins, go to: newrelic.com/integrations: Integrate the on-host and cloud systems you already use with New Relic, so you can filter and analyze data, create dashboards, and set alerts within a single platform. developer.newrelic.com: Use developer tools to collect data from any source, automate workflows, build apps, and use our APIs. Limited access to legacy plugins As of December 2, 2020, plugin access has been limited to accounts that have accessed a legacy plugin in the past 30 days. The legacy plugin experience will reach end of life (EoL) as of June 16, 2021. For more information, see our Explorers Hub post. Licenses for developing plugins In addition to the Plugins licenses used by New Relic, the software licenses associated with developing plugins depend on the plugin itself. For example: Plugins developed with the Java SDK for Plugins use the same MIT and Apache 2.0 licenses as New Relic APM's Java agent. Plugins developed with the Ruby SDK for Plugins use the same MIT licenses as New Relic APM's Ruby agent. Plugins developed with the .NET SDK for New Relic Plugins use the same MIT licenses as New Relic APM's .NET agent. Collectors for Plugins use the same MySQL Java licenses as New Relic. For more information, see Data collector licenses. Plugins that do not use an SDK fall under the licensing agreements that the individual plugin author uses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 60.16065,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Licenses</em> for plugin developers",
        "sections": "<em>Licenses</em> for plugin developers",
        "body": ") as of June 16, 2021. For more information, see our Explorers Hub post. <em>Licenses</em> for developing plugins In addition to the Plugins <em>licenses</em> used by New Relic, the software <em>licenses</em> associated with developing plugins depend on the plugin itself. For example: Plugins developed with the Java SDK"
      },
      "id": "604435cd64441f7eb5378ec7"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-06-15T13:34:45Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.776047,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic APM <em>licenses</em>",
        "sections": "New Relic APM <em>licenses</em>",
        "tags": "<em>Licenses</em>",
        "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;product-or-service-<em>licenses</em>&#x2F;new-relic-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement": [
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-06-15T01:04:59Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.69066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    },
    {
      "sections": [
        "New Relic Agent Software Notice"
      ],
      "title": "New Relic Agent Software Notice",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "2bf9501c2767105130d3808f1bf3a91a032d903e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice/",
      "published_at": "2021-06-15T13:30:43Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This software is  2008-2021 New Relic, Inc. and its licensors. This software is solely for use with New Relics proprietary SaaS service (New Relic Service), so to use the software you must have a valid account for the New Relic Service under a separate agreement with New Relic (Subscription Agreement). You may only use the software to support your use of the New Relic Service as permitted in the Subscription Agreement. Without a Subscription Agreement, you may not use the software. All other use is prohibited. New Relic and its suppliers retain all right, title and interest (including intellectual property rights) in the software. The Subscription Agreement will control in event of a conflict with this notice. Unless otherwise agreed by New Relic in your Subscription Agreement: You may not use, copy, distribute or sublicense the software, use the software on behalf of third parties, reverse engineer or decompile the software, modify or create derivative works of the software, use the software for competitive analysis or benchmarking, or remove or obscure any proprietary notices in the software. The software is provided AS IS and New Relic disclaims all warranties, whether express, implied, statutory or otherwise, including warranties of merchantability, fitness for a particular purpose, title or noninfringement. To the full extent permitted by law, New Relic will have no liability arising from or related to the software or under this notice for any direct, indirect, special, incidental, or consequential damages of any kind, even if advised of their possibility in advance, and regardless of legal theory (whether contract, tort, negligence, strict liability or otherwise). The software may contain third-party open source software (OSS) as described here and at https://github.com/newrelic. To the extent required by the OSS license, that license will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile and as set forth: https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started and https://docs.newrelic.com/docs/browser/new-relic-browser/installation/install-new-relic-browser-agent Software versions New Relic makes available under an OSS license (such as Apache 2.0) are governed by the terms of the applicable OSS license. For a current list of New Relic software versions released as OSS please visit https://opensource.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.16675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " and at https:&#x2F;&#x2F;github.com&#x2F;newrelic. To the extent required by the OSS <em>license</em>, that <em>license</em> will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile"
      },
      "id": "603eb73828ccbc1f99eba74a"
    },
    {
      "sections": [
        "FIT instrumentation end user license agreement"
      ],
      "title": "FIT instrumentation end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "e8e10baf120678407d08c9f78ab708d271cf0223",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement/",
      "published_at": "2021-06-15T13:30:43Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NEW RELIC, INC. FIT INSTRUMENTATION END USER LICENSE AGREEMENT In connection with the work provided by New Relics Field Instrumentation Team, you may be provided with certain custom-created software to enable, optimize, or enhance your use of New Relics Services. By downloading, installing, authorizing installation, or using the FIT Instrumentation with your Underlying Software (defined below), you (Customer) agree to the terms and conditions herein (Agreement) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (New Relic), (collectively the Parties). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the Terms of Service) available here: http://newrelic.com/terms IF YOU DO NOT AGREE TO THIS AGREEMENT, PLEASE DO NOT USE THE FIT INSTRUMENTATION. 1. DEFINITIONS FIT Instrumentation means the New Relic custom-made software, including but not limited to connectors, extensions, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (Underlying Software). For the purposes of the Terms of Service, the FIT Instrumentation shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE FIT INSTRUMENTATION 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the FIT Instrumentation solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the FIT Instrumentation and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the FIT Instrumentation in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (Feedback) regarding the FIT Instrumentation, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the FIT Instrumentation is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that FIT Instrumentation will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an Upgrade Event). Customer shall hold New Relic harmless from any claims or damages arising from Customers Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the FIT Instrumentation except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the FIT Instrumentation; (iii) decompile, disassemble or reverse engineer any software underlying the FIT Instrumentation; (iv) use the FIT Instrumentation to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other partys use and enjoyment of the Services; (v) use the FIT Instrumentation to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the FIT Instrumentation; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend usage of the Services by any user, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time at https://docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential Information means: (a) the FIT Instrumentation, and any features, results or output produced by, and other information relating to the FIT Instrumentation (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. FIT INSTRUMENTATION IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. FIT INSTRUMENTATION IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE. , OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE FIT INSTRUMENTATION THEREFROM. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES OR LIMITATIONS ON APPLICABLE STATUTORY RIGHTS OF A CONSUMER, SO THE ABOVE EXCLUSION AND LIMITATIONS MAY NOT APPLY TO THE CUSTOMER. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE FIT INSTRUMENTATION OR FOR ANY ERROR OR DEFECT IN THE FIT INSTRUMENTATION OR THE SERVICES, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON CONTRACT, WARRANTY, TORT, STRICT LIABILITY, OR OTHERWISE, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC'S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the FIT Instrumentation is not an official product and has not been commercially released for sale by New Relic; (b) the FIT Instrumentation may not operate properly, being in final form, or fully functional; (c) the FIT Instrumentation may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the FIT Instrumentation fully functional; (e) the information obtained using the FIT Instrumentation may not be accurate; (f) use of the FIT Instrumentation may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the FIT Instrumentation; and (h) New Relic has the right unilaterally to abandon development of the FIT Instrumentation, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the \"Documentation\").This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the FIT Instrumentation. In the absence of a separate agreement between New Relic and Customer with respect to the FIT Instrumentation, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such FIT Instrumentation. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the FIT Instrumentation only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.16675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "FIT instrumentation end user <em>license</em> agreement",
        "sections": "FIT instrumentation end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " Acceptable Use Policy as may be published and updated from time to time at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential <em>Information</em> means: (a) the FIT Instrumentation, and any features, results"
      },
      "id": "603e9f3ee7b9d206e32a0800"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement": [
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-06-15T01:04:59Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.69066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    },
    {
      "sections": [
        "Add-on end user license agreement",
        "New Relic, Inc. Add-on End User License Agreement"
      ],
      "title": "Add-on end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "a01c225ca30f95dab7db856cd946c76de557c31f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T06:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic, Inc. Add-on End User License Agreement In connection with the work provided by New Relic's Expert Services, Field Instrumentation Team, or Sales team, you may be provided with certain custom-created software to visualize, enable, optimize, or enhance your use of New Relic's Services. By downloading, installing, authorizing installation, or using the Add-on (defined below) with your Underlying Software (defined below), you (Customer) agree to the terms and conditions herein (Agreement) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (New Relic\"), (collectively the Parties). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the Terms of Service) available here: newrelic.com/termsandconditions/terms. IF YOU DO NOT AGREE TO THIS AGREEMENT, YOUR SOLE REMEDY IS TO NOT USE THE ADD-ON. 1. DEFINITIONS Add-on means the New Relic applications and/or software, including but not limited to connectors, extensions, UI extension, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (Underlying Software). For the purposes of the Terms of Service, the Add-on shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE PROGRAMMABILITY ADD-ON 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the Add-on solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the Add-on and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the Add-on in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (Feedback) regarding the Add-on, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the Add-on is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that Add-on will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an Upgrade Event). Customer shall hold New Relic harmless from any claims or damages arising from Customers Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the Add-on except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the Add-on; (iii) decompile, disassemble or reverse engineer any software underlying the Add-on; (iv) use the Add-on to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other partys use and enjoyment of the Services; (v) use the Add-on to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the Add-on; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend Customer usage of the Services, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time on the New Relic web site at docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential Information means: (a) the Programmability Add-on, and any features, results or output produced by, and other information relating to the Add-on (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. THE ADD-ON IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. THE ADD-ON IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE, OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE ADD-ON THEREFROM. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE ADD-ON OR FOR ANY ERROR OR DEFECT IN THE ADD-ON OR THE SERVICES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELICS AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND CUSTOMER. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the Add-on is not an official product and has not been commercially released for sale by New Relic; (b) the Add-on may not operate properly, being in final form, or fully functional; (c) the Add-on may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the Add-on fully functional; (e) the information obtained using the Add-on may not be accurate; (f) use of the Add-on may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the Add-on; and (h) New Relic has the right unilaterally to abandon development of the Add-on, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the Documentation). This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the Add-on. In the absence of a separate agreement, upon agreement between New Relic and Customer with respect to the Add-On, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such Add-On. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the Add-on only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.18098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add-on end user <em>license</em> agreement",
        "sections": "Add-on end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential <em>Information</em> means: (a) the Programmability Add-on, and any features, results or output produced by, and other <em>information</em> relating to the Add-on (including, without limitation"
      },
      "id": "603ec23328ccbccf1beba79a"
    },
    {
      "sections": [
        "New Relic Agent Software Notice"
      ],
      "title": "New Relic Agent Software Notice",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "2bf9501c2767105130d3808f1bf3a91a032d903e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice/",
      "published_at": "2021-06-15T13:30:43Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This software is  2008-2021 New Relic, Inc. and its licensors. This software is solely for use with New Relics proprietary SaaS service (New Relic Service), so to use the software you must have a valid account for the New Relic Service under a separate agreement with New Relic (Subscription Agreement). You may only use the software to support your use of the New Relic Service as permitted in the Subscription Agreement. Without a Subscription Agreement, you may not use the software. All other use is prohibited. New Relic and its suppliers retain all right, title and interest (including intellectual property rights) in the software. The Subscription Agreement will control in event of a conflict with this notice. Unless otherwise agreed by New Relic in your Subscription Agreement: You may not use, copy, distribute or sublicense the software, use the software on behalf of third parties, reverse engineer or decompile the software, modify or create derivative works of the software, use the software for competitive analysis or benchmarking, or remove or obscure any proprietary notices in the software. The software is provided AS IS and New Relic disclaims all warranties, whether express, implied, statutory or otherwise, including warranties of merchantability, fitness for a particular purpose, title or noninfringement. To the full extent permitted by law, New Relic will have no liability arising from or related to the software or under this notice for any direct, indirect, special, incidental, or consequential damages of any kind, even if advised of their possibility in advance, and regardless of legal theory (whether contract, tort, negligence, strict liability or otherwise). The software may contain third-party open source software (OSS) as described here and at https://github.com/newrelic. To the extent required by the OSS license, that license will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile and as set forth: https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started and https://docs.newrelic.com/docs/browser/new-relic-browser/installation/install-new-relic-browser-agent Software versions New Relic makes available under an OSS license (such as Apache 2.0) are governed by the terms of the applicable OSS license. For a current list of New Relic software versions released as OSS please visit https://opensource.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.16675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " and at https:&#x2F;&#x2F;github.com&#x2F;newrelic. To the extent required by the OSS <em>license</em>, that <em>license</em> will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile"
      },
      "id": "603eb73828ccbc1f99eba74a"
    }
  ],
  "/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice": [
    {
      "sections": [
        "Services licenses",
        "Contents",
        "Java internal services",
        "Java crash data API",
        "CoffeeScript",
        "JavaScript",
        "Crash reporting",
        "Label services",
        "Infrastructure Monitoring services",
        ".NET support uploader service",
        "Ruby gems",
        "Storage services",
        "Go packages"
      ],
      "title": "Services licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "49a2ad450d31dacfc2aae690ca947d2326d18761",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/other-licenses/services-licenses/",
      "published_at": "2021-06-15T01:04:59Z",
      "updated_at": "2021-04-06T00:26:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Contents Java internal services Java crash data API Framework License Apache TomCat Apache 2.0 Bean Validation Apache 2.0 Cassandra Driver Core Apache 2.0 ClassMate Apache 2.0 Hamcrest BSD Mockito MIT Netty Apache 2.0 Objenesis MIT SnakeYAML Apache 2.0 Spring Boot Apache 2.0 Java internal services Library License json_simple Apache 2.0 newrelic-api New Relic newrelic-api New Relic antlr BSD aopalliance Public Domain asm-analysis BSD asm-commons BSD asm-tree BSD asm-util BSD asm BSD c3p0 EPLv1.0 cglib-nodep Apache 2.0 cglib Apache 2.0 cglib Apache 2.0 cal10n-api MIT logback-classic EPLv1.0 logback-core EPLv1.0 guava-jetty-service Apache 2.0 zkclient Apache 2.0 reporter-config-base Apache 2.0 reporter-config3 Apache 2.0 reporter-config Apache 2.0 aws-java-sdk-acm Apache 2.0 aws-java-sdk-api-gateway Apache 2.0 aws-java-sdk-applicationautoscaling Apache 2.0 aws-java-sdk-autoscaling Apache 2.0 aws-java-sdk-cloudformation Apache 2.0 aws-java-sdk-cloudfront Apache 2.0 aws-java-sdk-cloudhsm Apache 2.0 aws-java-sdk-cloudsearch Apache 2.0 aws-java-sdk-cloudtrail Apache 2.0 aws-java-sdk-cloudwatch Apache 2.0 aws-java-sdk-cloudwatchmetrics Apache 2.0 aws-java-sdk-codecommit Apache 2.0 aws-java-sdk-codedeploy Apache 2.0 aws-java-sdk-codepipeline Apache 2.0 aws-java-sdk-cognitoidentity Apache 2.0 aws-java-sdk-cognitoidp Apache 2.0 aws-java-sdk-cognitosync Apache 2.0 aws-java-sdk-config Apache 2.0 aws-java-sdk-core Apache 2.0 aws-java-sdk-datapipeline Apache 2.0 aws-java-sdk-devicefarm Apache 2.0 aws-java-sdk-directconnect Apache 2.0 aws-java-sdk-directory Apache 2.0 aws-java-sdk-discovery Apache 2.0 aws-java-sdk-dms Apache 2.0 aws-java-sdk-dynamodb Apache 2.0 aws-java-sdk-ec2 Apache 2.0 aws-java-sdk-ecr Apache 2.0 aws-java-sdk-ecs Apache 2.0 aws-java-sdk-efs Apache 2.0 aws-java-sdk-elasticache Apache 2.0 aws-java-sdk-elasticbeanstalk Apache 2.0 aws-java-sdk-elasticloadbalancing Apache 2.0 aws-java-sdk-elasticloadbalancingv2 Apache 2.0 aws-java-sdk-elasticsearch Apache 2.0 aws-java-sdk-elastictranscoder Apache 2.0 aws-java-sdk-emr Apache 2.0 aws-java-sdk-events Apache 2.0 aws-java-sdk-gamelift Apache 2.0 aws-java-sdk-glacier Apache 2.0 aws-java-sdk-iam Apache 2.0 aws-java-sdk-importexport Apache 2.0 aws-java-sdk-inspector Apache 2.0 aws-java-sdk-iot Apache 2.0 aws-java-sdk-kinesis Apache 2.0 aws-java-sdk-kms Apache 2.0 aws-java-sdk-lambda Apache 2.0 aws-java-sdk-logs Apache 2.0 aws-java-sdk-machinelearning Apache 2.0 aws-java-sdk-marketplacecommerceanalytics Apache 2.0 aws-java-sdk-marketplacemeteringservice Apache 2.0 aws-java-sdk-models Apache 2.0 aws-java-sdk-opsworks Apache 2.0 aws-java-sdk-rds Apache 2.0 aws-java-sdk-redshift Apache 2.0 aws-java-sdk-route53 Apache 2.0 aws-java-sdk-s3 Apache 2.0 aws-java-sdk-servicecatalog Apache 2.0 aws-java-sdk-ses Apache 2.0 aws-java-sdk-simpledb Apache 2.0 aws-java-sdk-simpleworkflow Apache 2.0 aws-java-sdk-snowball Apache 2.0 aws-java-sdk-sns Apache 2.0 aws-java-sdk-sqs Apache 2.0 aws-java-sdk-ssm Apache 2.0 aws-java-sdk-storagegateway Apache 2.0 aws-java-sdk-sts Apache 2.0 aws-java-sdk-support Apache 2.0 aws-java-sdk-swf-libraries Apache 2.0 aws-java-sdk-waf Apache 2.0 aws-java-sdk-workspaces Apache 2.0 aws-java-sdk Apache 2.0 jmespath-java Apache 2.0 AppleJavaExtensions BSD jcommander Apache 2.0 high-scale-lib MIT hppc Apache 2.0 clover Paid stream Apache 2.0 metrics-core Apache 2.0 cassandra-driver-core Apache 2.0 cassandra-driver-core Apache 2.0 uuid MIT grabbag MIT speed4j Apache 2.0 yamlbeans BSD jackson-annotations Apache 2.0 jackson-core Apache 2.0 jackson-databind Apache 2.0 jackson-dataformat-cbor Apache 2.0 jackson-dataformat-csv Apache 2.0 jackson-dataformat-xml Apache 2.0 jackson-dataformat-yaml Apache 2.0 jackson-datatype-guava Apache 2.0 jackson-datatype-jdk7 Apache 2.0 jackson-datatype-jdk8 Apache 2.0 jackson-datatype-joda Apache 2.0 jackson-datatype-jsr310 Apache 2.0 jackson-jaxrs-base Apache 2.0 jackson-jaxrs-json-provider Apache 2.0 jackson-module-afterburner Apache 2.0 jackson-module-jaxb-annotations Apache 2.0 jackson-module-kotlin Apache 2.0 woodstox-core Apache 2.0 classmate Apache 2.0 zjsonpatch Apache 2.0 caffeine Apache 2.0 waffle-jna EPLv1.0 docker-java Apache 2.0 docker-java Apache 2.0 btf Apache 2.0 jackson-coreutils Apache 2.0 json-schema-core Apache 2.0 json-schema-validator Apache 2.0 msg-simple Apache 2.0 uri-template Apache 2.0 jamm Apache 2.0 jffi Apache 2.0 jnr-constants Apache 2.0 jnr-ffi Apache 2.0 jnr-ffi Apache 2.0 jnr-posix EPLv1.0 jnr-x86asm MIT embedded-redis Apache 2.0 memoryfilesystem MIT guava-retrying Apache 2.0 guava-retrying Apache 2.0 snowball-stemmer BSD system-rules CPL uuid Apache 2.0 wiremock Apache 2.0 auto-common Apache 2.0 annotations LGPLv2.1 annotations LGPLv2.1 bcel-findbugs LGPLv2.1 findbugs LGPLv2.1 jFormatString BSD jFormatString BSD jsr305 BSD jsr305 BSD jsr305 BSD gson Apache 2.0 spymemcached MIT guava-testlib Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guava Apache 2.0 guice-multibindings Apache 2.0 guice Apache 2.0 truth Apache 2.0 concurrent-trees Apache 2.0 concurrentlinkedhashmap-lru Apache 2.0 json-simple Apache 2.0 libphonenumber Apache 2.0 locality-uuid BSD h2 EPLv1.0 annotations Apache 2.0 json-path-assert Apache 2.0 json-path Apache 2.0 json-path Apache 2.0 jzlib BSD bonecp-provider Apache 2.0 bonecp Apache 2.0 junixsocket-common Apache 2.0 junixsocket-native-common Apache 2.0 disruptor Apache 2.0 geoip-api LGPLv2.1 c3p0 LGPLv2.1 mchange-commons-java LGPLv2.1 archaius-core Apache 2.0 hystrix-core Apache 2.0 hystrix-servo-metrics-publisher Apache 2.0 rxjava-core Apache 2.0 servo-core Apache 2.0 kafka-clients Apache 2.0 kafka_2.10 Apache 2.0 kafka_2.11 Apache 2.0 common-cassandra Apache 2.0 timeslice_utils New Relic mockito-kotlin MIT compress-lzf Apache 2.0 checkstyle Apache 2.0 dagger-compiler Apache 2.0 dagger Apache 2.0 okhttp Apache 2.0 okio Apache 2.0 javapoet Apache 2.0 javawriter Apache 2.0 jaxb-impl CDDLv1 thrift-server Apache 2.0 finagle-core_2.10 Apache 2.0 finagle-core_2.11 Apache 2.0 finagle-http_2.10 Apache 2.0 finagle-http_2.11 Apache 2.0 jsr166e Creative Commons util-app_2.10 Apache 2.0 util-app_2.11 Apache 2.0 util-cache_2.10 Apache 2.0 util-cache_2.11 Apache 2.0 util-codec_2.10 Apache 2.0 util-codec_2.11 Apache 2.0 util-collection_2.10 Apache 2.0 util-collection_2.11 Apache 2.0 util-core_2.10 Apache 2.0 util-core_2.11 Apache 2.0 util-function_2.10 Apache 2.0 util-function_2.11 Apache 2.0 util-hashing_2.10 Apache 2.0 util-hashing_2.11 Apache 2.0 util-jvm_2.10 Apache 2.0 util-jvm_2.11 Apache 2.0 util-lint_2.10 Apache 2.0 util-lint_2.11 Apache 2.0 util-logging_2.10 Apache 2.0 util-logging_2.11 Apache 2.0 util-registry_2.10 Apache 2.0 util-registry_2.11 Apache 2.0 util-stats_2.10 Apache 2.0 util-stats_2.11 Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 HikariCP Apache 2.0 commons-beanutils Apache 2.0 commons-cli Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-io Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 commons-pool Apache 2.0 unix-socket-factory Apache 2.0 unix-socket-factory Apache 2.0 jflex BSD dom4j BSD airline Apache 2.0 metrics-annotation Apache 2.0 metrics-core Apache 2.0 metrics-healthchecks Apache 2.0 metrics-httpclient Apache 2.0 metrics-jdbi Apache 2.0 metrics-jersey2 Apache 2.0 metrics-jetty9 Apache 2.0 metrics-json Apache 2.0 metrics-jvm Apache 2.0 metrics-logback Apache 2.0 metrics-servlets Apache 2.0 dropwizard-java8-jdbi Apache 2.0 dropwizard-client Apache 2.0 dropwizard-configuration Apache 2.0 dropwizard-core Apache 2.0 dropwizard-db Apache 2.0 dropwizard-jackson Apache 2.0 dropwizard-jdbi Apache 2.0 dropwizard-jersey Apache 2.0 dropwizard-jetty Apache 2.0 dropwizard-lifecycle Apache 2.0 dropwizard-logging Apache 2.0 dropwizard-metrics Apache 2.0 dropwizard-servlets Apache 2.0 dropwizard-testing Apache 2.0 dropwizard-util Apache 2.0 dropwizard-validation Apache 2.0 netty-all Apache 2.0 netty-buffer Apache 2.0 netty-codec-http Apache 2.0 netty-codec-socks Apache 2.0 netty-codec Apache 2.0 netty-common Apache 2.0 netty-handler-proxy Apache 2.0 netty-handler Apache 2.0 netty-resolver Apache 2.0 netty-transport-native-epoll Apache 2.0 netty-transport Apache 2.0 netty Apache 2.0 ratpack-core Apache 2.0 ratpack-groovy-test Apache 2.0 ratpack-groovy Apache 2.0 ratpack-guice Apache 2.0 ratpack-test Apache 2.0 rxjava Apache 2.0 fastutil Apache 2.0 janino BSD activation Apache 2.0 javax.annotation-api CDDLv1 jsr250-api CDDLv1 javax.inject Apache 2.0 mail CDDLv1 mailapi CDDLv1 javax.servlet-api Apache 2.0 servlet-api Apache 2.0 javax.transaction-api CDDLv1 validation-api Apache 2.0 javax.websocket-api CDDLv1 javax.ws.rs-api CDDLv1 jaxb-api CDDLv1 stax-api CDDLv1 jaxen Apache 2.0 jline BSD jline BSD joda-time Apache 2.0 junit-dep CPL junit CPL junit EPLv1.0 kafka_2.10 Apache 2.0 kafka_2.9.2 Apache 2.0 apache-log4j-extras Apache 2.0 log4j Apache 2.0 mysql-connector-java GPLv2 with Classpath Exception byte-buddy Apache 2.0 byte-buddy Apache 2.0 jna-platform LGPLv2.1 jna Apache 2.0 jcip-annotations Apache 2.0 lz4 Apache 2.0 accessors-smart Apache 2.0 asm Apache 2.0 json-smart Apache 2.0 json-smart Apache 2.0 primitive GPLv2 with Classpath Exception compiler Apache 2.0 lang Apache 2.0 beaver-cc BSD ehcache-core Apache 2.0 ehcache Apache 2.0 jopt-simple MIT jopt-simple MIT opencsv Apache 2.0 quality-check Apache 2.0 scannotation Apache 2.0 super-csv Apache 2.0 uadetector-core Apache 2.0 uadetector-resources Apache 2.0 argparse4j MIT spymemcached MIT kalium Apache 2.0 ST4 BSD antlr-runtime BSD antlr-runtime BSD antlr BSD stringtemplate BSD ant-launcher Apache 2.0 ant Apache 2.0 cassandra-all Apache 2.0 cassandra-all Apache 2.0 cassandra-thrift Apache 2.0 cassandra-thrift Apache 2.0 commons-collections4 Apache 2.0 commons-compress Apache 2.0 commons-csv Apache 2.0 commons-dbcp2 Apache 2.0 commons-io Apache 2.0 commons-lang3 Apache 2.0 commons-math3 Apache 2.0 commons-math Apache 2.0 commons-pool2 Apache 2.0 curator-client Apache 2.0 curator-framework Apache 2.0 curator-recipes Apache 2.0 curator-test Apache 2.0 derby Apache 2.0 geronimo-servlet_3.0_spec Apache 2.0 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 ivy Apache 2.0 kafka-clients Apache 2.0 kafka_2.11 Apache 2.0 libthrift Apache 2.0 tomcat-embed-core Apache 2.0 tomcat-embed-el Apache 2.0 tomcat-embed-logging-juli Apache 2.0 tomcat-embed-websocket Apache 2.0 tomcat-jdbc Apache 2.0 tomcat-juli Apache 2.0 zookeeper Apache 2.0 aspectjweaver EPLv1.0 assertj-core Apache 2.0 assertj-core Apache 2.0 evo-inflector Apache 2.0 bcmail-jdk15on MIT bcpkix-jdk15on MIT bcprov-jdk15on MIT ohc-core Apache 2.0 cassandra-unit-spring LGPLv3 cassandra-unit-spring LGPLv3 cassandra-unit LGPLv3 cassandra-unit LGPLv3 groovy-all Apache 2.0 groovy-all Apache 2.0 groovy Apache 2.0 groovy Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 easymock Apache 2.0 ecj EPLv1.0 javax.activation CDDLv1 javax.annotation CDDLv1 javax.mail.glassfish CDDLv1 javax.servlet CDDLv1 javax.transaction CDDLv1 org.objectweb.asm BSD jetty-setuid-java EPLv1.0 jetty-schemas Apache 2.0 javax-websocket-client-impl Apache 2.0 javax-websocket-server-impl Apache 2.0 websocket-api Apache 2.0 websocket-client Apache 2.0 websocket-common Apache 2.0 websocket-server Apache 2.0 websocket-servlet Apache 2.0 apache-jsp Apache 2.0 jetty-annotations CDDLv1 jetty-client Apache 2.0 jetty-continuation Apache 2.0 jetty-http Apache 2.0 jetty-io Apache 2.0 jetty-jmx Apache 2.0 jetty-jndi Apache 2.0 jetty-plus Apache 2.0 jetty-proxy Apache 2.0 jetty-security Apache 2.0 jetty-server Apache 2.0 jetty-servlet Apache 2.0 jetty-servlets Apache 2.0 jetty-util Apache 2.0 jetty-webapp Apache 2.0 jetty-xml Apache 2.0 sigar Apache 2.0 aopalliance-repackaged CDDLv1 javax.inject CDDLv1 hk2-api CDDLv1 hk2-locator CDDLv1 hk2-utils CDDLv1 osgi-resource-locator CDDLv1 jersey-guava CDDLv1 jersey-client CDDLv1 jersey-apache-connector CDDLv1 jersey-container-servlet-core CDDLv1 jersey-container-servlet CDDLv1 jersey-client CDDLv1 jersey-common CDDLv1 jersey-server CDDLv1 jersey-bean-validation CDDLv1 jersey-metainf-services CDDLv1 jersey-media-jaxb CDDLv1 jersey-client CDDLv1 jersey-test-framework-provider-inmemory CDDLv1 jersey-test-framework-core CDDLv1 javax.el CDDLv1 hamcrest-all BSD hamcrest-core BSD hamcrest-integration BSD hamcrest-library BSD HdrHistogram Public Domain hector-core MIT hibernate-commons-annotations LGPLv2.1 hibernate-jpa-2.0-api LGPLv2.1 hibernate-jpa-2.1-api LGPLv2.1 hibernate-c3p0 Apache 2.0 hibernate-core Apache 2.0 hibernate-ehcache Apache 2.0 hibernate-entitymanager Apache 2.0 hibernate-jmx Apache 2.0 hibernate-validator Apache 2.0 freebuilder Apache 2.0 org.jacoco.agent EPLv1.0 org.jacoco.ant EPLv1.0 org.jacoco.core EPLv1.0 org.jacoco.report EPLv1.0 javassist Apache 2.0 jboss-logging-annotations LGPLv2.1 jboss-logging Apache 2.0 jboss-transaction-api_1.1_spec LGPLv2.1 jboss-transaction-api_1.2_spec LGPLv2.1 jandex Apache 2.0 jdbi Apache 2.0 job-dsl-core Apache 2.0 version-number MIT kotlin-annotation-processing Apache 2.0 kotlin-reflect Apache 2.0 kotlin-runtime Apache 2.0 kotlin-stdlib Apache 2.0 kotlin-test-junit Apache 2.0 kotlin-test Apache 2.0 annotations Apache 2.0 jolokia-core Apache 2.0 jruby-complete LGPLv2.1 LGPLv2.1 json Public Domain json Apache 2.0 xstream BSD annotations Apache 2.0 mapdb Apache 2.0 mapdb Apache 2.0 jbcrypt ISC mockserver-client-java Apache 2.0 mockserver-core Apache 2.0 mockserver-logging Apache 2.0 mockserver-netty Apache 2.0 mockito-all MIT mockito-core MIT mockito-core MIT apache-el Apache 2.0 apache-jsp Apache 2.0 alpn-boot Apache 2.0 etcd4j Apache 2.0 msgpack Apache 2.0 objenesis Apache 2.0 objenesis Apache 2.0 jmh-core GPLv2 with Classpath Exception jmh-generator-annprocess GPLv2 with Classpath Exception jol-core GPLv2 with Classpath Exception asm-analysis BSD asm-analysis BSD asm-commons BSD asm-debug-all BSD asm-tree BSD asm-util BSD asm-util BSD asm BSD asm Public Domain postgresql BSD powermock-api-mockito Apache 2.0 powermock-api-support Apache 2.0 powermock-core Apache 2.0 powermock-module-junit4-common Apache 2.0 powermock-module-junit4 Apache 2.0 powermock-reflect Apache 2.0 lombok MIT reactive-streams Public Domain reflections WTFPL scala-java8-compat_2.11 Scala scala-parser-combinators_2.11 Scala scala-xml_2.11 Scala scala-library Scala scala-reflect Scala scalatest_2.10 Apache 2.0 scalatest_2.11 Apache 2.0 native-lib-loader BSD jsonassert Apache 2.0 jcl-over-slf4j MIT jul-to-slf4j MIT log4j-log4j12 MIT log4j-over-slf4j MIT slf4j-api MIT slf4j-ext MIT slf4j-log4j12 MIT slf4j-simple MIT spock-core Apache 2.0 spock-core Apache 2.0 spring-boot-actuator Apache 2.0 spring-boot-autoconfigure Apache 2.0 spring-boot-configuration-processor Apache 2.0 spring-boot-starter-actuator Apache 2.0 spring-boot-starter-aop Apache 2.0 spring-boot-starter-data-jpa Apache 2.0 spring-boot-starter-data-rest Apache 2.0 spring-boot-starter-jdbc Apache 2.0 spring-boot-starter-jetty Apache 2.0 spring-boot-starter-logging Apache 2.0 spring-boot-starter-test Apache 2.0 spring-boot-starter-tomcat Apache 2.0 spring-boot-starter-web Apache 2.0 spring-boot-starter Apache 2.0 spring-boot-test-autoconfigure Apache 2.0 spring-boot-test Apache 2.0 spring-boot Apache 2.0 spring-data-commons Apache 2.0 spring-data-jpa Apache 2.0 spring-data-rest-core Apache 2.0 spring-data-rest-webmvc Apache 2.0 spring-hateoas Apache 2.0 spring-plugin-core Apache 2.0 spring-aop Apache 2.0 spring-aspects Apache 2.0 spring-beans Apache 2.0 spring-context-support Apache 2.0 spring-context Apache 2.0 spring-core Apache 2.0 spring-core Apache 2.0 spring-expression Apache 2.0 spring-jdbc Apache 2.0 spring-orm Apache 2.0 spring-test Apache 2.0 spring-test Apache 2.0 spring-tx Apache 2.0 spring-web Apache 2.0 spring-webmvc Apache 2.0 xz Public Domain wasabi Apache 2.0 snappy-java Apache 2.0 xmlunit-core Apache 2.0 xmlunit-legacy Apache 2.0 snakeyaml Apache 2.0 JUnitParams Apache 2.0 postgresql BSD postgresql BSD jedis MIT scala-library Scala ion-java Apache 2.0 timeslice_service-thrift New Relic timeslice_service New Relic xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3_min Public Domain zkclient Apache 2.0 zookeeper Apache 2.0 CoffeeScript Library License CoffeeScript MIT coffin MIT JavaScript JavaScript License ie_html5/ie_html5.js MIT Angular.js MIT Angular UI directives for Bootstrap MIT Chart.js MIT Chosen JQuery plugin MIT Fullcalendar MIT Moment MIT Crash reporting Software License Apple OS X OS X Yosemite Xcode & Apple SDK Xcode license Label services Service License BoneCP Apache 2.0 Gradle Apache 2.0 Hibernate Apache 2.0 Spring Apache 2.0 Infrastructure Monitoring services Service License antlr BSD aopalliance Public Domain asm MIT cglib Apache 2.0 ch.qos.logback EPLv1.0 com.101tec Apache 2.0 com.amazonaws Apache 2.0 com.cenqua.clover Paid com.fasterxml.jackson.core Apache 2.0 com.fasterxml Apache 2.0 com.google.code.findbugs BSD com.google.guava Apache 2.0 com.googlecode.json-simple Apache 2.0 com.intellij Apache 2.0 New Relic com.squareup.dagger Apache 2.0 com.squareup Apache 2.0 com.yammer.metrics Apache 2.0 commons-codec Apache 2.0 commons-configuration Apache 2.0 commons-lang Apache 2.0 commons-logging Apache 2.0 dom4j BSD io.netty Apache 2.0 javax.annotation CDDLv1 javax.inject Apache 2.0 javax.servlet.jsp CDDLv1 javax.servlet Apache 2.0 javax.validation Apache 2.0 javax.websocket CDDLv1 jline BSD joda-time Apache 2.0 junit CPL log4j Apache 2.0 mysql GPLv2 with Classpath Exception net.sf.jopt-simple MIT org.apache.commons Apache 2.0 org.apache.httpcomponents Apache 2.0 org.apache.ivy Apache 2.0 org.apache.thrift Apache 2.0 org.apache.tomcat.embed Apache 2.0 org.apache.zookeeper Apache 2.0 org.codehaus.groovy Apache 2.0 org.codehaus.jackson Apache 2.0 org.easymock Apache 2.0 org.eclipse.jetty.orbit CDDLv1 org.eclipse.jetty.toolchain Apache 2.0 org.eclipse.jetty.websocket Apache 2.0 org.eclipse.jetty CDDLv1 org.glassfish.jersey.core CDDLv1 org.glassfish.web CDDLv1 org.glassfish CDDLv1 org.hamcrest BSD org.hibernate Apache 2.0 org.javassist Apache 2.0 org.jboss.logging LGPLv2.1 org.jenkins-ci.plugins Apache 2.0 org.jenkins-ci Apache 2.0 org.jetbrains Apache 2.0 org.jolokia Apache 2.0 org.jvnet.hudson BSD org.mockito MIT org.objenesis Apache 2.0 org.ow2.asm MIT org.reflections WTFPL org.scala-lang Scala org.slf4j MIT org.springframework.boot Apache 2.0 org.springframework Apache 2.0 org.xerial.snappy Apache 2.0 org.yaml Apache 2.0 xml-apis Apache 2.0 xmlpull Public Domain xmlunit Apache 2.0 xpp3 Public Domain .NET support uploader service Library License Amazon AWS SDK for Java Apache 2.0 Apache Commons Codec Apache 2.0 Gson Apache 2.0 Jetty Apache 2.0 Ruby gems Ruby gems Gem License aasm MIT actionmailer MIT actionpack MIT activeadmin MIT actionview MIT activejob MIT active_model_serializers MIT activemodel MIT activerecord MIT activerecord-deprecated_finders MIT activerecord-mysql2-adapter MIT activeresource MIT activesupport MIT addressable Apache 2.0 angularjs-rails MIT arbre MIT arel MIT arel MIT atomic Apache 2.0 atomic Apache-2.0 attr_required MIT awesome_print MIT backports MIT better_errors MIT binding_of_caller MIT bourbon MIT brwsr MIT browser-timezone-rails MIT builder MIT bundler MIT byebug MIT callsite MIT capistrano MIT capistrano-bundler MIT capistrano-ext MIT capistrano-rbenv MIT capistrano-stats MIT capybara MIT celluloid MIT CFPropertyList MIT chunky_png MIT ci_reporter MIT ci_reporter_rspec MIT clockwork MIT codeclimate-test-reporter MIT coderay MIT coderay MIT coffee-rails MIT coffee-script MIT coffee-script-source MIT columnize Ruby compass MIT compass-core MIT compass-import-once MIT compass-rails MIT concurrent-ruby MIT crack MIT crypt Unlicensed daemons MIT dalli MIT database_cleaner MIT debug_inspector MIT debugger-linecache MIT diff-lcs MIT docile MIT dotenv MIT dotenv-deployment MIT erubis MIT etcd MIT ethon MIT eventmachine Ruby excon MIT execjs MIT factory_girl MIT factory_girl_rails MIT faraday MIT faraday-middleware MIT faye-websocket MIT ffi MIT ffi BSD fission MIT fog MIT fog-atmos MIT fog-aws MIT fog-brightbox MIT fog-core MIT fog-ecloud MIT fog-google MIT fog-json MIT fog-local MIT fog-powerdns MIT fog-profitbricks MIT fog-radosgw MIT fog-riakcs MIT fog-sakuracloud MIT fog-serverlove MIT fog-softlayer MIT fog-storm_on_demand MIT fog-terremark MIT fog-vmfusion MIT fog-voxel MIT fog-xml MIT font-awesome-rails MIT foreman MIT formatador MIT formtastic MIT formtastic i18n MIT fssm MIT globalid MIT guard MIT guard-rspec MIT haml MIT haml-rails MIT has scope MIT hashie MIT highline Ruby hike MIT hipchat-api MIT histogram MIT hitimes ISC hiredis BSD http_parser.rb MIT httpclient Ruby httpclient Ruby httparty MIT i18n MIT inflecto MIT inherited resources MIT intercom-rails MIT ipaddress MIT jasmine MIT jasmine-core MIT jasmine-rails MIT jbuilder MIT jira MIT jira-ruby OSL-3.0 journey MIT jquery-rails MIT jquery-turbolinks MIT jquery-ui-rails MIT json Ruby jwt MIT kaminari MIT kgio LGPLv3 kgio LGPLv3 kgio LGPL-v2.1+ libv8 MIT listen MIT logger Ruby loofah MIT lumberjack MIT macaddr MIT mail MIT mailcatcher MIT memoist MIT metaclass MIT meta_request MIT method_source MIT mime-types MIT mini_portile MIT minitest MIT minitest-rails MIT mixlib-log Apache 2.0 mocha MIT mono_logger MIT multi_json MIT multi_xml MIT multipart-post MIT mysql2 MIT net-http-persistent MIT net-scp MIT net-sftp MIT net-ssh MIT net-ssh-gateway MIT netrc MIT nokogiri MIT oauth2 MIT oj MIT omniauth MIT omniauth-oauth2 MIT pagerduty MIT papers MIT pg BSD pg Ruby phantomjs BSD phantomjs-binaries Unlicensed poltergeist MIT polyamorous MIT polyglot MIT polyglot MIT protected_attributes MIT pry MIT pry-nav MIT pry-rails MIT pry-stack_explorer MIT puma BSD quiet assets MIT rack MIT rack-cache MIT rack-contrib MIT rack-oauth2 MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-protection MIT rack-ssl MIT rack-ssl-enforcer MIT rack-test MIT rails MIT rails-deprecated_sanitizer MIT rails-dom-testing MIT rails-html-sanitizer MIT rails-observers MIT rails_12factor MIT rails_serve_static_assets MIT rails_stdout_logging MIT railties MIT raindrops LGPLv3 raindrops LGPLv3 raindrops LGPLv2.1+ rake MIT rake MIT rake MIT rake MIT ransack MIT rb-fsevent MIT rb-inotify MIT rdoc Ruby redcarpet MIT redis MIT redis-namespace MIT redis-queue MIT ref MIT remote_syslog_logger MIT request_store MIT responders MIT resque MIT resque-cleaner MIT resque-pool MIT resque-scheduler MIT resque-status MIT rest-client MIT restforce MIT rspec MIT rspec-core MIT rspec-expectations MIT rspec-mocks MIT rspec-rails MIT rspec-support MIT rspec_junit_formatter MIT rubyntlm MIT ruby-saml MIT rufus-scheduler MIT safe_yaml MIT salesforce_bulk_query BSD sass MIT sass-rails MIT sass-rails MIT sdoc MIT secure_headers Apache 2.0 sequel MIT serveza MIT settingslogic MIT shoulda MIT shoulda-context MIT shoulda-matchers MIT simplecov MIT simplecov-html MIT simplecov-rcov MIT sinatra MIT sinatra-activerecord MIT sinatra-contrib MIT skinny MIT slop MIT spring MIT sprockets MIT sprockets-rails MIT sqlite3 BSD sshkit GPL-No Distro sys-uname Ruby syslog_protocol MIT systemu BSDL term-ansicolor GPL-No Distro terminal-table MIT therubyracer MIT thin Ruby thor MIT thread_safe Apache-2.0 thrift Apache 2.0 thrift-rack MIT tilt MIT timecop MIT timers MIT tins MIT treetop MIT turbolinks MIT twitter-bootstrap-rails MIT typhoeus MIT tzinfo MIT uglifier MIT unicorn Ruby unicorn-rails MIT uuid MIT uuidtools Apache-2.0 vegas MIT webmock MIT web-console MIT xml-simple Ruby xpath MIT yard MIT Storage services Library License Amazon AWS SDK for Java Apache 2.0 Amazon AWS Command Line Interface Apache 2.0 Go packages Library License Go-Mysql-Driver Mozilla Public License 2.0 gocql BSD 3-Clause groupcache Apache 2.0 Migrate MIT go-sqlite3 MIT Revel MIT Pathtree MIT Ansicolor MIT fsnotify BSD 3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.69066,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Services <em>licenses</em>",
        "sections": "Services <em>licenses</em>",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in various New Relic services. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Contents Java internal"
      },
      "id": "603ea24364441f91fb4e8864"
    },
    {
      "sections": [
        "Add-on end user license agreement",
        "New Relic, Inc. Add-on End User License Agreement"
      ],
      "title": "Add-on end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "a01c225ca30f95dab7db856cd946c76de557c31f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T06:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic, Inc. Add-on End User License Agreement In connection with the work provided by New Relic's Expert Services, Field Instrumentation Team, or Sales team, you may be provided with certain custom-created software to visualize, enable, optimize, or enhance your use of New Relic's Services. By downloading, installing, authorizing installation, or using the Add-on (defined below) with your Underlying Software (defined below), you (Customer) agree to the terms and conditions herein (Agreement) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (New Relic\"), (collectively the Parties). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the Terms of Service) available here: newrelic.com/termsandconditions/terms. IF YOU DO NOT AGREE TO THIS AGREEMENT, YOUR SOLE REMEDY IS TO NOT USE THE ADD-ON. 1. DEFINITIONS Add-on means the New Relic applications and/or software, including but not limited to connectors, extensions, UI extension, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (Underlying Software). For the purposes of the Terms of Service, the Add-on shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE PROGRAMMABILITY ADD-ON 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the Add-on solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the Add-on and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the Add-on in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (Feedback) regarding the Add-on, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the Add-on is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that Add-on will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an Upgrade Event). Customer shall hold New Relic harmless from any claims or damages arising from Customers Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the Add-on except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the Add-on; (iii) decompile, disassemble or reverse engineer any software underlying the Add-on; (iv) use the Add-on to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other partys use and enjoyment of the Services; (v) use the Add-on to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the Add-on; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend Customer usage of the Services, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time on the New Relic web site at docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential Information means: (a) the Programmability Add-on, and any features, results or output produced by, and other information relating to the Add-on (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. THE ADD-ON IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. THE ADD-ON IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE, OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE ADD-ON THEREFROM. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE ADD-ON OR FOR ANY ERROR OR DEFECT IN THE ADD-ON OR THE SERVICES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELICS AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND CUSTOMER. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the Add-on is not an official product and has not been commercially released for sale by New Relic; (b) the Add-on may not operate properly, being in final form, or fully functional; (c) the Add-on may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the Add-on fully functional; (e) the information obtained using the Add-on may not be accurate; (f) use of the Add-on may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the Add-on; and (h) New Relic has the right unilaterally to abandon development of the Add-on, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the Documentation). This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the Add-on. In the absence of a separate agreement, upon agreement between New Relic and Customer with respect to the Add-On, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such Add-On. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the Add-on only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.18098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add-on end user <em>license</em> agreement",
        "sections": "Add-on end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential <em>Information</em> means: (a) the Programmability Add-on, and any features, results or output produced by, and other <em>information</em> relating to the Add-on (including, without limitation"
      },
      "id": "603ec23328ccbccf1beba79a"
    },
    {
      "sections": [
        "FIT instrumentation end user license agreement"
      ],
      "title": "FIT instrumentation end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "e8e10baf120678407d08c9f78ab708d271cf0223",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement/",
      "published_at": "2021-06-15T13:30:43Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NEW RELIC, INC. FIT INSTRUMENTATION END USER LICENSE AGREEMENT In connection with the work provided by New Relics Field Instrumentation Team, you may be provided with certain custom-created software to enable, optimize, or enhance your use of New Relics Services. By downloading, installing, authorizing installation, or using the FIT Instrumentation with your Underlying Software (defined below), you (Customer) agree to the terms and conditions herein (Agreement) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (New Relic), (collectively the Parties). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the Terms of Service) available here: http://newrelic.com/terms IF YOU DO NOT AGREE TO THIS AGREEMENT, PLEASE DO NOT USE THE FIT INSTRUMENTATION. 1. DEFINITIONS FIT Instrumentation means the New Relic custom-made software, including but not limited to connectors, extensions, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (Underlying Software). For the purposes of the Terms of Service, the FIT Instrumentation shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE FIT INSTRUMENTATION 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the FIT Instrumentation solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the FIT Instrumentation and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the FIT Instrumentation in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (Feedback) regarding the FIT Instrumentation, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the FIT Instrumentation is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that FIT Instrumentation will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an Upgrade Event). Customer shall hold New Relic harmless from any claims or damages arising from Customers Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the FIT Instrumentation except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the FIT Instrumentation; (iii) decompile, disassemble or reverse engineer any software underlying the FIT Instrumentation; (iv) use the FIT Instrumentation to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other partys use and enjoyment of the Services; (v) use the FIT Instrumentation to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the FIT Instrumentation; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend usage of the Services by any user, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time at https://docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential Information means: (a) the FIT Instrumentation, and any features, results or output produced by, and other information relating to the FIT Instrumentation (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. FIT INSTRUMENTATION IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. FIT INSTRUMENTATION IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE. , OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE FIT INSTRUMENTATION THEREFROM. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES OR LIMITATIONS ON APPLICABLE STATUTORY RIGHTS OF A CONSUMER, SO THE ABOVE EXCLUSION AND LIMITATIONS MAY NOT APPLY TO THE CUSTOMER. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE FIT INSTRUMENTATION OR FOR ANY ERROR OR DEFECT IN THE FIT INSTRUMENTATION OR THE SERVICES, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON CONTRACT, WARRANTY, TORT, STRICT LIABILITY, OR OTHERWISE, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC'S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the FIT Instrumentation is not an official product and has not been commercially released for sale by New Relic; (b) the FIT Instrumentation may not operate properly, being in final form, or fully functional; (c) the FIT Instrumentation may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the FIT Instrumentation fully functional; (e) the information obtained using the FIT Instrumentation may not be accurate; (f) use of the FIT Instrumentation may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the FIT Instrumentation; and (h) New Relic has the right unilaterally to abandon development of the FIT Instrumentation, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the \"Documentation\").This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the FIT Instrumentation. In the absence of a separate agreement between New Relic and Customer with respect to the FIT Instrumentation, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such FIT Instrumentation. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the FIT Instrumentation only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.16675,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "FIT instrumentation end user <em>license</em> agreement",
        "sections": "FIT instrumentation end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " Acceptable Use Policy as may be published and updated from time to time at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential <em>Information</em> means: (a) the FIT Instrumentation, and any features, results"
      },
      "id": "603e9f3ee7b9d206e32a0800"
    }
  ],
  "/docs/licenses/license-information/faq/new-relic-one-pricing-plan-frequently-asked-questions": [
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.80532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": ". Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer"
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-05-22T17:24:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.80464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ebacc64441f77774e8872"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.54189,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": " <em>information</em> about using New Relic features, visit New Relic University and newrelic.com&#x2F;resources. For more help Recommendations for learning more: See the Docs site&#x27;s landing page for <em>Licenses</em> documentation. Browse New Relic&#x27;s Explorers Hub for community discussions about New Relic <em>licenses</em>."
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.7398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (PRC Use). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.8424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-06-15T13:32:51Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your accounts limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings": [
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (PRC Use). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.8424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relics Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-06-15T13:31:55Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relics mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (AUP). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the New Relic Properties) and is part of the New Relic documentation, which can be found at https://docs.newrelic.com (the Documentation). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relics Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relics or a third partys intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using botnets, robots, spiders and offline readers); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other hidden text; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including scraping or using any data mining methods); Sharing your New Relic Properties account or login credentials with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other users account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by spoofing or phishing); Collecting or harvesting any personally identifiable information, including account names, from any other users account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other peoples private and confidential information without their express permission; Using anyones name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (HIPAA); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any personal information as such term is defined under the Childrens Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, drivers license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; or (vii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R.  120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if youre a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term content means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, you may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and we means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Social Security numbers, drivers <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-06-15T13:32:51Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your accounts limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/government-addendum": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.73979,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (PRC Use). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.8424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relics Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-06-15T13:31:55Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relics mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (AUP). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the New Relic Properties) and is part of the New Relic documentation, which can be found at https://docs.newrelic.com (the Documentation). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relics Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relics or a third partys intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using botnets, robots, spiders and offline readers); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other hidden text; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including scraping or using any data mining methods); Sharing your New Relic Properties account or login credentials with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other users account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by spoofing or phishing); Collecting or harvesting any personally identifiable information, including account names, from any other users account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other peoples private and confidential information without their express permission; Using anyones name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (HIPAA); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any personal information as such term is defined under the Childrens Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, drivers license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; or (vii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R.  120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if youre a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term content means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, you may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and we means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Social Security numbers, drivers <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.73979,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (PRC Use). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.8424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relics Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-06-15T13:31:55Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relics mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (AUP). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the New Relic Properties) and is part of the New Relic documentation, which can be found at https://docs.newrelic.com (the Documentation). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relics Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relics or a third partys intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using botnets, robots, spiders and offline readers); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other hidden text; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including scraping or using any data mining methods); Sharing your New Relic Properties account or login credentials with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other users account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by spoofing or phishing); Collecting or harvesting any personally identifiable information, including account names, from any other users account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other peoples private and confidential information without their express permission; Using anyones name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (HIPAA); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any personal information as such term is defined under the Childrens Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, drivers license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; or (vii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R.  120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if youre a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term content means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, you may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and we means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Social Security numbers, drivers <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/new-relics-provision-services": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.73978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "The People's Republic of China"
      ],
      "title": "The People's Republic of China",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "c3c078b8139d695b928d2001cd6c6c9318c43599",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/peoples-republic-china/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important Information Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory requirements in the PRC. New Relic does not provide support for, including but not limited to, the deployment, access, or use of the Service(s) or Software in the PRC, or otherwise in respect of assets in the PRC (PRC Use). Without overriding any express prohibitions that you may have agreed to as part of your agreement with New Relic, you (and you as an agent of the respective New Relic Customer (\"Customer\")) acknowledge that any PRC use is subject to the PRC national firewall system and may be subject to outages and other interference outside of the control of New Relic. Accordingly, you acknowledge and agree (on behalf of yourself and including any Customer on whose behalf you use the Service(s) or Software) that any PRC Use is at your sole risk and is fully excepted from all representations and warranties, including, but not limited to, any terms that assure the confidentiality, integrity, availability or privacy of your data. New Relic makes no other representations and hereby expressly disclaims any and all warranties in respect of PRC Use.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.8424,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "Important <em>Information</em> Regarding the Peoples Republic of China and the Use of New Relic New Relic is not authorized to do business in the Peoples Republic of China (PRC). The Service(s) and Software are not designed, tested, or certified for compliance with any operational or regulatory"
      },
      "id": "603eb3a328ccbcb488eba76b"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relics Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-06-15T13:31:55Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relics mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (AUP). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the New Relic Properties) and is part of the New Relic documentation, which can be found at https://docs.newrelic.com (the Documentation). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relics Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relics or a third partys intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using botnets, robots, spiders and offline readers); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other hidden text; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including scraping or using any data mining methods); Sharing your New Relic Properties account or login credentials with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other users account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by spoofing or phishing); Collecting or harvesting any personally identifiable information, including account names, from any other users account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other peoples private and confidential information without their express permission; Using anyones name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (HIPAA); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any personal information as such term is defined under the Childrens Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, drivers license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; or (vii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R.  120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if youre a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term content means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, you may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and we means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Social Security numbers, drivers <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    }
  ],
  "/docs/licenses/license-information/general-usage-licenses/peoples-republic-china": [
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 234.73975,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Troubleshooting problems with ingesting data into New Relic <em>General</em> <em>usage</em> and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments &amp; frameworks Our Products"
      },
      "id": "603ea419e7b9d27b942a07b4"
    },
    {
      "sections": [
        "Acceptable use policy",
        "You will not, and not to allow third parties, in connection with your use of the New Relic Properties to:",
        "Harm New Relics Properties and interests, such as:",
        "Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as:",
        "Violate any applicable law or regulation or for high-risk purposes, such as:",
        "New Relic Properties do not include Third-Party Services",
        "Updates, Contact Information and Violations"
      ],
      "title": "Acceptable use policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b006ab295dae6522e8c76fcd47b3a0d4a45938e4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/acceptable-use-policy/",
      "published_at": "2021-06-15T13:31:55Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relics mission is to instrument, measure and improve the internet to help our customers create more perfect software, experiences and businesses. We strive to keep our resources operating efficiently, so our services are available to all subscribers. Because you have access to shared resources, we have put these rules in place to ensure everyone has a great experience. For example, you as a tenant would not want other tenants to engage in the types of activities described below. To help us do this, we have put some rules in place regarding your use of the New Relic Properties and created this Acceptable Use Policy (AUP). This AUP applies if you use any New Relic product, service, software, website, forum, page or system (collectively, the New Relic Properties) and is part of the New Relic documentation, which can be found at https://docs.newrelic.com (the Documentation). You will not, and not to allow third parties, in connection with your use of the New Relic Properties to: Harm New Relics Properties and interests, such as: Uploading, transmitting or otherwise provide content that infringes New Relics or a third partys intellectual property, privacy or other rights, violates applicable laws or regulations or contains viruses, worms, harmful code, malware or other harmful materials; Hosting, selling, reselling, renting, exploiting, sublicensing, leasing, or otherwise providing the New Relic Properties or any portion thereof or use such for time sharing purposes or on a service bureau basis without our express written permission; Modifying, disabling, or compromising the integrity or performance of the New Relic Properties or related systems, networks, or data; including by: Attempting to compromise the integrity of the New Relic Properties, including probing, scanning or testing the vulnerability of any part of the New Relic Properties without proper authorization; Overwhelming our infrastructure (such as by using botnets, robots, spiders and offline readers); Going beyond the use parameters for any given service as described in the corresponding Documentation; Using metatags or other hidden text; Drastically exceeding your contracted rate of use as set forth in your order or the Documentation; or Consuming an unreasonable amount of storage. Accessing any unauthorized part of the New Relic Properties, or accessing or searching any part of the New Relic Properties by means other than those provided or authorized by New Relic (including scraping or using any data mining methods); Sharing your New Relic Properties account or login credentials with any other individual; Deciphering or decrypting transmissions, circumventing any access, authentication or copy restrictions, or otherwise attempting to compromise the security of the New Relic Properties (including any other users account); Accessing the New Relic Properties in order to build a similar or competitive website, application or service; or Attempting to do anything else that may result in some form of adverse impact to the New Relic Properties or use of the New Relic Properties by any of our other customers. Harass others or engage in activity that is unlawful, invasive, infringing, defamatory, fraudulent or violates anyone's legal rights, such as: Posting or transmitting abusive messages, defamatory, libelous, false or misleading statements, hate speech or messages that incite or threaten violence, or stalk or harass others; Promoting, encouraging, or facilitating hate speech, violence, discrimination based on race, color, sexual orientation, marital status, gender or identity expression, parental status, religion or creed, national origin or ancestry, sex, age, physical or mental disability, veteran status, genetic information, citizenship and/or any other characteristic protected by law. You are not permitted to use New Relic Properties if you are an entity identified by nationally-recognized non-profits as engaging in such activities. Attempting to modify or gain unauthorized use of or access to, another user's account, website, application, system, equipment or data; Misrepresenting yourself, impersonating another person, falsely implying any sponsorship or association with New Relic or affiliation with any third party, engaging in fraud, hiding or attempt to hide your identity or disguising the origin of any content (including by spoofing or phishing); Collecting or harvesting any personally identifiable information, including account names, from any other users account or the New Relic Properties, or using the New Relic Properties to violate the privacy of others; Including, publishing or posting other peoples private and confidential information without their express permission; Using anyones name or trademarks without their express written permission; Using the New Relic Properties to generate or send unsolicited communications, advertising, chain letters, or spam; Soliciting our users for commercial purposes, unless expressly permitted in writing by New Relic; Disparaging anyone; or Disclosing any confidential information obtained through any method contrary to this AUP. Violate any applicable law or regulation or for high-risk purposes, such as: Using the New Relic Properties in violation of any applicable law or regulation, including data, privacy, and export control laws in applicable jurisdictions; Using the New Relic Properties in any situation for which they are not designed, manufactured or intended, such as for use in life support, emergency or mission critical circumstances, or in any activities where use or failure of the New Relic Properties could lead to death, personal injury or property or environmental damage. For example, you may not use, or permit any other person to use, the New Relic Properties in connection with aircraft or other modes of human mass transportation or nuclear or chemical facilities, life support systems, implantable medical equipment, motor vehicles, or weaponry systems; or Processing or submitting any personal data that could be legally considered sensitive in any applicable jurisdiction, including, but not limited to: (i) patient, medical, or other protected health information regulated by the Health Insurance Portability and Accountability Act (as amended and supplemented) (HIPAA); (ii) personal data about individuals under the age of 16, which for the avoidance of doubt includes any personal information as such term is defined under the Childrens Online Privacy Protection Act; (iii) government issued identification numbers, including Social Security numbers, drivers license numbers and other state-issued identification numbers; (iv) financial account information, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account, including the combination of a username or email address along with a password or security question and answer that would permit access to an online account; (vi) special categories of sensitive personal data, (such as defined under Regulation (EU) 2016/679 of the European Parliament), including personal data revealing racial or ethnic origin, political opinions, religious beliefs, trade union membership, physical or mental health or condition, sexual life, sexual orientation, genetic data, biometric data, or the commission or alleged commission any crime or offense; or (vii) any data similar to the above protected under foreign or domestic laws, including without limitation any data subject to regulation under the International Traffic in Arms Regulations (ITAR), 22 C.F.R.  120-130. You represent and warrant to New Relic that you have all necessary rights, consents, and permissions to use and submit data that you send to the New Relic Properties, all without violating or infringing any applicable laws, third-party rights (including intellectual property, publicity, or privacy rights), or any terms or policies governing such data. New Relic Properties do not include Third-Party Services If you choose to use any Third Party Services, your use of Third-Party Services is wholly subject to your separate agreement with the relevant provider. New Relic bears no responsibility or liability for Third-Party Services. If you enable a Third-Party Service with the New Relic Properties, New Relic may access and exchange Customer Data with the Third-Party Service on your behalf and instruction. Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a User integrates or enables for use with the Service, including third-party applications and plug-ins. Open source software that New Relic makes separately available for download (e.g. community tools) is, as required, governed by the terms of the applicable open source license. The license for any open source software identified as included in New Relic Properties will, as required, wholly apply to your use of that open source software. Updates, Contact Information and Violations We will occasionally need to modify this AUP to help us continue to provide you with a great experience while using the New Relic Properties. In the event we modify this AUP, we will do so by posting a revised version, and any changes will be effective immediately if youre a new user of the New Relic Properties and thirty (30) days after posting for all other users. If you continue using the New Relic Properties after we update this AUP, you agree to the latest version of this AUP. You can report a violation of this AUP to: AUP@newrelic.com. Or by mail at: Attn: Legal New Relic, Inc. 188 Spear Street, Suite 1200 San Francisco, CA 94105 This AUP, and our customers compliance with it, is essential for enabling us to provide you and our other customers with the New Relic Properties, which we take very seriously. You are wholly and solely responsible for appropriate configuration of systems and software that you own or can control to ensure your compliance with this AUP. So, if we determine in our sole discretion that you have violated this AUP, we may, without limiting any other remedies available to us, permanently or temporarily suspend, limit, or terminate your access to the New Relic Properties without notice or liability. This right applies even if the breach is unintentional or unauthorized if we believe that any such suspension, limitation, or termination is necessary to ensure compliance with laws, or to protect the rights, safety, privacy, security, or property of us or others. In this AUP, the term content means: (1) any information, data, text, software, code, scripts, music, sound, photos, graphics, videos, messages, tags, interactive features, or other materials that you post, upload, share, submit, or otherwise provide in any manner to the services and (2) any other materials, content, or data you provide to New Relic or use with the New Relic Properties. As used in this AUP, you may refer to an individual user or the legal entity an individual user is employed by that has contracted with New Relic, and we means New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Updates, Contact <em>Information</em> and Violations",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": " Social Security numbers, drivers <em>license</em> numbers and other state-issued identification numbers; (iv) financial account <em>information</em>, including financial account numbers or payment card data (including credit card or debit card numbers); (v) credentials granting access to an online account"
      },
      "id": "603e93bf28ccbc99f3eba7bc"
    },
    {
      "sections": [
        "New Relic data usage limits and policies",
        "Overview of limits",
        "View limits and manage data",
        "Account-level limits",
        "Data ingest APIs",
        "Other agent and integration limits",
        "Manage data"
      ],
      "title": "New Relic data usage limits and policies",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "fc32c25b40a030ffa0fad6bfc95be7fca1360ee1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/new-relic-data-usage-limits-policies/",
      "published_at": "2021-06-15T13:32:51Z",
      "updated_at": "2021-03-16T04:21:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data usage spikes in one New Relic account from impacting other customers' accounts, we have various data volume and rate limits in place. We reserve the right to enforce these limits to protect our system and to avoid issues for you and other customers. If your New Relic account, whether by configuration or by error, exceeds one of these limits, it or its sub-accounts might experience one or both of the following: Sampling of data Temporary pause or cessation of data collection To learn more about how hitting a limit can affect your data, see View limits. If you have further questions about these limits, your contract, or a limit you've reached, contact your New Relic account representative. We can work with you to adjust any rate limits to meet your needs. View limits and manage data Want to understand your accounts limit violations using the UI? See View limits. Want to manage your data for organization or billing purposes? See Manage data. Account-level limits The following table includes general max limits that apply across all New Relic accounts. Specific New Relic tools, like agents and integrations, have their own limits and configurations, and might be lower than these theoretical maximum limits. Limited condition Limit Rate of NRDB record * ingest 55 million per account per minute Max NRDB records * ingested per API call 1MB (10^6 bytes) Max attribute value size 1KB (10^3 bytes) Max payload size 1MB (10^6 bytes) Max total attributes per data type (including default attributes) 254 (less for some tools; for example, 64 for agents) Number of unique custom data types 250 per account per day (applies to custom events because that's source of new data types) APM limits Agent instances: 50K per account Agent instances per app: 10K APM apps/services: 10K per second Browser: number of page views 1M per minute per app Rate of metric timeslice data (used by APM, browser, mobile) Ingest: 2 million per minute Rate of names: 4 million per minute per account Number per monitored app: 300K Mobile monitoring: number of crashes reported 10K per hour Infrastructure agents, integrations Number of infrastructure agents and/or integrations: 5K per account Gross number of new monitored containers: 5K per hour per account Query limits NRDB records * inspected: 100 billion per account per hour Rate of queries: 20 per account per second See other query limits * NRDB records refers to database records for our core data types, which includes events, metrics (dimensional), logs, and distributed tracing (span) data, all stored in the New Relic database (NRDB). This does not include metric timeslice data. Data ingest APIs Our ingest APIs have additional limits that may override the more general account-level limits. Note that these limits also apply to our tools that use these APIs (like our Telemetry SDKs or our open source telemetry integrations). Metric API (dimensional metrics) Event API Log API Trace API Other agent and integration limits To find limits for our other agents and integrations, which will override more general account-level limits, see the docs for those tools: you can search our solutions here. Some default reporting limits are located in these tools' configuration docs. Manage data Want to manage your New Relic data ingest and storage to improve data organization or reduce billing? See Manage data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.83945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic data <em>usage</em> limits and policies",
        "sections": "New Relic data <em>usage</em> limits and policies",
        "tags": "<em>General</em> <em>usage</em> <em>licenses</em>",
        "body": "This document lists some important account-level limits and links to other limit-related docs. Overview of limits We strive to keep our resources operating efficiently so that our services are available to all our users. To prevent data <em>usage</em> spikes in one New Relic account from impacting other"
      },
      "id": "603eb1c528ccbc0311eba7c7"
    }
  ],
  "/docs/licenses/license-information/other-licenses/services-licenses": [
    {
      "sections": [
        "Add-on end user license agreement",
        "New Relic, Inc. Add-on End User License Agreement"
      ],
      "title": "Add-on end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "a01c225ca30f95dab7db856cd946c76de557c31f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/add-end-user-license-agreement/",
      "published_at": "2021-06-15T13:29:42Z",
      "updated_at": "2021-03-16T06:19:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic, Inc. Add-on End User License Agreement In connection with the work provided by New Relic's Expert Services, Field Instrumentation Team, or Sales team, you may be provided with certain custom-created software to visualize, enable, optimize, or enhance your use of New Relic's Services. By downloading, installing, authorizing installation, or using the Add-on (defined below) with your Underlying Software (defined below), you (Customer) agree to the terms and conditions herein (Agreement) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (New Relic\"), (collectively the Parties). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the Terms of Service) available here: newrelic.com/termsandconditions/terms. IF YOU DO NOT AGREE TO THIS AGREEMENT, YOUR SOLE REMEDY IS TO NOT USE THE ADD-ON. 1. DEFINITIONS Add-on means the New Relic applications and/or software, including but not limited to connectors, extensions, UI extension, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (Underlying Software). For the purposes of the Terms of Service, the Add-on shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE PROGRAMMABILITY ADD-ON 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the Add-on solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the Add-on and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the Add-on in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (Feedback) regarding the Add-on, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the Add-on is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that Add-on will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an Upgrade Event). Customer shall hold New Relic harmless from any claims or damages arising from Customers Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the Add-on except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the Add-on; (iii) decompile, disassemble or reverse engineer any software underlying the Add-on; (iv) use the Add-on to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other partys use and enjoyment of the Services; (v) use the Add-on to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the Add-on; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend Customer usage of the Services, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time on the New Relic web site at docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential Information means: (a) the Programmability Add-on, and any features, results or output produced by, and other information relating to the Add-on (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. THE ADD-ON IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. THE ADD-ON IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE, OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE ADD-ON THEREFROM. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE ADD-ON OR FOR ANY ERROR OR DEFECT IN THE ADD-ON OR THE SERVICES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELICS AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND CUSTOMER. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the Add-on is not an official product and has not been commercially released for sale by New Relic; (b) the Add-on may not operate properly, being in final form, or fully functional; (c) the Add-on may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the Add-on fully functional; (e) the information obtained using the Add-on may not be accurate; (f) use of the Add-on may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the Add-on; and (h) New Relic has the right unilaterally to abandon development of the Add-on, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the Documentation). This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the Add-on. In the absence of a separate agreement, upon agreement between New Relic and Customer with respect to the Add-On, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such Add-On. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the Add-on only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.18097,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add-on end user <em>license</em> agreement",
        "sections": "Add-on end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": "&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential <em>Information</em> means: (a) the Programmability Add-on, and any features, results or output produced by, and other <em>information</em> relating to the Add-on (including, without limitation"
      },
      "id": "603ec23328ccbccf1beba79a"
    },
    {
      "sections": [
        "New Relic Agent Software Notice"
      ],
      "title": "New Relic Agent Software Notice",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "2bf9501c2767105130d3808f1bf3a91a032d903e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/new-relic-agent-software-notice/",
      "published_at": "2021-06-15T13:30:43Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This software is  2008-2021 New Relic, Inc. and its licensors. This software is solely for use with New Relics proprietary SaaS service (New Relic Service), so to use the software you must have a valid account for the New Relic Service under a separate agreement with New Relic (Subscription Agreement). You may only use the software to support your use of the New Relic Service as permitted in the Subscription Agreement. Without a Subscription Agreement, you may not use the software. All other use is prohibited. New Relic and its suppliers retain all right, title and interest (including intellectual property rights) in the software. The Subscription Agreement will control in event of a conflict with this notice. Unless otherwise agreed by New Relic in your Subscription Agreement: You may not use, copy, distribute or sublicense the software, use the software on behalf of third parties, reverse engineer or decompile the software, modify or create derivative works of the software, use the software for competitive analysis or benchmarking, or remove or obscure any proprietary notices in the software. The software is provided AS IS and New Relic disclaims all warranties, whether express, implied, statutory or otherwise, including warranties of merchantability, fitness for a particular purpose, title or noninfringement. To the full extent permitted by law, New Relic will have no liability arising from or related to the software or under this notice for any direct, indirect, special, incidental, or consequential damages of any kind, even if advised of their possibility in advance, and regardless of legal theory (whether contract, tort, negligence, strict liability or otherwise). The software may contain third-party open source software (OSS) as described here and at https://github.com/newrelic. To the extent required by the OSS license, that license will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile and as set forth: https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/get-started and https://docs.newrelic.com/docs/browser/new-relic-browser/installation/install-new-relic-browser-agent Software versions New Relic makes available under an OSS license (such as Apache 2.0) are governed by the terms of the applicable OSS license. For a current list of New Relic software versions released as OSS please visit https://opensource.newrelic.com/.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.16673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " and at https:&#x2F;&#x2F;github.com&#x2F;newrelic. To the extent required by the OSS <em>license</em>, that <em>license</em> will apply to the OSS when used on a stand-alone basis. For avoidance of doubt, you may copy and distribute New Relic agents pursuant to your Subscription Agreement for New Relic Browser and New Relic Mobile"
      },
      "id": "603eb73828ccbc1f99eba74a"
    },
    {
      "sections": [
        "FIT instrumentation end user license agreement"
      ],
      "title": "FIT instrumentation end user license agreement",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Distributed licenses"
      ],
      "external_id": "e8e10baf120678407d08c9f78ab708d271cf0223",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/distributed-licenses/fit-instrumentation-end-user-license-agreement/",
      "published_at": "2021-06-15T13:30:43Z",
      "updated_at": "2021-03-16T04:20:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NEW RELIC, INC. FIT INSTRUMENTATION END USER LICENSE AGREEMENT In connection with the work provided by New Relics Field Instrumentation Team, you may be provided with certain custom-created software to enable, optimize, or enhance your use of New Relics Services. By downloading, installing, authorizing installation, or using the FIT Instrumentation with your Underlying Software (defined below), you (Customer) agree to the terms and conditions herein (Agreement) with New Relic, Inc., a Delaware corporation with offices located at 188 Spear Street, Suite 1200 San Francisco, CA 94105 (New Relic), (collectively the Parties). Capitalized terms not defined herein shall have the meanings set forth in the New Relic Terms of Service (the Terms of Service) available here: http://newrelic.com/terms IF YOU DO NOT AGREE TO THIS AGREEMENT, PLEASE DO NOT USE THE FIT INSTRUMENTATION. 1. DEFINITIONS FIT Instrumentation means the New Relic custom-made software, including but not limited to connectors, extensions, and plugins, provided by New Relic to Customer to enable the Services to operate with certain third party or Customer software or systems (Underlying Software). For the purposes of the Terms of Service, the FIT Instrumentation shall be treated like an Agent, subject to the separate terms herein. 2. USE OF THE FIT INSTRUMENTATION 2.1 Software Evaluation License. Subject to the terms herein, New Relic grants to Customer a limited, non-exclusive, non-transferrable, non-sublicensable right to install, use, and configure the FIT Instrumentation solely as needed to enable the Services for internal evaluation purposes. New Relic reserves all rights and licenses not expressly granted herein. 2.2 Ownership. As between the Parties, New Relic owns all right, title, and interest to the FIT Instrumentation and Feedback, including but not limited to any intellectual property and proprietary rights therein. Customer retains all right, title, and interest in any Customer Data processed by the FIT Instrumentation in connection with the Services. 2.3 Feedback. Customer agrees to provide feedback, suggestions, ideas, requests or recommendations (Feedback) regarding the FIT Instrumentation, and hereby irrevocably assigns all intellectual property and proprietary rights it holds in the Feedback to New Relic. 2.4 Notice. Customer acknowledges and agrees that the FIT Instrumentation is made to work with the Underlying Software as configured at the time of creation and there is no guarantee that FIT Instrumentation will continue to work in the event Customer changes, replaces, upgrades versions of, updates, or otherwise changes the Underlying Software (an Upgrade Event). Customer shall hold New Relic harmless from any claims or damages arising from Customers Upgrade Event. 2.5 Restrictions. Customer will not: (i) use the FIT Instrumentation except as permitted hereunder; (ii) distribute, sell, sublicense, or otherwise transfer the FIT Instrumentation; (iii) decompile, disassemble or reverse engineer any software underlying the FIT Instrumentation; (iv) use the FIT Instrumentation to damage, disable, overburden or impair any New Relic server or network(s) connected to any New Relic server or interfere with any other partys use and enjoyment of the Services; (v) use the FIT Instrumentation to defraud, defame, abuse, harass, stalk, threaten or infringe the rights of privacy or other intellectual property rights of others or otherwise violate any applicable law; (vi) circumvent or modify any security technologies included as part of the FIT Instrumentation; or (vii) attempt or permit any third party to do any of the foregoing. New Relic may suspend usage of the Services by any user, without notice, pending any investigation of misuse. These restrictions may be supplemented or superceded (to the extent they conflict) by the New Relic Acceptable Use Policy as may be published and updated from time to time at https://docs.newrelic.com/docs/licenses/license-information/acceptable-use-policy/acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential Information means: (a) the FIT Instrumentation, and any features, results or output produced by, and other information relating to the FIT Instrumentation (including, without limitation, all Feedback); and (b) any business or technical information of New Relic including but not limited to any technical information, research, development, know-how that a reasonable person would understand to be confidential. 3.2 Restrictions. Customer will not use or disclose any Confidential Information, except as necessary for the performance of this Agreement. Customer will use all reasonable efforts to protect Confidential Information from unauthorized use or disclosure, but in no event less than the efforts that it ordinarily uses with respect to its own proprietary information. Customer may disclose Confidential Information to those of its employees who have a bona fide need to know such Confidential Information for the performance of this Agreement; provided that each such employee first executes a written agreement that contains use and nondisclosure restrictions at least as protective as those set forth herein. Confidential Information shall not include any information that: (a) is or becomes generally known to the public through no fault or breach of this Agreement by Customer; (b) is rightfully known by Customer at the time of disclosure without an obligation of confidentiality; (c) is independently developed by Customer without access or use of any Confidential Information; or (d) is rightfully obtained from a third party without restriction on use or disclosure. 4. DISCLAIMER 4.1 DISCLAIMER. FIT INSTRUMENTATION IS PROVIDED AS-IS AND AS-AVAILABLE AND NEW RELIC DISCLAIMS AND MAKES NO WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT AND WHETHER OR NOT ARISING THROUGH A COURSE OF DEALING. FIT INSTRUMENTATION IS NOT GUARANTEED TO BE ERROR-FREE, COMPATIBLE WITH THE UNDERLYING SOFTWARE. , OR THAT CUSTOMER WILL ACHIEVE ANY RESULTS FROM USE OF THE FIT INSTRUMENTATION THEREFROM. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES OR LIMITATIONS ON APPLICABLE STATUTORY RIGHTS OF A CONSUMER, SO THE ABOVE EXCLUSION AND LIMITATIONS MAY NOT APPLY TO THE CUSTOMER. 4.2 LIMITATION OF LIABILITY. TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE TO CUSTOMER OR ANY THIRD PARTY FOR DAMAGES OF ANY KIND, INCLUDING, WITHOUT LIMITATION, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) ARISING OUT OF OR IN CONNECTION WITH THIS AGREEMENT OR THE INSTALLATION, USE OR INABILITY TO USE THE FIT INSTRUMENTATION OR FOR ANY ERROR OR DEFECT IN THE FIT INSTRUMENTATION OR THE SERVICES, WHETHER SUCH LIABILITY ARISES FROM ANY CLAIM BASED UPON CONTRACT, WARRANTY, TORT, STRICT LIABILITY, OR OTHERWISE, WHETHER OR NOT NEW RELIC HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSS OR DAMAGE. NEW RELIC'S AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS AGREEMENT WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE PARTIES HAVE AGREED THAT THESE LIMITATIONS WILL SURVIVE AND APPLY EVEN IF ANY LIMITED REMEDY SPECIFIED IN THIS AGREEMENT IS FOUND TO HAVE FAILED OF ITS ESSENTIAL PURPOSE. 4.3 EVALUATION VERSION. Customer agrees and acknowledges that: (a) the FIT Instrumentation is not an official product and has not been commercially released for sale by New Relic; (b) the FIT Instrumentation may not operate properly, being in final form, or fully functional; (c) the FIT Instrumentation may contain errors, security vulnerabilities, design flaws, or other problems; (d) it may not be possible to make the FIT Instrumentation fully functional; (e) the information obtained using the FIT Instrumentation may not be accurate; (f) use of the FIT Instrumentation may result in unexpected results, loss of data, delays or other unpredictable damages or loss; (g) New Relic is under no obligation to release a commercial version of the FIT Instrumentation; and (h) New Relic has the right unilaterally to abandon development of the FIT Instrumentation, at any time and without any obligation or liability to Customer. 5. GENERAL PROVISIONS 5.1 Terms of Service; Documentation. This Agreement shall be considered a part of the New Relic documentation, located at: https://docs.newrelic.com (the \"Documentation\").This Agreement and the Terms of Service constitute the entire and exclusive agreement between New Relic and Customer with respect to the FIT Instrumentation. In the absence of a separate agreement between New Relic and Customer with respect to the FIT Instrumentation, the terms and conditions of this Agreement shall govern the relationship between New Relic and Customer with respect to such FIT Instrumentation. To the extent of a conflict between the Agreement and the Terms of Service, this Agreement shall govern with respect to the FIT Instrumentation only.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.16673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "FIT instrumentation end user <em>license</em> agreement",
        "sections": "FIT instrumentation end user <em>license</em> agreement",
        "tags": "<em>Distributed</em> <em>licenses</em>",
        "body": " Acceptable Use Policy as may be published and updated from time to time at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>license</em>-<em>information</em>&#x2F;acceptable-use-policy&#x2F;acceptable-use-policy. 3. CONFIDENTIALITY 3.1 Definition. Confidential <em>Information</em> means: (a) the FIT Instrumentation, and any features, results"
      },
      "id": "603e9f3ee7b9d206e32a0800"
    }
  ],
  "/docs/licenses/license-information/product-definitions/legacy-product-definitions": [
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.30325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One pricing: <em>Definitions</em>",
        "sections": "New Relic One pricing: <em>Definitions</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " pricing, invoicing related <em>information</em>, and <em>product</em>-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing."
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
        "Important",
        "Usage Plan: New Relic Platform Pricing",
        "Eligible Services",
        "Eligible Services (Partners)",
        "Subscriptions with indeterminate pricing or usage quantities",
        "Product Usage Ratio"
      ],
      "title": "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "e2686dc773c4e844544ce633a9a41a16f15edf5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan/",
      "published_at": "2021-06-15T12:13:01Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more about pricing changes, see Overview of pricing changes. The following provisions are applicable to existing customers (i) that have existing Terms, and (ii) that to the extent its subscription to the New Relic products reference the usage plans set forth below or where a subscription has indeterminate product pricing or usage quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. Usage Plan: New Relic Platform Pricing The following Eligible Services with New Relic are products that are referenced in specific order forms for New Relic Platform Pricing. For more information, contact your New Relic account representative. Eligible Services Eligible Services Per Unit Unit of Measure Monthly Standard Fee Rate New Relic APM Pro CU Annual* 10,000 Compute Units $166.70 New Relic APM Pro Host Annual* 1 Hosts $149 New Relic Insights Pro Annual 50,000,000 Events $165 New Relic Infrastructure Pro Annual 10,000 Compute Units $12 New Relic Browser Pro Annual 500,000 Page Views $149 New Relic Logs Annual - 8 Days* * 1 Per GB Daily $55 New Relic Logs Annual - 15 Days* * 1 Per GB Daily $65 New Relic Logs Annual - 30 Days* * 1 Per GB Daily $75 New Relic Metrics Annual 1,000 Data Points per Minute $25 New Relic Mobile Enterprise Annual 50,000 Total Users $499 New Relic Serverless for AWS Lambda Annual 1,000,000 AWS Lambda Events $15 New Relic Synthetics Pro Annual 10,000 Checks $69 New Relic Synthetics private locations (for New Relic Synthetics Pro Annual product) Fixed fee N/A $1,000 New Relic Traces Annual 1,000,000 Spans $1 New Relic AI Incident Intelligence Annual 1,000 Incident Events $500 New Relic AI Proactive Detection Annual 1,000,000,000 App Transactions $250 * Customer may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more information about units of measures, see Product definitions. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units of 8,900 Compute Units New Relic APM Pro Host Annual* Sold in Units of 1 Host New Relic Browser Pro Annual Sold in Units of 500,000 Page Views New Relic Infrastructure Pro Annual Sold in Units of 125,000 Compute Units New Relic Insights Pro Annual Sold in Units of 45,000,000 Events New Relic Logs Annual - 8 Days* * Sold in Units of 3 GB Daily New Relic Logs Annual - 15 Days* * Sold in Units of 2.5 GB Daily New Relic Logs Annual - 30 Days* * Sold in Units of 2 GB Daily New Relic Metrics Annual Sold in Units of 6,000 Data Points per Minute New Relic Mobile Enterprise Annual Sold in Units of 15,000 Total Users New Relic Serverless for AWS Lambda Annual Sold in Units of 10,000,000 AWS Lambda Events New Relic Synthetics Pro with Private Locations Annual Sold in Units of 22,000 Checks New Relic Traces Annual Sold in Units of 149,000,000 Spans * Customer and/or Partner may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer and/or Partner will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer and/or Partner may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer and/or Partner will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. Subscriptions with indeterminate pricing or usage quantities Product Usage Ratio Where a Customer subscription to the Products contain no specific pricing or quantities, Product-specific usage for a specific calendar month shall be determined through the calculation of the following ratio (the Product Usage Ratio) where: (1) the numerator shall be the Product specific usage for such calendar month multiplied by such Products list price, and (2) the denominator shall be the the aggregate Customer usage of all Products during such calendar month multiplied by all such Product(s) list price. The Product Usage Ratio shall be the percentage of usage for a specific Product for a calendar month period, or if usage cannot be measured for a period, the last Product Usage Ratio that can be calculated shall be assumed constant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.09657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "sections": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "tags": "<em>License</em> <em>information</em>",
        "body": " will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more <em>information</em> about units of measures, see <em>Product</em> <em>definitions</em>. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units"
      },
      "id": "603ea32a28ccbc7e22eba768"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.541855,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Product</em> training",
        "tags": "<em>License</em> <em>information</em>",
        "body": " <em>information</em> about using New Relic features, visit New Relic University and newrelic.com&#x2F;resources. For more help Recommendations for learning more: See the Docs site&#x27;s landing page for <em>Licenses</em> documentation. Browse New Relic&#x27;s Explorers Hub for community discussions about New Relic <em>licenses</em>."
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions": [
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-05-22T17:24:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 226.30197,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Original <em>product</em>-based pricing <em>definitions</em>",
        "sections": "Original <em>product</em>-based pricing <em>definitions</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": "This is a glossary of terms that appear in contracts for our original <em>product</em>-based pricing. For New Relic One pricing plan terms, see New Relic One pricing <em>definitions</em>. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app"
      },
      "id": "603ebacc64441f77774e8872"
    },
    {
      "sections": [
        "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
        "Important",
        "Usage Plan: New Relic Platform Pricing",
        "Eligible Services",
        "Eligible Services (Partners)",
        "Subscriptions with indeterminate pricing or usage quantities",
        "Product Usage Ratio"
      ],
      "title": "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "e2686dc773c4e844544ce633a9a41a16f15edf5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan/",
      "published_at": "2021-06-15T12:13:01Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more about pricing changes, see Overview of pricing changes. The following provisions are applicable to existing customers (i) that have existing Terms, and (ii) that to the extent its subscription to the New Relic products reference the usage plans set forth below or where a subscription has indeterminate product pricing or usage quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. Usage Plan: New Relic Platform Pricing The following Eligible Services with New Relic are products that are referenced in specific order forms for New Relic Platform Pricing. For more information, contact your New Relic account representative. Eligible Services Eligible Services Per Unit Unit of Measure Monthly Standard Fee Rate New Relic APM Pro CU Annual* 10,000 Compute Units $166.70 New Relic APM Pro Host Annual* 1 Hosts $149 New Relic Insights Pro Annual 50,000,000 Events $165 New Relic Infrastructure Pro Annual 10,000 Compute Units $12 New Relic Browser Pro Annual 500,000 Page Views $149 New Relic Logs Annual - 8 Days* * 1 Per GB Daily $55 New Relic Logs Annual - 15 Days* * 1 Per GB Daily $65 New Relic Logs Annual - 30 Days* * 1 Per GB Daily $75 New Relic Metrics Annual 1,000 Data Points per Minute $25 New Relic Mobile Enterprise Annual 50,000 Total Users $499 New Relic Serverless for AWS Lambda Annual 1,000,000 AWS Lambda Events $15 New Relic Synthetics Pro Annual 10,000 Checks $69 New Relic Synthetics private locations (for New Relic Synthetics Pro Annual product) Fixed fee N/A $1,000 New Relic Traces Annual 1,000,000 Spans $1 New Relic AI Incident Intelligence Annual 1,000 Incident Events $500 New Relic AI Proactive Detection Annual 1,000,000,000 App Transactions $250 * Customer may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more information about units of measures, see Product definitions. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units of 8,900 Compute Units New Relic APM Pro Host Annual* Sold in Units of 1 Host New Relic Browser Pro Annual Sold in Units of 500,000 Page Views New Relic Infrastructure Pro Annual Sold in Units of 125,000 Compute Units New Relic Insights Pro Annual Sold in Units of 45,000,000 Events New Relic Logs Annual - 8 Days* * Sold in Units of 3 GB Daily New Relic Logs Annual - 15 Days* * Sold in Units of 2.5 GB Daily New Relic Logs Annual - 30 Days* * Sold in Units of 2 GB Daily New Relic Metrics Annual Sold in Units of 6,000 Data Points per Minute New Relic Mobile Enterprise Annual Sold in Units of 15,000 Total Users New Relic Serverless for AWS Lambda Annual Sold in Units of 10,000,000 AWS Lambda Events New Relic Synthetics Pro with Private Locations Annual Sold in Units of 22,000 Checks New Relic Traces Annual Sold in Units of 149,000,000 Spans * Customer and/or Partner may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer and/or Partner will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer and/or Partner may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer and/or Partner will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. Subscriptions with indeterminate pricing or usage quantities Product Usage Ratio Where a Customer subscription to the Products contain no specific pricing or quantities, Product-specific usage for a specific calendar month shall be determined through the calculation of the following ratio (the Product Usage Ratio) where: (1) the numerator shall be the Product specific usage for such calendar month multiplied by such Products list price, and (2) the denominator shall be the the aggregate Customer usage of all Products during such calendar month multiplied by all such Product(s) list price. The Product Usage Ratio shall be the percentage of usage for a specific Product for a calendar month period, or if usage cannot be measured for a period, the last Product Usage Ratio that can be calculated shall be assumed constant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.09657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "sections": "<em>Product</em>-based pricing usage and New Relic Platform Pricing Usage Plan",
        "tags": "<em>License</em> <em>information</em>",
        "body": " will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more <em>information</em> about units of measures, see <em>Product</em> <em>definitions</em>. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units"
      },
      "id": "603ea32a28ccbc7e22eba768"
    },
    {
      "sections": [
        "Global Technical Support offerings",
        "Support plans",
        "Support plan for New Relic One pricing and packaging model",
        "Original New Relic support plan",
        "Support resources",
        "Support channels",
        "Community forum",
        "Github",
        "Diagnostic tools",
        "Support ticket",
        "Scope of support",
        "Support includes",
        "Support does not include",
        "Unsupported or incompatible environments & frameworks",
        "Software customizations",
        "Custom applications",
        "Custom scripts & queries",
        "End of Life",
        "Beta or Limited Release",
        "Troubleshooting of customer environment",
        "Troubleshooting third-party tools & services",
        "Some account-related functions",
        "Product training",
        "Consultancy services",
        "Open source support",
        "Open source project categories",
        "Open source support includes",
        "Open source support does not include",
        "Support videos",
        "For more help"
      ],
      "title": "Global Technical Support offerings",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "General usage licenses"
      ],
      "external_id": "b988cdcfb8ae304e36bdd3195f1afdb0092bbc32",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/general-usage-licenses/global-technical-support-offerings/",
      "published_at": "2021-06-15T13:31:56Z",
      "updated_at": "2021-05-22T17:22:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Support Plan offers a variety of resources based on your service subscription. Check out the Support Plan information, resources, channels, and scope of support below. Support plans These Support Plans apply only to your paid service subscription under an existing New Relic agreement. If you have questions about these New Relic Support Plans, contact your New Relic account representative. Support plan for New Relic One pricing and packaging model The below New Relic One Support Plan applies only to a customers paid subscription to New Relic One (Full Stack Observability). Standard Pro Enterprise BENEFITS Explorers Hub Community Documentation Support Portal Access @ support.newrelic.com Communication Method Community Forum Community Forum, Ticket, Chat Community Forum, Ticket, Chat, Phone, Slack Support Hours 24x7/365 24x7/365 Initial Support Response SLA 2 hours critical, 8 hours standard 1 hour critical, 3 hours standard On-Boarding On-demand video Training Webinar/Virtual Training Designated Technical Account Manager Designated Support Customer Experience Manager Priority Ticket Routing Critical Date/Event Support Support Escalation 1-Click Away Notes: If you have not upgraded or changed to the New Relic One pricing plan, your existing support plan still applies. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Original New Relic support plan The below Support Plan applies only to a customers paid service subscription to non-New Relic One Products (our original product-based pricing plan). Silver Gold Platinum Priority Essential Plus BENEFITS Documentation New Relic University Support Portal Access at support.newrelic.com Explorers Hub Community Communication Methods Explorers Hub Explorers Hub, Ticket Explorers Hub, Ticket, Phone Explorers Hub, Ticket, Phone, Slack Explorers Hub, Ticket, Phone, Slack Support Hours 24/7x365 24/7x365 24/7x365 24/7x365 Initial Support Response Time 2 hours critical, 8 hours standard 2 hours critical, 4 hours standard 1 hours critical, 3 hours standard 1 hours critical, 3 hours standard Priority Ticket Routing Designated Support Customer Manager Expert Services Support Solutions Architect NRU Instructor Led Training Quarterly Health Check, Office Hours Notes: Silver tier applies to customers with $1 to $9,999 annual spend. Gold tier applies to customers with $10,000 to $99,999 annual spend. Platinum tier applies to customers with $100,000 annual spend and above. Contact your Account Manger regarding Priority Support. Initial Support Response Time begins when the request is received by the New Relic support system. Critical means customers business operations are severely impacted due to New Relic with no available workaround; or there is a critical security issue. This Support Plan is subject to change at any time; changes will take immediate effect. Support resources We're here to help you get everything you need from the New Relic One Platform. To begin with, we recommend that all New Relic users become familiar with these resources: New Relic Status Page: Get updates on any incidents New Relic Documentation: Comprehensive guidance for using our platform New Relic Community forum: Thousands of customer questions asked and answered New Relic Diagnostics: Diagnose and troubleshoot installation and configuration New Relic Open Source: Discover, research, and contribute to our open source projects New Relic Security Overview: Our approach to handling security issues You may find these resources helpful too: New Relic Developers: Resources for building custom observability applications New Relic University: A range of online training for New Relic users of every level New Relic on GitHub: Discuss issues and features related to our Open Source projects We are committed to providing documentation and tools to assist with installation, configuration, and diagnostics of New Relics distributed software as described here: New Relic Installation, configuration, and requirements Support channels If you need assistance with New Relic Products, you are in good hands with several support channels available to you depending on the service level associated with your New Relic account. For more information about service levels, please refer to our Support Plan. Community forum The New Relic Community Forum is 100% free and open to anyone with a New Relic account. The community is a place where many customer questions have already been asked and answered. Answers come from our community of experienced users, New Relic Support Engineers, and dozens of other Relics who help answer questions and solve problems. If you want to ask a question, check the community - if your question has not already been answered, members of the community can help. Github We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. You can find all our open source projects in our Github repo. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. For more information on support for Open Source projects, visit our Open Source Support Policy. Diagnostic tools New Relic offers a diagnostics utility that can automatically detect common problems with New Relic agents. If Diagnostics detects a problem, it suggests troubleshooting steps. New Relic Diagnostics can also automatically attach troubleshooting data to a New Relic Support ticket. We have also made available Troubleshooting Frameworks that step users through common troubleshooting questions. Support ticket Support is now available in the New Relic One Platform! Just click on the question mark at the top right of your New Relic One screen to surface contextual documentation and resources. Depending on the Service Level associated with your New Relic account, you may be eligible for ticketed support and can open a ticket without leaving the New Relic One Platform. As an alternative, customers eligible for ticketed support may also open a support ticket from the New Relic Support page We are available 24 hours a day, 7 days a week, 365 days a year to help you troubleshoot issues related to the New Relic One Platform and generally available New Relic Products as outlined below. Scope of support You can have confidence that the Products we make Generally Available are fully tested with the compatible environments outlined in New Relic Documentation. New Relics Global Technical Support provides assistance with the New Relic One Platform, and the features and capabilities inherent in the Telemetry Data Platform, Full Stack Observability, and Applied Intelligence Product lines. For issues within Third Party tools, or when tools in your infrastructure aren't working together properly, Global Technical Support may reach a point where we must refer New Relic users to such Third Party or community for assistance. Support includes Troubleshooting problems on the New Relic One Platform Assistance with issues during installation & upgrade in compatible environments Guidance on implementation and configuration in compatible environments Troubleshooting problems with ingesting data into New Relic General usage and best practice guidelines Identifying bugs with New Relic Products Assistance in English or Japanese Only (Japanese customer Terms of Service) Support does not include Unsupported or incompatible environments & frameworks Our Products are fully tested with the compatible environments and installation frameworks, and were here to help you through issues that may arise with our Products within these compatible environments and frameworks. We cannot support installation or configuration of our Products in environments or frameworks that do not meet established compatibility requirements. But if you're looking for help customizing New Relic for your particular environment, New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Software customizations We are eager to help troubleshoot issues with the Products and features we make generally available, and those categorized as New Relics Open Source Community Plus Projects. New Relics Global Technical Support does not support customizations, modifications, or extensions to our code. Customizations or extensions to New Relics Open Source Projects in other Project categories are supported by the developer community in GitHub. New Relics Expert Services is a team of highly skilled consultants that can assist with unique configurations or environments. Custom applications With New Relic One, users have the ability to extend beyond the curated dashboards and design custom applications tailored to your business. New Relics Global Technical Support team does not support custom applications. The New Relic Developer site provides guidance on building custom apps, and here are a growing number of open source apps that you can use to get started. Custom scripts & queries We are happy to help troubleshoot issues related to the New Relic One platform that may be causing issues with a script or query. We cannot provide solutions for specific script or query use cases. New Relic Documentation and New Relic University offer resources on how to construct custom scripts and queries. End of Life New Relic may EOL products in accordance with the EOL policy. We recommend upgrading to our newest versions so you can take advantage of recent capabilities and bug fixes. More details are available in our published End of Life Policy. Beta or Limited Release Our support team covers generally available New Relic Products. Products that are in Beta or Limited Release status are not considered generally available. If you are invited to participate in a Beta program, or are using a Limited Release component, your account team will be your point of contact for questions. Please contact your account representative directly. Troubleshooting of customer environment We want to help every customer get the most of their New Relic experience within what are increasingly complex environments. However, we cant help with things we didnt build. We cannot assist with administration, configuration, or troubleshooting of a customer environment. When in doubt, you can get in touch with us, and well help verify whether an issue is with our Product within a supported environment so you know where to go next. Troubleshooting third-party tools & services New Relic integrates well with many Third Party tools and services; however, we cannot support tools and services not provided or licensed by New Relic. Well do our best to determine whether an issue is with New Relics Products or caused by something outside of our control and purview. Issues with installation or configuration of the Third Party tools and services themselves should be directed to the respective owner of that Third Party tool or service or to the developer community. The Community and GitHub are great resources for assistance with Third Party tools and services as well. Some account-related functions For security reasons, some account-related Product functions must be conducted by the New Relic user designated as the account owner, such as Enabling SSO and High-Security Mode, adding users, and upgrading user permissions. Product training We are here to help you solve problems you may encounter on the road to instrumenting everything. Global Technical Support cannot provide user training on New Relic Products. New Relic offers a well-curated library of documentation and in-depth tutorials organized by Product, skill level, learning format, and solutions to help you navigate the observability journey. Check out New Relic University! Consultancy services Global Technical Support is here to help our valued customers as outlined in these support offerings. If you need help with something that falls outside of the Scope of Support, New Relics Expert Services is a team of highly skilled consultants that can help you navigate the challenges of building modern software and adopting the latest technologies, so you can focus on what you do best: delivering an incredible experience to your customers. Open source support We want everyone to monitor their systems, and we're contributing our technology back to the open-source community to make that happen. We're committed to open standards, open-sourcing all of our instrumentation, and engaging engineers where they are, in the communities they already belong to. Open source project categories New Relic Open Source Projects are assigned to one of five different categories. These categories determine the support options available for a project as listed below: Community plus projects: Actively maintained by New Relic. Support requests can be made through Github, Community, and Ticketed Support channels, depending on the service level associated with the New Relic account. Community projects: Actively maintained by New Relic. Support requests can be made through Github or Community. New Relic One catalog: Support requests can be made through the Github channel. Issues/Pull Requests should be directed to the relevant Github repository. Example code: Project support is through Github channel. Issues/Pull Requests should be directed to the relevant Github repository. New Relic experimental: Projects have no ongoing maintenance, development or support. Archived: Projects are read-only, are not actively maintained, and do not have support. Open source support includes Support for Community Plus Projects from New Relics Global Technical Support includes: Troubleshooting problems with the Community Plus Projects on the New Relic One Platform Assistance with issues with Community Plus Projects during installation & upgrade in compatible environments Guidance on implementation and configuration of Community Plus Projects in compatible environments Troubleshooting problems with ingesting data with Community Plus Projects into New Relic General usage and best practice guidelines with Community Plus Projects Identifying bugs in Community Plus Projects Assistance in English or Japanese Only (Japanese customer Terms of Service) Open source support does not include Open source projects assigned to categories other than the Community Plus category Unsupported environments & frameworks Code development End of Life Beta or Limited Release Troubleshooting of customer environment Troubleshooting third-party tools and services Product training Consultancy services Support videos For a library of additional videos, webinars, and other information about using New Relic features, visit New Relic University and newrelic.com/resources. For more help Recommendations for learning more: See the Docs site's landing page for Licenses documentation. Browse New Relic's Explorers Hub for community discussions about New Relic licenses.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.54185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Product</em> training",
        "tags": "<em>License</em> <em>information</em>",
        "body": " <em>information</em> about using New Relic features, visit New Relic University and newrelic.com&#x2F;resources. For more help Recommendations for learning more: See the Docs site&#x27;s landing page for <em>Licenses</em> documentation. Browse New Relic&#x27;s Explorers Hub for community discussions about New Relic <em>licenses</em>."
      },
      "id": "603ea419e7b9d27b942a07b4"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy": [
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Data Security",
        "2. Data Access",
        "3. Server Security",
        "4. Network Security",
        "5. Security Audits",
        "6. Security and Incident Response",
        "7. Disaster Recovery",
        "8. Copies and Removal",
        "9. Disclosure by Law"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-06-15T12:11:13Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Data Security 1.1. New Relic shall establish and maintain data security procedures and other safeguards designed to protect against the loss, theft or other unauthorized access or alteration of Customer Data in the possession or under the control of New Relic or to which New Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an information security policy that outlines a definition of information security and its overall objectives; a framework for setting control objectives and controls, including the structure of risk assessment and risk management; a brief explanation of the compliance requirements, and procedures for managing information security incidents. 2. Data Access 2.1. Access to Customer Data stored on New Relics systems shall not be granted to members of New Relic unless they have been uniquely identified and have sufficient credentials. 2.2. Access permissions shall be established in a manner that allows for the minimum access level(s) required for each employee. 2.3. Access to Customer Data shall be logged with sufficient information to determine the nature and scope of any inappropriate access. 3. Server Security 3.1. New Relic shall establish and follow reasonable server configuration guidelines and processes to prevent unauthorized access to Customer Data. 3.2. New Relic shall establish and follow reasonable configuration change management procedures for its servers containing Customer Data. 4. Network Security 4.1. New Relic network architecture shall be designed to limit site access and restrict the availability of information services that are considered to be vulnerable to attack. 4.2. New Relic shall utilize SSL certificates for all Internet activity. By default, Customer Data transmitted to and from the New Relic network shall be sent over encrypted medium or an encrypted format. 4.3. New Relic network shall use IDS technologies for network intrusion detection. 4.4. Access to New Relic systems containing Customer Data shall be restricted to authorized personnel. 5. Security Audits 5.1. New Relic shall conduct at least annually a SOC 2 or industry equivalent audit. New Relic shall provide to Customer audit results upon request, and shall explain and provide remediation plans to correct any problems to the extent reasonably possible. 6. Security and Incident Response 6.1. New Relic shall maintain an Information Security Incident Response plan, and make that plan available to Customer if requested. 6.2. In the event of an actual theft, loss, or unauthorized access of Customer Data by New Relics personnel and/or any unauthorized individual or entity, New Relic shall: (a) investigate such breach, (b) attempt to cure such breach, and (c) provide notification to Customer that describes such breach. 7. Disaster Recovery 7.1. New Relic shall have in effect a disaster recovery plan designed to respond to both a component failure of New Relic equipment within its data center and a catastrophic loss of service. This plan shall include documented policies and procedures to restore service in the event of either type of failure. 7.2. New Relic shall establish and follow backup and restore procedures for servers containing Customer Data. 8. Copies and Removal 8.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of this Agreement for any reason: (a) New Relic shall, and shall cause its personnel, to cease and desist all access and use of any Customer Data, (b) New Relic shall delete all copies of Customer Data within ninety (90) days. 9. Disclosure by Law 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.1409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an <em>information</em> security policy that outlines a definition of <em>information</em> security and its overall objectives; a framework for setting control objectives and controls"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    },
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to New Relic Full Stack Observability Pro or Enterprise Products, the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to New Relic Full Stack Observability Standard, any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customers access or use of the Service in accordance with this Agreement. This describes Customers sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.12384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.65802,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": ". Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer"
      },
      "id": "6044e6e528ccbc26f22c6084"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/security-policy": [
    {
      "sections": [
        "Service level availability commitment",
        "New Relic Service Level Availability"
      ],
      "title": "Service level availability commitment",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5489f268010887c72446f12059a1a0e4279ad960",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/service-level-availability-commitment/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you subscribe to New Relic Full Stack Observability Pro or Enterprise Products, the service level availability commitments available to you are those set forth (i) in the Terms, or (ii) as set forth on this page. If you subscribe to New Relic Full Stack Observability Standard, any service level availability commitment or related remedies contained in your Terms are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. If you subscribe to any other New Relic Products on a product-based pricing basis, any service level availability commitment are contained in (i) your Terms, or (ii) if your Terms explicitly references this Service Level Availability commitment applying to the Service purchased in an Order, this page for the Services you use. Capitalized terms not defined below shall take on the meaning set forth in your Terms. New Relic Service Level Availability The Service will be considered available so long as Customer is able to log in to its interface and view Customer Data (\"Service Availability\"). The applicable Service Availability will be calculated as a percentage of: (1) the total number of minutes in a month after (2) subtracting any periods of unavailability during such month from the total number of minutes in a month. New Relic will use commercially reasonable efforts to maintain Service Availability of at least 99.8% during any calendar month. In the event the Service Availability drops below: (i) 98.5% for two consecutive calendar months during the Subscription Term, or (ii) 96.5% in any single calendar month, Customer may request to terminate the relevant Service with no penalty. Such termination will be effective as of the end of the then-current billing period and no additional fees will be charged. The service level within New Relic's control is the Service Availability, not, for example, the transmission of data over the public Internet. Service Availability calculations will exclude unavailability arising from any: (a) planned maintenance periods; (b) emergency maintenance that is necessary to prevent imminent harm to the Service; (c) force majeure events; (d) Third-Party Services, Customer application, equipment, software or other technology, or Customer or its User's use of the Service, in violation of the Agreement or not in accordance with the Documentation; or (e) suspension, limitation, and/or termination of Customers access or use of the Service in accordance with this Agreement. This describes Customers sole and exclusive remedy for failures of Service Availability. Customer may request the Service Availability attainment for the previous month by filing a support ticket on the New Relic support site.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.12384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>"
      },
      "id": "603ea44828ccbcd9c8eba7b7"
    },
    {
      "sections": [
        "New Relic Pre-release policy",
        "New Relic Pre-Release Policy",
        "1. Introduction",
        "2. License and Restrictions",
        "3. Confidential Information",
        "4. Disclaimers and Acknowledgement",
        "5. Limitation of Liability",
        "6. Indemnity",
        "7. Export Restrictions",
        "8. Termination"
      ],
      "title": "New Relic Pre-release policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5ca324e942906913fc346245cfd80d405e90ad1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-03-13T01:17:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Without overriding any express provisions that you may have agreed to in a separate written beta or pre-release agreement executed by you and New Relic, the following terms apply to your use of any New Relic Pre-Release Service(s). New Relic Pre-Release Policy Through your use of any New Relic, Inc. (New Relic) Pre-Release Services (as further defined), you signify that you have read, understood, and accept the terms of this Pre-Release Policy (the Policy) governing your use and participation in New Relics program for making beta, alpha and pre-release versions of New Relic software (i.e. agents, SDKs, APIs, integrations, private locations, code, etc.), services, features, user-interfaces, and platforms made available for evaluation purposes (the Pre-Release Service(s)). This Policy is effective on behalf of yourself or the entity(ies) associated with your New Relic account (collectively referred to herein as you or your) as of your date of first use of the Pre-Release Service(s) (the Effective Date), which means that your choice to use the Pre-Release Service(s) means that you have the legal authority to use the Pre-Release Service(s) personally or on behalf of the company or organization associated with your New Relic account in accordance with this Policy. Please read this Policy carefully as your use of Pre-Release Service(s) may have unintended consequences and materially impact your data or use of the New Relic services and products. If you do not agree to this Policy, your sole remedy is to not make use of the Pre-Release Services. 1. Introduction This Policy and any New Relic technical guides and documentation made available with the Pre-Release Service(s) or from the dedicated Documentation page of the New Relic website (the Documentation) enables you to test experimental features and products before they are made generally available. New Relic reserves the right to withhold or discontinue any Pre-Release Service(s), which may be designated as an alpha, beta, pilot, limited release, developer preview, technology preview, non-production, evaluation, or by a similar description, in its sole discretion and provides no guarantee that any Pre-Release Service(s) will eventually be made commercially or generally available. Pre-Release Service(s) are versions provided before they are generally available and may have bugs, stability issues, or other problems. Use of the Pre-Release Service(s) may result in unexpected results, loss of data, outages, or other damage to your systems or networks. New Relic advises against using the Pre-Release Service(s) in production. No support is offered with or for Pre-Release Service(s). You hereby release New Relic from any liability arising from or related to your use of the Pre-Release Service(s). In connection with your use of the Pre-Release Services, you may provide feedback, comments, and/or suggestions based on or relating to the Pre-Release Services (Feedback). The Pre-Release Services and any related information, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback, and information related to any business or technical information of New Relic, including without limitation product plans, costs, prices, finances, marketing plans, business opportunities, research, development, and negotiations are considered confidential information of New Relic (Confidential Information). 2. License and Restrictions 2.1 Evaluation License. Subject to your compliance with the Policy, New Relic hereby grants you a limited, non-exclusive, non-transferable, revocable license, during the term of this Policy, to use the Pre-Release Service(s) in accordance with the Documentation solely for the purpose of internal evaluation and supplying Feedback to New Relic. 2.2 License Restrictions. You may not (and may not authorize or enable a third party to): (i) reverse engineer, decompile, disassemble, or otherwise attempt to discover the source code or other trade secrets in the Pre-Release Service(s); (ii) access the Pre-Release Service(s) in order to build a similar or competitive application, service, feature or other competitive purpose; (iii) remove or destroy any copyright notices or other proprietary marks contained on or in the Pre-Release Service(s); (iv) use the Pre-Release Service(s) for any benchmarking purposes or in connection with a service bureau, timeshare, service provider, or like activity where you operate the Pre-Release Service(s) on behalf of a third party; (v) mirror, frame, copy, modify, host, rent, lease, sell, commercialize, sublicense, assign or otherwise transfer the Pre-Release Service(s), or the access or use of the Pre-Release Service(s); (vi) use the Pre-Release Service(s) in a manner that may violate or infringe the intellectual property, data protection, or other proprietary right of a third party; (vii) use or access the Pre-Release Service(s) in an unauthorized manner and/or in a manner that violates any applicable law, rule, contract, or guideline (including but not limited to our Documentation or Community Guidelines); (viii) use the Pre-Release Service(s) to transmit worms, viruses, malicious code, security vulnerabilities, or otherwise negatively impact network operations, third parties, or New Relic; (ix) use any data mining or similar data gathering and extraction methods in connection with the Pre-Release Service(s); or (x) use the Pre-Release Service(s) to process sensitive personal information, e.g., personal information of children as defined by the Childrens Online Privacy Protection Act, protected health information as defined by the Health Insurance Portability and Accountability Act of 1996, government issued identification numbers, financial account information, payment card data, special categories of data as described in the EU General Data Protection Regulation (GDPR), or other information subject to regulatory, statutory, or contractual restrictions. New Relic reserves the right, but not the obligation, to monitor or review your use of the Pre-Release Service(s) at any time and may investigate any suspected violations of this Policy. 2.3 Intellectual Property Rights. You acknowledge and agree that, as between you and New Relic, New Relic owns all right, title, and interest in and to the Pre-Release Service(s), Confidential Information, and Feedback, including but not limited to all intellectual property and proprietary rights therein. New Relic and its licensors reserve all rights and licenses not expressly granted herein. 2.4 Feedback. You acknowledge and agree that all Feedback will be the sole and exclusive property of New Relic. You hereby irrevocably transfer and assign to New Relic all right, title, and interest in all Feedback, including but not limited to all intellectual property and proprietary rights therein. 3. Confidential Information You will not use or disclose any Confidential Information, except as necessary for the performance of this Policy, and you will use reasonable efforts to protect Confidential Information from unauthorized use or disclosure. You may disclose Confidential Information only to those employees with a bona fide need to know, provided that each employee has signed a written agreement with nondisclosure restrictions at least as protective of the Confidential Information as those set forth herein. For the purposes of this section, information will not be deemed Confidential Information if it: (a) is or becomes generally known to the public through no fault or breach of this Policy; (b) is rightfully known by you at the time of disclosure without an obligation of confidentiality; (c) is independently developed by you without access to or use of the Confidential Information; or (d) is rightfully obtained by you from a third party without restriction on use or disclosure. Upon New Relics request, you agree to destroy all Confidential Information in your possession within 30 days of termination of this Policy. 4. Disclaimers and Acknowledgement 4.1 Acknowledgement of Pre-Release Service(s). You acknowledge and agree that: (a) the Pre-Release Service(s) is not an official product and has not been commercially released for sale by New Relic; (b) the Pre-Release Service(s) may not operate properly, be in final form, or fully function; (c) the Pre-Release Service(s) may contain errors, design flaws, security vulnerabilities, or other problems; (d) it may not be possible to make the Pre-Release Service(s) fully functional or secure; (e) the information obtained using the Pre-Release Service(s) may not be accurate; (f) use of the Pre-Release Service(s) may result in unexpected results, vulnerabilities, loss of data, project delays, or other unpredictable damage or loss, including without limitation to your use of New Relic services and products not governed by this Policy (collectively Unintended Effects); (g) New Relic is under no obligation to release a commercial or generally available version of the Pre-Release Service(s); and (h) New Relic has the right unilaterally to abandon development of the Pre-Release Service(s) at any time and without any obligation or liability to you. 4.2 Your Data. You acknowledge and agree that you should not rely on the Pre-Release Service(s) for any reason. You further acknowledge and agree that you are solely responsible for maintaining and protecting all data and information that is stored, retrieved, or otherwise processed by the Pre-Release Service(s) in accordance with your contractual obligations and requirements under applicable law. Without limiting the foregoing, you are responsible for all costs and expenses required to backup and restore any data and information that is lost or corrupted as a result of your use of the Pre-Release Service(s) or any Unintended Effects. You understand and agree that your Data may be transferred to the United States for storage, processing, and use by New Relic to provide the Pre-Release Service(s). For any data that you process using the Pre-Release Service(s), you represent and warrant that you have all necessary rights and consent to do so. New Relic has no obligation to store any data you process using the Pre-Release Service(s) and shall have no liability for the deletion or accuracy of such data. 4.3 Warranty Disclaimers. YOU ACKNOWLEDGE THAT PRE-RELEASE SERVICE(S) ARE PROVIDED AS IS. TO THE EXTENT PERMITTED BY APPLICABLE LAW, NEW RELIC DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES REGARDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, SECURITY, AND ANY WARRANTIES ARISING OUT OF THE COURSE OF DEALING OR USAGE OF TRADE. NEW RELIC MAKES NO WARRANTY THAT PRE-RELEASE SERVICE(S) WILL MEET YOUR REQUIREMENTS OR WILL BE ACCURATE, RELIABLE, ERROR-FREE, UNINTERRUPTED, TIMELY, OR SECURE. YOUR USE OF PRE-RELEASE SERVICE(S) IS AT YOUR OWN RISK. 4.4 Modifications. New Relic may change the Policy from time to time as our business changes and technology evolves, and future versions of our generally available services may not be compatible with Pre-Release Service(s) built using previous versions. The most current version of this Policy will be posted in the Documentation. Any changes to this Policy will be effective immediately for all users in instances to comply with applicable law, for new users of a Pre-Release Service(s) and, for all other users, any changes to this Policy will be effective as of fifteen (15) days after posting notice of such changes. If we determine in our sole discretion that an update is material, we will provide notice of such material change to you through your New Relic account, the Pre-Release Service(s), the Documentation, our blogs or community forums, and/or by email to the email address of your account administrator. We may require you to provide consent to the updated Policy in a specified manner before further use of the Pre-Release Service(s) is permitted. If you do not agree to any change(s), your sole remedy is to stop using the Pre-Release Service(s) and any such termination by you shall be without penalty except as specified in this Policy. Otherwise, your use of any Pre-Release Service(s) after any such update shall constitute acceptance of the then-current Policy. 5. Limitation of Liability TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, EXEMPLARY OR CONSEQUENTIAL (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) DAMAGES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN WARNED OF THE POSSIBILITY OF SUCH DAMAGES, AND EVEN IF A REMEDY FAILS OF ITS ESSENTIAL PURPOSE. NEW RELICS AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS POLICY, THE PRE-RELEASE SERVICES, OR ANY UNINTENDED EFFECTS WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND YOU. 6. Indemnity You agree to indemnify and hold New Relic, its parents, subsidiaries, affiliates, officers, agents, employees, and licensors harmless from any claims, fees, fines, demands, losses, liabilities, damages, and costs, including reasonable attorneys fees, arising from or related to your use of the Pre-Release Service(s), including but not limited to allegations arising from your breach of any terms herein and/or allegations that data processed by the Pre-Release Service(s) violates or infringes the privacy, data protection, or intellectual property rights of a third party. 7. Export Restrictions You acknowledge that the software in the Pre-Release Service(s) licensed hereunder may be subject to the export control laws and regulations of the U.S. and other countries. You agree that you will not export or re-export the Pre-Release Service(s), any part thereof, or any process or service that is the direct product of the Pre-Release Service(s) to any country, person or entity subject to U.S. export restrictions. 8. Termination Your access to the Pre-Release Service(s) will terminate upon the earliest of: (i) New Relic making the Pre-Release Service(s) or a successor version of the Pre-Release Service(s) generally available or available for commercial release; (ii) New Relic ceasing to make the Pre-Release Service(s) available to you; or (iii) New Relic terminating this Policy. New Relic may terminate this Policy for any reason upon notice to you. Sections 2.2, 2.3, 2.4, 3, 4, 5, 6, and 7 will survive your use of the Pre-Release Service(s).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.49142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Pre-release <em>policy</em>",
        "sections": "2. <em>License</em> and Restrictions",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Services and any related <em>information</em>, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback"
      },
      "id": "6044e71b28ccbc984d2c60c8"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": ". Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer"
      },
      "id": "6044e6e528ccbc26f22c6084"
    }
  ],
  "/docs/licenses/license-information/referenced-policies/service-level-availability-commitment": [
    {
      "sections": [
        "Security policy",
        "New Relic Security Policy",
        "1. Data Security",
        "2. Data Access",
        "3. Server Security",
        "4. Network Security",
        "5. Security Audits",
        "6. Security and Incident Response",
        "7. Disaster Recovery",
        "8. Copies and Removal",
        "9. Disclosure by Law"
      ],
      "title": "Security policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "291509f6b521ca34ac9d49039518e7da8b883518",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-policy/",
      "published_at": "2021-06-15T12:11:13Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The below Security Policy applies only to customers with an existing New Relic agreement in place that explicitly references this Security Policy applying to the Service purchased in an Order. Capitalized terms not defined below shall take on the meaning set forth in such New Relic agreement. New Relic Security Policy 1. Data Security 1.1. New Relic shall establish and maintain data security procedures and other safeguards designed to protect against the loss, theft or other unauthorized access or alteration of Customer Data in the possession or under the control of New Relic or to which New Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an information security policy that outlines a definition of information security and its overall objectives; a framework for setting control objectives and controls, including the structure of risk assessment and risk management; a brief explanation of the compliance requirements, and procedures for managing information security incidents. 2. Data Access 2.1. Access to Customer Data stored on New Relics systems shall not be granted to members of New Relic unless they have been uniquely identified and have sufficient credentials. 2.2. Access permissions shall be established in a manner that allows for the minimum access level(s) required for each employee. 2.3. Access to Customer Data shall be logged with sufficient information to determine the nature and scope of any inappropriate access. 3. Server Security 3.1. New Relic shall establish and follow reasonable server configuration guidelines and processes to prevent unauthorized access to Customer Data. 3.2. New Relic shall establish and follow reasonable configuration change management procedures for its servers containing Customer Data. 4. Network Security 4.1. New Relic network architecture shall be designed to limit site access and restrict the availability of information services that are considered to be vulnerable to attack. 4.2. New Relic shall utilize SSL certificates for all Internet activity. By default, Customer Data transmitted to and from the New Relic network shall be sent over encrypted medium or an encrypted format. 4.3. New Relic network shall use IDS technologies for network intrusion detection. 4.4. Access to New Relic systems containing Customer Data shall be restricted to authorized personnel. 5. Security Audits 5.1. New Relic shall conduct at least annually a SOC 2 or industry equivalent audit. New Relic shall provide to Customer audit results upon request, and shall explain and provide remediation plans to correct any problems to the extent reasonably possible. 6. Security and Incident Response 6.1. New Relic shall maintain an Information Security Incident Response plan, and make that plan available to Customer if requested. 6.2. In the event of an actual theft, loss, or unauthorized access of Customer Data by New Relics personnel and/or any unauthorized individual or entity, New Relic shall: (a) investigate such breach, (b) attempt to cure such breach, and (c) provide notification to Customer that describes such breach. 7. Disaster Recovery 7.1. New Relic shall have in effect a disaster recovery plan designed to respond to both a component failure of New Relic equipment within its data center and a catastrophic loss of service. This plan shall include documented policies and procedures to restore service in the event of either type of failure. 7.2. New Relic shall establish and follow backup and restore procedures for servers containing Customer Data. 8. Copies and Removal 8.1. In addition to any obligations of New Relic in the Agreement, upon expiration or termination of this Agreement for any reason: (a) New Relic shall, and shall cause its personnel, to cease and desist all access and use of any Customer Data, (b) New Relic shall delete all copies of Customer Data within ninety (90) days. 9. Disclosure by Law 9.1. In the event the New Relic is required by law, regulation, or legal process to disclose any Customer Data, New Relic shall (a) give Customer, to the extent possible, reasonable advance notice prior to disclosure so Customer may contest the disclosure or seek a protective order, and (b) reasonably limit the disclosure to the minimum amount that is legally required to be disclosed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.14088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security <em>policy</em>",
        "sections": "Security <em>policy</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Relic has access, which are no less rigorous than accepted security standards in the industry. 1.2. New Relic shall maintain an <em>information</em> security policy that outlines a definition of <em>information</em> security and its overall objectives; a framework for setting control objectives and controls"
      },
      "id": "603ea3dbe7b9d22b802a0802"
    },
    {
      "sections": [
        "New Relic Pre-release policy",
        "New Relic Pre-Release Policy",
        "1. Introduction",
        "2. License and Restrictions",
        "3. Confidential Information",
        "4. Disclaimers and Acknowledgement",
        "5. Limitation of Liability",
        "6. Indemnity",
        "7. Export Restrictions",
        "8. Termination"
      ],
      "title": "New Relic Pre-release policy",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "5ca324e942906913fc346245cfd80d405e90ad1f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-03-13T01:17:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Without overriding any express provisions that you may have agreed to in a separate written beta or pre-release agreement executed by you and New Relic, the following terms apply to your use of any New Relic Pre-Release Service(s). New Relic Pre-Release Policy Through your use of any New Relic, Inc. (New Relic) Pre-Release Services (as further defined), you signify that you have read, understood, and accept the terms of this Pre-Release Policy (the Policy) governing your use and participation in New Relics program for making beta, alpha and pre-release versions of New Relic software (i.e. agents, SDKs, APIs, integrations, private locations, code, etc.), services, features, user-interfaces, and platforms made available for evaluation purposes (the Pre-Release Service(s)). This Policy is effective on behalf of yourself or the entity(ies) associated with your New Relic account (collectively referred to herein as you or your) as of your date of first use of the Pre-Release Service(s) (the Effective Date), which means that your choice to use the Pre-Release Service(s) means that you have the legal authority to use the Pre-Release Service(s) personally or on behalf of the company or organization associated with your New Relic account in accordance with this Policy. Please read this Policy carefully as your use of Pre-Release Service(s) may have unintended consequences and materially impact your data or use of the New Relic services and products. If you do not agree to this Policy, your sole remedy is to not make use of the Pre-Release Services. 1. Introduction This Policy and any New Relic technical guides and documentation made available with the Pre-Release Service(s) or from the dedicated Documentation page of the New Relic website (the Documentation) enables you to test experimental features and products before they are made generally available. New Relic reserves the right to withhold or discontinue any Pre-Release Service(s), which may be designated as an alpha, beta, pilot, limited release, developer preview, technology preview, non-production, evaluation, or by a similar description, in its sole discretion and provides no guarantee that any Pre-Release Service(s) will eventually be made commercially or generally available. Pre-Release Service(s) are versions provided before they are generally available and may have bugs, stability issues, or other problems. Use of the Pre-Release Service(s) may result in unexpected results, loss of data, outages, or other damage to your systems or networks. New Relic advises against using the Pre-Release Service(s) in production. No support is offered with or for Pre-Release Service(s). You hereby release New Relic from any liability arising from or related to your use of the Pre-Release Service(s). In connection with your use of the Pre-Release Services, you may provide feedback, comments, and/or suggestions based on or relating to the Pre-Release Services (Feedback). The Pre-Release Services and any related information, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback, and information related to any business or technical information of New Relic, including without limitation product plans, costs, prices, finances, marketing plans, business opportunities, research, development, and negotiations are considered confidential information of New Relic (Confidential Information). 2. License and Restrictions 2.1 Evaluation License. Subject to your compliance with the Policy, New Relic hereby grants you a limited, non-exclusive, non-transferable, revocable license, during the term of this Policy, to use the Pre-Release Service(s) in accordance with the Documentation solely for the purpose of internal evaluation and supplying Feedback to New Relic. 2.2 License Restrictions. You may not (and may not authorize or enable a third party to): (i) reverse engineer, decompile, disassemble, or otherwise attempt to discover the source code or other trade secrets in the Pre-Release Service(s); (ii) access the Pre-Release Service(s) in order to build a similar or competitive application, service, feature or other competitive purpose; (iii) remove or destroy any copyright notices or other proprietary marks contained on or in the Pre-Release Service(s); (iv) use the Pre-Release Service(s) for any benchmarking purposes or in connection with a service bureau, timeshare, service provider, or like activity where you operate the Pre-Release Service(s) on behalf of a third party; (v) mirror, frame, copy, modify, host, rent, lease, sell, commercialize, sublicense, assign or otherwise transfer the Pre-Release Service(s), or the access or use of the Pre-Release Service(s); (vi) use the Pre-Release Service(s) in a manner that may violate or infringe the intellectual property, data protection, or other proprietary right of a third party; (vii) use or access the Pre-Release Service(s) in an unauthorized manner and/or in a manner that violates any applicable law, rule, contract, or guideline (including but not limited to our Documentation or Community Guidelines); (viii) use the Pre-Release Service(s) to transmit worms, viruses, malicious code, security vulnerabilities, or otherwise negatively impact network operations, third parties, or New Relic; (ix) use any data mining or similar data gathering and extraction methods in connection with the Pre-Release Service(s); or (x) use the Pre-Release Service(s) to process sensitive personal information, e.g., personal information of children as defined by the Childrens Online Privacy Protection Act, protected health information as defined by the Health Insurance Portability and Accountability Act of 1996, government issued identification numbers, financial account information, payment card data, special categories of data as described in the EU General Data Protection Regulation (GDPR), or other information subject to regulatory, statutory, or contractual restrictions. New Relic reserves the right, but not the obligation, to monitor or review your use of the Pre-Release Service(s) at any time and may investigate any suspected violations of this Policy. 2.3 Intellectual Property Rights. You acknowledge and agree that, as between you and New Relic, New Relic owns all right, title, and interest in and to the Pre-Release Service(s), Confidential Information, and Feedback, including but not limited to all intellectual property and proprietary rights therein. New Relic and its licensors reserve all rights and licenses not expressly granted herein. 2.4 Feedback. You acknowledge and agree that all Feedback will be the sole and exclusive property of New Relic. You hereby irrevocably transfer and assign to New Relic all right, title, and interest in all Feedback, including but not limited to all intellectual property and proprietary rights therein. 3. Confidential Information You will not use or disclose any Confidential Information, except as necessary for the performance of this Policy, and you will use reasonable efforts to protect Confidential Information from unauthorized use or disclosure. You may disclose Confidential Information only to those employees with a bona fide need to know, provided that each employee has signed a written agreement with nondisclosure restrictions at least as protective of the Confidential Information as those set forth herein. For the purposes of this section, information will not be deemed Confidential Information if it: (a) is or becomes generally known to the public through no fault or breach of this Policy; (b) is rightfully known by you at the time of disclosure without an obligation of confidentiality; (c) is independently developed by you without access to or use of the Confidential Information; or (d) is rightfully obtained by you from a third party without restriction on use or disclosure. Upon New Relics request, you agree to destroy all Confidential Information in your possession within 30 days of termination of this Policy. 4. Disclaimers and Acknowledgement 4.1 Acknowledgement of Pre-Release Service(s). You acknowledge and agree that: (a) the Pre-Release Service(s) is not an official product and has not been commercially released for sale by New Relic; (b) the Pre-Release Service(s) may not operate properly, be in final form, or fully function; (c) the Pre-Release Service(s) may contain errors, design flaws, security vulnerabilities, or other problems; (d) it may not be possible to make the Pre-Release Service(s) fully functional or secure; (e) the information obtained using the Pre-Release Service(s) may not be accurate; (f) use of the Pre-Release Service(s) may result in unexpected results, vulnerabilities, loss of data, project delays, or other unpredictable damage or loss, including without limitation to your use of New Relic services and products not governed by this Policy (collectively Unintended Effects); (g) New Relic is under no obligation to release a commercial or generally available version of the Pre-Release Service(s); and (h) New Relic has the right unilaterally to abandon development of the Pre-Release Service(s) at any time and without any obligation or liability to you. 4.2 Your Data. You acknowledge and agree that you should not rely on the Pre-Release Service(s) for any reason. You further acknowledge and agree that you are solely responsible for maintaining and protecting all data and information that is stored, retrieved, or otherwise processed by the Pre-Release Service(s) in accordance with your contractual obligations and requirements under applicable law. Without limiting the foregoing, you are responsible for all costs and expenses required to backup and restore any data and information that is lost or corrupted as a result of your use of the Pre-Release Service(s) or any Unintended Effects. You understand and agree that your Data may be transferred to the United States for storage, processing, and use by New Relic to provide the Pre-Release Service(s). For any data that you process using the Pre-Release Service(s), you represent and warrant that you have all necessary rights and consent to do so. New Relic has no obligation to store any data you process using the Pre-Release Service(s) and shall have no liability for the deletion or accuracy of such data. 4.3 Warranty Disclaimers. YOU ACKNOWLEDGE THAT PRE-RELEASE SERVICE(S) ARE PROVIDED AS IS. TO THE EXTENT PERMITTED BY APPLICABLE LAW, NEW RELIC DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES REGARDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, SECURITY, AND ANY WARRANTIES ARISING OUT OF THE COURSE OF DEALING OR USAGE OF TRADE. NEW RELIC MAKES NO WARRANTY THAT PRE-RELEASE SERVICE(S) WILL MEET YOUR REQUIREMENTS OR WILL BE ACCURATE, RELIABLE, ERROR-FREE, UNINTERRUPTED, TIMELY, OR SECURE. YOUR USE OF PRE-RELEASE SERVICE(S) IS AT YOUR OWN RISK. 4.4 Modifications. New Relic may change the Policy from time to time as our business changes and technology evolves, and future versions of our generally available services may not be compatible with Pre-Release Service(s) built using previous versions. The most current version of this Policy will be posted in the Documentation. Any changes to this Policy will be effective immediately for all users in instances to comply with applicable law, for new users of a Pre-Release Service(s) and, for all other users, any changes to this Policy will be effective as of fifteen (15) days after posting notice of such changes. If we determine in our sole discretion that an update is material, we will provide notice of such material change to you through your New Relic account, the Pre-Release Service(s), the Documentation, our blogs or community forums, and/or by email to the email address of your account administrator. We may require you to provide consent to the updated Policy in a specified manner before further use of the Pre-Release Service(s) is permitted. If you do not agree to any change(s), your sole remedy is to stop using the Pre-Release Service(s) and any such termination by you shall be without penalty except as specified in this Policy. Otherwise, your use of any Pre-Release Service(s) after any such update shall constitute acceptance of the then-current Policy. 5. Limitation of Liability TO THE EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NEW RELIC, ITS AFFILIATES, OFFICERS, EMPLOYEES, AGENTS, SUPPLIERS OR LICENSORS BE LIABLE FOR ANY INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, EXEMPLARY OR CONSEQUENTIAL (INCLUDING LOSS OF USE, DATA, BUSINESS, OR PROFITS) DAMAGES, REGARDLESS OF LEGAL THEORY, WHETHER OR NOT NEW RELIC HAS BEEN WARNED OF THE POSSIBILITY OF SUCH DAMAGES, AND EVEN IF A REMEDY FAILS OF ITS ESSENTIAL PURPOSE. NEW RELICS AGGREGATE LIABILITY FOR ALL CLAIMS RELATING TO THIS POLICY, THE PRE-RELEASE SERVICES, OR ANY UNINTENDED EFFECTS WILL BE LIMITED TO FIFTY U.S. DOLLARS (U.S. $50). THE LIMITATIONS OF DAMAGES SET FORTH ABOVE ARE FUNDAMENTAL ELEMENTS OF THE BASIS OF THE BARGAIN BETWEEN NEW RELIC AND YOU. 6. Indemnity You agree to indemnify and hold New Relic, its parents, subsidiaries, affiliates, officers, agents, employees, and licensors harmless from any claims, fees, fines, demands, losses, liabilities, damages, and costs, including reasonable attorneys fees, arising from or related to your use of the Pre-Release Service(s), including but not limited to allegations arising from your breach of any terms herein and/or allegations that data processed by the Pre-Release Service(s) violates or infringes the privacy, data protection, or intellectual property rights of a third party. 7. Export Restrictions You acknowledge that the software in the Pre-Release Service(s) licensed hereunder may be subject to the export control laws and regulations of the U.S. and other countries. You agree that you will not export or re-export the Pre-Release Service(s), any part thereof, or any process or service that is the direct product of the Pre-Release Service(s) to any country, person or entity subject to U.S. export restrictions. 8. Termination Your access to the Pre-Release Service(s) will terminate upon the earliest of: (i) New Relic making the Pre-Release Service(s) or a successor version of the Pre-Release Service(s) generally available or available for commercial release; (ii) New Relic ceasing to make the Pre-Release Service(s) available to you; or (iii) New Relic terminating this Policy. New Relic may terminate this Policy for any reason upon notice to you. Sections 2.2, 2.3, 2.4, 3, 4, 5, 6, and 7 will survive your use of the Pre-Release Service(s).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 210.49142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Pre-release <em>policy</em>",
        "sections": "2. <em>License</em> and Restrictions",
        "tags": "<em>License</em> <em>information</em>",
        "body": " Services and any related <em>information</em>, including without limitation features, functionality, designs, user interface, capabilities, specifications, architectural diagrams, usage data, APIs, deployment schedules, email lists, bug databases, know how, source code, potential features, Feedback"
      },
      "id": "6044e71b28ccbc984d2c60c8"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.658,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": ". Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, <em>information</em>, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer"
      },
      "id": "6044e6e528ccbc26f22c6084"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/data-collector-licenses": [
    {
      "sections": [
        "New Relic Priority Support"
      ],
      "title": "New Relic Priority Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "f700b8b349627e66540b23ed020c7d9a46e19580",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-priority-support/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Priority Support document as a PDF (172 KB). The services described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.88925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Priority Support document as a PDF (172 KB). The <em>services</em> described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative."
      },
      "id": "603ea90ae7b9d2e9d42a07d1"
    },
    {
      "sections": [
        "New Relic Premium Support"
      ],
      "title": "New Relic Premium Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "db095214148ca053cdabd9815dc74b04299dbe7b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-premium-support/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Premium Support document as a PDF (248 KB). The services described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.8853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Premium Support document as a PDF (248 KB). The <em>services</em> described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative."
      },
      "id": "603ea8c964441fe48b4e88af"
    },
    {
      "sections": [
        "New Relic Diagnostics licenses",
        "Proprietary license",
        "New Relic Diagnostics license terms",
        "Open-source licenses"
      ],
      "title": "New Relic Diagnostics licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "6d86f8f63d372be98270fadc8634f9da8da2a893",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses/",
      "published_at": "2021-06-15T13:33:50Z",
      "updated_at": "2021-03-13T03:25:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proprietary license New Relic Diagnostics license terms These New Relic Diagnostics License Terms (Terms) set forth the terms and conditions under which you (Customer) may use New Relic Diagnostics (the Software), as made available by New Relic, Inc. (New Relic). By clicking accept or downloading or using the Software, you agree to be bound by these Terms. If you are agreeing to these Terms on behalf of your company, then Customer means your company and you are binding your company to these Terms. 1. License Grant. Subject to all of the terms and conditions of these Terms, New Relic grants Customer a limited, non-exclusive, non-transferable, non-sublicensable license to use the Software in accordance with its documentation in support of Customers use of New Relic products to which Customer has a separate subscription (New Relic Products). Unless otherwise specified, there is no fee for use of the Software. 2. License Restrictions. Customer will not (a) sell, rent, sublicense, transfer, time-share or otherwise provide access to any copies of the Software, or portions thereof, to a third party; (b) modify, decompile, disassemble or reverse engineer the Software; (c) use the Software to develop services or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance information or analysis (including benchmarks) relating to the Software. 3. Ownership. Except for the limited license rights expressly provided herein, New Relic and its suppliers have and will retain all right, title and interest in and to the Software, and all copies, updates, modifications and derivative works thereof. Customer acknowledges that it is obtaining only a limited license right to the Software and no ownership rights are being conveyed to Customer under these Terms or otherwise. 4. Usage Data. Customer agrees that New Relic and its affiliates have the right to collect Usage Data from Customer through the Software and use Usage Data to support, operate and improve New Relic products and services and for other lawful business purposes. Usage Data means diagnostics data related to the use of the Software with New Relic Products, including, without limitation, configuration information, details on diagnostics tasks, New Relic account and application ID numbers and New Relic license keys. For clarity, Usage Data is not considered Customer Data, your Data or any other similar term as used in any applicable subscription or license agreement for New Relic Products. At Customers election, Customer may disable the collection of Usage Data as described in the Software documentation. 5. Disclaimers. New Relic is not obligated to provide any support or maintenance for the Software. ALL USE OF SOFTWARE IS AT CUSTOMERS OWN RISK. SOFTWARE IS PROVIDED AS IS, WITH ALL FAULTS AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF TITLE OR NON-INFRINGEMENT. CUSTOMER MAY HAVE OTHER STATUTORY RIGHTS, HOWEVER, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, WILL BE LIMITED TO THE FULLEST EXTENT PERMITTED BY LAW. 6. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL NEW RELIC BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, REGARDLESS OF THE FORM OF ACTION, WHETHER IN CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF INFORMED OF THE POSSIBILITY OF SUCH DAMAGES IN ADVANCE. TO THE EXTENT ANY OF THE ABOVE LIMITATIONS ARE NOT ENFORCEABLE AT APPLICABLE LAW, NEW RELICS ENTIRE LIABILITY TO CUSTOMER UNDER THESE TERMS WILL NOT EXCEED $50. THESE LIMITATIONS ON LIABILITY ARE A FUNDAMENTAL BASIS OF THE BARGAIN AND NEW RELIC WOULD NOT BE ABLE TO PROVIDE THE SOFTWARE WITHOUT SUCH LIMITATIONS. THESE LIMITATIONS ON LIABILITY WILL APPLY NOTWITHSTANDING ANY FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY. 7. Changes and Termination. At its discretion, without notice or liability to Customer, New Relic may (a) update, modify or discontinue the Software; (b) modify these Terms, effective upon posting; or (c) terminate or suspend these Terms or Customers access to the Software. If Customer does not agree with any modification, its sole remedy is to terminate its use of the Software. Upon any termination or suspension, Customer must stop using the Software. 8. Third Party Code. The Software may contain or be provided with third party code (including code which may be made available to Customer in source code form). A list of third party code and ownership, use, warranty and modification rights with respect to such code may be identified in the documentation or provided by New Relic upon Customers written request. New Relic is not responsible for applications and services not licensed by New Relic. 9. Export Compliance. Customer acknowledges that the Software is subject to export restrictions by the U.S. government and import restrictions by certain foreign governments. Customer shall not remove or export from the U.S. or allow the export or re-export of any part of the Software or any direct product thereof: (a) into (or to a national or resident of) any embargoed or terrorist-supporting country; (b) to anyone on the U.S. Commerce Departments Table of Denial Orders or U.S. Treasury Departments list of Specially Designated Nationals; (c) to any country to which such export or re-export is restricted or prohibited, or as to which the U.S. government or any agency thereof requires an export license or other governmental approval at the time of export or re-export without first obtaining such license or approval; or (d) otherwise in violation of any export or import restrictions, laws or regulations of any U.S. or foreign agency or authority. Customer agrees to the foregoing and warrants that Customer is not located in, under the control of, or a national or resident of any such prohibited country or on any such prohibited party list. 10. Government End-Users. The Software is commercial computer software. If Customer is an entity of the U.S. government, the use, duplication, reproduction, release, modification, disclosure or transfer of the Software, or any related documentation of any kind, is restricted by a license agreement or by these Terms in accordance with Federal Acquisition Regulation 12.212 for civilian purposes and Defense Federal Acquisition Regulation Supplement 227.7202 for military purposes. The Software was developed fully at private expense. All other use is prohibited. 11. General. These Terms will be governed by and construed under the laws of the State of California and the U.S. without regard to conflicts of law provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods. The jurisdiction and venue for actions arising out of or relating to these Terms shall be in the state and federal courts in San Francisco, California. The parties are independent contractors. Customer may not assign these Terms without New Relics prior written consent and any attempt to do so will be void; New Relic may assign these Terms freely to any party without Customers consent. If any provision of these Terms is held by a court of competent jurisdiction to be unenforceable or invalid for any reason, that provision shall be limited to the minimum extent necessary so that these Terms shall otherwise remain in effect. These Terms are the entire agreement between the parties relating to the Software, and supersede all prior or contemporaneous agreements (oral or written) relating to the Software. Any separate agreement Customer has for New Relic Products does not apply to the Software. Open-source licenses We love open-source software, and use the following in New Relic Diagnostics. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License clbanning/mxj MIT go-yaml/yaml Apache 2.0 StackExchange/wmi MIT go-ole/go-ole MIT shirou/gopsutil BSD-3-Clause shirou/w32 BSD-3-Clause cheggaaa/pb BSD-3-Clause google/uuid BSD-3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Diagnostics <em>licenses</em>",
        "sections": "New Relic Diagnostics <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": ") use the Software to develop <em>services</em> or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance <em>information</em> or analysis (including benchmarks"
      },
      "id": "604505ad28ccbc457e2c60b4"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses": [
    {
      "sections": [
        "Data collector licenses"
      ],
      "title": "Data collector licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "8eeb19ae388c1f4fd6856084084467a037861675",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/data-collector-licenses/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Package Licenses annotations Apache 2.0 antlr BSD apache-log4j-extras Apache 2.0 apache-mime4j Apache 2.0 bonecp Apache 2.0 bonecp-provider Apache 2.0 bytelist MIT c3p0 Eclipse 1.0 commons-beanutils Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-digester Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-lang3 Apache 2.0 commons-logging Apache 2.0 commons-math Apache 2.0 commons-pool Apache 2.0 constantine MIT dom4j BSD ehcache Apache 2.0 gson Apache 2.0 guava Apache 2.0 hamcrest-core BSD-3-Clause hibernate-commons-annotations GNU LGPL 2.1 hibernate-core GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 hibernate-c3p0 GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 hystrix Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 jaffl GNU LGPL 3.0 java-driver Apache 2.0 javassist MPL 1.1, GNU GPL 2.1, Apache 2.0 javax.servlet Apache 2.0, Eclipse 1.0 javax.servlet-api CDDL + GPLv2 with classpath exception jboss-logging GNU LGPL 2.1 jboss-transaction-api_1.1_spec GNU LGPL 2.1 jcodings Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 jedis MIT jetty Apache 2.0, Eclipse 1.0 jffi GNU LGPL 3.0 jline BSD 2-Clause joni MIT jnr-netdb GNU LGPL 3.0 jnr-posix Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 joda-time Apache 2.0 jopt-simple MIT json-simple Apache 2.0 jsr305 Apache 2.0 junit Common Public License 1.0 kafka Apache 2.0 libthrift Apache 2.0 log4j Apache 2.0 logback-classic Eclipse 1.0 logback-core Eclipse 1.0 metrics-annotation Apache 2.0 mockito-all MIT msgpack Apache 2.0 mysql-connector-java GNU GPL 2 reflections WTFPL scala-library Apache 2.0 scannotation Apache 2.0 slf4j-api MIT slf4j-over-log4j MIT snakeyaml Apache 2.0 snappy Apache 2.0 syslog4j LGPL xml-apis Apache 2.0 yamlbeans MIT zkclient Apache 2.0 zookeeper Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.90233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data collector <em>licenses</em>",
        "sections": "Data collector <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Package <em>Licenses</em> annotations"
      },
      "id": "603eb41d64441fd7f74e8893"
    },
    {
      "sections": [
        "New Relic Priority Support"
      ],
      "title": "New Relic Priority Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "f700b8b349627e66540b23ed020c7d9a46e19580",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-priority-support/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Priority Support document as a PDF (172 KB). The services described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.88925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Priority Support document as a PDF (172 KB). The <em>services</em> described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative."
      },
      "id": "603ea90ae7b9d2e9d42a07d1"
    },
    {
      "sections": [
        "New Relic Premium Support"
      ],
      "title": "New Relic Premium Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "db095214148ca053cdabd9815dc74b04299dbe7b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-premium-support/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Premium Support document as a PDF (248 KB). The services described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.8853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Premium Support document as a PDF (248 KB). The <em>services</em> described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative."
      },
      "id": "603ea8c964441fe48b4e88af"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-premium-support": [
    {
      "sections": [
        "Data collector licenses"
      ],
      "title": "Data collector licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "8eeb19ae388c1f4fd6856084084467a037861675",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/data-collector-licenses/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Package Licenses annotations Apache 2.0 antlr BSD apache-log4j-extras Apache 2.0 apache-mime4j Apache 2.0 bonecp Apache 2.0 bonecp-provider Apache 2.0 bytelist MIT c3p0 Eclipse 1.0 commons-beanutils Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-digester Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-lang3 Apache 2.0 commons-logging Apache 2.0 commons-math Apache 2.0 commons-pool Apache 2.0 constantine MIT dom4j BSD ehcache Apache 2.0 gson Apache 2.0 guava Apache 2.0 hamcrest-core BSD-3-Clause hibernate-commons-annotations GNU LGPL 2.1 hibernate-core GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 hibernate-c3p0 GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 hystrix Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 jaffl GNU LGPL 3.0 java-driver Apache 2.0 javassist MPL 1.1, GNU GPL 2.1, Apache 2.0 javax.servlet Apache 2.0, Eclipse 1.0 javax.servlet-api CDDL + GPLv2 with classpath exception jboss-logging GNU LGPL 2.1 jboss-transaction-api_1.1_spec GNU LGPL 2.1 jcodings Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 jedis MIT jetty Apache 2.0, Eclipse 1.0 jffi GNU LGPL 3.0 jline BSD 2-Clause joni MIT jnr-netdb GNU LGPL 3.0 jnr-posix Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 joda-time Apache 2.0 jopt-simple MIT json-simple Apache 2.0 jsr305 Apache 2.0 junit Common Public License 1.0 kafka Apache 2.0 libthrift Apache 2.0 log4j Apache 2.0 logback-classic Eclipse 1.0 logback-core Eclipse 1.0 metrics-annotation Apache 2.0 mockito-all MIT msgpack Apache 2.0 mysql-connector-java GNU GPL 2 reflections WTFPL scala-library Apache 2.0 scannotation Apache 2.0 slf4j-api MIT slf4j-over-log4j MIT snakeyaml Apache 2.0 snappy Apache 2.0 syslog4j LGPL xml-apis Apache 2.0 yamlbeans MIT zkclient Apache 2.0 zookeeper Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.90233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data collector <em>licenses</em>",
        "sections": "Data collector <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Package <em>Licenses</em> annotations"
      },
      "id": "603eb41d64441fd7f74e8893"
    },
    {
      "sections": [
        "New Relic Priority Support"
      ],
      "title": "New Relic Priority Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "f700b8b349627e66540b23ed020c7d9a46e19580",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-priority-support/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:43:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Priority Support document as a PDF (172 KB). The services described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.88925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Priority Support document as a PDF (172 KB). The <em>services</em> described in this document only apply to initial orders entered after August 1, 2019. If you have questions about New Relic Priority Support, contact your New Relic account representative."
      },
      "id": "603ea90ae7b9d2e9d42a07d1"
    },
    {
      "sections": [
        "New Relic Diagnostics licenses",
        "Proprietary license",
        "New Relic Diagnostics license terms",
        "Open-source licenses"
      ],
      "title": "New Relic Diagnostics licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "6d86f8f63d372be98270fadc8634f9da8da2a893",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses/",
      "published_at": "2021-06-15T13:33:50Z",
      "updated_at": "2021-03-13T03:25:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proprietary license New Relic Diagnostics license terms These New Relic Diagnostics License Terms (Terms) set forth the terms and conditions under which you (Customer) may use New Relic Diagnostics (the Software), as made available by New Relic, Inc. (New Relic). By clicking accept or downloading or using the Software, you agree to be bound by these Terms. If you are agreeing to these Terms on behalf of your company, then Customer means your company and you are binding your company to these Terms. 1. License Grant. Subject to all of the terms and conditions of these Terms, New Relic grants Customer a limited, non-exclusive, non-transferable, non-sublicensable license to use the Software in accordance with its documentation in support of Customers use of New Relic products to which Customer has a separate subscription (New Relic Products). Unless otherwise specified, there is no fee for use of the Software. 2. License Restrictions. Customer will not (a) sell, rent, sublicense, transfer, time-share or otherwise provide access to any copies of the Software, or portions thereof, to a third party; (b) modify, decompile, disassemble or reverse engineer the Software; (c) use the Software to develop services or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance information or analysis (including benchmarks) relating to the Software. 3. Ownership. Except for the limited license rights expressly provided herein, New Relic and its suppliers have and will retain all right, title and interest in and to the Software, and all copies, updates, modifications and derivative works thereof. Customer acknowledges that it is obtaining only a limited license right to the Software and no ownership rights are being conveyed to Customer under these Terms or otherwise. 4. Usage Data. Customer agrees that New Relic and its affiliates have the right to collect Usage Data from Customer through the Software and use Usage Data to support, operate and improve New Relic products and services and for other lawful business purposes. Usage Data means diagnostics data related to the use of the Software with New Relic Products, including, without limitation, configuration information, details on diagnostics tasks, New Relic account and application ID numbers and New Relic license keys. For clarity, Usage Data is not considered Customer Data, your Data or any other similar term as used in any applicable subscription or license agreement for New Relic Products. At Customers election, Customer may disable the collection of Usage Data as described in the Software documentation. 5. Disclaimers. New Relic is not obligated to provide any support or maintenance for the Software. ALL USE OF SOFTWARE IS AT CUSTOMERS OWN RISK. SOFTWARE IS PROVIDED AS IS, WITH ALL FAULTS AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF TITLE OR NON-INFRINGEMENT. CUSTOMER MAY HAVE OTHER STATUTORY RIGHTS, HOWEVER, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, WILL BE LIMITED TO THE FULLEST EXTENT PERMITTED BY LAW. 6. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL NEW RELIC BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, REGARDLESS OF THE FORM OF ACTION, WHETHER IN CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF INFORMED OF THE POSSIBILITY OF SUCH DAMAGES IN ADVANCE. TO THE EXTENT ANY OF THE ABOVE LIMITATIONS ARE NOT ENFORCEABLE AT APPLICABLE LAW, NEW RELICS ENTIRE LIABILITY TO CUSTOMER UNDER THESE TERMS WILL NOT EXCEED $50. THESE LIMITATIONS ON LIABILITY ARE A FUNDAMENTAL BASIS OF THE BARGAIN AND NEW RELIC WOULD NOT BE ABLE TO PROVIDE THE SOFTWARE WITHOUT SUCH LIMITATIONS. THESE LIMITATIONS ON LIABILITY WILL APPLY NOTWITHSTANDING ANY FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY. 7. Changes and Termination. At its discretion, without notice or liability to Customer, New Relic may (a) update, modify or discontinue the Software; (b) modify these Terms, effective upon posting; or (c) terminate or suspend these Terms or Customers access to the Software. If Customer does not agree with any modification, its sole remedy is to terminate its use of the Software. Upon any termination or suspension, Customer must stop using the Software. 8. Third Party Code. The Software may contain or be provided with third party code (including code which may be made available to Customer in source code form). A list of third party code and ownership, use, warranty and modification rights with respect to such code may be identified in the documentation or provided by New Relic upon Customers written request. New Relic is not responsible for applications and services not licensed by New Relic. 9. Export Compliance. Customer acknowledges that the Software is subject to export restrictions by the U.S. government and import restrictions by certain foreign governments. Customer shall not remove or export from the U.S. or allow the export or re-export of any part of the Software or any direct product thereof: (a) into (or to a national or resident of) any embargoed or terrorist-supporting country; (b) to anyone on the U.S. Commerce Departments Table of Denial Orders or U.S. Treasury Departments list of Specially Designated Nationals; (c) to any country to which such export or re-export is restricted or prohibited, or as to which the U.S. government or any agency thereof requires an export license or other governmental approval at the time of export or re-export without first obtaining such license or approval; or (d) otherwise in violation of any export or import restrictions, laws or regulations of any U.S. or foreign agency or authority. Customer agrees to the foregoing and warrants that Customer is not located in, under the control of, or a national or resident of any such prohibited country or on any such prohibited party list. 10. Government End-Users. The Software is commercial computer software. If Customer is an entity of the U.S. government, the use, duplication, reproduction, release, modification, disclosure or transfer of the Software, or any related documentation of any kind, is restricted by a license agreement or by these Terms in accordance with Federal Acquisition Regulation 12.212 for civilian purposes and Defense Federal Acquisition Regulation Supplement 227.7202 for military purposes. The Software was developed fully at private expense. All other use is prohibited. 11. General. These Terms will be governed by and construed under the laws of the State of California and the U.S. without regard to conflicts of law provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods. The jurisdiction and venue for actions arising out of or relating to these Terms shall be in the state and federal courts in San Francisco, California. The parties are independent contractors. Customer may not assign these Terms without New Relics prior written consent and any attempt to do so will be void; New Relic may assign these Terms freely to any party without Customers consent. If any provision of these Terms is held by a court of competent jurisdiction to be unenforceable or invalid for any reason, that provision shall be limited to the minimum extent necessary so that these Terms shall otherwise remain in effect. These Terms are the entire agreement between the parties relating to the Software, and supersede all prior or contemporaneous agreements (oral or written) relating to the Software. Any separate agreement Customer has for New Relic Products does not apply to the Software. Open-source licenses We love open-source software, and use the following in New Relic Diagnostics. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License clbanning/mxj MIT go-yaml/yaml Apache 2.0 StackExchange/wmi MIT go-ole/go-ole MIT shirou/gopsutil BSD-3-Clause shirou/w32 BSD-3-Clause cheggaaa/pb BSD-3-Clause google/uuid BSD-3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Diagnostics <em>licenses</em>",
        "sections": "New Relic Diagnostics <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": ") use the Software to develop <em>services</em> or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance <em>information</em> or analysis (including benchmarks"
      },
      "id": "604505ad28ccbc457e2c60b4"
    }
  ],
  "/docs/licenses/license-information/special-services-licenses/new-relic-priority-support": [
    {
      "sections": [
        "Data collector licenses"
      ],
      "title": "Data collector licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "8eeb19ae388c1f4fd6856084084467a037861675",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/data-collector-licenses/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T06:20:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Package Licenses annotations Apache 2.0 antlr BSD apache-log4j-extras Apache 2.0 apache-mime4j Apache 2.0 bonecp Apache 2.0 bonecp-provider Apache 2.0 bytelist MIT c3p0 Eclipse 1.0 commons-beanutils Apache 2.0 commons-codec Apache 2.0 commons-collections Apache 2.0 commons-configuration Apache 2.0 commons-dbcp Apache 2.0 commons-dbutils Apache 2.0 commons-digester Apache 2.0 commons-io Apache 2.0 commons-lang Apache 2.0 commons-lang3 Apache 2.0 commons-logging Apache 2.0 commons-math Apache 2.0 commons-pool Apache 2.0 constantine MIT dom4j BSD ehcache Apache 2.0 gson Apache 2.0 guava Apache 2.0 hamcrest-core BSD-3-Clause hibernate-commons-annotations GNU LGPL 2.1 hibernate-core GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 hibernate-c3p0 GNU LGPL 2.1 hibernate-ehcache GNU LGPL 2.1 hibernate-jpa-2.0-api GNU LGPL 2.1 httpclient Apache 2.0 httpcore Apache 2.0 httpmime Apache 2.0 hystrix Apache 2.0 jackson-core-asl Apache 2.0 jackson-mapper-asl Apache 2.0 jaffl GNU LGPL 3.0 java-driver Apache 2.0 javassist MPL 1.1, GNU GPL 2.1, Apache 2.0 javax.servlet Apache 2.0, Eclipse 1.0 javax.servlet-api CDDL + GPLv2 with classpath exception jboss-logging GNU LGPL 2.1 jboss-transaction-api_1.1_spec GNU LGPL 2.1 jcodings Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 jedis MIT jetty Apache 2.0, Eclipse 1.0 jffi GNU LGPL 3.0 jline BSD 2-Clause joni MIT jnr-netdb GNU LGPL 3.0 jnr-posix Common Public License 1.0, GNU GPL 2, GNU LGPL 2.1 joda-time Apache 2.0 jopt-simple MIT json-simple Apache 2.0 jsr305 Apache 2.0 junit Common Public License 1.0 kafka Apache 2.0 libthrift Apache 2.0 log4j Apache 2.0 logback-classic Eclipse 1.0 logback-core Eclipse 1.0 metrics-annotation Apache 2.0 mockito-all MIT msgpack Apache 2.0 mysql-connector-java GNU GPL 2 reflections WTFPL scala-library Apache 2.0 scannotation Apache 2.0 slf4j-api MIT slf4j-over-log4j MIT snakeyaml Apache 2.0 snappy Apache 2.0 syslog4j LGPL xml-apis Apache 2.0 yamlbeans MIT zkclient Apache 2.0 zookeeper Apache 2.0",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.90233,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data collector <em>licenses</em>",
        "sections": "Data collector <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic data collectors. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the <em>license</em> we&#x27;ve chosen to use. Package <em>Licenses</em> annotations"
      },
      "id": "603eb41d64441fd7f74e8893"
    },
    {
      "sections": [
        "New Relic Premium Support"
      ],
      "title": "New Relic Premium Support",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "db095214148ca053cdabd9815dc74b04299dbe7b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-premium-support/",
      "published_at": "2021-06-15T12:12:03Z",
      "updated_at": "2021-03-16T04:14:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download the New Relic Premium Support document as a PDF (248 KB). The services described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.8853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": "Download the New Relic Premium Support document as a PDF (248 KB). The <em>services</em> described in this document only apply to initial orders entered after April 1, 2018. If you have questions about New Relic Premium Support, contact your New Relic account representative."
      },
      "id": "603ea8c964441fe48b4e88af"
    },
    {
      "sections": [
        "New Relic Diagnostics licenses",
        "Proprietary license",
        "New Relic Diagnostics license terms",
        "Open-source licenses"
      ],
      "title": "New Relic Diagnostics licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Special services licenses"
      ],
      "external_id": "6d86f8f63d372be98270fadc8634f9da8da2a893",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/special-services-licenses/new-relic-diagnostics-licenses/",
      "published_at": "2021-06-15T13:33:50Z",
      "updated_at": "2021-03-13T03:25:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Proprietary license New Relic Diagnostics license terms These New Relic Diagnostics License Terms (Terms) set forth the terms and conditions under which you (Customer) may use New Relic Diagnostics (the Software), as made available by New Relic, Inc. (New Relic). By clicking accept or downloading or using the Software, you agree to be bound by these Terms. If you are agreeing to these Terms on behalf of your company, then Customer means your company and you are binding your company to these Terms. 1. License Grant. Subject to all of the terms and conditions of these Terms, New Relic grants Customer a limited, non-exclusive, non-transferable, non-sublicensable license to use the Software in accordance with its documentation in support of Customers use of New Relic products to which Customer has a separate subscription (New Relic Products). Unless otherwise specified, there is no fee for use of the Software. 2. License Restrictions. Customer will not (a) sell, rent, sublicense, transfer, time-share or otherwise provide access to any copies of the Software, or portions thereof, to a third party; (b) modify, decompile, disassemble or reverse engineer the Software; (c) use the Software to develop services or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance information or analysis (including benchmarks) relating to the Software. 3. Ownership. Except for the limited license rights expressly provided herein, New Relic and its suppliers have and will retain all right, title and interest in and to the Software, and all copies, updates, modifications and derivative works thereof. Customer acknowledges that it is obtaining only a limited license right to the Software and no ownership rights are being conveyed to Customer under these Terms or otherwise. 4. Usage Data. Customer agrees that New Relic and its affiliates have the right to collect Usage Data from Customer through the Software and use Usage Data to support, operate and improve New Relic products and services and for other lawful business purposes. Usage Data means diagnostics data related to the use of the Software with New Relic Products, including, without limitation, configuration information, details on diagnostics tasks, New Relic account and application ID numbers and New Relic license keys. For clarity, Usage Data is not considered Customer Data, your Data or any other similar term as used in any applicable subscription or license agreement for New Relic Products. At Customers election, Customer may disable the collection of Usage Data as described in the Software documentation. 5. Disclaimers. New Relic is not obligated to provide any support or maintenance for the Software. ALL USE OF SOFTWARE IS AT CUSTOMERS OWN RISK. SOFTWARE IS PROVIDED AS IS, WITH ALL FAULTS AND WITHOUT WARRANTY OF ANY KIND, EXPRESS, IMPLIED OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, WARRANTIES OF TITLE OR NON-INFRINGEMENT. CUSTOMER MAY HAVE OTHER STATUTORY RIGHTS, HOWEVER, THE DURATION OF STATUTORILY REQUIRED WARRANTIES, IF ANY, WILL BE LIMITED TO THE FULLEST EXTENT PERMITTED BY LAW. 6. Limitation of Liability. TO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL NEW RELIC BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND, REGARDLESS OF THE FORM OF ACTION, WHETHER IN CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF INFORMED OF THE POSSIBILITY OF SUCH DAMAGES IN ADVANCE. TO THE EXTENT ANY OF THE ABOVE LIMITATIONS ARE NOT ENFORCEABLE AT APPLICABLE LAW, NEW RELICS ENTIRE LIABILITY TO CUSTOMER UNDER THESE TERMS WILL NOT EXCEED $50. THESE LIMITATIONS ON LIABILITY ARE A FUNDAMENTAL BASIS OF THE BARGAIN AND NEW RELIC WOULD NOT BE ABLE TO PROVIDE THE SOFTWARE WITHOUT SUCH LIMITATIONS. THESE LIMITATIONS ON LIABILITY WILL APPLY NOTWITHSTANDING ANY FAILURE OF ESSENTIAL PURPOSE OF ANY LIMITED REMEDY. 7. Changes and Termination. At its discretion, without notice or liability to Customer, New Relic may (a) update, modify or discontinue the Software; (b) modify these Terms, effective upon posting; or (c) terminate or suspend these Terms or Customers access to the Software. If Customer does not agree with any modification, its sole remedy is to terminate its use of the Software. Upon any termination or suspension, Customer must stop using the Software. 8. Third Party Code. The Software may contain or be provided with third party code (including code which may be made available to Customer in source code form). A list of third party code and ownership, use, warranty and modification rights with respect to such code may be identified in the documentation or provided by New Relic upon Customers written request. New Relic is not responsible for applications and services not licensed by New Relic. 9. Export Compliance. Customer acknowledges that the Software is subject to export restrictions by the U.S. government and import restrictions by certain foreign governments. Customer shall not remove or export from the U.S. or allow the export or re-export of any part of the Software or any direct product thereof: (a) into (or to a national or resident of) any embargoed or terrorist-supporting country; (b) to anyone on the U.S. Commerce Departments Table of Denial Orders or U.S. Treasury Departments list of Specially Designated Nationals; (c) to any country to which such export or re-export is restricted or prohibited, or as to which the U.S. government or any agency thereof requires an export license or other governmental approval at the time of export or re-export without first obtaining such license or approval; or (d) otherwise in violation of any export or import restrictions, laws or regulations of any U.S. or foreign agency or authority. Customer agrees to the foregoing and warrants that Customer is not located in, under the control of, or a national or resident of any such prohibited country or on any such prohibited party list. 10. Government End-Users. The Software is commercial computer software. If Customer is an entity of the U.S. government, the use, duplication, reproduction, release, modification, disclosure or transfer of the Software, or any related documentation of any kind, is restricted by a license agreement or by these Terms in accordance with Federal Acquisition Regulation 12.212 for civilian purposes and Defense Federal Acquisition Regulation Supplement 227.7202 for military purposes. The Software was developed fully at private expense. All other use is prohibited. 11. General. These Terms will be governed by and construed under the laws of the State of California and the U.S. without regard to conflicts of law provisions thereof, and without regard to the United Nations Convention on the International Sale of Goods. The jurisdiction and venue for actions arising out of or relating to these Terms shall be in the state and federal courts in San Francisco, California. The parties are independent contractors. Customer may not assign these Terms without New Relics prior written consent and any attempt to do so will be void; New Relic may assign these Terms freely to any party without Customers consent. If any provision of these Terms is held by a court of competent jurisdiction to be unenforceable or invalid for any reason, that provision shall be limited to the minimum extent necessary so that these Terms shall otherwise remain in effect. These Terms are the entire agreement between the parties relating to the Software, and supersede all prior or contemporaneous agreements (oral or written) relating to the Software. Any separate agreement Customer has for New Relic Products does not apply to the Software. Open-source licenses We love open-source software, and use the following in New Relic Diagnostics. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License clbanning/mxj MIT go-yaml/yaml Apache 2.0 StackExchange/wmi MIT go-ole/go-ole MIT shirou/gopsutil BSD-3-Clause shirou/w32 BSD-3-Clause cheggaaa/pb BSD-3-Clause google/uuid BSD-3-Clause",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.313,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Diagnostics <em>licenses</em>",
        "sections": "New Relic Diagnostics <em>licenses</em>",
        "tags": "<em>Special</em> <em>services</em> <em>licenses</em>",
        "body": ") use the Software to develop <em>services</em> or products for sale or include any components of the Software in any product; (d) remove any product identification, proprietary, copyright or other notices in the Software; or (e) publicly disseminate performance <em>information</em> or analysis (including benchmarks"
      },
      "id": "604505ad28ccbc457e2c60b4"
    }
  ],
  "/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions": [
    {
      "sections": [
        "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
        "Important",
        "Usage Plan: New Relic Platform Pricing",
        "Eligible Services",
        "Eligible Services (Partners)",
        "Subscriptions with indeterminate pricing or usage quantities",
        "Product Usage Ratio"
      ],
      "title": "Product-based pricing usage and New Relic Platform Pricing Usage Plan",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "e2686dc773c4e844544ce633a9a41a16f15edf5a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan/",
      "published_at": "2021-06-15T12:13:01Z",
      "updated_at": "2021-03-16T04:22:57Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc explains our original product-based pricing plan. For more about pricing changes, see Overview of pricing changes. The following provisions are applicable to existing customers (i) that have existing Terms, and (ii) that to the extent its subscription to the New Relic products reference the usage plans set forth below or where a subscription has indeterminate product pricing or usage quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. Usage Plan: New Relic Platform Pricing The following Eligible Services with New Relic are products that are referenced in specific order forms for New Relic Platform Pricing. For more information, contact your New Relic account representative. Eligible Services Eligible Services Per Unit Unit of Measure Monthly Standard Fee Rate New Relic APM Pro CU Annual* 10,000 Compute Units $166.70 New Relic APM Pro Host Annual* 1 Hosts $149 New Relic Insights Pro Annual 50,000,000 Events $165 New Relic Infrastructure Pro Annual 10,000 Compute Units $12 New Relic Browser Pro Annual 500,000 Page Views $149 New Relic Logs Annual - 8 Days* * 1 Per GB Daily $55 New Relic Logs Annual - 15 Days* * 1 Per GB Daily $65 New Relic Logs Annual - 30 Days* * 1 Per GB Daily $75 New Relic Metrics Annual 1,000 Data Points per Minute $25 New Relic Mobile Enterprise Annual 50,000 Total Users $499 New Relic Serverless for AWS Lambda Annual 1,000,000 AWS Lambda Events $15 New Relic Synthetics Pro Annual 10,000 Checks $69 New Relic Synthetics private locations (for New Relic Synthetics Pro Annual product) Fixed fee N/A $1,000 New Relic Traces Annual 1,000,000 Spans $1 New Relic AI Incident Intelligence Annual 1,000 Incident Events $500 New Relic AI Proactive Detection Annual 1,000,000,000 App Transactions $250 * Customer may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. For more information about units of measures, see Product definitions. Eligible Services (Partners) Eligible services for New Relic Partners Measurement New Relic APM Pro CU Annual* Sold in Units of 8,900 Compute Units New Relic APM Pro Host Annual* Sold in Units of 1 Host New Relic Browser Pro Annual Sold in Units of 500,000 Page Views New Relic Infrastructure Pro Annual Sold in Units of 125,000 Compute Units New Relic Insights Pro Annual Sold in Units of 45,000,000 Events New Relic Logs Annual - 8 Days* * Sold in Units of 3 GB Daily New Relic Logs Annual - 15 Days* * Sold in Units of 2.5 GB Daily New Relic Logs Annual - 30 Days* * Sold in Units of 2 GB Daily New Relic Metrics Annual Sold in Units of 6,000 Data Points per Minute New Relic Mobile Enterprise Annual Sold in Units of 15,000 Total Users New Relic Serverless for AWS Lambda Annual Sold in Units of 10,000,000 AWS Lambda Events New Relic Synthetics Pro with Private Locations Annual Sold in Units of 22,000 Checks New Relic Traces Annual Sold in Units of 149,000,000 Spans * Customer and/or Partner may utilize either New Relic APM Pro Annual or New Relic APM Pro CUs Annual, but not both. Customer and/or Partner will be provisioned New Relic APM Pro CUs Annual by default, unless otherwise stated in the relevant Order Form. * * Customer and/or Partner may utilize only one of New Relic Logs Annual - 8 Days, New Relic Logs Annual - 15 Days, or New Relic Logs Annual - 30 days. For the avoidance of doubt, Customer may not utilize New Relic Logs Annual with varying numbers of days retention concurrently. Customer and/or Partner will be provisioned New Relic Logs Annual - 30 Days by default, unless otherwise stated in the relevant Order Form. Subscriptions with indeterminate pricing or usage quantities Product Usage Ratio Where a Customer subscription to the Products contain no specific pricing or quantities, Product-specific usage for a specific calendar month shall be determined through the calculation of the following ratio (the Product Usage Ratio) where: (1) the numerator shall be the Product specific usage for such calendar month multiplied by such Products list price, and (2) the denominator shall be the the aggregate Customer usage of all Products during such calendar month multiplied by all such Product(s) list price. The Product Usage Ratio shall be the percentage of usage for a specific Product for a calendar month period, or if usage cannot be measured for a period, the last Product Usage Ratio that can be calculated shall be assumed constant.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.01115,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Product-based pricing <em>usage</em> and New Relic Platform Pricing <em>Usage</em> <em>Plan</em>",
        "sections": "Product-based pricing <em>usage</em> and New Relic Platform Pricing <em>Usage</em> <em>Plan</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " reference the <em>usage</em> <em>plans</em> set forth below or where a subscription has indeterminate product pricing or <em>usage</em> quantities. New customers are eligible for New Relic One pricing as described here. Capitalized terms not defined below shall take on the meaning set forth in such New Relic order form. <em>Usage</em>"
      },
      "id": "603ea32a28ccbc7e22eba768"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.805244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Usage</em> <em>Plan</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https:&#x2F;&#x2F;newrelic.com&#x2F;termsandconditions&#x2F;unpaid. <em>Usage</em> <em>Plan</em> <em>Usage</em> <em>Plan</em> refers to the Service or Product"
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-05-22T17:24:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.804565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing <em>plan</em> terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app"
      },
      "id": "603ebacc64441f77774e8872"
    }
  ],
  "/docs/licenses/license-information/usage-plans/product-based-pricing-usage-new-relic-platform-pricing-usage-plan": [
    {
      "sections": [
        "New Relic One Usage plan descriptions",
        "Pay As You Go",
        "Annual Pool of Funds",
        "Applicable Invoicing and Order Terms",
        "User Accounts",
        "New Relic One Pro and Enterprise Service Level Availability Commitment",
        "New Relic One Pro and Enterprise Support Plans",
        "Free tier, lite, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions"
      ],
      "title": "New Relic One Usage plan descriptions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Usage plans"
      ],
      "external_id": "c18e1c6c294914c28bba48f9de025333210ed254",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/usage-plans/new-relic-one-usage-plan-descriptions/",
      "published_at": "2021-06-15T12:13:01Z",
      "updated_at": "2021-03-13T04:19:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Usage Plan applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription. New Relic may modify the Usage Plan from time to time. Any changes to the Usage Plan will become effective immediately for changes that provide a benefit or right to the Customer, all other changes will become effective if Customer assents or upon any new or renewal Commitment Term. Usage Plan - Effective as February 19, 2021: The Order and Usage Plan may contain defined terms that are denoted by capitalization. In the event that a capitalized term is not defined in either the Order or the Usage Plan, such terms shall have the meaning set forth in the New Relic One pricing definitions page. Pay As You Go By electing and subscribing to the Pay As You Go subscription model (Pay As You Go or PAYG), Customer commits to paying for the New Relic Products on a month-to-month consumption basis. Monthly Product Usage will be invoiced regardless if a PO is required or not. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Customers usage of the Products in excess of the Free Tier each month shall be billed in arrears on the first business day of the following month based on the Customers Per Unit usage of each Product each month multiplied by the corresponding rates set forth in an Order and summed (Monthly Product Usage). Annual Pool of Funds By electing and subscribing to the Annual Pool of Funds subscription model (Annual Pool of Funds or APoF) for the Commitment Term, Customer commits in an Order to: (i) paying the Commitment Fee amounts described in the Subscription table and any additional commitment fees set forth; and (ii) the Monthly Discounted Fee Rates applying to Customers Monthly Product Usage. New Relic will invoice the Commitment Fee as per the Billing Terms described in an Order. On a monthly cadence during the Commitment Term, Customers Per Unit usage of the Products will be multiplied by the corresponding Monthly Discounted Rate and summed (Monthly Product Usage). Monthly Product Usage will be deducted from the Commitment Fee amounts that are paid in advance. If Monthly Product Usage exceeds any such remaining unconsumed amounts, Customer will be invoiced for the difference (Additional Usage), including for any Monthly Product Usage during the last month of the Commitment Term. Payment of such invoices will be governed as set forth in the Terms. Any Customer dispute to Monthly Product Usage from the prior month must be in good-faith and received by New Relic in writing within three (3) business days of the start of the next month (including for any Monthly Product Usage for the last month of the Commitment Term) or such dispute notice will be considered invalid. The dispute notice will set forth in reasonable detail the information concerning the disputed charges. The parties will use good-faith efforts to promptly resolve any disputed charges. Any unconsumed balances from the Customer payment of each annual Commitment Fee and any additional payments, if applicable, as set out in an Order will expire and lapse at the end of each year of the Commitment Term. Applicable Invoicing and Order Terms All amounts stated in an Order are non-cancelable payment obligations of the Customer for the Commitment Term regardless of usage. Any fees paid are non-refundable and do not represent a deposit for, or a credit towards, the purchase of other products not specified in an Order or for any purchase after the Commitment Term. Customer acknowledges that a final payment for the full outstanding amount of any remaining unpaid Commitment Fee and/or Monthly Product Usage Fee may be invoiced upon each anniversary date of the term start date. Tax will be added where applicable. New Relic may review Customer's use of the Products at any time. If New Relic identifies any Customer usage of the Product(s) that is not in accordance with the Terms or Documentation, New Relic may suspend such unauthorized usage. All existing purchases and related pricing in effect prior to the execution of an Order shall remain in force. Unless otherwise stated in an Order, an Order does not modify or amend any existing purchases. Additional future products or quantities are not subject to promotional pricing unless otherwise stated in an Order. In the event that a Customer indicates in an Order that it requires a purchase order (PO) for its subscription, Customer agrees to provide the required PO prior to the provisioning of the Products. If a Customer does not indicate a PO is required, Customer agrees that New Relic may issue invoice(s) and is entitled to such payment without a PO reference. All Additional Usage fees will be invoiced regardless of a PO requirement. The Product(s) are deemed accepted upon its provisioning. User Accounts Use of the Products require Customer users to create Login Credentials. Customer user Login Credential information must be accurate, current, and complete. New Relics use and collection of Login Credentials (in accordance with its General Data Privacy Notice) is for account and product management and support of its customers. Customer and Customer users must abide by the New Relic Acceptable Use Policy (AUP) and Login Credentials may not be shared. Each Customer user must have their own user account. Entry into an Order indicates your agreement that the amount of provisioned users (at the rate specified in the Order) applies in lieu of and supersedes any other amount of users of the Products that may be specified in the agreement between Customer and New Relic. New Relic One Pro and Enterprise Service Level Availability Commitment With a subscription to New Relic Full Stack Observability Pro or Enterprise Products, you agree that during the Commitment Term the applicable service level availability commitment set forth on the Service level availability commitment page in the Documentation shall apply to the Products. For clarity, if your agreement with New Relic contains a different service level availability commitment or remedies, the above does not apply to your subscription to the New Relic Full Stack Observability Pro or Enterprise Products. If you subscribe to any other New Relic Products with New Relic One pricing, any service level availability commitment or related remedies contained within your agreement with New Relic are vacated and nullified, and New Relic will use commercially reasonable efforts to make New Relic Full Stack Observability Standard and Telemetry Data Platform available in line with industry standards. New Relic One Pro and Enterprise Support Plans With a subscription to New Relic One Users (Full Stack Observability), New Relic provides an updated support plan commitment. By subscribing to New Relic One Users (Full Stack Observability), you agree that during the Commitment Term the applicable Support Plan set forth on the Support plan page in the Documentation shall apply in lieu of, and supersedes and replaces, any other support related commitments that may be contained within your agreement with New Relic. For New Relic K.K. customers (Japan), the above does not currently apply to the support offerings provided by New Relic to you. Free tier, lite, no-charge, preview access, New Relic One - Data, New Relic One - Standard User subscriptions If you are using New Relics Products in the free tier only, or on a no-charge, or a lite or preview access basis you agree that the Unpaid Terms of Service will apply to such Product usage and replace and supersede any other terms. In addition, if your subscription contains the New Relic One - Standard User (Full Stack Observability Standard) Product, you agree that the Paid Terms of Service will apply to your subscription to the Products set forth in an Order and replace and supersede any other terms.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 188.46727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>Usage</em> <em>plan</em> descriptions",
        "sections": "New Relic One <em>Usage</em> <em>plan</em> descriptions",
        "tags": "<em>License</em> <em>information</em>",
        "body": "The <em>Usage</em> <em>Plan</em> applies to (i) your Pay As You Go subscription, or (ii) your Commitment Term for the Annual Pool of Funds subscription. New Relic may modify the <em>Usage</em> <em>Plan</em> from time to time. Any changes to the <em>Usage</em> <em>Plan</em> will become effective immediately for changes that provide a benefit or right"
      },
      "id": "6044e74ee7b9d2a4515799c8"
    },
    {
      "sections": [
        "New Relic One pricing: Definitions",
        "Account",
        "Commitment Term",
        "Customer Data",
        "Customer Properties",
        "Documentation",
        "GB Ingested",
        "Incident event",
        "Login Credentials",
        "Monthly Provisioned User",
        "Order",
        "Paid Terms of Service",
        "Product(s)",
        "Software",
        "Terms",
        "Third-Party Services",
        "Unpaid Terms of Service",
        "Usage Plan"
      ],
      "title": "New Relic One pricing: Definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "609575acd671fecf7899378157eabc57bc8d68e2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/new-relic-one-pricing-definitions/",
      "published_at": "2021-06-15T12:11:12Z",
      "updated_at": "2021-05-22T17:25:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our New Relic One pricing plan (for a glossary for our original pricing, see Original pricing definitions. Account Account refers to the online account or subaccounts that New Relic provides for customers to manage their use of the Products. Commitment Term Commitment Term means the non-cancelable, committed Subscription Term for the Products. Customer Data Customer Data means the data, information, or content that Customer and its users send to an Account from the Software, the Customer Properties, or Third-Party Services. Customer Properties Customer Properties means Customers websites, infrastructure, networks, mobile applications, or other systems, as well as Customer accounts on Third-Party Services. Documentation Documentation means the New Relic technical guides and documentation made available from the dedicated Documentation page of the New Relic website. GB Ingested A GB Ingested is a measurement of the volume of metrics, events, logs, traces, or other telemetry data sent to or generated by the Products for the benefit of the Customer, including from the Software, the Customer Properties, or Third-Party Services. In this context, a GB is defined as 1 billion bytes. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Login Credentials Login Credentials means the username, email address, password, or other personal information that is provided by a Customer user in order to manage an Account. Monthly Provisioned User A Monthly Provisioned User is any user who can log into Customers Account(s) and access the New Relic One Product functionality as specified in an Order and the Documentation. In our public docs, this is referred to as a full user. Order Order means the purchasing order for access to the Service or related services that: (1) is either executed by the Parties or entered into by you via self-service, and references this Agreement, or (2) is entered into by you and a Channel Partner. Paid Terms of Service Paid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/paid. Product(s) Product(s) mean the purchase of the New Relic subscription products described in the applicable Order and any updates, corrections, bug fixes, modifications, improvements, related services, new features, and functionality (made generally available to New Relics customer base) thereto. Software Software means the distributed software, APIs, scripts, or other code proprietary to New Relic provided with the Products. Terms Terms means the underlying Customer-New Relic agreement and the Order. Third-Party Services Third-Party Services means any third party platform, add-on, service, or product not provided by New Relic and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https://newrelic.com/termsandconditions/unpaid. Usage Plan Usage Plan refers to the Service or Product pricing, invoicing related information, and product-specific terms (e.g. concurrent user account sessions) contained within the Documentation. To learn more about this pricing plan, see New Relic One pricing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.80524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Usage</em> <em>Plan</em>",
        "tags": "<em>License</em> <em>information</em>",
        "body": " and that a user integrates or enables for use with the Products, including third-party applications and plug-ins. Unpaid Terms of Service Unpaid Terms of Service means the legal terms and conditions located at: https:&#x2F;&#x2F;newrelic.com&#x2F;termsandconditions&#x2F;unpaid. <em>Usage</em> <em>Plan</em> <em>Usage</em> <em>Plan</em> refers to the Service or Product"
      },
      "id": "6044e6e528ccbc26f22c6084"
    },
    {
      "sections": [
        "Original product-based pricing definitions",
        "App",
        "App transaction",
        "AWS Lambda event",
        "Check",
        "Compute unit",
        "Datapoints per minute",
        "Event",
        "Host",
        "Incident event",
        "Page view",
        "Per GB daily",
        "Span",
        "User"
      ],
      "title": "Original product-based pricing definitions",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Product definitions"
      ],
      "external_id": "42087e53167736831855bf9a4c2967c465677b45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/product-definitions/legacy-product-definitions/",
      "published_at": "2021-06-15T12:10:22Z",
      "updated_at": "2021-05-22T17:24:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing plan terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app includes a predefined number of users. App transaction An app transaction is an APM application's attempt to process a web or non-web request. In APM these manifest as throughput TIMESERIES or individually as events in the Transaction event type. AWS Lambda event An AWS Lambda event means the row of data collected from the customer's AWS Lambda function by the New Relic agent or sent from an external service into the New Relic platform. It consists of the AwsLambdaInvocation, AwsLambdaInvocationError, or custom event types. Check A check means the single instance of a Synthetics monitor running in New Relic's monitoring network and reporting back response time, and whether the check was a success or failure. Compute unit A compute unit means the measure of resources associated with a unit of computation on a physical or virtual host. Datapoints per minute Datapoints per minute (DPM) refers to the per-minute rate at which individual metric values are sent to the New Relic Metric Ingest API. For billing purposes, datapoints per minute are calculated as a monthly average value by summing the datapoints ingested during a 30 day period and dividing by the number of minutes in that period (43,200). Event An event means the row of data collected from the customer's application by the New Relic agent or sent from an external service into the Insights event database. Host A host means the physical computer or virtual machine instance running a single copy of an operating system. Host usage is tracked monthly by summing the hours that every host in the account is connected to New Relic and dividing by 750. A host is counted if it is connected any time during an hour. Incident event An incident event is an alerting event (open, closed, etc.) created by an alerting engine that is sent into the New Relic Applied Intelligence platform (non-unique) for de-duplication, flapping detection, smart suppression, enrichment, and correlation. Page view A page view means the full page load (triggering an onLoad event) or a recorded URL change (state change). Per GB daily Per GB daily represents a daily average of Log data sent to New Relic over a 30 day period. Span A span represents an operation summary collected from the customer's application via the New Relic APM agent or New Relic Serverless for AWS Lambda agent, or sent from other tracing tools to the New Relic Trace API. User A user means the individual that connects to your app from a single device. Each unique device is considered as a unique user.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 122.80455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>License</em> <em>information</em>",
        "body": "This is a glossary of terms that appear in contracts for our original product-based pricing. For New Relic One pricing <em>plan</em> terms, see New Relic One pricing definitions. App An app means the application software designed to run on smartphones, tablet computers, and other mobile devices. Each app"
      },
      "id": "603ebacc64441f77774e8872"
    }
  ],
  "/docs/licenses/product-or-service-licenses/miscellaneous/help-center-documentation-licenses": [
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-06-15T12:19:16Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0  2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0  2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0  2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0  2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0  2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright  2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright  2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright  1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright  1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.33154,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    },
    {
      "sections": [
        "New Relic APM licenses"
      ],
      "title": "New Relic APM licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic APM"
      ],
      "external_id": "e08100d5a48d87c7769f401957826f627bf29779",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm/new-relic-apm-licenses/",
      "published_at": "2021-06-15T13:34:45Z",
      "updated_at": "2021-03-30T21:22:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view licenses for... See... APM agents docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-apm",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.08221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic APM <em>licenses</em>",
        "sections": "New Relic APM <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We use many third-party libraries and tools to create New Relic APM, including a large number contributed by the open source community. To view <em>licenses</em> for... See... APM agents docs.newrelic.com&#x2F;docs&#x2F;<em>licenses</em>&#x2F;<em>product</em>-or-<em>service</em>-<em>licenses</em>&#x2F;new-relic-apm"
      },
      "id": "603e7895e7b9d24e832a07d5"
    },
    {
      "sections": [
        "New Relic Insights licenses"
      ],
      "title": "New Relic Insights licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Insights"
      ],
      "external_id": "3d0f8f4275af8bcf9f6f3ffb02a2e46ff3fc374f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-insights/new-relic-insights-licenses/",
      "published_at": "2021-06-15T12:19:16Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Product Licenses New Relic Insights See insights.newrelic.com/licenses",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.63113,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Insights <em>licenses</em>",
        "sections": "New Relic Insights <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in New Relic Insights. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. <em>Product</em> <em>Licenses</em> New Relic Insights See insights.newrelic.com&#x2F;<em>licenses</em>"
      },
      "id": "6044e84428ccbcf6fa2c60c1"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses": [
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-06-15T12:13:55Z",
      "updated_at": "2021-05-05T16:26:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright  2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright  2010, Ajax.org B.V. ActiveLabel MIT Copyright  2015 Optonaut Alamofire MIT Copyright  2014-2018 Alamofire Software Foundation AlamofireObjectMapper MIT Copyright  2015 Tristan Himmelman Analytics MIT Copyright  2016 Segment.io, Inc. BBlock MIT Copyright  2012 David Keegan BigNumber MIT Copyright  2019 mkrd CDMarkdownKit MIT Copyright  2016-2017 Christopher de Haan contact@christopherdehaan.me ECSlidingViewController MIT Copyright  2013 EdgeCase LoginManagerSDK New Relic License Copyright  2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright  GitHub, Inc. All rights reserved. Copyright  2012, Bitswift, Inc MetricMetadata New Relic License Copyright  2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright  2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright  2016 Vinh Nguyen NewRelicAgent New Relic License Copyright  2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright  2014 Hearst RadarKit New Relic License  2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright  2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright  2011 kishikawa katsumi WidgetLibrary New Relic License  2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright  2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright  2016 JP Simard. jsTimezoneDetect MIT Copyright  2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright  JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.41737,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS <em>application</em> <em>licenses</em>",
        "sections": "iOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic iOS <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-06-15T12:13:56Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright  2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright  2016 Segment.io, Inc. CDMarkdownKit MIT Copyright  2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License  2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright  GitHub, Inc. All rights reserved. Copyright  2012, Bitswift, Inc MetricMetadata New Relic License  2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License  2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright  2016 Vinh Nguyen NewRelicAgent New Relic License  2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright  2011 kishikawa katsumi WidgetLibrary New Relic License  2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright  2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright  2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright  2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.41736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-06-15T12:19:16Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0  2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0  2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0  2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0  2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0  2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright  2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright  2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright  1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright  1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.18347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ],
  "/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses": [
    {
      "sections": [
        "Android application licenses"
      ],
      "title": "Android application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "68c9bdc9dec6f02240f002494309519e41619f29",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/android-application-licenses/",
      "published_at": "2021-06-15T12:13:56Z",
      "updated_at": "2021-05-05T16:29:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Android app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Third Party Dependencies License Copyright Android-FlowLayout Apache 2.0 Copyright  2011, Artem Votincev (apmem.org) AVLoadingIndicatorView Apache 2.0 Copyright  2015, Jack Wang BottomNavigationViewEx MIT Copyright  2017, ittianyu Butterknife Apache 2.0 Copyright  2013, Jake Wharton Crouton Apache 2.0 Copyright  2012 - 2014, Benjamin Weiss CWAC-SafeRoom Apache 2.0 The copyrights are owned by CommonsWare for things unique to this library and a combination of CommonsWare and the Android Open Source Project for code modified from the Architecture Components' Framework* set of classes. Dagger 2 Apache 2.0 Copyright  2012, The Dagger Authors Dragtop Layout Apache 2.0 Copyright  2015, chenupt EventBus Apache 2.0 Copyright  2012-2017 Markus Junginger, greenrobot FlexibleAdapter Apache 2.0 Copyright  2015-2018 Davide Steduto, Davidea Solutions Sprl Gson Apache 2.0 Copyright  2008, Google Inc. markwon Apache 2.0 Copyright  2019 Dimitry Ivanov (legal@noties.io) mockk Apache 2.0 Copyright  [ 2017] [ github.com/mockk] leakcanary Apache 2.0 Copyright  2015 Square, Inc. mockito mockito MIT Copyright  2007 Mockito contributors mosby Apache 2.0 Copyright  2015 Hannes Dorfmann moshi Apache 2.0 Copyright  2015 Square, Inc. MPAndroidChart Apache 2.0 Copyright  2019 Philipp Jahoda New Relic Mobile Agent OKHttp Apache 2.0 Copyright  2019 Square, Inc. okio Apache 2.0 Copyright  2013 Square, Inc. Picasso Apache 2.0 Copyright  2013 Square, Inc. RESTMock Apache 2.0 Copyright  2016 Appflate.io Retrofit Apache 2.0 Copyright  2013 Square, Inc. RxJava Apache 2.0 Copyright  2016-present, RxJava Contributors. Segment IO MIT Copyright  2016 Segment, Inc. Snackyaml Apache 2.0 Copyright  2008, www.snakeyaml.org. StickyHeaders Apache 2.0 Copyright  2014 Emil Sjlander TableView Apache 2.0 Copyright  2017 Evren Cokun Transitions-Everywhere Apache 2.0 The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.4186,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>application</em> <em>licenses</em>",
        "sections": "Android <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Android <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Third Party Dependencies"
      },
      "id": "603e9e30196a67b71fa83d96"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-06-15T12:13:56Z",
      "updated_at": "2021-05-05T16:26:53Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright  2011-2020 Alamofire Software Foundation (http://alamofire.org/) Analytics MIT Copyright  2016 Segment.io, Inc. CDMarkdownKit MIT Copyright  2016-2017 Christopher de Haan contact@christopherdehaan.me LoginManagerSDK New Relic License  2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright  GitHub, Inc. All rights reserved. Copyright  2012, Bitswift, Inc MetricMetadata New Relic License  2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License  2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright  2016 Vinh Nguyen NewRelicAgent New Relic License  2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright  2011 kishikawa katsumi WidgetLibrary New Relic License  2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright  2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright  2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright  2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.41736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS <em>application</em> <em>licenses</em>",
        "sections": "tvOS <em>application</em> <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic for TV <em>app</em>. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Logs plugin licenses",
        "Plugins for Logs",
        "AWS CloudWatch",
        "Fluentd",
        "Fluent Bit",
        "Kubernetes",
        "Logstash",
        "Go plugins for Logs",
        "Logrus 1.4.0",
        "Java plugins for Logs",
        "Apache Log4j 1.x",
        "Apache Log4j 2.x",
        "Dropwizard 1.3",
        "Logback 1.2"
      ],
      "title": "Logs plugin licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic Logs"
      ],
      "external_id": "994019d539d8db05675ae7b7e6e48caba02bdd45",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-logs/logs-plugin-licenses/",
      "published_at": "2021-06-15T12:19:16Z",
      "updated_at": "2021-05-05T16:28:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. For a list of the licenses used for New Relic Logs, see Logs licenses. Plugins for Logs The following licenses are for the plugins used to connects your log data with New Relic Logs. AWS CloudWatch Library License Copyright AWS CloudWatch Apache License 2.0  2019 New Relic, Inc. Fluentd Library License Copyright Fluentd Apache License 2.0  2019 New Relic, Inc. Fluent Bit Library License Copyright Fluent Bit Apache License 2.0  2019 New Relic, Inc. Kubernetes Library License Copyright Kubernetes Apache License 2.0  2019 New Relic, Inc. Logstash Library License Copyright Logstash Apache License 2.0  2019 New Relic, Inc. Go plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Go agent. For Go licenses, see Go agent licenses. Logrus 1.4.0 Library License Copyright Logrus MIT Copyright  2014 Simon Eskildsen Java plugins for Logs The following licenses are for the plugins used link your logs and APM data using New Relic's Java agent. For Java licenses, see Java agent licenses. Apache Log4j 1.x Library License Copyright Apache Log4j 1 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Apache Log4j 2.x Library License Copyright Apache Log4j 2 Apache License 2.0 Copyright  1999-2005 The Apache Software Foundation Dropwizard 1.3 Library License Copyright Dropwizard Apache License 2.0 Copyright  2010-2013 Coda Hale and Yammer, Inc., 2014-2016 Dropwizard Team Logback 1.2 Library License Copyright Logback EPL v1.0 Copyright  1999-2017, QOS.ch. All rights reserved. Logback LGPL 2.1 Copyright  1999-2017, QOS.ch. All rights reserved. The remainder of the code is covered by the New Relic license agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.18347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Logs plugin <em>licenses</em>",
        "sections": "Logs plugin <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the New Relic Logs plugins. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. For a list of the <em>licenses</em>"
      },
      "id": "603ea5b628ccbcc9c6eba76d"
    }
  ]
}