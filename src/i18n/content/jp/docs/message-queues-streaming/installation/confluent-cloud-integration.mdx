---
title: Confluent クラウド統合
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

New Relic [Confluent Cloud で管理されるApache Kafka データのストリーミングを](https://www.confluent.io/confluent-cloud/)収集するための統合を提供します。 このドキュメントでは、この統合を有効にする方法と、レポートできるデータについて説明します。

## 前提条件

* New Relicアカウント
* 有効な Confluent Cloud アカウント
* Confluent Cloud APIキーとシークレット
* `MetricsViewer` Confluent Cloudアカウントへのアクセス

## 統合をアクティブ化する [#activate]

この統合を有効にするには、 <DNT>**Integrations &amp; Agents**</DNT>に移動し、 <DNT>**Confluent Cloud -&gt; API Polling**</DNT>選択して指示に従います。

<Callout variant="important">
  IP フィルタリングが設定されている場合は、次の IP アドレスをフィルタに追加します。

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  クラウドインテグレーションのNew Relic IP 範囲の詳細については、[このドキュメント](/docs/new-relic-solutions/get-started/networks/#webhooks)を参照してください。 このタスクを実行する手順については、 [このドキュメント](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html)を参照してください。
</Callout>

## 構成とポーリング [#polling]

Confluent Cloud Kafka 統合のデフォルトのポーリング情報:

* New Relicのポーリング間隔：5分
* Confluent Cloud データ間隔: 1 分

ポーリング頻度は初期設定時にのみ変更できます。

## データの表示と使用 [#find-data]

次の[ イベント](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels) [タイプ を使用して、 データをクエリおよび探索](/docs/using-new-relic/data/understand-data/query-new-relic-data) できます。

<table>
  <thead>
    <tr>
      <th>
        エンティティ
      </th>

      <th>
        データ型
      </th>

      <th>
        プロバイダー
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        クラスタ
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

データの使用方法の詳細[については、統合データの理解と使用](/docs/infrastructure/integrations/find-use-infrastructure-integration-data)を参照してください。

## メトリックデータ [#metrics]

この統合は、クラスタ、パーティション、トピックエンティティの Amazon Managed Kafka データを記録します。

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        メトリック
      </th>

      <th style={{ width: "150px" }}>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        パーセント
      </td>

      <td>
        クラスターの使用率の尺度。 値は 0.0 ～ 1.0 の範囲です。 このメトリクスデータを持っているのは専用のティアクラスタだけです。
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        パーセント
      </td>

      <td>
        入力スループットによって発生したホット パーティションの存在を示すインジケーター。 ホット パーティションが検出された場合は値は 1.0 になり、ホット パーティションが検出されなかった場合は空になります。
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        パーセント
      </td>

      <td>
        出力スループットによって発生したホット パーティションの存在を示すインジケーター。 ホット パーティションが検出された場合は値は 1.0 になり、ホット パーティションが検出されなかった場合は空になります。
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワーク経由で送信された指定されたリクエスト タイプからの合計リクエスト バイトのデルタ カウント。 各サンプルは、前のデータ ポイント以降に送信されたバイト数です。 カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワーク経由で送信された指定された応答タイプからの合計応答バイトのデルタカウント。 各サンプルは、前のデータ ポイント以降に送信されたバイト数です。 カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワークから受信した顧客データのバイト数の差分。各サンプルは、前のデータ サンプル以降に受信したバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワーク経由で送信された顧客データのバイト数の差分。各サンプルは、前のデータ ポイント以降に送信されたバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Count
      </td>

      <td>
        受信したレコードのデルタ カウント。各サンプルは、前のデータ サンプル以降に受信したレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Count
      </td>

      <td>
        送信されたレコードのデルタ カウント。各サンプルは、前のデータ ポイント以降に送信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Count
      </td>

      <td>
        パーティションの数。
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        グループ メンバーのコミットされたオフセットとパーティションの最高水準点の間のラグ。
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Count
      </td>

      <td>
        成功した認証のデルタ カウント。各サンプルは、前のデータ ポイント以降の成功した認証の数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Count
      </td>

      <td>
        アクティブな認証済み接続の数。
      </td>
    </tr>
  </tbody>
</table>

## 次のステップ

<DocTiles>
  <DocTile title="Data and UI" path="/docs/message-queues-streaming/ui-data/understand-ui">New Relicを使用して Kafka クラスタを監視する方法を学ぶ</DocTile>
</DocTiles>