---
title: Confluent クラウド統合
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

New Relic [Confluent Cloud で管理されるApache Kafka データのストリーミングを](https://www.confluent.io/confluent-cloud/)収集するための統合を提供します。 このドキュメントでは、この統合を有効にする方法と、レポートできるデータについて説明します。

## 前提条件

* New Relicアカウント
* 有効な Confluent Cloud アカウント
* Confluent Cloud APIキーとシークレット
* `MetricsViewer` Confluent Cloudアカウントへのアクセス

## 統合をアクティブ化する [#activate]

この統合を有効にするには、 <DNT>**Integrations &amp; Agents**</DNT>に移動し、 <DNT>**Confluent Cloud -&gt; API Polling**</DNT>選択して指示に従います。

<Callout variant="important">
  IP フィルタリングが設定されている場合は、次の IP アドレスをフィルタに追加します。

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  クラウドインテグレーションのNew Relic IP 範囲の詳細については、[このドキュメント](/docs/new-relic-solutions/get-started/networks/#webhooks)を参照してください。 このタスクを実行する手順については、 [このドキュメント](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html)を参照してください。
</Callout>

## 構成とポーリング [#polling]

Confluent Cloud Kafka 統合のデフォルトのポーリング情報:

* New Relicのポーリング間隔：5分
* Confluent Cloud データ間隔: 1 分

ポーリング頻度は初期設定時にのみ変更できます。

## データの表示と使用 [#find-data]

次の[ イベント](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels) [タイプ を使用して、 データをクエリおよび探索](/docs/using-new-relic/data/understand-data/query-new-relic-data) できます。

<table>
  <thead>
    <tr>
      <th>
        エンティティ
      </th>

      <th>
        データ型
      </th>

      <th>
        プロバイダー
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        クラスタ
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        コネクタ
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        ksql
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

データの使用方法の詳細[については、統合データの理解と使用](/docs/infrastructure/integrations/find-use-infrastructure-integration-data)を参照してください。

## メトリックデータ [#metrics]

この統合は、クラスタ、コネクタ、ksql の Confluent cloud Kafka データを記録します。

### クラスターデータ

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        メトリック
      </th>

      <th style={{ width: "150px" }}>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        パーセント
      </td>

      <td>
        クラスターの使用率の尺度。 値は 0.0 ～ 1.0 の範囲です。 このメトリクスデータを持っているのは専用のティアクラスタだけです。
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        パーセント
      </td>

      <td>
        入力スループットによって発生したホット パーティションの存在を示すインジケーター。 ホット パーティションが検出された場合は値は 1.0 になり、ホット パーティションが検出されなかった場合は空になります。
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        パーセント
      </td>

      <td>
        出力スループットによって発生したホット パーティションの存在を示すインジケーター。 ホット パーティションが検出された場合は値は 1.0 になり、ホット パーティションが検出されなかった場合は空になります。
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワーク経由で送信された指定されたリクエスト タイプからの合計リクエスト バイトのデルタ カウント。 各サンプルは、前のデータ ポイント以降に送信されたバイト数です。 カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワーク経由で送信された指定された応答タイプからの合計応答バイトのデルタカウント。 各サンプルは、前のデータ ポイント以降に送信されたバイト数です。 カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワークから受信した顧客データのバイト数の差分。各サンプルは、前のデータ サンプル以降に受信したバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        ネットワーク経由で送信された顧客データのバイト数の差分。各サンプルは、前のデータ ポイント以降に送信されたバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Count
      </td>

      <td>
        受信したレコードのデルタ カウント。各サンプルは、前のデータ サンプル以降に受信したレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Count
      </td>

      <td>
        送信されたレコードのデルタ カウント。各サンプルは、前のデータ ポイント以降に送信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Count
      </td>

      <td>
        パーティションの数。
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        グループ メンバーのコミットされたオフセットとパーティションの最高水準点の間のラグ。
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Count
      </td>

      <td>
        成功した認証のデルタ カウント。各サンプルは、前のデータ ポイント以降の成功した認証の数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Count
      </td>

      <td>
        アクティブな認証済み接続の数。
      </td>
    </tr>
  </tbody>
</table>

### コネクタデータ

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        メトリック
      </th>

      <th style={{ width: "150px" }}>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Count
      </td>

      <td>
        変換から送信され、ソース コネクタの Kafka に書き込まれたレコードの合計数のデルタ カウント。各サンプルは、前のデータ ポイント以降に送信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `connector_status`
      </td>

      <td>
        少し
      </td>

      <td>
        システム内のコネクタのステータス。その値は常に 1 に設定され、コネクタが存在することを示します。コネクタの現在の動作状態は、Metriks.status タグを通じて識別されます。
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_status`
      </td>

      <td>
        少し
      </td>

      <td>
        システム内のコネクタのタスクのステータス。その値は常に 1 に設定され、コネクタ タスクの存在を示します。コネクタの現在の動作状態は、Metriks.status タグを通じて識別されます。
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_avg`
      </td>

      <td>
        Count
      </td>

      <td>
        1 分あたりの平均バッチ サイズ (レコード数で測定)。ソース コネクタの場合、Kafka に送信される平均バッチ サイズを示します。シンク コネクタの場合、シンク タスクによって読み取られる平均バッチ サイズを示します。
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_max`
      </td>

      <td>
        Count
      </td>

      <td>
        1 分あたりの最大バッチ サイズ (レコード数で測定)。ソース コネクタの場合、Kafka に送信される最大バッチ サイズを示します。シンク コネクタの場合、シンク タスクによって読み取られる最大バッチ サイズを示します。
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Count
      </td>

      <td>
        シンク コネクタによって受信されたレコードの合計数のデルタ カウント。各サンプルは、前のデータ ポイント以降に受信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        シンク コネクタによって受信されたレコードの合計数のデルタ カウント。各サンプルは、前のデータ ポイント以降に受信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        シンク コネクタによって受信された合計バイト数のデルタ カウント。各サンプルは、前のデータ ポイント以降に受信したバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        `dead_letter_queue_records`
      </td>

      <td>
        Count
      </td>

      <td>
        シンク コネクタの Kafka に書き込まれたデッドレター キュー レコードのデルタ数。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>
  </tbody>
</table>

### ksqlデータ

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        メトリック
      </th>

      <th style={{ width: "150px" }}>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `streaming_unit_count`
      </td>

      <td>
        Count
      </td>

      <td>
        この KSQL インスタンスの Confluent Streaming Units (CSU) の数。カウントは 60 秒ごとにサンプリングされます。このメトリクスの暗黙的な時間集計は MAX です。
      </td>
    </tr>

    <tr>
      <td>
        `query_saturation`
      </td>

      <td>
        パーセント
      </td>

      <td>
        すべてのノードにわたる特定の ksqlDB クエリの最大飽和度。0 から 1 の間の値を返します。1 に近い値は、ksqlDB クエリ処理が利用可能なリソースでボトルネックになっていることを示します。
      </td>
    </tr>

    <tr>
      <td>
        `task_stored_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        特定のタスクの状態のサイズはバイト単位で保存されます。
      </td>
    </tr>

    <tr>
      <td>
        `storage_utilization`
      </td>

      <td>
        パーセント
      </td>

      <td>
        特定の ksqlDB アプリケーションの合計ストレージ使用率。
      </td>
    </tr>

    <tr>
      <td>
        `consumed_total_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        要求された期間中に継続的なクエリによって Kafka から消費されたバイトの差分カウント。
      </td>
    </tr>

    <tr>
      <td>
        `produced_total_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        要求された期間中に継続的なクエリによって Kafka に生成されたバイトの差分数。
      </td>
    </tr>

    <tr>
      <td>
        `offsets_processed_total`
      </td>

      <td>
        Count
      </td>

      <td>
        特定のクエリ、タスク、トピック、またはオフセットによって処理されたオフセットのデルタ数。
      </td>
    </tr>

    <tr>
      <td>
        `committed_offset_lag`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        特定のクエリ、タスク、トピック、またはオフセットのコミットされたオフセットと終了オフセット間の現在の遅延。
      </td>
    </tr>

    <tr>
      <td>
        `processing_errors_total`
      </td>

      <td>
        Count
      </td>

      <td>
        要求された期間におけるクエリのレコード処理エラーの数のデルタカウント。
      </td>
    </tr>

    <tr>
      <td>
        `query_restarts`
      </td>

      <td>
        Count
      </td>

      <td>
        要求された期間中にクエリの再開を引き起こす失敗の数のデルタカウント。
      </td>
    </tr>
  </tbody>
</table>

## 次のステップ

<DocTiles>
  <DocTile title="データとUI" path="/docs/message-queues-streaming/ui-data/understand-ui">
    New Relicを使用して Kafka クラスタを監視する方法を学ぶ
  </DocTile>
</DocTiles>