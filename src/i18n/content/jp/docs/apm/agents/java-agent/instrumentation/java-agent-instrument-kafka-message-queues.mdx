---
title: Javaエージェントです。Kafkaメッセージキューの計測
tags:
  - Agents
  - Java agent
  - Instrumentation
metaDescription: 'New Relic for Java includes built-in Kafka monitoring, as well as advanced event and distributed tracing data collection.'
translationType: machine
---

New Relic Java エージェントは、 [Kafka](https://kafka.apache.org/documentation/)'s Java clients library からデータを自動的に収集します。Kafka は大量のデータを生成する高性能なメッセージングシステムであるため、アプリの特定のスループットやユースケースに合わせてエージェントをカスタマイズすることができます。

このドキュメントでは、3種類のKafkaデータを収集して表示する方法を説明しています。

* [Kafkaメトリクス](#view-kafka-metrics)
* [Kafkaイベント](#collect-kafka-events)
* [Kafkaの分散型トレース](#collect-kafka-distributed-traces)

Kafka のインスツルメンテーションは、Java エージェントのバージョン 4.12.0 以降で利用できます。サポートされているKafkaクライアントのバージョンについては、 [Javaの互換性と要件](/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent) を参照してください。

<Callout variant="tip">
  Kafkaインテグレーションについては、 [Kafkaモニタリングインテグレーション](/docs/integrations/host-integrations/host-integrations-list/kafka-monitoring-integration) を参照してください。
</Callout>

## Kafkaメトリクスの表示

[インストール後](/docs/agents/java-agent/installation/install-java-agent) 、エージェントは、メッセージングレート、レイテンシー、ラグなどの情報を含むリッチなKafkaメトリクスを自動的にレポートします。Javaエージェントは、 [Kafkaのコンシューマーおよびプロデューサーのすべてのメトリクス](https://kafka.apache.org/documentation/#monitoring) を収集します（ただし、コネクトおよびストリームのメトリクスは収集しません）。

これらのメトリクスを表示するには、カスタムダッシュボードを作成します。

1. [New Relic metric explorer](/docs/insights/use-insights-ui/explore-data/metric-explorer-search-chart-metrics-sent-new-relic-agents) にアクセスします。

2. メトリクスエクスプローラーを使って、メトリクスを探します。Kafkaのメトリクスは、このmetricフォルダにあります。

   ```
   MessageBroker/Kafka/Internal/KafkaMetricName
   ```

   たとえば、 `request-rate`メトリックは次の場所にあります。

   ```
   MessageBroker/Kafka/Internal/consumer-metrics/request-rate
   ```

   <Callout variant="tip">
     Kafkaのコンシューマーとプロデューサーのメトリクスの全リストについては、 [Kafka documentation](https://kafka.apache.org/documentation/#monitoring) を参照してください。
   </Callout>

3. **Add to dashboard** をクリックして、モニターしたいメトリクスをダッシュボードに追加します。

## Kafkaイベントコレクションの有効化 [#collect-kafka-events]

メトリックのタイムスライスデータではなく、イベントデータを収集するようにエージェントを構成することができます（メトリックのタイムスライスとイベントデータの違いについては、 [データ収集](/docs/using-new-relic/metrics/analyze-your-metrics/data-collection-metric-timeslice-event-data#overview) ）。これにより、 [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) を使用して、デフォルトの Kafka メトリクスをフィルタリングおよびファセットすることができます。有効にすると、エージェントは 30 秒ごとに 1 つの Kafka イベントを収集します。このイベントには、 [Kafka コンシューマーからのすべてのデータと、前回のイベント以降に取得したプロダク トメトリクス](https://kafka.apache.org/documentation/#monitoring) が含まれます。

<Callout variant="important">
  エージェントは[収集サイクル](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#harvest-cycle)ごとに最大 2000 のイベントを記録しますが、この値は[`max_samples_stored`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored)で変更できます。Kafka イベント データは、このプールに含まれています。`recordCustomEvent()` API 呼び出しを使用して[カスタム イベント](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents)を New Relic に送信し、2000 を超えるイベントを送信すると、エージェントは一部の Kafka またはカスタム イベントを破棄します。
</Callout>

Kafkaのイベント収集を有効にするには

1. `kafka.metrics.as_events.enabled`要素を`newrelic.yml`構成ファイルに追加します。

   ```
   kafka.metrics.as_events.enabled: true
   ```

2. JVMを再起動します。

3. [イベント エクスプローラー](/docs/insights/use-insights-ui/explore-data/event-explorer-query-chart-your-event-data)を使用して、 `KafkaMetrics`イベント タイプにある Kafka イベントを表示します。または、 [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql)を使用してイベントを直接クエリします。例えば：

   ```
   SELECT average('producer-metrics.record-send-rate') from KafkaMetrics SINCE 30 minutes ago timeseries
   ```

## Kafkaの分散型トレースの有効化 [#collect-kafka-distributed-traces]

Java エージェントは、Kafka クライアントから [分散型トレース](/docs/apm/distributed-tracing/getting-started/introduction-distributed-tracing) を収集することもできます。トレースを有効にしても、エージェントの通常の動作には影響しません。Kafkaからのメトリックデータやイベントデータの報告は継続されます。

実現する前に考慮すべき影響と要件

* **インスツルメンテーションは、メッセージヘッダーに150～200バイトのペイロードを追加します。** Kafkaメッセージが非常に小さい場合、トレースは大きな処理およびストレージのオーバーヘッドを追加します。このペイロードサイズの追加により、Kafkaのメッセージサイズ制限を超えると、Kafkaがメッセージをドロップする可能性があります。このため、本番環境で有効にする前に、開発環境でKafka分散トレースをテストすることをお勧めします。
* 分散トレーシングは、Kafkaクライアントのバージョン0.11.0.0以降でのみ利用可能です。
* **以前にアプリで** distributed tracing を有効にしていない場合は、有効にする前に [Transition guide](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) をお読みください。
* Kafkaメッセージヘッダーを介してW3Cトレースコンテキストを伝播するには、Java agent 6.4.0でリリースされたAPIの詳細について、 [distributed tracing API usage guide](/docs/agents/java-agent/api-guides/guide-using-java-agent-api#trace-calls) を参照してください。なお、Kafkaメッセージに追加のヘッダを追加すると、ペイロードサイズがさらに大きくなります。これらのAPIの動作を確認するには、 [Using Java agent trace APIs with Kafka](https://github.com/newrelic/newrelic-java-examples/tree/main/newrelic-java-agent/distributed-tracing/kafka-examples) を参照してください。

この機能を有効にするための完全なプロセスは以下のとおりですが、大まかには以下のような基本的なステップがあります。1) エージェントの設定でトレースを有効にする。2) [Java エージェント API](/docs/agents/java-agent/api-guides/guide-using-java-agent-api) を呼び出して、プロデューサ側とコンシューマ側の両方のトランザクションを計測する。

Kafkaから分散型トレースを収集する。

<CollapserGroup>
  <Collapser
    id="enable-dt-kafka"
    title="1.設定ファイルで分散型トレーシングを有効にする"
  >
    以前にアプリでdistributed tracingを有効にしていない場合は、有効にする前に [distributed tracing transition guide](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) をお読みください。

    Kafka 分散トレースを有効にするには、 [`newrelic.yml`構成ファイル](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Structure)で次の 2 つの設定を有効にする必要があります。

    * [`distributed_tracing`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#distributed-tracing)要素が有効になっていることを確認します。

      ```
      distributed_tracing:
        enabled: true
      ```

    * 以下を設定ファイルに追加して、Kafka固有の分散型トレーシング機能を有効にします。

      ```
      class_transformer:
        com.newrelic.instrumentation.kafka-clients-spans-0.11.0.0:
          enabled: true
      ```
  </Collapser>

  <Collapser
    id="instrument-kafka-producer"
    title="2.Kafkaプロデューサーのインストゥルメント"
  >
    Kafka プロデューサーを計測するには、 `Producer.send(ProducerRecord<K, V> record)`を呼び出す前にトランザクションを開始する必要があります。これを行うには、Java エージェント`@Trace(dispatcher = true)`アノテーションをメソッドに追加します。

    例えば：

    ```
    @Trace(dispatcher = true)
    public static void createAndSend(KafkaProducer<String, String> producer){
        ProducerRecord<String, String> data = new ProducerRecord<String, String>("topic", "key", "value");
        producer.send(data);
    }
    ```
  </Collapser>

  <Collapser
    id="instrument-kafka-consumer"
    title="3.Kafkaコンシューマーのインストゥルメント"
  >
    Kafka コンシューマーを計測するには、メッセージの処理中にトランザクションを開始する必要があります。エージェントは、分散トレース ペイロード ヘッダーを`newrelic`キーまたは W3C の`traceparent`および`tracestate`キーの下に保存します。ヘッダーを取得し、New Relic トランザクション API を呼び出してペイロードを受け入れます。

    例えば：

    ```
    @Trace(dispatcher = true)
    private static void processMessage(ConsumerRecord<String, String> rec) {
      // create a distributed trace headers map
      Headers dtHeaders = ConcurrentHashMapHeaders.build(HeaderType.MESSAGE);

      // Iterate through each record header and insert the trace headers into the dtHeaders map
      for (Header header : rec.headers()) {
        String headerValue = new String(header.value(), StandardCharsets.UTF_8);

        // using the newrelic key
        if (header.key().equals("newrelic")) {
          dtHeaders.addHeader("newrelic", headerValue);
        }

        // or using the W3C keys
        if (header.key().equals("traceparent")) {
          dtHeaders.addHeader("traceparent", headerValue);
        }

        if (header.key().equals("tracestate")) {
          dtHeaders.addHeader("tracestate", headerValue);
        }
      }

      // Accept distributed tracing headers to link this request to the originating request
      NewRelic.getAgent().getTransaction().acceptDistributedTraceHeaders(TransportType.Kafka, dtHeaders);
    }
    ```
  </Collapser>
</CollapserGroup>