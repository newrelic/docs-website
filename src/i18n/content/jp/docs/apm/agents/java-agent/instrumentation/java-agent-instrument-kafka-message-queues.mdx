---
title: Javaエージェントです。Kafkaメッセージキューの計測
tags:
  - Agents
  - Java agent
  - Instrumentation
metaDescription: 'New Relic for Java includes built-in Kafka monitoring, as well as advanced event and distributed tracing data collection.'
freshnessValidatedDate: never
translationType: machine
---

New Relic Java エージェントは、 [Kafka](https://kafka.apache.org/documentation/)&apos;s Java clients library からデータを自動的に収集します。Kafka は大量のデータを生成する高性能なメッセージングシステムであるため、アプリの特定のスループットやユースケースに合わせてエージェントをカスタマイズすることができます。

このドキュメントでは、次の Kafka データ タイプを収集および表示する方法について説明します。

* [Kafkaメトリクス](#view-kafka-metrics)
* [Kafkaイベント](#collect-kafka-events)
* [Kafka ストリーム トランザクション](#collect-kafka-streams-transactions)
* [Kafkaの分散型トレース](#collect-kafka-distributed-traces)

<Callout variant="tip">
  また、Kafka との統合もあります。詳細については、 [Kafka 監視統合 を](/docs/integrations/host-integrations/host-integrations-list/kafka-monitoring-integration)参照してください。
</Callout>

## 要件 [#requirements]

Kafka クライアントのインスツルメンテーションは、Java エージェント バージョン 4.12.0 以降で使用できます。Kafka ストリーム インストルメンテーションは、Java エージェント バージョン 8.1.0 で使用できます。以上。サポートされているすべての Kafka ライブラリを確認するには、 [Java の互換性と要件のページ](/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent)を確認してください。Kafka Streams は Kafka クライアント上で実行されるため、Kafka クライアントに適用されるすべてのインストルメンテーションは Streams にも適用されることに注意してください。

## Kafkaメトリクスの表示

[インストール](/docs/agents/java-agent/installation/install-java-agent)後、 Javaエージェントは、メッセージング レート、レイテンシ、ラグなどに関する情報を含む豊富な Kafka メトリクスを自動的にレポートします。 エージェントは、すべての[Kafka 消費者とプロデューサーのメトリクス](https://kafka.apache.org/documentation/#monitoring)を収集します (ただし、メトリクスの接続やストリーミングは行いません)。

これらのメトリクスを表示するには、カスタムダッシュボードを作成します。

1. [New Relic metric explorer](/docs/insights/use-insights-ui/explore-data/metric-explorer-search-chart-metrics-sent-new-relic-agents) にアクセスします。

2. メトリック エクスプローラーを使用してメトリックを見つけます。メトリクスを見つけることができるいくつかのフォルダーを次に示します。

   * Kafka メトリクス:

     ```
     MessageBroker/Kafka/Internal/KafkaMetricName
     ```

     たとえば、 `request-rate` 指標は次のようになります。

     ```
     MessageBroker/Kafka/Internal/consumer-metrics/request-rate
     ```

   * カフカストリーム:

     ```
     Kafka/Streams/KafkaStreamsMetricName
     ```

     たとえば、 `poll-latency-avg` 指標は次のようになります。

     ```
     Kafka/Streams/stream-thread-metrics/poll-latency-avg
     ```

   * カフカ接続:

     ```
     Kafka/Connect/KafkaConnectMetricName
     ```

     たとえば、 `connector-count` 指標は次のようになります。

     ```
     Kafka/Connect/connect-worker-metrics/connector-count
     ```

3. <DNT>**Add to dashboard**</DNT>をクリックして、監視するメトリックをダッシュボードに追加します。

<Callout variant="tip">
  Kafka のコンシューマー、プロデューサー、およびストリームのメトリックの完全なリストについては、 [Kafka のドキュメント を](https://kafka.apache.org/documentation/#remote_jmx)参照してください。これらのドキュメントのメトリックは、JMX を介して検索できます。ドキュメントに記載されているすべてのメトリクスが New Relic にエクスポートされるわけではないことに注意してください。これは、次のいずれかの理由による可能性があります。

  * このメトリクスは、実際には Kafka クライアントまたは Kafka ストリームによって生成されるわけではありません。これは、古いバージョンのクライアントまたはストリームを使用しているか、Kafka ライブラリの設定方法と使用方法に基づいていることが原因である可能性があります。
  * メトリックが数値でないか、その値が `NaN`です。New Relic は、数値を持つメトリクスのみを受け入れます。
</Callout>

## Kafka イベントコレクションを表示 [#collect-kafka-events]

メトリックのタイムスライスデータではなく、イベントデータを収集するようにエージェントを構成することができます（メトリックのタイムスライスとイベントデータの違いについては、 [データ収集](/docs/using-new-relic/metrics/analyze-your-metrics/data-collection-metric-timeslice-event-data#overview) ）。これにより、 [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) を使用して、デフォルトの Kafka メトリクスをフィルタリングおよびファセットすることができます。有効にすると、エージェントは 30 秒ごとに 1 つの Kafka イベントを収集します。このイベントには、 [Kafka コンシューマーからのすべてのデータと、前回のイベント以降に取得したプロダク トメトリクス](https://kafka.apache.org/documentation/#monitoring) が含まれます。

Kafka ストリームを使用している場合、エージェントは、前のイベント以降にキャプチャされた [Kafka ストリーム メトリック](https://kafka.apache.org/documentation/#remote_jmx) からのすべてのデータを含む別のイベントを生成します。イベントも 30 秒ごとに収集されます。

<Callout variant="important">
  エージェントは[収集サイクル](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#harvest-cycle)ごとに最大 2000 のイベントを記録しますが、この値は[`max_samples_stored`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored)で変更できます。Kafka イベント データは、このプールに含まれています。`recordCustomEvent()` API 呼び出しを使用して[カスタム イベント](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents)を New Relic に送信し、2000 を超えるイベントを送信すると、エージェントは一部の Kafka またはカスタム イベントを破棄します。
</Callout>

Kafkaのイベント収集を有効にするには

1. `kafka.metrics.as_events.enabled`要素を`newrelic.yml`構成ファイルに追加します。

   ```yml
   kafka.metrics.as_events.enabled: true
   ```

2. JVMを再起動します。

3. [イベント エクスプローラー](/docs/insights/use-insights-ui/explore-data/event-explorer-query-chart-your-event-data)を使用して、 `KafkaMetrics`イベント タイプにある Kafka イベントを表示します。または、 [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql)を使用してイベントを直接クエリします。例えば：

   ```sql
   SELECT average('producer-metrics.record-send-rate') FROM KafkaMetrics SINCE 30 minutes ago TIMESERIES
   ```

   Kafka ストリーム メトリクスをクエリする場合は、 `KafkaStreamsMetrics` イベント タイプを使用してストリーム固有のメトリクスにアクセスします。

<Callout variant="important">
  タイムスライス メトリックとして New Relic に送信できる Kafka メトリックの種類に関する制限は、イベントにも適用されることに注意してください。つまり、非数値および NaN メトリックはイベント属性として含まれません。
</Callout>

## Kafka ノードのメトリクスを有効にする [#kafka-node-metrics]

<Callout variant="important">
  Kafka クライアント ノード メトリクス インストゥルメンテーションは、 `kafka-clients`ライブラリ バージョン 3.7.0 ～ 3.8.x およびJavaバージョン 8.15.0 ～ 8.17.0 のユーザーにはロードされない場合があります。

  `kafka-clients` 3.7.0-3.8.x で Kafka クライアント ノード メトリクスを有効にするには、 Javaエージェントをバージョン 8.18.0 以降にアップグレードしてください。
</Callout>

Kafka メトリクスの粒度をさらに高める、Kafka クライアント用の代替インスツルメンテーション モジュールがあります。このインストルメンテーション モジュールはエージェント 8.6.0 以降で利用可能で、デフォルトでは無効になっています。

このインストルメンテーション モジュールを有効にするには、既存のインストルメンテーション モジュールを無効にし、次の内容を `newrelic.yml` 構成ファイルに追加して新しいインストルメンテーション モジュールを有効にする必要があります。

```yml
class_transformer:
  kafka-clients-metrics:
    enabled: false
  kafka-clients-node-metrics:
    enabled: true
```

## Kafka設定イベント [#kafka-config]

`kafka-clients-config` インストルメンテーション モジュールは、Kafka クライアント構成の内容を含むイベントを定期的に送信します。このモジュールはエージェント 8.6.0 以降で利用可能で、デフォルトでは無効になっています。

`kafka-clients-config` を有効にするには、以下を `newrelic.yml` 構成ファイルに追加します。

```yml
class_transformer:
  kafka-clients-config:
    enabled: true
```

## Kafka ストリーム トランザクション [#collect-kafka-streams-transactions]

Kafka Streams を使用している場合、デフォルトではトランザクションは有効になりません。これは、Kafka アプリケーションのスループットが高くなる傾向があるため、不要なオーバーヘッドを防ぐためです。

JMS トランザクションとは異なり、Kafka Streams トランザクションはレコードごとに処理されません。代わりに、Kafka コンシューマーがレコードをポーリングし、結果のデータが処理されるときにトランザクションが開始されます。

トランザクションを作成したい場合は、 `kafka-streams-spans` モジュールを有効にする必要があります:

```yml
class_transformer:
  kafka-streams-spans:
    enabled: true
```

## Kafka Connect を有効にする [#collect-kafka-connect-transactions]

Kafka Connect を使用している場合、デフォルトではトランザクションは有効になりません。Kafka アプリケーションはスループットが高い傾向があるため、これは不要なオーバーヘッドを防ぐためです。

Kafka Connect トランザクションは、シンク/ソース タスクの反復ごとに記録されます。シンク タスクの場合、トランザクションは、Kafka コンシューマーのポーリング、各メッセージの変換、およびターゲットへのデータの送信で構成されます。ソース タスクの場合、トランザクションは、ターゲットからの読み取り、データのメッセージへの変換、Kafka プロデューサによる各メッセージの送信で構成されます。

これらのトランザクションを収集したい場合は、 `kafka-connect-spans` モジュールを有効にする必要があります。

```yml
class_transformer:
  kafka-connect-spans:
    enabled: true
```

## Kafkaの分散型トレース [#collect-kafka-distributed-traces]

Java エージェントは、Kafka クライアントから [分散トレースを](/docs/apm/distributed-tracing/getting-started/introduction-distributed-tracing) 収集することもできます。Kafka Streams は Kafka クライアント上で実行されるため、分散トレースを管理する手順も適用されます。トレースを有効にしても、エージェントの通常の操作には影響しません。 Kafka からのメトリックまたはイベント データは引き続きレポートされます。

実現する前に考慮すべき影響と要件

* <DNT>**The instrumentation adds a 150 to 200 byte payload to message headers.**</DNT> Kafka メッセージが非常に小さい場合、トレースによって処理とストレージのオーバーヘッドが大幅に増加する可能性があります。 この追加のペイロード サイズにより、メッセージが Kafka メッセージング サイズの制限を超えた場合に Kafka がメッセージをドロップする可能性があります。 このため、本番環境で有効にする前に、開発環境で Kafka ディストリビューティッド（分散）トレーシングをテストすることをお勧めします。
* 分散トレーシングは、Kafkaクライアントのバージョン0.11.0.0以降でのみ利用可能です。
* **以前にアプリで** distributed tracing を有効にしていない場合は、有効にする前に [Transition guide](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) をお読みください。
* Kafkaメッセージヘッダーを介してW3Cトレースコンテキストを伝播するには、Java agent 6.4.0でリリースされたAPIの詳細について、 [distributed tracing API usage guide](/docs/agents/java-agent/api-guides/guide-using-java-agent-api#trace-calls) を参照してください。なお、Kafkaメッセージに追加のヘッダを追加すると、ペイロードサイズがさらに大きくなります。これらのAPIの動作を確認するには、 [Using Java agent trace APIs with Kafka](https://github.com/newrelic/newrelic-java-examples/tree/main/newrelic-java-agent/distributed-tracing/kafka-examples) を参照してください。
* Kafka Streams を使用している場合は、スパン インストルメンテーション モジュールを有効にする必要があります ( [Kafka Streams トランザクション セクション](#collect-kafka-streams-transactions)を参照してください)。トランザクションはレコードごとに記録されないため、分散トレース ヘッダーの受け入れは 1 つのレコードに対してのみ機能します。

これを有効にする完全なプロセスを以下に説明しますが、大まかに言えば、次の基本的な手順が含まれます。1) エージェント構成を介してトレースを有効にし、2) [Java エージェント API](/docs/agents/java-agent/api-guides/guide-using-java-agent-api) を呼び出してプロデューサー側とコンシューマー側の両方でトランザクションを計測します。

Kafkaから分散型トレースを収集する。

<CollapserGroup>
  <Collapser id="enable-dt-kafka" title="1.設定ファイルで分散型トレーシングを有効にする">
    以前にアプリでdistributed tracingを有効にしていない場合は、有効にする前に [distributed tracing transition guide](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) をお読みください。

    Kafka 分散トレースを有効にするには、 [`newrelic.yml`構成ファイル](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Structure)で次の 2 つの設定を有効にする必要があります。

    * [`distributed_tracing`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#distributed-tracing)要素が有効になっていることを確認します。

      ```yml
      distributed_tracing:
        enabled: true
      ```

    * 以下を構成ファイルに追加して、一般的な Kafka 固有のディストリビューティッド（分散）トレーシング機能を有効にします。

      ```yml
      class_transformer:
        com.newrelic.instrumentation.kafka-clients-spans-0.11.0.0:
          enabled: true
      ```

    * エージェント バージョン`8.21`以降で spring-kafka 計装を有効にします。

      <Callout variant="important">
        これにより、取り込みとメモリ使用量が急増する可能性があるため、無効になっています。
      </Callout>

      ```yml
      class_transformer:
        com.newrelic.instrumentation.spring-kafka-2.2.0:
          enabled: true
      ```

    * エージェント バージョン`8.21`以降の Kafka のバッチ呼び出しに対してディストリビューティッド（分散）トレーシングを有効にします。 (トランザクションはメッセージから 1 つの親トレースのみを受け入れることができるため、バッチ呼び出しディストリビューティッド（分散）トレーシングはデフォルトで無効になっています):

      ```yml
      kafka:
        spans:
          distributed_trace: 
            consume_many:
              enabled: true
      ```
  </Collapser>

  <Collapser id="instrument-kafka-producer" title="2.Kafkaプロデューサーのインストゥルメント">
    Kafka プロデューサーを計測するには、 `Producer.send(ProducerRecord<K, V> record)`を呼び出す前にトランザクションを開始する必要があります。これを行うには、Java エージェント`@Trace(dispatcher = true)`アノテーションをメソッドに追加します。

    例えば：

    ```java
    @Trace(dispatcher = true)
    public static void createAndSend(KafkaProducer<String, String> producer){
      ProducerRecord<String, String> data = new ProducerRecord<String, String>("topic", "key", "value");
      producer.send(data);
    }
    ```

    <Callout variant="important">
      Kafka Streams を使用している場合、トランザクションを直接開始したり、プロデューサーにデータを送信したりする必要はありません。
    </Callout>
  </Collapser>

  <Collapser id="instrument-kafka-consumer" title="3.Kafkaコンシューマーのインストゥルメント">
    ### シナリオ 1: Kafka クライアントで手動計装を使用する

    手動インスタンス化によって Kafka 消費者を計量するには、メッセージの処理中にトランザクションを開始する必要があります。 エージェントは、ディストリビューティッド（分散）トレーシング ペイロード ヘッダーを`newrelic`キーまたは W3C の`traceparent`と`tracestate`キーの下に保存します。 ヘッダーを取得し、New Relic トランザクション API を呼び出してペイロードを受け入れます。

    例えば：

    ```java
    @Trace(dispatcher = true)
    private static void processMessage(ConsumerRecord<String, String> rec) {
      // create a distributed trace headers map
      Headers dtHeaders = ConcurrentHashMapHeaders.build(HeaderType.MESSAGE);

      // Iterate through each record header and insert the trace headers into the dtHeaders map
      for (Header header : rec.headers()) {
        String headerValue = new String(header.value(), StandardCharsets.UTF_8);

        // using the newrelic key
        if (header.key().equals("newrelic")) {
          dtHeaders.addHeader("newrelic", headerValue);
        }

        // or using the W3C keys
        if (header.key().equals("traceparent")) {
          dtHeaders.addHeader("traceparent", headerValue);
        }

        if (header.key().equals("tracestate")) {
          dtHeaders.addHeader("tracestate", headerValue);
        }
      }

      // Accept distributed tracing headers to link this request to the originating request
      NewRelic.getAgent().getTransaction().acceptDistributedTraceHeaders(TransportType.Kafka, dtHeaders);
    }
    ```

    ### シナリオ 2: Kafka クライアントに対する自動インストゥルメンテーションの使用

    これはエージェント バージョン`8.21`以上にのみ適用されます。自動インストゥルメンテーションを活用して、kafka 消費者のディストリビューティッド（分散）トレーシングを読み取ることもできます。 これは、トランザクションを開始し、トランザクションの発生時に Consumer の`poll(...)`メソッドを呼び出すことによって実現されます。

    これはデフォルトでは無効になっています。これは、消費者ポーリングがデフォルトで複数のメッセージを受け入れ、トランザクションが持つことができる親トレースが 1 つだけであるため、読み取られるメッセージは 1 つだけになるためです。

    Kafka 消費者投票のディストリビューティッド（分散）トレーシングの自動受け入れを有効にするには、ステップ 1 に示すように、バッチ呼び出しに対してディストリビューティッド（分散）トレーシングを有効にする必要があります。

    インストゥルメントで行われた kafka 消費者投票の例:

    ```java
    @Trace(dispatcher = true)
    private void consumeMessage(KafkaConsumer<String, String> consumer) {
      final ConsumerRecords<String, String> records = consumer.poll(1000);
      // Process your records ....
    }
    ```

    ### シナリオ3: Spring Kafkaの使用

    Spring Kafka を使用している場合、エージェント バージョン `8.21.0` 以降を使用している場合、 `@KafkaListener`でインストゥルメントされたメソッドに対して自動インストゥルメンテーションを有効にすることができ 。 これにより、トランザクションが作成され、消費者向けにディストリビューティッド（分散）トレーシングが自動承認されます。 Kafka は高スループットのプラットフォームであるため、過剰な取り込みとメモリのオーバーヘッドを防ぐために無効になっています。手順 1 に示されている構成を使用して、spring-kafka インストルメンテーションを有効にできます。

    例：

    ```java
    @KafkaListener(id = "foo", topics = "myTopic", clientIdPrefix = "myClientId")
    public void listen(String data) {
      ...
    }
    ```

    <Callout variant="important">
      Kafka Streams でトランザクションを有効にした場合 ( [Kafka Streams トランザクション セクション](#collect-kafka-streams-transactions)を参照)、トランザクションが多くのレコードに適用される場合でも、分散トレース ヘッダーの受け入れは 1 つのレコードにのみ適用されます。
    </Callout>
  </Collapser>
</CollapserGroup>