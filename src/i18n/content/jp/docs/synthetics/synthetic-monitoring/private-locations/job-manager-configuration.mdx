---
title: Synthetics ジョブ マネージャーの構成
tags:
  - synthetics
  - Synthetic monitoring
  - Private locations
metaDescription: Customize your New Relic synthetics job manager.
freshnessValidatedDate: '2024-07-29T00:00:00.000Z'
translationType: machine
---

このドキュメントでは、次の方法を示して[、外形監視ジョブ マネージャー](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager)の構成について説明します。

* [環境変数](#environment-variables)を使用して、外形監視ジョブ マネージャーを構成します。
* [](#custom-modules)[スクリプトAPI](/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/) または[ スクリプトbrowser](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) モニターの カスタム モジュール を設定します。
* 設定に[ユーザー定義の変数](#user-defined-vars)を提供します。

## 環境変数を使用した設定 [#environment-variables]

環境変数を使用すると、合成ジョブ マネージャーの構成を微調整して、特定の環境および機能のニーズを満たすことができます。

<CollapserGroup>
  <Collapser id="docker-env-config" title="Dockerの環境設定">
    変数は、起動時に`-e, --env`引数を使用して提供されます。

    次の表は、synthetics ジョブ マネージャーがサポートするすべての環境変数を示しています。`PRIVATE_LOCATION_KEY`は必須で、その他の変数はすべてオプションです。

    <table>
      <thead>
        <tr>
          <th>
            名前
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DNT>**Required.**</DNT> プライベートロケーション エンティティ リストにあるプライベートロケーション キー。
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_API_VERSION`
          </td>

          <td>
            形式： `"vX.Y"`指定されたDockerサービスで使用されるAPIバージョン。

            デフォルト： `v1.35.`
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_HOST`
          </td>

          <td>
            合成ジョブ マネージャーを特定の`DOCKER_HOST`にポイントします。存在しない場合、デフォルト値は `/var/run/docker.sock.`
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            米国ベースのアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.nr-data.net.`

            [EUベース](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy)のアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.eu01.nr-data.net/`

            モニターにサービスを提供するために、合成ジョブ マネージャーが適切なエンドポイントに接続できることを確認します。
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            ランタイム イメージがホストされる Docker レジストリ ドメイン。これを使用して、 `docker.io`をデフォルトとしてオーバーライドします。
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            ランタイム イメージがホストされている Docker リポジトリまたは組織。これを使用して、 `newrelic`デフォルトとして上書きします。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー ホスト。形式: `"localhost"` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー ポート。形式: `8888` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバーのユーザー名。形式: `"username"` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバーのパスワード。形式: `"password"` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー接続の自己署名プロキシ証明書を受け入れますか?許容値: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            モニター チェックの実行が許可される最大秒数。この値は、0 秒 (除く) から 900 秒 (含む) までの整数である必要があります (たとえば、1 秒から 15 分まで)。

            デフォルト: 180 秒
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            デフォルト： `INFO.`

            追加オプション: `WARN` 、 `ERROR` 、 `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            一度に実行できる同時重量ジョブ ( browser /スクリプト化されたbrowserおよびスクリプト化された API) の数。

            デフォルト: 使用可能な CPU - 1。
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            特定のランタイム イメージを実行するために使用される配列。 形式: \[&apos;newrelic/外形監視-ping-runtime:latest&apos;,&apos;newrelic/外形監視-node- API -runtime:latest&apos;,&apos;newrelic/外形監視-node-browser-runtime:latest&apos;]

            デフォルト: すべての最新のランタイム。
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            設定すると、 <DNT>**verified script execution**</DNT>が有効になり、この値が<DNT>**passphrase**</DNT>として使用されます。
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            ユーザーが定義したキーバリューペアのセットをローカルにホストすること。
          </td>
        </tr>

        <tr>
          <td>
            `ENABLE_WASM`
          </td>

          <td>
            設定されている場合、ノードbrowserランタイムの Web アセンブリが有効になります。 WebAssembly を使用するには、外形監視ジョブ マネージャーの最小バージョンが release-367 以上であり、ノードbrowserランタイム バージョンが 2.3.21 以上である必要があります。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="podman-env-config" title="Podman環境設定">
    変数は、起動時に`-e, --env`引数を使用して提供されます。

    次の表には、外形監視ジョブ マネージャーがサポートするすべての環境変数が表示されます。 `PRIVATE_LOCATION_KEY`は必須ですが、その他の変数はオプションです。Podman 環境で外形監視ジョブ マネージャーを実行するには、最小バージョンがリリース 418 以上である必要があります。

    <table>
      <thead>
        <tr>
          <th>
            名前
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DNT>**Required.**</DNT> プライベートロケーション エンティティ リストにあるプライベートロケーション キー。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            米国ベースのアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.nr-data.net.`

            [EUベース](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy)のアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.eu01.nr-data.net/`

            モニターにサービスを提供するために、合成ジョブ マネージャーが適切なエンドポイントに接続できることを確認します。
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_SERVICE_HOST`
          </td>

          <td>
            SJM が実行される場所に作成されたポッドに追加されたホスト エントリ。これを使用して、 `podman.service`デフォルトとして上書きします。
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_SERVICE_PORT`
          </td>

          <td>
            インスタンス内で Podman LibPod RESTful API サービスが実行されているポート。これを使用して、 `8000`デフォルトとして上書きします。
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_VERSION`
          </td>

          <td>
            使用されている Podman LibPod RESTful API の特定のバージョン。これを使用して、 `v5.0.0`デフォルトとして上書きします。
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_POD_NAME`
          </td>

          <td>
            SJM コンテナが実行されるポッドの名前。これを使用して、 `SYNTHETICS`デフォルトとして上書きします。
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            ランタイム イメージがホストされる Docker レジストリ ドメイン。これを使用して、 `docker.io`をデフォルトとしてオーバーライドします。
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            ランタイム イメージがホストされている Docker リポジトリまたは組織。これを使用して、 `newrelic`デフォルトとして上書きします。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー ホスト。形式: `"localhost"` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー ポート。形式: `8888` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバーのユーザー名。形式: `"username"` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバーのパスワード。形式: `"password"` 。
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー接続の自己署名プロキシ証明書を受け入れますか?許容値: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            モニター チェックの実行が許可される最大秒数。この値は、0 秒 (除く) から 900 秒 (含む) までの整数である必要があります (たとえば、1 秒から 15 分まで)。

            デフォルト: 180 秒
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            デフォルト： `INFO.`

            追加オプション: `WARN` 、 `ERROR` 、 `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            一度に実行できる同時重量ジョブ ( browser /スクリプト化されたbrowserおよびスクリプト化された API) の数。

            デフォルト: 使用可能な CPU - 1。
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            特定のランタイム イメージを実行するために使用される配列。 形式: \[&apos;newrelic/外形監視-ping-runtime:latest&apos;,&apos;newrelic/外形監視-node- API -runtime:latest&apos;,&apos;newrelic/外形監視-node-browser-runtime:latest&apos;]

            デフォルト: すべての最新のランタイム。
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            設定すると、 <DNT>**verified script execution**</DNT>が有効になり、この値が<DNT>**passphrase**</DNT>として使用されます。
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            ユーザーが定義したキーバリューペアのセットをローカルにホストすること。
          </td>
        </tr>

        <tr>
          <td>
            `ENABLE_WASM`
          </td>

          <td>
            設定されている場合、ノードbrowserランタイムの Web アセンブリが有効になります。 WebAssembly を使用するには、外形監視ジョブ マネージャーの最小バージョンが release-367 以上であり、ノードbrowserランタイム バージョンが 2.3.21 以上である必要があります。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="kubernetes-env-config" title="Kubernetesの環境設定">
    変数は、起動時に`--set`引数を使用して提供されます。

    次のリストは、synthetics ジョブ マネージャーがサポートするすべての環境変数を示しています。`synthetics.privateLocationKey`は必須で、その他の変数はすべてオプションです。

    多数の追加の高度な設定が利用可能であり[、Helm チャートの README](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)に完全に記載されています。

    <table>
      <thead>
        <tr>
          <th>
            名前
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DNT>**Required if `synthetics.privateLocationKeySecretName` is not set**</DNT>.プライベートロケーション Web ページにあるプライベート[ロケーションのキー](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key)。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.privateLocationKeySecretName`
          </td>

          <td>
            <DNT>**Required if `synthetics.privateLocationKey` is not set**</DNT>。キー`privateLocationKey`を含む Kubernetes シークレットの名前。これには、外形監視プライベートロケーションに関連付けられた認証キーが含まれます。
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            指定されたコンテナレジストリからイメージを引き出すために使用されるシークレットオブジェクトの名前です。
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            デフォルトを置き換えて、デプロイメントに使用される名前のオーバーライド。
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml)で指定されたバージョンの代わりに使用する、synthetics-job-manager のリリース バージョン。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            デフォルト： `INFO.`

            追加オプション: `WARN` 、 `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            米国ベースのアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.nr-data.net.`

            [EUベース](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy)のアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.eu01.nr-data.net/`

            モニターにサービスを提供するために、合成ジョブ マネージャーが適切なエンドポイントに接続できることを確認します。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.minionDockerRunnerRegistryEndpoint`
          </td>

          <td>
            MinionRunnerイメージがホストされているDockerレジストリと組織。これを使用して、デフォルトとして`quay.io/newrelic`をオーバーライドします（たとえば、 `docker.io/newrelic` ）
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            設定すると、 <DNT>**verified script execution**</DNT>が有効になり、この値が<DNT>**passphrase**</DNT>として使用されます。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            設定すると、検証済みスクリプトの実行が有効になり、この値を使用して、 `vsePassphrase`というキーを持つ Kubernetes シークレットからパスフレーズを取得します。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.enableWasm`
          </td>

          <td>
            設定されている場合、ノードbrowserランタイムの Web アセンブリが有効になります。 WebAssembly を使用するには、外形監視ジョブ マネージャーの最小バージョンが release-367 以上であり、ノードbrowserランタイム バージョンが 2.3.21 以上である必要があります。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー。形式: `"host"` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー ポート。形式: `port` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Horde 通信にプロキシ サーバーを使用する場合は、自己署名証明書を受け入れます。許容値: `true` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Horde 通信用のプロキシ サーバーのユーザー名。フォーマット： `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Horde 通信用のプロキシ サーバーのパスワード。形式: `"password"` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            ユーザー定義変数の JSON 文字列。 ユーザーはスクリプト内でこれらの変数にアクセスできます。 形式: `'{"key":"value","key2":"value2"}'` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            ユーザー定義変数を含む JSON ファイルへの、ユーザーにとってローカルなパス。 これは`--set-file`経由で渡され、値ファイルで設定することはできません。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            user\_define\_variables.json 파일에 대한 사용자가 제공한 PertantVolume의 경로입니다.この変数が設定されている場合、ユーザーは Persistent Volume または Persistent VolumeClaim を指定する必要があります。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingClaimName`
          </td>

          <td>
            ボリュームをマウントする場合、ユーザーはクラスター内に既に存在する PersistentVolumeClaim の名前を指定できます。 対応する PersistentVolume が存在することを前提とします。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingVolumeName`
          </td>

          <td>
            ボリュームをマウントし、PersistentVolumeClaim を指定しない場合、ユーザーは少なくとも Persistent Volume 名を指定する必要があります。 Helm は PersistentVolumeClaim を生成します。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.storageClass`
          </td>

          <td>
            生成された PersistentVolumeClaim の StorageClass の名前。 これは、既存の PV の StorageClassName と一致する必要があります。 プロバイダーでない場合、Kubernetes はデフォルトのストレージ クラスが存在する場合はそれを使用します。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.size`
          </td>

          <td>
            生成された PersistentVolumeClaim のボリュームのサイズ。 フォーマット: `10Gi` 。 デフォルトは2Giです。
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            モニター チェックの実行が許可される最大秒数。この値は、0 秒 (除く) から 900 秒 (含む) までの整数である必要があります (たとえば、1 秒から 15 分まで)。

            デフォルト: 180 秒
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            引くための容器です。

            デフォルト： `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            引きの方針です。

            デフォルト： `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            Synthetics-job-manager ポッドのカスタム セキュリティ コンテキストを設定します。
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            永続的な ping ランタイムをデプロイする必要があるかどうか。ping モニターを使用しない場合は、これを無効にすることができます。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            デプロイする ping ランタイム コンテナーの数。ping 監視のニーズに基づいてデプロイをスケーリングするには、replicaCount を増やします。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            ping ランタイム用にプルするコンテナー イメージ。

            デフォルト： `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            ping-runtime コンテナーのプル ポリシー。

            デフォルト： `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Node.js API ランタイムをデプロイする必要があるかどうか。スクリプト化された API モニターを使用しない場合、これを無効にすることができます。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            デプロイする Node.js API ランタイム`CronJobs`の数。同時に実行される Node.js API ジョブの最大数。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            1 分あたりに完了する Node.js API ランタイム`CronJobs`の数。並列処理とともにこの設定を増やして、スループットを向上させます。これは、並列処理が増加するたびに増加する必要があり、完了は常に少なくとも並列処理以上である必要があります。 .API ランタイム ジョブが実行されていない期間がある場合は、この設定を増やしてください。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            Node.js API ランタイム用にプルするコンテナー イメージ。

            デフォルト： `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            Node.js API ランタイム コンテナーのプル ポリシー。

            デフォルト： `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Node.js ブラウザー ランタイムをデプロイする必要があるかどうか。シンプルなブラウザ モニタまたはスクリプト化されたブラウザ モニタを使用しない場合は、これを無効にすることができます。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            デプロイする Chrome ブラウザー ランタイム`CronJobs`の数。同時に実行される Chrome ブラウザ ジョブの最大数。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            1 分あたりに完了する Chrome ブラウザ ランタイム`CronJobs`の数。並列処理とともにこの設定を増やして、スループットを向上させます。これは、並列処理が増加するたびに増加する必要があり、完了は常に少なくとも並列処理以上である必要があります。ブラウザーのランタイム ジョブが実行されていない期間があることに気付いた場合は、この設定を増やしてください。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            Node.js ブラウザー ランタイム用にプルするコンテナー イメージ。

            デフォルト： `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            Node.js ブラウザー ランタイム コンテナーのプル ポリシー。

            デフォルト： `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="openshift-environment-config" title="OpenShift環境設定">
    変数は、起動時に`--set`引数を使用して提供されます。

    次のリストは、synthetics ジョブ マネージャーがサポートするすべての環境変数を示しています。`synthetics.privateLocationKey`は必須で、その他の変数はすべてオプションです。

    多数の追加の高度な設定が利用可能であり[、Helm チャートの README](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)に完全に記載されています。

    <table>
      <thead>
        <tr>
          <th>
            名前
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DNT>**Required**</DNT>. [プライベートロケーション キー](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key)。プライベートロケーション エンティティ リストにあります。
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            指定されたコンテナレジストリからイメージを引き出すために使用されるシークレットオブジェクトの名前です。
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            デフォルトを置き換えて、デプロイメントに使用される名前のオーバーライド。
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml)で指定されたバージョンの代わりに使用する、synthetics-job-manager のリリース バージョン。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            デフォルト： `INFO.`

            追加オプション: `WARN` 、 `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            米国ベースのアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.nr-data.net.`

            [EUベース](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy)のアカウントの場合、エンドポイントは次のとおりです。 `https://synthetics-horde.eu01.nr-data.net/`

            モニターにサービスを提供するために、合成ジョブ マネージャーが適切なエンドポイントに接続できることを確認します。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            設定すると、 <DNT>**verified script execution**</DNT>が有効になり、この値が<DNT>**passphrase**</DNT>として使用されます。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            設定すると、検証済みスクリプトの実行が有効になり、この値を使用して、 `vsePassphrase`というキーを持つ Kubernetes シークレットからパスフレーズを取得します。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.enableWasm`
          </td>

          <td>
            設定されている場合、ノードbrowserランタイムの Web アセンブリが有効になります。 WebAssembly を使用するには、外形監視ジョブ マネージャーの最小バージョンが release-367 以上であり、ノードbrowserランタイム バージョンが 2.3.21 以上である必要があります。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー。形式: `"host"` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Horde 通信に使用されるプロキシ サーバー ポート。形式: `port` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Horde 通信にプロキシ サーバーを使用する場合は、自己署名証明書を受け入れます。許容値: `true` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Horde 通信用のプロキシ サーバーのユーザー名。フォーマット： `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Horde 通信用のプロキシ サーバーのパスワード。形式: `"password"` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            ユーザー定義変数の JSON 文字列。 ユーザーはスクリプト内でこれらの変数にアクセスできます。 形式: `'{"key":"value","key2":"value2"}'` 。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            ユーザー定義変数を含む JSON ファイルへの、ユーザーにとってローカルなパス。 これは`--set-file`経由で渡され、値ファイルで設定することはできません。
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            ユーザーが指定した`PersistentVolume`上の` user_defined_variables.json`ファイルへのパス。この変数が設定されている場合、ユーザーは`PersistentVolume`または`PersistentVolumeClaim`指定する必要があります。
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.existingClaimName`
          </td>

          <td>
            ボリュームをマウントする場合、ユーザーはクラスター内に既に存在する`PersistentVolumeClaim`の名前を指定できます。対応する`PersistentVolume`が存在することを前提としています。
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.existingVolumeName`
          </td>

          <td>
            ボリュームをマウントし、 `PersistentVolumeClaim`を指定しない場合、ユーザーは少なくとも`PersistentVolume`名を指定する必要があります。Helm は`PersistentVolumeClaim`を生成します。
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.storageClass`
          </td>

          <td>
            生成された`PersistentVolumeClaim`の`StorageClass`の名前。これは既存の PV の`StorageClassName`と一致する必要があります。プロバイダーでない場合、 **Kubernetes は**デフォルトのストレージ クラス (存在する場合) を使用します。
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.size`
          </td>

          <td>
            生成された`PersistentVolumeClaim`のボリュームのサイズ。フォーマット: `10Gi` 。デフォルトは`2Gi` 。
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            モニター チェックの実行が許可される最大秒数。この値は、0 秒 (除く) から 900 秒 (含む) までの整数である必要があります (たとえば、1 秒から 15 分まで)。

            デフォルト: 180 秒
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            引くための容器です。

            デフォルト： `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            引きの方針です。

            デフォルト： `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            `synthetics-job-manager`ポッドのカスタム セキュリティ コンテキストを設定します。
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            永続的な ping ランタイムをデプロイする必要があるかどうか。ping モニターを使用しない場合は、これを無効にすることができます。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            デプロイする ping ランタイム コンテナの数。ping 監視のニーズに基づいてデプロイメントをスケールするには、 `replicaCount`を増やします。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            ping ランタイム用にプルするコンテナー イメージ。

            デフォルト： `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            ping-runtime コンテナーのプル ポリシー。

            デフォルト： `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Node.js API ランタイムをデプロイする必要があるかどうか。スクリプト化された API モニターを使用しない場合、これを無効にすることができます。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            デプロイする Node.js API ランタイム`CronJobs`の数。同時に実行される Node.js API ジョブの最大数。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            1 分あたりに完了する Node.js API ランタイム`CronJobs`の数。並列処理とともにこの設定を増やして、スループットを向上させます。これは、並列処理が増加するたびに増加する必要があり、完了は常に少なくとも並列処理以上である必要があります。 .API ランタイム ジョブが実行されていない期間がある場合は、この設定を増やしてください。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            Node.js API ランタイム用にプルするコンテナー イメージ。

            デフォルト： `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            Node.js API ランタイム コンテナーのプル ポリシー。

            デフォルト： `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Node.js ブラウザー ランタイムをデプロイする必要があるかどうか。シンプルなブラウザ モニタまたはスクリプト化されたブラウザ モニタを使用しない場合は、これを無効にすることができます。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            デプロイする Chrome ブラウザー ランタイム`CronJobs`の数。同時に実行される Chrome ブラウザ ジョブの最大数。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            1 分あたりに完了する Chrome ブラウザ ランタイム`CronJobs`の数。並列処理とともにこの設定を増やして、スループットを向上させます。これは、並列処理が増加するたびに増加する必要があり、完了は常に少なくとも並列処理以上である必要があります。ブラウザーのランタイム ジョブが実行されていない期間があることに気付いた場合は、この設定を増やしてください。[追加の詳細](#kubernetes-sizing)。

            デフォルト： `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            Node.js ブラウザー ランタイム用にプルするコンテナー イメージ。

            デフォルト： `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            Node.js ブラウザー ランタイム コンテナーのプル ポリシー。

            デフォルト： `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## スクリプト モニターのユーザー定義変数 [#user-defined-vars]

プライベート外形監視ジョブ マネージャーを使用すると、スクリプト化された監視の環境変数を構成できます。 これらの変数は SJM 上でローカルに管理され、 `$env.USER_DEFINED_VARIABLES`を介してアクセスできます。 ユーザー定義変数は 2 つの方法で設定できます。 JSON ファイルをマウントするか、リリースの SJM に環境変数を指定することができます。 両方が指定されている場合、SJM は環境によって提供される値のみを使用します。

<CollapserGroup>
  <Collapser id="user-file-example" title="JSONファイルの実装">
    ユーザーは JSON 形式のファイルを作成し、そのファイルが配置されているボリュームを SJM コンテナ内の指定されたターゲット パスにマウントできます。

    ファイルには読み取り権限が必要であり、JSON 形式のマップが含まれている必要があります。 ユーザー定義変数ファイルの例:

    ```json
    {
      "KEY": "VALUE",
      "user_name": "MINION",
      "my_password": "PASSW0RD123",
      "my_URL": "https://newrelic.com/",
      "ETC": "ETC"
    }
    ```

    ファイルをホスト上のソース ディレクトリに配置します。 SJM은 파일 이름이 user\_define\_variables.json이 될 것으로 예상합니다.

    Dockerの例です。

    想定されるターゲット ディレクトリは次のとおりです。 `/var/lib/newrelic/synthetics/variables/`

    ```sh
    docker run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw ...
    ```

    Podmanの例:

    SELinux の場合は、ボリュームを`:z`または`:Z`で追加でマウントします。詳細については、 [Podman のドキュメントを参照してください。](https://docs.podman.io/en/latest/markdown/podman-run.1.html#volume-v-source-volume-host-dir-container-dir-options)想定されるターゲット ディレクトリは次のとおりです。 `/var/lib/newrelic/synthetics/variables/`

    ```sh
    podman run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw,z ...
    ```

    Kubernetesの例。

    Kubernetes の SJM ポッドにファイルを提供する場合、ユーザーには 2 つのオプションがあります。 以下の可能性があります:

    * ローカルファイルを渡します。
    * `user_defined_variables.json`を含む PersistentVolume を提供します。

    ### ローカルファイルを渡す

    このオプションは、ConfigMap Kubernetes リソースを作成し、それを SJM ポッドにマウントします。

    ```sh
    helm install newrelic/synthetics-job-manager ... --set-file "synthetics.userDefinedVariables.userDefinedFile=[local-path]/user_defined_variables.json" ...
    ```

    ### マウント `PersistentVolume`

    このオプションでは、ユーザーは`user_defined_variables.json`ファイルを含む`PersistentVolume`または同じファイルに対する`PersistentVolumeClaim`指定する必要があります。`PersistentVolume`を使用した helm chart インストレーションの詳細については、 [永続的なデータ ストレージ](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#permanent-data-storage)の手順に従ってください。

    ユーザーが下記の説明に従って`PersistentVolume`を準備したら、SJM をリリースし、 `user_defined_variables.json`ファイルが配置されているパスを設定し、必要に応じてその他の`synthetics.persistence`変数を設定します。

    ```sh
    helm install newrelic/synthetics-job-manger ... --set synthetics.userDefinedVariables.userDefinedPath="variables"
    ```
  </Collapser>

  <Collapser id="passing-env-var" title="環境変数として渡す">
    変数は環境変数を介してそれぞれのコンテナ システムに渡される場合があります。

    Dockerの例です。

    `-e`フラグを使用して、 `USER_DEFINED_VARIABLES`という名前の環境変数を設定し、JSON 形式のマップ文字列の値を指定します。

    ```sh
    docker run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Podmanの例:

    `-e`フラグを使用して、 `USER_DEFINED_VARIABLES`という名前の環境変数を設定し、JSON 形式のマップ文字列の値を指定します。

    ```sh
    podman run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Kubernetesの例。

    JSON 形式の文字列を渡すには、 `--set-literal`フラグを使用します。

    ```sh
    helm install newrelic/synthetics-job-manager ... --set-literal synthetics.userDefinedVariables.userDefinedJson='{"key":"value","name":"sjm"}' ...
    ```
  </Collapser>
</CollapserGroup>

### スクリプトからユーザー定義の環境変数にアクセスする [#env-vars-scripts]

構成されたユーザー定義の環境変数を参照するには、予約語の`$env.USER_DEFINED_VARIABLES`に続けて、ドット表記の特定の変数の名前を使用します (例: `$env.USER_DEFINED_VARIABLES.MY_VARIABLE` )。

<Callout variant="caution">
  ユーザー定義の環境変数はログから削除されません。 機密情報には[安全な認証情報](/docs/synthetics/new-relic-synthetics/using-monitors/secure-credentials-store-credentials-information-scripted-browsers)機能を使用することを検討してください。
</Callout>

## カスタムノードモジュール [#custom-modules]

カスタム ノード モジュールは、1分間あたりの呼出し回数と SJM の両方で提供されます。 これらを使用すると、カスタマイズされた[ノード モジュール](https://docs.npmjs.com/about-packages-and-modules)のセットを作成し、外形監視用のスクリプト モニター (スクリプトAPIおよびスクリプトbrowser ) で使用できます。

### カスタムモジュールディレクトリを設定する

ルート フォルダーに[npm の公式ガイドライン](https://docs.npmjs.com/files/package.json)に従って、 `package.json`ファイルを含むディレクトリを作成します。 SJMはpackage.jsonにリストされている依存関係をインストールします。 `dependencies`フィールド。 これらの依存関係は、プライベート外形監視ジョブ マネージャーでモニターを実行するときに使用できます。 以下の例をご覧ください。

#### 例

この例では、次のような構造のカスタムモジュールディレクトリを使用しています。

```
/example-custom-modules-dir/
    ├── counter
    │   ├── index.js
    │   └── package.json
    └── package.json            ⇦ the only mandatory file
```

`package.json`は`dependencies`ローカル モジュール (例: `counter` ) とホストされたモジュール (例: `smallest`バージョン`1.0.1` ) の両方として定義します。

```json
{
    "name": "custom-modules",
    "version": "1.0.0",                                ⇦ optional
    "description": "example custom modules directory", ⇦ optional
    "dependencies": {
    "smallest": "1.0.1",                               ⇦ hosted module
    "counter": "file:./counter"                        ⇦ local module
    }
}
```

### Docker、Podman、KubernetesのSJMにカスタムモジュールディレクトリを追加します。

<CollapserGroup>
  <Collapser id="docker" title="Docker">
    dockerの場合、リリース SJM はディレクトリを `/var/lib/newrelic/synthetics/modules` にマウントします。 例えば：

    ```sh
    docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ...
    ```
  </Collapser>

  <Collapser id="podman" title="ポッドマン">
    podman の場合は、SJM をリリースして`/var/lib/newrelic/synthetics/modules`にディレクトリをマウントします。 SELinux の場合は、 `:z`または`:Z`を使用してボリュームを追加でマウントします。詳細については、 [Podman のドキュメント](https://docs.podman.io/en/latest/markdown/podman-run.1.html#volume-v-source-volume-host-dir-container-dir-options)を参照してください。例えば：

    ```sh
    podman run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw,z ...
    ```
  </Collapser>

  <Collapser id="kubernetes" title="Kubernetes">
    Kubernetes の場合、カスタム モジュールを有効にして SJM を起動する前に、 `/var/lib/newrelic/synthetics/modules`のディレクトリが PV 上に存在している必要があります。

    <Callout variant="tip">
      複数のポッド間でストレージを共有する必要がある場合は、PV アクセス モードを ReadWriteMany にする必要があります。
    </Callout>

    1 つの方法は、カスタム モジュール ディレクトリを PV にコピーするためだけに PV をマウントするポッドを作成することです。次の例では、Amazon EKS と Amazon EFS を使用します。

    #### ネームスペース、永続ボリューム、および永続ボリューム要求を作成する

    1. EFS ファイルシステムがすでにセットアップされており、クラスターに[EFS CSI ドライバー](https://github.com/kubernetes-sigs/aws-efs-csi-driver)がインストールされていることを確認してください。PV の`spec.csi.volumeHandle`の EFS ファイルシステム ID も必要になります。

       ```sh
       kubectl apply -f - <<EOF
       apiVersion: v1
       kind: Namespace
       metadata:
         name: newrelic

       ---
       kind: StorageClass
       apiVersion: storage.k8s.io/v1
       metadata:
         name: efs-sc
       provisioner: efs.csi.aws.com

       ---
       apiVersion: v1
       kind: PersistentVolume
       metadata:
         name: custom-modules-pvc
       spec:
         capacity:
           storage: 5Gi
         volumeMode: Filesystem
         accessModes:
           - ReadWriteMany
         persistentVolumeReclaimPolicy: Retain
         storageClassName: efs-sc
         csi:
           driver: efs.csi.aws.com
           volumeHandle: <your-efs-filesystem-id>

       ---
       apiVersion: v1
       kind: PersistentVolumeClaim
       metadata:
         name: custom-modules-pvc
         namespace: newrelic
       spec:
         accessModes:
           - ReadWriteMany
         storageClassName: efs-sc
         resources:
           requests:
             storage: 5Gi
       EOF
       ```

    2. `~/.kube/config`の`newrelic`ネームスペースに切り替えます。

       ```sh
       kubectl config get-contexts
       kubectl config set-context YOUR_CONTEXT --namespace=newrelic
       kubectl config view --minify | grep namespace:
       ```

    3. この時点で、PVC は RWX アクセス モードで PV にバインドされる必要があります。

       ```sh
       kubectl get pv,pvc
       [output] NAME                                  CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                         STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
       [output] persistentvolume/custom-modules-pvc   5Gi        RWX            Retain           Bound    newrelic/custom-modules-pvc   efs-sc         <unset>                          4m46s
       [output]
       [output] NAME                                       STATUS   VOLUME               CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
       [output] persistentvolumeclaim/custom-modules-pvc   Bound    custom-modules-pvc   5Gi        RWX            efs-sc         <unset>                 4m10s
       ```

       #### カスタムモジュールディレクトリをコピーするには、 `mount-custom-mods-pod`作成します。

       ```sh
       kubectl apply -f - <<EOF
       apiVersion: v1
       kind: Pod
       metadata:
         name: mount-custom-mods-pod
       spec:
         containers:
         - name: mount-custom-mods-pod
           image: nginx
           resources:
             requests:
               memory: "64Mi"
               cpu: "250m"
             limits:
               memory: "128Mi"
               cpu: "500m"
           volumeMounts:
             - mountPath: "/var/lib/newrelic/synthetics/modules"
               name: custom-modules-storage
         volumes:
         - name: custom-modules-storage
           persistentVolumeClaim:
             claimName: custom-modules-pvc
       EOF
       ```

       この時点で、ボリュームを使用するために`mount-custom-mods-pod`が作成され、構成される必要があります。

       ```sh
       kubectl describe po mount-custom-mods-pod | grep -A4 Volumes:
       [output] Volumes:
       [output]   custom-modules-storage:
       [output]     Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
       [output]     ClaimName:  custom-modules-pvc
       [output]     ReadOnly:   false
       ```

       PV、PVC、または`mount-custom-mods-pod`に関連する警告がないかイベントを確認します。

       ```sh
       kubectl get events --field-selector type=Warning --sort-by='.lastTimestamp'
       ```

       #### カスタムモジュールディレクトリをPVにコピーします

       `node_modules` `npm install`の SJM によって生成されるため、コピーする必要はありません。

       ```sh
       cd custom-modules
       rm -rf node_modules && cd ..
       ```

    4. `mount-custom-mods-pod`が実行中であることを確認してください。

       ```sh
       kubectl get po
       [output] NAME                    READY   STATUS    RESTARTS   AGE
       [output] mount-custom-mods-pod   1/1     Running   0          5m43s
       ```

    5. PVにコピーします。

       ```sh
       kubectl cp custom-modules newrelic/mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules
       ```

    6. PV に`/var/lib/newrelic/synthetics/modules/custom-modules/package.json`が存在することを確認してください。

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l
       [output] total 4
       [output] drwxr-xr-x 2 root root 6144 Jun 29 03:49 custom-modules
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l custom-modules/
       [output] total 4
       [output] -rw-r--r-- 1 501 staff 299 Jun 29 03:49 package.json
       ```

       #### カスタムモジュール機能を有効にしたSJMをリリース

       インストレーション中に、コマンドラインまたは YAML ファイルで`persistence.existingClaimName`と`customNodeModules.customNodeModulesPath`の値を設定します。 `customNodeModules.customNodeModulesPath`値には、カスタム モジュール ファイルが存在する永続ボリューム上のサブパスを指定する必要があります。例えば：

       ```sh
       helm upgrade --install synthetics-job-manager newrelic/synthetics-job-manager -n newrelic --set global.persistence.existingClaimName=custom-modules-pvc --set global.customNodeModules.customNodeModulesPath=custom-modules --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY
       [output] Release "synthetics-job-manager" does not exist. Installing it now.
       [output] NAME: synthetics-job-manager
       [output] LAST DEPLOYED: Fri Jun 28 16:53:28 2024
       [output] NAMESPACE: newrelic
       [output] STATUS: deployed
       [output] REVISION: 1
       [output] TEST SUITE: None
       ```

       `custom-modules`ディレクトリには、 `node_modules`にインストールされたパッケージが含まれるようになりました。

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l custom-modules/
       [output] total 16
       [output] -rw-r--r--  1 root root   836 Jun 29 03:51 README
       [output] drwxr-xr-x 18 root root  6144 Jun 29 03:51 node_modules
       [output] -rw-r--r--  1  501 staff  299 Jun 29 03:49 package.json
       [output] -rw-r--r--  1 root root   190 Jun 29 03:51 package.json.shasum
       ```

       カスタム ノード モジュールが検出されない場合は、 `custom-modules`ディレクトリと`package.json`ファイルの権限を調整します。

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# chmod -R 777 custom-modules
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# chown -R 2000:2000 custom-modules
       ```
  </Collapser>
</CollapserGroup>

モジュールが正しくインストールされたかどうか、またはエラーが発生したかどうかを確認するには、 `synthetics-job-manager` [コンテナ](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs)または[ポッドの](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring/#review-kubernetes-logs)ログで次の行を探します。

```log
2024-06-29 03:51:28,407{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Detected mounted path for custom node modules
2024-06-29 03:51:28,408{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Validating permission for custom node modules package.json file
2024-06-29 03:51:28,409{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Installing custom node modules...
2024-06-29 03:51:44,670{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Custom node modules installed successfully.
```

これで、このプライベートな場所に送信するモニターの[スクリプト](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers)に`"require('smallest');"`を追加できます。

### 変化 `package.json` [#change-package-json]

ローカル モジュールとホスト モジュールに加えて、 [Node.js モジュール](/docs/synthetics/new-relic-synthetics/scripting-monitors/import-nodejs-modules)も利用できます。 SJM で使用されるカスタム モジュールを更新するには、 `package.json`ファイルに変更を加えて、SJM を再起動します。 再起動プロセス中に、SJM は設定の変更を認識し、クリーンアップと再インストール操作を自動的に実行して、更新されたモジュールが確実に適用されるようにします。

<Callout variant="caution">
  ローカル モジュール: `package.json`には任意のローカル モジュールを含めることができますが、これらのモジュールはカスタム モジュール ディレクトリの下のツリー内に存在する必要があります。 ツリー外に保存すると、初期化プロセスが失敗し、SJM を起動した後に[dockerログ](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs)にエラー メッセージが表示されます。
</Callout>

## データの永久保存 [#permanent-data-storage]

ユーザーは、 `user_defined_variables.json`ファイルを提供したり、カスタム ノード モジュールをサポートしたりするために、永続的なデータ ストレージを使用することがあります。

### Docker

Dockerに恒久的なデータ保存を設定するには

1. ジョブ マネージャーを起動するホスト上にディレクトリを作成します。 これがソース ディレクトリです。

2. ジョブ マネージャーをリリースし、ソース ディレクトリをターゲット ディレクトリ`/var/lib/newrelic/synthetics`にマウントします。

   例：

   ```sh
   docker run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw ...
   ```

### ポッドマン

Podman で永続的なデータ ストレージを設定するには:

1. ジョブ マネージャーを起動するホスト上にディレクトリを作成します。 これがソース ディレクトリです。
2. ジョブ マネージャーをリリースし、ソース ディレクトリをターゲット ディレクトリ`/var/lib/newrelic/synthetics`にマウントします。

例：

```sh
podman run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw,z ...
```

### Kubernetes

Kubernetes に永続的なデータ ストレージを設定するには、ユーザーには 2 つのオプションがあります。

1. 既存の PersistentVolume (PV) に既存の PersistentVolumeClaim (PVC) を指定して、 `synthetics.persistence.existingClaimName`構成値を設定してください。例：

   ```sh
   helm install ... --set synthetics.persistence.existingClaimName=sjm-claim ...
   ```

2. 既存の PersistentVolume (PV) 名を指定して、 `synthetics.persistence.existingVolumeName`構成値を設定してください。Helm はユーザー用の PVC を生成します。ユーザーはオプションで次の値も設定できます。

* `synthetics.persistence.storageClass`: 既存の PV のストレージ クラス。指定されない場合、Kubernetes はデフォルトのストレージ クラスを使用します。

* `synthetics.persistence.size`: 請求のサイズ。設定されていない場合、デフォルトは現在 2Gi です。

  ```sh
  helm install ... --set synthetics.persistence.existingVolumeName=sjm-volume --set synthetics.persistence.storageClass=standard ...
  ```

## Sizing considerations for Docker and Podman [#vm-sizing]

プライベートロケーションを効率的に実行するには、監視ワークロードを処理するのに十分な CPU リソースをホスト上にプロビジョニングする必要があります。 サイズはさまざまな要因によって左右されますが、ニーズはすぐに見積もることができます。**重量級のモニター (シンプル ブラウザー、スクリプト ブラウザー、スクリプト API モニターなど) ごとに 1 つの CPU コアが**必要になります。現在のセットアップを診断する場合でも、将来のセットアップを計画する場合でも、必要なコアの数を計算するのに役立つ 2 つの式を以下に示します。

### 公式1：既存の場所の診断

現在のプライベートロケーションを維持するのが難しく、ジョブがキューに登録されているのではないかと思われる場合は、この式を使用して実際に必要なコアの数を調べてください。 これは、システムの観測可能なパフォーマンスに基づいています。

$$ C\_req = (R\_proc + R\_growth) \cdot D\_avg,m $$

* $C\_req$ =**必要な CPU コア数**。
* $R\_proc$ = 1 分あたりに**処理される**高負荷ジョブの**速度**。
* $R\_growth$ = `jobManagerHeavyweightJobs`キューが 1 分あたりに**増加している****速度**。
* $D\_avg,m$ = 重いジョブの**平均所要時間**（**分）** 。

This formula calculates your true job arrival rate by adding the jobs your system *is processing* to the jobs that are *piling up* in the queue. Multiplying this total load by the average job duration tells you exactly how many cores you need to clear all the work without queuing.

### 公式2: 新しい場所または将来の場所の予測

新しいプライベートロケーションを設定している場合、またはモニターの追加を計画している場合は、この公式を使用して事前にニーズを予測してください。

$$ C\_req = N\_mon \cdot D\_avg,m \cdot \frac1P\_avg,m $$

* $C\_req$ =**必要な CPU コア数**。
* $N\_mon$ = 実行を計画している重量級**モニター**の合計**数**。
* $D\_avg,m$ = 重いジョブの**平均実行時間**（**分）** 。
* $P\_avg,m$ = 重量モニターの**平均期間**(**分**単位) (たとえば、5 分ごとに実行されるモニターの場合、$P\_avg,m = 5$ になります)。

This calculates your expected workload from first principles: how many monitors you have, how often they run, and how long they take.

**重要なサイズ決定要因**

これらの数式を使用する場合は、次の要素を考慮してください。

* **ジョブ期間 ($D\_avg,m$):**平均には、**タイムアウトする**ジョブ (多くの場合、約 3 分) を含める必要があります。これらのジョブは、期間全体にわたってコアを保持するためです。
* **ジョブの失敗と再試行:**モニターが失敗すると、自動的に再試行されます。これらの再試行は、合計負荷に追加される追加のジョブです。継続して失敗し再試行するモニターは**、実質的にその期間が倍増し**、スループットに大きな影響を与えます。
* **スケールアウト:**ホストにコアを追加する (スケールアップ) ことに加えて、同じプライベートロケーションキーを持つ追加の外部監視ジョブマネージャーを展開して、複数の環境間でジョブの負荷を分散する (スケールアウト) ことができます。

単一の外形監視ジョブ マネージャー (SJM) には**、1 分あたり約 15 の重量ジョブ**というスループット制限があることに注意することが重要です。 これは、SJM ごとに処理されるジョブの数よりも、複数の SJM 間でのジョブの効率的な競争を優先する内部スレッド戦略によるものです。計算により、より高いスループットが必要であることが示された場合は、追加の SJM を展開して**スケールアウトする**必要があります。 [ジョブ キューが大きくなっているかどうかを確認し](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring/)、さらに SJM が必要かどうかを判断できます。

同じプライベートロケーションキーを持つ SJM を追加すると、いくつかの利点が得られます。

* **負荷分散**: プライベートロケーションのジョブは、利用可能なすべての SJM に分散されます。
* **フェイルオーバー保護**: 1 つの SJM インスタンスがダウンしても、他のインスタンスがジョブの処理を続行できます。
* **より高い合計スループット**: プライベート ロケーションの合計スループットは、各 SJM からのスループットの合計になります (たとえば、2 つの SJM は最大 30 件/分までのジョブを提供します)。

### 診断用のNRQL書き込み

これらの書き込みを[書き込みビルダー](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/)で実行して、診断式の入力を取得できます。 安定した平均値を得るために、時間範囲を十分に長い期間に設定してください。

**1. Find the rate of jobs processed per minute ($R\_proc$)**: This query counts the number of non-ping (heavyweight) jobs completed over the last day and shows the average rate per minute.

```sql
FROM SyntheticCheck
SELECT rate(uniqueCount(id), 1 minute) AS 'job rate per minute'
WHERE location = 'YOUR_PRIVATE_LOCATION' AND typeLabel != 'Ping'
SINCE 1 day ago
```

**2. Find the rate of queue growth per minute ($R\_growth$)**: This query calculates the average per-minute growth of the `jobManagerHeavyweightJobs` queue on a time series chart. A line above zero indicates the queue is growing, while a line below zero means it&apos;s shrinking.

```sql
FROM SyntheticsPrivateLocationStatus
SELECT derivative(jobManagerHeavyweightJobs, 1 minute) AS 'queue growth rate per minute'
WHERE name = 'YOUR_PRIVATE_LOCATION'
TIMESERIES SINCE 1 day ago
```

<Callout variant="tip">
  必ずプライベートロケーションが存在するアカウントを選択してください。 微分関数は大きく変化する可能性があるため、このクエリを時系列として表示するのが最適です。目標は、1 分あたりのキューの増加率を推定することです。さまざまな時間範囲をPlayて、最も効果的な方法を見つけてください。
</Callout>

**3. Find total number of heavyweight monitors ($N\_mon$)**: This query finds the unique count of heavyweight monitors.

```sql
FROM SyntheticCheck
SELECT uniqueCount(monitorId) AS 'monitor count'
WHERE location = 'YOUR_PRIVATE_LOCATION' AND typeLabel != 'Ping'
SINCE 1 day ago
```

**4. Find average job duration in minutes ($D\_avg,m$)**: This query finds the average execution duration of completed non-ping jobs and converts the result from milliseconds to minutes. `executionDuration` represents the time the job took to execute on the host.

```sql
FROM SyntheticCheck
SELECT average(executionDuration)/60e3 AS 'avg job duration (m)'
WHERE location = 'YOUR_PRIVATE_LOCATION' AND typeLabel != 'Ping'
SINCE 1 day ago
```

**5. 平均ヘビーウェイト モニター期間 ($P\_avg,m$) を見つける:**プライベートロケーションの`jobManagerHeavyweightJobs`キューが増大している場合、既存の結果から平均モニター期間を計算することは正確ではありません。 これは、[合成モニター](https://one.newrelic.com/synthetics)ページのモニターのリストから推定する必要があります。 正しい New Relic アカウントを選択してください。また、 `privateLocation`でフィルタリングする必要がある場合があります。

<Callout variant="tip">
  合成モニターは複数のサブアカウントに存在する場合があります。書き込みビルダーで選択できる数を超えるサブアカウントがある場合は、モニター数が最も多いアカウントを選択してください。
</Callout>

### ping モニターと`pingJobs`キューに関する注意

**Pingモニターは異なります。** これらは、それぞれ CPU コアを完全に消費しない軽量ジョブです。代わりに、別のキュー ( `pingJobs` ) を使用し、ワーカー スレッドのプールで実行されます。

リソースの消費量は少なくなりますが、大量の ping ジョブ、特に失敗するジョブは、パフォーマンスの問題を引き起こす可能性があります。次の点に留意してください。

* **リソース モデル:** Ping ジョブは専用の CPU コアではなくワーカー スレッドを利用します。これらにはジョブあたりのコア数の計算は適用されません。
* **タイムアウトと再試行:**失敗した ping ジョブは、最大**60 秒間**ワーカー スレッドを占有する可能性があります。最初に HTTP HEAD リクエスト (30 秒のタイムアウト) を試行します。これが失敗した場合は、HTTP GETリクエストを使用してすぐに再試行します (さらに 30 秒のタイムアウト)。
* **スケーリング:**サイズ設定の式は異なりますが、同じ原則が適用されます。大量の ping ジョブを処理し、 `pingJobs`キューが拡大しないようにするには、スケールアップまたはスケールアウト (あるいはその両方) が必要になる場合があります。スケールアップとは、ホストまたはネームスペースあたりの CPU リソースとメモリ リソースを増やすことを意味します。 スケール アウトとは、ping ランタイムのインスタンスを追加することを意味します。これは、より多くのホスト、より多くのネームスペース、または[同じネームスペース内で](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#scaling-out-with-multiple-sjm-instances)さらに多くのジョブ マネージャーをデプロイすることによって実行できます。 あるいは、Kubernetes の`ping-runtime`使用すると、デプロイメントごとにより[多くのレプリカを](https://github.com/newrelic/helm-charts/blob/41c03e287dafd41b9c914e5a6c720d5aa5c01ace/charts/synthetics-job-manager/values.yaml#L173)設定できます。

## Sizing considerations for Kubernetes and OpenShift [#kubernetes-sizing]

Kubernetes および OpenShift 合成ジョブ マネージャーによって使用される各ランタイムは、 [Helm チャート](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager)で値を設定することで個別にサイズを変更できます。[node-api-runtime](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager/charts/node-api-runtime)と[node-browser-runtime は、](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager/charts/node-browser-runtime) `parallelism`と`completions`設定の組み合わせを使用して個別にサイズ設定されます。

* The `parallelism` setting controls how many pods of a particular runtime run concurrently.
* The `completions` setting controls how many pods must complete before the `CronJob` starts another Kubernetes Job for that runtime.

### How to Size Your Deployment: A Step-by-Step Guide

Your goal is to configure enough parallelism to handle your job load without exceeding the throughput limit of your SJM instances.

### Step 1: Estimate Your Required Workload

**Completions:** This determines how many runtime pods should complete before a new Kubernetes Job is started.

First, determine your private location&apos;s average job execution duration and job rate. Use `executionDuration` as it most accurately reflects the pod&apos;s active runtime.

```sql
-- Get average job execution duration (in seconds)
FROM SyntheticCheck
SELECT average(executionDuration / 60e3) AS 'D_avg_m'
WHERE typeLabel != 'Ping' AND location = 'YOUR_PRIVATE_LOCATION'
FACET typeLabel SINCE 1 hour ago
```

$$ Completions = \frac5D\_avg,m $$

Where $D\_avg,m$ is your **average job execution duration in seconds**.

**Required Parallelism:** This determines how many workers (pods) you need running concurrently to handle your 5-minute job load.

```sql
-- Get jobs per 5 minutes
FROM SyntheticCheck
SELECT rate(uniqueCount(id), 5 minutes) AS 'N_m'
WHERE typeLabel != 'Ping' AND location = 'YOUR_PRIVATE_LOCATION'
FACET typeLabel SINCE 1 hour ago
```

$$ P\_req = \fracN\_mCompletions $$

Where $N\_m$ is your **number of jobs per 5 minutes**. This $P\_req$ value is your **target total parallelism**.

### Step 2: Check Against the Single-SJM Throughput Limit

**Max Parallelism:** This determines how many workers (pods) your SJM can effectively utilize.

$$ P\_max \approx 15 \cdot D\_avg,m $$

This $P\_max$ value is your **system limit for one SJM Helm deployment**.

<Callout variant="tip">
  The above queries are based on current results. If your private location does not have any results or the job manager is not performing at its best, query results may not be accurate. In that case, start with the examples in the table below and adjust until your queue is stable.
</Callout>

<Callout variant="tip">
  A key consideration is that a **single SJM instance has a maximum throughput of approximately 15 heavyweight jobs per minute**. You can calculate the maximum effective parallelism ($P\_max$) a single SJM can support before hitting this ceiling.
</Callout>

### Step 3: Compare, Configure, and Scale

Compare your **required** parallelism ($P\_req$) from Step 1 to the **maximum** parallelism ($P\_max$) from Step 2.

<DNT>
  **Scenario A:** $P\_req \le P\_max$
</DNT>

* **Diagnosis:** Your job load is within the limit of a single SJM instance.

* **Action:**

  1. You will deploy **one** SJM Helm release.
  2. In your Helm chart `values.yaml`, set `parallelism` to your calculated $P\_req$.
  3. Set `completions` to your calculated **Completions**. For improved efficiency, this value should typically be 6-10x your `parallelism` setting.

<DNT>
  **Scenario B:** $P\_req &gt; P\_max$
</DNT>

* **Diagnosis:** Your job load **exceeds the \~15 jobs/minute limit** of a single SJM.

* **Action:**

  1. You must **scale out by deploying multiple, separate SJM Helm releases**.
  2. See the **[Scaling Out with Multiple SJM Deployments](#scaling-out-with-multiple-sjm-deployments)** section below for the correct procedure.
  3. **Do not** increase the `replicaCount` in your Helm chart.

### Step 4: Monitor Your Queue

After applying your changes, you must verify that your job queue is stable and not growing. A consistently growing queue means your location is still under-provisioned.

Run this query to check the queue&apos;s growth rate:

```sql
-- Check for queue growth (a positive value means the queue is growing)
SELECT derivative(jobManagerHeavyweightJobs, 1 minute) AS 'Heavyweight Queue Growth Rate (per min)'
FROM SyntheticsPrivateLocationStatus
WHERE name = 'YOUR_PRIVATE_LOCATION'
SINCE 1 hour ago TIMESERIES
```

If the &quot;Queue Growth Rate&quot; is consistently positive, you need to install more SJM Helm deployments (Scenario B) or re-check your `parallelism` settings (Scenario A).

### Configuration Examples and Tuning

The `parallelism` setting directly affects how many synthetics jobs per minute can be run. Too small a value and the queue may grow. Too large a value and nodes may become resource constrained.

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        例
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `parallelism=1` `completions=1`
      </td>

      <td>
        ランタイムは 1 分あたり 1 つの外形監視ジョブを実行します。 1 つのジョブが完了すると、 `CronJob`設定は次の瞬間に新しいジョブを開始します。 <DNT>**Throughput will be extremely limited with this configuration.**</DNT>
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=1` `completions=6`
      </td>

      <td>
        The runtime will execute 1 synthetics job at a time. After the job completes, a new job will start immediately. After 6 jobs complete, the `CronJob` configuration will start a new Kubernetes Job. <DNT>**Throughput will be limited.**</DNT> A single long-running synthetics job will block the processing of any other synthetics jobs of this type.
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=3` `completions=24`
      </td>

      <td>
        The runtime will execute 3 synthetics jobs at once. After any of these jobs complete, a new job will start immediately. After 24 jobs complete, the `CronJob` configuration will start a new Kubernetes Job. <DNT>**Throughput is much better with this or similar configurations.**</DNT>
      </td>
    </tr>
  </tbody>
</table>

If your `parallelism` setting is working well (keeping the queue at zero), setting a higher `completions` value (e.g., 6-10x `parallelism`) can improve efficiency by:

* Accommodating variability in job durations.
* Reducing the number of completion cycles to minimize the &quot;nearing the end of completions&quot; inefficiency where the next batch can&apos;t start until the final job from the current batch completes.

`completions` 値が大きすぎないように注意することが重要です。大きすぎると、CronJob で次のような警告イベントが発生します。

```sh
8m40s     Warning   TooManyMissedTimes   cronjob/synthetics-node-browser-runtime   too many missed start times: 101. Set or decrease .spec.startingDeadlineSeconds or check clock skew
```

<Callout variant="tip">
  New Relic外形監視ジョブ マネージャー ファイルに加えた変更については責任を負いません。
</Callout>

### Scaling out with multiple SJM deployments

To scale beyond the \~15 jobs/minute throughput of a single SJM, you must install **multiple, separate SJM Helm releases**.

<Callout variant="important">
  **Do not use `replicaCount` to scale the job manager pod.** You **cannot** scale by increasing the `replicaCount` for a single Helm release. The SJM architecture requires a 1:1 relationship between a runtime pod and its parent SJM pod. If runtime pods send results back to the wrong SJM replica (e.g., through a Kubernetes service), those results will be lost.
</Callout>

The correct strategy is to deploy multiple SJM instances, each as its own Helm release. Each SJM will compete for jobs from the same private location, providing load balancing, failover protection, and an increased total job throughput.

#### Simplified Scaling Strategy

Assuming $P\_req &gt; P\_max$ and you need to scale out, you can simplify maintenance by treating each SJM deployment as a fixed-capacity unit.

1. **Set Max Parallelism:** For *each* SJM, set `parallelism` to the same $P\_max$ value. This maximizes the potential throughput of each SJM.

2. **Set Completions:** For *each* SJM, set `completions` to a fixed value as well. The $P\_req$ formula from [Step 1](#step-1-estimate-your-required-workload) can be modified to estimate completions by substituting in the $P\_max$ value:

   $$ Completions = \fracN\_mP\_max $$

   Where $N\_m$ is your **number of jobs per 5 minutes**. Adjust as needed after deploying to target a 5 minute Kubernetes job age per runtime, i.e., node-browser-runtime and node-api-runtime.

3. **Install Releases:** Install as many separate Helm releases as you need to handle your total $P\_req$. For example, if your total $P\_req$ is 60 and you&apos;ve fixed each SJM&apos;s `parallelism` at 20 ($P\_max$ from [Step 2](#step-2-check-against-the-single-sjm-throughput-limit)), you would need **three** separate Helm deployments to meet the required job demand.

4. **Monitor and Add:** Monitor your job queue (see [Step 4](#step-4-monitor-your-queue)). If it starts to grow, simply install another Helm release (e.g., `sjm-delta`) using the same fixed configuration.

By fixing parallelism and completions to static values based on $P\_max$, increasing or decreasing capacity becomes a simpler process of **adding or removing Helm releases**. This helps to avoid wasting cluster resources on a parallelism value that is higher than the SJM can effectively utilize.

#### Installation Example

When installing multiple SJM releases, you must provide a **unique name for each release**. All instances must be configured with the **same private location key**.

Setting the `fullnameOverride` is highly recommended to create shorter, more manageable resource names. For example, to install two SJMs named `sjm-alpha` and `sjm-beta` into the `newrelic` namespace (both using the same `values.yaml` with your fixed parallelism and completions):

```sh
# Install the first SJM deployment
helm upgrade --install sjm-alpha newrelic/synthetics-job-manager \
  -n newrelic \
  -f values.yaml \
  --set fullnameOverride=sjm-alpha \
  --set ping-runtime.fullnameOverride=sjm-alpha-ping \
  --set node-api-runtime.fullnameOverride=sjm-alpha-api \
  --set node-browser-runtime.fullnameOverride=sjm-alpha-browser
```

```sh
# Install the second SJM deployment to add capacity
helm upgrade --install sjm-beta newrelic/synthetics-job-manager \
  -n newrelic \
  -f values.yaml \
  --set fullnameOverride=sjm-beta
  --set ping-runtime.fullnameOverride=sjm-beta-ping \
  --set node-api-runtime.fullnameOverride=sjm-beta-api \
  --set node-browser-runtime.fullnameOverride=sjm-beta-browser
```

You can continue this pattern (`sjm-charlie`, `sjm-delta`, etc.) for as many SJMs as needed to keep the job queue from growing.