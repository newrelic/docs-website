---
title: データの取り込みを最適化する
tags:
  - Observability maturity
  - Operational efficiency
  - Data ingest cost
  - Sampling rate
  - Drop rules
  - Observability as code
  - Value drivers
  - Bill and Usage Data
  - Data ingest cost
metaDescription: 'The third part of New Relic''s data ingest governance series on optimizing how you ingest and use your telemetry data: this focuses on optimizing data ingest.'
translationType: machine
---

import omaoedgOptimizingIcon from 'images/oma-oe-dg_icon_optimizing.webp'

import omaoedgValueDriverUptime from 'images/oma-oe-dg_diagram_value-driver-uptime.webp'

import omaoedgValueDriverCustomer from 'images/oma-oe-dg_diagram_value-driver-customer.webp'

import omaoedgValueDriverInnovation from 'images/oma-oe-dg_diagram_value-driver-innovation.webp'

import omaoedgKubeStateMetrics from 'images/oma-oe-dg_diagram_update-k8s-kube-state-metrics.webp'

import omaoedgKubernetesScrapeInterval from 'images/oma-oe-dg_diagram_update-k8s-scrape-interval.webp'

<img
  src={omaoedgOptimizingIcon}
  alt="Optimize"
  style={{ height: '96px', width: '120px', verticalAlign: 'middle', horizontalAlign: 'right'}}
/>

**データ インジェスト ガバナンスは、** 組織によって収集されたテレメトリ データの最適な価値を得るためのプラクティスです。これは、多数のビジネス ユニットとワーキング グループを持つ複雑な組織にとって特に重要です。これは、New Relic データの取り込みを最適化するための 4 部構成のガイドの 3 部目であり、 [オブザーバビリティの成熟度に関するシリーズ](/docs/new-relic-solutions/observability-maturity/introduction)の一部です。

## 始める前に [#before-start]

このガイドには、データの取り込みを最適化するための詳細な推奨事項が含まれています。このガイドを使用する前に、 [一般的なデータ管理ドキュメント](/docs/data-apis/manage-data/manage-your-data)を確認することをお勧めします。

## 望ましい結果 [#desired-outcome]

データインジェストを最適化することにより、データの観測可能な価値を最大化します。不要なインジェストデータを削減し、予算内に収まるようにします。

## プロセス [#process]

このプロセスには、次の手順が含まれます。

* [観測可能な目標に優先順位をつける](#prioritize-objectives)
* [最適化プランの策定](#develop-plan)
* [データ削減のテクニックを使って、計画を実行する](#use-reduction-techniques)

これらの手順について詳しく説明します。

## 観測可能な目標に優先順位をつける [#prioritize-objectives]

データ取り込みガバナンスフレームワークの最も重要な部分の1つは、収集されたテレメトリを**可観測性の値の推進要因**と整合させることです。新しいテレメトリを構成するときの主な可観測性の目的を確実に理解する必要があります。

新しい遠隔測定を導入する場合、それが観測可能なソリューション全体に何をもたらすかを理解する必要があります。新しいデータは他のデータと重なるかもしれません。もし、どの重要な目的にも合致しないテレメトリーを導入するのであれば、そのデータの導入は再考する必要があるかもしれません。

目的は以下の通りです。

* 社内SLAを満たす
* 外部SLAを満たす
* 機能革新のサポート（A / Bパフォーマンスおよび導入テスト）
* カスタマーエクスペリエンスのモニター
* ベンダーと社内サービスプロバイダのSLAを遵守する
* ビジネスプロセスのヘルスモニタリング
* その他のコンプライアンス要件

これらの目標に沿うことで、あるデータセットを別のデータセットよりも優先させるという柔軟かつ直感的な判断が可能になり、新しいプラットフォームやサービスのインストルメント化を行う際に、どこから手をつければよいのか、チームのガイド役を務めることができます。

## 最適化プランの策定 [#develop-plan]

このセクションでは、2つの主要な仮定を行います。

* 「[データ取り込みのベースライン」](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining)セクションのツールとテクニックを使用して、データの出所を適切に把握できます。
* [可観測性の成熟度の値のドライバー](/docs/new-relic-solutions/observability-maturity/introduction)をよく理解している。これは、テレメトリのグループに値と優先順位を適用する上で非常に重要です。

以下の例は、テレメトリーインジェストをどのように評価し、予算内に収めるために必要な、時には難しい決断を下すかをイメージするのに役立ちます。これらの例はそれぞれバリュードライバーに焦点を当てようとしていますが、ほとんどのインスツルメンテーションは1つ以上のバリュードライバーに貢献しています。これはデータインジェストガバナンスの最も難しい部分です。

<CollapserGroup>
  <Collapser
    id="case-study-1"
    title="例1．稼働率・信頼性の重視"
  >
    アカウントは、予算よりも約20％多く取り込みます。彼らはマネージャーから消費を減らす方法を見つけるように頼まれました。それらの最も重要なバリュードライバーは**、稼働時間、パフォーマンス、および信頼性**です。

    <img
      src={omaoedgValueDriverUptime}
      alt="Observability value drivers with a focus on uptime and reliability"
      title="Observability value drivers with a focus on uptime and reliability"
      style={{width: "400px"}}
    />

    <figcaption>
      稼働時間と信頼性に重点を置いた可観測性バリュードライバー。
    </figcaption>

    彼らの遺産は以下の通りです。

    * <InlinePopover type="apm"/>(開発、ステージング、本番)

    * ディストリビューティッド（分散）トレーシング

    * ブラウザ

    * 100台のホストのインフラストラクチャ監視

    * K8sのモニタリング（dev, staging, prod）

    * ログ（dev, staging, prod - debugを含む）

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * デバッグログを省略する（問題がある場合はオンにできることを承知で）（5%節約できる）
        * Kubernetesクラスターエクスプローラーを表示するために必要のないいくつかのK8s状態メトリックを省略します（10％節約）
        * 新機能のA/Bテストを多く行っていた頃に収集していたカスタムブラウザのイベントを削除（10%節約可能）
      </Callout>

      これらの変更を実行した後、チームは予算を5％下回るようになり、NPMパイロットを実行するためのスペースが解放されました。彼らのマネージャーは、大幅な稼働時間と信頼性の可観測性を失わないことに満足しています。

      <Callout
        variant="IMPORTANT"
        title="最終結果"
      >
        * 当初予算より5%減
        * 稼働時間、パフォーマンス、および信頼性の目標を提供するNPMパイロット用に作成されたヘッドルーム
        * 稼働時間と信頼性の可観測性の損失を最小限に抑える
      </Callout>
  </Collapser>

  <Collapser
    id="case-study-2"
    title="例2:カスタマーエクスペリエンスへの注力"
  >
    モバイルモニタリングとブラウザモニタリングに重点を置いた新しいユーザー向けプラットフォームを担当するチームは、予算を50％上回っています。摂取量を適切なサイズにする必要がありますが、**カスタマーエクスペリエンス**の可観測性を犠牲にしないことに固執しています。

    <img
      src={omaoedgValueDriverCustomer}
      alt="Observability value drivers with a focus on customer experience"
      title="Observability value drivers with a focus on customer experience"
      style={{width: "400px"}}
    />

    <figcaption>
      **カスタマーエクスペリエンス**に焦点を当てた可観測性バリュードライバー
    </figcaption>

    彼らの遺産は以下の通りです。

    * モバイル
    * ブラウザ
    * APM
    * ディストリビューティッド（分散）トレーシング
    * プロセスサンプルを含む30台のホスト上のインフラ
    * バックエンドの非同期プロセスのサーバーレス監視
    * そのサーバーレス機能からのログ
    * 各種クラウドインテグレーション

    <Callout
      variant="IMPORTANT"
      title="最適化計画"
    >
      * サーバーレスのログを省略する（基本的にLambdaとの連携で得られるものと冗長になっている）
      * そのホストのプロセスのサンプルレートを1分ごとに減少させる
      * DEV環境でのサンプルデータのドロップ処理
      * New Relic infra agentが提供する他のインフラ監視と冗長性が高いEC2統合をオフにする。
    </Callout>

    <Callout
      variant="IMPORTANT"
      title="最終結果"
    >
      * 当初予算より5％オーバー
      * ピークシーズンを乗り切るのに十分
      * 顧客体験の観測可能性を損なわない
    </Callout>

    変更を実行した後、元の予算をわずか5％上回っていますが、ピークシーズンを乗り切るにはこれで十分であると彼らは結論付けています。
  </Collapser>

  <Collapser
    id="case-study-3"
    title="例3：イノベーションへの注力"
  >
    あるチームが、大規模なPythonモノリスを4つのマイクロサービスにリファクタリングしている最中です。モノリスは、顧客データベースやキャッシュレイヤーなど、多くのインフラを新しいアーキテクチャと共有しています。彼らは予算を70%超過しており、モノリスを正式に廃止するまであと2ヶ月しかない。

    <img
      src={omaoedgValueDriverInnovation}
      alt="Observability value drivers with a focus on Innovation and Growth"
      title="Observability value drivers with a focus on Innovation and Growth"
      style={{width: "400px"}}
    />

    <figcaption>
      **イノベーションと成長**に焦点を当てた可観測性の価値ドライバー。
    </figcaption>

    彼らの遺産は以下の通りです。

    * K8sの監視（マイクロサービス）

    * New Relic ホスト監視 (monolith)

    * APM（マイクロサービス、ホスト監視）

    * 分散トレース(マイクロサービス、ホスト監視)

    * Postgresql（共有）

    * Redis(共有)

    * MSSQL (マイクロサービスアーキテクチャのための将来のDB)

    * ロードバランサーのログ取得（マイクロサービス、ホスト監視）

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * ロードバランサーのログを5xxレスポンスコードのみ監視するように設定する（monolith）
        * モノリスを実行しているホストの`ProcessSample` 、 `StorageSample` 、および`NetworkSample`から60秒のカスタムサンプルレート
        * 現在、新しいアーキテクチャではMSSQLを使用していないため、MSSQLの監視を無効にします。
        * モノリスの分散トレースは、マイクロサービスアーキテクチャではあまり役に立たないので、無効にしてください。
      </Callout>

      <Callout
        variant="IMPORTANT"
        title="最終成果"
      >
        * 当初予算を1％下回る
        * **イノベーションと成長**の可観測性を失うことはありません
      </Callout>
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  使い慣れたタスク管理ツールで計画を追跡することをお勧めします。これは、最適化計画を管理し、各最適化タスクがもたらす効果を理解するのに役立ちます。この [データ最適化計画テンプレート](https://docs.google.com/spreadsheets/d/1CimLpALwl1Z9f41vzbNWx00bGcED9XPV3s4ROqVEnr0/copy)を使用できます。
</Callout>

## データ削減のテクニックを使って、計画を実行する [#use-reduction-techniques]

この段階で、アカウント内のすべての種類のテレメトリと、それがバリュードライバーとどのように関連しているかについて考えました。このセクションでは、さまざまなテレメトリタイプを削減する方法に関する詳細な技術的手順と例を提供します。

データ削減に取り組むには、主に2つの方法があります。

* 構成を通じて
* ドロップルールを使用して

### コンフィギュレーションによる最適化 [#optimization-through-configuration]

このセクションには、データのレポートと取り込みを最適化するためにNewRelicの機能を構成するさまざまな方法が含まれています。

<CollapserGroup>
  <Collapser
    id="apm-agent"
    title="APMエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象取引
      * エラー活動
      * カスタムイベント
    </Callout>

    APMエージェントが生成するデータ量は、いくつかの要因によって決定される。

    * アプリケーションによって生成される有機トラフィックの量（たとえば、1日に100万回呼び出されるアプリケーションと等しいすべてのものは、1日に1000回呼び出されるアプリケーションよりも多くのデータを生成します）
    * 基礎となるトランザクションデータ自体のいくつかの特徴（URLの長さと複雑さ）
    * アプリケーションがデータベースクエリーを報告しているかどうか
    * アプリケーションに多くの（または任意の）カスタム属性を持つトランザクションがあるかどうか
    * アプリケーションのエラー量
    * アプリケーションエージェントが分散トレース用に設定されているかどうか

    ### 容量の管理

    ビジネスをサポートするには、アプリケーションへのすべての呼び出しが必要であると想定できますが、アーキテクチャ全体でより節約できる可能性があります。極端な場合、クライアントによって10秒ごとに呼び出されるユーザープロファイルマイクロサービスがある場合があります。これにより、一部のユーザー情報が他のクライアントによって更新された場合の遅延を減らすことができます。ただし、私たちが持っている1つの手段は、このサービスへの呼び出しの頻度を、たとえば1分ごとに減らすことです。

    ### カスタムアトリビュート

    APM API [`addCustomParameter`](https://developer.newrelic.com/collect-data/custom-attributes/)への呼び出しを使用して追加された[カスタム属性](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/)は、追加の属性をトランザクション ペイロードに追加します。これらは有用な場合が多いですが、アプリケーションのロジックと優先度が変化すると、データの価値が低下したり、時代遅れになったりすることさえあります。

    Java エージェントは、デフォルトで次の`request.headers`をキャプチャします。

    * `request.headers.referer`
    * `request.headers.accept`
    * `request.headers.contentLength`
    * `request.headers.host`
    * `request.headers.userAgent`

    開発者は、 `addCustomParameter`を使用して追加情報（より詳細なヘッダーになる可能性があります）をキャプチャすることもできます。

    APMに関連して利用できる豊富な構成の例については、 [Javaエージェントのドキュメント](/docs/apm/agents/java-agent/attributes/java-agent-attributes/#requestparams)を参照してください。

    ### エラーイベント

    エラーがAPMによってどのように処理されるかを決定することが可能です。これにより、場合によってはデータの量を減らすことができます。たとえば、現時点では削除できない大量の無害なエラーが発生する可能性があります。

    `collect` 、 `ignore` 、または`mark as expected`の機能があります。詳細については、「 [APMエラーの管理](/docs/apm/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected)」を参照してください。

    ### データベースクエリ

    APMインスタンスで大きく変動するのは、データベースの呼び出し回数と、どのような設定をしたかという点です。データベースクエリの監視をどの程度冗長にするかは、かなりコントロールできます。これらのクエリは、トランザクショントレースページに表示されます。

    一般的なデータベースクエリの設定変更は以下の通りです。

    * [難読化されたクエリデータではなく、生のクエリデータを収集する、またはクエリの収集をオフにする](/docs/apm/transactions/transaction-traces/configure-transaction-traces#record-sql)
    * スタックトレースの閾値の変更
    * クエリの説明プラン収集をオンにする

    詳細については、「 [トランザクション追跡データベース クエリ ページ」](/docs/apm/transactions/transaction-traces/transaction-traces-database-queries-page/#settings)を参照してください。

    ### イベント制限の設定

    APMとモバイルエージェントには、収穫サイクルごとに報告できるイベントの数に制限があります。制限がない場合、送信されるイベントの数が非常に多いと、アプリケーションまたはNewRelicのパフォーマンスに影響を与える可能性があります。制限に達すると、エージェントは、収穫サイクル全体のイベントの代表的なサンプルを提供するために、イベントのサンプリングを開始します。エージェントが異なれば、制限も異なります。

    キャップされ、サンプリングの対象となるイベントは以下の通りです。

    * エージェントAPIを介して報告されたカスタムイベント（たとえば、.NETエージェントの`RecordCustomEvent` ）
    * `Mobile`
    * `MobileCrash`
    * `MobileHandledException`
    * `MobileRequest`
    * `Span` （分散トレースサンプリングを参照）
    * `Transaction`
    * `TransactionError`

    ほとんどのエージェントには、サンプリングされたトランザクションのイベント制限を変更するための構成オプションがあります。たとえば、Java エージェントは[`max_samples_stored`](/docs/apm/agents/java-agent/configuration/java-agent-configuration-config-file/#ae-max_samples_stored)を使用します。`max_samples_stored`のデフォルト値は`2000`で、最大値は`10000`です。この値は、エージェント インスタンスから 60 秒ごとにレポートできるサンプル イベントの数を制御します。

    イベントサンプリング制限の完全な説明については、[イベント](/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling)制限を参照してください。

    NRQL [`EXTRAPOLATE`演算子](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#extrapolate)を使用して、サンプリングされたイベントを補正できます。

    サンプリングの方法を変更する前に、以下の注意点と推奨事項をお読みください。

    * レポートするイベントが多いほど、エージェントが使用するメモリも多くなります。
    * 通常、エージェントのイベントレポートの制限を上げることなく、必要なデータを取得できます。
    * ペイロードサイズの制限は1MB（10 ^ 6バイト）（圧縮）であるため、イベントの数は引き続きその制限の影響を受ける可能性があります。イベントがドロップされているかどうかを確認するには、エージェントログで`413 HTTP`ステータスメッセージを確認してください。

    ### ログサンプリングレート

    New Relic APM言語エージェントの新しいバージョンでは、ログをNewRelicに直接転送できます。場合によっては、各APMエージェントインスタンスからのログスパイクの大きさの制限を管理したい場合があります。

    APMエージェントのログサンプリングの詳細については、[ログフォワーダー](#log-forwarders)を参照してください。

    ### トランザクショントレース

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 接続サービス数
      * 接続サービスごとの監視対象メソッドコール数
    </Callout>

    APMでは、[トランザクショントレース](/docs/apm/transactions/transaction-traces/transaction-traces)によって、アプリケーションのトランザクションやデータベースコールについての、綿密な詳細を記録します。トランザクショントレースのデフォルト設定を編集することができます。

    これは、 [トランザクション追跡構成](/docs/apm/transactions/transaction-traces/configure-transaction-traces)によって高度に構成することもできます。多くの場合、構成可能性のレベルとモードは言語固有です。

    サーバーサイドの設定を使用して利用できるトランザクショントレースの設定は、使用するNew Relicエージェントによって異なります。UI には、それぞれの説明が記載されています。UI での設定には、以下のものが含まれる場合があります。

    * トランザクショントレーシングと閾値
    * 記録レベルと入力フィールドなどの、SQLを記録する
    * SQLとスタックトレースの閾値をログする
    * SQLクエリプランと閾値
    * HTTPコードとエラークラスなどの、エラーの収集
    * 遅いクエリのトレース
    * スレッドプロファイラー

    ### ディストリビューティッド（分散）トレーシング

    分散トレース構成には、言語固有の違いがいくつかあります。

    分散トレースは、必要に応じて無効にすることができます。これはJavaエージェント`newrelic.yml`の例です：

    ```yml
    distributed_tracing:
        enabled: false
    ```

    これはnode.jsの例です `newrelic.js`

    ```js
    distributed_tracing: {
      enabled: false
    }
    ```

    データ量は、 [InfiniteTracing](/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing)を使用しているかどうかによっても異なります。

    APM エージェントの標準分散トレース (上記) はトレースの最大 10% をキャプチャしますが、すべてのデータを分析して最も関連性の高いトレースを見つけたい場合は、無限トレースを設定できます。標準の分散トレースに代わるこの方法は、すべての APM 言語エージェントで利用できます。

    月間の摂取量を少しでも増やすための主なパラメータは以下の通りです。

    * トレースオブザーバーの監視を構成する
    * スパン属性トレースフィルタを設定する
    * ランダムトレースフィルターを構成する
  </Collapser>

  <Collapser
    id="browser-agent"
    title="Browserエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ページロード
      * Ajaxコール
      * エラー活動
    </Callout>

    [ブラウザエージェントバージョン1211](/docs/release-notes/new-relic-browser-release-notes/browser-agent-release-notes)以降の場合、ページによって行われたすべてのネットワーク要求は`AjaxRequest`イベントとして記録されます。アプリケーション設定UIページの拒否リスト構成オプションを使用して、レコードイベントを記録する要求をフィルタリングできます。このフィルターに関係なく、すべてのネットワークリクエストはメトリックとしてキャプチャされ、AJAXページで利用できます。

    ### 拒否リストの使用

    リクエストは3つの方法でブロックされます。

    * すべての`AjaxRequest`イベントの記録をブロックするには、アスタリスク`*`をワイルドカードとして追加します。
    * ドメインへの`AjaxRequest`イベントの記録をブロックするには、ドメイン名のみを入力します。例： `example.com`
    * 特定のドメインとパスへの`AjaxRequest`イベントの記録をブロックするには、ドメインとパスを入力します。例： `example.com/path`
    * 拒否リストでは、URLのプロトコル、ポート、サーチ、ハッシュは無視されます。

    追加したフィルターが期待どおりに機能するかどうかを検証するには、フィルターに一致する`AjaxRequest`イベントに対して NRQL クエリを実行します。

    ### 拒否リストにアクセスする

    アプリケーションがイベントの作成からフィルタリングするURLの拒否リストを更新するには、アプリ設定のUIページに移動します。

    1. **[one.newrelic.com](https://one.newrelic.com/all-capabilities)**にアクセスし、をクリックし、\[ブラウザ] をクリックします。
    2. アプリを選択します。
    3. 左のナビゲーションで、 **アプリの設定** をクリックします。
    4. **Ajaxリクエスト拒否リスト**の下に、適用するフィルターを追加します。
    5. **Save application settings** を選択して、エージェントの設定を更新します。
    6. ブラウザエージェントを再デプロイします（関連するAPMエージェントを再起動するか、ブラウザのコピー/貼り付けのインストールを更新します）。

    ### バリデーション

    ```sql
    FROM AjaxRequest SELECT * WHERE requestUrl LIKE `%example.com%`
    ```
  </Collapser>

  <Collapser
    id="mobile-agent"
    title="モバイルエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 月間アクティブユーザー数
      * クラッシュイベント
      * ユーザーごとのイベント数
    </Callout>

    ### Android

    エージェントを呼び出すための呼び出しを含むすべての設定は、 `MainActivity`クラスの`onCreate`メソッドで呼び出されます。設定を変更するには、次の2つの方法のいずれかで設定を呼び出します（設定でサポートされている場合）。

    ```java
    NewRelic.disableFeature(FeatureFlag.DefaultInteractions);
    NewRelic.enableFeature(FeatureFlag.CrashReporting);
    NewRelic.withApplicationToken(NEW_RELIC_TOKEN).start(this.getApplication());
    ```

    [分析設定](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#analytics-settings)は、イベントデータの収集を有効または無効にします。これらのイベントはNewRelicに報告され、**クラッシュ分析**ページで使用されます。

    [エージェントのログ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#logging-settings-logging)を多かれ少なかれ冗長になるように構成することもできます。

    ### iOS

    Androidと同様に、New RelicのiOS構成では、 [機能フラグ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags)を有効または無効にできます。

    以下の機能フラグを設定することができます。

    #### クラッシュとエラーの報告

    * `NRFeatureFlag_CrashReporting`
    * `NRFeatureFlag_HandleExceptionEvents`
    * `NRFeatureFlag_CrashReporting`

    #### ディストリビューティッド（分散）トレーシング

    * `NRFeatureFlag_DistributedTracing`

    #### 相互作用

    * `NRFeatureFlag_DefaultInteractions`
    * `NRFeatureFlag_InteractionTracing`
    * `NRFeatureFlag_SwiftInteractionTracing`

    #### ネットワーク機能フラグ

    * `NRFeatureFlag_ExperimentalNetworkInstrumentation`
    * `NRFeatureFlag_NSURLSessionInstrumentation`
    * `NRFeatureFlag_NetworkRequestEvents`
    * `NRFeatureFlag_RequestErrorEvents`
    * `NRFeatureFlag_HttpResponseBodyCapture`

    詳細については、 [「機能フラグ」](/docs/mobile-monitoring/new-relic-mobile/mobile-sdk/configure-settings/)を参照してください。
  </Collapser>

  <Collapser
    id="infrastructure-agent"
    title="インフラストラクチャー・エージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ホストとコンテナの監視
      * コアイベントのサンプリングレート
      * プロセスサンプル構成
      * カスタムアトリビュート
      * インストールされているオンホストインテグレーションの数および種類
      * ログ転送の設定
    </Callout>

    New Relic の[インフラストラクチャ エージェント構成ファイル](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings)には、取り込み量を制御する強力な方法がいくつか含まれています。最も重要な取り込み制御は、サンプリング レートの構成です。調整可能ないくつかの異なるサンプリング レート構成があります。さらに、正規表現を作成して、 `ProcessSample`や`NetworkSample`などの特定のコレクターから何を収集するかを制御できます。

    ### 構成可能なサンプリングレート

    インフラストラクチャで設定可能なサンプリングレートは多数ありますが、最も一般的に使用されるのはこれらのレートです。

    | パラメータ                         | デフォルト | 無効化 |
    | ----------------------------- | ----- | --- |
    | `metrics_storage_sample_rate` | 5     | -1  |
    | `metrics_process_sample_rate` | 20    | -1  |
    | `metrics_network_sample_rate` | 10    | -1  |
    | `metrics_system_sample_rate`  | 5     | -1  |
    | `metrics_nfs_sample_rate`     | 5     | -1  |

    ### プロセスサンプル

    プロセスサンプルは、インフラストラクチャエージェントからの単一の最も大量のデータソースになる可能性があります。これは、ホスト上で実行中のプロセスに関する情報を送信するためです。これらはデフォルトで無効になっていますが、次のように有効にできます。

    ```yaml
    enable_process_metrics: true
    ```

    これは、 `metrics_process_sample_rate`を`-1`に設定するのと同じ効果があります。

    デフォルトでは、メモリ不足のプロセスはサンプリングから除外されます。詳細については、 `disable-zero-mem-process-filter`を参照してください。

    `include_matching_metrics`を設定することで、New Relicに送信されるデータの量を制御できます。これにより、メトリック[属性](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql#naming-conventions)の値に基づいてメトリックデータの送信を制限できます。

    メトリックの属性のいずれかにリテラルまたは部分的な値を定義して、メトリック データを含めます。たとえば、 `process.name`が`^java`正規表現と一致するすべてのプロセスの`host.process.cpuPercent`を送信するように選択できます。

    この例では、実行ファイルと名前を使ってプロセスメトリクスを含めています。

    ```yaml
      include_matching_metrics:             # You can combine attributes from different metrics
        process.name:
          - regex "^java"                   # Include all processes starting with "java"
        process.executable:
          - "/usr/bin/python2"              # Include the Python 2.x executable
          - regex "\\System32\\svchost"     # Include all svchost executables
    ```

    また、このフィルターはKubernetesの統合にも使用できます。

    ```yaml
      env:
        - name: NRIA_INCLUDE_MATCHING_METRICS
          value: |
            process.name:
              - regex "^java"
            process.executable:
              - "/usr/bin/python2"
              - regex "\\System32\\svchost"
    ```

    ### ネットワークインターフェースフィルタ

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視するネットワーク・インターフェース数
    </Callout>

    この設定では、シンプルなパターンマッチングメカニズムを使用しており、いずれかのパターンに続く特定の文字または数字のシーケンスで始まるインターフェースを探すことができます。

    * `{name}[other characters]`
    * `[number]{name}[other characters]`、ここで`index-1`オプションを使用して名前を指定します

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    Linuxのデフォルトのネットワークインターフェイスフィルタ。

    * `dummy` 、 `lo` 、 `vmnet` 、 `sit` 、 `tun` 、 `tap` 、または `veth`
    * `tun`またはを含むネットワークインターフェース `tap`

    Windowsのデフォルトのネットワークインターフェイスフィルタ。

    * `Loop` 、 `isatap` 、またはで始まるネットワークインターフェイス `Local`

    デフォルトを上書きするには、設定ファイルに独自のフィルタを記述します。

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    ### カスタムアトリビュート

    [カスタム属性は、](/docs/data-apis/custom-data/custom-events/collect-custom-attributes) インフラストラクチャ エージェントからのデータに注釈を付けるために使用されるキーと値のペア (他のツールのタグと同様) です。このメタデータを使用して、ホスト グループを構築し、結果をグループ化し、データに注釈を付けることができます。たとえば、マシンの環境 (ステージングまたは運用)、マシンがホストするサービス (ログイン サービスなど)、またはそのマシンを担当するチームを指定できます。

    からのカスタム属性の例 `newrelic.yml`

    ```yaml
    custom_attributes:
      environment: production
      service: billing
      team: alpha-team
    ```

    これらは強力で便利ですが、データが適切に整理されていないか、何らかの形で廃止されている場合は、これらの合理化を検討する必要があります。
  </Collapser>

  <Collapser
    id="k8s-integration"
    title="Kubernetesインテグレーション"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視された`pods`と`containers`の数
      * kubeステートメトリクスの収集頻度と数
      * クラスタごとに生成されるログ
    </Callout>

    Kubernetesのような複雑で分散型のシステムが、多くのテレメトリを高速に生成する可能性があることは驚くべきことではありません。 Kubernetesでデータの取り込みを管理するための優れたアプローチがいくつかあります。 K8sデプロイメントでコードとして可観測性を使用している場合、これらは非常に簡単です。 K8の取り込みを減らすことを決定する前に、このKubernetesデータ取り込み分析ダッシュボードをインストールすることを強くお勧めします。このダッシュボードを入手するには、 [インフラストラクチャ統合のクイックスタート](https://newrelic.com/instant-observability/infrastructure-integrations-data-analysis/8e31a0ae-81c0-4df0-a119-a0ada9ec16fa)を参照してください。

    ### スクレイプ間隔

    可観測性の目的に応じて、スクレイプ間隔の調整を検討できます。デフォルトは15秒です。現在、Kubernetesクラスターエクスプローラーは45秒ごとにのみ更新されます。 K8sデータの主な用途がKCEの視覚化をサポートすることである場合は、スクレイプ間隔を20秒に変更することを検討してください。 15秒から20秒への変更は、大きな影響を与える可能性があります。これの管理の詳細については、 [Helm統合スクレイプ間隔のドキュメント](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#scrape-interval)を参照してください。

    ### 名前空間のフィルタリング

    Kubernetes Integration v3以降では、ラベルを付けることで、どの名前空間をスクレイピングするかをフィルタリングできます。デフォルトでは、すべての名前空間がスクレイピングされます。

    Kubernetesと同じように`namespaceSelector`を使用します。ラベルに一致する名前空間のみを含めるには、 `newrelic-infrastructure`セクションの下の`values-newrelic.yaml`に以下を追加して`namespaceSelector`を変更します。

    ```yaml
    common:
      config:
        namespaceSelector:
          matchLabels:
            key1 : "value1"
    ```

    この例では、ラベル`newrelic.com/scrape`が`true`に設定されている名前空間のみがスクレイプされます。

    ```yaml
    global:
      licenseKey: _YOUR_NEW_RELIC_LICENSE_KEY_
      cluster: _K8S_CLUSTER_NAME_

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchLabels:
              newrelic.com/scrape: "true"
    ```

    Kubernetes 一致式を使用して、名前空間を含めたり除外したりすることもできます。有効な演算子は次のとおりです。

    * の
    * ありませんで
    * 存在する
    * 存在しない

    `matchExpressions`セクションの一般的な構造は、次の行の 1 つまたは複数です。

    ```yaml
    {key: VALUE, operator: OPERATOR, values: LIST_OF_VALUES}
    ```

    完全な例を次に示します。

    ```yaml
    common:
      config:
        namespaceSelector:
          matchExpressions:
          - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    <Callout variant="tip">
      `matchExpresions`セクションには複数の行を含めることができ、式は連結されます。フィルターを適用するには、すべてが true である必要があります。ラベルと一致式については、 [こちら](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)で詳しく説明しています。
    </Callout>

    この例では、ラベル`newrelic.com/scrape`が`false`に設定された名前空間が除外されます。

    ```yaml
    global:
      licenseKey: _YOUR_NEW_RELIC_LICENSE_KEY_
      cluster: _K8S_CLUSTER_NAME_

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchExpressions:
            - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    [チャートのREADMEファイル](https://github.com/newrelic/nri-kubernetes/tree/main/charts/newrelic-infrastructure)で変更できる設定の完全なリストを参照してください。

    #### どの名前空間が除外されているかを知るにはどうすればよいですか？ [#excluded-namespaces]

    `K8sNamespace`サンプルのおかげで、クラスター内のすべての名前空間が一覧表示されます。`nrFiltered`属性は、名前空間に関連するデータをスクレイプするかどうかを決定します。

    このクエリを使用して、監視されているネームスペースを確認します。

    ```sql
    FROM K8sNamespaceSample SELECT displayName, nrFiltered
    WHERE clusterName = INSERT_NAME_OF_CLUSTER SINCE
    2 MINUTES AGO
    ```

    #### 除外された名前空間からどのデータが破棄されていますか？ [#namespaces-discarded-data]

    次のサンプルは、除外された名前空間では使用できません。

    * `K8sContainerSample`
    * `K8sDaemonsetSample`
    * `K8sDeploymentSample`
    * `K8sEndpointSample`
    * `K8sHpaSample`
    * `K8sPodSample`
    * `K8sReplicasetSample`
    * `K8sServiceSample`
    * `K8sStatefulsetSample`
    * `K8sVolumeSample`

    ### Kubeステートメトリクス

    Kubernetes cluster explorerで必要なのは、以下のkube state metrics（KSM）のみです。

    * コンテナデータ

    * クラスターデータ

    * ノードデータ

    * ポッドデータ

    * ボリュームデータ

    * APIサーバーデータ

      <sup>1</sup>

    * コントローラマネージャデータ

      <sup>1</sup>

    * ETCDデータ

      <sup>1</sup>

    * スケジューラデータ

      <sup>1</sup>

    <sup>1</sup>管理されたKubernetes環境（EKS、GKE、AKSなど）では収集されません

    以下の一部を無効化することをご検討ください。

    * デーモンセットデータ

    * デプロイメントデータ

    * エンドポイントデータ

    * 名前空間データ

    * ReplicaSetデータ

      <sup>2</sup>

    * サービスデータ

    * StatefulSetデータ

    <sup>2</sup>デフォルトのアラートで使用：「ReplicaSetに必要な数のポッドがありません」

    #### マニフェストの状態メトリックを更新する例（デプロイメント）

    ```shell
    [spec]
      [template]
        [spec]
          [containers]
            [name=kube-state-metrics]
            [args]
            #- --collectors=daemonsets
            #- --collectors=deployments
            #- --collectors=endpoints
            #- --collectors=namespaces
            #- --collectors=replicasets
            #- --collectors=services
            #- --collectors=statefulsets
    ```

    _マニフェストの状態メトリックを更新する例（ClusterRole）_

    ```shell
    [rules]
    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - daemonsets
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - deployments
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - endpoints
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - namespaces
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - replicasets
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - services
    #   verbs: ["list", "watch"]

    # - apiGroups: ["apps"]
    #   resources:
    #   - statefulsets
    #   verbs: ["list", "watch"]
    ```

    ### `nri-bundle`チャートの構成`lowDataMode`

    当社のヘルムチャートは、詳細情報をドロップする代わりに、取り込まれるデータの量を減らすオプションの設定をサポートしています。有効にするには、 `nri-bundle`チャートで`global.lowDataMode`を`true`に設定します。

    `lowDataMode` `nri-bundle`チャートの3つの特定のコンポーネントに影響します。

    1. インフラストラクチャエージェントの間隔を`15` }秒から`30`秒に増やします。
    2. Prometheus OpenMetricsの統合では、以下のHelmドキュメントに示されているように、いくつかのメトリックが除外されます。
    3. ラベルと注釈の詳細はログから削除されます。

    この構成の詳細については、 [Helmドキュメント](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#reducedataingest)を参照してください。
  </Collapser>

  <Collapser
    id="on-host-integrations"
    title="オンホストインテグレーション"
  >
    New Relicのオンホスト統合は、Postgresql、MySQL、Kafka、RabbitMQなどのサードパーティサービスの多様な統合セットを表しています。このドキュメントの範囲内ですべての最適化手法を提供することはできませんが、これらの一般的に適用可能な手法を提供できます。 ：

    * サンプリングレートの管理
    * コレクションの幅を広げたり狭めたりできるコンフィグの部分を管理する。
    * カスタムクエリを可能にするコンフィグ部分の管理
    * インフラストラクチャーエージェントのカスタム属性は、ホスト上のすべての統合データに適用されるため、管理します。

    いくつかの例を使って説明します。

    ### [PostgreSQLの統合](/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration/#example-postgresSQL-collection-config)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象テーブル数
      * 監視対象指標数
    </Callout>

    PostgreSQLのオンホスト統合設定では、データ量の管理に役立つこれらの調整可能な設定が提供されています。

    * `interval`: デフォルトは 15 秒です
    * `COLLECTION_LIST`: 監視するテーブルのリスト (ALL を使用してすべてを監視します)
    * `COLLECT_DB_LOCK_METRICS`: `dblock`メトリクスを収集
    * `PGBOUNCER`: `pgbouncer`メトリクスを収集
    * `COLLECT_BLOAT_METRICS`: 肥大化指標を収集する
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `CUSTOM_METRICS_CONFIG`: カスタム コレクション クエリを含む構成ファイル

    **サンプル構成：**

    ```yaml
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres
          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

    ### [Kafkaとの統合](/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration/)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * クラスタ内のブローカー数
      * クラスタ内のトピック数
    </Callout>

    Kafkaのオンホスト統合設定では、データ量の管理に役立つ、これらの調整可能な設定が提供されています。

    * `interval`: デフォルトは 15 秒です
    * `TOPIC_MODE`: 収集するトピックの数を決定します。オプションは`all` 、 `none` 、 `list`または`regex`です。
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `TOPIC_LIST`: 監視するトピック名の JSON 配列。topic_mode が list に設定されている場合にのみ有効です。
    * `COLLECT_TOPIC_SIZE`: メトリクス トピック サイズを収集します。オプションは`true`または`false`で、デフォルトは`false`です。
    * `COLLECT_TOPIC_OFFSET`:メトリクス トピック オフセットを収集します。オプションは`true`または`false`で、デフォルトは`false`です。

    トピックレベルのメトリック、特にオフセットの収集は、収集するのにリソースを大量に消費する可能性があり、データ量に影響を与える可能性があることに注意してください。クラスターに新しいKafkaトピックを追加するだけで、クラスターの取り込みが1桁増加する可能性があります。

    ### [MongoDBとの連携](/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象データベース数
    </Callout>

    MongoDBとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

    * `interval`: デフォルトは 15 秒です
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `FILTERS`: データベース名からコレクション名の配列への JSON マップ。空の場合、デフォルトですべてのデータベースとコレクションになります。

    使用するオンホスト統合では、デフォルトですべてのデータベースからメトリックを収集する`FILTERS`などのパラメーターに注意することが重要です。これは、監視の優先順位を使用して、収集されたデータを合理化できる領域です。

    **METRICとINVENTORYの間隔が異なる構成例：**

    ```yaml
    integrations:
      - name: nri-mongodb
        env:
          METRICS: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 15s
        labels:
          environment: production

      - name: nri-mongodb
        env:
          INVENTORY: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 60s
        labels:
          environment: production
        inventory_source: config/mongodb
    ```

    ### [Elasticsearchの統合](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * クラスタ内のノード数
      * クラスタ内のインデックス数
    </Callout>

    Elasticsearchとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

    * `interval`: デフォルトは 15 秒です
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `COLLECT_INDICES`: インデックス メトリックを収集するかどうかを通知します。
    * `COLLECT_PRIMARIES`: プライマリ メトリックを収集するかどうかを示します。
    * `INDICES_REGEX`: 収集するインデックスをフィルタリングします。
    * `MASTER_ONLY`: 選択されたマスターのみでクラスタ メトリックを収集します。

    **`METRICS`と`INVENTORY`の間隔が異なる構成の例:**

    ```yaml
    integrations:
      - name: nri-elasticsearch
        env:
          METRICS: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          REMOTE_MONITORING: true
        interval: 15s
        labels:
          environment: production

      - name: nri-elasticsearch
        env:
          INVENTORY: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          CONFIG_PATH: /etc/elasticsearch/elasticsearch.yml
        interval: 60s
        labels:
          environment: production
        inventory_source: config/elasticsearch
    ```

    ### [JMXの統合](/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * に記載されている指標 `COLLECTION_CONFIG`
    </Callout>

    JMXの統合は、本質的に汎用的です。これは、任意のJMXインスタンスからメトリクスをスクレイピングすることを可能にします。この統合によって収集されるものについては、十分な量の制御が可能です。一部のエンタープライズ向け New Relic 環境では、JMX メトリクスが収集される全データの中で比較的高い割合を占めています。

    JMX統合は、データ量の管理に役立つこれらの調整可能な設定を提供します。

    * `interval`: デフォルトは 15 秒です
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `METRIC_LIMIT`: エンティティごとに収集できるメトリックの数。この制限を超えると、エンティティは報告されません。0 の制限は、制限がないことを意味します。
    * `LOCAL_ENTITY`: ローカル エンティティのすべてのメトリックを収集します。localhost を監視する場合にのみ使用されます。
    * `COLLECTION_FILES`: メトリック コレクション定義ファイルへの完全なファイル パスのコンマ区切りリスト。オンホスト インストールの場合、デフォルトの JVM メトリック コレクション ファイルは`/etc/newrelic-infra/integrations.d/jvm-metrics.yml`にあります。
    * `COLLECTION_CONFIG`: JSON としてのメトリクス コレクションの構成。

    取り込まれるデータ量を最も左右するのは`COLLECTION_CONFIG`エントリです。スクレイピングしている JMX モデルを理解すると、最適化に役立ちます。

    _`COLLECTION_CONFIG` JVM メトリックの例_

    ```java
    COLLECTION_CONFIG='{"collect":[{"domain":"java.lang","event_type":"JVMSample","beans":[{"query":"type=GarbageCollector,name=*","attributes":["CollectionCount","CollectionTime"]},{"query":"type=Memory","attributes":["HeapMemoryUsage.Committed","HeapMemoryUsage.Init","HeapMemoryUsage.Max","HeapMemoryUsage.Used","NonHeapMemoryUsage.Committed","NonHeapMemoryUsage.Init","NonHeapMemoryUsage.Max","NonHeapMemoryUsage.Used"]},{"query":"type=Threading","attributes":["ThreadCount","TotalStartedThreadCount"]},{"query":"type=ClassLoading","attributes":["LoadedClassCount"]},{"query":"type=Compilation","attributes":["TotalCompilationTime"]}]}]}'
    ```

    `NonHeapMemoryUsage.Init`など、その構成から1つのエントリを省略すると、収集されるデータ量全体に具体的な影響があります。

    _`COLLECTION_CONFIG` Tomcat メトリクスの例_

    ```java
    COLLECTION_CONFIG={"collect":[{"domain":"Catalina","event_type":"TomcatSample","beans":[{"query":"type=UtilityExecutor","attributes":["completedTaskCount"]}]}]}
    ```

    ### その他のオンホストインテグレーション

    その他にも、収集の最適化に役立つ設定オプションを持つオンホスト統合が多数あります。よく使われるものをいくつか紹介します。

    * [NGINX](/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/)
    * [MySQL](/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration)
    * [Redis](/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration)
    * [Apache](/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration)
    * [RabbitMQ](/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration)

    これは良い [スタート地点](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations#on-host) もっと学ぶために。
  </Collapser>

  <Collapser
    id="network-performance-monitoring"
    title="ネットワーク監視"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      駆動するモニター機器。

      * ハードコンフィグデバイス
      * ディスカバリーセクションのCIDRスコープ
      * トラップ設定
    </Callout>

    このセクションでは、Kentik の `ktranslate` エージェントに依存する New Relic のネットワーク監視に焦点を当てます。このエージェントは非常に洗練されているため、大規模な最適化を行う前に [高度な構成ドキュメントを](/docs/network-performance-monitoring/advanced/advanced-config) 完全に理解することが重要です。構成オプションには次のものがあります。

    * `mibs_enabled`: KTranslate Docker イメージがポーリングするすべてのアクティブな MIB の配列。`discovery_add_mibs`属性が`true`の場合、このリストは検出中に自動的に生成されます。ここにリストされていない MIB は、構成ファイル内のどのデバイスでもポーリングされません。`MIB-NAME.tableName`構文を使用して、MIB ファイルで SNMP テーブルを直接指定できます。例: `HOST-RESOURCES-MIB.hrProcessorTable` .

    * `user_tags`: key:value ペアの属性で、デバイスにより多くのコンテキストを提供します。このレベルのタグは、構成ファイル内のすべてのデバイスに適用されます。

    * `devices`: フローを監視するデバイスのセクション一覧

    * `traps`: SNMP トラップで監視する IP とポートを構成します (デフォルトは`127.0.0.1:1162`です)。

    * `discovery`: エンドポイントを検出する方法を構成します。このセクションでは、次のパラメーターがスコープを増減するために最も効果的です。

      * `cidrs`: [CIDR 表記](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation)のターゲット IP 範囲の配列。
      * `ports`: SNMP ポーリング中にスキャンするターゲット ポートの配列。
      * `debug`: 検出中にデバッグ レベルのログを有効にするかどうかを示します。デフォルトでは、 `false`
      * `default_communities`: SNMP ポーリング中にスキャンする SNMPv1/v2c コミュニティ ストリングの配列。この配列は順番に評価され、検出は最初に通過したコミュニティを受け入れます。

    可観測性のニーズに見合う価値を生み出さないデータのフィルタリングをサポートするために、 `global.match_attributes.{}`または`devices.<deviceName>.match_attributes.{}`属性マップを設定できます。

    これにより、データを New Relic に送信する前に KTranslate レベルでフィルタリングが提供され、インターフェイスなどの監視をきめ細かく制御できるようになります。

    詳細については、 [「ネットワーク監視の構成」](/docs/network-performance-monitoring/advanced/advanced-config/#match_attributes-attribute)を参照してください。
  </Collapser>

  <Collapser
    id="log-forwarders"
    title="ログフォワーダー"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ログ転送
      * フォワードログの平均レコードサイズ
    </Callout>

    ログは、通常、独自のルーティングルールと変換ルールを備えた専用の転送レイヤーを介してログをルーティングするという点で、テレメトリの最も柔軟なソースの1つです。さまざまなフォワーダーがあるため、最も一般的に使用されるフォワーダーに焦点を当てます。

    * APM言語エージェント（最近のバージョン）
    * Fluentd
    * Fluentbit
    * New Relic インフラエージェント (Fluentbit 内蔵)
    * Logstash

    ### APMエージェントログのサンプリング

    New Relic言語エージェントの最近のバージョンでは、ログをNewRelicに直接転送できます。場合によっては、各APMエージェントインスタンスからのログスパイクの大きさの制限を管理したい場合があります。

    環境変数を使用してサンプリングを有効にできます `NEW_RELIC_APPLICATION_LOGGING_FORWARDING_MAX_SAMPLES_STORED`

    これは、APMエージェントのログキューに保存されるログの最大数を提供するだけで構成されます。カスタム優先キューに基づいて動作します。すべてのログメッセージが優先されます。トランザクション内で発生するログは、トランザクションの優先順位を取得します。

    ログのキューは、優先度とログの到着時刻に基づいて並べ替えられます。優先度の高い方が優先され、必要に応じて最新のログが優先されます（キュー内の各エントリのカウントを保持します）。ログはキューに個別に追加され（トランザクション内のログも含む）、制限に達すると、キューの最後にあるログがプッシュされ、新しいログが優先されます。以下のリソースセクションには、簡単な方法でログボリュームを追跡するのに役立つ[クイックスタートダッシュボード](https://onenr.io/0Bj3BlEZkRX)があります。ログボリュームを追跡すると、可観測性のニーズに合わせてサンプリングレートを調整または無効にすることができます。

    ### FluentdまたはFluentbitでのフィルターの構成

    ほとんどの一般的なフォワーダーは、フィルタリングと変換を含むかなり完全な[ルーティング ワークフロー](https://docs.fluentd.org/configuration/routing-examples)を提供します。New Relic のインフラストラクチャ エージェントは、不要なログをフィルタリングするための非常に単純なパターンをいくつか提供します。レコードをフィルタリングするための正規表現。`tail` 、 `systemd` 、 `syslog` 、および`tcp` (形式が none の場合のみ) ソースでのみサポートされます。このフィールドは、Unix システムの`grep -E`と同様に機能します。たとえば、特定のファイルがキャプチャされている場合、次を使用して`WARN`または`ERROR`を含むレコードをフィルタリングできます。

    ```yaml
      - name: only-records-with-warn-and-error
        file: /var/log/logFile.log
        pattern: WARN|ERROR
    ```

    貴重なフィルタリングまたは解析を行うFluentbit用に事前に作成されたFluentd構成がある場合は、それらをNewRelicロギング構成にインポートできます。これを行うには、 `logging.d`フォルダ内の任意の`.yaml`ファイルで`config_file`および`parsers`パラメータを使用します。

    * `config_file`：既存のFluentBit構成ファイルへのパス。ソースが重複していると、NewRelicのログ管理でメッセージが重複します。
    * `parsers_file`：既存のFluentBitパーサーファイルへのパス。

    次のパーサー名が予約されています： `rfc3164` 、 `rfc3164-local` 、および`rfc5424` 。

    データパイプラインのログに属性（またはタグ）を挿入する方法と変換を実行する方法を学ぶと、NewRelicドロップルールを使用してダウンストリーム機能をドロップするのに役立ちます。ソースに関するメタデータを使用してログを拡張することにより、バックエンドに何をドロップするかについて、一元化された簡単に元に戻せる決定を行うことができます。少なくとも、次の属性が何らかの形でログに存在することを確認してください。

    * チーム
    * 環境(dev/stage/prod)
    * アプリケーション
    * データセンター
    * ログレベル

    以下は、ルーティングとフィルタリングの詳細なリソースです。

    * [Fluentdの一般的なフィルタとルーティングのパターン](https://docs.fluentd.org/configuration/routing-examples)
    * [Fluentbitデータパイプライン](https://docs.fluentbit.io/manual/concepts/data-pipeline)
    * [New Relic インフラストラクチャエージェントによるログの転送](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/)

    ### インフラストラクチャエージェントのデフォルトの属性セットを調整する

    インフラストラクチャエージェントは、ホストに追加されたカスタムタグなど、デフォルトでいくつかの属性を追加します。New Relicに`aws.[attributename]`の形式で表示される多数のAWSタグを含め、構成によってそれ以上のものがもたらされる可能性があります。これらの属性は、最適な可観測性にとって重要であるため、計画された構成変更に照らして、視覚化、分析、およびアラートのニーズを評価することを強くお勧めします。たとえば、Kubernetesクラスタからのログは、次のようなメタデータがないと役に立たない可能性があります。

    * `cluster_name`
    * `pod_name`
    * `container_name`
    * `node_name`
  </Collapser>

  <Collapser
    id="prometheus-metrics-sources"
    title="Prometheusのメトリクスソース"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * アプリからエクスポートされたメトリクス数
      * リモートライトまたはPOMIで転送されたメトリクス数
    </Callout>

    New Relicは、PrometheusメトリックをNewRelicに送信するための2つの主要なオプションを提供します。このドキュメントでメトリックの取り込みを管理するためのベストプラクティスは、主にオプション2（Prometheus OpenMetrics統合（POMI））に焦点を当てています。これは、このコンポーネントがNewRelicによって作成されたためです。

    ### オプション1： [Prometheusリモート書き込み統合](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)

    Prometheus サーバーのスクレイプ構成オプションについては [、Prometheus 構成ドキュメント](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)を参照してください。これらのスクレイプ構成は、Prometheus サーバーによって収集されるメトリックを決定します。[`remote_write`](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)パラメータを構成することで、収集されたメトリクスを New Relic Metric API 経由で New Relic データベース (NRDB) に書き込むことができます。

    ### オプション2： [Prometheus OpenMetrics統合（POMI）](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration)

    POMIは、動的に発見されたPrometheusのエンドポイントと静的なエンドポイントの両方からメトリクスをスクレイピングするスタンドアローンの統合です。POMI は、このデータを New Relic Metric API 経由で NRDB に送信します。この統合は、現在 Prometheus Server を実行していないお客様にとって理想的です。

    #### POMI：スクレープレーベル

    POMIは、デフォルトでラベルまたは注釈`prometheus.io/scrape=true`を含むPrometheusエンドポイントを検出します。クラスタにデプロイされているものによっては、これは多数のエンドポイントになる可能性があるため、多数のメトリックが取り込まれる可能性があります。

    `scrape_enabled_label`パラメータをカスタム（たとえば`newrelic/scrape` ）に変更し、データの取り込みが最大の懸念事項である場合は、Prometheusエンドポイントに選択的にラベルを付けるか注釈を付けることをお勧めします。

    最新のリファレンス設定については、 [nri-prometheus-latest.yaml](https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml)を参照してください。

    **POMI構成パラメーター：**

    ```yaml
    # Label used to identify scrapable targets. 
    # Defaults to "prometheus.io/scrape"
      scrape_enabled_label: "prometheus.io/scrape"
    ```

    POMIは、デフォルトでノードレベルで公開されているPrometheusのエンドポイントを検出します。これは通常、Kubelet と cAdvisor から来るメトリクスを含みます。

    New Relic Kubernetes Daemonsetを実行している場合は、POMIが重複するメトリックを収集しないように`require_scrape_enabled_label_for_nodes: true`を設定することが重要です。

    New Relic Kubernetes Daemonsetの対象となるエンドポイントについては、 [GitHubのKubernetesREADME](https://github.com/newrelic/nri-kubernetes/blob/main/README.md)を参照してください。

    #### POMI: ノードのラベルをスクレイプする

    POMIは、デフォルトでノードレベルで公開されているPrometheusのエンドポイントを検出します。これは通常、Kubelet と cAdvisor から来るメトリクスを含みます。

    New Relic Kubernetes Daemonsetを実行している場合は、POMIが重複するメトリックを収集しないように`require_scrape_enabled_label_for_nodes: true`を設定することが重要です。

    New Relic Kubernetes Daemonsetの対象となるエンドポイントについては、 [GitHubのKubernetesREADME](https://github.com/newrelic/nri-kubernetes/blob/main/README.md)を参照してください。

    _POMIコンフィグパラメーター_

    ```yaml
    # Whether k8s nodes need to be labeled to be scraped or not. 
    # Defaults to false.
      require_scrape_enabled_label_for_nodes: false
    ```

    #### POMI：との共存 `nri-kubernetes`

    New Relicの[Kubernetes統合](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)は、箱から出してすぐに[多くのメトリック](/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data#metrics)を収集します。ただし、Kubernetesクラスターから利用可能なすべてのメトリックを収集するわけではありません。

    POMI構成には、これに似たセクションが表示されます。これにより、NewRelicKubernetes統合が**KubeStateMetrics**からすでに収集しているメトリックのサブセットのメトリック収集が**無効**になります。

    KubeletとcAdvisorの指標が重複しないように`require_scrape_enabled_label_for_node: true`を設定することも非常に重要です。

    **POMI構成パラメーター：**

    ```yaml
      transformations:
        - description: "Uncomment if running New Relic Kubernetes integration"
          ignore_metrics:
            - prefixes:
              - kube_daemonset_
              - kube_deployment_
              - kube_endpoint_
              - kube_namespace_
              - kube_node_
              - kube_persistentvolume_
              - kube_persistentvolumeclaim_
              - kube_pod_
              - kube_replicaset_
              - kube_service_
              - kube_statefulset_

    ```

    #### POMI：リクエスト/リミット設定

    POMIを実行するときは、約500kDPMを生成するクラスターに次の[リソース制限](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/)を適用することをお勧めします。

    * CPU制限：1コア（1000m）
    * メモリ制限：1Gb 1024（1G）

    CPUとメモリのリソース要求は、POMIがクラスターから十分なリソースを受け取るように、適切な値に設定する必要があります。これを極端に低い値（CPU：50mなど）に設定すると、クラスターリソースが「ノイズの多いネイバー」によって消費される可能性があります。

    **POMI構成パラメーター：**

    ```yaml
    spec:
      serviceAccountName: nri-prometheus
      containers:
      - name: nri-prometheus
        image: newrelic/nri-prometheus:2.2.0
        resources:
          requests:
            memory: 512Mi
            cpu: 500m
          limits:
            memory: 1G
            cpu: 1000m
    ```

    ### POMI：DPMとカーディナリティの推定

    カーディナリティはGBインジェストあたりの請求額とは直接関係ありませんが、New Relicはカーディナリティと1分あたりのデータポイントについて一定のレート制限を維持しています。Prometheus クラスタからカーディナリティと DPM を可視化できることは、非常に重要なことです。

    <Callout variant="tip">
      NewRelicアカウントには1MDPMと1Mカーディナリティの制限がありますが、最大15MDPMと15Mカーディナリティをリクエストできます。変更をリクエストするには、NewRelicアカウントの担当者にお問い合わせください。詳細については、「[メトリックAPIの制限](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes)」を参照してください。
    </Callout>

    すでにPrometheusServerを実行している場合は、POMIまたは`remote_write`を有効にする前に、そこでDPMとカーディナリティの見積もりを実行できます。

    **1分あたりのデータポイント（DPM）：**

    ```promql
    rate(prometheus_tsdb_head_samples_appended_total[10m]) * 60
    ```

    **上位20のメトリック（最高のカーディナリティ）：**

    ```promql
    topk(20, count by (**name**, job)({__name__=~".+"}))
    ```
  </Collapser>

  <Collapser
    id="cloud-integration"
    title="クラウドインテグレーション"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 統合ごとにエクスポートされるメトリクスの数
      * ポーリング頻度(ポーリングベースの統合の場合)
    </Callout>

    一部のNewRelicクラウド統合は、クラウドプロバイダーのAPIからデータを取得します。この実装では、データは通常、AWS CloudWatch、Azure Monitor、GCP StackdriverなどのモニタリングAPIから収集され、インベントリメタデータは特定のサービスのAPIから収集されます。

    他のクラウド統合は、AWS Kinesisなどのストリーミングサービスを介してプッシュされるストリーミングメトリック（または「プッシュ」メトリック）からデータを取得します。

    ### ポーリングAPIベースの統合

    クラウドインテグレーションからのデータをより多くまたはより少なく報告したい場合、あるいはクラウドアカウントのレートやスロットリングの制限に達しないようクラウドプロバイダーのAPIの使用を制御する必要がある場合、構成設定を変更して報告するデータ量を変更することができます。主な制御は次の2つです。

    * [ポーリング周波数の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#polling)
    * [データの報告内容の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#filter-data)

    投票頻度の変更を希望するビジネス上の理由の例としては、以下のようなものがあります。

    * **請求**：AWS CloudWatchの請求を管理する必要がある場合は、ポーリングの頻度を減らすことをお勧めします。これを行う前に、クラウド統合に設定されたアラート条件がこの削減の影響を受けないことを確認してください。
    * **新しいサービス**：新しいサービスまたは構成を展開していて、より頻繁にデータを収集する場合は、ポーリングの頻度を一時的に増やすことをお勧めします。

    <Callout variant="caution">
      統合のコンフィギュレーション設定を変更すると、アラート条件やチャートトレンドに影響を与える場合があります。
    </Callout>

    詳細については、「 [ポーリングの構成](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations)」を参照してください。

    ### 「ストリーミング」または「プッシュ」メトリック

    ますます多くのクラウド統合が、APIポーリングを使用する代わりに、[ストリーミングサービス](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream)を介してデータをプッシュするオプションを提供しています。これにより、レイテンシーが大幅に削減されることが証明されています。一部のユーザーが観察した問題の1つは、サンプリングレートを構成できないため、ボリュームの制御が簡単ではないことです。

    データをドロップするための新しいRelicルールについては、次のセクションで詳しく説明します。これらは、ボリュームが大きすぎるストリーミングメトリックを除外するための主要な方法です。ただし、ストリームの量をいくらか制限するために、クラウドプロバイダー側で実行できることがいくつかあります。

    たとえば、AWSでは、条件キーを使用[してCloudWatch\*名前空間へのアクセスを制限することができます](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/iam-cw-condition-keys-namespace.html)。

    次のポリシーは、ユーザーが`MyCustomNamespace`という名前空間でのみメトリックを公開するように制限します。

    ```json
    {
        "Version": "2012-10-17",
        "Statement": {
            "Effect": "Allow",
            "Resource": "*",
            "Action": "cloudwatch:PutMetricData",
            "Condition": {
                "StringEquals": {
                    "cloudwatch:namespace": "MyCustomNamespace"
                }
            }
        }
    }
    ```

    次のポリシーでは、ユーザーは`CustomNamespace2`を除く任意の名前空間でメトリックを公開できます:

    ```json
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData"
            },
            {
                "Effect": "Deny",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData",
                "Condition": {
                    "StringEquals": {
                        "cloudwatch:namespace": "CustomNamespace2"
                    }
                }
            }
        ]
    }
    ```
  </Collapser>
</CollapserGroup>

#### ドロップルールによる最適化 [#optimization-with-drop-rules]

ドロップルールで何ができるかを理解するための簡単なルールは次のとおり**です。クエリを実行できる場合は、ドロップできます。**

ドロップフィルターのルールは、いくつかの重要な目標を達成するのに役立ちます。

* お客様のアカウントに関連するログのみを保存することで、コストを削減できます。
* 個人を特定できる情報（PII）を削除することで、プライバシーとセキュリティを保護します。
* 無関係なイベントや属性を削除して、ノイズを減らす。

**注意事項**：ドロップルールを作成するときは、設定した条件を満たすデータをルールが正確に識別して破棄するようにする必要があります。また、ルールと、NewRelicに開示するデータを監視する責任もあります。常にクエリをテストして再テストし、ドロップルールをインストールした後、意図したとおりに機能することを確認してください。ドロップ前とドロップ後のデータを監視するダッシュボードを作成すると役立ちます。

ドロップルールを使用して特定のツールのデータ取り込みを最適化するためのガイダンスは次のとおりです。

<CollapserGroup>
  <Collapser
    id="logs"
    title="ログ"
  >
    すべての New Relic ドロップルールは、同じバックエンドデータモデルと API によって実装されています。しかし、New Relic のログ管理は、ドロップルールを非常に簡単に作成および監視できる強力な UI を提供します。

    遠隔測定の優先順位付けに関する前回のセクションでは、特定のデータを非推奨にする方法を示す演習を行いました。この例をもう一度見てみましょう。

    ```
    Omit debug logs (knowing they can be turned on if there is an issue) (saves 5%)
    ```

    #### 方法1：[ログUI](/docs/logs/ui-data/drop-data-drop-filter-rules)

    * ログUIのフィルターを使用して気になるログを特定します： `level: DEBUG` 。
    * ドロップしたいログが見つかることを確認してください。
    * `level:debug`や`log_level:Debug`などの代替構文を確認してください。これらのバリエーションは一般的です。
    * \[**データの管理**]で、\[**ドロップフィルター**]クリックし、\[デバッグログの削除]という名前のフィルターを作成して有効にします。
    * ルールが機能することを確認します。

    #### 方法2: [弊社のNerdGraph APIを利用する。](/docs/data-apis/manage-data/drop-data-using-nerdgraph/)

    * 関連する NRQL クエリを作成します。

      ```sql
      SELECT count(*) FROM Log WHERE `level` = 'DEBUG'
      ```

    * ドロップしたいログが見つかることを確認してください。

    * 属性名と値のバリエーションを確認してください ( `Debug`と`DEBUG` )。

    * 以下のNerdGraph文を実行し、動作することを確認します。

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_DATA
                nrql: "SELECT * FROM Log WHERE `level` = 'DEBUG'"
                description: "Drops DEBUG logs.  Disable if needed for troubleshooting."
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser
    id="process-samples"
    title="プロセスサンプル"
  >
    推奨事項を実装しましょう： `Drop process sample data in DEV environments` 。

    * 関連するクエリを作成します。

      ```sql
      SELECT * FROM ProcessSample WHERE `env` = 'DEV'
      ```

    * ドロップしたいプロセスサンプルが見つかることを確認する。

    * `env` `ENV`や `Environment`

    * `Dev`などのさまざまな`DEV`を確認してください `Development`

    * NerdGraph APIを使用して、以下のステートメントを実行し、動作を確認してください。

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM ProcessSample WHERE `env` = 'DEV'"
                  description: "Drops ProcessSample from development environments"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="cloud-metrics"
    title="クラウドメトリクス"
  >
    場合によっては、冗長なカバレッジがあるデータを節約できます。たとえば、AWS RDS 統合が実行されている環境と、 `nri-mysql`や`nri-postgresql`などの SQL データベースを監視する New Relic オンホスト統合の 1 つが実行されている環境では、重複するメトリックをいくつか破棄できる場合があります。

    手っ取り早く調べるには、次のようなクエリを実行します。

    ```sql
    FROM Metric select count(*) where metricName like 'aws.rds%' facet metricName limit max
    ```

    これにより、パターンに一致するすべての`metricName`値が表示されます。

    結果から、パターン`aws.rds.cpu%`のメトリックが大量にあることがわかります。それらのための他のインストルメンテーションがあるので、それらを削除しましょう：

    * 関連するクエリを作成します。

      ```sql
      FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago
      ```

    * ドロップするプロセスサンプルが見つかることを確認してください。

    * NerdGraph APIを使用して、以下の文を実行し、動作することを確認する。

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago"
                  description: "Drops rds cpu related metrics"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="drop-specific-attributes"
    title="特定の属性を削除する"
  >
    ドロップルールの強力な点の1つは、特定の属性をドロップするが、残りのデータはそのまま維持するルールを構成できることです。これを使用して、NRDBからプライベートデータを削除したり、過度に大きな属性を削除したりします。たとえば、ログレコード内のスタックトレースまたはJSONの大きなチャンクは、非常に大きくなる場合があります。

    これらのドロップルールを設定するには、 `action`フィールドを&#x7B; `DROP_DATA` }ではなく`DROP_ATTRIBUTES`に変更します。

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_ATTRIBUTES
                nrql: "SELECT stack_trace, json_data FROM Log where appName='myApp'"
                description: "Drops large fields from logs for myApp"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-random-sample-of-events"
    title="イベントのランダムサンプルをドロップします"
  >
    <Callout variant="caution">
      このアプローチは慎重に使用し、他に選択肢がない状況でのみ使用してください。これは、データから作成された統計的推測を変更する可能性があるためです。ただし、サンプルサイズが大きいイベントの場合、結果を理解している限り、データの一部のみを使用できます。
    </Callout>

    この例では、特定のトレースIDの相対的な分布を利用して、ランダムサンプリングを概算します。 `rlike`演算子を使用して、スパンの`trace.id`属性の先頭の値を確認できます。

    次の例では、スパンの約25％がドロップする可能性があります。

    ```sql
    SELECT * FROM Span WHERE trace.id rlike r'.*[0-3]' and appName = 'myApp'
    ```

    便利な表現は次のとおりです。

    * `r'.*0'` 約6.25％

    * `r'.*[0-1]'` 約12.5％

    * `r'.*[0-2]'` 約18.75％

    * `r'.*[0-3]'` 約25.0％

      完全なミューテーションの例を次に示します。

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_ATTRIBUTES
                  nrql: "SELECT * FROM Span WHERE trace.id rlike r'.*[0-3]' and appName = 'myApp'"
                  description: "Drops approximately 25% of spans for myApp"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="other-events-and-metrics"
    title="その他のイベントと指標"
  >
    NRDBの他のイベントやメトリックにこれらのテクニックを使用するために必要な知識は、前述の例ですべてわかるはずです。クエリーができれば、それをドロップすることができる。ドロップルールのクエリを構成する正確な方法について質問がある場合は、New Relic に連絡してください。
  </Collapser>
</CollapserGroup>

## エクササイズ [#exercise]

次の質問に答えることで、最適化計画を作成して実行する能力に自信をつけることができます。 `Baselining`セクションの[データ取り込みベースライン](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-dashboard)および[データ取り込みエンティティの内訳](http://localhost:8000/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-entity-breakdown-dashboard)ダッシュボードを使用することをお勧めします。説明されているようにこれらのダッシュボードをインストールし、これらの質問のうちどれだけに答えられるかを確認してください。

| 質問                                                                                                                                                                                                                                                                   |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| この組織の取り込みを月に少なくとも5％削減できる3つのドロップルールを表示しますか？ドロップルールのNerdGraph構文を応答に含めます。                                                                                                                                                                                               |
| この組織の取り込みを月に少なくとも5％削減するために実装できる、3つのインストルメンテーション構成の変更を提案しますか？応答に構成スニペットを含めます。                                                                                                                                                                                         |
| K8sモニタリングからのデータ量を減らすためにできる3つのことは何ですか？どのくらいのデータ削減を達成できますか？この削減の潜在的なトレードオフは何ですか？ （たとえば、それらは実質的な可観測性を失いますか？）                                                                                                                                                            |
| 1. データ取り込みガバナンス ベースライン ダッシュボードを使用して、大量のログ データを New Relic に送信しているアカウントを特定します。<br/> 2.アカウント スイッチャーからそのアカウントを見つけて選択します。<br/> 3.アカウントの**ログ**ページに移動し、左側のメニューから**パターン**を選択します。<br/> 4.示されているログ パターンを確認し、価値の低いログ パターンの例をいくつか示します。それらの価値が低い理由は何ですか？これらのログを削除することで達成できる総削減量は? |
| この組織の全体的な分析に基づいて、どのテレメトリが十分に活用されていませんか？                                                                                                                                                                                                                              |

## 結論 [#conclusion]

プロセスセクションでは、テレメトリを特定の可観測性値の推進要因または目的に関連付ける方法を示しました。これにより、アカウントの取り込みを最適化するという難しい決定がいくらか簡単になります。目標を保護しながら摂取を最適化する高レベルの[最適化計画](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#develop-plan)を説明する方法を学びました。最後に、構成とドロップルールベースの取り込み最適化のための[豊富なレシピセット](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#use-reduction-techniques)が紹介されました。