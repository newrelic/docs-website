---
title: データの取り込みを最適化する
tags:
  - Observability maturity
  - Operational efficiency
  - Data ingest cost
  - Sampling rate
  - Drop rules
  - Observability as code
  - Value drivers
  - Bill and Usage Data
  - Data ingest cost
metaDescription: 'The third part of New Relic''s data ingest governance series on optimizing how you ingest and use your telemetry data: this focuses on optimizing data ingest.'
translationType: machine
---

import optimizingicon from 'images/oma-oe-dg-optimizing-icon.png'

import valuedriversuptime from 'images/oma-oe-dg-value-driver-uptime.png'

import valuedriverscustomer from 'images/oma-oe-dg-value-driver-customer.png'

import valuedriversinnovation from 'images/oma-oe-dg-value-driver-innovation.png'

import kubestatemetrics from 'images/oma-oe-dg-update-k8s-kube-state-metrics.png'

import kubernetesscrapeinterval from 'images/oma-oe-dg-update-k8s-scrape-interval.png'

<img
  src={optimizingicon}
  alt="Optimize"
  style={{ height: '96px', width: '120px', verticalAlign: 'middle', horizontalAlign: 'right'}}
/>

**データ取り込みガバナンス**は、組織によって収集されたテレメトリデータの最適な値を取得するためのプラクティスです。これは、多数のビジネスユニットとワーキンググループを持つ複雑な組織にとって特に重要です。これは、NewRelicデータの取り込みを最適化するための4部構成のガイドの第3部です。

## 望ましい結果 [#desired-outcome]

データインジェストを最適化することにより、データの観測可能な価値を最大化します。不要なインジェストデータを削減し、予算内に収まるようにします。

## プロセス [#process]

このプロセスには、次の手順が含まれます。

* [観測可能な目標に優先順位をつける](#prioritize-objectives)
* [最適化プランの策定](#develop-plan)
* [データ削減のテクニックを使って、計画を実行する](#use-reduction-techniques)

これらの手順について詳しく説明します。

### 観測可能な目標に優先順位をつける [#prioritize-objectives]

データ取り込みガバナンスフレームワークの最も重要な部分の1つは、収集されたテレメトリを**可観測性の値の推進要因**と整合させることです。新しいテレメトリを構成するときの主な可観測性の目的を確実に理解する必要があります。

新しい遠隔測定を導入する場合、それが観測可能なソリューション全体に何をもたらすかを理解する必要があります。新しいデータは他のデータと重なるかもしれません。もし、どの重要な目的にも合致しないテレメトリーを導入するのであれば、そのデータの導入は再考する必要があるかもしれません。

目的は以下の通りです。

* 社内SLAを満たす
* 外部SLAを満たす
* 機能革新のサポート（A / Bパフォーマンスおよび導入テスト）
* カスタマーエクスペリエンスのモニター
* ベンダーと社内サービスプロバイダのSLAを遵守する
* ビジネスプロセスのヘルスモニタリング
* その他のコンプライアンス要件

これらの目標に沿うことで、あるデータセットを別のデータセットよりも優先させるという柔軟かつ直感的な判断が可能になり、新しいプラットフォームやサービスのインストルメント化を行う際に、どこから手をつければよいのか、チームのガイド役を務めることができます。

### 最適化プランの策定 [#develop-plan]

このセクションでは、2つの主要な仮定を行います。

* 「[データ取り込みのベースライン」](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining)セクションのツールとテクニックを使用して、データの出所を適切に把握できます。
* [可観測性の成熟度の値のドライバー](/docs/new-relic-solutions/observability-maturity/introduction)をよく理解している。これは、テレメトリのグループに値と優先順位を適用する上で非常に重要です。

以下の例は、テレメトリーインジェストをどのように評価し、予算内に収めるために必要な、時には難しい決断を下すかをイメージするのに役立ちます。これらの例はそれぞれバリュードライバーに焦点を当てようとしていますが、ほとんどのインスツルメンテーションは1つ以上のバリュードライバーに貢献しています。これはデータインジェストガバナンスの最も難しい部分です。

<CollapserGroup>
  <Collapser
    id="case-study-1"
    title="例1．稼働率・信頼性の重視"
  >
    アカウントは、予算よりも約20％多く取り込みます。彼らはマネージャーから消費を減らす方法を見つけるように頼まれました。それらの最も重要なバリュードライバーは**、稼働時間、パフォーマンス、および信頼性**です。

    <img
      src={valuedriversuptime}
      alt="Observability value drivers with a focus on uptime and reliability"
      title="Observability value drivers with a focus on uptime and reliability"
      style={{width: "400px"}}
    />

    <figcaption>
      稼働時間と信頼性に重点を置いた可観測性バリュードライバー。
    </figcaption>

    彼らの遺産は以下の通りです。

    * APM (dev、staging、prod)

    * ディストリビューティッド（分散）トレーシング

    * ブラウザ

    * 100台のホストのインフラストラクチャ監視

    * K8sのモニタリング（dev, staging, prod）

    * ログ（dev, staging, prod - debugを含む）

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * デバッグログを省略する（問題がある場合はオンにできることを承知で）（5%節約できる）
        * Kubernetesクラスターエクスプローラーを表示するために必要のないいくつかのK8s状態メトリックを省略します（10％節約）
        * 新機能のA/Bテストを多く行っていた頃に収集していたカスタムブラウザのイベントを削除（10%節約可能）
      </Callout>

      これらの変更を実行した後、チームは予算を5％下回るようになり、NPMパイロットを実行するためのスペースが解放されました。彼らのマネージャーは、大幅な稼働時間と信頼性の可観測性を失わないことに満足しています。

      <Callout
        variant="IMPORTANT"
        title="最終結果"
      >
        * 当初予算より5%減
        * 稼働時間、パフォーマンス、および信頼性の目標を提供するNPMパイロット用に作成されたヘッドルーム
        * 稼働時間と信頼性の可観測性の損失を最小限に抑える
      </Callout>
  </Collapser>

  <Collapser
    id="case-study-2"
    title="例2:カスタマーエクスペリエンスへの注力"
  >
    モバイルモニタリングとブラウザモニタリングに重点を置いた新しいユーザー向けプラットフォームを担当するチームは、予算を50％上回っています。摂取量を適切なサイズにする必要がありますが、**カスタマーエクスペリエンス**の可観測性を犠牲にしないことに固執しています。

    <img
      src={valuedriverscustomer}
      alt="Observability value drivers with a focus on customer experience"
      title="Observability value drivers with a focus on customer experience"
      style={{width: "400px"}}
    />

    <figcaption>
      **カスタマーエクスペリエンス**に焦点を当てた可観測性バリュードライバー
    </figcaption>

    彼らの遺産は以下の通りです。

    * モバイル

    * ブラウザ

    * APM

    * ディストリビューティッド（分散）トレーシング

    * プロセスサンプルを含む30台のホスト上のインフラ

    * バックエンドの非同期プロセスのサーバーレス監視

    * そのサーバーレス機能からのログ

    * 各種クラウドインテグレーション

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * サーバーレスのログを省略する（基本的にLambdaとの連携で得られるものと冗長になっている）
        * そのホストのプロセスのサンプルレートを1分ごとに減少させる
        * DEV環境でのサンプルデータのドロップ処理
        * New Relic infra agentが提供する他のインフラ監視と冗長性が高いEC2統合をオフにする。
      </Callout>

      <Callout
        variant="IMPORTANT"
        title="最終結果"
      >
        * 当初予算より5％オーバー
        * ピークシーズンを乗り切るのに十分
        * 顧客体験の観測可能性を損なわない
      </Callout>

      変更を実行した後、元の予算をわずか5％上回っていますが、ピークシーズンを乗り切るにはこれで十分であると彼らは結論付けています。
  </Collapser>

  <Collapser
    id="case-study-3"
    title="例3：イノベーションへの注力"
  >
    あるチームが、大規模なPythonモノリスを4つのマイクロサービスにリファクタリングしている最中です。モノリスは、顧客データベースやキャッシュレイヤーなど、多くのインフラを新しいアーキテクチャと共有しています。彼らは予算を70%超過しており、モノリスを正式に廃止するまであと2ヶ月しかない。

    <img
      src={valuedriversinnovation}
      alt="Observability value drivers with a focus on Innovation and Growth"
      title="Observability value drivers with a focus on Innovation and Growth"
      style={{width: "400px"}}
    />

    <figcaption>
      **イノベーションと成長**に焦点を当てた可観測性の価値ドライバー。
    </figcaption>

    彼らの遺産は以下の通りです。

    * K8sの監視（マイクロサービス）

    * New Relic ホスト監視 (monolith)

    * APM（マイクロサービス、ホスト監視）

    * 分散トレース(マイクロサービス、ホスト監視)

    * Postgresql（共有）

    * Redis(共有)

    * MSSQL (マイクロサービスアーキテクチャのための将来のDB)

    * ロードバランサーのログ取得（マイクロサービス、ホスト監視）

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * ロードバランサーのログを5xxレスポンスコードのみ監視するように設定する（monolith）
        * モノリスを実行しているホストの`ProcessSample` 、 `StorageSample` 、および`NetworkSample`から60秒のカスタムサンプルレート
        * 現在、新しいアーキテクチャではMSSQLを使用していないため、MSSQLの監視を無効にします。
        * モノリスの分散トレースは、マイクロサービスアーキテクチャではあまり役に立たないので、無効にしてください。
      </Callout>

      <Callout
        variant="IMPORTANT"
        title="最終成果"
      >
        * 当初予算を1％下回る
        * **イノベーションと成長**の可観測性を失うことはありません
      </Callout>
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  使い慣れたタスク管理ツールで計画を追跡することをお勧めします。これは、最適化計画を管理し、各最適化タスクがもたらす効果を理解するのに役立ちます。この [データ最適化計画テンプレート](https://docs.google.com/spreadsheets/d/1CimLpALwl1Z9f41vzbNWx00bGcED9XPV3s4ROqVEnr0/copy)を使用できます。
</Callout>

### データ削減のテクニックを使って、計画を実行する [#use-reduction-techniques]

この段階で、アカウント内のすべての種類のテレメトリと、それがバリュードライバーとどのように関連しているかについて考えました。このセクションでは、さまざまなテレメトリタイプを削減する方法に関する詳細な技術的手順と例を提供します。

データ削減に取り組むには、主に2つの方法があります。

* 構成を通じて
* ドロップルールを使用して

#### コンフィギュレーションによる最適化 [#optimization-through-configuration]

このセクションには、データのレポートと取り込みを最適化するためにNewRelicの機能を構成するさまざまな方法が含まれています。

<CollapserGroup>
  <Collapser
    id="apm-agent"
    title="APMエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象取引
      * エラー活動
      * カスタムイベント
    </Callout>

    APMエージェントが生成するデータ量は、いくつかの要因によって決定される。

    * アプリケーションによって生成される有機トラフィックの量（たとえば、1日に100万回呼び出されるアプリケーションと等しいすべてのものは、1日に1000回呼び出されるアプリケーションよりも多くのデータを生成します）

    * 基礎となるトランザクションデータ自体のいくつかの特徴（URLの長さと複雑さ）

    * アプリケーションがデータベースクエリーを報告しているかどうか

    * アプリケーションに多くの（または任意の）カスタム属性を持つトランザクションがあるかどうか

    * アプリケーションのエラー量

    * アプリケーションエージェントが分散トレース用に設定されているかどうか

      ### 容量の管理

      ビジネスをサポートするには、アプリケーションへのすべての呼び出しが必要であると想定できますが、アーキテクチャ全体でより節約できる可能性があります。極端な場合、クライアントによって10秒ごとに呼び出されるユーザープロファイルマイクロサービスがある場合があります。これにより、一部のユーザー情報が他のクライアントによって更新された場合の遅延を減らすことができます。ただし、私たちが持っている1つの手段は、このサービスへの呼び出しの頻度を、たとえば1分ごとに減らすことです。

      ### カスタムアトリビュート

      APM API [addCustomParameter](https://developer.newrelic.com/collect-data/custom-attributes/)の呼び出しを使用して追加された[カスタム属性](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/)は、トランザクションペイロードに追加の属性を追加します。これらは多くの場合便利ですが、アプリケーションロジックと優先順位が変わると、データの価値が低下したり、時代遅れになったりする可能性があります。

      Javaエージェントは、デフォルトで以下のrequest.headerをキャプチャします。

    * request.headers.referer

    * request.headers.accept

    * request.headers.contentLength

    * request.headers.host

    * request.headers.userAgent

      開発者は、 `addCustomParameter`を使用して追加情報（より詳細なヘッダーになる可能性があります）をキャプチャすることもできます。

      APMに関連して利用できる豊富な構成の例については、 [Javaエージェントのドキュメント](/docs/apm/agents/java-agent/attributes/java-agent-attributes/#requestparams)を参照してください。

      ### エラーイベント

      エラーがAPMによってどのように処理されるかを決定することが可能です。これにより、場合によってはデータの量を減らすことができます。たとえば、現時点では削除できない大量の無害なエラーが発生する可能性があります。

      `collect` 、 `ignore` 、または`mark as expected`の機能があります。詳細については、「 [APMエラーの管理](/docs/apm/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected)」を参照してください。

      ### データベースクエリ

      APMインスタンスで大きく変動するのは、データベースの呼び出し回数と、どのような設定をしたかという点です。データベースクエリの監視をどの程度冗長にするかは、かなりコントロールできます。これらのクエリは、トランザクショントレースページに表示されます。

      一般的なデータベースクエリの設定変更は以下の通りです。

    * [難読化されたクエリデータではなく、生のクエリデータを収集する、またはクエリの収集をオフにする](/docs/apm/transactions/transaction-traces/configure-transaction-traces#record-sql)

    * スタックトレースの閾値の変更

    * クエリの説明プラン収集をオンにする

      詳細については、 [トランザクショントレースデータベースクエリページ](docs/apm/transactions/transaction-traces/transaction-traces-database-queries-page/#settings)を参照してください。

      ### イベント制限の設定

      APMとモバイルエージェントには、収穫サイクルごとに報告できるイベントの数に制限があります。制限がない場合、送信されるイベントの数が非常に多いと、アプリケーションまたはNewRelicのパフォーマンスに影響を与える可能性があります。制限に達すると、エージェントは、収穫サイクル全体のイベントの代表的なサンプルを提供するために、イベントのサンプリングを開始します。エージェントが異なれば、制限も異なります。

      キャップされ、サンプリングの対象となるイベントは以下の通りです。

    * エージェントAPIを介して報告されたカスタムイベント（たとえば、.NETエージェントの`RecordCustomEvent` ）

    * `Mobile`

    * `MobileCrash`

    * `MobileHandledException`

    * `MobileRequest`

    * `Span` （分散トレースサンプリングを参照）

    * `Transaction`

    * `TransactionError`

      ほとんどのエージェントには、サンプリングされたトランザクションのイベント制限を変更するための構成オプションがあります。たとえば、Javaエージェントは[max_samples_stored](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored)を使用します。 `max_samples_stored`のデフォルト値は`2000`で、最大値は`10000`です。この値は、エージェントインスタンスから60秒ごとに報告できるサンプリングされたイベントの数を示します。

      イベントサンプリング制限の完全な説明については、[イベント](/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling)制限を参照してください。

      NRQL [`EXTRAPOLATE`演算子](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#extrapolate)を使用して、サンプリングされたイベントを補正できます。

      サンプリングの方法を変更する前に、以下の注意点と推奨事項をお読みください。

    * レポートするイベントが多いほど、エージェントが使用するメモリも多くなります。

    * 通常、エージェントのイベントレポートの制限を上げることなく、必要なデータを取得できます。

    * ペイロードサイズの制限は1MB（10 ^ 6バイト）（圧縮）であるため、イベントの数は引き続きその制限の影響を受ける可能性があります。イベントがドロップされているかどうかを確認するには、エージェントログで`413 HTTP`ステータスメッセージを確認してください。

      ### トランザクショントレース

      <Callout
        variant="IMPORTANT"
        title="成長ドライバー"
      >
        * 接続サービス数
        * 接続サービスごとの監視対象メソッドコール数
      </Callout>

      APMでは、[トランザクショントレース](/docs/apm/transactions/transaction-traces/transaction-traces)は、アプリケーションのトランザクションとデータベース呼び出しに関する詳細を記録します。トランザクショントレースのデフォルト設定を編集できます。これは、[トランザクショントレード構成](/docs/apm/transactions/transaction-traces/configure-transaction-traces)を介して高度に構成することもできます。多くの場合、構成可能性のレベルとモードは言語固有です。

      サーバーサイドの設定を使用して利用できるトランザクショントレースの設定は、使用するNew Relicエージェントによって異なります。UI には、それぞれの説明が記載されています。UI での設定には、以下のものが含まれる場合があります。

    * トランザクショントレーシングと閾値

    * 記録レベルと入力フィールドなどの、SQLを記録する

    * SQLとスタックトレースの閾値をログする

    * SQLクエリプランと閾値

    * HTTPコードとエラークラスなどの、エラーの収集

    * 遅いクエリのトレース

    * スレッドプロファイラー

      ### ディストリビューティッド（分散）トレーシング

      分散トレース構成には、言語固有の違いがいくつかあります。

      分散トレースは、必要に応じて無効にすることができます。これはJavaエージェント`newrelic.yml`の例です：

      ```
      distributed_tracing:
          enabled: false
      ```

      これはnode.jsの例です `newrelic.js`

      ```
      distributed_tracing: {
        enabled: false
      }
      ```

      データ量は、 [InfiniteTracing](/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing)を使用しているかどうかによっても異なります。

      APMエージェント（上）の標準ディストリビューティッド（分散）トレーシングはトレースの最大10%を取得しますが、すべてのデータを分析し、最も関連のあるトレースを検索すると、無限トレーシングを設定できます。この標準ディストリビューティッド（分散）トレーシングの代替は、C SDKを除く、すべてのAPM言語エージェントに使用できます。

      月間の摂取量を少しでも増やすための主なパラメータは以下の通りです。

    * トレースオブザーバモニタリングの設定

    * span属性トレースフィルターの設定

    * ランダムトレースフィルターの設定
  </Collapser>

  <Collapser
    id="browser-agent"
    title="Browserエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ページロード
      * Ajaxコール
      * エラー活動
    </Callout>

    [ブラウザエージェントバージョン1211](/docs/release-notes/new-relic-browser-release-notes/browser-agent-release-notes)以降の場合、ページによって行われたすべてのネットワーク要求は`AjaxRequest`イベントとして記録されます。アプリケーション設定UIページの拒否リスト構成オプションを使用して、レコードイベントを記録する要求をフィルタリングできます。このフィルターに関係なく、すべてのネットワークリクエストはメトリックとしてキャプチャされ、AJAXページで利用できます。

    ### 拒否リストの使用

    リクエストは3つの方法でブロックされます。

    * すべての`AjaxRequest`イベントの記録をブロックするには、ワイルドカードとしてアスタリスク\*を追加します。

    * ドメインへの`AjaxRequest`イベントの記録をブロックするには、ドメイン名のみを入力します。例： `example.com`

    * 特定のドメインとパスへの`AjaxRequest`イベントの記録をブロックするには、ドメインとパスを入力します。例： `example.com/path`

    * 拒否リストでは、URLのプロトコル、ポート、サーチ、ハッシュは無視されます。

      追加したフィルタが期待通りに動作するかどうかを検証するために、フィルタにマッチするAjaxRequestイベントのNRQLクエリを実行します。

      ### 拒否リストにアクセスする

      アプリケーションがイベントの作成からフィルタリングするURLの拒否リストを更新するには、アプリ設定のUIページに移動します。

    1. [one.newrelic.com](http://one.newrelic.com/)にアクセスし、\[ブラウザ]をクリックします。

    2. アプリを選択します。

    3. 左のナビゲーションで、 **アプリの設定** をクリックします。

    4. **Ajaxリクエスト拒否リスト**の下に、適用するフィルターを追加します。

    5. **Save application settings** を選択して、エージェントの設定を更新します。

    6. ブラウザエージェントを再デプロイします（関連するAPMエージェントを再起動するか、ブラウザのコピー/貼り付けのインストールを更新します）。

       ### バリデーション

       ```
       FROM AjaxRequest SELECT * WHERE requestUrl LIKE `%example.com%`
       ```
  </Collapser>

  <Collapser
    id="mobile-agent"
    title="モバイルエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 月間アクティブユーザー数
      * クラッシュイベント
      * ユーザーごとのイベント数
    </Callout>

    ### Android

    エージェントを呼び出すための呼び出しを含むすべての設定は、 `MainActivity`クラスの`onCreate`メソッドで呼び出されます。設定を変更するには、次の2つの方法のいずれかで設定を呼び出します（設定でサポートされている場合）。

    ```
    NewRelic.disableFeature(FeatureFlag.DefaultInteractions);
    NewRelic.enableFeature(FeatureFlag.CrashReporting);
    NewRelic.withApplicationToken(<var>NEW_RELIC_TOKEN</var>).start(this.getApplication());
    ```

    [分析設定](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#analytics-settings)は、イベントデータの収集を有効または無効にします。これらのイベントはNewRelicに報告され、**クラッシュ分析**ページで使用されます。

    [エージェントのログ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#logging-settings-logging)を多かれ少なかれ冗長になるように構成することもできます。

    ### iOS

    Androidと同様に、New RelicのiOS構成では、 [機能フラグ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags)を有効または無効にできます。

    以下の機能フラグを設定することができます。

    #### クラッシュとエラーの報告

    * NRFeatureFlag_CrashReporting

    * NRFeatureFlag_HandleExceptionEvents

    * NRFeatureFlag_CrashReporting

      #### ディストリビューティッド（分散）トレーシング

    * NRFATUREFLAG_DistributedTracing

      #### 相互作用

    * NRFeatureFlag_DefaultInteractions

    * NRFureFlag_InteractionTracing

    * NRFureFlag_SwiftInteractionTracing

      #### ネットワーク機能フラグ

    * NRFeatureFlag_ExperimentalNetworkInstrumentation

    * NRFeatureFlag_NSURLSessionInstrumentation

    * NRFeatureFlag_NetworkRequestEvents

    * NRFeatureFlag_RequestErrorEvents

    * NRFeatureFlag_HttpResponseBodyCapture

      詳細については、 [機能フラグ](/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/ios-agent-configuration-feature-flags)を参照してください。
  </Collapser>

  <Collapser
    id="infrastructure-agent"
    title="インフラストラクチャー・エージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ホストとコンテナの監視
      * コアイベントのサンプリングレート
      * プロセスサンプル構成
      * カスタムアトリビュート
      * インストールされているオンホストインテグレーションの数および種類
      * ログ転送の設定
    </Callout>

    New Relicの[インフラストラクチャエージェント構成ファイル](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings)には、取り込み量を制御するための強力な方法がいくつか含まれています。最も重要なのは、サンプリングレートを使用することです。使用できるいくつかの異なるサンプリングレート構成があります。

    もう1つは、カスタムプロセスサンプルフィルターを使用する方法です。

    ### サンプリングレート

    インフラストラクチャで設定可能なサンプリングレートは多数ありますが、最も一般的に使用されるのはこれらのレートです。

    | パラメータ                                            | デフォルト | 無効化 |
    | ------------------------------------------------ | ----- | --- |
    | メトリクス・ストレージ・サンプル・レート（metrics_storage_sample_rate | 5     | -1  |
    | メトリクス・プロセス・サンプル・レート（metrics_process_sample_rate  | 20    | -1  |
    | metrics_network_sample_rate                      | 10    | -1  |
    | メトリクス・システム・サンプル・レート（metrics_system_sample_rate   | 5     | -1  |
    | Metrics_nfs_sample_rate                          | 5     | -1  |

    ### プロセスサンプル

    プロセスサンプルは、インフラストラクチャエージェントからの単一の最も大量のデータソースになる可能性があります。これは、ホスト上で実行中のプロセスに関する情報を送信するためです。これらはデフォルトで無効になっていますが、次のように有効にできます。

    ```
    enable_process_metrics: true
    ```

    これは、 `metrics_process_sample_rate`を-1に設定するのと同じ効果があります。

    デフォルトでは、メモリ不足のプロセスはサンプリングから除外されます。詳細については、 `disable-zero-mem-process-filter`を参照してください。

    `include_matching_metrics`を設定することで、New Relicに送信されるデータの量を制御できます。これにより、メトリック[属性](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql#naming-conventions)の値に基づいてメトリックデータの送信を制限できます。

    メトリックの属性のいずれかにリテラル値または部分値を定義することにより、メトリックデータを含めます。たとえば、 `process.name`が^java正規表現と一致するすべてのプロセスの`host.process.cpuPercent`を送信するように選択できます。

    この例では、実行ファイルと名前を使ってプロセスメトリクスを含めています。

    ```
    include_matching_metrics: # You can combine attributes from different metrics
        process.name:
          - regex “^java”    # Include all processes starting with "java"
        process.executable:
          - “/usr/bin/python2”              # Include the Python 2.x executable
          - regex “\\System32\\svchost”     # Include all svchost executables
    ```

    また、このフィルターはKubernetesの統合にも使用できます。

    ```
    env:
        - name: NRIA_INCLUDE_MATCHING_METRICS
          value: |
            process.name:
              - regex "^java"
            process.executable:
              - "/usr/bin/python2"
              - regex "\\System32\\svchost"
    ```

    ### ネットワークインターフェースフィルタ

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視するネットワーク・インターフェース数
    </Callout>

    この設定では、シンプルなパターンマッチングメカニズムを使用しており、いずれかのパターンに続く特定の文字または数字のシーケンスで始まるインターフェースを探すことができます。

    * `{name}[other characters]`

    * `[number]{name}[other characters]`、ここで`index-1`オプションを使用して名前を指定します

      ```
      network_interface_filters:
        prefix:
          - dummy
          - lo
        index-1:
          - tun
      ```

      Linuxのデフォルトのネットワークインターフェイスフィルタ。

    * `dummy` 、 `lo` 、 `vmnet` 、 `sit` 、 `tun` 、 `tap` 、または `veth`

    * `tun`またはを含むネットワークインターフェース `tap`

      Windowsのデフォルトのネットワークインターフェイスフィルタ。

    * `Loop` 、 `isatap` 、またはで始まるネットワークインターフェイス `Local`

      デフォルトを上書きするには、設定ファイルに独自のフィルタを記述します。

      ```
      network_interface_filters:
        prefix:
          - dummy
          - lo
        index-1:
          - tun
      ```

      ### カスタムアトリビュート

      [カスタム属性](/docs/data-apis/custom-data/custom-events/collect-custom-attributes)は、インフラストラクチャエージェントからのデータに注釈を付けるために使用されるキーと値のペア（他のツールのタグと同様）です。このメタデータを使用して、フィルターセットを作成し、結果をグループ化し、データに注釈を付けることができます。たとえば、マシンの環境（ステージングまたは本番）、マシンがホストするサービス（ログインサービスなど）、またはそのマシンを担当するチームを指定できます。

      からのカスタム属性の例 `newrelic.yml`

      ```
      custom_attributes:
        environment: production
        service: billing
        team: alpha-team
      ```

      これらは強力で便利ですが、データが適切に整理されていないか、何らかの形で廃止されている場合は、これらの合理化を検討する必要があります。
  </Collapser>

  <Collapser
    id="k8s-integration"
    title="Kubernetesインテグレーション"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視された`pods`と`containers`の数
      * kubeステートメトリクスの収集頻度と数
      * クラスタごとに生成されるログ
    </Callout>

    Kubernetesのような複雑で分散型のシステムが、多くのテレメトリを高速に生成する可能性があることは驚くべきことではありません。 Kubernetesでデータの取り込みを管理するための優れたアプローチがいくつかあります。 K8sデプロイメントでコードとして可観測性を使用している場合、これらは非常に簡単です。 K8の取り込みを減らすことを決定する前に、このKubernetesデータ取り込み分析ダッシュボードをインストールすることを強くお勧めします。このダッシュボードを入手するには、 [インフラストラクチャ統合のクイックスタート](https://newrelic.com/instant-observability/infrastructure-integrations-data-analysis/8e31a0ae-81c0-4df0-a119-a0ada9ec16fa)を参照してください。

    ### スクレイプ間隔

    可観測性の目的に応じて、スクレイプ間隔の調整を検討できます。デフォルトは15秒です。現在、Kubernetesクラスターエクスプローラーは45秒ごとにのみ更新されます。 K8sデータの主な用途がKCEの視覚化をサポートすることである場合は、スクレイプ間隔を20秒に変更することを検討してください。 15秒から20秒への変更は、大きな影響を与える可能性があります。これの管理の詳細については、 [Helm統合スクレイプ間隔のドキュメント](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#scrape-interval)を参照してください。

    ### Kubeステートメトリクス

    Kubernetes cluster explorerで必要なのは、以下のkube state metrics（KSM）のみです。

    * コンテナデータ

    * クラスターデータ

    * ノードデータ

    * ポッドデータ

    * ボリュームデータ

    * APIサーバーデータ<sup>1</sup>

    * コントローラマネージャデータ<sup>1</sup>

    * ETCDデータ<sup>1</sup>

    * スケジューラデータ<sup>1</sup>

      <sup>1</sup>管理されたKubernetes環境（EKS、GKE、AKSなど）では収集されません

      以下の一部を無効化することをご検討ください。

    * デーモンセットデータ

    * デプロイメントデータ

    * エンドポイントデータ

    * 名前空間データ

    * ReplicaSetデータ<sup>2</sup>

    * サービスデータ

    * StatefulSetデータ

      <sup>2</sup>デフォルトのアラートで使用：「ReplicaSetに必要な数のポッドがありません」

    #### マニフェストの状態メトリックを更新する例（デプロイメント）

    ```shell
    [spec]
      [template]
        [spec]
          [containers]
            [name=kube-state-metrics]
            [args]
            #- --collectors=daemonsets
            #- --collectors=deployments
            #- --collectors=endpoints
            #- --collectors=namespaces
            #- --collectors=replicasets
            #- --collectors=services
            #- --collectors=statefulsets
    ```

    _マニフェストの状態メトリックを更新する例（ClusterRole）_

    ```shell
    [rules]
    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - daemonsets
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - deployments
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - endpoints
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - namespaces
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - replicasets
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - services
    #   verbs: ["list", "watch"]

    # - apiGroups: ["apps"]
    #   resources:
    #   - statefulsets
    #   verbs: ["list", "watch"]
    ```

    ### `nri-bundle`チャートの構成`lowDataMode`

    当社のヘルムチャートは、詳細情報をドロップする代わりに、取り込まれるデータの量を減らすオプションの設定をサポートしています。有効にするには、 `nri-bundle`チャートで`global.lowDataMode`を`true`に設定します。

    `lowDataMode` `nri-bundle`チャートの3つの特定のコンポーネントに影響します。

    1. インフラストラクチャエージェントの間隔を`15` }秒から`30`秒に増やします。
    2. Prometheus OpenMetricsの統合では、以下のHelmドキュメントに示されているように、いくつかのメトリックが除外されます。
    3. ラベルと注釈の詳細はログから削除されます。

    この構成の詳細については、 [Helmドキュメント](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#reducedataingest)を参照してください。
  </Collapser>

  <Collapser
    id="on-host-integrations"
    title="オンホストインテグレーション"
  >
    New Relicのオンホスト統合は、Postgresql、MySQL、Kafka、RabbitMQなどのサードパーティサービスの多様な統合セットを表しています。このドキュメントの範囲内ですべての最適化手法を提供することはできませんが、これらの一般的に適用可能な手法を提供できます。 ：

    * サンプリングレートの管理

    * コレクションの幅を広げたり狭めたりできるコンフィグの部分を管理する。

    * カスタムクエリを可能にするコンフィグ部分の管理

    * インフラストラクチャーエージェントのカスタム属性は、ホスト上のすべての統合データに適用されるため、管理します。

      いくつかの例を使って説明します。

      ### [PostgreSQLの統合](/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration/#example-postgresSQL-collection-config)

      <Callout
        variant="IMPORTANT"
        title="成長ドライバー"
      >
        * 監視対象テーブル数
        * 監視対象指標数
      </Callout>

      PostgreSQLのオンホスト統合設定では、データ量の管理に役立つこれらの調整可能な設定が提供されています。

    * の間隔を指定します。デフォルトは15s

    * COLLECTION_LIST: 監視するテーブルのリスト (すべて監視する場合はALLを使用)

    * COLLECT_DB_LOCK_METRICS： `dblock`メトリックを収集します

    * PGBOUNCER： `pgbouncer`メトリックを収集します

    * collect_bloat_metrics:ブロートメトリクスを収集する

    * METRICS：メトリックのみを収集するには`true`に設定します

    * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

    * CUSTOM_METRICS_CONFIG: カスタムコレクションクエリを含むコンフィグファイル

      **サンプル構成：**

      ```
      integrations:
        - name: nri-postgresql
          env:
            USERNAME: postgres
            PASSWORD: pass
            HOSTNAME: psql-sample.localnet
            PORT: 6432
            DATABASE: postgres

            COLLECT_DB_LOCK_METRICS: false
            COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
            TIMEOUT:  10
          interval: 15s
          labels:
            env: production
            role: postgresql
          inventory_source: config/postgresql
      ```

      ### [Kafkaとの統合](/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration/)

      <Callout
        variant="IMPORTANT"
        title="成長ドライバー"
      >
        * クラスタ内のブローカー数
        * クラスタ内のトピック数
      </Callout>

      Kafkaのオンホスト統合設定では、データ量の管理に役立つ、これらの調整可能な設定が提供されています。

    * の間隔を指定します。デフォルトは15s

    * TOPIC_MODE：収集するトピックの数を決定します。オプションは、 `all` 、 `none` 、 `list` 、または`regex`です。

    * METRICS：メトリックのみを収集するには`true`に設定します

    * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

    * TOPIC_LIST。監視するトピック名のJSON配列。topic_mode が list に設定されている場合のみ有効。

    * COLLECT_TOPIC_SIZE：メトリックトピックサイズを収集します。オプションは`true`または`false`で、デフォルトは`false`です。

    * COLLECT_TOPIC_OFFSET：メトリックトピックオフセットを収集します。オプションは`true`または`false`で、デフォルトは`false`です。

      トピックレベルのメトリック、特にオフセットの収集は、収集するのにリソースを大量に消費する可能性があり、データ量に影響を与える可能性があることに注意してください。クラスターに新しいKafkaトピックを追加するだけで、クラスターの取り込みが1桁増加する可能性があります。

      ### [MongoDBとの連携](/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration)

      <Callout
        variant="IMPORTANT"
        title="成長ドライバー"
      >
        * 監視対象データベース数
      </Callout>

      MongoDBとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

    * の間隔を指定します。デフォルトは15s

    * METRICS：メトリックのみを収集するには`true`に設定します

    * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

    * FILTERS: データベース名とコレクション名の配列のJSONマップ。空の場合、デフォルトはすべてのデータベースとコレクションです。

      使用するオンホスト統合では、デフォルトですべてのデータベースからメトリックを収集する`FILTERS`などのパラメーターに注意することが重要です。これは、監視の優先順位を使用して、収集されたデータを合理化できる領域です。

      **METRICとINVENTORYの間隔が異なる構成例：**

      ```
      integrations:
        - name: nri-mongodb
          env:
            METRICS: true
            CLUSTER_NAME: my_cluster
            HOST: localhost
            PORT: 27017
            USERNAME: mongodb_user
            PASSWORD: mongodb_password
          interval: 15s
          labels:
            environment: production

        - name: nri-mongodb
          env:
            INVENTORY: true
            CLUSTER_NAME: my_cluster
            HOST: localhost
            PORT: 27017
            USERNAME: mongodb_user
            PASSWORD: mongodb_password
          interval: 60s
          labels:
            environment: production
          inventory_source: config/mongodb
      ```

      ### [Elasticsearchの統合](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration)

      <Callout
        variant="IMPORTANT"
        title="成長ドライバー"
      >
        * クラスタ内のノード数
        * クラスタ内のインデックス数
      </Callout>

      Elasticsearchとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

    * の間隔を指定します。デフォルトは15s

    * METRICS：メトリックのみを収集するには`true`に設定します

    * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

    * COLLECT_INDICES: インデックスを収集するかどうかを示す。

    * COLLECT_PRIMARIES: プライマリーメトリクスを収集するかどうかをシグナリングする。

    * INDICES_REGEX: どのインデックスを収集するかフィルタリングする。

    * MASTER_ONLY: 選出されたマスタのみで、クラスタ・メトリクスを収集します。

      **METRICとINVENTORYの間隔が異なる構成例：**

      ```
      integrations:
        - name: nri-elasticsearch
          env:
            METRICS: true
            HOSTNAME: localhost
            PORT: 9200
            USERNAME: elasticsearch_user
            PASSWORD: elasticsearch_password
            REMOTE_MONITORING: true
          interval: 15s
          labels:
            environment: production

        - name: nri-elasticsearch
          env:
            INVENTORY: true
            HOSTNAME: localhost
            PORT: 9200
            USERNAME: elasticsearch_user
            PASSWORD: elasticsearch_password
            CONFIG_PATH: /etc/elasticsearch/elasticsearch.yml
          interval: 60s
          labels:
            environment: production
          inventory_source: config/elasticsearch
      ```

      ### [JMXの統合](/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration)

      <Callout
        variant="IMPORTANT"
        title="成長ドライバー"
      >
        * COLLECTION_CONFIGSに記載されている指標
      </Callout>

      JMXの統合は、本質的に汎用的です。これは、任意のJMXインスタンスからメトリクスをスクレイピングすることを可能にします。この統合によって収集されるものについては、十分な量の制御が可能です。一部のエンタープライズ向け New Relic 環境では、JMX メトリクスが収集される全データの中で比較的高い割合を占めています。

      JMX統合は、データ量の管理に役立つこれらの調整可能な設定を提供します。

    * の間隔を指定します。デフォルトは15s

    * METRICS：メトリックのみを収集するには`true`に設定します

    * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

    * METRIC_LIMIT: エンティティごとに収集可能なメトリクスの数。この制限を超えた場合、そのエンティティは報告されない。0は制限なしを意味する。

    * LOCAL_ENTITY：ローカル・エンティティのすべてのメトリクスを収集します。localhostを監視するときのみ使用。

    * COLLECTION_FILES: メトリックコレクション定義ファイルへの完全なファイルパスのカンマ区切りリストです。オンホストインストールの場合、デフォルトの JVM メトリックコレクションファイルは、 /etc/newrelic-infra/integrations.d/jvm-metrics.yml にあります。

    * COLLECTION_CONFIG: JSONとしてのメトリクスコレクションの構成。

      取り込まれるデータの量を最も支配するのはCOLLECTION_CONFIGエントリです。スクレイピングしているJMXモデルを理解すると、最適化に役立ちます。

      _JVMメトリクスのためのCOLLECTION_CONFIGの例_

      ```
      COLLECTION_CONFIG='{"collect":[{"domain":"java.lang","event_type":"JVMSample","beans":[{"query":"type=GarbageCollector,name=*","attributes":["CollectionCount","CollectionTime"]},{"query":"type=Memory","attributes":["HeapMemoryUsage.Committed","HeapMemoryUsage.Init","HeapMemoryUsage.Max","HeapMemoryUsage.Used","NonHeapMemoryUsage.Committed","NonHeapMemoryUsage.Init","NonHeapMemoryUsage.Max","NonHeapMemoryUsage.Used"]},{"query":"type=Threading","attributes":["ThreadCount","TotalStartedThreadCount"]},{"query":"type=ClassLoading","attributes":["LoadedClassCount"]},{"query":"type=Compilation","attributes":["TotalCompilationTime"]}]}]}'
      ```

      `NonHeapMemoryUsage.Init`など、その構成から1つのエントリを省略すると、収集されるデータ量全体に具体的な影響があります。

      _Tomcatのメトリクス用COLLECTION_CONFIGの例_

      ```
      COLLECTION_CONFIG={"collect":[{"domain":"Catalina","event_type":"TomcatSample","beans":[{"query":"type=UtilityExecutor","attributes":["completedTaskCount"]}]}]}
      ```

      ### その他のオンホストインテグレーション

      その他にも、収集の最適化に役立つ設定オプションを持つオンホスト統合が多数あります。よく使われるものをいくつか紹介します。

    * [NGINX](/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-advanced-config)

    * [MySQL](/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration)

    * [Redis](/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration)

    * [アパッチ](/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration)

    * [RabbitMQ](/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration)

      これは良い [スタート地点](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations#on-host) もっと学ぶために。
  </Collapser>

  <Collapser
    id="network-performance-monitoring"
    title="ネットワークパフォーマンスモニタリング（NPM）"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      駆動するモニター機器。

      * ハードコンフィグデバイス
      * ディスカバリーセクションのCIDRスコープ
      * トラップ設定
    </Callout>

    このセクションでは、Kentikの`ktranslate`エージェントに依存するNewRelicのネットワークパフォーマンスモニタリングに焦点を当てます。このエージェントは非常に洗練されており、主要な最適化を行う前に、[高度な構成ドキュメント](/docs/network-performance-monitoring/advanced/advanced-config)を完全に理解することが重要です。構成オプションは次のとおりです。

    * mibs_enabled。ktranslate ドッカーイメージがポーリングするすべてのアクティブな MIB の配列です。このリストは、discovery_add_mibs 属性が true の場合、検出時に自動的に生成されます。ここにリストアップされていない MIB は、設定ファイル内のどのデバイスでもポーリングされません。MIB-NAME.tableName構文を使用して、MIBファイル内でSNMPテーブルを直接指定することができます。例：HOST-RESOURCES-MIB.hrProcessorTable.HOST-RESOURCES-MIB.hrProcessorテーブル。

    * user_tags: キーと値のペアの属性で、デバイスにさらにコンテキストを与えます。このレベルのタグは、コンフィギュレーションファイル内の全てのデバイスに適用されます。

    * のデバイスを使用します。流量を監視する機器をリストアップするセクション

    * traps: SNMP トラップを監視する IP およびポートを設定します（デフォルトは 127.0.0.1:1162 です）。

    * 発見：エンドポイントを発見する方法を設定します。このセクションでは、以下のパラメータがスコープを拡大または縮小するために最も効果的です。

      * cidrs:Array of target IP ranges in [CIDR notation](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation).
      * ポートです: SNMPポーリング中にスキャンするターゲットポートの配列。
      * debug：検出中にデバッグレベルのログを有効にするかどうかを示します。デフォルトでは、 `false`
      * default_communities。SNMPポーリング中にスキャンするSNMPv1/v2cコミュニティ文字列の配列。この配列は順番に評価され、ディスカバリーは最初に通過したコミュニティを受け入れます。

      可観測性のニーズに見合う価値を生み出さないデータのフィルタリングをサポートするために、 `global.match_attributes.{}`または`devices.<deviceName>.match_attributes.{}`属性マップを設定できます。

      これにより、New Relicにデータを送信する前に、ktranslateレベルでフィルタリングが提供され、インターフェースなどの監視をきめ細かく制御できるようになります。

      詳細については、[ネットワークパフォーマンス監視の構成](/docs/network-performance-monitoring/advanced/advanced-config/#match_attributes-attribute)を参照してください。
  </Collapser>

  <Collapser
    id="log-forwarders"
    title="ログフォワーダー"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ログ転送
      * フォワードログの平均レコードサイズ
    </Callout>

    ログは、通常、独自のルーティングルールと変換ルールを備えた専用の転送レイヤーを介してログをルーティングするという点で、テレメトリの最も柔軟なソースの1つです。さまざまなフォワーダーがあるため、最も一般的に使用されるフォワーダーに焦点を当てます。

    * Fluentd

    * Fluentbit

    * New Relic インフラエージェント (Fluentbit 内蔵)

    * Logstash

      フォワーダーは通常、フィルタリングと変換を含むかなり完全な[ルーティングワークフロー](https://docs.fluentd.org/configuration/routing-examples)を提供します。 New Relicのインフラストラクチャエージェントは、不要なログをフィルタリングするための非常に単純なパターンをいくつか提供します。レコードをフィルタリングするための正規表現。 tail、systemd、syslog、およびtcp（フォーマットなしの場合のみ）ソースでのみサポートされます。このフィールドは、Unixシステムのgrep-Eと同じように機能します。たとえば、キャプチャされている特定のファイルについて、次を使用して`WARN`または`ERROR`を含むレコードをフィルタリングできます。

      ```

      ```

    * 名前：only-records-with-warn-and-errorファイル：/var/log/logFile.logパターン：WARN | ERROR

      ```

      If you have pre-written Fluentd configurations for Fluentbit that do valuable filtering or parsing, you can import them into our New Relic logging config. To do this, use the `config_file` and `parsers` parameters in any `.yaml` file in your `logging.d` folder: 
      ```

    * `config_file`：既存のFluentBit構成ファイルへのパス。ソースが重複していると、NewRelicのログ管理でメッセージが重複します。

    * `parsers_file`：既存のFluentBitパーサーファイルへのパス。

      次のパーサー名が予約されています： `rfc3164` 、 `rfc3164-local` 、および`rfc5424` 。

      データパイプラインのログに属性（またはタグ）を挿入する方法と変換を実行する方法を学ぶと、NewRelicドロップルールを使用してダウンストリーム機能をドロップするのに役立ちます。ソースに関するメタデータを使用してログを拡張することにより、バックエンドに何をドロップするかについて、一元化された簡単に元に戻せる決定を行うことができます。少なくとも、次の属性が何らかの形でログに存在することを確認してください。

    * チーム

    * 環境(dev/stage/prod)

    * アプリケーション

    * データセンター

    * ログレベル

      以下は、ルーティングとフィルタリングの詳細なリソースです。

    * [Fluentdの一般的なフィルタとルーティングのパターン](https://docs.fluentd.org/configuration/routing-examples)

    * [Fluentbitデータパイプライン](https://docs.fluentbit.io/manual/concepts/data-pipeline)

    * [New Relic インフラストラクチャエージェントによるログの転送](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/)
  </Collapser>

  <Collapser
    id="prometheus-metrics-sources"
    title="Prometheusのメトリクスソース"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * アプリからエクスポートされたメトリクス数
      * リモートライトまたはPOMIで転送されたメトリクス数
    </Callout>

    New Relicは、PrometheusメトリックをNewRelicに送信するための2つの主要なオプションを提供します。このドキュメントでメトリックの取り込みを管理するためのベストプラクティスは、主にオプション2（Prometheus OpenMetrics統合（POMI））に焦点を当てています。これは、このコンポーネントがNewRelicによって作成されたためです。

    ### オプション1： [Prometheusリモート書き込み統合](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)

    Prometheusサーバーのスクレイプ構成オプションについては [、Prometheus構成ドキュメント](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)を参照してください。これらのスクレイプ構成は、Prometheusサーバーによって収集されるメトリックを決定します。 [remote_write](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)パラメーターを構成することにより、収集されたメトリックをNew Relic Metric APIを介してNewRelicデータベース（NRDB）に書き込むことができます。

    ### オプション2： [Prometheus OpenMetrics統合（POMI）](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration)

    POMIは、動的に発見されたPrometheusのエンドポイントと静的なエンドポイントの両方からメトリクスをスクレイピングするスタンドアローンの統合です。POMI は、このデータを New Relic Metric API 経由で NRDB に送信します。この統合は、現在 Prometheus Server を実行していないお客様にとって理想的です。

    #### POMI：スクレープレーベル

    POMIは、デフォルトでラベルまたは注釈`prometheus.io/scrape=true`を含むPrometheusエンドポイントを検出します。クラスタにデプロイされているものによっては、これは多数のエンドポイントになる可能性があるため、多数のメトリックが取り込まれる可能性があります。

    `scrape_enabled_label`パラメータをカスタム（たとえば`newrelic/scrape` ）に変更し、データの取り込みが最大の懸念事項である場合は、Prometheusエンドポイントに選択的にラベルを付けるか注釈を付けることをお勧めします。

    最新のリファレンス設定については、 [nri-prometheus-latest.yaml](https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml)を参照してください。

    **POMI構成パラメーター：**

    ```
    # Label used to identify scrapable targets. 
    # Defaults to "prometheus.io/scrape"
        scrape_enabled_label: "prometheus.io/scrape"
    ```

    POMIは、デフォルトでノードレベルで公開されているPrometheusのエンドポイントを検出します。これは通常、Kubelet と cAdvisor から来るメトリクスを含みます。

    New Relic Kubernetes Daemonsetを実行している場合は、POMIが重複するメトリックを収集しないように`require_scrape_enabled_label_for_nodes: true`を設定することが重要です。

    New Relic Kubernetes Daemonsetの対象となるエンドポイントについては、 [GitHubのKubernetesREADME](https://github.com/newrelic/nri-kubernetes/blob/main/README.md)を参照してください。

    #### POMI: ノードのラベルをスクレイプする

    POMIは、デフォルトでノードレベルで公開されているPrometheusのエンドポイントを検出します。これは通常、Kubelet と cAdvisor から来るメトリクスを含みます。

    New Relic Kubernetes Daemonsetを実行している場合は、POMIが重複するメトリックを収集しないようにrequire_scrape_enabled_label_for_nodes：trueを設定することが重要です。

    New Relic Kubernetes Daemonsetの対象となるエンドポイントについては、 [GitHubのKubernetesREADME](https://github.com/newrelic/nri-kubernetes/blob/main/README.md)を参照してください。

    _POMIコンフィグパラメーター_

    ```
    # Whether k8s nodes need to be labeled to be scraped or not. 
    # Defaults to false.
      require_scrape_enabled_label_for_nodes: false
    ```

    #### POMI：との共存 `nri-kubernetes`

    New Relicの[Kubernetes統合](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)は、箱から出してすぐに[多くのメトリック](/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data#metrics)を収集します。ただし、Kubernetesクラスターから利用可能なすべてのメトリックを収集するわけではありません。

    POMI構成には、これに似たセクションが表示されます。これにより、NewRelicKubernetes統合が**KubeStateMetrics**からすでに収集しているメトリックのサブセットのメトリック収集が**無効**になります。

    KubeletとcAdvisorの指標が重複しないように`require_scrape_enabled_label_for_node: true`を設定することも非常に重要です。

    **POMI構成パラメーター：**

    ```
    transformations:
        - description: "Uncomment if running New Relic Kubernetes integration"
          ignore_metrics:
            - prefixes:
              - kube_daemonset_
              - kube_deployment_
              - kube_endpoint_
              - kube_namespace_
              - kube_node_
              - kube_persistentvolume_
              - kube_persistentvolumeclaim_
              - kube_pod_
              - kube_replicaset_
              - kube_service_
              - kube_statefulset_

    ```

    #### POMI：リクエスト/リミット設定

    POMIを実行するときは、約500kDPMを生成するクラスターに次の[リソース制限](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/)を適用することをお勧めします。

    * CPU制限：1コア（1000m）

    * メモリ制限：1Gb 1024（1G）

      CPUとメモリのリソース要求は、POMIがクラスターから十分なリソースを受け取るように、適切な値に設定する必要があります。これを極端に低い値（CPU：50mなど）に設定すると、クラスターリソースが「ノイズの多いネイバー」によって消費される可能性があります。

      **POMI構成パラメーター：**

      ```
      …

      spec:
        serviceAccountName: nri-prometheus
        containers:
        - name: nri-prometheus
          image: newrelic/nri-prometheus:2.2.0
          resources:
            requests:
              memory: 512Mi
              cpu: 500m
            limits:
              memory: 1G
              cpu: 1000m

      …
      ```

      ### POMI：DPMとカーディナリティの推定

      カーディナリティはGBインジェストあたりの請求額とは直接関係ありませんが、New Relicはカーディナリティと1分あたりのデータポイントについて一定のレート制限を維持しています。Prometheus クラスタからカーディナリティと DPM を可視化できることは、非常に重要なことです。

      <Callout variant="tip">
        NewRelicアカウントには1MDPMと1Mカーディナリティの制限がありますが、最大15MDPMと15Mカーディナリティをリクエストできます。変更をリクエストするには、NewRelicアカウントの担当者にお問い合わせください。詳細については、「[メトリックAPIの制限](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes)」を参照してください。
      </Callout>

      すでにPrometheusServerを実行している場合は、POMIまたは`remote_write`を有効にする前に、そこでDPMとカーディナリティの見積もりを実行できます。

      **1分あたりのデータポイント（DPM）：**

      レート(prometheus_tsdb_head_samples_appended_total\[10m]) \* 60

      **上位20のメトリック（最高のカーディナリティ）：**

      ```
      topk(20, count by (**name**, job)({__name__=~".+"}))
      ```
  </Collapser>

  <Collapser
    id="cloud-integration"
    title="クラウドインテグレーション"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 統合ごとにエクスポートされるメトリクスの数
      * ポーリング頻度(ポーリングベースの統合の場合)
    </Callout>

    一部のNewRelicクラウド統合は、クラウドプロバイダーのAPIからデータを取得します。この実装では、データは通常、AWS CloudWatch、Azure Monitor、GCP StackdriverなどのモニタリングAPIから収集され、インベントリメタデータは特定のサービスのAPIから収集されます。

    他のクラウド統合は、AWS Kinesisなどのストリーミングサービスを介してプッシュされるストリーミングメトリック（または「プッシュ」メトリック）からデータを取得します。

    ### ポーリングAPIベースの統合

    クラウドインテグレーションからのデータをより多くまたはより少なく報告したい場合、あるいはクラウドアカウントのレートやスロットリングの制限に達しないようクラウドプロバイダーのAPIの使用を制御する必要がある場合、構成設定を変更して報告するデータ量を変更することができます。主な制御は次の2つです。

    * [ポーリング周波数の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#polling)

    * [データの報告内容の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#filter-data)

      投票頻度の変更を希望するビジネス上の理由の例としては、以下のようなものがあります。

    * **請求**：AWS CloudWatchの請求を管理する必要がある場合は、ポーリングの頻度を減らすことをお勧めします。これを行う前に、クラウド統合に設定されたアラート条件がこの削減の影響を受けないことを確認してください。

    * **新しいサービス**：新しいサービスまたは構成を展開していて、より頻繁にデータを収集する場合は、ポーリングの頻度を一時的に増やすことをお勧めします。

      <Callout variant="caution">
        統合のコンフィギュレーション設定を変更すると、アラート条件やチャートトレンドに影響を与える場合があります。
      </Callout>

      詳細については、「 [ポーリングの構成](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations)」を参照してください。

      ### 「ストリーミング」または「プッシュ」メトリック

      ますます多くのクラウド統合が、APIポーリングを使用する代わりに、[ストリーミングサービス](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream)を介してデータをプッシュするオプションを提供しています。これにより、レイテンシーが大幅に削減されることが証明されています。一部のユーザーが観察した問題の1つは、サンプリングレートを構成できないため、ボリュームの制御が簡単ではないことです。

      データをドロップするための新しいRelicルールについては、次のセクションで詳しく説明します。これらは、ボリュームが大きすぎるストリーミングメトリックを除外するための主要な方法です。ただし、ストリームの量をいくらか制限するために、クラウドプロバイダー側で実行できることがいくつかあります。

      たとえば、AWSでは、条件キーを使用[してCloudWatch\*名前空間へのアクセスを制限することができます](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/iam-cw-condition-keys-namespace.html)。

      次のポリシーは、ユーザーが`MyCustomNamespace`という名前空間でのみメトリックを公開するように制限します。

      ```
      {
          "Version": "2012-10-17",
          "Statement": {
              "Effect": "Allow",
              "Resource": "*",
              "Action": "cloudwatch:PutMetricData",
              "Condition": {
                  "StringEquals": {
                      "cloudwatch:namespace": "MyCustomNamespace"
                  }
              }
          }
      }
      ```

      次のポリシーにより、ユーザーはCustomNamespace2を除く任意の名前空間でメトリックを公開できます。

      ```
      {
          "Version": "2012-10-17",
          "Statement": [
              {
                  "Effect": "Allow",
                  "Resource": "*",
                  "Action": "cloudwatch:PutMetricData"
              },
              {
                  "Effect": "Deny",
                  "Resource": "*",
                  "Action": "cloudwatch:PutMetricData",
                  "Condition": {
                      "StringEquals": {
                          "cloudwatch:namespace": "CustomNamespace2"
                      }
                  }
              }
          ]
      }
      ```
  </Collapser>
</CollapserGroup>

#### ドロップルールによる最適化 [#optimization-with-drop-rules]

ドロップルールで何ができるかを理解するための簡単なルールは次のとおり**です。クエリを実行できる場合は、ドロップできます。**

ドロップフィルターのルールは、いくつかの重要な目標を達成するのに役立ちます。

* お客様のアカウントに関連するログのみを保存することで、コストを削減できます。
* 個人を特定できる情報（PII）を削除することで、プライバシーとセキュリティを保護します。
* 無関係なイベントや属性を削除して、ノイズを減らす。

**注意事項**：ドロップルールを作成するときは、設定した条件を満たすデータをルールが正確に識別して破棄するようにする必要があります。また、ルールと、NewRelicに開示するデータを監視する責任もあります。常にクエリをテストして再テストし、ドロップルールをインストールした後、意図したとおりに機能することを確認してください。ドロップ前とドロップ後のデータを監視するダッシュボードを作成すると役立ちます。

ドロップルールを使用して特定のツールのデータ取り込みを最適化するためのガイダンスは次のとおりです。

<CollapserGroup>
  <Collapser
    id="logs"
    title="ログ"
  >
    すべての New Relic ドロップルールは、同じバックエンドデータモデルと API によって実装されています。しかし、New Relic のログ管理は、ドロップルールを非常に簡単に作成および監視できる強力な UI を提供します。

    遠隔測定の優先順位付けに関する前回のセクションでは、特定のデータを非推奨にする方法を示す演習を行いました。この例をもう一度見てみましょう。

    ```
    Omit debug logs (knowing they can be turned on if there is an issue) (saves 5%)
    ```

    #### 方法1：[ログUI](/docs/logs/ui-data/drop-data-drop-filter-rules)

    * ログUIのフィルターを使用して気になるログを特定します： `level: DEBUG` 。

    * ドロップしたいログが見つかることを確認してください。

    * `level:debug`や`log_level:Debug`などの代替構文を確認してください。これらのバリエーションは一般的です。

    * \[**データの管理**]で、\[**ドロップフィルター**]クリックし、\[デバッグログの削除]という名前のフィルターを作成して有効にします。

    * ルールが機能することを確認します。

      #### 方法2: [弊社のNerdGraph APIを利用する。](/docs/data-apis/manage-data/drop-data-using-nerdgraph/)

    * 関連するNRQLクエリを作成します： `SELECT count(*) FROM Log WHERE `レベル` = 'DEBUG'` 。

    * ドロップしたいログが見つかることを確認してください。

    * 属性名と値のバリエーションを確認します（デバッグとデバッグ）。

    * 以下のNerdGraph文を実行し、動作することを確認します。

      ```
      mutation {
          nrqlDropRulesCreate(accountId: <var>YOUR_ACCOUNT_ID</var>, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM Log WHERE `level` = 'DEBUG'"
                  description: "Drops DEBUG logs.  Disable if needed for troubleshooting."
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="process-samples"
    title="プロセスサンプル"
  >
    推奨事項を実装しましょう： `Drop process sample data in DEV environments` 。

    * 関連するクエリを作成します：'SELECT \* FROM ProcessSample WHERE `env` ='DEV''

    * ドロップしたいプロセスサンプルが見つかることを確認する。

    * `env` `ENV`や `Environment`

    * `Dev`などのさまざまな`DEV`を確認してください `Development`

    * NerdGraph APIを使用して、以下のステートメントを実行し、動作を確認してください。

      ```
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM ProcessSample WHERE `env` = 'DEV'"
                  description: "Drops ProcessSample from development environments"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="cloud-metrics"
    title="クラウドメトリクス"
  >
    場合によっては、冗長なカバレッジを持つデータを節約することができます。例えば、AWS RDS統合とNew Relicオンホスト統合を実行している環境では、重複するメトリクスを捨てることができるかもしれません。

    手っ取り早く調べるには、次のようなクエリを実行します。

    ```
    FROM Metric select count(*) where metricName like 'aws.rds%' facet metricName limit max
    ```

    これにより、パターンに一致するすべての`metricName`値が表示されます。

    結果から、パターン`aws.rds.cpu%`のメトリックが大量にあることがわかります。それらのための他のインストルメンテーションがあるので、それらを削除しましょう：

    * 該当するクエリを作成します。'FROM Metric select \* where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago'

    * ドロップするプロセスサンプルが見つかることを確認してください。

    * NerdGraph APIを使用して、以下の文を実行し、動作することを確認する。

      ```
      mutation {
          nrqlDropRulesCreate(accountId: <var>YOUR_ACCOUNT_ID</var>, rules: [
              {
                  action: DROP_DATA
                  nrql: "FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago"
                  description: "Drops rds cpu related metrics"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="drop-specific-attributes"
    title="特定の属性を削除する"
  >
    ドロップルールの強力な点の1つは、特定の属性をドロップするが、残りのデータはそのまま維持するルールを構成できることです。これを使用して、NRDBからプライベートデータを削除したり、過度に大きな属性を削除したりします。たとえば、ログレコード内のスタックトレースまたはJSONの大きなチャンクは、非常に大きくなる場合があります。

    これらのドロップルールを設定するには、 `action`フィールドを&#x7B; `DROP_DATA` }ではなく`DROP_ATTRIBUTES`に変更します。

    ```
    mutation {
        nrqlDropRulesCreate(accountId: <var>YOUR_ACCOUNT_ID</var>, rules: [
            {
                action: DROP_ATTRIBUTES
                nrql: "SELECT stack_trace, json_data FROM Log where appName='myApp'"
                description: "Drops large fields from logs for myApp"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-random-sample-of-events"
    title="イベントのランダムサンプルをドロップします"
  >
    <Callout variant="caution">
      このアプローチは慎重に使用し、他に選択肢がない状況でのみ使用してください。これは、データから作成された統計的推測を変更する可能性があるためです。ただし、サンプルサイズが大きいイベントの場合、結果を理解している限り、データの一部のみを使用できます。
    </Callout>

    この例では、特定のトレースIDの相対的な分布を利用して、ランダムサンプリングを概算します。 `rlike`演算子を使用して、スパンの`trace.id`属性の先頭の値を確認できます。

    次の例では、スパンの約25％がドロップする可能性があります。

    ```
    SELECT * FROM Span WHERE trace.id rlike r'^[0-3].*' and appName = 'myApp'
    ```

    便利な表現は次のとおりです。

    * `^0.*` 約6.25％

    * `^[0-1].*` 約12.5％

    * `^[0-2].*` 約18.75％

    * `^[0-3].*` 約25.0％

      完全なミューテーションの例を次に示します。

      ```
      mutation {
          nrqlDropRulesCreate(accountId: <var>YOUR_ACCOUNT_ID</var>, rules: [
              {
                  action: DROP_ATTRIBUTES
                  nrql: "SELECT * FROM Span WHERE trace.id rlike r'^[0-3].*' and appName = 'myApp'"
                  description: "Drops approximately 25% of spans for myApp"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="other-events-and-metrics"
    title="その他のイベントと指標"
  >
    NRDBの他のイベントやメトリックにこれらのテクニックを使用するために必要な知識は、前述の例ですべてわかるはずです。クエリーができれば、それをドロップすることができる。ドロップルールのクエリを構成する正確な方法について質問がある場合は、New Relic に連絡してください。
  </Collapser>
</CollapserGroup>

## エクササイズ [#exercise]

次の質問に答えることで、最適化計画を作成して実行する能力に自信をつけることができます。 `Baselining`セクションの[データ取り込みベースライン](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-dashboard)および[データ取り込みエンティティの内訳](http://localhost:8000/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-entity-breakdown-dashboard)ダッシュボードを使用することをお勧めします。説明されているようにこれらのダッシュボードをインストールし、これらの質問のうちどれだけに答えられるかを確認してください。

| 質問                                                                                                                                                                                                                                                                        |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| この組織の取り込みを月に少なくとも5％削減できる3つのドロップルールを表示しますか？ドロップルールのNerdGraph構文を応答に含めます。                                                                                                                                                                                                    |
| この組織の取り込みを月に少なくとも5％削減するために実装できる、3つのインストルメンテーション構成の変更を提案しますか？応答に構成スニペットを含めます。                                                                                                                                                                                              |
| K8sモニタリングからのデータ量を減らすためにできる3つのことは何ですか？どのくらいのデータ削減を達成できますか？この削減の潜在的なトレードオフは何ですか？ （たとえば、それらは実質的な可観測性を失いますか？）                                                                                                                                                                 |
| 1.データ取り込みガバナンスベースラインダッシュボードを使用して、大量のログデータをNewRelicに送信しているアカウントを特定します。<br/> 2.アカウントのドロップダウンメニューからそのアカウントを見つけて選択します。<br/> 3.アカウントの**ログ**ページに移動し、左側のメニューから**パターン**を選択します。<br/> 4.表示されたログパターンを確認し、値の低いログパターンの例をいくつか示します。何がそれらを低い価値にしているのですか？これらのログを削除することで、どれだけの合計削減を達成できますか？ |
| この組織の全体的な分析に基づいて、どのテレメトリが十分に活用されていませんか？                                                                                                                                                                                                                                   |

## 結論 [#conclusion]

プロセスセクションでは、テレメトリを特定の可観測性値の推進要因または目的に関連付ける方法を示しました。これにより、アカウントの取り込みを最適化するという難しい決定がいくらか簡単になります。目標を保護しながら摂取を最適化する高レベルの[最適化計画](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#develop-plan)を作成する方法を学びました。最後に、構成とドロップルールベースの取り込み最適化のための[豊富なレシピセット](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#use-reduction-techniques)が紹介されました。