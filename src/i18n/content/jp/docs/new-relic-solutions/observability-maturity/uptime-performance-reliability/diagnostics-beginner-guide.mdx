---
title: '信頼性エンジニアリング診断: アプリケーション パフォーマンスのトラブルシューティングに関する初心者向けガイド'
tags:
  - Observability maturity
  - 'Uptime, performance, and reliability'
  - Site reliability engineering
  - SRE
metaDescription: 'New Relic observability maturity series: A beginner''s guide on identifying common application performance issues.'
translationType: machine
---

import solutionsOmaUprPatternNormal from 'images/solutions_screenshot-full_oma-upr-pattern-normal.webp'

import solutionsNormalPercentilePattern from 'images/solutions_screenshot-full_normal-percentile-pattern.webp'

import solutionsPatternAbnormal from 'images/solutions_screenshot-full_pattern-abnormal.webp'

import solutionsPatternAbnormalCompare from 'images/solutions_screenshot-full_pattern-abnormal-compare.webp'

このガイドは、顧客に影響を与える問題を診断するスキルを向上させるための入門書です。このガイドの手順に従うことで、アプリケーションのパフォーマンスの問題からより迅速に回復できるようになります。

このガイドは[、オブザーバビリティの成熟度に関するシリーズ](/docs/new-relic-solutions/observability-maturity/introduction)の一部です。

## 前提条件

このガイドを使用するための要件と推奨事項を次に示します。

* New Relic 可観測性の範囲:

  * **必須**:[分散トレース](/docs/apm/apm-ui-pages/monitoring/apm-summary-page-view-transaction-apdex-usage-data)を使用する[APM、コンテキスト内の APM ログ](/docs/apm/new-relic-apm/getting-started/get-started-logs-context)、および[インフラストラクチャ エージェント](/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring)
  * **推奨**:[ログ](/docs/logs/get-started/get-started-log-management)と[ネットワーク監視](/docs/network-performance-monitoring/get-started/npm-introduction)(NPM)

* **必須**: [サービスレベル管理](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)

* **推奨**: New Relic APM、分散トレース、NRQL クエリ、およびログ管理 UI の使用経験

* **推奨**: これらのガイドを読みました:

  * [アラート品質管理](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide)
  * [サービスレベル管理](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)

## 概要 [#overview]

このガイドの使用を開始する前に、学習内容を理解するのに役立ちます。このガイドは、次のことを理解するのに役立ちます。

* 診断スキルの向上がビジネスに与える影響。

* 成功を測定するために使用される運用上の主要業績評価指標。

* エンド ユーザーがさまざまな種類の信頼性の問題をどのように認識しているか。

* 問題の_直接的な原因_と_根本的_な原因の違い。

* 問題を見つけて解決するための基本的な診断手順には、次のものが含まれます。

  * 問題の定義 - 問題ステートメントの作成
  * 問題の原因を見つける
  * その問題の直接の原因を見つける

* 一部のパフォーマンスの問題カテゴリ (出力パフォーマンス、入力パフォーマンス、およびクライアント パフォーマンス) と、それらの問題の診断に使用される New Relic 機能 (APM、合成、ブラウザー、およびモバイル監視)。

* 一般的な問題とその原因を理解するためのチート シートである問題マトリックスの使用方法。

最後に、これらの概念をよりよく理解するのに役立ついくつかのパフォーマンスの問題の例を確認します。

## 期待される成果 [#desired-outcomes]

### 概要

ビジネスにとっての価値は次のとおりです。

* 業務に支障をきたすインシデントの発生を抑制する
* 問題解決に要する時間 (MTTR) の短縮
* インシデントの運用コストを削減

IT 運用と SRE の価値は次のとおりです。

* 理解と解決にかかる時間を短縮

### 事業成果 [#business-outcome]

2014 年、 [Gartner は IT ダウンタイムの平均コストを 1 分あたり 5,600 ドルと見積もっ](https://blogs.gartner.com/andrew-lerner/2014/07/16/the-cost-of-downtime)ています。ビジネスに影響を与えるインシデントの累積コストは、知るまでの時間、頻度、修復にかかる時間、収益への影響、およびインシデントをトリアージして解決するエンジニアの数などの要因によって決まります。簡単に言えば、パフォーマンスへの影響を解決するために必要な人員を減らして、ビジネスに影響を与えるインシデントを減らし、インシデントの期間を短縮し、診断を高速化する必要があります。

最終的に、ビジネスの目標は、稼働時間を最大化し、ダウンタイムを最小化することです。ダウンタイムのコストは次のとおりです。

**`Downtime minutes x Cost per minute = Downtime cost`**

ダウンタイムは、ビジネスを混乱させるインシデントの数とその期間によって決まります。ダウンタイムのコストには多くの要因が含まれますが、最も直接的に測定できるのは運用コストと収益の損失です。

ビジネスは、以下の削減を推進する必要があります。

* ビジネスを混乱させるインシデントの数
* インシデントの運用コスト

### 運用成果 [#operational-outcome]

必要な運用上の結果は、製品層のサービス レベル目標への準拠を維持することです。これを行うには、低下したサービス レベルを診断し、診断を伝え、迅速な解決策を実行します。しかし、予期しない劣化やインシデントは常に発生するため、迅速かつ効果的に対応する必要があります。

このシリーズの他のガイドでは**、知るまでの時間を短縮すること**に重点を置いています。[アラートの品質管理ガイド](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide)では、知るまでの時間を改善する事後対応的な方法に焦点を**当て**、 [サービス レベル管理ガイド](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)では**事前対応的な**方法に焦点を当てています。

あなたが今読んでいるガイドでは、**理解する**までの**時間と解決するまで**の時間の短縮に焦点を当てています。

## 主要業績評価指標 - 運用 [#operational-kpis]

「インシデント管理」と SRE 理論の世界では、多くの指標が議論され、議論されています。ただし、主要業績評価指標の小さなセットに注目することが重要であることにほとんどの人が同意しています。

以下の KPI は、成功した SRE およびインシデント管理プラクティスで使用される最も一般的な指標です。

<CollapserGroup>
  <Collapser
    id="slo-compliance"
    title="サービスレベル目標 (SLO) への準拠"
  >
    これが主要な指標です。サービス レベルは、パフォーマンスの低下の開始、パフォーマンスの傾向、影響の範囲、および問題がいつ解決されたかを測定します。

    このプロセスの詳細については、 [サービス レベル管理ガイド](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)を参照してください。
  </Collapser>

  <Collapser
    id="time-to-know"
    title="知る時間"
  >
    これは、インシデントが人間によって最初に記録された時間です。サービス レベルの低下が始まってから、パフォーマンスの問題の記録が作成されるまでの時間を知るための測定値。[アラート品質管理ガイド](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide)では、この運用メトリックを測定および改善する方法を示しています。
  </Collapser>

  <Collapser
    id="time-to-understand"
    title="理解する時間"
  >
    これは、インシデントの記録 (time to know) と影響の解決 (time to resolve) の間の時間です。
  </Collapser>

  <Collapser
    id="time-to-resolve"
    title="解決する時間"
  >
    解決までの時間は、多くの場合、MTTR (復元/修復/解決の平均時間) と呼ばれます。これは、(サービス レベルによって決定される) パフォーマンスの低下が始まってから、サービス レベルが期待されるパフォーマンス レベルに戻るまでの時間を測定します。

    **注**: 解決までの時間は、根本原因が特定され、完全に修正されたことを意味するものではありません。恒久的な修正は、インシデントが解決された後の「問題管理」プロセスの一部です。根本原因と直接原因、および「根本原因の症状」について調査してください。
  </Collapser>
</CollapserGroup>

## 信頼性に対するエンドユーザーの認識 [#end-user-perception]

顧客が製品のパフォーマンスをどのように認識しているかは、緊急性と優先度を測定する方法を理解する上で重要です。また、顧客の視点を理解することは、ビジネスが問題をどのように見ているかを理解するのに役立ち、影響を受ける機能をサポートするために必要なワークフローを理解するのにも役立ちます。顧客とビジネスの認識を理解すると、その機能の信頼性に影響を与えている可能性があるものをよりよく理解できます。

最終的に、顧客の視点から見たオブザーバビリティは、信頼性エンジニアリングに積極的かつ熟練するための最初のステップです。

デジタル製品のパフォーマンスとその機能に対するエンド ユーザーの認識に影響を与える 2 つの主要なエクスペリエンスがあります。以下の条件は、一般的な顧客用語を使用した顧客の観点からのものです。

<CollapserGroup>
  <Collapser
    id="availability"
    title="可用性、別名、機能していません"
  >
    可用性は、接続性、稼働時間、到達可能性とも呼ばれます。しかし、それはまた、成功 (非エラー) と混同されています。

    エンド ユーザーは、ログイン、ブラウズ、検索、インベントリの表示などの必要な機能にアクセスできないと述べる場合があります。または、サービス全体が利用できないと単に述べている場合もあります。これは、サービスに接続できないか、エラーを返すサービスのいずれかの症状です。

    従来、「可用性」または「アップタイム」は、サービスへの接続能力を測定することにより、バイナリの「アップ/ダウン」方法で測定されていました。従来の方法には、サービス全体が完全に利用できなくなった場合にのみ測定するという重大なギャップがあります。この従来の信頼性の尺度では、可観測性のギャップが大きくなり、診断が困難になり、対応する前にエンド ユーザーが大きな影響を受けることになります。

    可用性は、「稼働時間」とも呼ばれる「サービスに到達する能力」と、「期待される応答を返すサービスの能力」(つまり、「エラーがないこと」) の両方によって測定されます。New Relic の可観測性成熟度フレームワークは、**入力パフォーマンス**(接続性) と**出力パフォーマンス**(応答の成功とレイテンシー) によって 2 つを区別します。
  </Collapser>

  <Collapser
    id="performance"
    title="パフォーマンス、別名、遅すぎる"
  >
    パフォーマンスは、レイテンシーおよび応答時間としても知られています。

    エンド ユーザーは、サービスが遅すぎると言うことがあります。

    IT リーダーとビジネス リーダーの両方にとって、「パフォーマンス」という用語にはさまざまな問題が含まれます。New Relic のサービス レベル管理では、「速度」は「出力」と「クライアント」の両方のカテゴリで測定されます。ただし、速度の問題の大部分は、従来「バックエンド サービス」と呼ばれていたものに起因する出力の問題が原因で発生します。
  </Collapser>
</CollapserGroup>

## 根本原因と直接原因 [#root-cause-vs-direct-cause]

問題の根本原因は、その問題の直接の原因と同じではあり**ません**。同様に、直接的な原因 (短期的) を修正しても、通常、問題の根本原因 (長期的) が修正されたことにはなりません。**この区別をすることは非常に重要です。**

パフォーマンスの問題を探すときは、まず「何が変わったの?」という質問をして、問題の直接の原因を見つけようとする必要があります。通常、変更されたコンポーネントまたは動作は根本的な原因ではありませんが、実際には最初に解決する必要がある直接的な原因です。根本原因を解決することは重要ですが、通常、インシデント後の遡及的な議論と長期的な問題管理が必要です。

たとえば、ログイン機能のサービス レベルが突然低下します。トラフィック パターンが通常よりもはるかに多いことがすぐにわかります。パフォーマンスの問題を追跡して、TCP 接続キューがはるかに大きくなるオープン TCP 接続制限の構成にたどり着きます。TCP 制限の引き上げといくつかの追加のサーバー インスタンスを展開することで、問題をすぐに解決します。短期的には問題の直接的な原因を解決しましたが、根本的な原因は、不適切なキャパシティ プランニング、マーケティングからの連絡の欠落、上流の負荷に意図しない結果をもたらす関連展開などである可能性があります。

この区別は、ITIL/ITSM**インシデント管理**と**問題管理**でも行われます。インシデント後の話し合いで根本原因が議論され、その後、長期的な問題管理プロセスで解決されます。

## 診断手順 (概要) [#diagnostic-steps]

### ステップ 1: 問題を定義する [#create-problem-statement]

最初のルールは、問題のステートメントをすばやく確立することです。問題文を作成するためのガイドはたくさんありますが、シンプルで効果的なものが一番です。適切に構成された問題ステートメントは、次のことを行います。

1. エンドユーザーが経験していることを説明してください。エンドユーザーが経験している問題は何ですか?
2. 製品機能の予想される動作を説明します。エンドユーザーが経験すべきことは何ですか?
3. 製品機能の現在の動作を説明します。ユーザーが経験していることの技術的評価は何ですか?

問題文では、仮定を避けてください。事実に固執する。

### ステップ 2: ソースを見つける [#find-source]

「ソース」は、問題の直接の原因に最も近いコンポーネントまたはコードです。

多くのジャンクション、スプリッター、バルブを介して接続された多くの水道管を考えてみてください。給水サービス レベルが低下しているというアラートが表示されます。どの合流点、分岐点、バルブ、またはパイプが問題を引き起こしているかを特定するまで、パイプを通る水の出力から問題を追跡します。電気バルブの 1 つがショートしていることに気付きました。そのバルブが問題の原因です。ショートはあなたの問題の直接の原因です。値を置き換えることで、直接的な原因を簡単に解決できます。根本的な原因は、気象条件、水中の化学物質、または製造など、より複雑なものである可能性があることに注意してください.

これは、複雑なテクノロジー スタックを診断する場合と同じ概念です。ログイン機能が制限されている場合 (出力)、問題をその制限の原因となっているコンポーネント (ソース) までさかのぼって修正する必要があります。それは、API ソフトウェア (サービス境界)、ミドルウェア サービス、データベース、リソースの制約、サード パーティ サービスなどです。

IT では、応答時間を改善するための主要なブレークポイント カテゴリが 3 つあります。

1. **出力**
2. **入力**
3. **クライアント**

これらのカテゴリ (別名[サービス レベル](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)) 内でパフォーマンス メトリックを定義すると、問題の原因を特定する際の応答時間が大幅に短縮されます。これらのカテゴリの測定については[、サービス レベル管理ガイド](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)で説明しています。診断でそれらを使用する方法を理解するには、読み続けてください。

### ステップ 3: 直接の原因を見つける [#find-direct-cause]

問題の原因に近づいたら、何が変わったのかを特定します。これにより、短期間で問題を即座に解決する方法をすばやく判断できます。[ステップ 2](#find-source)の例では、ハードウェアの劣化によりショートが発生したため、バルブが機能しなくなったという変化がありました。

IT における一般的な変更の例は次のとおりです。

1. スループット (トラフィック)
2. コード (デプロイ)
3. リソース (ハードウェアの割り当て)
4. アップストリームまたはダウンストリームの依存関係の変更
5. データ量

パフォーマンスに影響を与える問題のその他の一般的な例については、以下の[問題マトリックス](#problem-matrix)を参照してください。

## ヘルス データ ポイントを使用する [#health-data-points]

前述のように、診断の旅をすぐに開始できる 3 つの主要なパフォーマンス カテゴリがあります。これらの正常性データ ポイントを理解すると、問題の原因がどこにあるかを理解するための時間が大幅に短縮されます。

<CollapserGroup>
  <Collapser
    id="output-perf"
    title="出力性能"
  >
    **これには次のものが必要**です: APM

    出力パフォーマンスとは、期待される応答 (出力) をエンドユーザーに提供するための内部テクノロジ スタックの能力です。これは伝統的に「バックエンド」サービスと呼ばれています。

    大多数のシナリオでは、出力パフォーマンスは単に応答の速度と応答の品質によって測定されます (つまり、エラーがないかどうか)。上記のユーザーの視点を思い出してください。エンドユーザーは、サービスが遅い、機能していない、またはアクセスできないと述べます。

    最も一般的な問題は、エンド ユーザーの要求にタイムリー**かつ**適切に応答する能力です。

    これは、問題のある製品機能をサポートするサービスのレイテンシ異常またはエラー異常によって簡単に識別されます。
  </Collapser>

  <Collapser
    id="input-perf"
    title="入力パフォーマンス"
  >
    **これには次のものが必要**です。

    入力パフォーマンスとは、サービスがクライアントからの要求を受け取る能力です。これは、リクエストを送信するクライアントの機能と同じではありません。

    出力パフォーマンス (バックエンド サービス) が、予想されるパフォーマンス レベルを超えている可能性があります。ただし、クライアントとサービスの間の何かが、要求と応答のライフサイクルを壊しています。これは、クライアントとサービスの間のあらゆるものである可能性があります。
  </Collapser>

  <Collapser
    id="client-perf"
    title="クライアントのパフォーマンス"
  >
    **これには以下が必要**です: ブラウザ監視および/またはモバイル監視

    クライアント パフォーマンスとは、ブラウザーやモバイル アプリケーションが要求を作成し、応答をレンダリングする能力です。出力 (バックエンド) と入力パフォーマンス (シンセティックス) の両方が除外されると、ブラウザーやモバイルが問題の原因として簡単に特定されます。

    出力と入力のパフォーマンスは、除外 (または除外) するのが比較的簡単です。入力および出力診断の診断の深さにより、ブラウザとモバイルは将来的に高度な診断ガイドでカバーされる予定です。
  </Collapser>
</CollapserGroup>

## 問題マトリックス [#problem-matrix]

問題マトリックスは、3 つの健康データ ポイントによって分類された一般的な問題のチート シートです。

問題の原因は、頻度の高い順に並べられており、最も一般的なものが一番上の行の左側に表示されます。より詳細な内訳を以下に示します。サービス レベル管理が適切に行われていれば、これらのデータ ポイントの 3 つのうち 2 つを迅速に除外することができます。

この表は、健康データ ポイントごとに並べ替えられた問題マトリックスです。

| データポイント | New Relic の機能   | 一般的な問題の原因                                                                  |
| ------- | --------------- | -------------------------------------------------------------------------- |
| 出力      | APM、インフラ、ログ、NPM | アプリケーション、データ ソース、ハードウェア構成の変更、インフラストラクチャ、内部ネットワーク、サード パーティ プロバイダー (AWS、GCP) |
| 入力      | 合成、ログ           | 外部ルーティング (CDN、ゲートウェイなど)、内部ルーティング、インターネット上のもの (ISP など)                      |
| クライアント  | ブラウザ、モバイル       | ブラウザまたはモバイル コード                                                            |

問題は複雑化する傾向がありますが、サービス レベルを迅速に回復するために、「原因を突き止め」、「何が変化したか」を特定することが目標です。

### 問題例 [#example-problem]

問題の例を見てみましょう。あなたの会社が新製品を展開し、要求の大幅な増加により許容できない応答時間が発生したとします。ソースは、ログイン ミドルウェア サービスで検出されます。問題は、TCP キュー時間の急増です。

この状況の内訳は次のとおりです。

* **カテゴリー**: 出力性能
* **出典**：ログインミドルウェア
* **直接的な原因**: 追加のリクエスト負荷による TCP キュー時間
* **解決策**: TCP 接続制限の増加とリソースのスケーリング
* **根本原因**: ログイン ミドルウェアに影響を与えるダウンストリーム サービスのキャパシティ プランニングと品質保証テストが不十分

### 別の問題例 [#example-problem-2]

別の問題の例を次に示します。

* ログイン時に 500 のゲートウェイ エラーが突然増加しました...
* ログイン API の応答時間は、タイムアウトが始まるポイントまで増加しました...
* タイムアウトは、ミドルウェア層のデータベース接続まで追跡されました...
* トランザクション追跡により、ログイン要求ごとのデータベース クエリ数が大幅に増加していることが明らかになりました...
* 問題の直前に発生した展開の展開マーカーが見つかりました。

この状況の内訳は次のとおりです。

* **カテゴリ**: 入力性能の障害につながる出力性能の低下
* **出典**：ミドルウェアサービス呼び出しデータベース
* **直接的な原因**: コードのデプロイ後にデータベース クエリが 10 倍に増加
* **解決策**: 展開のロールバック
* **根本原因**: 不十分な品質保証テスト

### ソース別の問題マトリックス [#problem-matrix-sources]

これは、ソース別にソートされた問題マトリックスを含む表です。

<table>
  <thead>
    <tr>
      <th>
        **ソース**
      </th>

      <th>
        **一般的な直接原因**
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        アプリケーション
      </td>

      <td>
        1. 最近の展開 (コード)
        2. ハードウェア リソースの制約
        3. データベースの制約
        4. 構成の変更 (ハードウェア / ルーティング / ネットワーキング)
        5. サードパーティの依存関係
      </td>
    </tr>

    <tr>
      <td>
        情報源
      </td>

      <td>
        1. データベースの制約
        2. クエリ ロジックの変更 (n+1)
        3. メッセージ キュー (通常、プロデューサーまたはコンシューマーのパフォーマンスが低下します)
      </td>
    </tr>

    <tr>
      <td>
        内部ネットワーキングとルーティング
      </td>

      <td>
        1. ロードバランサー
        2. プロキシ
        3. API ゲートウェイ
        4. ルーター (まれ)
        5. ISP/CDN (まれ)
      </td>
    </tr>
  </tbody>
</table>

## パフォーマンス パターンの異常の特定 [#pattern-anomalies]

<Callout variant="tip">
  主要なトランザクション (機能) に関連するサービス境界で整形式の[サービス レベル](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)を設定すると、問題が存在するエンド ツー エンドのワークフローをより迅速に特定するのに役立ちます。
</Callout>

パターンの異常を特定することで、問題の直接の原因がどこにあるのかを特定する能力が向上します。

パターンの識別に関する優れた情報や無料のオンライン クラスはたくさんありますが、一般的な概念はかなり単純で、強力な診断能力を解き放つことができます。

パフォーマンス データのパターンと異常を特定するための鍵は、サービスがどのように実行されているかを知る必要がない**ことです。最近の動作が変化したかどうかを判断するだけで済みます。**

このセクションで提供されている例では、メトリックとして応答時間またはレイテンシーを使用していますが、エラー、スループット、ハードウェア リソース メトリック、キューの深さなど、ほぼすべてのデータセットに同じ分析を適用できます。

### ノーマル [#normal]

以下は、APM での一見不安定な応答時間チャート (7 日間) の例です。よく見ると、応答時間の動作が反復的であることがわかります。つまり、7 日間にわたって行動に劇的な変化はありません。スパイクは反復的であり、タイムラインの残りの部分と比較して異常ではありません。

<img
  alt="normal pattern"
  title="Normal pattern"
  src={solutionsOmaUprPatternNormal}
/>

実際、データの表示を**経時的な平均から経時的な****パーセンタイル**に変更すると、応答時間の変化がいかに「規則的」であるかがさらに明確になります。

<img
  alt="normal pattern with percentile"
  title="Normal pattern with percentile"
  src={solutionsNormalPercentilePattern}
/>

### 異常な [#abnormal]

このグラフは、最近の動作と比較して異常に増加したと思われるアプリケーションの応答時間を示しています。

<img
  alt="abnormal pattern"
  title="Abnormal pattern"
  src={solutionsPatternAbnormal}
/>

これは、週ごとの比較を使用して確認できます。

<img
  alt="abnormal pattern week-over-week"
  title="Abnormal pattern week-over-week comparison"
  src={solutionsPatternAbnormalCompare}
/>

パターンが変化し、先週の比較から悪化しているように見えます。

## ソースを見つける [#finding-source]

次に、New Relic でソースを見つける方法について説明します。このワークフローは分散トレースに依存していることに注意してください。

まず、エンド ユーザーが経験する遅延またはエラーに関連するアプリケーションを見つけます。これは、アプリケーションやコードが問題であることを意味するわけではありませんが、フロー (_最初_) 内のアプリケーションを見つけることで、より迅速にソースに近づくことができます。このアプリケーションが見つかったら、コード、ホスト、データベース、構成、ネットワークなどのコンポーネントをすばやく除外できます。

アプリケーションが特定されると、問題は、そのアプリケーション内のどのトランザクションが問題の一部であるかです。パフォーマンスの問題が発生していると特定したアプリケーションを使用し、影響を受けるトランザクションを特定します。ここで、前述の[Identif パフォーマンス パターンの異常](#pattern-anomalies)で説明したパフォーマンス パターンの異常スキルを繰り返すことができますが、今回はトランザクション自体についてです。

次のドキュメントは、New Relic を使用して問題のあるトランザクションを特定するのに役立ちます。

1. [Transactionsページ：特定のパフォーマンス問題を突き止める](/docs/apm/apm-ui-pages/monitoring/transactions-page-find-specific-performance-problems/)
2. [サービスの概要ページでトランザクションが遅い](/whats-new/2021/03/slow-transactions)

問題のあるトランザクションが特定されたら、分散トレースを使用して、そのトランザクションをサポートするエンド ツー エンドのコンポーネントを確認できます。分散トレースを使用すると、スタック全体でレイテンシが発生している場所やエラーが発生している場所をすべて 1 つのビュー内ですばやく特定できます。

次のリソースは、分散トレーシングを使用して問題のソース コンポーネントを特定する方法を学習するのに役立ちます。

1. [分散トレースの概要](/docs/distributed-tracing/concepts/introduction-distributed-tracing)
2. [分散トレース UI の使用方法](/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/)
3. [分散トレーシングに関する無料のオンライン ウェビナー](https://learn.newrelic.com/new-relic-distributed-tracing-tracking-across-your-application-stacks)
4. [直接原因分析のための分散トレーシングの使用に関するビデオ](https://www.youtube.com/watch?v=r9ImAQ5J5h4)

ソースの検索手順の簡単な要約を次に示します。

1. 影響を受けるパフォーマンスに関連するアプリケーションを調べます。
2. 問題の原因となっているトランザクションを特定します。
3. 分散トレースを使用して、エンド ツー エンド フロー内で問題のあるコンポーネントを特定します。

これで、直接的な原因を特定する最終ステップに進むことができます。

## 直接の原因を見つける [#finding-direct-cause]

ソース コンポーネントが見つかったら、直接的な原因の特定を開始できます。

前の手順の知識を使用すると、問題が遅延、成功、またはその両方であるかがわかります。

遅延の問題は、分散トレース内のトランザクション トレースや「インプロセス スパン」を使用して見つけることができます。

成功の問題のエラー メッセージもトレースで確認できますが、成功の問題の詳細は通常、アプリケーション ログで確認できます。

いずれにせよ、あなたが第 1 層のインシデント レスポンダーまたは SRE である場合、直接的な原因を見つけることは、通常、発見されたソース コンポーネントを担当する開発者およびエンジニアである対象分野の専門家 (SME) に委ねられます。

ソース コンポーネントを発見した後の最も効果的な次のステップは、そのコンポーネントの対象分野の専門家に連絡することです。トリアージで発見されたデータと、トラブルシューティングを有利に開始するために完了した診断を示します。

<Callout variant="tip">
  コンテキスト内ログインと分散トレースの両方がデフォルトで有効になっていることに注意してください <InlinePopover type="apm"/>エージェント。 (エージェントをしばらく更新していない場合は、 [エージェントを定期的に更新すること](/docs/new-relic-solutions/new-relic-one/install-configure/update-new-relic-agent)をお勧めします。)

  ログインコンテキストと分散トレースは、トリアージ、診断、および長期的な問題解決にかかる時間を短縮するために必要な重要な機能です。
</Callout>

さあ、New Relic で優れたサイト信頼性エンジニアになりましょう!

## 次のステップ [#next-steps]

まだ読んでいない場合は、次のような関連する[可観測性成熟度ガイド](/docs/new-relic-solutions/observability-maturity/introduction)を読むことをお勧めします。

* [アラート品質管理](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide)
* [サービスレベル管理](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)