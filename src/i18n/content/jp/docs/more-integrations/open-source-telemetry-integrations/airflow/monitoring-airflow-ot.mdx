---
title: OpenTelemetry を使用して Apache Airflow を監視する
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Airflow
  - Quickstart
metaDescription: Monitor Airflow data with New Relic using OpenTelemetry.
freshnessValidatedDate: '2023-11-16T00:00:00.000Z'
translationType: machine
---

import opentelemetryAirflow01 from 'images/opentelemetry_screenshot_airflow_01.webp'

import opentelemetryAirflow02 from 'images/opentelemetry_screenshot_airflow_02.webp'

[OpenTelemetry](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry)を構成して New Relic にデータを送信することで Apache Airflow データを監視し、タスク、オペレーター、DAG の実行をメトリクスとして視覚化できます。

<img
  title="Screenshot showing sample Airflow DAG runs in New Relic"
  alt="Screenshot showing sample Airflow DAG runs in New Relic"
  src={opentelemetryAirflow01}
/>

## 前提条件 [#prerequisites]

Apache Airflow で OpenTelemetry を有効にする前に、 `otel`エクストラを含む Airflow パッケージをインストールする必要があります。インストール方法は、Airflow 導入アプローチによって異なります。

### オプション 1: PyPi からインストールする [#install-pypi]

1. [Airflow のドキュメント](https://airflow.apache.org/docs/apache-airflow/stable/installation/installing-from-pypi.html)のインストール手順に従ってください。
2. pip を使用してインストールする場合は、コマンドに`otel`を追加します。ａ．例えば。 `pip install "apache-airflow[otel]"`

### オプション 2: Docker からのインストール [#install-docker]

1. [Airflow のドキュメント](https://airflow.apache.org/docs/docker-stack/index.html)の手順に従って、Airflow Docker イメージをセットアップします。
2. Dockerfile を使用してビルド済みの Docker イメージを拡張し、 `otel`エクストラをインストールします。最新のタグを希望のバージョンのイメージに置き換えることができます。

```
FROM apache/airflow:latest
RUN pip install --no-cache-dir "apache-airflow[otel]==$AIRFLOW_VERSION"
```

<Callout variant="tip">
  `$AIRFLOW_VERSION` は、Apache/airflow コンテナによってすでに設定されていますが、他のベース イメージのバージョン番号に置き換えることができます。
</Callout>

## 構成 [#configuration]

Airflow メトリクスを New Relic に送信するには、OpenTelemetry [コレクタ](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-intro/)にデータをエクスポートするように OpenTelemetry メトリクスを設定します。これにより、データが New Relic [OTLP エンドポイント](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/#note-endpoints)に転送されます。 <InlinePopover type="licenseKey"/>。

<Callout variant="important">
  現在、Airflow では認証ヘッダーを含む OpenTelemetry データの送信がサポートされていないため、New Relic での認証には OpenTelemetry コレクターが不可欠です。
</Callout>

### OpenTelemetry コレクターを構成する [#configuration-collector]

1. [基本的なコレクターの例](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-basic/)に従って、OpenTelemetry コレクターを設定します。

2. `https://otlp.nr-data.net:4317`などの適切な OTLP エンドポイントを使用してコレクターを構成します。

3. 認証のために、

   <InlinePopover type="licenseKey"/>

   環境変数`NEW_RELIC_LICENSE_KEY`に値を設定して、 `api-key`ヘッダーに値を設定します。

4. 実行中の Airflow インスタンスからコレクターのポート 4318 に到達できることを確認します。(Docker の場合は、 [Docker ネットワークを](https://docs.docker.com/network/)使用する必要がある場合があります。)

5. コレクターを起動します。

### エアフローメトリクスを構成する [#configuration-airflow]

Airflow は、ポート`4318`を使用する OTLP over HTTP を使用してメトリクスを送信します。Airflow には、[構成オプションを設定する](https://airflow.apache.org/docs/apache-airflow/stable/howto/set-config.html)複数の方法があります。

<Callout variant="important">
  ご使用の環境で、OpenTelemetry Collector と並行して Docker コンテナで Airflow が実行されている場合は、 `otel_host`設定を`localhost`からコレクタのコンテナ アドレスに変更する必要があります。
</Callout>

次のいずれかの方法を選択して、エアフローに必要なオプションを設定します。

1. `airflow.cfg`ファイルに必要なオプションを設定します。

```
[metrics]
otel_on = True
otel_host = localhost
otel_port = 4318
otel_ssl_active = False
```

2. または、必要なオプションを環境変数として設定します。

```
export AIRFLOW__METRICS__OTEL_ON=True
export AIRFLOW__METRICS__OTEL_HOST=localhost
export AIRFLOW__METRICS__OTEL_PORT=4318
export AIRFLOW__METRICS__OTEL_SSL_ACTIVE=False
```

<Callout variant="tip">
  Airflow には、役立つ可能性のあるメトリクスの[追加設定が](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry)あります。これには、送信前に[メトリクスの名前を変更する](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#rename-metrics)機能が含まれます。これは、メトリクス名が OpenTelemetry の 63 バイト制限を超える場合に役立ちます。
</Callout>

## データが New Relic に送信されることを検証する [#validation]

New Relic が Airflow データを収集していることを確認するには、DAG またはパイプラインを実行します。

1. エアフローにログインします。
2. 既存のチュートリアル DAG の 1 つ、または独自のチュートリアル DAG の実行ボタンをクリックします。
3. パイプラインの実行が完了するまで待ちます。
4. **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities)> APM & services > Services - OpenTelemetry > Airflow**に移動します。
5. **Metrics Explorer** \[メトリック エクスプローラー]をクリックして、パイプライン実行のメトリックを視覚化します。

## ダッシュボードの構築 [#building-dashboards]

Airflow メトリクスを使用すると、個々のパイプラインや全体的なパフォーマンスに関するダッシュボードを構築したり、異なるパイプライン間の比較を表示したりできます。[メトリクスのクエリの](/docs/data-apis/understand-data/metric-data/query-metric-data-type/)詳細については、ここをクリックしてください。

このクエリは、Airflow について報告されたすべてのメトリクスのリストを取得します。

```
SELECT uniques(metricName) FROM Metric WHERE entity.name = 'Airflow' AND metricName LIKE 'airflow.%' SINCE 30 MINUTES AGO LIMIT 100
```

メトリクス名が制限 ( `100` ) を超える場合は、必ず制限を変更してください。

このクエリは、さまざまな DAG が正常に実行された場合のさまざまな完了時間を比較します。

```
SELECT latest(airflow.dagrun.duration.success) FROM Metric FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img
  title="Screenshot showing sample Airflow DAG runs in New Relic"
  alt="Screenshot showing sample Airflow DAG runs in New Relic"
  src={opentelemetryAirflow01}
/>

このクエリは、失敗した DAG 実行の数を表示します。これは、重要なパイプラインのアラートを作成するために使用できます。

```
SELECT count(airflow.dagrun.duration.failed) FROM Metric FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img
  title="Screenshot showing sample Airflow failures in New Relic"
  alt="Screenshot showing sample Airflow failures in New Relic"
  src={opentelemetryAirflow02}
/>

<Callout variant="important">
  Airflow の OpenTelemetry メトリクスは New Relic によって保守されていないため、インストルメンテーションに問題がある場合は、 [Airflow の GitHub リポジトリで新しい問題を作成してください](https://github.com/apache/airflow/issues)。
</Callout>

<InstallFeedback/>