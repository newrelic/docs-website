---
title: Confluent Cloud & Kafka モニタリング用コレクター
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector.
freshnessValidatedDate: never
translationType: machine
---

OpenTelemetry Collector を使用して、Confluent Cloud 管理の Kafka デプロイメントに関するメトリクスを収集できます。コレクターは、テレメトリ データを収集、処理し、New Relic (または任意の可観測性バックエンド) にエクスポートする OpenTelemetry のコンポーネントです。

この統合は、OpenTelemetry コレクター内で Prometheus レシーバー構成を実行することによって機能します。これにより、 [Confluent Cloud のメトリクス API](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w)が取得され、そのデータが New Relic にエクスポートされます。

Confluent から Kafka メトリクスを収集し、New Relic にエクスポートするには、以下の手順を実行します。

<Steps>
  <Step>
    ## セットアップが完了していることを確認してください

    始める前に、次のものが必要です。 <InlinePopover type="licenseKey"/>データを報告したいアカウントの。次のことも確認する必要があります。

    * Docker デーモンが実行されている
    * [Docker Compose が](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud)インストールされている
    * [Confluent Cloud アカウント](https://www.confluent.io/get-started/)をお持ちです
    * [Confluent Cloud API キーとシークレット](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html)を利用できるようになりました
  </Step>

  <Step>
    ## サンプル リポジトリをダウンロードまたは複製する

    このセットアップではサンプル コレクター設定を使用しているため[、New Relic の OpenTelemetry Examples リポジトリ](https://github.com/newrelic/newrelic-opentelemetry-examples)をダウンロードしてください。インストールしたら、 [Confluent Cloud サンプル](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud)ディレクトリを開きます。詳細については、 `README`も確認してください。
  </Step>

  <Step>
    ## 環境変数を設定してコレクターを実行する

    * Confluent Cloud と New relic の両方の API キーとシークレット変数を`.env`ファイルに設定します
    * `Cluster_ID`変数にターゲット Kafka クラスター ID を設定します。
    * (オプション) Confluent Cloud によって管理されるコネクタまたはスキーマ レジストリを監視するには、 `collector.yaml`ファイル内の構成のコメントを解除し、対応する ID を`.env`ファイルに設定します。

    ```bash
    # Open the confluent cloud example directory
    cd newrelic-opentelemetry-examples/other-examples/collector/confluentcloud

    # Set environment variables.

    # run the collector in docker
    docker compose up
    ```

    ### ローカル変数情報

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px"}}>
            変数
          </th>

          <th>
            説明
          </th>

          <th>
            ドキュメント
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic インジェスト API キー
          </td>

          <td>
            [API キーのドキュメント](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            デフォルトの米国 New Relic OTLP エンドポイントは[https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)です
          </td>

          <td>
            [OTLP エンドポイント構成ドキュメント](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/get-started/opentelemetry-set-up-your-app/#review-settings)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            Confluent Cloud からのクラスターの ID
          </td>

          <td>
            [list クラスター ID コマンドのドキュメント](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            クラウド API キー
          </td>

          <td>
            [クラウド API キーのドキュメント](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            クラウド API シークレット
          </td>

          <td>
            [クラウド API キーのドキュメント](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (オプション) ここで ID を指定すると、Confluent コネクタを監視できます。
          </td>

          <td>
            [コネクタ ID のリスト コマンドのドキュメント](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (オプション) ここで ID を指定することで、Confluent スキーマ レジストリを監視できます。
          </td>

          <td>
            [コネクタ ID のリスト コマンドのドキュメント](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ## New Relic でデータを表示する

    Confluent Cloud データは、いくつかの異なる方法で表示できます。

    * [New Relic マーケットプレイス](https://one.newrelic.com/marketplace)に移動し、 `Confluent`を検索します。利用可能なダッシュボードはアカウントに直接インストールできます。
    * メトリック エクスプローラーに移動し、 `confluent_kafka`をフィルターします。このデータは、任意のカスタム アラートまたはダッシュボードに追加できます。
  </Step>
</Steps>

### コンフルエント クラウド メトリクス [#confluent-metrics]

この統合は、_ _[Confluent Cloud Metrics API 内のすべての](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud) エクスポート可能な メトリクスをカバーします。以下に_エクスポート可能な_メトリクスの部分的なリストを示します。

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        名前
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        ネットワークから受信した顧客データのバイト数の差分。各サンプルは、前のデータ サンプル以降に受信したバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        ネットワーク経由で送信された顧客データのバイト数の差分。各サンプルは、前のデータ ポイント以降に送信されたバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        受信したレコードのデルタ カウント。各サンプルは、前のデータ サンプル以降に受信したレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        送信されたレコードのデルタ カウント。各サンプルは、前のデータ ポイント以降に送信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        クラスターによって保持されている現在のバイト数。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        アクティブな認証済み接続の数。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        ネットワーク経由で受信したリクエストのデルタ カウント。各サンプルは、前のデータ ポイント以降に受信したリクエストの数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        パーティション数
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        成功した認証のデルタ カウント。各サンプルは、前のデータ ポイント以降の成功した認証の数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        グループ メンバーのコミットされたオフセットとパーティションの最高水準点の間のラグ。
      </td>
    </tr>
  </tbody>
</table>