---
title: Confluent Cloud & Kafka モニタリング用コレクター
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector.
translationType: machine
---

OpenTelemetry Collector を使用して、Confluent Cloud 管理の Kafka デプロイメントに関するメトリクスを収集できます。コレクターは、テレメトリ データを収集、処理し、New Relic (または任意の可観測性バックエンド) にエクスポートする OpenTelemetry のコンポーネントです。

Docker で実行されている OpenTelemetry コレクターを使用して、Confluent から Kafka メトリクスを収集するには、以下の手順を実行します。

<Steps>
  <Step>
    ## セットアップが完了していることを確認してください

    始める前に、次のものが必要です。 <InlinePopover type="licenseKey"/>データを報告したいアカウントの。次のことも確認する必要があります。

    * Docker デーモンが実行されている
    * [Docker Compose が](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud)インストールされている
    * [Confluent Cloud アカウント](https://www.confluent.io/get-started/)をお持ちです
  </Step>

  <Step>
    ## サンプル リポジトリをダウンロードまたは複製する

    このセットアップではサンプル コレクター設定を使用しているため[、New Relic の OpenTelemetry Examples リポジトリを](https://github.com/newrelic/newrelic-opentelemetry-examples)ダウンロードしてください。インストールしたら、 [Confluent Cloud サンプル](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud)ディレクトリを開きます。詳細については、 `README`も確認してください。
  </Step>

  <Step>
    ## 認証ファイルを追加する

    このセットアップ例では、TLS を使用して Confluent Cloud へのリクエストを認証します。認証には複数の方法があるため、会社のベスト プラクティスと認証方法に従う必要があります。

    * TLS/SSL では、キーと証明書を作成し、独自の認証局 (CA) を作成して、証明書に署名する必要があります。

    * これを実行すると、このディレクトリに追加する必要がある 3 つのファイルが残ります。

    * これらのファイルは、この例では次のファイルとして参照されます: `key.pem` 、 `cert.pem` 、 `ca.pem` 。

      <Callout variant="important">
        Confluent Cloud での TLS 認証の詳細については、 [TLS による認証に関するドキュメント](https://docs.confluent.io/platform/current/kafka/authentication_ssl.html)と[セキュリティ チュートリアル](https://docs.confluent.io/platform/current/security/security_tutorial.html)を確認してください。

        開発/テスト用の Confluent 環境の場合、プレーン テキスト認証を使用することでこれを簡素化できます。
      </Callout>
  </Step>

  <Step>
    ## 環境変数を設定してコレクターを実行する

    次の変数をエクスポートするか、 `.env`ファイルに追加してから、 `docker compose up`コマンドを実行します。

    ```bash
    # Open the confluent cloud example directory
    cd newrelic-opentelemetry-examples/other-examples/collector/confluentcloud

    # Set environment variables.
    export NEW_RELIC_API_KEY=<YOUR_API_KEY>
    export NEW_RELIC_OTLP_ENDPOINT=https://otlp.nr-data.net
    export CLUSTER_ID=<YOUR_CLUSTER_ID>
    export CLUSTER_API_KEY=<YOUR_CLUSTER_API_KEY>
    export CLUSTER_API_SECRET=<YOUR_CLUSTER_API_SECRET>
    export CLUSTER_BOOTSTRAP_SERVER=<YOUR_CLUSTER_BOOTSTRAP_SERVER>

    # run the collector in docker
    docker compose up
    ```

    ### ローカル変数情報

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px"}}>
            変数
          </th>

          <th>
            説明
          </th>

          <th>
            ドキュメント
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic インジェスト API キー
          </td>

          <td>
            [API キーのドキュメント](https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            New Relic OTLP エンドポイントは[https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)です
          </td>

          <td>
            [OTLP エンドポイント構成ドキュメント](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/get-started/opentelemetry-set-up-your-app/#review-settings)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            Confluent Cloud からのクラスターの ID
          </td>

          <td>
            Confluent クラスター設定で利用可能
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_ID`
          </td>

          <td>
            クラウド API キー
          </td>

          <td>
            [クラウド API キーのドキュメント](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            クラウド API シークレット
          </td>

          <td>
            [クラウド API キーのドキュメント](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_BOOTSTRAP_SERVER`
          </td>

          <td>
            クラスター用ブートストラップサーバー
          </td>

          <td>
            クラスター設定で利用可能
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ## New Relic でデータを表示する

    Confluent Cloud データは、いくつかの異なる方法で表示できます。

    * [New Relic マーケットプレイス](https://one.newrelic.com/marketplace)に移動し、 `Confluent`を検索します。利用可能なダッシュボードはアカウントに直接インストールできます。
    * メトリック エクスプローラーに移動し、 `confluent_kafka`をフィルターします。このデータは、任意のカスタム アラートまたはダッシュボードに追加できます。
  </Step>
</Steps>

### コンフルエント クラウド メトリクス [#confluent-metrics]

この統合は、_ _[Confluent Cloud Metrics API 内のすべての](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud) エクスポート可能な メトリクスをカバーします。以下に_エクスポート可能な_メトリクスの部分的なリストを示します。

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        名前
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        ネットワークから受信した顧客データのバイト数の差分。各サンプルは、前のデータ サンプル以降に受信したバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        ネットワーク経由で送信された顧客データのバイト数の差分。各サンプルは、前のデータ ポイント以降に送信されたバイト数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        受信したレコードのデルタ カウント。各サンプルは、前のデータ サンプル以降に受信したレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        送信されたレコードのデルタ カウント。各サンプルは、前のデータ ポイント以降に送信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        クラスターによって保持されている現在のバイト数。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        アクティブな認証済み接続の数。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        ネットワーク経由で受信したリクエストのデルタ カウント。各サンプルは、前のデータ ポイント以降に受信したリクエストの数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        パーティション数
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        成功した認証のデルタ カウント。各サンプルは、前のデータ ポイント以降の成功した認証の数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        グループ メンバーのコミットされたオフセットとパーティションの最高水準点の間のラグ。
      </td>
    </tr>
  </tbody>
</table>