---
title: Confluent Cloud と Kafka のコレクター 監視
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
  - kubernetes
  - helm
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector on Kubernetes.
freshnessValidatedDate: '2024-05-28T00:00:00.000Z'
translationType: machine
---

OpenTelemetry Collector を使用して、Confluent Cloud 管理の Kafka デプロイメントに関するメトリクスを収集できます。コレクターは、テレメトリ データを収集、処理し、New Relic (または任意の可観測性バックエンド) にエクスポートする OpenTelemetry のコンポーネントです。

このインテグレーションは、 OpenTelemetryコレクター内でPrometheusレシーバー設定を実行し、 [Confluent CloudのメトリクスAPI](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w)をスクレイピングしてそのデータをNew Relicにエクスポートすることで機能します。

## 監視を設定する [#set-up-monitoring]

Confluent から Kafka メトリクスを収集し、New Relic にエクスポートするには、以下の手順を実行します。

<Steps>
  <Step>
    ### 始める準備ができていることを確認してください [#get-started]

    開始する前に、データを報告するアカウントの<InlinePopover type="licenseKey"/>が必要です。 以下の点も確認する必要があります。

    * Kubernetesクラスターが稼働している
    * (Helmユーザーの場合) [Helmが](https://helm.sh/docs/intro/quickstart/)インストールされていることを確認してください
    * [Confluent Cloudアカウント](https://www.confluent.io/get-started/)があり、クラスタが稼働している
    * [Confluent Cloud API キーとシークレット](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html)を利用できるようになりました
  </Step>

  <Step>
    ### OpenTelemetry 技術パートナーのサンプル リポジトリをダウンロードまたはクローンします。 [#download-repo]

    このセットアップでは[New RelicのOpenTelemetry技術パートナーシップの例 リポジトリ](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations)をダウンロードしてください。その例の コレクター 設定 が使用されています。 インストールしたら、 [Confluent Cloud のサンプル](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations/confluent-cloud)ディレクトリを開きます。 詳細については、 `README`も参照してください。
  </Step>

  <Step>
    ### 例を実行する [#run-the-example]

    環境に応じて、以下の Helm または Kubernetes の手順のいずれかを完了します。

    #### ヘルムの例 [#run-helm-example]

    1. `./confluent-cloud/helm`ディレクトリから、 `values.yaml`ファイル内の変数を更新します。 個々の変数の詳細については、以下の[ローカル変数](#local-variables)表を参照してください。

    2. 次のコマンドを使用してコレクターを実行します。

       ```bash
       # Open the confluent cloud helm example directory
       cd ./confluent-cloud/helm

       # Make sure to set environment variables.

       # Install and run helm
       helm install ./helm
       ```

    #### Kubernetesの例 [#run-kubernetes-example]

    1. `./confluent-cloud/k8s`ディレクトリから、 `./k8s/deployment.yaml`ファイル内の変数を更新します。 個々の変数の詳細については、以下の[ローカル変数](#local-variables)表を参照してください。

    2. 変数を設定したら、次のコマンドを実行して、コレクターを Kubernetes クラスタに適用します。

       ```bash
       # Open the Confluent Cloud k8s example directory
       cd ./confluent-cloud/k8s

       # Make sure to set environment variables

       # Apply the collector to the cluster
       kubectl apply -f ./k8s
       ```

    #### Helm と Kubernetes のローカル変数 [#local-variables]

    <table>
      <thead>
        <tr>
          <th style={{ width: "275px"}}>
            変数
          </th>

          <th>
            説明
          </th>

          <th>
            ドキュメント
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic インジェスト API キー
          </td>

          <td>
            [API キーのドキュメント](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            デフォルトの米国 New Relic OTLP エンドポイントは[https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)です
          </td>

          <td>
            [OTLP エンドポイント構成ドキュメント](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            Confluent Cloud からのクラスターの ID
          </td>

          <td>
            [list クラスター ID コマンドのドキュメント](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            クラウド API キー
          </td>

          <td>
            [クラウド API キーのドキュメント](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            クラウド API シークレット
          </td>

          <td>
            [クラウド API キーのドキュメント](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (オプション) ここで ID を指定すると、Confluent コネクタを監視できます。
          </td>

          <td>
            [コネクタ ID のリスト コマンドのドキュメント](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (オプション) ここで ID を指定することで、Confluent スキーマ レジストリを監視できます。
          </td>

          <td>
            [コネクタ ID のリスト コマンドのドキュメント](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ### New Relic でデータを表示する [#view-your-data]

    Confluent Cloud データは、いくつかの異なる方法で表示できます。

    * [New Relic マーケットプレイス](https://one.newrelic.com/marketplace)に移動して、 `Confluent`を検索します。 利用可能なダッシュボードをアカウントに直接インストールできます。
    * メトリック エクスプローラーに移動し、 `confluent_kafka`をフィルターします。このデータは、任意のカスタム アラートまたはダッシュボードに追加できます。
  </Step>
</Steps>

## コンフルエント クラウド メトリクス [#confluent-metrics]

この統合は、_ _[Confluent Cloud Metrics API 内のすべての](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud) エクスポート可能な メトリクスをカバーします。以下に_エクスポート可能な_メトリクスの部分的なリストを示します。

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        名前
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        ネットワークから受信したデータのバイト数の差分。 各サンプルは、前のデータ サンプル以降に受信されたバイト数です。 カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        ネットワーク経由で送信されたデータのバイト数の差分。 各サンプルは、前のデータ ポイント以降に送信されたバイト数です。 カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        受信したレコードのデルタ カウント。各サンプルは、前のデータ サンプル以降に受信したレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        送信されたレコードのデルタ カウント。各サンプルは、前のデータ ポイント以降に送信されたレコードの数です。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        クラスターによって保持されている現在のバイト数。カウントは 60 秒ごとにサンプリングされます。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        アクティブな認証済み接続の数。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        ネットワーク経由で受信したリクエストのデルタ カウント。各サンプルは、前のデータ ポイント以降に受信したリクエストの数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        パーティション数
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        成功した認証のデルタ カウント。各サンプルは、前のデータ ポイント以降の成功した認証の数です。60 秒ごとにサンプリングされるカウント。
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        グループ メンバーのコミットされたオフセットとパーティションの最高水準点の間のラグ。
      </td>
    </tr>
  </tbody>
</table>