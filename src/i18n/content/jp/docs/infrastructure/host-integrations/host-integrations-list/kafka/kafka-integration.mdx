---
title: Kafkaモニタリングの統合
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: 'New Relic''s Kafka integration: how to install it and configure it, and what data it reports.'
dataSource: kafka
translationType: machine
---

import osLinux from 'images/os_icon_linux.webp'

import osWindows from 'images/os_icon_windows.webp'

import osEcs from 'images/os_icon_ecs.webp'

import osk8 from 'images/os_icon_k8.webp'

New Relic Kafka [on-host integration](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) は、お使いの Kafka サービスからメトリクスと設定データをレポートします。ブローカー（ZooKeeperとBootstrapの両方）、プロデューサー、コンシューマー、トピックなど、クラスタの主要な要素をすべて計測します。

Kafkaモニタリング統合をインストールするには、次の手順を実行する必要があります。

1. [インストールの準備をします](#prepare)。
2. [インテグレーションのインストールとアクティブ化](#install)。
3. [インテグレーションの設定](#config)。
4. [データの検索と使用](#find-and-use)。
5. 必要に応じて、 [Kafkaの構成設定](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config)を参照してください。

<Callout variant="tip">
  Kafkaを監視する際のベストプラクティスについては、[このブログ投稿](https://newrelic.com/blog/best-practices/new-relic-kafkapocalypse)を確認してください。
</Callout>

## 互換性と要件 [#req]

### カフカバージョン [#kafka-versions]

この統合は、Kafka バージョン 3 以下と互換性があります。

[サポート終了の](https://docs.confluent.io/platform/current/installation/versions-interoperability.html#cp-and-apache-ak-compatibility) Kafka バージョンを使用すると、予期しない結果が生じる可能性があるため [、Apache Kafka EOL ポリシー](https://cwiki.apache.org/confluence/display/KAFKA/Time+Based+Release+Plan#TimeBasedReleasePlan-WhatIsOurEOLPolicy) に注意してください。

### 対応するオペレーティング・システム [#supported-os]

* ウィンドウズ

  <img style={{ width: '32px', height: '32px'}} class="inline" title="Windows" alt="Windows" src={osWindows}/>

* Linux

  <img style={{ width: '32px', height: '32px'}} class="inline" title="Linux" alt="Linux" src={osLinux}/>

特定のWindowsおよびLinuxバージョンの包括的なリストについては、 [互換性のあるオペレーティングシステム](/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/#operating-systems)の表を確認してください。

### システム要求 [#system-reqs]

* NewRelicアカウント。持っていませんか？[無料でお申し込み頂けます！](https://newrelic.com/signup)クレジットカードは必要ありません。

* KafkaがKubernetesまたはAmazonECSで実行されていない場合は[、インフラストラクチャエージェント](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic)をLinuxまたはWindows OSホスト、またはKafkaがインストールされている場所にリモートアクセスできるホストにインストールできます。さもないと：

  * 実行中の場合

    <img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src={osk8}/>

    Kubernetes、 [これらの要件](/docs/monitor-service-running-kubernetes#requirements)を参照してください。

  * 実行中の場合

    <img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src={osEcs}/>

    Amazon ECS、 [これらの要件](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)を参照してください。

* Javaバージョン8以降。

* JMXはすべてのブローカーで有効になっています。

* Javaベースのコンシューマーとプロデューサーのみで、JMXが有効になっています。

* 監視対象トピックの総数は10000未満である必要があります。

### 接続条件 [#connectivity-requirements]

統合を構成し、以下に接続できるようにする必要があります。

* `autodiscover_strategy`が`zookeeper`に設定されている場合、Zookeeper認証メカニズムを使用して、Zookeeperプロトコルを介して`zookeeper_hosts`にリストされているホスト。
* `autodiscover_strategy`が`bootstrap`に設定されている場合、Kafkaブローカーの認証/トランスポートメカニズムを使用して、Kafkaプロトコルを介して`bootstrap_broker_host`で定義されたホスト。
* クラスター内のすべてのブローカーがKafkaのプロトコルとポートを介して、Kafkaブローカーの認証/トランスポートメカニズムを使用します。
* クラスター内のすべてのブローカーが、ブローカーのJMX構成で指定された認証/トランスポートメカニズムを使用して、JMXプロトコルとポートを介して。
* プロデューサ/コンシューマのモニタリングを行う場合は、JMXプロトコルとポートを介してプロデューサとコンシューマで指定されたすべてのプロデューサ/コンシューマ。コンシューマーのJMX設定は、ブローカーと同じである必要があります。

<Callout variant="important">
  デフォルトでは、AWSの他のクラウドプロバイダーのセキュリティグループとそれに相当するものは、デフォルトで必要なポートを開いていません。 JMXが機能するには、JMXポートとRMIポートの2つのポートが必要です。これらは、JMXを有効にするようにJVMを構成するときに同じ値に設定でき、ブローカーに接続してブローカーからメトリックを収集できるように統合を開く必要があります。
</Callout>

## インストールの準備 [#prepare]

Kafkaは、分散システムとして構築された複雑なソフトウェアです。このため、データが正しく収集されるように、統合が必要なすべてのホストとサービスに接続できることを確認する必要があります。

<CollapserGroup>
  <Collapser
    id="autodiscovery"
    title="オートディスカバリー"
  >
    Kafkaの分散型の性質を考慮すると、ブローカーの実際の数とリストは通常、構成によって固定されておらず、代わりにかなり動的になります。このため、Kafkaインテグレーションでは、クラスタ内のブローカーのリストを自動的に検出する2つのメカニズムを提供しています。BootstrapとZookeeperです。どちらのメカニズムを使用するかは、監視対象のKafkaクラスタの設定によります。

    ### ブートストラップ

    [ブートストラップメカニズム](#bootstrap)を使用すると、統合はブートストラップブローカーを使用して自動検出を実行します。これは、アドレスがよく知られているブローカーであり、認識している他のブローカーに尋ねられます。統合は、ブートストラップ検出が機能するために、bootstrap_broker_hostパラメーターで指定されたアドレスでこのブローカーに接続できる必要があります。

    ### ズーキーパー

    または、Kafka統合は、ブローカーのリストを取得するために[Zookeeperサーバー](#zookeeper)と通信することもできます。これを行うには、統合に次のものを提供する必要があります。

    * 連絡するZookeeperホストのリスト`zookeeper_hosts` 。

    * ホストとの接続に必要な適切な認証シークレット。

      Zookeeper は、知っているブローカーのリストと一緒に、それぞれのブローカーがどのような接続メカニズムをサポートしているかをアドバタイズする。

      Kafka統合を構成して、 `preferred_listener`パラメーターを使用してこれらのメカニズムの1つを直接試すことができます。このパラメーターが指定されていない場合、統合は、アドバタイズされたすべての構成をブローカーの1つが成功するまで、ブローカーに接続しようとします。

      <Callout variant="tip">
        Zookeeper は、ブローカーを検出するためにのみ使用され、メトリクスは取得しません。
      </Callout>
  </Collapser>

  <Collapser
    id="topic-listing"
    title="トピックス一覧"
  >
    ブローカーによって処理されたトピックを正しくリストアップするために、統合はKafkaプロトコルを介してブローカーに連絡する必要があります。ブローカーの構成によっては、SSLやSASLをブローカーの構成に合わせて設定する必要があります。トピックにはDESCRIBEアクセスが必要です。
  </Collapser>

  <Collapser
    id="broker-monitoring"
    title="ブローカーの監視（JMX）"
  >
    Kafkaインテグレーションでは、Javaアプリケーションでメトリクスを交換するための標準的なJava拡張機能であるJMXを照会します。JMX は Kafka ブローカーではデフォルトでは有効になっておらず、メトリクス収集が正しく動作するためには有効にする必要があります。JMX は RMI を有効にする必要があり、RMI ポートは JMX と同じポートに設定する必要があります。

    ユーザー名/パスワード認証、およびSSLを使用するようにJMXを設定することができます。ブローカーのJMX設定でこのような機能が有効になっている場合は、それに応じて統合を設定する必要があります。

    自動検出がブートストラップに設定されている場合、ブートストラップブローカーに定義されたJMX設定は、検出された他のすべてのブローカーに適用されるため、ポートおよびその他の設定はすべてのブローカーで同じである必要があります。 <Callout variant="important">パブリックまたは信頼できないネットワークセグメントで匿名および/または暗号化されていないJMX/RMIアクセスを有効にすることは、セキュリティ上の大きなリスクをもたらすため、お勧めしません。</Callout>
  </Collapser>

  <Collapser
    id="consumer-offset"
    title="消費者のオフセット"
  >
    トピックのコンシューマーグループとコンシューマーグループのオフセット、およびラグは、 `CONSUMER_OFFSET=true`フラグを持つ[KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection)として取得できますが、このフラグがアクティブ化されるとインスタンスは他のサンプルを収集しないため、別のインスタンスに含める必要があります。
  </Collapser>

  <Collapser
    id="producer"
    title="プロデューサーおよびコンシューマー監視（JMX）"
  >
    また、Javaで書かれたプロデューサーとコンシューマーは、同じメカニズム（JMX）を通じて、より具体的なメタデータを得るために監視することができます。これにより、 [KafkaConsumerSamples と KafkaProducerSamples](#KafkaConsumerSample-collection) が生成されます。JMX がデフォルトで有効になっていないアプリケーションでは、JMX を有効にして設定する必要があります。

    非JavaのプロデューサーとコンシューマーはJMXをサポートしていないため、Kafkaとの統合ではサポートされません。
  </Collapser>
</CollapserGroup>

## インテグレーションのインストールとアクティブ化 [#install]

Kafka統合をインストールするには、ご使用の環境の指示に従ってください。

### Linuxのインストール [#linux-install]

1. [統合のインストール](/docs/install-integrations-package)手順に従い、 `INTEGRATION_FILE_NAME`変数を`nri-kafka`に置き換えます。

2. 以下を実行して、ディレクトリをインテグレーションの設定フォルダーに変更します。

   ```shell
   cd /etc/newrelic-infra/integrations.d
   ```

3. 以下を実行して、サンプルの設定ファイルをコピーします。

   ```shell
   sudo cp kafka-config.yml.sample kafka-config.yml
   ```

4. お気に入りのエディターで`kafka-config.yml`構成ファイルを編集します。いくつかの[優れた構成ファイルの例を確認してください。](#examples) 。

5. Infrastructureエージェントを再起動します。[さまざまなLinux環境でInfrastructureエージェントを再起動する](/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/#linux)方法を参照してください。

### その他の環境 [#other-env]

<CollapserGroup>
  <Collapser
    id="windows-install"
    title={<><img src={osWindows} title="Windows installation" alt="Windows installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/>Windowsへのインストレーション</>}
  >
    1. [New Relic の Kafka 統合用の .MSI インストーラー イメージをダウンロードします](https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-kafka/nri-kafka-amd64.msi)。

    2. コマンドプロンプトを開いて実行することにより、NewRelicのKafka統合をインストールします。

       ```shell
       msiexec.exe /qn /i $PATH_TO\nri-kafka-amd64.msi
       ```

    3. Integrationsディレクトリ`C:\Program Files\New Relic\newrelic-infra\integrations.d\`で、次のコマンドを実行してサンプル構成ファイルのコピーを作成します。

       ```shell
       cp kafka-config.yml.sample kafka-config.yml
       ```

    4. [`kafka-config.yml`サンプルファイル](#examples)の1つを使用して`kafka-config.yml`ファイルを編集します。

    5. Infrastructureエージェントを再起動します。[さまざまなLinux環境でInfrastructureエージェントを再起動する](/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/#linux)方法を参照してください。
  </Collapser>

  <Collapser
    id="ecs-install"
    title={<><img src={osEcs} title="Amazon ECS installation" alt="Amazon ECS installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/>' ' Amazon ECSへのインストレーション</>}
  >
    [ECSで実行されているモニターサービスを](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)参照してください。
  </Collapser>

  <Collapser
    id="k8s-install"
    title={<><img src={osk8} title="Kubernetes installation" alt="Kubernetes installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/>Kubernetesへのインストレーション</>}
  >
    [Kubernetesで実行されているモニターサービスを](/docs/monitor-service-running-kubernetes)参照してください。
  </Collapser>
</CollapserGroup>

その他の注意事項：

* **高度：**統合は[tarball形式](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball)でも利用可能であり、パッケージマネージャーの外部にインストールできます。
* **オンホスト統合は自動的に更新されません。**最良の結果を得るには、統合パッケージと[インフラストラクチャエージェント](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent)を定期的に[更新して](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package)ください。

<InstallFeedback/>

## 統合を構成する [#config]

インストール方法に応じて、統合を構成する方法はいくつかあります。

* 経由で有効にした場合

  <img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src={osk8}/>

  Kubernetes、[Kubernetesで実行されているサービスを監視するをご覧ください](/docs/monitor-service-running-kubernetes)。

* 経由で有効にした場合

  <img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src={osEcs}/>

  Amazon ECS 、 [ECSで実行されているサービスを監視する](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)。

* ホストにインストールされている場合は、統合のYAML構成ファイル`kafka-config.yml`の構成を編集します。統合のYAML形式の構成では、必要なログイン資格情報を配置し、データの収集方法を構成できます。どのオプションを変更するかは、セットアップと設定によって異なります。構成ファイルには、 `interval` 、 `timeout` 、 `inventory_source`などのすべての統合に適用できる共通の設定があります。これらの一般的な設定のすべてを読むには、 [構成フォーマット](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/#configuration-basics)のドキュメントを参照してください。

<Callout variant="important">
  レガシー設定および定義ファイルを引き続き使用する場合は、この[ドキュメント](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/)を参照してください。
</Callout>

他の統合と同様に、1つの`kafka-config.yml`構成ファイルには、さまざまなブローカー、コンシューマー、およびプロデューサーのメトリックを収集する統合の多くのインスタンスを含めることができます。[`kafka-config.yml`サンプルファイル](#examples)で1つまたは複数のインスタンスを使用した構成例を確認できます

Kafkaに関連する特定の設定は、 `kafka-config.yml`構成ファイルの各インスタンスの`env`セクションを使用して定義されます。これらの設定は、ブローカー、Zookeeper、JMXへの接続、およびその他のセキュリティ設定と機能を制御します。有効な設定のリストは、 [Kafkaの構成設定](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config)に記載されています。

統合には、各インスタンスで2つの動作モードがあり、これらは相互に排他的であり、 `CONSUMER_OFFSET`パラメーターを使用してセットアップできます。

* コンシューマーオフセットコレクション： [KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection)を収集するように`CONSUMER_OFFSET = true`を設定します。
* コア収集モード：残りのサンプルを収集するには、 `CONSUMER_OFFSET = false`を設定します： [KafkaBrokerSample、KafkaTopicSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#broker-collection) 、 [KafkaProducerSample、KafkaConsumerSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaConsumerSample-collection) 。

<Callout variant="important">
  コンシューマーオフセット収集は実行に時間がかかり、高いパフォーマンス要件があるため、これらのモードは相互に排他的です。両方のサンプルグループを収集するには、各モードに1つずつ、2つのインスタンスを設定します。
</Callout>

これらの設定の値は、いくつかの方法で定義できます。

* 設定ファイルに直接値を追加します。これが最も一般的な方法です。
* `{{ }}` 表記を使用して環境変数の値を置き換えます。 [オンホスト統合での環境変数パススルーの使用](/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent/#passthrough) について詳しく読むか、 [環境変数の置換](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch/elasticsearch-integration#envvar-replacement)の例を参照してください。
* シークレット管理の使用。これを使用して、設定ファイルのプレーンテキストで公開されないようにパスワードなどの重要な情報を保護してください。詳細については、[シークレット管理](/docs/integrations/host-integrations/installation/secrets-management)を参照してください。

### オフセット監視

`CONSUMER_OFFSET = true`を設定すると、デフォルトでは、アクティブなコンシューマーを持つコンシューマーグループからのメトリック（およびコンシューマーメトリック）のみが収集されます。非アクティブなコンシューマーを持つコンシューマーグループからメトリックを収集するには、 `INACTIVE_CONSUMER_GROUP_OFFSET`を`true`に設定する必要があります。

消費者グループが複数のトピックを監視している場合、特にトピックの1つに非アクティブな消費者がいる場合は、消費者グループのメトリックをトピックごとに分けることが重要です。これにより、消費者グループが遅れているトピックを特定できるためです。その消費者グループとトピックのアクティブな消費者です。

消費者グループの指標をトピックごとに分けるには、 `CONSUMER_GROUP_OFFSET_BY_TOPIC`を`true`に設定する必要があります（デフォルトは`false` ）

オフセット監視の設定方法の詳細については、「 [KafkaOffsetSampleコレクションの構成」](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection)を参照してください。

## kafka-config.ymlサンプルファイル [#examples]

<CollapserGroup>
  <Collapser
    id="zookeeper"
    title="Zookeperの発見"
  >
    この構成では、2つの異なるJMXホストからブローカーを検出するすべてのトピックを含むMetricsとInventoryを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}, {"host": "localhost2", "port": 2181}]'
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: all
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="zookeeper-ssl"
    title="ZookeperSSLディスカバリー"
  >
    この構成では、SSLを使用したJMXホストからブローカーを検出して、MetricsとInventoryを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password

          KEY_STORE: "/path/to/your/keystore"
          KEY_STORE_PASSWORD: keystore_password
          TRUST_STORE: "/path/to/your/truststore"
          TRUST_STORE_PASSWORD: truststore_password

          TIMEOUT: 10000  #The timeout for individual JMX queries in milliseconds.
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="bootstrap"
    title="ブートストラップの発見"
  >
    この構成では、1つのブートストラップブローカから、ブローカを検出するすべてのトピックを含むメトリクスとインベントリを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          BOOTSTRAP_BROKER_JMX_PORT: 9999  # This same port will be used to connect to all discover broker JMX
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          LOCAL_ONLY_COLLECTION: false

          COLLECT_BROKER_TOPIC_DATA: true
          TOPIC_MODE: "all"
          COLLECT_TOPIC_SIZE: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="bootstrap-tls"
    title="ブートストラップ検出TLS"
  >
    この設定では、TLSプロトコルでリッスンする1つのブートストラップブローカから、ブローカを発見したメトリクスのみを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          TLS_CA_FILE: "/path/to/CA.pem"
          TLS_CERT_FILE: "/path/to/cert.pem"
          TLS_KEY_FILE: "/path/to/key.pem"
          TLS_INSECURE_SKIP_VERIFY: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="boostrap-kerberos"
    title="ブートストラップ検出Kerberos認証"
  >
    この設定では、Kerberos Auth Clusterの1つのブートストラップブローカからブローカを検出するMetricsのみを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT # Currently support PLAINTEXT and SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          SASL_MECHANISM: GSSAPI
          SASL_GSSAPI_REALM: SOMECORP.COM
          SASL_GSSAPI_SERVICE_NAME: Kafka
          SASL_GSSAPI_USERNAME: kafka
          SASL_GSSAPI_KEY_TAB_PATH: /etc/newrelic-infra/kafka.keytab
          SASL_GSSAPI_KERBEROS_CONFIG_PATH: /etc/krb5.conf
          SASL_GSSAPI_DISABLE_FAST_NEGOTIATION: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="zookeeper-topic-bucket"
    title="Zookeeperdicsoveryトピックバケット"
  >
    この構成では、トピックの収集を3つの異なるインスタンスに分割してMetricsを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host1", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '1/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster2
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host2", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '2/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster3
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host3", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '3/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="java-consumer-producer"
    title="Javaのコンシューマーおよびプロデューサー"
  >
    ここでは、JavaのコンシューマとプロデューサからJMXメトリクスを収集する例を示します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: "true"
          CLUSTER_NAME: "testcluster3"
          PRODUCERS: '[{"host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          CONSUMERS: '[{"host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          DEFAULT_JMX_HOST: "localhost"
          DEFAULT_JMX_PORT: "9999"
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="consumer-offset"
    title="消費者のオフセット"
  >
    この構成では、クラスタのコンシューマ・オフセット・メトリクスとインベントリを収集します。

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CONSUMER_OFFSET: true
          CLUSTER_NAME: testcluster3
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          # A regex pattern that matches the consumer groups to collect metrics from
          CONSUMER_GROUP_REGEX: '.*'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>
</CollapserGroup>

## 統合のための構成オプション [#config-options]

データを検索して使用する方法の詳細については、 [Kafkaの構成設定](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config)を参照してください。

## データを見つけて使用する [#find-and-use]

このサービスからのデータは、 [統合ダッシュボード](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts)に報告されます。

Kafkaのデータは、以下の [イベントタイプに添付されています。](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic):

* [`KafkaBrokerSample`](#broker-sample)
* [`KafkaTopicSample`](#topic-sample)
* [`KafkaProducerSample`](#producer-sample)
* [`KafkaConsumerSample`](#consumer-sample)
* [`KafkaOffsetSample`](#offset-sample)

トラブルシューティング目的で、またはチャートとダッシュボードを作成するために、[このデータのクエリ](/docs/using-new-relic/data/understand-data/query-new-relic-data)を行えます。

データを検索して使用する方法の詳細については、[統合データを理解する](/docs/infrastructure/integrations/find-use-infrastructure-integration-data)方法を参照してください。

## 統合によって収集されたメトリック [#metrics]

Kafka統合は、次のメトリックを収集します。各メトリック名の前には、カテゴリインジケーターとピリオド（ `broker.`や`consumer.`など）が付いています。

<CollapserGroup>
  <Collapser
    id="broker-sample"
    title="KafkaBrokerSampleイベント"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            メトリック
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `broker.bytesWrittenToTopicPerSecond`
          </td>

          <td>
            ブローカーが1秒あたりにトピックに書き込んだバイト数。
          </td>
        </tr>

        <tr>
          <td>
            `broker.IOInPerSecond`
          </td>

          <td>
            クラスター内のブローカーへのネットワークIOを1秒あたりのバイト数で表示しています。
          </td>
        </tr>

        <tr>
          <td>
            `broker.IOOutPerSecond`
          </td>

          <td>
            クラスター内のブローカーのネットワークIOアウト（バイト/秒）。
          </td>
        </tr>

        <tr>
          <td>
            `broker.logFlushPerSecond`
          </td>

          <td>
            ログ・フラッシュ・レート
          </td>
        </tr>

        <tr>
          <td>
            `broker.messagesInPerSecond`
          </td>

          <td>
            着信メッセージ数/秒
          </td>
        </tr>

        <tr>
          <td>
            `follower.requestExpirationPerSecond`
          </td>

          <td>
            フォロワーに対するリクエストの失効率（1秒あたりの退避数）。
          </td>
        </tr>

        <tr>
          <td>
            `net.bytesRejectedPerSecond`
          </td>

          <td>
            拒否されたバイト数/秒
          </td>
        </tr>

        <tr>
          <td>
            `replication.isrExpandsPerSecond`
          </td>

          <td>
            ISRプールに参加するレプリカの割合。
          </td>
        </tr>

        <tr>
          <td>
            `replication.isrShrinksPerSecond`
          </td>

          <td>
            ISRプールから離れるレプリカの割合。
          </td>
        </tr>

        <tr>
          <td>
            `replication.leaderElectionPerSecond`
          </td>

          <td>
            リーダー選出率。
          </td>
        </tr>

        <tr>
          <td>
            `replication.uncleanLeaderElectionPerSecond`
          </td>

          <td>
            汚れたリーダーの選出率
          </td>
        </tr>

        <tr>
          <td>
            `replication.unreplicatedPartitions`
          </td>

          <td>
            複製されていないパーティションの数。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeFetch`
          </td>

          <td>
            フェッチリクエスト1回あたりの平均時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeMetadata`
          </td>

          <td>
            メタデータ・リクエストの平均時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeMetadata99Percentile`
          </td>

          <td>
            99パーセンタイルのメタデータ・リクエストの時間（ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeOffset`
          </td>

          <td>
            オフセットリクエストの平均時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeOffset99Percentile`
          </td>

          <td>
            99パーセンタイルのオフセット要求の時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeProduceRequest`
          </td>

          <td>
            プロデュースリクエストの平均時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeUpdateMetadata`
          </td>

          <td>
            メタデータを更新するリクエストの平均時間（ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeUpdateMetadata99Percentile`
          </td>

          <td>
            99パーセンタイルのメタデータ更新要求の時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.clientFetchesFailedPerSecond`
          </td>

          <td>
            クライアントのフェッチリクエストの失敗数/秒。
          </td>
        </tr>

        <tr>
          <td>
            `request.fetchTime99Percentile`
          </td>

          <td>
            99パーセンタイルのフェッチリクエストの時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `request.handlerIdle`
          </td>

          <td>
            リクエストハンドラースレッドがアイドル状態である時間の平均割合。
          </td>
        </tr>

        <tr>
          <td>
            `request.produceRequestsFailedPerSecond`
          </td>

          <td>
            1秒あたりの失敗したプロダクション・リクエスト
          </td>
        </tr>

        <tr>
          <td>
            `request.produceTime99Percentile`
          </td>

          <td>
            99パーセンタイルのプロデュース依頼にかかる時間。
          </td>
        </tr>

        <tr>
          <td>
            `topic.diskSize`
          </td>

          <td>
            ディスク内トピック・サイズ。COLLECT_TOPIC_SIZEが有効な場合のみ存在します。
          </td>
        </tr>

        <tr>
          <td>
            `topic.offset`
          </td>

          <td>
            トピック・オフセット。COLLECT_TOPIC_OFFSETが有効な場合のみ存在します。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="consumer-sample"
    title="KafkaConsumerSampleイベント"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            メトリック
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `consumer.avgFetchSizeInBytes`
          </td>

          <td>
            特定のトピックのリクエストごとに取得されたバイト数の平均値。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.avgRecordConsumedPerTopic`
          </td>

          <td>
            特定のトピックに対する各リクエストの平均レコード数。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.avgRecordConsumedPerTopicPerSecond`
          </td>

          <td>
            特定のトピックについて、1秒間に消費されるレコードの平均数（単位：レコード/秒）。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.bytesInPerSecond`
          </td>

          <td>
            コンシューマーバイト/秒。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.fetchPerSecond`
          </td>

          <td>
            コンシューマがフェッチリクエストをブレイクスルーに送信する際の最小レート（1秒あたりのリクエスト数）。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.maxFetchSizeInBytes`
          </td>

          <td>
            特定のトピックのリクエストごとに取得される最大バイト数。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.maxLag`
          </td>

          <td>
            最大限のコンシューマー・ラグ。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.messageConsumptionPerSecond`
          </td>

          <td>
            コンシューマのメッセージ消費率（1秒あたりのメッセージ数）。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.offsetKafkaCommitsPerSecond`
          </td>

          <td>
            Kafkaへのオフセットコミットの割合（コミット数/秒）。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.offsetZooKeeperCommitsPerSecond`
          </td>

          <td>
            ZooKeeper へのオフセットコミットの割合 (Write per Second)。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.requestsExpiredPerSecond`
          </td>

          <td>
            遅延したコンシューマ・リクエストの失効率（1秒あたりのエヴィジョン数）。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="producer-sample"
    title="KafkaProducerSampleイベント"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            メトリック
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `producer.ageMetadataUsedInMilliseconds`
          </td>

          <td>
            現在使用されているプロデューサーメタデータの年齢（秒単位）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.availableBufferInBytes`
          </td>

          <td>
            使用されていないバッファメモリの総量（単位：バイト）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgBytesSentPerRequestInBytes`
          </td>

          <td>
            パーティションごとのリクエストごとの平均送信バイト数。
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgCompressionRateRecordBatches`
          </td>

          <td>
            レコードバッチの平均圧縮率
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordAccumulatorsInMilliseconds`
          </td>

          <td>
            レコードバッチがレコードアキュムレータにかかった平均時間（ms）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordSizeInBytes`
          </td>

          <td>
            平均レコードサイズ（単位：バイト）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordsSentPerSecond`
          </td>

          <td>
            1秒間に送信されるレコードの平均数。
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordsSentPerTopicPerSecond`
          </td>

          <td>
            トピックの1秒あたりの平均送信レコード数。
          </td>
        </tr>

        <tr>
          <td>
            `producer.AvgRequestLatencyPerSecond`
          </td>

          <td>
            プロデューサーの平均リクエストレイテンシー。
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgThrottleTime`
          </td>

          <td>
            ブローカーによってリクエストがスロットルされた平均時間（ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.bufferMemoryAvailableInBytes`
          </td>

          <td>
            クライアントが使用できるバッファメモリの最大量（単位：バイト）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.bufferpoolWaitTime`
          </td>

          <td>
            アペンダーがスペースの割り当てを待つ時間の派閥。
          </td>
        </tr>

        <tr>
          <td>
            `producer.bytesOutPerSecond`
          </td>

          <td>
            プロデューサーバイト/秒アウト。
          </td>
        </tr>

        <tr>
          <td>
            `producer.compressionRateRecordBatches`
          </td>

          <td>
            あるトピックのレコードバッチの平均圧縮率。
          </td>
        </tr>

        <tr>
          <td>
            `producer.iOWaitTime`
          </td>

          <td>
            プロデューサーI/Oの待ち時間（ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxBytesSentPerRequestInBytes`
          </td>

          <td>
            パーティションごとに送信される最大バイト数 per-request。
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxRecordSizeInBytes`
          </td>

          <td>
            最大レコードサイズ（単位：バイト）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxRequestLatencyInMilliseconds`
          </td>

          <td>
            最大リクエストレイテンシー（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxThrottleTime`
          </td>

          <td>
            リクエストがブローカによってスロットルされた最大時間（単位：ミリ秒）。
          </td>
        </tr>

        <tr>
          <td>
            `producer.messageRatePerSecond`
          </td>

          <td>
            1秒あたりのプロデューサーメッセージ数
          </td>
        </tr>

        <tr>
          <td>
            `producer.responsePerSecond`
          </td>

          <td>
            1秒あたりのプロデューサーの応答数
          </td>
        </tr>

        <tr>
          <td>
            `producer.requestPerSecond`
          </td>

          <td>
            1秒あたりのプロデューサー・リクエストの数。
          </td>
        </tr>

        <tr>
          <td>
            `producer.requestsWaitingResponse`
          </td>

          <td>
            応答を待っている機内リクエストの現在の数。
          </td>
        </tr>

        <tr>
          <td>
            `producer.threadsWaiting`
          </td>

          <td>
            レコードをエンキューするためのバッファメモリを待ってブロックされたユーザースレッドの数。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="topic-sample"
    title="KafkaTopicSampleイベント"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            メトリック
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `topic.diskSize`
          </td>

          <td>
            ブローカーあたりの現在のトピックのディスクサイズ（単位：バイト）。
          </td>
        </tr>

        <tr>
          <td>
            `topic.partitionsWithNonPreferredLeader`
          </td>

          <td>
            トピックごとのパーティションのうち、優先するレプリカに導かれていないパーティションの数。
          </td>
        </tr>

        <tr>
          <td>
            `topic.respondMetaData`
          </td>

          <td>
            メタデータの要求に応えたトピックの数
          </td>
        </tr>

        <tr>
          <td>
            `topic.retentionSizeOrTime`
          </td>

          <td>
            パーティションをサイズで保持するか、サイズと時間の両方で保持するか。値が0の場合は時間、値が1の場合はサイズと時間の両方です。
          </td>
        </tr>

        <tr>
          <td>
            `topic.underReplicatedPartitions`
          </td>

          <td>
            アンダーレプリケートされているトピックごとのパーティションの数。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="offset-sample"
    title="KafkaOffsetSampleイベント"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            メトリック
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `consumer.offset`
          </td>

          <td>
            消費者グループがパーティション上で最後に消費したオフセット。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.lag`
          </td>

          <td>
            ブローカーの最高水準点と消費者のオフセットの差（ `consumer.hwm` - `consumer.offset` ）。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.hwm`
          </td>

          <td>
            パーティションに書き込まれた最後のメッセージのオフセット（ハイウォーターマーク）。
          </td>
        </tr>

        <tr>
          <td>
            `consumer.totalLag`
          </td>

          <td>
            コンシューマが消費するパーティション間のラグの合計。
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.totalLag`
          </td>

          <td>
            `consumerGroup`によって消費されるすべてのパーティションにわたるラグの合計。
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.maxLag`
          </td>

          <td>
            `consumerGroup`によって消費されるすべてのパーティションにわたる最大ラグ。
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.activeConsumers`
          </td>

          <td>
            この`consumerGroup`のアクティブなコンシューマーの数。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>