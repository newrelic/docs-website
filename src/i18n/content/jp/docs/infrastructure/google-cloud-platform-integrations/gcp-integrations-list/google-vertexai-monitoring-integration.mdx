---
title: Google VertexAI 監視インテグレーション
tags:
  - Integrations
  - Google Cloud Platform integrations
  - GCP integrations list
metaDescription: 'New Relic Google VertexAI integration: the data it reports and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

[New Relic の統合には、](/docs/infrastructure/introduction-infra-monitoring) GCP 実行データを製品に報告するための統合が含まれています。 ここでは、インテグレーションを有効にする方法と、インテグレーションが収集するデータについて説明します。

## 統合をアクティブ化する [#activate]

インテグレーションを有効にするには、標準の手順に従って[GCP サービスをNew Relicに接続します](/docs/connect-google-cloud-platform-services-infrastructure)。

## 構成とポーリング [#polling]

[構成オプション](/docs/integrations/new-relic-integrations/getting-started/configure-polling-frequency-data-collection-cloud-integrations)を使用して、ポーリング頻度とフィルターデータを変更できます。

デフォルト [ポーリング](/docs/integrations/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations) GCP Run統合のための情報です。

* New Relicのポーリング間隔：5分

## データを見つけて使用する [#find-data]

インテグレーションデータを検索するには、 <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Infrastructure &amp;gt; GCP**</DNT>に移動してインテグレーションを選択してください。

データは、次の[イベントタイプ](/docs/data-apis/understand-data/new-relic-data-types/#event-data)に添付されます。

<table>
  <thead>
    <tr>
      <th>
        エンティティ
      </th>

      <th>
        イベントタイプ
      </th>

      <th>
        プロバイダー
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        終点
      </td>

      <td>
        `GcpVertexAiEndpointSample`
      </td>

      <td>
        `GcpVertexAiEndpoint`
      </td>
    </tr>

    <tr>
      <td>
        機能ストア
      </td>

      <td>
        `GcpVertexAiFeaturestoreSample`
      </td>

      <td>
        `GcpVertexAiFeaturestore`
      </td>
    </tr>

    <tr>
      <td>
        機能オンラインストア
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStoreSample`
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStore`
      </td>
    </tr>

    <tr>
      <td>
        場所
      </td>

      <td>
        `GcpVertexAiLocationSample`
      </td>

      <td>
        `GcpVertexAiLocation`
      </td>
    </tr>

    <tr>
      <td>
        索引
      </td>

      <td>
        `GcpVertexAiIndexSample`
      </td>

      <td>
        `GcpVertexAiIndex`
      </td>
    </tr>

    <tr>
      <td>
        パイプラインジョブ
      </td>

      <td>
        `GcpVertexAiPipelineJobSample`
      </td>

      <td>
        `GcpVertexAiPipelineJob`
      </td>
    </tr>
  </tbody>
</table>

データの使用方法の詳細[については、統合データの理解と使用](/docs/infrastructure/integrations/find-use-infrastructure-integration-data)を参照してください。

## メトリックデータ [#metrics]

このインテグレーションは、VertexAI の GCP データを収集します。

### VertexAI エンドポイントデータ

<table>
  <thead>
    <tr>
      <th>
        メトリック
      </th>

      <th>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `prediction.online.accelerator.duty_cycle`
      </td>

      <td>
        パーセント
      </td>

      <td>
        過去のサンプル期間中にアクセラレータがアクティブに処理していた時間の平均割合。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.accelerator.memory.bytes_used`
      </td>

      <td>
        バイト
      </td>

      <td>
        デプロイされたモデルレプリカによって割り当てられたアクセラレータ メモリの量。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.error_count`
      </td>

      <td>
        Count
      </td>

      <td>
        オンライン予測エラーの数。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.memory.bytes_used`
      </td>

      <td>
        バイト
      </td>

      <td>
        デプロイされたモデルレプリカによって割り当てられ、現在使用されているメモリの量。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.received_bytes_count`
      </td>

      <td>
        バイト
      </td>

      <td>
        デプロイされたモデルレプリカによってネットワーク経由で受信されたバイト数。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.sent_bytes_count`
      </td>

      <td>
        バイト
      </td>

      <td>
        デプロイされたモデルレプリカによってネットワーク経由で送信されたバイト数。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_count`
      </td>

      <td>
        Count
      </td>

      <td>
        オンライン予測の数。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_latencies`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        デプロイモデルのオンライン予測レイテンシ。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.private.prediction_latencies`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        プライベートデプロイモデルのオンライン予測レイテンシ。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.replicas`
      </td>

      <td>
        Count
      </td>

      <td>
        デプロイされたモデルで使用されるアクティブなレプリカの数。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.response_count`
      </td>

      <td>
        Count
      </td>

      <td>
        異なるオンライン予測応答コードの数。
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.target_replicas`
      </td>

      <td>
        Count
      </td>

      <td>
        デプロイ モデルに必要なアクティブなレプリカの数。
      </td>
    </tr>
  </tbody>
</table>

### VertexAI Featurestore データ

<table>
  <thead>
    <tr>
      <th>
        メトリック
      </th>

      <th>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featurestore.cpu_load`
      </td>

      <td>
        パーセント
      </td>

      <td>
        Featurestore オンライン ストレージ内のノードの平均 CPU 負荷。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.cpu_load_hottest_node`
      </td>

      <td>
        パーセント
      </td>

      <td>
        Featurestore オンライン ストレージ内の最もホットなノードの CPU 負荷。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.node_count`
      </td>

      <td>
        Count
      </td>

      <td>
        Featurestore オンライン ストレージのノード数。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_entities_updated`
      </td>

      <td>
        Count
      </td>

      <td>
        Featurestore オンライン ストレージで更新されたエンティティの数。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.latencies`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        EntityType によるレイテンシのオンライン サービング。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_bytes_count`
      </td>

      <td>
        バイト
      </td>

      <td>
        EntityType によるリクエスト サイズ。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_count`
      </td>

      <td>
        Count
      </td>

      <td>
        EntityType ごとの Featurestore オンライン サービング数。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.response_size`
      </td>

      <td>
        バイト
      </td>

      <td>
        EntityType による応答サイズ。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.billable_processed_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        処理されたオフライン データに対して課金されるバイト数。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.stored_bytes`
      </td>

      <td>
        バイト
      </td>

      <td>
        Featurestore に保存されるバイト。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_processed_count`
      </td>

      <td>
        Count
      </td>

      <td>
        オフライン ストレージに対して処理されたストリーミング書き込み要求の数。
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_write_delays`
      </td>

      <td>
        秒
      </td>

      <td>
        書き込み API が呼び出されてからオフライン ストレージに書き込まれるまでの時間 (秒単位)。
      </td>
    </tr>
  </tbody>
</table>

### VertexAI FeatureOnlineStore データ

<table>
  <thead>
    <tr>
      <th>
        メトリック
      </th>

      <th>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featureonlinestore.online_serving.request_count`
      </td>

      <td>
        Count
      </td>

      <td>
        FeatureView によるサービングカウントの数。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_bytes_count`
      </td>

      <td>
        バイト
      </td>

      <td>
        FeatureView による応答サイズの提供。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_latencies`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        FeatureView によるオンライン サービスのレイテンシ。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.running_sync`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        特定の時点で実行中の同期の数。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_ages`
      </td>

      <td>
        秒
      </td>

      <td>
        提供データの経過時間を秒単位で測定します。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_by_sync_time`
      </td>

      <td>
        Count
      </td>

      <td>
        機能 Online Store のデータを同期されたタイムスタンプ別に内訳します。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load`
      </td>

      <td>
        パーセント
      </td>

      <td>
        機能オンラインストア内のノードの平均 CPU 負荷。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load_hottest_node`
      </td>

      <td>
        パーセント
      </td>

      <td>
        機能オンラインストアで最もホットなノードの CPU 負荷。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_nodes`
      </td>

      <td>
        Count
      </td>

      <td>
        機能オンラインストア(Bigtable)のノード数。
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.stored_bytes`
      </td>

      <td>
        Count
      </td>

      <td>
        機能オンラインストアに保存されたバイト。
      </td>
    </tr>
  </tbody>
</table>

### VertexAI 位置データ

<table>
  <thead>
    <tr>
      <th>
        メトリック
      </th>

      <th>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `online_prediction_requests_per_base_model`
      </td>

      <td>
        Count
      </td>

      <td>
        基本モデルごとのリクエスト数。
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.exceeded`
      </td>

      <td>
        Count
      </td>

      <td>
        クォータ制限を超過する試行回数。
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.limit`
      </td>

      <td>
        Count
      </td>

      <td>
        現在のクォータ制限メトリクス。
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.usage`
      </td>

      <td>
        Count
      </td>

      <td>
        クォータメトリックの現在の使用状況。
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_jobs`
      </td>

      <td>
        Count
      </td>

      <td>
        実行中のパイプライン ジョブの数。
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_tasks`
      </td>

      <td>
        Count
      </td>

      <td>
        実行中のパイプライン タスクの数。
      </td>
    </tr>
  </tbody>
</table>

### VertexAI インデックスデータ

<table>
  <thead>
    <tr>
      <th>
        メトリック
      </th>

      <th>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `matching_engine.stream_update.datapoint_count`
      </td>

      <td>
        Count
      </td>

      <td>
        正常にアップサートまたは削除されたデータポイントの数。
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.latencies`
      </td>

      <td>
        ミリ秒
      </td>

      <td>
        ユーザー間のレイテンシは UpsertDatapointsResponse または RemoveDatapointsResponse を受信し、その更新が有効になります。
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.request_count`
      </td>

      <td>
        Count
      </td>

      <td>
        ストリーム更新リクエストの数。
      </td>
    </tr>
  </tbody>
</table>

### VertexAI パイプラインジョブデータ

<table>
  <thead>
    <tr>
      <th>
        メトリック
      </th>

      <th>
        ユニット
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `pipelinejob.duration`
      </td>

      <td>
        秒
      </td>

      <td>
        実行中のパイプライン ジョブの実行時間 (作成から終了まで) (秒)。
      </td>
    </tr>

    <tr>
      <td>
        `pipelinejob/task_completed_count`
      </td>

      <td>
        Count
      </td>

      <td>
        完了したパイプライン タスクの合計数。
      </td>
    </tr>
  </tbody>
</table>