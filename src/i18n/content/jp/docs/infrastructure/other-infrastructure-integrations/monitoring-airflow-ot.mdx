---
title: OpenTelemetry を使用して Apache Airflow を監視する
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Airflow
  - Quickstart
metaDescription: Monitor Airflow data with New Relic using OpenTelemetry.
freshnessValidatedDate: '2023-11-16T00:00:00.000Z'
translationType: machine
---

[OpenTelemetry](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry)を構成して New Relic にデータを送信することで Apache Airflow データを監視し、タスク、オペレーター、DAG の実行をメトリクスとして視覚化できます。

<img title="Screenshot showing sample Airflow DAG runs in New Relic" alt="Screenshot showing sample Airflow DAG runs in New Relic" src="/images/opentelemetry_screenshot_airflow_01.webp" />

## 前提条件 [#prerequisites]

Apache Airflow で OpenTelemetry を有効にする前に、 `otel`エクストラを含む Airflow パッケージをインストールする必要があります。インストール方法は、Airflow 導入アプローチによって異なります。

### オプション 1: PyPi からインストールする [#install-pypi]

1. [Airflow のドキュメント](https://airflow.apache.org/docs/apache-airflow/stable/installation/installing-from-pypi.html)のインストール手順に従ってください。

2. pip を使用してインストールする場合は、コマンドに`otel`を追加します。 例えば：

   ```sh
   pip install "apache-airflow[otel]"
   ```

### オプション 2: Docker からのインストール [#install-docker]

1. [Airflow のドキュメント](https://airflow.apache.org/docs/docker-stack/index.html)の手順に従って、Airflow Docker イメージをセットアップします。

2. Dockerfile を使用してビルド済みの Docker イメージを拡張し、 `otel`エクストラをインストールします。最新のタグを希望のバージョンのイメージに置き換えることができます。

   ```dockerfile
   FROM apache/airflow:latest
   RUN pip install --no-cache-dir "apache-airflow[otel]==$AIRFLOW_VERSION"
   ```

<Callout variant="tip">
  `$AIRFLOW_VERSION` は、Apache/airflow コンテナによってすでに設定されていますが、他のベース イメージのバージョン番号に置き換えることができます。
</Callout>

## 構成 [#configuration]

Airflow メトリクスをNew Relic に送信するには、OpenTelemetry にデータをエクスポートするように メトリクスを設定します。これにより、[OpenTelemetry ](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-intro/)を使用してデータがNew Relic[ OTLP エンド ポイント](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/#note-endpoints) <InlinePopover type="licenseKey" />に転送されます。

<Callout variant="important">
  AirflowOpenTelemetry OpenTelemetryは現在、認証ヘッダー付きの データの送信をサポートしていないため、 での認証にはNew Relic コレクターが不可欠です。
</Callout>

### OpenTelemetryコレクターを構成する [#configuration-collector]

1. [基本的なコレクターの例](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-basic/)に従って、OpenTelemetry コレクターを設定します。
2. `https://otlp.nr-data.net:4317`などの適切な OTLP エンドポイントを使用してコレクターを構成します。
3. 認証のために、 <InlinePopover type="licenseKey" />を環境変数`NEW_RELIC_LICENSE_KEY`に追加して、 `api-key`ヘッダーに値が設定されるようにします。
4. 実行中の Airflow インスタンスからコレクターのポート 4318 にアクセスできることを確認します。 (docker の場合は、 [docker ネットワーク を](https://docs.docker.com/network/)使用する必要がある場合があります。)
5. コレクターをリリースします。

### エアフローメトリクスを構成する [#configuration-airflow]

Airflow は、ポート`4318`を使用する OTLP over HTTP を使用してメトリクスを送信します。Airflow には、[構成オプションを設定する](https://airflow.apache.org/docs/apache-airflow/stable/howto/set-config.html)複数の方法があります。

<Callout variant="important">
  dockerご使用の環境でOpenTelemetry コレクターと並んで コンテナーで Airflow が実行されている場合は、`otel_host` 設定を`localhost` からコレクターのコンテナー アドレスに変更する必要があります。
</Callout>

次のいずれかの方法を選択して、エアフローに必要なオプションを設定します。

1. `airflow.cfg`ファイルに必要なオプションを設定します。

   ```ini
   [metrics]
   otel_on = True
   otel_host = localhost
   otel_port = 4318
   otel_ssl_active = False
   ```

2. または、必要なオプションを環境変数として設定します。

   ```sh
   export AIRFLOW__METRICS__OTEL_ON=True
   export AIRFLOW__METRICS__OTEL_HOST=localhost
   export AIRFLOW__METRICS__OTEL_PORT=4318
   export AIRFLOW__METRICS__OTEL_SSL_ACTIVE=False
   ```

<Callout variant="tip">
  Airflow には、役立つ可能性のあるメトリクスの[追加設定が](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry)あります。これには、送信前に[メトリクスの名前を変更する](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#rename-metrics)機能が含まれます。これは、メトリクス名が OpenTelemetry の 63 バイト制限を超える場合に役立ちます。
</Callout>

## データが New Relic に送信されることを検証する [#validation]

New Relic が Airflow データを収集していることを確認するには、DAG またはパイプラインを実行します。

1. エアフローにログインします。
2. 既存のチュートリアル DAG の 1 つ、または独自のチュートリアル DAG の実行ボタンをクリックします。
3. パイプラインの実行が完了するまで待ちます。
4. <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; APM &amp; services &gt; Services - OpenTelemetry &gt; Airflow**</DNT>に移動します。
5. <DNT>**Metrics Explorer**</DNT>をクリックして、パイプライン実行のメトリクスを視覚化します。

## ダッシュボードの構築 [#building-dashboards]

Airflow メトリクスを使用すると、個々のパイプラインや全体的なパフォーマンスに関するダッシュボードを構築したり、異なるパイプライン間の比較を表示したりできます。[メトリクスのクエリの](/docs/data-apis/understand-data/metric-data/query-metric-data-type/)詳細については、ここをクリックしてください。

このクエリは、Airflow について報告されたすべてのメトリクスのリストを取得します。

```sql
SELECT uniques(metricName) FROM Metric WHERE entity.name = 'Airflow' 
AND metricName LIKE 'airflow.%' SINCE 30 MINUTES AGO LIMIT 100
```

メトリクス名が制限 ( `100` ) を超える場合は、必ず制限を変更してください。

このクエリは、さまざまな DAG が正常に実行された場合のさまざまな完了時間を比較します。

```sql
SELECT latest(airflow.dagrun.duration.success) FROM Metric 
FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img title="Screenshot showing sample Airflow DAG runs in New Relic" alt="Screenshot showing sample Airflow DAG runs in New Relic" src="/images/opentelemetry_screenshot_airflow_01.webp" />

このクエリは、失敗した DAG 実行の数を示します。これは、重要なパイプラインの<InlinePopover type="alerts" />を構築するために使用できます。

```sql
SELECT count(airflow.dagrun.duration.failed) FROM Metric 
FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img title="Screenshot showing sample Airflow failures in New Relic" alt="Screenshot showing sample Airflow failures in New Relic" src="/images/opentelemetry_screenshot_airflow_02.webp" />

<Callout variant="important">
  Airflow の OpenTelemetry メトリクスは New Relic によって保守されていないため、インストルメンテーションに問題がある場合は、 [Airflow の GitHub リポジトリで新しい問題を作成してください](https://github.com/apache/airflow/issues)。
</Callout>

<InstallFeedback />