---
title: Prometheus OpenMetrics インテグレーションの設定
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure OpenMetrics
metaDescription: Configuration options and examples for your Prometheus OpenMetrics integration with New Relic in Docker and Kubernetes environments.
freshnessValidatedDate: never
translationType: machine
---

特に明記されていない限り、Prometheus OpenMetrics インテグレーションとNew Relicの設定オプションは、 docker環境とKubernetes環境の両方に適用されます。 少なくとも、次の設定値は<DNT>**required**</DNT>です。

* <InlinePopover type="licenseKey" />
* [クラスター名](#definitions-configuration-file)

推奨事項: New Relicライセンスキーを `LICENSE_KEY` という名前の環境変数として構成します。 これにより、New Relic は[相互 TLS 認証シークレット](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints)から環境変数を読み込むことができるため、より安全な環境が提供されます。

## nri-prometheus-latest.yamlの設定 [#general-config]

`nri-prometheus-latest.yaml`マニフェストファイルには、設定例を示す`nri-prometheus-cfg`マップが含まれています。マニフェストファイルを使用して、次のパラメータを設定します。

<CollapserGroup>
  <Collapser id="example-configuration-file" title="設定ファイルの例">
    以下は構成ファイルの例で、保存して必要に応じて変更することができます。詳細については、 [相互TLS認証](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) および [PromQLからNRQLへの変換](/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql) に関するドキュメントを参照してください。

    ```yml
    # The name of your cluster. It's important to match other New Relic products to relate the data.
    cluster_name: "YOUR_CLUSTER_NAME"

    # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true
    # standalone: true

    # How often the integration should run. Defaults to 30s.
    # scrape_duration: "30s"

    # The HTTP client timeout when fetching data from targets. Defaults to 5s.
    # scrape_timeout: "5s"

    # How old must the entries used for calculating the counters delta be
    # before the telemetry emitter expires them. Defaults to 5m.
    # telemetry_emitter_delta_expiration_age: "5m"

    # How often must the telemetry emitter check for expired delta entries.
    # Defaults to 5m.
    # telemetry_emitter_delta_expiration_check_interval: "5m"

    # Wether the integration should run in verbose mode or not. Defaults to false.
    verbose: false

    # Whether the integration should run in audit mode or not. Defaults to false.
    # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent.
    # It does not include verbose mode. This can lead to a high log volume, use with care.
    audit: false

    # Wether the integration should skip TLS verification or not. Defaults to false.
    insecure_skip_verify: false

    # The label used to identify scrapable targets. Defaults to "prometheus.io/scrape".
    scrape_enabled_label: "prometheus.io/scrape"

    # scrape_services Allows to enable scraping the service and not the endpoints behind.
    # When endpoints are scraped this is no longer needed
    scrape_services: true

    # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does.
    # Please notice that depending on the number of endpoints behind a service the load can increase considerably
    scrape_endpoints: false

    # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true.
    require_scrape_enabled_label_for_nodes: true

    # Number of worker threads used for scraping targets.
    # For large clusters with many (>400) targets, slowly increase until scrape
    # time falls between the desired `scrape_duration`.
    # Increasing this value too much will result in huge memory consumption if too
    # many metrics are being scraped.
    # Default: 4
    # worker_threads: 4

    # Maximum number of metrics to keep in memory until a report is triggered.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # max_stored_metrics: 10000

    # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # min_emitter_harvest_period: 200ms

    # targets:
    #   - description: Secure etcd example
    #     urls: ["https://192.168.3.1:2379", "https://192.168.3.2:2379", "https://192.168.3.3:2379"]
    #     tls_config:
    #       ca_file_path: "/etc/etcd/etcd-client-ca.crt"
    #       cert_file_path: "/etc/etcd/etcd-client.crt"
    #       key_file_path: "/etc/etcd/etcd-client.key"

    # Proxy to be used by the emitters when submitting metrics. It should be
    # in the format [scheme]://[domain]:[port].
    # The emitter is the component in charge of sending the scraped metrics.
    # This proxy won't be used when scraping metrics from the targets.
    # By default it's empty, meaning that no proxy will be used.
    # emitter_proxy: "http://localhost:8888"

    # Certificate to add to the root CA that the emitter will use when
    # verifying server certificates.
    # If left empty, TLS uses the host's root CA set.
    # emitter_ca_file: "/path/to/cert/server.pem"

    # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account
    # having limited privileges. Defaults to false.
    # disable_autodiscovery: false

    # Whether the emitter should skip TLS verification when submitting data.
    # Defaults to false.
    # emitter_insecure_skip_verify: false

    # Histogram support is based on New Relic's guidelines for higher
    # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md.
    # To better support visualization of this data, percentiles are calculated
    # based on the histogram metrics and sent to New Relic.
    # By default, the following percentiles are calculated: 50, 95 and 99.
    #
    # percentiles:
    #   - 50
    #   - 95
    #   - 99

    # transformations:
    #   - description: "General processing rules"
    #     rename_attributes:
    #       - metric_prefix: ""
    #         attributes:
    #           container_name: "containerName"
    #           pod_name: "podName"
    #           namespace: "namespaceName"
    #           node: "nodeName"
    #           container: "containerName"
    #           pod: "podName"
    #           deployment: "deploymentName"
    #     ignore_metrics:
    #       # Ignore all the metrics except the ones listed below.
    #       # This is a list that complements the data retrieved by the New
    #       # Relic Kubernetes Integration, that's why Pods and containers are
    #       # not included, because they are already collected by the
    #       # Kubernetes Integration.
    #       - except:
    #         - kube_hpa_
    #         - kube_daemonset_
    #         - kube_statefulset_
    #         - kube_endpoint_
    #         - kube_service_
    #         - kube_limitrange
    #         - kube_node_
    #         - kube_poddisruptionbudget_
    #         - kube_resourcequota
    #         - nr_stats
    #     copy_attributes:
    #       # Copy all the labels from the time series with metric name
    #       # `kube_hpa_labels` into every time series with a metric name that
    #       # starts with `kube_hpa_` only if they share the same `namespace`
    #       # and `hpa` labels.
    #       - from_metric: "kube_hpa_labels"
    #         to_metrics: "kube_hpa_"
    #         match_by:
    #           - namespace
    #           - hpa
    #       - from_metric: "kube_daemonset_labels"
    #         to_metrics: "kube_daemonset_"
    #         match_by:
    #           - namespace
    #           - daemonset
    #       - from_metric: "kube_statefulset_labels"
    #         to_metrics: "kube_statefulset_"
    #         match_by:
    #           - namespace
    #           - statefulset
    #       - from_metric: "kube_endpoint_labels"
    #         to_metrics: "kube_endpoint_"
    #         match_by:
    #           - namespace
    #           - endpoint
    #       - from_metric: "kube_service_labels"
    #         to_metrics: "kube_service_"
    #         match_by:
    #           - namespace
    #           - service
    #       - from_metric: "kube_node_labels"
    #         to_metrics: "kube_node_"
    #         match_by:
    #           - namespace
    #           - node
    # integration definition files required to map metrics to entities
    # definition_files_path: /etc/newrelic-infra/definition-files
    ```
  </Collapser>

  <Collapser id="definitions-configuration-file" title="主な名称と定義">
    ここでは、Prometheus OpenMetricsの設定ファイルの主要な名称と定義を紹介します。

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px" }}>
            キー名
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr id="cluster-name">
          <td>
            `cluster_name`

            <DNT>
              **Required.**
            </DNT>
          </td>

          <td>
            クラスターの名前。この値は、すべてのメトリックの`clusterName`属性として含まれます。
          </td>
        </tr>

        <tr id="verbose">
          <td>
            `verbose`
          </td>

          <td>
            文字列化されたブーリアンです。

            * `true` （デフォルト）：デバッグ情報をログに記録します。
            * `false`：エラーメッセージのみをログに記録します。
          </td>
        </tr>

        <tr id="targets">
          <td>
            `targets`
          </td>

          <td>
            インテグレーションによってスクレイピングされる静的エンドポイントの設定。オブジェクトのリストを含んでいます。この構造についての詳細は、 [target configuration](#target-config) に関するドキュメントを参照してください。
          </td>
        </tr>

        <tr id="scrape-enabled-label">
          <td>
            `scrape_enabled_label`

            <img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

            <DNT>**Kubernetes**</DNT>
          </td>

          <td>
            文字列です。統合は、Kubernetesポッドとサービスがアノテーションされているか、この値のラベルを持っているかどうかをチェックして、スクレイピングする必要があるかどうかを判断します。

            これは、メトリクスを無視したり、New Relic に送信される特定のメトリクスを含めたりして、データ量を制限したい場合に特に有効です。デフォルトでは、Prometheusがスクレイピング可能なターゲットを発見するために使用するのと同じラベルを使用しているので、インストールしたほとんどのエクスポーターは自動的にこのラベルを設定します。

            統合でスクレイプするターゲットをきめ細かく制御するには、このオプションを他の値（ `newrelic/scrape`など）に設定してから、アノテーションまたはラベル`newrelic/scrape: "true"`をKubernetesオブジェクトに追加します。両方が設定されている場合、注釈はラベルよりも優先されます。

            デフォルト： `"prometheus.io/scrape"`
          </td>
        </tr>

        <tr id="scrape-duration">
          <td>
            `scrape_duration`
          </td>

          <td>
            スクレーパーはどのくらいの頻度で稼働させればいいのでしょうか。

            * メモリ使用量を少なくするには、この値を大きくします。

            * メモリ使用量を増やすには、この値を減らします。

              メモリ使用量への影響は、すべてのデータを一度に照会（およびバッファリング）しないように、ターゲットのフェッチをスクレイプ間隔に分散させているためです。

              デフォルトは`30s`です。有効な値には、 `1s` 、 `15s` 、 `30s` 、 `1m` 、 `5m`などがあります。
          </td>
        </tr>

        <tr id="scrape-timeout">
          <td>
            `scrape_timeout`
          </td>

          <td>
            エンドポイントからデータを取得する際のHTTPクライアントのタイムアウトです。

            デフォルト： `5s` 。有効な値には、 `1s` 、 `15s` 、 `30s` 、 `1m` 、 `5m`などがあります。
          </td>
        </tr>

        <tr>
          <td>
            `worker_threads`
          </td>

          <td>
            ターゲットのスクレイピングに使用されるワーカースレッドの数。ターゲットの数が多い環境やレイテンシーの高いターゲットでは増やすことができますが、メモリ消費量が増える可能性があります。

            デフォルト： `4` 。 10を超える使用はお勧めしません。
          </td>
        </tr>

        <tr>
          <td>
            `require_scrape_enabled_label_for_nodes`

            <img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

            <DNT>**Kubernetes**</DNT>
          </td>

          <td>
            Kubernetesノードがスクレイピングにラベルを必要とするかどうか。

            デフォルト： `true` 。
          </td>
        </tr>

        <tr id="percentiles">
          <td>
            `percentiles`
          </td>

          <td>
            ヒストグラムのサポートは、 [New Relic&apos;s guidelines for higher level metrics abstractions](https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md) に基づいています。

            このデータの視覚化をより適切にサポートするために、パーセンタイルはヒストグラムメトリックに基づいて計算され、NewRelicに送信されます。有効な値には、 `50` 、 `95` 、および`99`が含まれます。
          </td>
        </tr>

        <tr>
          <td id="emitter-proxy">
            `emitter_proxy`
          </td>

          <td>
            メトリクスを送信する際に統合が使用するプロキシ。

            `[scheme]://[domain]:[port]`

            このプロキシは、ターゲットからメトリクスを取得する際には使用されません。

            デフォルトでは、これは空で、プロキシは使用されません。
          </td>
        </tr>

        <tr>
          <td id="emitter-ca-file">
            `emitter_ca_file`
          </td>

          <td>
            エミッタがサーバ証明書を検証する際に使用するルートCAに追加する証明書。空の場合、TLSはホストのルートCAセットを使用する。
          </td>
        </tr>

        <tr id="emitter-insecure-skip-verify">
          <td>
            `emitter_insecure_skip_verify`
          </td>

          <td>
            データを送信するときにエミッターがTLS検証をスキップする必要があるかどうか。デフォルト： `false` 。
          </td>
        </tr>

        <tr id="disable-autodiscovery">
          <td>
            `disable_autodiscovery`
          </td>

          <td>
            k8sクラスターで自動検出を無効にするには、trueに設定します。権限が制限されているサービスアカウントでポッドを実行する場合に便利です。デフォルト： `false` 。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## ターゲットキーにオブジェクトを設定 [#target-config]

設定ファイルのターゲットキーに1つ以上のオブジェクトを含める場合は、YAMLリストに以下の構造を使用します。

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        キー名
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr id="description">
      <td>
        `description`
      </td>

      <td>
        このターゲット内のURLの説明です。
      </td>
    </tr>

    <tr id="urls">
      <td>
        `urls`
      </td>

      <td>
        スクレイピングされるURLを含む文字列のリスト。
      </td>
    </tr>

    <tr id="tls-config">
      <td>
        `tls_config`
      </td>

      <td>
        リクエストを送信する際に使用する認証設定です。TLSとMutual TLSに対応しています。詳細は、 [相互TLS認証に関するドキュメント](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) を参照してください。
      </td>
    </tr>
  </tbody>
</table>

<CollapserGroup>
  <Collapser
    id="specify-path-port"
    title={<><img src="/images/os_icon_k8.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ width: '30px', height: '25px' }} /></>
    }
  >
    NewRelicのPrometheusOpenMetrics統合は、スクレイプするターゲットを自動的に検出します。ターゲットを構築するときに使用するポートとエンドポイントパスを指定するには、Kubernetesポッドとサービスで`prometheus.io/port`と`prometheus.io/path`のアノテーションまたはラベルを使用できます。注釈はラベルよりも優先されます。

    * `prometheus.io/port`が存在しない場合、統合はサービスに対して定義された各`port`または`ContainerPort`をスクレイプしようとします。
    * `prometheus.io/path`が存在しない場合、統合はデフォルトで`/metrics`になります。
    * サービスがデフォルトの`/my-metrics-path`パスで実行されていない場合は、ポッド`prometheus.io/path=my-metrics-path`にラベルを追加します。メトリックエンドポイントへのパスがより複雑で、有効なラベル値（たとえば、 `foo/bar` ）にできない場合は、代わりにアノテーションを使用してください。
  </Collapser>

  <Collapser
    id="example-port-path"
    title={<><img src="/images/os_icon_k8.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ width: '30px', height: '25px' }} /></>
    }
  >
    この例では、クラスターにデプロイがあり、ポッドはポート`8080`とパスでPrometheusメトリックを公開します `my-metrics.`

    デプロイメントマニフェストの`PodSpec`メタデータで、ラベル`prometheus.io/port: "8080"`と`prometheus.io/path: "my-metrics"`を設定します。統合がポッドからメトリックを取得しようとすると、 `http://<pod-ip>:8080/my-metrics`にリクエストが送信されます。

    ```yml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-deployment
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: my-app
      template:
        metadata:
          labels:
            app: my-app
            prometheus.io/scrape: "true"
            prometheus.io/port: "8080"
            prometheus.io/path: "my-metrics"
    ```
  </Collapser>
</CollapserGroup>

## サービスとエンドポイントのスクレイプ動作

デフォルトでは、 `scrape_services`は`true`に設定され、 `scrape_endpoints`は`false`に設定されているため、サービスは基になるエンドポイントではなく直接スクレイピングされます。

この動作を変更するには、 `scrape_endpoints`を`true`に設定し、直接サービスではなく、Prometheusサーバーがネイティブに行うように、基になるエンドポイントをスクレイプするように`Prometheus OpenMetrics integrations`を構成します。

クラスタ内のサービスの背後にあるエンドポイントの数に応じて、負荷と取り込まれるデータが大幅に増加する可能性があることに留意し、監視し、必要に応じてリソース要件を増加させてください。

さらに、下位互換性を確保するために`scrape_services`と`scrape_endpoints`の両方をtrueに設定できる場合でも、データが重複する可能性があります。

## 設定の再読み込み [#reload-config]

Prometheus OpenMetrics インテグレーション<DNT>**does not**</DNT>は、設定ファイルに変更を加えると、設定を自動的に再読み込みします。

<img style={{ width: '30px', height: '25px'}} class="inline" title="Docker icon" alt="Docker icon" src="/images/os_icon_docker.webp" />

<DNT>**Docker**</DNT>

設定を再読み込みするには、統合を実行しているコンテナを再起動します。

```sh
docker restart nri-prometheus
```

<img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

<DNT>**Kubernetes**</DNT>

設定を再読み込みするには、インテグレーションを再起動してください。 推奨事項: デプロイメントをレプリカ 0 個までスケールダウンし、その後レプリカ 1 個までスケールバックします。

```sh
kubectl scale deployment nri-prometheus --replicas=0
kubectl scale deployment nri-prometheus --replicas=1
```

## Dockerです。以前の設定ファイルの実行 [#run-previous]

<img style={{ width: '30px', height: '25px'}} class="inline" title="Docker icon" alt="Docker icon" src="/images/os_icon_docker.webp" />

<DNT>**Docker:**</DNT>以前の設定ファイルを使用してインテグレーションを実行するには:

1. コンテンツをコピーして、 `config.yaml`ファイルに保存します。

2. 同じディレクトリ内で、コマンドを実行します。

   ```sh
   docker run -d --restart unless-stopped \
       --name nri-prometheus \
       -e CLUSTER_NAME="YOUR_CLUSTER_NAME" \
       -e LICENSE_KEY="YOUR_LICENSE_KEY" \
       -v "$(pwd)/config.yaml:/config.yaml" \
       newrelic/nri-prometheus:latest --configfile=/config.yaml
   ```