---
title: 疎なデータ、欠落した測定基準、データギャップ
type: troubleshooting
tags:
  - Integrations
  - Prometheus integrations
  - Troubleshooting
metaDescription: Troubleshooting tips for the Prometheus OpenMetrics integration for Docker or Kubernetes if no data appears in New Relic's UI.
translationType: machine
---

## 問題

[Prometheus OpenMetrics integration](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration) for Docker or Kubernetes をインストールしましたが、New Relic の UI でデータがまばらであったり、メトリクスが欠けていたり、データにギャップがあることに気づきました。

## 解決

一部のメトリクスが定期的に収集されていない場合は、次のようにしてください。

1. CPUがスロットルされていないか、コンテナに割り当てられているメモリが十分かどうかを確認します。

   コンテナに十分なリソースが用意されていない場合、サンプルの間隔を長くしてデータを送信することがあります。メモリの上限が低いと、統合が強制終了して再起動されることがあります。リソースの適切な制限と要求は、監視するターゲットの数や、各ターゲットが公開するメトリクスの数によって異なる場合があります。詳細については、大規模環境の構成に関するドキュメント（ ）の [ガイドラインを参照してください。](/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations)

   [](/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations)

2. [* インテグレーションのログに以下のエラーメッセージが表示されていないか確認してください。

     ```json
     {"err":"unexpected post response code: 413: Request Entity Too Large"}
     ```

     この問題は、一部のペイロードがドロップされる原因となります。現在、新しいリリースでは修正されています。この問題が発生した場合は、イメージを最新のものに更新してください。* 統合によって監視されている一部の `/metrics` エンドポイントがタイムアウトになるか、応答に数秒かかる場合、データのスクレイピングが遅くなる可能性があります。複数のエンドポイントが応答するのに非常に長い時間がかかる場合、統合のパフォーマンスが低下する可能性があります。これにより、断続的なデータの欠落が発生します。

     それらのエンドポイントを検出するために、実行します。

     ```sql
     SELECT average(nr_stats_integration_fetch_target_duration_seconds) 
     FROM Metric where clusterName=’clustername' SINCE 30 MINUTES AGO FACET target LIMIT 30
     ```

     このクエリは、Prometheus OpenMetricsインテグレーションで公開されているデータを取得し、各エンドポイントの取得に要した時間を表示しています。

     待ち時間が `1s`を超えるエンドポイントを修正するか、監視から除外して Prometheus スクレイピング ラベルを削除してください。* これらのエンドポイントを削除することが現実的ではなく、回答の遅延が避けられない場合は、より多くのワーカーを並行して実行するように統合を設定します。これにより、インテグレーションは同時により多くのエンドポイントを取得することができます。

     これを行うには、統合を最新バージョンに更新し、新しい構成オプション `worker_threads`を適用します。4、6、8 から 16 まで、徐々に行うことをお勧めします。

     この回避策は問題を最小限に抑えるものであり、複数のエンドポイントが悪さをしている場合は、やはりパフォーマンスが低下します。また、ワーカーの数が増えるとメモリやCPUの消費量が増えるため、それに合わせてメモリやCPUを増やす必要があります。* 監視対象のすべてのエンドポイントのレイテンシーが低く、コンテナーが調整されていない場合は、次のクエリを実行します。これは、統合がすべてのターゲットを取得するのにかかる時間を確認し、構成された `scrape_duration`を超えている場合はデータを送信するのに役立ちます。

     ```sql
     SELECT latest(nr_stats_integration_process_duration_seconds) FROM Metric
     where clusterName=’clustername' SINCE 30 MINUTES AGO TIMESERIES
     ```

     まず、公開された最新のイメージに統合を更新します。次に、すべてのターゲットをスクレイピングするのに必要な時間を短縮するために、構成オプション `worker_threads`を使用してワーカーの数を増やします。 `r_stats_integration_process_duration_seconds` が定義された `scrape_duration`に近づくまで、4 から 6、8、そして 16 まで徐々に行うことをお勧めします。メモリ消費量と CPU 使用率が増加することに注意してください。](/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations)

[](/docs/integrations/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations)