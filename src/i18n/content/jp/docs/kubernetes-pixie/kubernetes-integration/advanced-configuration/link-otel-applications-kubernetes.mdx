---
title: OpenTelemetryをインストルメント化したアプリケーションをKubernetesにリンクする
tags:
  - Integrations
  - Kubernetes integration
  - OpenTelemetry
  - Link apps and services
metaDescription: Connect New Relic's Kubernetes monitoring with applications monitored with OpenTelemetry.
freshnessValidatedDate: never
translationType: machine
---

Kubernetesでアプリケーションを実行している開発者であれば、 New Relicを使用して、 KubernetesインフラストラクチャがOpenTelemetryインストゥルメントされたアプリケーションにどのように影響するかを理解できます。

以下の手順を完了すると、 New Relic UIを使用して、 OpenTelemetryのアプリケーション レベルのメトリックをKubernetesインフラストラクチャ メトリックと相関させることができます。 これにより、テレメトリデータの全体像を把握し、チーム間で連携して、 環境の問題の平均解決時間 (MTTR )Kubernetes を短縮できます。

## データの相関関係 [#correlate]

このドキュメントでは、アプリケーションがインフラストラクチャ固有のデータをテレメトリデータに挿入できるようにする手順について説明します。 その結果、New Relic UI に実用的な情報が表示されます。 開始するには、次の手順に従います。

* 各アプリケーションのコンテナで、テレメトリーデータをコレクターに送信するための環境変数を定義します。
* 関連するメタデータ (クラスタ、コンポーネント、ネームスペース名) を挿入するために、`resourcedetection`、`resource`、`batch`、および `k8sattributes` プロセッサを使用してOpenTelemetry Collector を `DaemonSet` イン[エージェント モード](https://opentelemetry.io/docs/collector/getting-started/#agent)としてデプロイします。

## あなたが始める前に [#prereqs]

以下の手順を正常に完了するには、OpenTelemetry と Kubernetes についてすでに理解しており、次の操作を実行しておく必要があります。

* 次の環境変数を作成しました:

  * `OTEL_EXPORTER_OTLP_ENDPOINT`詳細については、 [New Relic OTLP エンドポイント](/docs/opentelemetry/best-practices/opentelemetry-otlp/)を参照してください。
  * `NEW_RELIC_API_KEY`: 詳細については[、 New Relic APIキー](/docs/apis/intro-apis/new-relic-api-keys/)を参照してください。

* クラスタに[New Relic Kubernetesインテグレーション](/install/kubernetes)をインストールしました。

* アプリケーションが でインストゥルメントされ、[OpenTelemetry](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/) New RelicOpenTelemetryProtocol (OTLP) 経由で にデータを正常に送信しました。

New Relicでのコレクターの使用に関する一般的な質問がある場合は[、NewRelicでのOpenTelemetryコレクターの概要を](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-intro)参照してください。

## テレメトリ データを OpenTelemetry Collector に送信するようにアプリケーションを構成する [#instrument]

これを設定するには、Kubernetes YAML ファイルの`env`セクションにカスタム スニペットを追加する必要があります。 以下の例は、サンプルのフロントエンド マイクロサービス ( `Frontend.yaml` ) のスニペットを示しています。 スニペットには、次の操作を実行する 2 つのセクションが含まれています。

* <DNT>**Section 1:**</DNT> テレメトリーデータがコレクターに送信されていることを確認します。 これにより、環境変数`OTEL_EXPORTER_OTLP_ENDPOINT`がホスト IP で設定されます。 これは、下位 API を呼び出してホスト IP を取得することによって行われます。
* <DNT>**Section 2:**</DNT> インフラストラクチャ固有のメタデータを添付します。 これを行うには、下向き API を使用して`metadata.uid`をキャプチャし、それを`OTEL_RESOURCE_ATTRIBUTES`環境変数に追加します。 この環境変数は、 OpenTelemetryの `resourcedetection` および `k8sattributes` プロセッサによって、テレメトリーデータにインフラストラクチャ固有の追加のコンテキストを追加するために使用されます。

OpenTelemetryでマイクロサービス インストゥルメントされた各場合、以下の強調表示された行をマニフェストの `env` セクションに追加します。

```yaml
# Frontend.yaml
apiVersion: apps/v1
kind: Deployment

# ...
spec:
  containers:
    - name: yourfrontendservice
      image: yourfrontendservice-beta
  env:
    # Section 1: Ensure that telemetry data is sent to the collector
    - name: HOST_IP
      valueFrom:
        fieldRef:
          fieldPath: status.hostIP
    
    # This is picked up by the opentelemetry sdks
    - name: OTEL_EXPORTER_OTLP_ENDPOINT
      value: "http://$(HOST_IP):55680"
    
    # Section 2: Attach infrastructure-specific metadata
    # Get pod ip so that k8sattributes can tag resources
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    
    - name: POD_UID
      valueFrom:
        fieldRef:
          fieldPath: metadata.uid
    
    # This is picked up by the resource detector
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: "service.instance.id=$(POD_NAME),k8s.pod.uid=$(POD_UID)"
```

## OpenTelemetryコレクターをエージェントとして構成およびデプロイします [#agent]

Kubernetes クラスター内のすべてのノードに [コレクターをエージェントとして](https://opentelemetry.io/docs/collector/getting-started/#agent) デプロイすることをお勧めします。エージェントはテレメトリ データを受信し、メタデータを使用してテレメトリ データを強化できます。たとえば、コレクタは、プロセッサを通じてカスタム属性やインフラストラクチャ情報を追加したり、バッチ処理、再試行、圧縮、およびクライアント インストルメンテーション レベルではあまり効率的に処理されない追加の高度な機能を処理したりできます。

コレクターの構成については、以下のサンプル コレクター構成ファイルと、これらのオプションの設定に関するセクションを参照してください。

* [OTLPエクスポーター](#otlp-exporter)
* [バッチプロセッサ](#batch)
* [リソース検出プロセッサ](#resource-detection)
* [k8sattributesプロセッサ：一般](#attributes-general)
* [k8sattributesプロセッサ：RBAC](#rbac)
* [k8sattributesプロセッサ：フィルタ](#discovery-filter)

```yaml
receivers:
  otlp:
    protocols:
      grpc:

processors:
  batch:
  resource:
    attributes:
      - key: host.id
        from_attribute: host.name
        action: upsert
  resourcedetection:
    detectors: [gke, gce]
  k8sattributes:
    auth_type: "serviceAccount"
    passthrough: false
    filter:
      node_from_env_var: KUBE_NODE_NAME
    extract:
      metadata:
        - k8s.pod.name
        - k8s.pod.uid
        - k8s.deployment.name
        - k8s.cluster.name
        - k8s.namespace.name
        - k8s.node.name
        - k8s.pod.start_time
    pod_association:
      - from: resource_attribute
        name: k8s.pod.uid

exporters:
  otlp:
    endpoint: $OTEL_EXPORTER_OTLP_ENDPOINT
    headers:
      api-key: $NEW_RELIC_API_KEY
  logging:
    logLevel: DEBUG

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [resourcedetection, k8sattributes, resource, cumulativetodelta, batch]
      exporters: [otlp]
    traces:
      receivers: [otlp]
      processors: [resourcedetection, k8sattributes, resource, batch]
      exporters: [otlp]
    logs:
      receivers: [otlp]
      processors: [resourcedetection, k8sattributes, resource, batch]
      exporters: [otlp]
```

OpenTelemetryをエージェントとして構成してデプロイするには、次の手順に従います。

<Steps>
  <Step>
    ### OTLPエクスポーターを構成する [#otlp-exporter]

    まず、 [OpenTelemetryコレクター設定YAMLファイル](https://opentelemetry.io/docs/collector/configuration/)に、 New Relic <InlinePopover type="licenseKey"/>をヘッダーとして含めたOTLPエクスポーターを追加します。

    ```yaml
    exporters:
    otlp:
        endpoint: $OTEL_EXPORTER_OTLP_ENDPOINT
        headers: api-key: $NEW_RELIC_API_KEY
    ```
  </Step>

  <Step>
    ### バッチプロセッサを構成する [#batch]

    バッチ プロセッサは、スパン、メトリック、またはログを受け入れ、それらをバッチに配置します。 これにより、データの圧縮が容易になり、コレクターからの送信要求が削減されます。

    ```yaml
    processors:
    batch:
    ```
  </Step>

  <Step>
    ### リソース検出プロセッサを構成する [#resource-detection]

    `resourcedetection`プロセッサは、ホスト固有の情報を取得して、コレクタを介して処理されているテレメトリデータにコンテキストを追加します。この例では、Google Kubernetes Engine（GKE）とGoogle Compute Engine（GCE）を使用して、次のようなGoogleCloud固有のメタデータを取得します。

    * `cloud.provider` （「GCP」）

    * `cloud.platform` （「 `gcp_compute_engine` 」）

    * `cloud.account.id`

    * `cloud.region`

    * `cloud.availability_zone`

    * `host.id`

    * `host.image.id`

    * `host.type`

      ```yaml
      processors:
      resourcedetection:
          detectors: [gke, gce]
      ```
  </Step>

  <Step>
    ### Kubernetes 属性プロセッサを構成する (一般) [#attributes-general]

    エージェントとして実行される OpenTelemetry Collector の一部として `k8sattributes` プロセッサを実行すると、テレメトリ データを OpenTelemetry Collector エージェントに送信するポッドの IP アドレスが検出され、ポッドのメタデータの抽出に使用されます。以下は、プロセッサ セクションのみを含む基本的な Kubernetes マニフェストの例です。OpenTelemetry Collector を `DaemonSet`としてデプロイするには、この [包括的なマニフェストの例](https://github.com/newrelic-forks/microservices-demo/tree/main/src/otel-collector-agent)をお読みください。

    ```yaml
    processors:
    k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
        node_from_env_var: KUBE_NODE_NAME
        extract:
        metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.cluster.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
        pod_association:
        - from: resource_attribute
            name: k8s.pod.uid
    ```
  </Step>

  <Step>
    ### Kubernetes 属性プロセッサ (RBAC) を構成する [#rbac]

    ロールベースアクセス制御 (RBAC) の設定を追加する必要があります。 `k8sattributes`プロセッサには、構成されたフィルターに含まれるポッドおよびネームスペース リソースに対する`get` 、 `watch` 、および`list`権限が必要です。 この[例では](https://github.com/newrelic-forks/microservices-demo/blob/main/otel-kubernetes-manifests/otel-collector-agent.yaml#L43-L69)、 `ClusterRole`のロールベース アクセス制御 (RBAC) を構成して、 `ServiceAccount`にクラスタ内のすべてのポッドとネームスペースに対する必要な権限を付与する方法を示します。
  </Step>

  <Step>
    ### Kubernetes 属性プロセッサ (検出フィルター) を構成する [#discovery-filter]

    コレクターをエージェントとして実行する場合は、プロセッサが実行中のホストと同じホストからのポッドのみを検出するように、検出フィルターを適用する必要があります。 フィルターを使用しない場合、特に大規模なクラスターでは、リソースの使用量が不必要に高くなる可能性があります。 フィルターが適用されると、各プロセッサは自身のノードで実行されているポッドのみをKubernetes API照会します。

    フィルターを設定するには、下向きAPIを使用して、 OpenTelemetryコレクター エージェント設定 YAML ファイルの pod `env` セクションにノード名を環境変数として挿入します。 例を見るには、 [GitHub を](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/examples/kubernetes/otel-collector-config.yml)ご覧ください。 これにより、OpenTelemetry コレクター エージェントのコンテナーに新しい環境変数が挿入されます。 値は、ポッドの実行がスケジュールされたノードの名前になります。

    ```yaml
    spec:
    containers:
        - env:
            - name: KUBE_NODE_NAME
            valueFrom:
                fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
    ```

    次に、 `k8sattributes`のノードでフィルタリングできます。

    ```yaml
    k8sattributes:
    filter:
        node_from_env_var: KUBE_NODE_NAME
    ```
  </Step>
</Steps>

## 構成が機能していることを確認します [#validate]

OpenTelemetryデータとKubernetesデータが正常にリンクされると、設定が機能していることを確認できるようになります。

1. <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > APM & Services**</DNT>に移動し、 <DNT>**Services - OpenTelemetry**</DNT>内のアプリケーションを選択します。
2. **Monitor** \[モニター]セクションで、 **Service map** \[サービス マップ]をクリックします。
3. OpenTelemetry サービスとクラスター間の接続を確認します。 右側には、 `k8s.cluster.name` 、 `k8s.namespace.name` 、 `k8s.deployment.name`などの Kubernetes 属性がタグとして表示されます。

<img
  src="/images/kubernetes_screenshot-crop_otel-validation.webp"
  title="Screenshot showing K8s metadata in the New Relic UI"
  alt="Screenshot showing K8s metadata in the New Relic UI"
/>

## 次のステップを選択 [#next]

<DocTiles>
  <DocTile
    title="See our best practices guide"
    path="/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-concepts"
  >
    OpenTelemetry と New Relic の使用を改善する方法を学びます。
  </DocTile>

  <DocTile
    title="Check out this blog post"
    path="https://newrelic.com/blog/how-to-relic/k8s-with-otel"
  >
    OpenTelemetry 、メトリクス、ログをKubernetesパフォーマンスデータと相関させる
  </DocTile>
</DocTiles>
