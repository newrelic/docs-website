---
title: OpenTelemetryをインストルメント化したアプリケーションをKubernetesにリンクする
tags:
  - Integrations
  - Kubernetes integration
  - OpenTelemetry
  - Link apps and services
metaDescription: Connect New Relic's Kubernetes monitoring with applications monitored with OpenTelemetry.
translationType: machine
---

import kubernetesOtelValidation from 'images/kubernetes_screenshot-crop_otel-validation.png'

Kubernetesでアプリを実行している開発者の場合は、New Relicを使用して、KubernetesインフラストラクチャがOpenTelemetryが計測されたアプリケーションにどのように影響するかを理解できます。

以下の手順を完了すると、New Relic UIを使用して、OpenTelemetryのアプリケーションレベルの指標をKubernetesインフラストラクチャの指標と関連付けることができます。これにより、テレメトリデータの全体像を確認し、チーム間で作業して、Kubernetes環境の問題の平均解決時間（MTTR）を短縮できます。

## 概要：データをどのように関連付けるか [#correlate]

このガイドの手順により、アプリケーションはインフラストラクチャ固有のメタデータをテレメトリデータに挿入できます。その結果、NewRelicUIに実用的な情報が入力されます。これを実行するために実行する手順は次のとおりです。

* 各アプリケーションコンテナで、テレメトリデータをコレクタに送信するための環境変数を定義します
* OpenTelemetryコレクターを[エージェントモード](https://opentelemetry.io/docs/collector/getting-started/#agent)で`DaemonSet`としてデプロイし、 `resourcedetection` 、 `resource` 、 `batch` 、および`k8sattributes`プロセッサーを使用して、関連するメタデータ（クラスター、デプロイメント、および名前空間の名前）を挿入します。

## 前提条件 [#prereqs]

以下の手順を成功させるには、OpenTelemetryとKubernetesに精通しており、次のことを行っている必要があります。

* 次の環境変数を作成しました。

  * `OTEL_EXPORTER_OTLP_ENDPOINT` （ [お住まいの地域または目的に合わせたNew Relicエンドポイント](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/#review-settings)）
  * `NEW_RELIC_API_KEY` （[ライセンスキーを取り込む](/docs/apis/intro-apis/new-relic-api-keys/#overview-keys)）

* クラスターに[NewRelicKubernetes統合](/docs/kubernetes-pixie/kubernetes-integration/installation/kubernetes-integration-install-configure)をインストールしました

* [OpenTelemetry](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/)を使用してアプリケーションをインストルメント化し、OpenTelemetry Protocol（OTLP）を介してNewRelicにデータを正常に送信しました

New Relicでのコレクターの使用に関する一般的な質問がある場合は[、NewRelicでのOpenTelemetryコレクターの概要を](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-intro)参照してください。

## テレメトリデータをOpenTelemetryコレクターに送信するようにアプリケーションを構成します [#instrument]

これを設定するには、KubernetesYAMLファイルの`env`スタンザにカスタムスニペットを追加する必要があります。以下に、サンプルのフロントエンドマイクロサービス（ `Frontend.yaml` ）のスニペットを示す例を示します。スニペットには、次の2つのセクションが含まれています。

* **セクション1：**テレメトリデータがコレクターに送信されていることを確認します。これにより、環境変数`OTEL_EXPORTER_OTLP_ENDPOINT`にホストIPが設定されます。これは、ダウンワードAPIを呼び出してホストIPをプルすることによって行われます。
* **セクション2：**インフラストラクチャ固有のメタデータを添付します。これを行うには、下位APIを使用して`metadata.uid`をキャプチャし、それをOTEL_RESOURCE_ATTRIBUTES環境変数に追加します。この環境変数は、OpenTelemetryコレクターの`resourcedetection`および`k8sattributes`プロセッサーによって使用され、テレメトリデータにインフラストラクチャ固有のコンテキストを追加します。

OpenTelemetryを備えたマイクロサービスごとに、以下の強調表示された行をマニフェストの`env`スタンザに追加します。

```yaml
# Frontend.yaml
apiVersion: apps/v1
kind: Deployment
...
spec:
  containers:
  - name: yourfrontendservice
    image: yourfrontendservice-beta
  env:
  # Section 1: Ensure that telemetry data is sent to the collector
  - name: HOST_IP
        valueFrom:
          fieldRef:
            fieldPath: status.hostIP
      # This is picked up by the opentelemetry sdks
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: "http://$(HOST_IP):55680"
  # Section 2: Attach infrastructure-specific metadata
     # Get pod ip so that k8sattributes can tag resources
- name: POD_NAME
valueFrom:
fieldRef:
fieldPath: metadata.name
- name: POD_UID
valueFrom:
fieldRef:
fieldPath: metadata.uid
      # This is picked up by the resource detector
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: service.instance.id=$(POD_NAME),k8s.pod.uid=$(POD_UID)”
```

## OpenTelemetryコレクターをエージェントとして構成およびデプロイします [#agent]

[コレクターをエージェントとして](https://opentelemetry.io/docs/collector/getting-started/#agent)Kubernetesクラスター内のすべてのノードにデプロイすることをお勧めします。エージェントは、テレメトリデータを受信できるだけでなく、メタデータでテレメトリデータを強化できます。たとえば、コレクターは、プロセッサーを介してカスタム属性またはインフラストラクチャ情報を追加したり、バッチ処理、再試行、圧縮、およびクライアントインストルメンテーションレベルであまり効率的に処理されないその他のより高度な機能を処理したりできます。

コレクターの構成については、以下のサンプルコレクター構成ファイルと、これらのオプションの設定に関するセクションを参照してください。

* [OTLPエクスポーター](#otlp-exporter)
* [バッチプロセッサ](#batch)
* [リソース検出プロセッサ](#resource-detection)
* [k8sattributesプロセッサ：一般](#attributes-general)
* [k8sattributesプロセッサ：RBAC](#rbac)
* [k8sattributesプロセッサ：フィルタ](#discovery-filter)

```yaml
receivers:
  otlp:
    protocols:
      grpc:

processors:
  batch:
  resource:
    attributes:
      - key: host.id
        from_attribute: host.name
        action: upsert
  resourcedetection:
    detectors: [ gke, gce ]
  k8sattributes:
    auth_type: "serviceAccount"
    passthrough: false
    filter:
      node_from_env_var: KUBE_NODE_NAME
    extract:
      metadata:
        - k8s.pod.name
        - k8s.pod.uid
        - k8s.deployment.name
        - k8s.cluster.name
        - k8s.namespace.name
        - k8s.node.name
        - k8s.pod.start_time
    pod_association:
      - from: resource_attribute
        name: k8s.pod.uid

exporters:
  otlp:
    endpoint: $OTEL_EXPORTER_OTLP_ENDPOINT
    headers:
      api-key: $NEW_RELIC_API_KEY
  logging:
    logLevel: DEBUG

service:
  pipelines:
    metrics:
      receivers: [ otlp ]
      processors: [ resourcedetection, k8sattributes, resource, cumulativetodelta, batch ]
      exporters: [ otlp ]
    traces:
      receivers: [ otlp ]
      processors: [ resourcedetection, k8sattributes, resource, batch ]
      exporters: [ otlp ]
    logs:
      receivers: [ otlp ]
      processors: [ resourcedetection, k8sattributes, resource, batch ]
      exporters: [ otlp ]
```

### ステップ1：OTLPエクスポーターを構成する [#otlp-exporter]

まず、OTLPエクスポーターを[OpenTelemetryコレクター構成のYAMLファイル](https://opentelemetry.io/docs/collector/configuration/)に追加し、ヘッダーとしてNew Relic APIキー（取り込みライセンスキー）を追加して構成します。

```yaml
exporters:
  otlp:
    endpoint: $OTEL_EXPORTER_OTLP_ENDPOINT
  headers: api-key: $NEW_RELIC_API_KEY
```

### ステップ2：バッチプロセッサを構成する [#batch]

バッチプロセッサは、スパン、メトリック、またはログを受け入れ、それらをバッチに配置して、データの圧縮を容易にし、コレクタからの送信要求の数を減らします。

```
processors:
  batch:
```

### 手順3：リソース検出プロセッサを構成する [#resource-detection]

`resourcedetection`プロセッサは、ホスト固有の情報を取得して、コレクタを介して処理されているテレメトリデータにコンテキストを追加します。この例では、Google Kubernetes Engine（GKE）とGoogle Compute Engine（GCE）を使用して、次のようなGoogleCloud固有のメタデータを取得します。

* cloud.provider（ "gcp"）
* cloud.platform（ "gcp_compute_engine"）
* cloud.account.id
* cloud.region
* cloud.availability_zone
* host.id
* host.image.id
* host.type

```yaml
processors:
  resourcedetection:
Detectors: [ gke, gce ]
```

### 手順4：Kubernetes属性プロセッサを設定する（一般） [#attributes-general]

エージェントとして実行されているOpenTelemetryコレクターの一部として`k8sattributes`プロセッサーを実行すると、テレメトリデータをOpenTelemetryコレクターエージェントに送信しているポッドのIPアドレスを検出し、それらを使用してポッドメタデータを抽出します。以下は、プロセッサセクションのみを使用した基本的なKubernetesマニフェストの例です。 OpenTelemetryコレクターを`DaemonSet`としてデプロイするには、この [包括的なマニフェストの例](https://github.com/newrelic-forks/microservices-demo/tree/main/src/otel-collector-agent)をお読みください。

```yaml
processors:
  k8sattributes:
    auth_type: "serviceAccount"
    passthrough: false
    filter:
      node_from_env_var: KUBE_NODE_NAME
    extract:
      metadata:
        - k8s.pod.name
        - k8s.pod.uid
        - k8s.deployment.name
        - k8s.cluster.name
        - k8s.namespace.name
        - k8s.node.name
        - k8s.pod.start_time
    pod_association:
      - from: resource_attribute
        name: k8s.pod.uid
```

### 手順5：Kubernetes属性プロセッサ（RBAC）を設定する [#rbac]

ロールベースのアクセス制御（RBAC）の構成を追加する必要があります。 `k8sattributes`プロセッサには、構成されたフィルターに含まれるポッドと名前空間リソースに対する`get` 、 `watch` 、および`list`のアクセス許可が必要です。クラスター内のすべてのポッドと名前空間に必要なアクセス許可を`ServiceAccount`に与えるために、 `ClusterRole`の役割ベースのアクセス制御（RBAC）を構成する方法のこの[例](https://github.com/newrelic-forks/microservices-demo/blob/main/otel-kubernetes-manifests/otel-collector-agent.yaml#L43-L69)を参照してください。

### 手順6：Kubernetes属性プロセッサを設定する（検出フィルタ） [#discovery-filter]

コレクターをエージェントとして実行する場合は、プロセッサーが実行しているのと同じホストからのみポッドを検出するように、検出フィルターを適用する必要があります。フィルタを使用しない場合、特に非常に大規模なクラスタでは、リソースの使用量が不必要に高くなる可能性があります。フィルタが適用されると、各プロセッサは、独自のノードで実行されているポッドについてのみKubernetesAPIにクエリを実行します。

フィルタを設定するには、下向きAPIを使用して、OpenTelemetryコレクターエージェント構成YAMLファイルのポッド`env`セクションに環境変数としてノード名を挿入します（例については、 [GitHub](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/examples/kubernetes/otel-collector-config.yml)を参照してください）。これにより、OpenTelemetryコレクターエージェントのコンテナーに新しい環境変数が挿入されます。値は、ポッドの実行がスケジュールされたノードの名前になります。

```yaml
spec:
  containers:
  - env:
    - name: KUBE_NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
```

次に、 `k8sattributes`のノードでフィルタリングできます。

```yaml
  k8sattributes:
    filter:
      node_from_env_var: KUBE_NODE_NAME
```

## 構成が機能していることを確認します [#validate]

OpenTelemetryデータをKubernetesデータに正常にリンクすると、分散トレースUI内のスパンに`k8s.cluster.name`や`k8s.deployment.name`などのKubernetes属性が表示されるはずです。

クリックして画像を拡大します。

<img
  src={kubernetesOtelValidation}
  title="Screenshot showing K8s metadata in the New Relic UI"
  alt="Screenshot showing K8s metadata in the New Relic UI"
/>

## 次は何ですか？ [#next]

OpenTelemetryをインストルメント化したアプリをKubernetesに接続したので、OpenTelemetryとNewRelicの使用を改善するためのヒントについての[ベストプラクティス](/docs/integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-concepts/)ガイドを確認してください。