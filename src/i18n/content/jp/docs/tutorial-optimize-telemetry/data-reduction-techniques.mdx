---
title: 取り込みデータの量を削減する
metaDescription: Taking your ingested and reported ingest data and optimizing it.
translationType: machine
---

前のステップでは、ベースライン レポートを組織の目標に照らして確認することで、データ最適化計画を作成し、調整しました。データを整理し、価値要因と照らし合わせて測定したら、データの削減と取り込みの最適化を開始できます。データ削減に取り組むには、主に 2 つの方法があります。

* 構成を通じて
* ドロップルールを使用して

以下では両方の方法と、各オプションで提供されるすべての可能な構成について説明します。

### コンフィギュレーションによる最適化 [#optimization-through-configuration]

このセクションには、データのレポートと取り込みを最適化するためにNewRelicの機能を構成するさまざまな方法が含まれています。

<CollapserGroup>
  <Collapser
    id="apm-agent"
    title="APMエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象取引
      * エラー活動
      * カスタムイベント
    </Callout>

    APMエージェントが生成するデータ量は、いくつかの要因によって決定される。

    * アプリケーションによって生成される有機トラフィックの量（たとえば、1日に100万回呼び出されるアプリケーションと等しいすべてのものは、1日に1000回呼び出されるアプリケーションよりも多くのデータを生成します）
    * 基礎となるトランザクションデータ自体のいくつかの特徴（URLの長さと複雑さ）
    * アプリケーションがデータベースクエリーを報告しているかどうか
    * アプリケーションに多くの（または任意の）カスタム属性を持つトランザクションがあるかどうか
    * アプリケーションのエラー量
    * アプリケーションエージェントが分散トレース用に設定されているかどうか

    ### 容量の管理

    アプリケーションへの呼び出しはすべて必要であると想定できますが、アーキテクチャ全体をより効率的にすることは可能です。クライアントによって 10 秒ごとに呼び出されるユーザー プロファイル マイクロサービスがある場合があります。これは、一部のユーザー情報が他のクライアントによって更新された場合の待ち時間を短縮するのに役立ちます。ただし、このサービスへの呼び出し頻度をたとえば 1 分ごとに減らすオプションもあります。

    ### カスタムアトリビュート

    APM API [`addCustomParameter`](https://developer.newrelic.com/collect-data/custom-attributes/) [への呼び出しを使用して追加され](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/) た カスタム属性 は、トランザクション ペイロードに追加の属性を追加します。これらは多くの場合便利ですが、状況が変化すると、データの価値が低下したり、古くなったりする可能性があります。

    Java エージェントは、デフォルトで次の`request.headers`をキャプチャします。

    * `request.headers.referer`
    * `request.headers.accept`
    * `request.headers.contentLength`
    * `request.headers.host`
    * `request.headers.userAgent`

    開発者は `addCustomParameter` を使用して、より詳細なヘッダーを使用してより多くの情報を取得することもできます。

    APM に関連して使用できる豊富な構成の例については、 [Java エージェントのドキュメントを](/docs/apm/agents/java-agent/attributes/java-agent-attributes/#requestparams)参照してください。

    ### エラーイベント

    APM がエラーを処理する方法を見つけることで、データの量を減らすことができます。たとえば、現時点では削除できない、無害だが大量のエラーが存在する可能性があります。

    これを行うには、エラーに対して `collect` 、 `ignore` 、または `mark as expected` を使用できます。詳細については、 [「APM エラーの管理」](/docs/apm/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected)を参照してください。

    ### データベースクエリ

    APM インスタンスの非常に変動しやすい側面の 1 つは、データベース呼び出しとセット構成の数です。これを支援するために、データベース クエリ監視の詳細度を制御できます。これらのクエリは、 **Transaction traces** \[トランザクション追跡] ページに表示されます。

    一般的なデータベースクエリの設定変更は以下の通りです。

    * [クエリ収集を難読化または無効にする代わりに、生のクエリ データを収集します](/docs/apm/transactions/transaction-traces/configure-transaction-traces#record-sql)。
    * スタック トレースのしきい値を変更します。
    * クエリ説明プランの収集をオンにします。

    詳細については、「 [トランザクション追跡データベース クエリ ページ」](/docs/apm/transactions/transaction-traces/transaction-traces-database-queries-page/#settings)を参照してください。

    ### イベント制限の設定

    APM およびモバイル エージェントには、収集サイクルごとに報告できるイベントの数に制限があります。制限がない場合、送信されるイベントの数が十分に多いと、アプリケーションまたは New Relic のパフォーマンスに影響を与える可能性があります。制限に達すると、エージェントはイベントのサンプリングを開始し、収集サイクル全体にわたるイベントの表現を提供します。エージェントごとに制限も異なります。

    制限があり、サンプリングの対象となるイベントには次のものが含まれます。

    * エージェントAPIを介して報告されたカスタムイベント（たとえば、.NETエージェントの`RecordCustomEvent` ）
    * `Mobile`
    * `MobileCrash`
    * `MobileHandledException`
    * `MobileRequest`
    * `Span` （分散トレースサンプリングを参照）
    * `Transaction`
    * `TransactionError`

    ほとんどのエージェントには、サンプリングされたトランザクションのイベント制限を変更するための構成オプションがあります。たとえば、Java エージェントは [`max_samples_stored`](/docs/apm/agents/java-agent/configuration/java-agent-configuration-config-file/#ae-max_samples_stored)を使用します。`max_samples_stored` のデフォルト値は `2000` で、最大値は `10000`です。この値は、エージェント インスタンスから 60 秒ごとにレポートできるサンプリング イベントの数を制御します。イベント サンプリング制限の詳細については、 [「イベント制限」](/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling)を参照してください。

    NRQL [`EXTRAPOLATE`演算子](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#extrapolate)を使用して、サンプリングされたイベントを補正できます。

    サンプリングの実行方法を変更する前に、次の点に留意してください。

    * レポートするイベントが多いほど、エージェントが使用するメモリも多くなります。
    * 通常、エージェントのイベントレポートの制限を上げることなく、必要なデータを取得できます。
    * ペイロード サイズの制限は 1MB (10^6 バイト) (圧縮) であるため、イベントの数は依然としてその制限の影響を受ける可能性があります。イベントが削除されているかどうかを確認するには、エージェント ログで `413 HTTP` ステータス メッセージを確認してください。

    ### ログサンプリングレート

    New Relic APM 言語エージェントの新しいバージョンは、ログを New Relic に直接転送できます。場合によっては、各 APM エージェント インスタンスからのロギング スパイクの最大値を制限する必要がある場合があります。

    APMエージェントのログサンプリングの詳細については、[ログフォワーダー](#log-forwarders)を参照してください。

    ### トランザクショントレース

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 接続サービス数
      * 接続サービスごとの監視対象メソッドコール数
    </Callout>

    APMでは、[トランザクショントレース](/docs/apm/transactions/transaction-traces/transaction-traces)によって、アプリケーションのトランザクションやデータベースコールについての、綿密な詳細を記録します。トランザクショントレースのデフォルト設定を編集することができます。

    これは、 [トランザクション追跡構成](/docs/apm/transactions/transaction-traces/configure-transaction-traces)によって高度に構成することもできます。構成可能性のレベルとモードは言語によって異なります。

    サーバーサイドの設定を使用して利用できるトランザクショントレースの設定は、使用するNew Relicエージェントによって異なります。UI には、それぞれの説明が記載されています。UI での設定には、以下のものが含まれる場合があります。

    * トランザクショントレーシングと閾値
    * 記録レベルと入力フィールドなどの、SQLを記録する
    * SQLとスタックトレースの閾値をログする
    * SQLクエリプランと閾値
    * HTTPコードとエラークラスなどの、エラーの収集
    * 遅いクエリのトレース
    * スレッドプロファイラー

    ### ディストリビューティッド（分散）トレーシング

    分散トレース構成には、言語固有の違いがいくつかあります。必要に応じて分散トレースを無効にすることができます。これは Java エージェント `newrelic.yml`の例です。

    ```yml
    distributed_tracing:
        enabled: false
    ```

    これはnode.jsの例です `newrelic.js`

    ```js
    distributed_tracing: {
      enabled: false
    }
    ```

    データ量は、 [Infinite Tracing を](/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing)使用しているかどうかによっても異なります。APM エージェントの標準分散トレース (上記) ではトレースの最大 10% がキャプチャされますが、すべてのデータを分析して最も関連性の高いトレースを見つけたい場合は、無限トレースを設定できます。標準の分散トレースに代わるこの機能は、すべての APM 言語エージェントで利用できます。毎月の取り込み量がわずかに増加する可能性がある主なパラメータは次のとおりです。

    * トレースオブザーバーの監視を構成する
    * スパン属性トレースフィルタを設定する
    * ランダムトレースフィルターを構成する
  </Collapser>

  <Collapser
    id="browser-agent"
    title="Browserエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ページロード
      * Ajaxコール
      * エラー活動
    </Callout>

    [ブラウザエージェントバージョン1211](/docs/release-notes/new-relic-browser-release-notes/browser-agent-release-notes)以降の場合、ページによって行われたすべてのネットワーク要求は`AjaxRequest`イベントとして記録されます。アプリケーション設定UIページの拒否リスト構成オプションを使用して、レコードイベントを記録する要求をフィルタリングできます。このフィルターに関係なく、すべてのネットワークリクエストはメトリックとしてキャプチャされ、AJAXページで利用できます。

    ### 拒否リストの使用

    リクエストをブロックするには、次の 3 つの方法があります。

    * すべての`AjaxRequest`イベントの記録をブロックするには、アスタリスク`*`をワイルドカードとして追加します。
    * ドメインへの`AjaxRequest`イベントの記録をブロックするには、ドメイン名のみを入力します。例： `example.com`
    * 特定のドメインとパスへの`AjaxRequest`イベントの記録をブロックするには、ドメインとパスを入力します。例： `example.com/path`
    * 拒否リストでは、URLのプロトコル、ポート、サーチ、ハッシュは無視されます。

    追加したフィルターが期待どおりに機能するかどうかを検証するには、フィルターに一致する`AjaxRequest`イベントに対して NRQL クエリを実行します。

    ### 拒否リストにアクセスする

    アプリケーションがイベントの作成からフィルタリングするURLの拒否リストを更新するには、アプリ設定のUIページに移動します。

    1. **[one.newrelic.com](https://one.newrelic.com/all-capabilities)**にアクセスし、をクリックし、 **Browser** \[ブラウザ] をクリックします。
    2. アプリを選択します。
    3. 左のナビゲーションで、 **アプリの設定** をクリックします。
    4. **Ajaxリクエスト拒否リスト**の下に、適用するフィルターを追加します。
    5. **Save application settings** を選択して、エージェントの設定を更新します。
    6. 関連する APM エージェントを再起動するか、コピー/ペーストしたブラウザーのインストールを更新して、ブラウザー エージェントを再デプロイします。

    ### バリデーション

    ```sql
    FROM AjaxRequest SELECT * WHERE requestUrl LIKE `%example.com%`
    ```
  </Collapser>

  <Collapser
    id="mobile-agent"
    title="モバイルエージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 月間アクティブユーザー数
      * クラッシュイベント
      * ユーザーごとのイベント数
    </Callout>

    ### Android

    エージェントを呼び出すための呼び出しを含むすべての設定は、 `MainActivity`クラスの`onCreate`メソッドで呼び出されます。設定を変更するには、次の2つの方法のいずれかで設定を呼び出します（設定でサポートされている場合）。

    ```java
    NewRelic.disableFeature(FeatureFlag.DefaultInteractions);
    NewRelic.enableFeature(FeatureFlag.CrashReporting);
    NewRelic.withApplicationToken(NEW_RELIC_TOKEN).start(this.getApplication());
    ```

    [Analytics settings](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#analytics-settings) \[分析設定は]、 イベント データの収集を有効または無効にします。これらのイベントは **Crash analysis** \[クラッシュ分析] ページに報告され、そこで使用されます。

    [エージェントのログ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#logging-settings-logging)を多かれ少なかれ冗長になるように構成することもできます。

    ### iOS

    Androidと同様に、New RelicのiOS構成では、 [機能フラグ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags)を有効または無効にできます。

    次の機能フラグを設定できます。

    #### クラッシュとエラーの報告

    * `NRFeatureFlag_CrashReporting`
    * `NRFeatureFlag_HandleExceptionEvents`
    * `NRFeatureFlag_CrashReporting`

    #### ディストリビューティッド（分散）トレーシング

    * `NRFeatureFlag_DistributedTracing`

    #### 相互作用

    * `NRFeatureFlag_DefaultInteractions`
    * `NRFeatureFlag_InteractionTracing`
    * `NRFeatureFlag_SwiftInteractionTracing`

    #### ネットワーク機能フラグ

    * `NRFeatureFlag_ExperimentalNetworkInstrumentation`
    * `NRFeatureFlag_NSURLSessionInstrumentation`
    * `NRFeatureFlag_NetworkRequestEvents`
    * `NRFeatureFlag_RequestErrorEvents`
    * `NRFeatureFlag_HttpResponseBodyCapture`

    詳細については、 [機能フラグ](/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/ios-agent-configuration-feature-flags)を参照してください。
  </Collapser>

  <Collapser
    id="infrastructure-agent"
    title="インフラストラクチャー・エージェント"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ホストとコンテナの監視
      * コアイベントのサンプリングレート
      * プロセスサンプル構成
      * カスタムアトリビュート
      * インストールされているオンホストインテグレーションの数および種類
      * ログ転送の設定
    </Callout>

    [インフラストラクチャ エージェント構成ファイルには、](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings) 取り込み量を制御する 2 つの方法が含まれています。最も重要な取り込み制御は、サンプリング レートの構成です。調整できる個別のサンプリング レート構成がいくつかあります。正規表現を作成して、 `ProcessSample` や `NetworkSample`などの特定のコレクターから収集されるものを制御することもできます。

    ### 構成可能なサンプリングレート

    インフラストラクチャで構成できるサンプリング レートは多数ありますが、これらが最も一般的に使用されます。

    | パラメータ                         | デフォルト | 無効化 |
    | ----------------------------- | ----- | --- |
    | `metrics_storage_sample_rate` | 5     | -1  |
    | `metrics_process_sample_rate` | 20    | -1  |
    | `metrics_network_sample_rate` | 10    | -1  |
    | `metrics_system_sample_rate`  | 5     | -1  |
    | `metrics_nfs_sample_rate`     | 5     | -1  |

    ### プロセスサンプル

    プロセス サンプルは、ホスト上で実行中のプロセスに関する情報を送信するため、多くの場合、インフラストラクチャ エージェントからの単一の最も大量のデータ ソースになります。これらはデフォルトでは無効になっていますが、次のように有効にすることができます。

    ```yaml
    enable_process_metrics: true
    ```

    これは、 `metrics_process_sample_rate` を `-1`に設定するのと同じ効果があります。デフォルトでは、メモリ使用量が少ないプロセスはサンプリングから除外されます。詳細については、 `disable-zero-mem-process-filter`を参照してください。

    `include_matching_metrics`を構成することで送信するデータの量を制御できます。これにより、メトリック [属性](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql#naming-conventions)の値に基づいてメトリック データの送信を制限できます。メトリックの属性のいずれかに対してリテラル値または部分値を定義することによって、メトリック データを含めます。たとえば、 `process.name` が正規表現 `^java` に一致するすべてのプロセスの `host.process.cpuPercent` を送信するように選択できます。

    この例では、実行ファイルと名前を使ってプロセスメトリクスを含めています。

    ```yaml
      include_matching_metrics:             # You can combine attributes from different metrics
        process.name:
          - regex "^java"                   # Include all processes starting with "java"
        process.executable:
          - "/usr/bin/python2"              # Include the Python 2.x executable
          - regex "\\System32\\svchost"     # Include all svchost executables
    ```

    また、このフィルターはKubernetesの統合にも使用できます。

    ```yaml
      env:
        - name: NRIA_INCLUDE_MATCHING_METRICS
          value: |
            process.name:
              - regex "^java"
            process.executable:
              - "/usr/bin/python2"
              - regex "\\System32\\svchost"
    ```

    ### ネットワークインターフェースフィルタ

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視するネットワーク・インターフェース数
    </Callout>

    この設定では、シンプルなパターンマッチングメカニズムを使用しており、いずれかのパターンに続く特定の文字または数字のシーケンスで始まるインターフェースを探すことができます。

    * `{name}[other characters]`
    * `[number]{name}[other characters]`、ここで`index-1`オプションを使用して名前を指定します

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    Linuxのデフォルトのネットワークインターフェイスフィルタ。

    * `dummy` 、 `lo` 、 `vmnet` 、 `sit` 、 `tun` 、 `tap` 、または `veth`
    * `tun`またはを含むネットワークインターフェース `tap`

    Windowsのデフォルトのネットワークインターフェイスフィルタ。

    * `Loop` 、 `isatap` 、またはで始まるネットワークインターフェイス `Local`

    デフォルトを上書きするには、設定ファイルに独自のフィルタを記述します。

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    ### カスタムアトリビュート

    [カスタム属性は、](/docs/data-apis/custom-data/custom-events/collect-custom-attributes) インフラストラクチャ エージェントからのデータに注釈を付けるために使用される他のツールのタグに似たキーと値のペアです。このメタデータを使用して、フィルター セットを構築し、結果をグループ化し、データに注釈を付けることができます。たとえば、マシンの環境 (ステージングまたは運用)、マシンがホストするサービス (ログイン サービスなど)、またはそのマシンを担当するチームを指定できます。

    からのカスタム属性の例 `newrelic.yml`

    ```yaml
    custom_attributes:
      environment: production
      service: billing
      team: alpha-team
    ```

    <Callout variant="tip">
      データが適切に整理されていない場合、または何らかの形で古くなっている場合は、データのストリーム化を検討する必要があります。
    </Callout>
  </Collapser>

  <Collapser
    id="k8s-integration"
    title="Kubernetesインテグレーション"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視された`pods`と`containers`の数
      * kubeステートメトリクスの収集頻度と数
      * クラスタごとに生成されるログ
    </Callout>

    Kubernetes のような複雑な分散システムは、短時間で大量のテレメトリを生成する可能性があります。Kubernetes でのデータ取り込みを管理するには、いくつかの優れたアプローチがあります。K8s デプロイメントでコードとして可観測性を使用している場合、これらは非常に簡単になります。

    取り込みの削減について決定を下す前に、この Kubernetes データ取り込み分析ダッシュボードをインストールすることを強くお勧めします。このダッシュボードを取得するには、 [「インフラストラクチャ統合クイックスタート」](https://newrelic.com/instant-observability/infrastructure-integrations-data-analysis/8e31a0ae-81c0-4df0-a119-a0ada9ec16fa)を参照してください。

    ### スクレイプ間隔

    可観測性の目標に応じて、デフォルトの時間は 15 秒であるスクレイピング間隔を調整することを検討してください。Kubernetes クラスター エクスプローラーは 45 秒ごとにのみ更新されます。Kubernetes データの主な用途が KCE 視覚化のサポートである場合は、スクレイピング間隔を 20 秒に変更することを検討してください。15 代から 20 代への変化は大きな影響を与える可能性があります。

    これの管理の詳細については、 [Helm 統合のスクレイピング間隔に関するドキュメント を](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#scrape-interval)参照してください。

    ### 名前空間のフィルタリング

    Kubernetes 統合バージョン 3 以降では、ラベルを付けることでスクレイピングされる名前空間をフィルタリングできます。デフォルトでは、すべての名前空間がスクレイピングされます。

    Kubernetes と同じ方法で `namespaceSelector` を使用します。ラベルに一致する名前空間のみを含めるには、 `newrelic-infrastructure` セクションの `values-newrelic.yaml`に次の内容を追加して、 `namespaceSelector` を変更します。

    ```yaml
    common:
      config:
        namespaceSelector:
          matchLabels:
            key1 : "value1"
    ```

    この例では、ラベル`newrelic.com/scrape`が`true`に設定されている名前空間のみがスクレイプされます。

    ```yaml
    global:
      licenseKey: _YOUR_NEW_RELIC_LICENSE_KEY_
      cluster: _K8S_CLUSTER_NAME_

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchLabels:
              newrelic.com/scrape: "true"
    ```

    Kubernetes 一致式を使用して、名前空間を含めたり除外したりすることもできます。有効な演算子は次のとおりです。

    * の
    * ありませんで
    * 存在する
    * 存在しない

    `matchExpressions`セクションの一般的な構造は、次の行の 1 つまたは複数です。

    ```yaml
    {key: VALUE, operator: OPERATOR, values: LIST_OF_VALUES}
    ```

    完全な例を次に示します。

    ```yaml
    common:
      config:
        namespaceSelector:
          matchExpressions:
          - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    <Callout variant="tip">
      `matchExpresions` セクションには複数の行を含めることができ、式は連結されます。フィルターを適用するには、すべてが true である必要があります。ラベルと一致式については、 [ここ](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)で詳しく説明します。
    </Callout>

    この例では、ラベル`newrelic.com/scrape`が`false`に設定された名前空間が除外されます。

    ```yaml
    global:
      licenseKey: _YOUR_NEW_RELIC_LICENSE_KEY_
      cluster: _K8S_CLUSTER_NAME_

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchExpressions:
            - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    [チャートの README ファイル](https://github.com/newrelic/nri-kubernetes/tree/main/charts/newrelic-infrastructure)で可能な設定の完全なリストを参照してください。

    #### どの名前空間が除外されているかを知るにはどうすればよいですか？ [#excluded-namespaces]

    `K8sNamespace`サンプルのおかげで、クラスター内のすべての名前空間が一覧表示されます。`nrFiltered`属性は、名前空間に関連するデータをスクレイプするかどうかを決定します。

    このクエリを使用して、監視されているネームスペースを確認します。

    ```sql
    FROM K8sNamespaceSample SELECT displayName, nrFiltered
    WHERE clusterName = INSERT_NAME_OF_CLUSTER SINCE
    2 MINUTES AGO
    ```

    #### 除外された名前空間からどのデータが破棄されていますか？ [#namespaces-discarded-data]

    次のサンプルは、除外された名前空間では使用できません。

    * `K8sContainerSample`
    * `K8sDaemonsetSample`
    * `K8sDeploymentSample`
    * `K8sEndpointSample`
    * `K8sHpaSample`
    * `K8sPodSample`
    * `K8sReplicasetSample`
    * `K8sServiceSample`
    * `K8sStatefulsetSample`
    * `K8sVolumeSample`

    ### Kubernetes 状態メトリクス

    Kubernetes cluster explorerで必要なのは、以下のkube state metrics（KSM）のみです。

    * コンテナデータ

    * クラスターデータ

    * ノードデータ

    * ポッドデータ

    * ボリュームデータ

    * APIサーバーデータ

      <sup>1</sup>

    * コントローラマネージャデータ

      <sup>1</sup>

    * ETCDデータ

      <sup>1</sup>

    * スケジューラデータ

      <sup>1</sup>

    <sup>1</sup>管理されたKubernetes環境（EKS、GKE、AKSなど）では収集されません

    以下の一部を無効化することをご検討ください。

    * デーモンセットデータ

    * デプロイメントデータ

    * エンドポイントデータ

    * 名前空間データ

    * ReplicaSetデータ

      <sup>2</sup>

    * サービスデータ

    * StatefulSetデータ

    <sup>2</sup>デフォルトのアラートで使用：「ReplicaSetに必要な数のポッドがありません」

    #### マニフェストの状態メトリックを更新する例（デプロイメント）

    ```shell
    [spec]
      [template]
        [spec]
          [containers]
            [name=kube-state-metrics]
            [args]
            #- --collectors=daemonsets
            #- --collectors=deployments
            #- --collectors=endpoints
            #- --collectors=namespaces
            #- --collectors=replicasets
            #- --collectors=services
            #- --collectors=statefulsets
    ```

    _マニフェストの状態メトリックを更新する例（ClusterRole）_

    ```shell
    [rules]
    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - daemonsets
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - deployments
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - endpoints
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - namespaces
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - replicasets
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - services
    #   verbs: ["list", "watch"]

    # - apiGroups: ["apps"]
    #   resources:
    #   - statefulsets
    #   verbs: ["list", "watch"]
    ```

    ### `nri-bundle`チャートの構成`lowDataMode`

    Helm チャートは、詳細情報を削除して取り込むデータ量を削減するオプションをサポートしています。これを有効にするには、 `nri-bundle` グラフで `global.lowDataMode` を `true` に設定します。

    `lowDataMode` `nri-bundle`チャートの3つの特定のコンポーネントに影響します。

    1. インフラストラクチャエージェントの間隔を`15` }秒から`30`秒に増やします。
    2. Prometheus OpenMetricsの統合では、以下のHelmドキュメントに示されているように、いくつかのメトリックが除外されます。
    3. ラベルと注釈の詳細はログから削除されます。

    この構成の詳細については、 [Helmドキュメント](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#reducedataingest)を参照してください。
  </Collapser>

  <Collapser
    id="on-host-integrations"
    title="オンホストインテグレーション"
  >
    New Relic のオンホスト統合は、Postgresql、MySQL、Kafka、RabbitMQ などのサードパーティ サービスの多様な統合セットを表します。このドキュメントの範囲内ですべての最適化手法を提供することは不可能ですが、これらの手法は一般的に適用されます。

    * サンプリングレートの管理
    * コレクションの幅を増減できる構成部分を管理します
    * カスタムクエリを可能にする構成部分を管理します。
    * すべてのオンホスト統合データに適用するインフラストラクチャ エージェントのカスタム属性を管理します。

    いくつかの例を使って説明します。

    ### [PostgreSQLの統合](/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration/#example-postgresSQL-collection-config)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象テーブル数
      * 監視対象指標数
    </Callout>

    PostgreSQLのオンホスト統合設定では、データ量の管理に役立つこれらの調整可能な設定が提供されています。

    * `interval`: デフォルトは 15 秒です
    * `COLLECTION_LIST`: 監視するテーブルのリスト (ALL を使用してすべてを監視します)
    * `COLLECT_DB_LOCK_METRICS`: `dblock`メトリクスを収集
    * `PGBOUNCER`: `pgbouncer`メトリクスを収集
    * `COLLECT_BLOAT_METRICS`: 肥大化指標を収集する
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `CUSTOM_METRICS_CONFIG`: カスタム コレクション クエリを含む構成ファイル

    **サンプル構成：**

    ```yaml
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres
          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

    ### [Kafkaとの統合](/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration/)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * クラスタ内のブローカー数
      * クラスタ内のトピック数
    </Callout>

    Kafkaのオンホスト統合設定では、データ量の管理に役立つ、これらの調整可能な設定が提供されています。

    * `interval`: デフォルトは 15 秒です
    * `TOPIC_MODE`: 収集するトピックの数を決定します。オプションは`all` 、 `none` 、 `list`または`regex`です。
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `TOPIC_LIST`: 監視するトピック名の JSON 配列。topic_mode が list に設定されている場合にのみ有効です。
    * `COLLECT_TOPIC_SIZE`: メトリクス トピック サイズを収集します。オプションは`true`または`false`で、デフォルトは`false`です。
    * `COLLECT_TOPIC_OFFSET`:メトリクス トピック オフセットを収集します。オプションは`true`または`false`で、デフォルトは`false`です。

    トピック レベルのメトリクス、特にオフセットの収集は、収集に多くのリソースを消費する可能性があり、データ量に影響を与える可能性があります。新しい Kafka トピックをクラスターに追加するだけで、クラスターの取り込み量が 1 桁増加する可能性があります。

    ### [MongoDBとの連携](/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 監視対象データベース数
    </Callout>

    MongoDBとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

    * `interval`: デフォルトは 15 秒です
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `FILTERS`: データベース名からコレクション名の配列への JSON マップ。空の場合、デフォルトですべてのデータベースとコレクションになります。

    使用するオンホスト統合では、デフォルトですべてのデータベースからメトリクスを収集することになっている `FILTERS` のようなパラメータに注意することが重要です。これは、監視の優先順位を使用して収集されたデータを合理化できる領域です。

    **METRICとINVENTORYの間隔が異なる構成例：**

    ```yaml
    integrations:
      - name: nri-mongodb
        env:
          METRICS: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 15s
        labels:
          environment: production

      - name: nri-mongodb
        env:
          INVENTORY: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 60s
        labels:
          environment: production
        inventory_source: config/mongodb
    ```

    ### [Elasticsearchの統合](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * クラスタ内のノード数
      * クラスタ内のインデックス数
    </Callout>

    Elasticsearchとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

    * `interval`: デフォルトは 15 秒です
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `COLLECT_INDICES`: インデックス メトリックを収集するかどうかを通知します。
    * `COLLECT_PRIMARIES`: プライマリ メトリックを収集するかどうかを示します。
    * `INDICES_REGEX`: 収集するインデックスをフィルタリングします。
    * `MASTER_ONLY`: 選択されたマスターのみでクラスタ メトリックを収集します。

    **`METRICS`と`INVENTORY`の間隔が異なる構成の例:**

    ```yaml
    integrations:
      - name: nri-elasticsearch
        env:
          METRICS: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          REMOTE_MONITORING: true
        interval: 15s
        labels:
          environment: production

      - name: nri-elasticsearch
        env:
          INVENTORY: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          CONFIG_PATH: /etc/elasticsearch/elasticsearch.yml
        interval: 60s
        labels:
          environment: production
        inventory_source: config/elasticsearch
    ```

    ### [JMXの統合](/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration)

    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * に記載されている指標 `COLLECTION_CONFIG`
    </Callout>

    JMX 統合は本質的に汎用的です。これにより、任意の JMX インスタンスからメトリクスを取得できます。この統合によって収集される内容を制御できます。一部の企業では、New Relic 環境の JMX メトリクスが、収集されたすべてのデータの比較的高い割合を占めています。

    JMX統合は、データ量の管理に役立つこれらの調整可能な設定を提供します。

    * `interval`: デフォルトは 15 秒です
    * `METRICS`: メトリックのみを収集するには、 `true`に設定します
    * `INVENTORY`: `true`に設定すると、インベントリの収集のみが有効になります
    * `METRIC_LIMIT`: エンティティごとに収集できるメトリックの数。この制限を超えると、エンティティは報告されません。0 の制限は、制限がないことを意味します。
    * `LOCAL_ENTITY`: ローカル エンティティのすべてのメトリックを収集します。localhost を監視する場合にのみ使用されます。
    * `COLLECTION_FILES`: メトリック コレクション定義ファイルへの完全なファイル パスのコンマ区切りリスト。オンホスト インストールの場合、デフォルトの JVM メトリック コレクション ファイルは`/etc/newrelic-infra/integrations.d/jvm-metrics.yml`にあります。
    * `COLLECTION_CONFIG`: JSON としてのメトリクス コレクションの構成。

    取り込まれるデータ量を最も左右するのは`COLLECTION_CONFIG`エントリです。スクレイピングしている JMX モデルを理解すると、最適化に役立ちます。

    _`COLLECTION_CONFIG` JVM メトリックの例_

    ```java
    COLLECTION_CONFIG='{"collect":[{"domain":"java.lang","event_type":"JVMSample","beans":[{"query":"type=GarbageCollector,name=*","attributes":["CollectionCount","CollectionTime"]},{"query":"type=Memory","attributes":["HeapMemoryUsage.Committed","HeapMemoryUsage.Init","HeapMemoryUsage.Max","HeapMemoryUsage.Used","NonHeapMemoryUsage.Committed","NonHeapMemoryUsage.Init","NonHeapMemoryUsage.Max","NonHeapMemoryUsage.Used"]},{"query":"type=Threading","attributes":["ThreadCount","TotalStartedThreadCount"]},{"query":"type=ClassLoading","attributes":["LoadedClassCount"]},{"query":"type=Compilation","attributes":["TotalCompilationTime"]}]}]}'
    ```

    `NonHeapMemoryUsage.Init`など、その構成から1つのエントリを省略すると、収集されるデータ量全体に具体的な影響があります。

    _`COLLECTION_CONFIG` Tomcat メトリクスの例_

    ```java
    COLLECTION_CONFIG={"collect":[{"domain":"Catalina","event_type":"TomcatSample","beans":[{"query":"type=UtilityExecutor","attributes":["completedTaskCount"]}]}]}
    ```

    ### その他のオンホストインテグレーション

    その他にも、収集の最適化に役立つ設定オプションを持つオンホスト統合が多数あります。よく使われるものをいくつか紹介します。

    * [NGINX](/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/)
    * [MySQL](/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration)
    * [Redis](/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration)
    * [Apache](/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration)
    * [RabbitMQ](/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration)

    これは良い [スタート地点](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations#on-host) もっと学ぶために。
  </Collapser>

  <Collapser
    id="network-performance-monitoring"
    title="ネットワークパフォーマンスモニタリング（NPM）"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      駆動するモニター機器。

      * ハードコンフィグデバイス
      * ディスカバリーセクションのCIDRスコープ
      * トラップ設定
    </Callout>

    このセクションでは、Kentikの`ktranslate`エージェントに依存するNewRelicのネットワークパフォーマンスモニタリングに焦点を当てます。このエージェントは非常に洗練されており、主要な最適化を行う前に、[高度な構成ドキュメント](/docs/network-performance-monitoring/advanced/advanced-config)を完全に理解することが重要です。構成オプションは次のとおりです。

    * `mibs_enabled`: KTranslate Docker イメージがポーリングするすべてのアクティブな MIB の配列。`discovery_add_mibs`属性が`true`の場合、このリストは検出中に自動的に生成されます。ここにリストされていない MIB は、構成ファイル内のどのデバイスでもポーリングされません。`MIB-NAME.tableName`構文を使用して、MIB ファイルで SNMP テーブルを直接指定できます。例: `HOST-RESOURCES-MIB.hrProcessorTable` .

    * `user_tags`: key:value ペアの属性で、デバイスにより多くのコンテキストを提供します。このレベルのタグは、構成ファイル内のすべてのデバイスに適用されます。

    * `devices`: フローを監視するデバイスのセクション一覧

    * `traps`: SNMP トラップで監視する IP とポートを構成します (デフォルトは`127.0.0.1:1162`です)。

    * `discovery`: エンドポイントを検出する方法を構成します。このセクションでは、次のパラメーターがスコープを増減するために最も効果的です。

      * `cidrs`: [CIDR 表記](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation)のターゲット IP 範囲の配列。
      * `ports`: SNMP ポーリング中にスキャンするターゲット ポートの配列。
      * `debug`: 検出中にデバッグ レベルのログを有効にするかどうかを示します。デフォルトでは、 `false`
      * `default_communities`: SNMP ポーリング中にスキャンする SNMPv1/v2c コミュニティ ストリングの配列。この配列は順番に評価され、検出は最初に通過したコミュニティを受け入れます。

    可観測性のニーズに見合う価値を生み出さないデータのフィルタリングをサポートするために、 `global.match_attributes.{}`または`devices.<deviceName>.match_attributes.{}`属性マップを設定できます。

    これにより、データを New Relic に送信する前に KTranslate レベルでフィルタリングが提供され、インターフェイスなどの監視をきめ細かく制御できるようになります。

    詳細については、[ネットワークパフォーマンス監視の構成](/docs/network-performance-monitoring/advanced/advanced-config/#match_attributes-attribute)を参照してください。
  </Collapser>

  <Collapser
    id="log-forwarders"
    title="ログフォワーダー"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * ログ転送
      * フォワードログの平均レコードサイズ
    </Callout>

    ログは、通常、独自のルーティングルールと変換ルールを備えた専用の転送レイヤーを介してログをルーティングするという点で、テレメトリの最も柔軟なソースの1つです。さまざまなフォワーダーがあるため、最も一般的に使用されるフォワーダーに焦点を当てます。

    * APM言語エージェント（最近のバージョン）
    * Fluentd
    * Fluentbit
    * New Relic インフラエージェント (Fluentbit 内蔵)
    * Logstash

    ### APMエージェントログのサンプリング

    New Relic 言語エージェントの最新バージョンは、ログを New Relic に直接転送できます。各 APM エージェント インスタンスからのロギングのスパイクがどのくらい大きくなるかについて、いくつかの制限を管理することが必要な場合があります。

    環境変数 `NEW_RELIC_APPLICATION_LOGGING_FORWARDING_MAX_SAMPLES_STORED`を使用してサンプリングを有効にし、APM エージェントのログ キューに保存されるログの最大数を指定して構成できます。これはカスタム優先キューに基づいて動作し、すべてのログ メッセージに優先順位を与えます。トランザクション内で発生したログには、トランザクションの優先順位が与えられます。

    ログのキューは、優先順位とログの到着時期に基づいて並べ替えられます。優先度の高いものが最初に設定され、必要に応じて最新のログが優先されます。ログは個別にキューに追加され (トランザクション内のログも含めて)、制限に達すると、キューの最後にあるログが押し出され、新しいログが優先されます。

    以下のリソース セクションには、ログ ボリュームを簡単な方法で追跡するのに役立つ [クイックスタート ダッシュボード](https://onenr.io/0Bj3BlEZkRX) があります。ログ量を追跡すると、可観測性のニーズに合わせてサンプリング レートを調整または無効にすることができます。

    ### FluentdまたはFluentbitでのフィルターの構成

    ほとんどの一般的なフォワーダーは、フィルタリングや変換を含む、かなり完全な [ルーティング ワークフロー](https://docs.fluentd.org/configuration/routing-examples) を提供します。当社のインフラストラクチャ エージェントは、不要なログをフィルタリングするための非常にシンプルなパターンを提供します。

    レコードをフィルタリングするための正規表現。`tail` 、 `systemd` 、 `syslog` 、および `tcp` (形式 `none`の場合のみ) ソースでのみサポートされます。このフィールドは、Unix システムの `grep -E` と同様の方法で機能します。たとえば、キャプチャされている特定のファイルについて、次を使用して `WARN` または `ERROR` を含むレコードをフィルタリングできます。

    ```yaml
      - name: only-records-with-warn-and-error
        file: /var/log/logFile.log
        pattern: WARN|ERROR
    ```

    有益なフィルタリングまたは解析を行う Fluentbit 用の Fluentd 構成を事前に作成している場合は、それらをログ構成にインポートできます。これを行うには、 `logging.d` フォルダー内の任意の `.yaml` ファイルで `config_file` パラメーターと `parsers` パラメーターを使用します。

    * `config_file`：既存のFluentBit構成ファイルへのパス。ソースが重複していると、NewRelicのログ管理でメッセージが重複します。
    * `parsers_file`：既存のFluentBitパーサーファイルへのパス。

    次のパーサー名が予約されています： `rfc3164` 、 `rfc3164-local` 、および`rfc5424` 。

    データ パイプラインのログに属性またはタグを挿入し、変換を実行する方法を学習すると、New Relic ドロップ ルールを使用してダウンストリーム機能をドロップするのに役立ちます。ソースに関するメタデータでログを強化することで、バックエンドに何をドロップするかについて一元的かつ可逆的な決定を下すことができます。少なくとも、次の属性が何らかの形式でログに存在することを確認してください。

    * チーム
    * 環境(dev/stage/prod)
    * アプリケーション
    * データセンター
    * ログレベル

    以下は、ルーティングとフィルタリングの詳細なリソースです。

    * [Fluentdの一般的なフィルタとルーティングのパターン](https://docs.fluentd.org/configuration/routing-examples)
    * [Fluentbitデータパイプライン](https://docs.fluentbit.io/manual/concepts/data-pipeline)
    * [New Relic インフラストラクチャエージェントによるログの転送](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/)

    ### インフラストラクチャエージェントのデフォルトの属性セットを調整する

    インフラストラクチャ エージェントは、ホストに追加されたカスタム タグを含むいくつかの属性をデフォルトで追加します。構成では、New Relic に `aws.[attributename]`の形式で表示される多数の AWS タグなど、それ以外の多くのタグが取り込まれる可能性があります。これらの属性は重要であるため、計画された構成変更と比較して、視覚化、分析、アラートのニーズを評価することを強くお勧めします。たとえば、Kubernetes クラスターからのログは、次のようなメタデータがなければ役に立ちません。

    * `cluster_name`
    * `pod_name`
    * `container_name`
    * `node_name`
  </Collapser>

  <Collapser
    id="prometheus-metrics-sources"
    title="Prometheusのメトリクスソース"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * アプリからエクスポートされたメトリクス数
      * リモートライトまたはPOMIで転送されたメトリクス数
    </Callout>

    New Relic には、Prometheus メトリクスを New Relic に送信するための 2 つの主要なオプションが用意されています。メトリクスの取り込みを管理するためのベスト プラクティスは、主に 2 番目のオプションである Prometheus OpenMetrics 統合 (POMI) に焦点を当てています。これは、このコンポーネントが New Relic によって作成されたためです。

    ### オプション1： [Prometheusリモート書き込み統合](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)

    Prometheus サーバーのスクレイピング構成オプションについては、 [「Prometheus config docs」](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)を参照してください。これらのスクレイピング構成により、Prometheus サーバーによってどのメトリクスが収集されるかが決まります。[`remote_write`](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration) パラメータを設定すると、収集したメトリクスを New Relic Metric API 経由で New Relic データベース (NRDB) に書き込むことができます。

    ### オプション2： [Prometheus OpenMetrics統合（POMI）](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration)

    POMI は、動的に検出された Prometheus エンドポイントと静的な Prometheus エンドポイントの両方からメトリクスを取得するスタンドアロン統合です。次に、POMI は、New Relic Metric API を介してこのデータを NRDB に送信します。この統合は、現在 Prometheus サーバーを実行していないお客様にとって理想的です。

    #### POMI：スクレープレーベル

    POMI は、デフォルトでラベルまたはアノテーション `prometheus.io/scrape=true` を含む Prometheus エンドポイントを検出します。これは、クラスターにデプロイされているものによっては、多数のエンドポイントになる可能性があるため、大量のメトリクスが取り込まれる可能性があります。

    `scrape_enabled_label` パラメータをカスタムのものに変更することをお勧めします（例:`newrelic/scrape`)、データの取り込みが最も重要な場合には、Prometheus エンドポイントに選択的にラベルを付ける必要があります。

    最新のリファレンス設定については、 [nri-prometheus-latest.yaml](https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml)を参照してください。

    **POMI構成パラメーター：**

    ```yaml
    # Label used to identify scrapable targets. 
    # Defaults to "prometheus.io/scrape"
      scrape_enabled_label: "prometheus.io/scrape"
    ```

    POMI は、デフォルトでノードレベルで公開されている Prometheus エンドポイントを検出します。これには通常、Kubelet と cAdvisor からのメトリクスが含まれます。New Relic Kubernetes Daemonset を実行している場合は、POMI が重複したメトリクスを収集しないように `require_scrape_enabled_label_for_nodes: true` を設定することが重要です。

    New Relic Kubernetes Daemonsetの対象となるエンドポイントについては、 [GitHubのKubernetesREADME](https://github.com/newrelic/nri-kubernetes/blob/main/README.md)を参照してください。

    #### POMI: ノードのラベルをスクレイプする

    POMI は、デフォルトでノードレベルで公開されている Prometheus エンドポイントを検出します。これには通常、Kubelet と cAdvisor からのメトリクスが含まれます。New Relic Kubernetes Daemonset を実行している場合は、POMI が重複したメトリクスを収集しないように `require_scrape_enabled_label_for_nodes: true` を設定することが重要です。

    New Relic Kubernetes Daemonsetの対象となるエンドポイントについては、 [GitHubのKubernetesREADME](https://github.com/newrelic/nri-kubernetes/blob/main/README.md)を参照してください。

    _POMIコンフィグパラメーター_

    ```yaml
    # Whether k8s nodes need to be labeled to be scraped or not. 
    # Defaults to false.
      require_scrape_enabled_label_for_nodes: false
    ```

    #### POMI：との共存 `nri-kubernetes`

    New Relicの[Kubernetes統合](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)は、箱から出してすぐに[多くのメトリック](/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data#metrics)を収集します。ただし、Kubernetesクラスターから利用可能なすべてのメトリックを収集するわけではありません。

    POMI構成には、これに似たセクションが表示されます。これにより、NewRelicKubernetes統合が**KubeStateMetrics**からすでに収集しているメトリックのサブセットのメトリック収集が**無効**になります。

    Kubelet と cAdvisor のメトリクスが重複しないように `require_scrape_enabled_label_for_node: true` を設定することも非常に重要です。

    **POMI構成パラメーター：**

    ```yaml
      transformations:
        - description: "Uncomment if running New Relic Kubernetes integration"
          ignore_metrics:
            - prefixes:
              - kube_daemonset_
              - kube_deployment_
              - kube_endpoint_
              - kube_namespace_
              - kube_node_
              - kube_persistentvolume_
              - kube_persistentvolumeclaim_
              - kube_pod_
              - kube_replicaset_
              - kube_service_
              - kube_statefulset_

    ```

    #### POMI：リクエスト/リミット設定

    POMIを実行するときは、約500kDPMを生成するクラスターに次の[リソース制限](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/)を適用することをお勧めします。

    * CPU制限：1コア（1000m）
    * メモリ制限：1Gb 1024（1G）

    POMI にクラスターから十分なリソースを提供するには、CPU とメモリのリソース要求を設定する必要があります。これを非常に低い値に設定します (例:cpu: 50m) により、クラスター リソースが「ノイジー ネイバー」によって消費される可能性があります。

    **POMI構成パラメーター：**

    ```yaml
    spec:
      serviceAccountName: nri-prometheus
      containers:
      - name: nri-prometheus
        image: newrelic/nri-prometheus:2.2.0
        resources:
          requests:
            memory: 512Mi
            cpu: 500m
          limits:
            memory: 1G
            cpu: 1000m
    ```

    ### POMI：DPMとカーディナリティの推定

    カーディナリティはGBインジェストあたりの請求額とは直接関係ありませんが、New Relicはカーディナリティと1分あたりのデータポイントについて一定のレート制限を維持しています。Prometheus クラスタからカーディナリティと DPM を可視化できることは、非常に重要なことです。

    <Callout variant="tip">
      NewRelicアカウントには1MDPMと1Mカーディナリティの制限がありますが、最大15MDPMと15Mカーディナリティをリクエストできます。変更をリクエストするには、NewRelicアカウントの担当者にお問い合わせください。詳細については、「[メトリックAPIの制限](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes)」を参照してください。
    </Callout>

    すでに Prometheus Server を実行している場合は、 POMI または `remote_write`を有効にする前に、DPM とカーディナリティの推定を実行できます。

    **1分あたりのデータポイント（DPM）：**

    ```promql
    rate(prometheus_tsdb_head_samples_appended_total[10m]) * 60
    ```

    **上位20のメトリック（最高のカーディナリティ）：**

    ```promql
    topk(20, count by (**name**, job)({__name__=~".+"}))
    ```
  </Collapser>

  <Collapser
    id="cloud-integration"
    title="クラウドインテグレーション"
  >
    <Callout
      variant="IMPORTANT"
      title="成長ドライバー"
    >
      * 統合ごとにエクスポートされるメトリクスの数
      * ポーリング頻度(ポーリングベースの統合の場合)
    </Callout>

    一部の New Relic クラウド統合は、クラウド プロバイダーの API からデータを取得します。この実装では、AWS CloudWatch、Azure Monitor、GCP Stackdriver などのモニタリング API からデータが収集され、特定のサービスの API からインベントリ メタデータが収集されます。

    他のクラウド統合は、AWS Kinesisなどのストリーミングサービスを介してプッシュされるストリーミングメトリック（または「プッシュ」メトリック）からデータを取得します。

    ### ポーリングAPIベースの統合

    クラウド統合からのより多くのまたはより少ないデータをレポートしたい場合、またはクラウド アカウントの制限レートやスロットル制限に達しないようにクラウド プロバイダーの API の使用を制御する必要がある場合は、構成設定を変更して変更できます。報告されるデータの量。主なコントロールは次の 2 つです。

    * [ポーリング周波数の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#polling)
    * [データの報告内容の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#filter-data)

    投票頻度の変更を希望するビジネス上の理由の例としては、以下のようなものがあります。

    * **請求**: AWS CloudWatch の請求を管理する必要がある場合は、ポーリング頻度を減らすことができます。これを行う前に、クラウド統合に設定されているアラート条件がこの削減の影響を受けないことを確認してください。
    * **新しいサービス**：新しいサービスまたは構成を展開していて、より頻繁にデータを収集する場合は、ポーリングの頻度を一時的に増やすことをお勧めします。

    <Callout variant="caution">
      統合のコンフィギュレーション設定を変更すると、アラート条件やチャートトレンドに影響を与える場合があります。
    </Callout>

    詳細については、「 [ポーリングの構成](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations)」を参照してください。

    ### 「ストリーミング」または「プッシュ」メトリック

    API ポーリングを使用する代わりに、 [ストリーミング サービスを](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream) 介してデータをプッシュするオプションを提供するクラウド統合が増えており、これにより遅延が大幅に削減されます。一部のユーザーが気づいている問題の 1 つは、サンプリング レートを構成できないため、音量の制御がそれほど簡単ではないことです。

    データを削除するための New Relic ルールは、ボリュームが大きすぎるストリーミング メトリクスをフィルタリングして除外する主な方法です。ただし、ストリーム量を制限するためにクラウドプロバイダー側でできることがいくつかあります。

    たとえば、AWS では、条件キーを使用して [CloudWatch\* 名前空間へのアクセスを制限](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/iam-cw-condition-keys-namespace.html)できます。

    次のポリシーは、ユーザーが`MyCustomNamespace`という名前空間でのみメトリックを公開するように制限します。

    ```json
    {
        "Version": "2012-10-17",
        "Statement": {
            "Effect": "Allow",
            "Resource": "*",
            "Action": "cloudwatch:PutMetricData",
            "Condition": {
                "StringEquals": {
                    "cloudwatch:namespace": "MyCustomNamespace"
                }
            }
        }
    }
    ```

    次のポリシーでは、ユーザーは`CustomNamespace2`を除く任意の名前空間でメトリックを公開できます:

    ```json
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData"
            },
            {
                "Effect": "Deny",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData",
                "Condition": {
                    "StringEquals": {
                        "cloudwatch:namespace": "CustomNamespace2"
                    }
                }
            }
        ]
    }
    ```
  </Collapser>
</CollapserGroup>

#### ドロップルールによる最適化 [#optimization-with-drop-rules]

ドロップ ルールで何ができるかを理解するための簡単なルールは次のとおりです。**クエリできればドロップできるということです。** ドロップ フィルター ルールは、いくつかの重要な目標を達成するのに役立ちます。

* お客様のアカウントに関連するログのみを保存することで、コストを削減できます。
* 個人を特定できる情報（PII）を削除することで、プライバシーとセキュリティを保護します。
* 無関係なイベントや属性を削除して、ノイズを減らす。

<Callout variant="tip">
  ドロップ ルールを作成するときは、設定した条件を満たすデータをルールが正確に識別して破棄するようにする必要があります。また、ルールと、New Relic に開示するデータを監視する責任もあります。常にクエリをテストおよび再テストし、ドロップ ルールをインストールした後、それが意図したとおりに動作することを確認してください。ドロップの前後にデータを監視するダッシュボードを作成すると役立ちます。
</Callout>

ドロップルールを使用して特定のツールのデータ取り込みを最適化するためのガイダンスは次のとおりです。

<CollapserGroup>
  <Collapser
    id="logs"
    title="ログ"
  >
    すべての New Relic ドロップ ルールは、同じバックエンド データ モデルと API によって実装されます。当社のログ管理は、ドロップ ルールの作成と監視を非常に簡単にする強力な UI を提供します。

    以前、このチュートリアル シリーズでは、特定のデータを非推奨にする方法を示すいくつかの演習を実行することで、テレメトリの優先順位付けについて説明しました。この例をもう一度見てみましょう。

    ```
    Omit debug logs (knowing they can be turned on if there is an issue) (saves 5%)
    ```

    #### 方法1：[ログUI](/docs/logs/ui-data/drop-data-drop-filter-rules)

    * ログUIのフィルターを使用して気になるログを特定します： `level: DEBUG` 。
    * ドロップしたいログが見つかることを確認してください。
    * `level:debug`や`log_level:Debug`などの代替構文を確認してください。これらのバリエーションは一般的です。
    * \[**データの管理**]で、\[**ドロップフィルター**]クリックし、\[デバッグログの削除]という名前のフィルターを作成して有効にします。
    * ルールが機能することを確認します。

    #### 方法2: [弊社のNerdGraph APIを利用する。](/docs/data-apis/manage-data/drop-data-using-nerdgraph/)

    * 関連する NRQL クエリを作成します。

      ```sql
      SELECT count(*) FROM Log WHERE `level` = 'DEBUG'
      ```

    * 削除したいログが見つかったことを確認してください。

    * 属性名と値のバリエーションを確認してください ( `Debug`と`DEBUG` )。

    * 以下のNerdGraph文を実行し、動作することを確認します。

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_DATA
                nrql: "SELECT * FROM Log WHERE `level` = 'DEBUG'"
                description: "Drops DEBUG logs.  Disable if needed for troubleshooting."
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser
    id="process-samples"
    title="プロセスサンプル"
  >
    推奨事項を実装しましょう： `Drop process sample data in DEV environments` 。

    * 関連するクエリを作成します。

      ```sql
      SELECT * FROM ProcessSample WHERE `env` = 'DEV'
      ```

    * ドロップするプロセスサンプルが見つかることを確認してください。

    * `ENV` や `Environment`など、 `env` の他のバリエーションがないか確認してください。

    * `Dev` や `Development`などのさまざまな `DEV` を確認します。

    * NerdGraph APIを使用して、以下のステートメントを実行し、動作を確認してください。

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM ProcessSample WHERE `env` = 'DEV'"
                  description: "Drops ProcessSample from development environments"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="cloud-metrics"
    title="クラウドメトリクス"
  >
    多くの場合、冗長なカバレッジでデータを削減することで、データ使用量を削減できます。たとえば、AWS RDS 統合と、SQL データベースを監視する New Relic オンホスト統合 ( `nri-mysql` や `nri-postgresql`など) の 1 つが実行されている環境では、重複するメトリクスの一部を破棄できる場合があります。

    たとえば、次のようなクエリを実行できます。

    ```sql
    FROM Metric select count(*) where metricName like 'aws.rds%' facet metricName limit max
    ```

    これにより、パターンに一致するすべての `metricName` 値が表示されます。

    結果から、パターン `aws.rds.cpu%`のメトリクスが大量にあることがわかります。他のインストルメンテーションがあるため、これらを削除できます。

    * 関連するクエリを作成します。

      ```sql
      FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago
      ```

    * 削除したいプロセス サンプルが見つかったことを確認してください。

    * NerdGraph APIを使用して、以下の文を実行し、動作することを確認する。

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago"
                  description: "Drops rds cpu related metrics"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="drop-specific-attributes"
    title="特定の属性を削除する"
  >
    ドロップ ルールに関する重要な点の 1 つは、特定の属性を削除しながら残りのデータの整合性を維持するルールを設定できることです。これを使用して、NRDB からプライベート データを削除したり、スタック トレースや大きすぎるログ レコード内の JSON の大きなチャンクなどの大きすぎる属性を削除したりできます。

    これらのドロップルールを設定するには、 `action`フィールドを&#x7B; `DROP_DATA` }ではなく`DROP_ATTRIBUTES`に変更します。

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_ATTRIBUTES
                nrql: "SELECT stack_trace, json_data FROM Log where appName='myApp'"
                description: "Drops large fields from logs for myApp"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-random-sample-of-events"
    title="イベントのランダムサンプルをドロップします"
  >
    <Callout variant="caution">
      データから得られる情報が変更される可能性があるため、このアプローチは他に選択肢がない状況でのみ慎重に使用してください。ただし、サンプル サイズが大きいイベントの場合は、結果を理解していれば、データの一部だけで満足できる場合もあります。
    </Callout>

    この例では、特定のトレース ID の相対分布を利用して、ランダム サンプリングを近似できます。`rlike` 演算子を使用すると、スパンの `trace.id` 属性の先頭の値を確認できます。次の例では、スパンの約 25% が削除される可能性があります。

    ```sql
    SELECT * FROM Span WHERE trace.id rlike r'.*[0-3]' and appName = 'myApp'
    ```

    便利な表現は次のとおりです。

    * `r'.*0'` 約6.25％

    * `r'.*[0-1]'` 約12.5％

    * `r'.*[0-2]'` 約18.75％

    * `r'.*[0-3]'` 約25.0％

      完全なミューテーションの例を次に示します。

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_ATTRIBUTES
                  nrql: "SELECT * FROM Span WHERE trace.id rlike r'.*[0-3]' and appName = 'myApp'"
                  description: "Drops approximately 25% of spans for myApp"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser
    id="other-events-and-metrics"
    title="その他のイベントと指標"
  >
    前述の例は、NRDB の他のイベントまたはメトリクスに対してこれらの手法を使用するために知っておく必要があるすべてを示しています。覚えておいてください: クエリできる場合は削除できます。ドロップ ルールのクエリを構築する正確な方法について質問がある場合は、お問い合わせください。
  </Collapser>
</CollapserGroup>

### 次は何ですか？ [#whats-next]

最適化ステップが完了すると、テレメトリ データの最適化チュートリアルは完了です。アカウントにアカウント エグゼクティブがいる場合は、次にどこに進むべきか、最適化されていることを確認するための詳細なガイダンスを得るために、彼らに連絡することができます。

New Relic プラットフォームを初めて使用する場合は、他のチュートリアル シリーズにアクセスして、プラットフォームを使用したシステムの最適化について詳しく学ぶことができます。

* [サービス停止への対応](/docs/tutorial-errors/respond-outages/)
* [大量のログの管理](/docs/tutorial-large-logs/get-started-managing-large-logs/)
* [ピーク需要に備える](/docs/tutorial-peak-demand/get-started/)
* [アラートの作成と管理](/docs/tutorial-create-alerts/create-new-relic-alerts/)