---
title: Google Cloud Platformからのログ転送
tags:
  - Logs
  - Enable log management in New Relic
  - Enable log monitoring in New Relic
  - GCP
  - Dataflow
metaDescription: Configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic.
translationType: machine
---

Google Cloud PlatformのPub/SubトピックからNew Relicにログを転送する方法として、2種類の方法をサポートしています。

## オプションの選択 [#gcp-options]

以下は、お客様のビジネスニーズに最適なオプションを決定する際の参考になるでしょう。

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        GCPログフォワーディングオプション
      </th>

      <th>
        考察
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        ヘッダーレスAPI
      </td>

      <td>
        * 送信するログレコードごとに1回のAPIコールを実行するため、ログ量が少ない場合に最適です。
        * GCPサブスクリプションに追加費用は発生しません。
        * ログの量が増えてくると、このソリューションではNew Relicアカウントのクォータ制限に抵触する可能性があります。
      </td>
    </tr>

    <tr>
      <td>
        データフロージョブ
      </td>

      <td>
        * ログレコードをバッチでグループ化してからNew Relicに送信するため、大容量のログに最適です。
        * APIコールの数を減らし、クォータの使用量を減らすことができます。
        * お客様の敷地内でDataflowジョブを実行するため、GCPサブスクリプションに追加費用が発生する場合があります。
      </td>
    </tr>
  </tbody>
</table>

## ヘッダーレスAPIの使用 [#gcp-headerless-api]

GCPのログをヘッダーレスAPIを使ってNew Relicに送信するためのものです。

<CollapserGroup>
  <Collapser
    id="ingest-url"
    title="1.GCP Pub/SubのインジェストURLを生成します。"
  >
    まず、GCP Pub/SubトピックのインジェストURLを作成します。

    ![データソースの追加](./images/gcp-add-more-data.png "データソースの追加")

    1. [**Logs** in New Relic One](https://one.newrelic.com/launcher/logger.log-launcher) に移動し、 **Add more data sources** をクリックします。

    2. **Google Cloud Platform** をクリックして、ログを転送する New Relic アカウントを選択し、 **Continue** をクリックします。

    3. オプションです。次のステップで生成されるインジェストURLに送信されるすべてのログイベントに含まれるメタデータ（属性と値のペア）を設定します。

    4. **Generate URL** をクリックします。

    5. 新しく生成された **インジェストURL** をコピーして、安全な場所に保管してください。

       新しいインジェストURLを使って、New Relicにログを送信するPub/Subトピックを設定します。
  </Collapser>

  <Collapser
    id="create-gcp-topic"
    title="2.GCP Pub/Sub Topicを作成します。"
  >
    次に、インジェストURLが使用するGCP Pub/Subトピックを作成します。

    ![GCPトピックの作成](./images/gcp-create-topic.png "GCPトピックの作成")

    1. Navigate to [GCP Pub/Sub Console](https://console.cloud.google.com/cloudpubsub/topic/list).
    2. **トピックの作成** をクリックします。
    3. 意味のある **トピックID** を入力し、必要に応じてその他のオプションを設定します。
    4. **トピックの作成** をクリックします。
  </Collapser>

  <Collapser
    id="configure-gcp-log-forwarding"
    title="3.New Relic にログを転送するための GCP Pub/Sub Topic を用意する。"
  >
    Pub/Subトピックを作成したら、そのトピックのサブスクリプションを作成します。

    ![GCP Pub/Subトピックサブスクリプションの作成](./images/gcp-create-subscription.png "GCP Pub/Subトピックサブスクリプションの作成")

    1. [GCP Pub/Sub Consoleに戻る](https://console.cloud.google.com/cloudpubsub/topic/list).

    2. 以前作成した [Pub/Sub トピック](#create-gcp-topic) をクリックします。

    3. スクロールダウンして **Subscriptions** タブを選択し、 **Create Subscription** をクリックし、 **Create a simple subscription** を選択します。

       ![GCP Pub/Subトピックの購読タイプを選択](./images/gcp-create-subscription-type.png "GCP Pub/Subトピックの購読タイプを選択")

    4. **Subscription ID** を入力します。次に、 **Delivery Type** で、 **Push** を選択します。

    5. **Endpoint URL** フィールドに、先に生成した [ingest URL](#ingest-url) を貼り付けます。

    6. 必要に応じて残りの設定を行い、「 **Create** 」をクリックします。
  </Collapser>

  <Collapser
    id="forward-logs"
    title="4.ログをNew Relicに転送するためのルーティングシンクを作成します。"
  >
    セットアップを終えるために、GCPのPub/Subトピックに、ログをNew Relicに転送するためのルーティングシンクを作成します。

    ![GCP Pub/Subログの作成 ルーターシンク](./images/gcp-create-sink.png "GCP Pub/Subログの作成 ルーターシンク")

    1. Navigate to [GCP Logs Router Console](https://console.cloud.google.com/logs/router).
    2. **Create Sink** をクリックします。
    3. **シンクの名前** と **シンクの説明** を入力し、 **Next** をクリックします。
    4. **Select sink service** の下で、 **Cloud Pub/Sub topic** を選択し、以前作成した [Pub/Sub topic](#create-gcp-topic) を選択します。
    5. 必要に応じて残りのフィルターを設定し、 **Create sink** をクリックして設定を完了します。
  </Collapser>
</CollapserGroup>

## Dataflowジョブの使用 [#gcp-dataflow]

Dataflow ジョブを使用して GCP ログを New Relic に送信するには、弊社の Dataflow テンプレートを使用します。始める前に、ローカルコンピュータに以下のツールがあることを確認してください。

* LinuxまたはmacOSのUnixターミナル
* [ジット](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
* [Java JDK 8以上](https://adoptopenjdk.net/index.html)
* [Apache Maven 3.2 以上](https://maven.apache.org/).それ以前のバージョンでは、コンパイル時に失敗することがあります。
* [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) 、これには `gcloud` と `gsutil` のコマンドラインツールが含まれます。

<CollapserGroup>
  <Collapser
    id="dataflow-login-gcp"
    title="1.Google Cloud Platformのアカウントにログインします。"
  >
    以下のコマンドを実行し、画面の指示に従ってGCPにログインし、クラウドプロジェクトを選択します。

    ```
    gcloud init
    ```

    ウィザードでは、使用するクラウドプロジェクトを選択します。また、 `gcloud` または `gsutil` を使用して作成するリソースのデフォルトのコンピュートリージョンとゾーンをオプションで選択することができます。以下のコマンドでは、デフォルトのプロジェクト、ロケーション、リージョンを想定していません。
  </Collapser>

  <Collapser
    id="dataflow-repo"
    title="2.DataflowTemplatesのGitHubリポジトリをクローンします。"
  >
    1. 以下のコマンドでDataflowTemplatesのGitHubリポジトリをクローンします。

       ```
       git clone https://github.com/newrelic-forks/DataflowTemplates.git
       ```

    2. 先ほど作成したディレクトリを入力します。

       ```
       cd DataflowTemplates
       ```

       その後、次のセクションに進み、追加のコマンドを実行します。
  </Collapser>

  <Collapser
    id="dataflow-configuration"
    title="3.Dataflow forwarderをコンパイルして実行します。"
  >
    Dataflow Forwarder のコンパイルと実行に必要な設定を行うには、 `DataflowTemplates` ディレクトリで以下のコマンドを実行します。必要な値は以下のみです。

    * `PROJECT_ID`

    * `BUCKET_NAME`

    * `NR_LICENSE_KEY`

    * `入力サブスクリプション名`

      その他のデフォルト値はそのままで構いません。

      ```bash
      # The Google Cloud Platform project id where your logs are and where the Dataflow log forwarder will run
      PROJECT_ID=<your_project_id>
      # Temporary bucket that will store intermediary files as a result of compiling the Dataflow template. Its name must be unique.
      BUCKET_NAME=<a_nonexisting_gcs_bucket_name>
      # New Relic license key
      NR_LICENSE_KEY=<your_newrelic_license_key>
      Input PubSub subscription to read logs from
      INPUT_SUBSCRIPTION_NAME=<your_pubsub_input_subscription_name>

      # Region where the created resources will be placed
      REGION=us-west1
      # Service account used to execute the Dataflow template
      SERVICE_ACCOUNT_NAME=nr-dataflow-forwarder-sa
      # File name where the service account credentials will be stored
      SERVICE_ACCOUNT_KEY_FILENAME=service-account-key.json
      # The name your Dataflow log forwarder job will have
      JOB_NAME=nr-log-forwarder
      ```
  </Collapser>

  <Collapser
    id="dataflow-bucket"
    title="4.Dataflowテンプレート用のGCPバケットを作成します。"
  >
    以下のコマンドを実行して、生成されたDataflowテンプレートを格納するバケットをGCPに作成します。

    ```bash
    gsutil mb -p ${PROJECT_ID} -l ${REGION} gs://${BUCKET_NAME}
    ```
  </Collapser>

  <Collapser
    id="dataflow-account"
    title="5.サービスアカウントを作成します。"
  >
    以下のコマンドを実行します。

    1. サービスアカウントを作成します。

       ```bash
       gcloud iam service-accounts create ${SERVICE_ACCOUNT_NAME}
       ```

    2. サービスアカウントに権限を付与します。

       ```bash
       gcloud projects add-iam-policy-binding ${PROJECT_ID} --member="serviceAccount:${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com" --role="roles/owner"
       ```

    3. サービスアカウントキーファイルの生成

       ```bash
       gcloud iam service-accounts keys create ${SERVICE_ACCOUNT_KEY_FILENAME} --iam-account=${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com
       ```

    4. `GOOGLE_APPLICATION_CREDENTIALS` 環境変数を使用して、サービスアカウントキーファイルを参照してください。

       ```bash
       export GOOGLE_APPLICATION_CREDENTIALS=${SERVICE_ACCOUNT_KEY_FILENAME}
       ```
  </Collapser>

  <Collapser
    id="dataflow-compile"
    title="6.PubsubToNewRelicテンプレートをコンパイルして公開します。"
  >
    次のコマンドを実行します。

    ```bash
    mvn compile exec:java \
        -Dexec.mainClass=com.google.cloud.teleport.templates.PubsubToNewRelic \
        -Dexec.cleanupDaemonThreads=false \
        -Dexec.args=" \
            --project=${PROJECT_ID} \
            --region=${REGION} \
            --enableStreamingEngine \
            --stagingLocation=gs://${BUCKET_NAME}/staging/ \
            --gcpTempLocation=gs://${BUCKET_NAME}/temp/ \
            --templateLocation=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
            --runner=DataflowRunner \
        "
    ```
  </Collapser>

  <Collapser
    id="dataflow-job"
    title="7.テンプレートをDataflowジョブとして実行します。"
  >
    次のコマンドを実行すると、Pub/Subトピックから読み取るDataflowジョブを使用してログの出荷が開始されます。

    ```bash
    gcloud dataflow jobs run ${JOB_NAME} \
        --gcs-location=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
        --region=${REGION} \
        --parameters "inputSubscription=projects/${PROJECT_ID}/subscriptions/${INPUT_SUBSCRIPTION_NAME},licenseKey=${NR_LICENSE_KEY}"
    ```

    このコマンドでは、この2つの値だけが必要です。

    * ログメッセージの読み取りに使用される入力PubSubサブスクリプション

    * ログの送信に使用するNew Relicのライセンスキー

      その他の値の場合、コマンドはデフォルトのコンフィギュレーション設定を使用し、必要に応じてさらに [カスタマイズすることができます](#dataflow-config) 。
  </Collapser>

  <Collapser
    id="dataflow-config"
    title="8.オプションです。Dataflowのログフォワーダジョブをチューニングします。"
  >
    ここでは、Dataflowログフォワーダージョブの実行をさらに調整するために使用できるオプションのリファレンスを示します。

    <table>
      <thead>
        <tr>
          <th style={{ width: "250px" }}>
            設定パラメータ
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `licenseKey` **必須。**
          </td>

          <td>
            New Relicのライセンスキーです。
          </td>
        </tr>

        <tr>
          <td>
            `inputSubscription` **必須。**
          </td>

          <td>
            ログを消費するために使用されるCloud Pub/Subサブスクリプションです。このフォーマットを使用します。

            ```
            projects/<project-id>/subscriptions/<subscription-name>
            ```
          </td>
        </tr>

        <tr>
          <td>
            `logsApiUrl`
          </td>

          <td>
            New Relic の Log API の URL です。これは、Dataflow パイプラインが実行される VPC からルーティングされます。

            デフォルト：

            ```
            https://log-api.newrelic.com/log/v1
            ```
          </td>
        </tr>

        <tr>
          <td>
            `バッチカウント`
          </td>

          <td>
            1つのHTTP POSTリクエストでNew Relicに送信する前に、バッチに集約するログレコードの最大数。

            デフォルト： `100`
          </td>
        </tr>

        <tr>
          <td>
            `flushDelay`
          </td>

          <td>
            非完全なバッチの最後のログレコードを受信してから、New Relic にフラッシュする前に、追加のログを待つ秒数 (最大で `batchCount`)。

            デフォルト： `2`
          </td>
        </tr>

        <tr>
          <td>
            `パラレリズム`
          </td>

          <td>
            並列リクエストの最大数。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `DisableCertificateValidation`
          </td>

          <td>
            SSL証明書の検証を無効にする。

            デフォルト： `false`
          </td>
        </tr>

        <tr>
          <td>
            `useCompression`
          </td>

          <td>
            New Relic Logs API に送信されるペイロードを (GZIP で) 圧縮します。

            デフォルト： `真`
          </td>
        </tr>

        <tr>
          <td>
            `tokenKMSEncryptionKey`
          </td>

          <td>
            トークンのKMS暗号化キー。このフォーマットを使用します。

            ```
            projects/{gcp_project}/locations/{key_region}/keyRings/{key_ring}/cryptoKeys/{kms_key_name}
            ```

            デフォルト： `null`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## 次のステップ [#what-next]

[New Relic One UI](/docs/logs/log-management/ui-data/use-logs-ui/) を使って、プラットフォーム全体のロギングデータを調べることができます。

* [logs in context](/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/) の機能を使ってログを転送することで、アプリケーションとプラットフォームの両方のパフォーマンスデータをより深く把握することができます。
* [アラートの設定](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions/).
* [データのクエリ](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/) と [ダッシュボードの作成](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/).