---
title: Google Cloud Platformからのログ転送
tags:
  - Logs
  - Enable log management in New Relic
  - Enable log monitoring in New Relic
  - GCP
  - Dataflow
metaDescription: 'Configure New Relic logging for a Google Cloud Platform Pub/Sub topic, so you can use enhanced log management capabilities.'
translationType: machine
---

import logsGCPLogsCreateTopic from 'images/logs_screenshot-full_GCP-logs-create-topic.webp'

import logsGCPCreateSubscription from 'images/logs_screenshot-crop_GCP-create-subscription.webp'

import logsGCPCreateSubscriptionType from 'images/logs_screenshot-crop_GCP-create-subscription-type.webp'

import logsGCPCreateSink from 'images/logs_screenshot-crop_GCP-create-sink.webp'

Google Cloud PlatformのPub/SubトピックからNew Relicにログを転送する方法として、2種類の方法をサポートしています。

## オプションの選択 [#gcp-options]

以下は、お客様のビジネスニーズに最適なオプションを決定する際の参考になるでしょう。

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        GCPログフォワーディングオプション
      </th>

      <th>
        考察
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        ヘッダーレスAPI
      </td>

      <td>
        * 送信するログレコードごとに1回のAPIコールを実行するため、ログ量が少ない場合に最適です。
        * GCPサブスクリプションに追加費用は発生しません。
        * ログの量が増えてくると、このソリューションではNew Relicアカウントのクォータ制限に抵触する可能性があります。
      </td>
    </tr>

    <tr>
      <td>
        データフロージョブ
      </td>

      <td>
        * ログレコードをバッチでグループ化してからNew Relicに送信するため、大容量のログに最適です。
        * APIコールの数を減らし、クォータの使用量を減らすことができます。
        * お客様の敷地内でDataflowジョブを実行するため、GCPサブスクリプションに追加費用が発生する場合があります。
      </td>
    </tr>
  </tbody>
</table>

## ヘッダーレスAPIの使用 [#gcp-headerless-api]

GCPのログをヘッダーレスAPIを使ってNew Relicに送信するためのものです。

<CollapserGroup>
  <Collapser
    id="ingest-url"
    title="1.GCP Pub/SubのインジェストURLを生成します。"
  >
    まず、GCP Pub/Sub トピックの取り込み URL を作成します。

    1. [**Add data** UI](https://one.newrelic.com/marketplace)に移動し、 **Logging**をクリックして、 **Google Cloud Platform**をクリックします。

    2. ログを転送する New Relic アカウントを選択し、 **Continue**をクリックします。

    3. オプションです。次のステップで生成されるインジェストURLに送信されるすべてのログイベントに含まれるメタデータ（属性と値のペア）を設定します。

    4. **Generate URL** をクリックします。

    5. 新しく生成された **インジェストURL** をコピーして、安全な場所に保管してください。

       新しいインジェストURLを使って、New Relicにログを送信するPub/Subトピックを設定します。
  </Collapser>

  <Collapser
    id="create-gcp-topic"
    title="2.GCP Pub/Sub Topicを作成します。"
  >
    次に、インジェストURLが使用するGCP Pub/Subトピックを作成します。

    <img
      title="Create GCP topic"
      alt="Create GCP topic"
      src={logsGCPLogsCreateTopic}
    />

    1. Navigate to [GCP Pub/Sub Console](https://console.cloud.google.com/cloudpubsub/topic/list).
    2. **トピックの作成** をクリックします。
    3. 意味のある **トピックID** を入力し、必要に応じてその他のオプションを設定します。
    4. **トピックの作成** をクリックします。
  </Collapser>

  <Collapser
    id="configure-gcp-log-forwarding"
    title="3.New Relic にログを転送するための GCP Pub/Sub Topic を用意する。"
  >
    Pub/Subトピックを作成したら、そのトピックのサブスクリプションを作成します。

    <img
      title="Create GCP Pub/Sub topic subscription"
      alt="Create GCP Pub/Sub topic subscription"
      src={logsGCPCreateSubscription}
    />

    1. [GCP Pub/Sub Consoleに戻る](https://console.cloud.google.com/cloudpubsub/topic/list).

    2. 以前作成した [Pub/Sub トピック](#create-gcp-topic) をクリックします。

    3. スクロールダウンして **Subscriptions** タブを選択し、 **Create Subscription** をクリックし、 **Create a simple subscription** を選択します。

       <img
         title="Select GCP Pub/Sub topic subscription type"
         alt="Select GCP Pub/Sub topic subscription type"
         src={logsGCPCreateSubscriptionType}
       />

    4. **Subscription ID** を入力します。次に、 **Delivery Type** で、 **Push** を選択します。

    5. **Endpoint URL** フィールドに、先に生成した [ingest URL](#ingest-url) を貼り付けます。

    6. 必要に応じて残りの設定を行い、「 **Create** 」をクリックします。
  </Collapser>

  <Collapser
    id="forward-logs"
    title="4.ログをNew Relicに転送するためのルーティングシンクを作成します。"
  >
    セットアップを終えるために、GCPのPub/Subトピックに、ログをNew Relicに転送するためのルーティングシンクを作成します。

    <img
      title="Create GCP Pub/Sub logs router sink"
      alt="Create GCP Pub/Sub logs router sink"
      src={logsGCPCreateSink}
    />

    1. Navigate to [GCP Logs Router Console](https://console.cloud.google.com/logs/router).
    2. **Create Sink** をクリックします。
    3. **シンクの名前** と **シンクの説明** を入力し、 **Next** をクリックします。
    4. **Select sink service** の下で、 **Cloud Pub/Sub topic** を選択し、以前作成した [Pub/Sub topic](#create-gcp-topic) を選択します。
    5. 必要に応じて残りのフィルターを設定し、 **Create sink** をクリックして設定を完了します。
  </Collapser>
</CollapserGroup>

## Dataflowジョブの使用 [#gcp-dataflow]

Dataflow ジョブを使用して GCP ログを New Relic に送信するには、弊社の Dataflow テンプレートを使用します。始める前に、ローカルコンピュータに以下のツールがあることを確認してください。

* LinuxまたはmacOSのUnixターミナル
* [ジット](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
* [Java JDK 8](https://adoptopenjdk.net/index.html)
* [Apache Maven 3.2 以上](https://maven.apache.org/).それ以前のバージョンでは、コンパイル時に失敗することがあります。
* `gcloud`および`gsutil`コマンドラインツールを含む[GoogleCloudSDK](https://cloud.google.com/sdk/docs/install)

<CollapserGroup>
  <Collapser
    id="dataflow-login-gcp"
    title="1.Google Cloud Platformのアカウントにログインします。"
  >
    以下のコマンドを実行し、画面の指示に従ってGCPにログインし、クラウドプロジェクトを選択します。

    ```
    gcloud init
    ```

    ウィザードを使用して、使用するクラウドプロジェクトを選択し、オプションで、 `gcloud`または`gsutil`を使用して作成するリソースのデフォルトの計算領域とゾーンを選択できます。以下のコマンドでは、デフォルトのプロジェクト、場所、または地域を想定していません。
  </Collapser>

  <Collapser
    id="dataflow-repo"
    title="2.DataflowTemplatesのGitHubリポジトリをクローンします。"
  >
    1. 以下のコマンドでDataflowTemplatesのGitHubリポジトリをクローンします。

       ```
       git clone https://github.com/newrelic-forks/DataflowTemplates.git
       ```

    2. 先ほど作成したディレクトリを入力します。

       ```
       cd DataflowTemplates
       ```

       その後、次のセクションに進み、追加のコマンドを実行します。
  </Collapser>

  <Collapser
    id="dataflow-configuration"
    title="3.Dataflow forwarderをコンパイルして実行します。"
  >
    Dataflowフォワーダーをコンパイルして実行するために必要な構成を設定するには、 `DataflowTemplates`ディレクトリで次のコマンドを実行します。必要な値は次のとおりです。

    * `PROJECT_ID`

    * `BUCKET_NAME`

    * `NR_LICENSE_KEY`

    * `INPUT_SUBSCRIPTION_NAME`

      その他のデフォルト値はそのままで構いません。

      ```bash
      # The Google Cloud Platform project id where your logs are and where the Dataflow log forwarder will run
      PROJECT_ID=<your_project_id>
      # Temporary bucket that will store intermediary files as a result of compiling the Dataflow template. Its name must be unique.
      BUCKET_NAME=<a_nonexisting_gcs_bucket_name>
      # New Relic license key
      NR_LICENSE_KEY=<your_newrelic_license_key>
      # Input PubSub subscription to read logs from
      INPUT_SUBSCRIPTION_NAME=<your_pubsub_input_subscription_name>

      # Region where the created resources will be placed
      REGION=us-west1
      # Service account used to execute the Dataflow template
      SERVICE_ACCOUNT_NAME=nr-dataflow-forwarder-sa
      # File name where the service account credentials will be stored
      SERVICE_ACCOUNT_KEY_FILENAME=service-account-key.json
      # The name your Dataflow log forwarder job will have
      JOB_NAME=nr-log-forwarder
      ```
  </Collapser>

  <Collapser
    id="dataflow-bucket"
    title="4.Dataflowテンプレート用のGCPバケットを作成します。"
  >
    以下のコマンドを実行して、生成されたDataflowテンプレートを格納するバケットをGCPに作成します。

    ```bash
    gsutil mb -p ${PROJECT_ID} -l ${REGION} gs://${BUCKET_NAME}
    ```
  </Collapser>

  <Collapser
    id="dataflow-account"
    title="5.サービスアカウントを作成します。"
  >
    以下のコマンドを実行します。

    1. サービスアカウントを作成します。

       ```bash
       gcloud iam service-accounts create ${SERVICE_ACCOUNT_NAME}
       ```

    2. サービスアカウントに権限を付与します。

       ```bash
       gcloud projects add-iam-policy-binding ${PROJECT_ID} --member="serviceAccount:${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com" --role="roles/owner"
       ```

    3. サービスアカウントキーファイルの生成

       ```bash
       gcloud iam service-accounts keys create ${SERVICE_ACCOUNT_KEY_FILENAME} --iam-account=${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com
       ```

    4. `GOOGLE_APPLICATION_CREDENTIALS`環境変数を使用して、サービスアカウントキーファイルを参照します。これは、後続のコマンドで使用されるためです。

       ```bash
       export GOOGLE_APPLICATION_CREDENTIALS=${SERVICE_ACCOUNT_KEY_FILENAME}
       ```
  </Collapser>

  <Collapser
    id="dataflow-compile"
    title="6.PubsubToNewRelicテンプレートをコンパイルして公開します。"
  >
    次のコマンドを実行します。

    ```bash
    mvn compile exec:java \
        -Dexec.mainClass=com.google.cloud.teleport.templates.PubsubToNewRelic \
        -Dexec.cleanupDaemonThreads=false \
        -Dexec.args=" \
            --project=${PROJECT_ID} \
            --region=${REGION} \
            --enableStreamingEngine \
            --stagingLocation=gs://${BUCKET_NAME}/staging/ \
            --gcpTempLocation=gs://${BUCKET_NAME}/temp/ \
            --templateLocation=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
            --runner=DataflowRunner \
        "
    ```
  </Collapser>

  <Collapser
    id="dataflow-job"
    title="7.テンプレートをDataflowジョブとして実行します。"
  >
    次のコマンドを実行すると、Pub/Subトピックから読み取るDataflowジョブを使用してログの出荷が開始されます。

    ```bash
    gcloud dataflow jobs run ${JOB_NAME} \
        --gcs-location=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
        --region=${REGION} \
        --parameters "inputSubscription=projects/${PROJECT_ID}/subscriptions/${INPUT_SUBSCRIPTION_NAME},licenseKey=${NR_LICENSE_KEY}"
    ```

    このコマンドでは、この2つの値だけが必要です。

    * ログメッセージの読み取りに使用される入力PubSubサブスクリプション

    * ニューレリック

      <InlinePopover type="licenseKey"/>

      ログの送信に使用

    <CollapserGroup>
      <Collapser
        id="eu-customers-gcp-dataflow"
        title="欧州地域のアカウント"
      >
        ヨーロッパのアカウントでは、値として`https://log-api.eu.newrelic.com/log/v1`を使用して`logsApiUrl`パラメータも追加する必要があります。

        ```bash
        gcloud dataflow jobs run ${JOB_NAME} \
            --gcs-location=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
            --region=${REGION} \
            --parameters "inputSubscription=projects/${PROJECT_ID}/subscriptions/${INPUT_SUBSCRIPTION_NAME},licenseKey=${NR_LICENSE_KEY},logsApiUrl=https://log-api.eu.newrelic.com/log/v1"
        ```
      </Collapser>
    </CollapserGroup>

    <Callout variant="tip">
      その他の値の場合、コマンドはデフォルトのコンフィギュレーション設定を使用し、必要に応じてさらに [カスタマイズすることができます](#dataflow-config) 。
    </Callout>
  </Collapser>

  <Collapser
    id="dataflow-config"
    title="8.オプションです。Dataflowのログフォワーダジョブをチューニングします。"
  >
    ここでは、Dataflowログフォワーダージョブの実行をさらに調整するために使用できるオプションのリファレンスを示します。

    <table>
      <thead>
        <tr>
          <th style={{ width: "250px" }}>
            設定パラメータ
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `licenseKey` **必要です。**
          </td>

          <td>
            ニューレリック <InlinePopover type="licenseKey"/>.
          </td>
        </tr>

        <tr>
          <td>
            `inputSubscription` **必要です。**
          </td>

          <td>
            ログを消費するために使用されるCloud Pub/Subサブスクリプションです。このフォーマットを使用します。

            ```
            projects/<project-id>/subscriptions/<subscription-name>
            ```
          </td>
        </tr>

        <tr>
          <td>
            `logsApiUrl`
          </td>

          <td>
            New Relic の Log API の URL です。これは、Dataflow パイプラインが実行される VPC からルーティングされます。

            デフォルト：

            ```
            https://log-api.newrelic.com/log/v1
            ```

            ヨーロッパ地域。

            ```
            https://log-api.eu.newrelic.com/log/v1
            ```
          </td>
        </tr>

        <tr>
          <td>
            `batchCount`
          </td>

          <td>
            1つのHTTP POSTリクエストでNew Relicに送信する前に、バッチに集約するログレコードの最大数。

            デフォルト： `100`
          </td>
        </tr>

        <tr>
          <td>
            `flushDelay`
          </td>

          <td>
            フルバッチではない最後のログレコードを受信してから、New Relicにフラッシュする前に、追加のログ（最大`batchCount` ）を待機する秒数。

            デフォルト： `2`
          </td>
        </tr>

        <tr>
          <td>
            `parallelism`
          </td>

          <td>
            並列リクエストの最大数。

            デフォルト： `1`
          </td>
        </tr>

        <tr>
          <td>
            `disableCertificateValidation`
          </td>

          <td>
            SSL証明書の検証を無効にする。

            デフォルト： `false`
          </td>
        </tr>

        <tr>
          <td>
            `useCompression`
          </td>

          <td>
            NewRelicのLogsAPIに送信されたペイロードを（GZIPで）圧縮します。

            デフォルト： `true`
          </td>
        </tr>

        <tr>
          <td>
            `tokenKMSEncryptionKey`
          </td>

          <td>
            トークンのKMS暗号化キー。このフォーマットを使用します。

            ```
            projects/{gcp_project}/locations/{key_region}/keyRings/{key_ring}/cryptoKeys/{kms_key_name}
            ```

            デフォルト： `null`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

<InstallFeedback/>

## 次は何ですか？ [#what-next]

[ログ UI](/docs/logs/log-management/ui-data/use-logs-ui/)を使用して、プラットフォーム全体のログ データを調べます。

* [ログインコンテキスト](/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/)機能を使用してログを転送することにより、アプリケーションとプラットフォームのパフォーマンスデータの両方をより深く把握できます。
* [アラートを](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions/)設定します。
* [データをクエリ](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/)し、[ダッシュボードを作成します](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/)。

## ログ転送を無効にする [#disable]

ログ転送機能を無効にするには、 [Google Cloud Platform のドキュメント](https://cloud.google.com/sdk/docs/) に記載されている標準的な手順に従ってください。New Relic では、他に何もする必要はありません。