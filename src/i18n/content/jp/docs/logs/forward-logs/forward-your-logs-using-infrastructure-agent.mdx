---
title: インフラストラクチャエージェントを使用してログを転送する
tags:
  - Logs
  - Enable log management in New Relic
  - Enable log monitoring in New Relic
metaDescription: 'How to forward your logs to New Relic using our infrastructure agent, so you can use enhanced log management capabilities.'
freshnessValidatedDate: never
translationType: machine
---

ログを New Relic に転送すると、すべてのログ データが 1 か所で利用できるようになり、アプリケーションとプラットフォームのパフォーマンス データの両方をより詳細に可視化できます。ログを 1 か所にまとめて、ログ データで見つかったエラーや異常を収集、処理、調査、クエリ、およびアラートできます。

<img title="Logs in context for a host" alt="Screenshot of logs in context for a host" src="/images/logs_full_host_logs_ui.webp" />

<figcaption>
  ホストの UI から、選択した期間のイベントのコンテキストにログが配置されます。強調表示された属性の詳細データにドリルダウンできます。
</figcaption>

インフラストラクチャ エージェントはログ転送機能を有効にするため、ログの転送方法はインフラストラクチャ エージェントのインストール方法によって異なります。次の方法でインフラストラクチャ エージェントをインストールできます。

* ガイド付きインストール (ほとんどのユーザーに推奨)
* 手動インストール
* Linux ターボール

<Callout variant="important">
  Linux バージョンのインフラストラクチャ エージェント、具体的にはバージョン 1.42.0 は、td-agent-bit パッケージの使用から Fluent-bit パッケージに移行しました。この変更は、メジャー バージョン 2.x アップデートの後、fluent-bit が td-agent-bit フレーバーで配布されなくなったため、必要になりました。

  スムーズな操作を確保し、fluent-bit パッケージに問題が発生した場合に td-agent-bit に戻すオプションを提供するために、インフラストラクチャ エージェントは両方のパッケージ (td-agent-bit と fluent-bit) をインストールするようになりました。デフォルトでは、エージェントは Fluent-bit を使用するように構成されています。

  ロールバック方法の詳細については [、「Fluent Bit 1.9 へのロールバック」](#rollback-after-fluent-bit-2) を参照してください。
</Callout>

<Callout variant="tip">
  ログがたくさんありますか? [それらを最適化および管理する方法については、チュートリアル](/docs/tutorial-large-logs/get-started-managing-large-logs/)をご覧ください。
</Callout>

## システム要求 [#system]

* インフラストラクチャ・エージェント・バージョン1.11.4以上
* [流暢なビット](https://fluentbit.io/)。インフラストラクチャエージェントは、すでに最新バージョンをインストールしています。特定のバージョンに更新またはダウングレードするには、FluentBitの[インストール](#install-fb-version)手順を参照してください。
* OpenSSL ライブラリ 1.1.0以上
* LinuxシステムでのARM64アーキテクチャ（AWS Gravitonアーキテクチャなど）の組み込みサポートがインフラストラクチャエージェント[1.20.6](https://github.com/newrelic/infrastructure-agent/releases/tag/1.20.6)に追加されました。
* Amazon Linux 2および2023
* CentOS バージョン 8 および 9 ストリーム (Rocky Linux および AlmaLinux もサポートされています)
* RedHat バージョン 8 および 9
* Debian バージョン 11 (Bullseye) および 12 (Bookworm)。
* SUSE Linux Enterprise Server (SLES) バージョン 12 および 15 (ARM64 はサポートされていません)。
* Ubuntuバージョン16.04.x、18.04.x、20.04.x、22.04.x、24.04.x(LTS バージョン)。
* Windows Server 2016、2019、2022およびそれらのサービスパック。
* Windows 10、Windows 11。

## ガイド付きインストールによるログの自動転送 [#infra]

ガイド付きインストールを使用してインフラストラクチャ エージェントをインストールすると、インストール プロセス中にログ転送機能が自動的に構成されます。

インストールを開始するには、展開方法を選択します。

<TechTileGrid>
  <TechTile name="Amazon Linux" to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20" icon={<img src="/images/infrastructure_logo_Amazon-linux.webp" alt="Amazon Linux" variant="TechTile"/>} />

  <TechTile name="Ansible" to="/docs/infrastructure/new-relic-infrastructure/config-management-tools/configure-new-relic-infrastructure-using-ansible" icon={<img src="/images/os_icon_ansible-red.webp" alt="Ansible" variant="TechTile"/>} />

  <TechTile name="CentOS" to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20" icon={<img src="/images/infrastructure_logo_centos.webp" alt="CentOS" variant="TechTile"/>} />

  <TechTile name="Debian" to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20" icon={<img src="/images/infrastructure_logo_debian.webp" alt="Debian" variant="TechTile"/>} />

  <TechTile name="RHEL" to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20" icon={<img src="/images/infrastructure_logo_redhat.webp" alt="Red Hat" variant="TechTile"/>} />

  <TechTile name="SLES" to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20" icon={<img src="/images/infrastructure_logo_suse.webp" alt="SLES" variant="TechTile"/>} />

  <TechTile name="Ubuntu" to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20" icon={<img src="/images/infrastructure_logo_ubuntu.webp" alt="Ubuntu" variant="TechTile"/>} />

  <TechTile name="Windows" to="https://one.newrelic.com/marketplace?state=a792b092-300f-a5a4-ff62-510f4e0c52a5" icon={<img src="/images/infrastructure_logo_windows.webp" alt="Windows" variant="TechTile"/>} />
</TechTileGrid>

<Callout variant="important">
  Dockerコンテナからログを転送するには、この[Dockerイメージを](https://hub.docker.com/r/newrelic/newrelic-fluentbit-output)Kubernetes統合で使用するベース イメージとして使用するか、さまざまな環境に合わせてカスタム設定を使用して独自のコンテナを構築することができます。
</Callout>

## 手動でインストールされたエージェントでログ転送を有効にする [#manual]

インフラストラクチャ エージェントを手動でインストールするには、 [チュートリアルに従ってパッケージ マネージャーをインストールする](/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-agent-linux-using-package-manager)か、 [MSI インストーラー](/docs/infrastructure/install-configure-manage-infrastructure/windows-installation/install-infrastructure-windows-server-using-msi-installer)(Windows) を確認してください。

### 手順 1.インフラストラクチャ エージェントを構成する

設定ファイルは、New Relic に表示するログ ソースを転送するようにシステムに指示します。必要な数だけ設定ファイルを追加できます。当社のインフラストラクチャエージェントは、 `.yml`ファイルを使用してロギングを構成します。 [のインテグレーションおよび](https://one.newrelic.com/marketplace?state=78678a7f-91c5-ca40-ac55-e6b74a50085c) エージェント を介してインフラストラクチャ エージェントをインストールすると、ファイルUI `logging.yml`が自動的に作成されます。

ログ転送機能の新しい構成ファイルを追加するには、次のようにします。

1. ログフォワーダー構成フォルダーに移動します。

   * Linux： `/etc/newrelic-infra/logging.d/`
   * ウィンドウズ： `C:\Program Files\New Relic\newrelic-infra\logging.d\`

2. `logging.yml` 構成ファイルを作成し、必要なパラメータを追加します。 `logging.d` ディレクトリには、参照または開始点として使用できるさまざまな `.yml.example` ファイルがあります。Windows の例については、 [Github リポジトリを](https://github.com/newrelic/infrastructure-agent/tree/master/assets/examples/logging/windows)参照してください。

   ```yml
   # Log forwarder configuration file example
   # Source: file
   # Available customization parameters: attributes, max_line_kb, pattern
   logs:
     # Basic tailing of a single file
     - name: basic-file
       file: /var/log/logFile.log

     # File with spaces in its path. No need to use quotes.
     - name: file-with-spaces-in-path
       file: /var/log/folder with spaces/logFile.log

     # Specify a list of custom attributes, as key-value pairs, to be included
     # in each log record
     - name: file-with-attributes
       file: /var/log/logFile.log
       attributes:
         application: tomcat
         department: sales
         maintainer: example@mailprovider.com

     # Use wildcards to refer to multiple files having a common extension or
     # prefix. Newly generated files will be automatically detected every 60
     # seconds.
     #
     # WARNING: avoid using wildcards that include the file extension, since
     # it'll cause logs to be forwarded repeatedly if log rotation is enabled.
     - name: log-files-in-folder
       file: /var/log/logF*.log

     # Lines longer than 128 KB will be automatically skipped. Use 'max_line_kb'
     # to increase this limit.
     - name: log-file-with-long-lines
       file: /var/log/logFile.log
       max_line_kb: 256

     # Use 'pattern' to filter records using a regular expression
     - name: only-records-with-warn-and-error
       file: /var/log/logFile.log
       pattern: WARN|ERROR
   ```

エージェントは、インフラストラクチャ監視サービスを再起動しなくても、新しい構成ファイルを自動的に処理します。これに対する唯一の例外は、カスタムFluentBit構成を構成する場合です。

### ステップ 2. ログ転送パラメーターを設定する [#parameters]

ログ転送`.yml`構成ファイルで`name`およびログ ソース パラメータを設定する必要があります。まず、New Relic に転送するログの`name`を定義します。

ログ ソースに何を使用するかは、ログのソースとなる場所によって異なります。ログ ソースに使用できるオプションは次のとおりです。

<CollapserGroup>
  <Collapser id="file" title="ファイル">
    ログ ファイルへのパス。エージェントは、 `tail -f`シェルと同様の方法でログ ファイルの変更を追跡します。

    <DNT>
      **Example:**
    </DNT>

    ```yml
    logs:
      - name: example-log
        file: /var/log/example.log     # Path to a single log file
      - name: example-log-two
        file: /var/log/example-two.log # Path to another single log file
    ```

    `file`パラメータは、名前と拡張子に適用されるワイルドカードを使用して、特定のログファイルまたは複数のファイルを指すことができます。たとえば、 `/logs/*.log` 。ファイルパス内のディレクトリの代わりにワイルドカードを使用できます。これを使用して、別のディレクトリにあるファイルを調整できます。

    <DNT>
      **Example:**
    </DNT>

    ```yml
    logs:
      - name: docker-logs
        file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files
    ```

    <Callout variant="important">
      ワイルドカードを使用すると、ファイル記述子の数が大幅に増加し、Fluent Bitプロセスが開いたままになるのを監視します。これにより、ホストのファイル記述子の制限に達した場合にログの収集が妨げられる可能性があります。多数のファイルをテーリングするには、ファイル記述子の最大数を増やし、オペレーティングシステムで許可されているウォッチャーをinotifyする必要がある場合があります。ログファイルを増やす方法の詳細については[、大量のログファイルをテーリングするときのエラーを](#too-many-files)参照してください。
    </Callout>
  </Collapser>

  <Collapser id="systemd" title="systemd">
    Linux環境で`journald`デーモンによって収集されたログメッセージを転送するには、 `systemd`パラメーターを使用します。この入力タイプでは、エージェントが[ルートモード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行されている必要があります。

    <DNT>
      **Example:**
    </DNT>

    ```yml
    logs:
      - name: systemd-example
        systemd: cupsd
    ```
  </Collapser>

  <Collapser id="syslog" title="syslog">
    Syslogデータソース。

    <DNT>
      **Parameters:**
    </DNT>

    * `uri:` Syslogソケット。形式はプロトコルによって異なります。

      * TCP / UDPネットワークソケット： `[tcp/udp]://LISTEN_ADDRESS:PORT`
      * Unixドメインソケット： `unix_[tcp/udp]:// + /socket/path`

    * `parser:` Syslogパーサー。デフォルトは`rfc3164`です。メッセージに秒の小数部が含まれている場合は、 `rfc5424`を使用します。注： `rfc3164`は現在SuSEでは機能しません。

    * `unix_permissions:` ドメインソケットのデフォルトは`0644`です。これにより、エントリは root として実行されるプロセスに制限されます。`0666`を使用すると、root 以外のプロセスをリッスンできます (自己責任で)。

      エージェントを[特権モード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行する場合、他のプロセスがソケットにログを書き込むことができるように、ポートとソケットは、 `nri-agent`によって使用可能または所有されており、 `0666`ファイル権限を持つ必要があります。

      ```yml
      logs:
        # TCP network socket
        - name: syslog-tcp-test
          syslog:
            uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format
            parser: rfc5424 # Default syslog parser is rfc3164

        # UDP network socket
        - name: syslog-udp-test
          syslog:
            uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format
          max_line_kb: 35

        # Unix TCP domain socket
        - name: syslog-unix-tcp-test
          syslog:
            uri: unix_tcp:///var/unix-tcp-socket-test
            unix_permissions: 0666 # Default is 0644. Change at your own risk

        # Unix UDP domain socket
        - name: syslog-unix-udp-test
          syslog:
            uri: unix_udp:///var/unix-udp-socket-test
            parser: rfc5424
      ```
  </Collapser>

  <Collapser id="tcp" title="tcp">
    TCP接続を介して取得されたログ。

    <DNT>
      **Parameters:**
    </DNT>

    * `uri:` 受信データをリッスンするための TCP/IP ソケット。URI 形式は`tcp://LISTEN_ADDRESS:PORT`です。

    * `format:` データの形式。`json`または`none`を指定できます。

    * `separator:` `format: none`を使用する場合は、レコードを分割するための区切り文字列を定義できます（デフォルト： `\n` ）。

      ```yml
      logs:
        - name: tcp-simple-test
          tcp:
            uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format
            format: none            # Raw text - this is default for 'tcp'
            separator: \t           # String for separating raw text entries
          max_line_kb: 32
        - name: tcp-json-test
          tcp:
            uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format
            format: json
      ```
  </Collapser>

  <Collapser id="winevtlog" title="winevtlog">
    <Callout variant="important">
      インフラストラクチャエージェント v.1.24.3 以降で利用可能 Windows Server 2019 以降とのみ互換性があります。以前のバージョンの場合は代わりに[`winlog`](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/#winlog)使用してください。
    </Callout>

    [winevtlog Fluent Bitプラグイン](https://docs.fluentbit.io/manual/pipeline/inputs/windows-event-log-winevtlog)を使用して、新しいWindowsイベントログAPIを使用してWindowsログチャネルからイベントを収集します。

    <DNT>
      **Parameters:**
    </DNT>

    * `channel`: ログが収集されるチャネルの名前。

    * `collect-eventids`: 収集され、New Relic に転送される Windows イベント ID のリスト。イベント ID の範囲がサポートされています。

    * `exclude-eventids`: 収集から除外する Windows イベント ID のリスト。イベント ID の範囲がサポートされています。

    * `use-ansi`: `winlog`メッセージに ANSI エンコードを使用します。Windows Server 2016 以前のバージョンではデフォルトで ANSI エンコードが使用され、それ以降のバージョンでは UTF-8 が使用されます。これらのデフォルトがユースケースに合わない場合は、この設定でこの動作をオーバーライドできます。 これにより、ANSI 文字コード ログが空の文字列になる問題が解決されます。ANSI文字コード内のマルチバイト文字コードログをUTF-8に変換する機能ではありません。

      デフォルトでは、すべてのイベントは指定されたチャネルから収集されます。New Relicアカウントに不要なログが送信されないように、 `collect-eventids`セクションと`exclude-eventids`セクションを構成します。

      イベントIDまたは範囲を`collect-eventids`または`exclude-eventids`に追加して、特定のイベントを転送またはドロップします。同じイベントIDが両方のセクションに存在する場合、 `exclude-eventids`は`collect-eventids`よりも優先されます。

      <DNT>
        **Example:**
      </DNT>

      ```yml
      logs:
        # Example winevtlog security log ingestion with eventId filters.
        - name: windows-security
          winevtlog:
            channel: Security
            collect-eventids:
              - 4624
              - 4265
              - 4700-4800
            exclude-eventids:
              - 4735
          attributes:
            logtype: windows_security

        # Example entries for the application and system channels
        - name: windows-application
          winevtlog:
            channel: Application
            attributes:
              logtype: windows_application

        # Example entries for the application use-ansi
        - name: windows-application
          winevtlog:
            channel: Application
            attributes:
              logtype: windows_application
            use-ansi: true

        - name: windows-system
          winevtlog:
            channel: System
            attributes:
              logtype: windows_system

        # Example/Optional entry for Windows Defender Logs
        - name: windows-defender
          winevtlog:
            channel: Microsoft-Windows-Windows Defender/Operational

        # Example/Optional entry for Windows Clustering Logs
        - name: windows-clustering
          winevtlog:
            channel: Microsoft-Windows-FailoverClustering/Operational
      ```
  </Collapser>

  <Collapser id="winlog" title="winlog">
    <Callout variant="important">
      `Winlog` 従来のイベント ログのみを収集できます。他のユーザーをキャプチャしようとすると、アプリケーション ログがサイレントに収集されます。
    </Callout>

    Windowsログチャネルからイベントを収集します。

    <DNT>
      **Parameters:**
    </DNT>

    * `channel`: ログが収集されるチャネルの名前。カスタムチャンネルでは機能しません。

    * `collect-eventids`: 収集され、New Relic に転送される Windows イベント ID のリスト。イベント ID の範囲がサポートされています。

    * `exclude-eventids`: 収集から除外する Windows イベント ID のリスト。イベント ID の範囲がサポートされています。

    * `use-ansi`: `winlog`メッセージに ANSI エンコードを使用します。Windows Server 2016 以前のバージョンではデフォルトで ANSI エンコードが使用され、それ以降のバージョンでは UTF-8 が使用されます。これらのデフォルトがユースケースに合わない場合は、この設定でこの動作をオーバーライドできます。 これにより、ANSI 文字コード ログが空の文字列になる問題が解決されます。ANSI文字コード内のマルチバイト文字コードログをUTF-8に変換する機能ではありません。

      デフォルトでは、すべてのイベントは指定されたチャネルから収集されます。New Relicアカウントに不要なログが送信されないように、 `collect-eventids`セクションと`exclude-eventids`セクションを構成します。

      イベントIDまたは範囲を`collect-eventids`または`exclude-eventids`に追加して、特定のイベントを転送またはドロップします。同じイベントIDが両方のセクションに存在する場合、 `exclude-eventids`は`collect-eventids`よりも優先されます。

      <DNT>
        **Example:**
      </DNT>

      ```yml
      logs:
        # Example winlog security log ingestion with eventId filters.
        - name: windows-security
          winlog:
            channel: Security
            collect-eventids:
              - 4624
              - 4265
              - 4700-4800
            exclude-eventids:
              - 4735
          attributes:
            logtype: windows_security

        # Example entries for the application and system channels
        - name: windows-application
          winlog:
            channel: Application
            attributes:
              logtype: windows_application
        - name: windows-system
          winlog:
            channel: System
            attributes:
              logtype: windows_system

        # Example entries for the application use-ansi
        - name: windows-application
          winlog:
            channel: Application
            attributes:
              logtype: windows_application
            use-ansi: true

        # Example/Optional entry for Windows Defender Logs
        - name: windows-defender
          winlog:
            channel: Microsoft-Windows-Windows Defender/Operational

        # Example/Optional entry for Windows Clustering Logs
        - name: windows-clustering
          winlog:
            channel: Microsoft-Windows-FailoverClustering/Operational
      ```
  </Collapser>
</CollapserGroup>

### ステップ 3. 主要な属性を定義する [#optional-config]

これらの構成パラメータは必須ではありませんが、これらの構成を`logging.yml`ファイルに適用して、ログ転送を最大限に活用することをお勧めします。

<CollapserGroup>
  <Collapser id="attributes" title="属性">
    キーと値のペアとして指定されたカスタム属性のリスト。ログとともに追加のデータを送信するために使用でき、その後クエリを実行できます。`attributes`構成パラメーターは、任意のログソースで使用できます。

    <Callout variant="important">
      `attributes`構成パラメーターは、外部Fluent Bit構成を介して（たとえば、 `fluentbit`構成パラメーターを使用して）転送されるログにカスタム属性を追加しません。このシナリオでは、 [FluentBitドキュメント](https://docs.fluentbit.io/manual/)の`record_modifier`オプションを参照する必要があります。
    </Callout>

    `attributes`設定の問題の一般的な使用法の 1 つは、 `logtype`属性を指定することです。 この属性により、New Relic の<InlinePopover type="logs" />機能でサポートされる[組み込みの解析ルールの](/docs/logs/log-management/ui-data/parsing/#built-in-rules)1 つを利用できるようになります。

    <DNT>
      **Example:**
    </DNT>

    ```yml
    logs:
      - name: example-file-attributes
        file: /var/log/example.log
        attributes:
          logtype: nginx
          region: example-us-02
          team: A-team
      - name: example-tcp-attributes
        tcp:
          uri: tcp://0.0.0.0:2345
          format: json
        attributes:
          logtype: nginx
          region: example-us-02
          team: B-team
    ```
  </Collapser>

  <Collapser id="automatically-inserted-attributess" title="インフラストラクチャエージェントによって自動的に挿入される属性">
    インフラストラクチャエージェントは、便宜上、ログ属性を自動的に挿入します。それらのいくつかはログレコードに挿入されますが、その他はログフォワーダーのセットアップ中に使用した構成パラメーターに依存します。

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px" }}>
            属性名
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `entity.guids`
          </td>

          <td>
            常に挿入されます。

            インフラストラクチャ エージェントは、New Relic によって割り当てられた [エンティティ GUID を](/attribute-dictionary/?event=Span&attribute=entityGuid) 挿入して、実行されているホストを識別します。これは、 `entity.guids` フィールドで使用できます。

            注：キャプチャされたログがAPMを使用してインストルメント化されたアプリケーションに属している場合、 `entity.guids`フィールドには、インフラストラクチャのエンティティGUIDとAPMのGUIDの両方が、パイプ（|）区切り文字で区切られて含まれます。
          </td>
        </tr>

        <tr>
          <td>
            `fb.input`
          </td>

          <td>
            常に挿入されます。

            ログのキャプチャに使用される基になる[FluentBit入力プラグインタイプ](https://docs.fluentbit.io/manual/pipeline/inputs)。現在、その値は`tail` 、 `systemd` 、 `winlog` 、 `syslog` 、および`tcp`です。
          </td>
        </tr>

        <tr>
          <td>
            `filePath`
          </td>

          <td>
            `file`入力タイプを使用するときに挿入されます。

            監視対象のファイルの絶対ファイルパス。
          </td>
        </tr>

        <tr>
          <td>
            `hostname`
          </td>

          <td>
            常に挿入されます。

            インフラストラクチャエージェントを実行しているマシン/VM/コンテナのホスト名。
          </td>
        </tr>

        <tr>
          <td>
            `plugin.type`
          </td>

          <td>
            常に挿入されます。

            ログのキャプチャに使用されるユーティリティを示します。この場合、それはインフラストラクチャエージェント自体であるため、この属性の値は常に`nri-agent`です。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="pattern" title="パターン">
    レコードをフィルタリングするための正規表現。`file` 、 `systemd` 、 `syslog` 、および`tcp` （形式`none`の場合のみ）のソースでのみサポートされます。

    このフィールドは、Unixシステムの`grep -E`と同じように機能します。たとえば、キャプチャされている特定のファイルについて、次を使用して`WARN`または`ERROR`のいずれかを含むレコードをフィルタリングできます。

    ```yml
    - name: only-records-with-warn-and-error
      file: /var/log/logFile.log
      pattern: WARN|ERROR
    ```

    デフォルトでは、フィルタリングは適用されません。
  </Collapser>

  <Collapser id="max_line_kb" title="max_line_kb">
    ログ エントリ/行の最大サイズ (KB)。ログエントリが制限を超えた場合、それらはスキップされます。デフォルトは`128` 、最小許容値は`33`です。
  </Collapser>

  <Collapser id="fluentbit" title="fluentbit">
    外部[FluentBit](https://fluentbit.io/)構成およびパーサーファイル。定義されている場合、それらはインフラストラクチャエージェントによって生成された既存の構成ファイルおよびパーサーファイルとマージされます。

    インフラストラクチャエージェントは、 `logging.d`ディレクトリにある構成ファイルを処理し、適切な`[INPUT]` 、 `[FILTER]` 、および`[OUTPUT]`セクションを含むランタイムFluentBit構成ファイルを生成します。オプションで、 `fluentbit`オプションを介して外部Fluent Bit構成ファイルを提供した場合は、 `@INCLUDE`も宣言します。

    ランタイム ファイルで[`[SERVICE]`セクション](https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/configuration-file)が定義されていないため、すべてのデフォルトの Fluent Bit 構成値が残されています。外部の Fluent Bit 構成ファイルで独自の`[SERVICE]`セクションを定義し、 `fluentbit`オプションを介して含めることで、Fluent Bit のデフォルト設定をオーバーライドできます。

    <DNT>
      **Parameters:**
    </DNT>

    `config_file:` 既存の Fluent Bit 構成ファイルへのパス。重複するソースがあると、ログ UI で重複したメッセージが表示されることに注意してください。

    `parsers_file:` 既存のFluentBitパーサーファイルへのパス。次のパーサー名が予約されています： `rfc3164` 、 `rfc3164-local` 、および`rfc5424` 。

    <Callout variant="important">
      このドキュメントで説明されているように、インフラストラクチャ エージェントでは、 `logging.d/`ディレクトリ内の YAML ファイルに単純なログ転送構成を定義することで、最も一般的なユースケースのログを転送できます。これらのファイルは、正しい形式と適切な構成デフォルトを備えた Fluent Bit 構成ファイルに内部で変換されます。New Relic は、生成された設定ファイルが正しく動作することを保証するため、これらの設定オプションの公式サポートを提供します。

      ただし、サポートされている構成オプションでカバーされていないユースケースについては、 `fluentbit` 、 `config_file` 、および`parsers_file`オプションを使用して、外部で生成された Fluent Bit 構成およびパーサー ファイルを使用する可能性を提供します。

      注: 提供された構成は完全に任意であり、エージェントによって生成/検証されていないため、この場合、転送されたログが正しく動作することは保証できません。したがって、New Relic は、これらのオプションで指定された外部構成に対する公式サポートを提供しません。
    </Callout>
  </Collapser>
</CollapserGroup>

### サンプル構成ファイル [#running-modes]

YAML形式の`logging.d`構成ファイルの例を次に示します。その他の構成例[については、インフラストラクチャエージェントリポジトリを参照してください](https://github.com/newrelic/infrastructure-agent/tree/master/assets/examples/logging)。

<CollapserGroup>
  <Collapser id="configuration-file" title="logging.d / sample.yaml">
    ```yml
    # Remember to only use spaces for indentation

    logs:
      # Example of 'file' source
      - name: file-with-attributes
        file: /var/log/test.log # Path to a single file or pattern
        attributes:             # You can use custom attributes to enrich your data
          logtype: nginx
          team: The A Team
        pattern: Error          # Regular expression to filter log entries

      # Example of 'systemd' source (Linux only)
      - name: systemd-example
        systemd: cupsd

      # Examples of 'syslog' source, one per protocol
      # TCP network socket
      - name: syslog-tcp-test
        syslog:
          uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format
          parser: rfc5424         # Default syslog parser is rfc3164

      # UDP network socket
      - name: syslog-udp-test
        syslog:
          uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format
        max_line_kb: 35

      # Paths for Unix sockets are defined by combining protocol and path:
      # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket
      # Unix TCP domain socket
      - name: syslog-unix-tcp-test
        syslog:
          uri: unix_tcp:///var/unix-tcp-socket-test
          unix_permissions: 0666 # Default is 0644. Change at your own risk

      # Unix UDP domain socket
      - name: syslog-unix-udp-test
        syslog:
          uri: unix_udp:///var/unix-udp-socket-test
          parser: rfc5424

      # Examples of 'tcp' source for formats 'none' and 'json'
      - name: tcp-simple-test
        tcp:
          uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format
          format: none            # Raw text - this is default for 'tcp'
          separator: \t           # String for separating raw text entries
        attributes:               # You can add custom attributes to any source of logs
          tcpFormat: none
          someOtherAttribute: associatedValue
        max_line_kb: 32
      - name: tcp-json-test
        tcp:
          uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format
          format: json
        attributes:
          tcpFormat: json
          yetAnotherAttribute: 12345

      # Example of Fluent Bit configuration import
      - name: fluentbit-import
        fluentbit:
          config_file: /path/to/fluentbit.config
          parsers_file: /path/to/fluentbit/parsers.conf
    ```
  </Collapser>
</CollapserGroup>

### ステップ 4. ログデータを表示する [#find-data]

すべてが正しく構成され、データが収集されている場合は、次の場所にログと関連するテレメトリデータが表示されます。

* [ログUI](https://one.newrelic.com/launcher/logger.log-launcher)
* インフラストラクチャUIで、ホスト テーブルから、 <Icon name="fe-more-horizontal" />特定のホストのアイコンをクリックし、 <DNT>**View logs**</DNT>クリックします。
* [NRQL クエリ](/docs/chart-builder/use-chart-builder/choose-data/use-advanced-nrql-mode-specify-data)を実行するためのツール。たとえば、次のようなクエリを実行できます。

```sql
SELECT * FROM Log
```

## オンホスト統合のログを有効にする [#on-host]

インフラストラクチャエージェントをインストールすると、最も一般的なオンホスト統合の自動ログ解析と転送を1つのステップで有効にできます。この機能を有効にするには、 `on-host-log.yml.example`ファイルの名前を`on-host-log.yml`に変更します。完了すると、統合のログが自動的に解析され、NewRelicに送信されます。

このオプションは、[サポートされているLinuxプラットフォーム](#requirements)で使用できます。

オンホスト統合ログ転送機能を有効にするには：

<CollapserGroup>
  <Collapser id="elastic-search-logs" title="Elasticsearchログ">
    `elasticsearch-log.yml.example`ファイルをコピーするか、名前を`elasticsearch-log.yml`に変更して、Elasticsearch JSON 形式のログの自動解析と New Relic への転送を有効にします。エージェントを再起動する必要はありません。

    <DNT>
      **Example:**
    </DNT>

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/elasticsearch-log.yml.example /etc/newrelic-infra/logging.d/elasticsearch-log.yml
    ```
  </Collapser>

  <Collapser id="mysql-logs" title="MySQLログ">
    MySQL エラー ログの自動解析と New Relic への転送を有効にするには、 `mysql-log.yml.example`ファイルをコピーするか名前を`mysql-log.yml`に変更します。エージェントを再起動する必要はありません。

    <DNT>
      **Example:**
    </DNT>

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/mysql-log.yml.example /etc/newrelic-infra/logging.d/mysql-log.yml
    ```
  </Collapser>

  <Collapser id="nginx-logs" title="NGINXログ">
    `nginx-log.yml.example`ファイルをコピーするか、名前を`nginx-log.yml`に変更して、自動 NGINX アクセスとエラー ログの解析と New Relic への転送を有効にします。エージェントを再起動する必要はありません。

    <DNT>
      **Example:**
    </DNT>

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/nginx-log.yml.example /etc/newrelic-infra/logging.d/nginx-log.yml
    ```
  </Collapser>

  <Collapser id="rabbitmq-logs" title="Rabbitmqログ">
    `rabbitmq-log.yml.example`ファイルをコピーするか、名前を`rabbitmq-log.yml`に変更して、Rabbitmq エラー ログの自動解析と New Relic への転送を有効にします。エージェントを再起動する必要はありません。

    <DNT>
      **Example:**
    </DNT>

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/rabbitmq-log.yml.example /etc/newrelic-infra/logging.d/rabbitmq-log.yml
    ```
  </Collapser>

  <Collapser id="redis-logs" title="Redisログ">
    Redis エラー ログの自動解析と New Relic への転送を有効にするには、 `redis-log.yml.example`ファイルをコピーするか名前を`redis-log.yml`に変更します。エージェントを再起動する必要はありません。

    <DNT>
      **Example:**
    </DNT>

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/redis-log.yml.example /etc/newrelic-infra/logging.d/redis-log.yml
    ```
  </Collapser>
</CollapserGroup>

## Linuxtarballを使用してインストールされたエージェントでログ転送を有効にする [#tarball-install]

インフラストラクチャ監視用のカスタム Linux インストール プロセスを使用すると、インストール プロセスのあらゆる側面を調整し、マシン上にファイルやフォルダを配置できます。[支援](/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux)または[手動の](/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux)tarball インストール プロセスを選択した場合は、次の手順に従ってログ フォワーダー機能を実装します。

1. 次のディレクトリを作成します。

   * `/var/db/newrelic-infra/newrelic-integrations/logging`
   * `/etc/newrelic-infra/logging.d`

2. 次のようなコマンドを実行して、New Relicの[fluent-bit-package（RPM）](https://github.com/newrelic/fluent-bit-package/releases)をダウンロードしてインストールします。

   ```shell
   yum localinstall fluent-bit-<some-version>.rpm
   ```

3. New Relicの[fluentbitプラグイン](https://github.com/newrelic/newrelic-fluent-bit-output/releases)をダウンロードし、 `/var/db/newrelic-infra/newrelic-integrations/logging/out_newrelic.so`として保存します。

4. [この Github リポジトリ](https://github.com/newrelic/fluent-bit-package/blob/main/parsers.conf)から`parsers.conf`ファイルをダウンロードまたはコピーし、 `/var/db/newrelic-infra/newrelic-integrations/logging/parsers.conf`として保存します。

<InstallFeedback />

## トラブルシューティング [#troubleshoot]

ログフォワーダーの構成で問題が発生した場合は、次のトラブルシューティングのヒントを試してください。

<CollapserGroup>
  <Collapser className="freq-link" id="log-data" title="ログデータなし">
    ログ管理機能を有効にしてもデータが表示されない場合は、[標準のログトラブルシューティング手順](/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/)に従ってください。
  </Collapser>

  <Collapser className="freq-link" id="no-data" title="ファイルをテーリングするときにデータが表示されない">
    ログ転送機能では、エージェントがデータソースを読み取るためのアクセス許可を持っている必要があります。インフラストラクチャエージェントを[特権モードまたは非特権モード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行する場合は、転送するログファイル（およびそのパス内の中間ディレクトリ）が、 `nri-agent`を実行しているユーザーが読み取れることを確認してください。

    <DNT>
      **Example: Check file access under Linux**
    </DNT>

    `nri-agent`ユーザーがファイル`/var/log/restrictedLogs/logFile.log`を監視できるかどうかを確認しましょう。Linuxでは、 `namei`コマンドを使用して簡単なチェックを行うことができます。

    ```bash
    sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log
    [output] f: /var/log/restrictedLogs/logFile.log
    [output] drwxr-xr-x root root /
    [output] drwxr-xr-x root root var
    [output] drwxrwxr-x root syslog log
    [output] drwxr--r-- root root restrictedLogs
    [output] logFile.log - No such file or directory
    ```

    ファイルが`nri-agent`ユーザーに表示されないため、このコマンドは失敗しました。前の出力を調べることにより、 `restrictedLogs`ディレクトリに`others`の実行フラグがないことを検出できます。

    これを修正するには、次を実行します。

    ```bash
    sudo chmod 755 /var/log/restrictedLogs
    ```

    次に、ファイルアクセスを再度確認します。

    ```bash
    sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log
    [output] f: /var/log/restrictedLogs/logFile.log
    [output] drwxr-xr-x root root /
    [output] drwxr-xr-x root root var
    [output] drwxrwxr-x root syslog log
    [output] drwxr-xr-x root root restrictedLogs
    [output] -rw-r----- vagrant vagrant logFile.log
    ```

    これで、ファイルは`nri-agent`ユーザーに表示されます。`nri-agent`ユーザーもファイルを読み取れるようにする必要があります。これを確認するには、次を使用します。

    ```bash
    sudo -u nri-agent head /var/log/restrictedLogs/logFile.log
    [output] head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied
    ```

    この例では、ファイルに`others`グループ（ `vagrant`および`vagrant`ユーザーグループ以外のユーザー）の読み取り権限がありません。`others`に読み取り権限を付与することでこれを修正できますが、アプリケーションは再起動時にこれらの権限を変更する可能性があります。

    これを回避するには、 `nri-agent`ユーザーを`vagrant`ユーザーグループに追加することをお勧めします。
  </Collapser>

  <Collapser className="freq-link" id="syslog" title="Syslogソケットを介してキャプチャするときにデータが表示されない">
    ログ転送機能には、エージェントがデータソースを読み取る権限を持っている必要があります。インフラストラクチャエージェントを[特権モードまたは非特権モード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行する場合：

    * Unixドメインソケットファイルを使用している場合は、`nri-agent`ユーザーがこれらのファイルにアクセスできること（前のセクションを参照してください）と、他のユーザーが読み取りおよび書き込み権限（`666`）を持っていることを確認してください。 `nri-agent`よりも多くのユーザーが書き込み可能です。

    * IPソケットを使用している場合は、使用しているポートがシステムで予約されているポートではないことを確認してください（たとえば、ポート`80`など）。

      ログ管理を有効にしてもデータが表示されない場合は、[標準のログ管理のトラブルシューティング手順](/docs/logs/new-relic-logs/troubleshooting/no-data-appears-logs)に従ってください。
  </Collapser>

  <Collapser className="freq-link" id="proxy" title="インフラストラクチャエージェントプロキシを使用してデータが表示されない">
    [インフラストラクチャ エージェントの構成ガイドライン](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings#proxy)で説明されているように、 `proxy`パラメータは HTTP または HTTPS を使用し、 `https://user:password@hostname:port`の形式にする必要があります。エージェントは HTTP または HTTPS を使用せずにパラメーターを解析できますが、ログ フォワーダーは解析できません。エージェントの詳細ログに次のようなエラーが表示されます。

    ```
    [ERROR] building HTTP transport: parse \"hostname:port\":
    first path segment in URL cannot contain colon
    ```

    この問題を解決するには、 `newrelic-infra.yml`ファイルをチェックし、 `proxy`パラメータがこのフォームに準拠していることを確認してください。

    証明書を指定するために`caBundleFile`または`caBundleDir`を使用している場合は、OSごとに以下のルールに従うことをお勧めします。

    <DNT>
      **Linux**
    </DNT>

    `HTTP`プロキシの場合は、証明書を設定する必要はありません。 プラグインはシステム証明書をロードし、New Relic はログをロギングエンドポイントに送信します。 ただし、 `caBundleFile`または`caBundleDir`のいずれかを使用して、プロキシの自己署名証明書 (PEM ファイル) を指定できます。

    <DNT>
      **Windows**
    </DNT>

    * `HTTP`プロキシの場合、証明書を設定する必要はありません。プラグインはシステム証明書をロードします。

    * `HTTPS`の場合、次のいずれかの方法で構成できます。

      * (推奨) プロキシ証明書をシステム プールにインポートします。 MMC ツールを使用して、プロキシ自己署名証明書 (PEM ファイル) をインポートします。 [このリンク](https://www.ssls.com/knowledgebase/how-to-import-intermediate-and-root-certificates-via-mmc/)を参照し、 <DNT>**Step 2**</DNT>で、それを`Intermediate Certification Authorities`ではなく`Trusted Root Certification Authorities`にインポートしてください。

      * `caBundleFile`および`caBundleDir`パラメータを使用する Windows では、システム証明書プールからの証明書と、 `caBundleFile` `caBundleDir`パラメータで指定された証明書の両方をロードすることはできません。したがって、 `caBundleFile`または`caBundleDir`を使用している場合は、次の証明書が同じ PEM ファイル ( `caBundleFile`を使用する場合) または同じディレクトリ ( `caBundleDir`を使用する場合) に配置されていることを確認してください。

    * プロキシ証明書 ( `HTTPS`プロキシであるため)。

    * ロギング エンドポイント証明書 (例:`https://log-api.newrelic.com/log/v1` )。

    * インフラストラクチャ エージェント証明書 (例:`https://infra-api.newrelic.com` )。

      次のコマンドを実行して、証明書を確認できます。

      ```bash
      openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com
      ```
  </Collapser>

  <Collapser className="freq-link" id="agent-logs" title="インフラストラクチャエージェントのログをNewRelicに送信する">
    独自のログをNewRelicに送信するようにインフラストラクチャエージェントを設定できます。これは、ログ転送、エージェントに関する問題のトラブルシューティング、または[サポート](https://support.newrelic.com/)に連絡するときに役立ちます。

    <Callout variant="important">
      トレース ログは、大量のデータを非常に迅速に生成します。ディスク容量の消費とデータの取り込みを減らすために、ログの生成が終了したら、必ず`level: info` (またはそれ以下) を設定してください。
    </Callout>

    インフラストラクチャエージェントのログをNewRelicに転送するには：

    1. `newrelic-infra.yml`ファイルを編集します。

    2. 次の構成スニペットを追加して、New Relic へのログ転送を有効にします。

       ```yml
       log:
         level: trace  # Recommended: Helps with troubleshooting
         forward: true # Enables sending logs to New Relic
         format: json  # Recommended: Enable agent logging in JSON format
         stdout: false # On Windows and systems that don't use `systemd` or where `journald` is inaccessible
       ```

    3. [エージェントを再起動して](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)、新しい設定をロードします。

       この設定では、エージェントがトラブルシューティングモードに設定されますが、ログフォワーダ（ [Fluent Bit](https://fluentbit.io/)に基づく）は非冗長モードで続行されます。
  </Collapser>

  <Collapser className="freq-link" id="fluentbit-logs" title="ログ転送で詳細モードを有効にする (Fluent Bit)">
    場合によっては、ログ フォワーダー自体に問題が発生することがあります。たとえば、Windows ログ イベントの送信時や特定のログ ファイルへのアクセス時に、特定のチャネルへのアクセスに問題が発生する場合があります。このような状況では、ログ フォワーダーの冗長モードを有効にすることもできます。

    <Callout variant="important">
      トレース ログは、大量のデータを非常に迅速に生成します。ディスク容量の消費とデータの取り込みを減らすために、ログの生成が終了したら、必ず`level: info` (またはそれ以下) を設定してください。
    </Callout>

    1. `newrelic-infra.yml`ファイルを編集します。
    2. 次の構成スニペットを追加して、Fluent Bit の詳細ログを有効にします。
       ```yml
       log:
         level: trace
         forward: true # Enables sending logs to New Relic
         format: json  # Recommended: Enable agent logging in JSON format
         stdout: false # On Windows and systems that don't use `systemd` or where `journald` is inaccessible
         include_filters:
           traces:
             - supervisor # Required to see verbose logs from Fluent Bit
       ```
    3. [エージェントを再起動して](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)、新しい設定をロードします。
  </Collapser>

  <Collapser className="freq-link" id="no-fb" title="FluentBitがインフラエージェントで開始しない">
    <Callout variant="important">
      FluentBitのテールプラグインはネットワークドライブをサポートしていません。
    </Callout>

    2016より前のバージョンのLinuxの場合、OpenSSLライブラリを1.1.0に更新する必要がある場合があります（以上）。この問題があるかどうかを確認するには：

    1. 次のコマンドを実行して、 `infra-agent`がFluentBitを開始したかどうかを確認します。

       ```bash
       ps -aux | grep fluent-bit
       ```

    2. 実行されていない場合は、 `/var/db/newrelic-infra/newrelic-integrations/logging`に移動して実行します。

       ```bash
       ./fluent-bit -i systemd -o stdout
       ```

    3. 次のエラーが発生した場合:

       ```
       error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory
       ```

       OpenSSL を 1.1.0 に更新してください。以上。
  </Collapser>

  <Collapser className="freq-link" id="windows-runtime-error" title="Windowsでのランタイムエラー">
    Windowsでログ転送を有効にすると、次のエラーメッセージのいずれかが表示される場合があります。

    ```
    The code execution cannot proceed because VCRUNTIME140.dll was not found.
    ```

    また

    ```
    error="exit status 3221225781" process=log-forwarder
    ```

    これは、DLLが見つからないことが原因です。

    この問題を解決するには、必要に応じて[Microsoft VisualC++再頒布](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)可能パッケージをインストールします。

    * [x64](https://aka.ms/vs/16/release/vc_redist.x64.exe)
    * [x86](https://aka.ms/vs/16/release/vc_redist.x86.exe)
  </Collapser>

  <Collapser className="freq-link" id="too-many-files" title="大量のログファイルをテーリングするときのエラー（Linux）">
    大量のファイルを追尾しようとすると、次のいずれかのエラーメッセージが表示されるのが一般的です。

    * `Too many open files`
    * `The user limit on the total number of inotify watches was reached or the kernel failed to allocate a needed resource`

    オペレーティングシステムは、割り当て可能なファイル記述子の最大量（通常はデフォルトで1024）と、割り当て可能なinotifyウォッチの最大量（通常はデフォルトで8192）を定義します。これらの制限を超えようとするプロセスは失敗し、上記のエラーの1つを返します。

    ログの転送に使用する基盤テクノロジーである[Fluent Bit は](https://fluentbit.io/)、1 つのファイル記述子を開き、転送するように設定した各ファイルに対して inotify ウォッチを設定します。 さらに、このセクションの執筆時点では、Fluent Bit は通常の動作に 32 個のファイル記述子の追加セットを使用し、シャットダウン時に別の追加のファイル記述子を使用します。 したがって、 <DNT>**to capture a large amount of files you need to ensure that both the file descriptor and inotify watch limits are slightly greater than the amount of log files you wish to tail**</DNT> 。

    次の手順は、10,000個のログファイルを追跡する場合にこれらの制限を増やす方法をまとめたものです。また、インフラストラクチャエージェントが`root` [実行モード](/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/)でインストールされていることを前提としているため、 `root`ユーザーを使用して実行する必要があります。

    1. プロセスごとのファイル記述子の量の現在のハード制限を確認してください。通常、この制限は非常に高く、変更する必要はありません。

       ```bash
       ulimit -Hn
       ```

    2. 次の行を`/etc/security/limits.conf`に追加します。Fluent Bitが機能する必要のある追加のファイル記述子を割り当てることができるように、ここでは`10000`ではなく`10100`の制限を指定しました。

       ```bash
       root soft nofile 10100 # replace root by nri-agent for non-root (privileged and unprivileged) installations
       ```

    3. 再起動時に前の制限が適用されるように、次の行を`/etc/pam.d/common-session`に追加します。

       ```bash
       session required pam_limits.so
       ```

    4. 次の行を`/etc/sysctl.conf`に追加して、ユーザーごとに許可されるinotifyウォッチャーの数を増やします。ここでは、 `10000`ではなく`18192`の制限を指定して、 `root`ユーザーが引き続き`8192`のinotifyウォッチ（デフォルト値）を使用できるようにしました。

       ```bash
       fs.inotify.max_user_watches=18192
       ```

    5. システムを再起動します。

    6. 次のコマンドを実行して、新しい制限が適用されていることを確認します。

       ```bash
       ulimit -Sn                                 # Should return 10100
       cat /proc/sys/fs/inotify/max_user_watches  # Should return 18192
       ```

       [開いているファイルの制限を増やす](https://tecadmin.net/increase-open-files-limit-ubuntu/)[方法、またはinotifyウォッチを増やす](https://dev.to/rubiin/ubuntu-increase-inotify-watcher-file-watch-limit-kf4)方法の詳細をご覧ください。
  </Collapser>

  <Collapser className="freq-link" id="install-fb-version" title="最新の Fluent Bit バージョンをインストールする (Linux)">
    バージョン[1.19.0](/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1190) （またはSLES 12.5の場合はバージョン1.20.3）より前は、Linuxインフラストラクチャエージェントに[FluentBit](/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1203)バイナリがバンドルされていました。このバージョン以降、FluentBitは個別の`recommended`パッケージ依存関係として含まれるようになりました。

    これは、Fluent Bitをエージェントとは別にインストール、更新、またはダウングレードできることを意味します。便宜上、インフラストラクチャが存在する同じリポジトリにいくつかのFluent Bitパッケージが含まれているため、FluentBitをアップグレードするために追加のリポジトリをインストールする必要はありません。

    エージェントは、最初にインストールしたときに、利用可能な最新バージョンを使用してFluentBitを自動的にインストールすることに注意してください。最初のインストール後、Linuxパッケージで通常行うようにFluentBitをアップグレードできます。

    次のコマンドを実行して、使用可能なFluentBitバージョンを一覧表示できます。

    RPM：

    ```bash
    sudo yum check-update
    yum list fluent-bit --showduplicates
    ```

    DEB：

    ```bash
    sudo apt update
    apt-cache showpkg fluent-bit
    ```

    最新の Fluent Bit バージョンにアップグレードするには、次のコマンドを実行します。

    RPM：

    ```bash
    # Remove command only required when downgrading to a previous version
    # sudo yum remove fluent-bit
    sudo yum install fluent-bit
    ```

    DEB：

    ```bash
    sudo apt install fluent-bit
    ```
  </Collapser>

  <Collapser className="freq-link" id="rollback-after-fluent-bit-2" title="Linux 上のインフラストラクチャ エージェント 1.42.0 後の Fluent-bit 1.x へのロールバック">
    td-agent-bit は次のディストリビューションでは使用できないため、ロールバックできないことに注意してください。

    * CentOS 9 ストリーム (Rocky Linux および AlmaLinux を含む)
    * レッドハット9
    * Ubuntu 22.04.x
    * オープン スース (SLES) 15.4
    * Amazon Linux 2023

    td-agent-bit に戻したい場合は、以下の手順に従ってください。

    1. 任意のテキスト エディタを使用してファイル `/etc/newrelic-infra.yml` を開きます。
    2. ファイルの最後に次の行を追加します: `fluent_bit_exe_path: /opt/td-agent-bit/bin/td-agent-bit`。
    3. 変更を保存します。
    4. コマンド `sudo systemctl restart newrelic-infra`を実行して、インフラストラクチャ エージェントを再起動します。

    これらの手順を完了すると、インフラストラクチャ エージェントは、fluent-bit の代わりに td-agent-bit を使用するように構成されます。
  </Collapser>
</CollapserGroup>

## 次は何ですか？ [#what-next]

[ログ UI](/docs/logs/log-management/ui-data/use-logs-ui/)を使用して、プラットフォーム全体のログ データを調べます。

* [ログインコンテキスト](/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/)機能を使用してログを転送することにより、アプリケーションとプラットフォームのパフォーマンスデータの両方をより深く把握できます。
* [アラートを](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions/)設定します。
* [データをクエリ](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/)し、[ダッシュボードを作成します](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/)。

## ログ転送を無効にする [#uninstall]

ログ転送機能を無効にするには、 `logging.d`ディレクトリに移動し、[設定](#step-1-configure-the-infrastructure-agent)プロセス中に最初に追加された`.yml`拡張子を持つファイルを削除します。

* Linux： `/etc/newrelic-infra/logging.d/`
* ウィンドウズ： `C:\Program Files\New Relic\newrelic-infra\logging.d\`