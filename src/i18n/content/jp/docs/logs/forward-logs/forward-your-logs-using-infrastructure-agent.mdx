---
title: インフラストラクチャエージェントを使用してログを転送する
tags:
  - Logs
  - Enable log management in New Relic
  - Enable log monitoring in New Relic
metaDescription: 'How to forward your logs to New Relic using our infrastructure agent, so you can use enhanced log management capabilities.'
signupBanner:
  text: Monitor and improve your entire stack. 100GB free. Forever.
translationType: machine
---

import logsHostLogsUi from 'images/logs_screenshot-full_host-logs-ui.webp'

import infrastructureAmazonLinux from 'images/infrastructure_logo_Amazon-linux.webp'

import infrastructureCentos from 'images/infrastructure_logo_centos.webp'

import infrastructureDocker from 'images/infrastructure_logo_docker.webp'

import infrastructureDebian from 'images/infrastructure_logo_debian.webp'

import infrastructureRedhat from 'images/infrastructure_logo_redhat.webp'

import infrastructureSuse from 'images/infrastructure_logo_suse.webp'

import infrastructureUbuntu from 'images/infrastructure_logo_ubuntu.webp'

import infrastructureWindows from 'images/infrastructure_logo_windows.webp'

import osAnsibleRed from 'images/os_icon_ansible-red.webp'

ログを New Relic に転送すると、すべてのログ データが 1 か所で利用できるようになり、アプリケーションとプラットフォームのパフォーマンス データの両方をより詳細に可視化できます。ログを 1 か所にまとめて、ログ データで見つかったエラーや異常を収集、処理、調査、クエリ、およびアラートできます。

<img
  title="Logs in context for a host"
  alt="Screenshot of logs in context for a host"
  src={logsHostLogsUi}
/>

<figcaption>
  ホストの UI から、選択した期間のイベントのコンテキストにログが配置されます。強調表示された属性の詳細データにドリルダウンできます。
</figcaption>

インフラストラクチャ エージェントはログ転送機能を有効にするため、ログの転送方法はインフラストラクチャ エージェントのインストール方法によって異なります。次の方法でインフラストラクチャ エージェントをインストールできます。

* ガイド付きインストール (ほとんどのユーザーに推奨)
* 手動インストール
* Linux ターボール

<Callout variant="important">
  Linux バージョンのインフラストラクチャ エージェント、具体的にはバージョン 1.42.0 は、td-agent-bit パッケージの使用から Fluent-bit パッケージに移行しました。この変更は、メジャー バージョン 2.x アップデートの後、fluent-bit が td-agent-bit フレーバーで配布されなくなったため、必要になりました。

  スムーズな操作を確保し、fluent-bit パッケージに問題が発生した場合に td-agent-bit に戻すオプションを提供するために、インフラストラクチャ エージェントは両方のパッケージ (td-agent-bit と fluent-bit) をインストールするようになりました。デフォルトでは、エージェントは Fluent-bit を使用するように構成されています。

  ロールバック方法の詳細については [、「Fluent Bit 1.9 へのロールバック」](#rollback-after-fluent-bit-2) を参照してください。
</Callout>

<Callout variant="tip">
  ログがたくさんありますか? [それらを最適化および管理する方法については、チュートリアル](/docs/tutorial-large-logs/get-started-managing-large-logs/)をご覧ください。
</Callout>

## システム要求 [#system]

* インフラストラクチャ・エージェント・バージョン1.11.4以上
* [流暢なビット](https://fluentbit.io/)。インフラストラクチャエージェントは、すでに最新バージョンをインストールしています。特定のバージョンに更新またはダウングレードするには、FluentBitの[インストール](#install-fb-version)手順を参照してください。
* OpenSSL ライブラリ 1.1.0以上
* LinuxシステムでのARM64アーキテクチャ（AWS Gravitonアーキテクチャなど）の組み込みサポートがインフラストラクチャエージェント[1.20.6](https://github.com/newrelic/infrastructure-agent/releases/tag/1.20.6)に追加されました。
* Amazon Linux 2 および 2023 (ARM64 は 2023 ではサポートされません)
* CentOS バージョン 7、8、および 9 ストリーム (Rocky Linux および AlmaLinux もサポートされています)
* RedHat バージョン 7、8、9
* Debian バージョン 9 (ストレッチ)、10 (バスター)、および 11 (ブルズアイ)。
* SUSE Linux Enterprise Server (SLES) バージョン 12 および 15 (ARM64 はサポートされていません)。
* Ubuntu バージョン 16.04.x、18.04.x、20.04.x、22.04.x(LTS バージョン)。
* Windows Server 2012、2016、2019、2022、およびそれらのサービスパック。
* ウィンドウズ10

## ガイド付きインストールによるログの自動転送 [#infra]

ガイド付きインストールを使用してインフラストラクチャ エージェントをインストールすると、インストール プロセス中にログ転送機能が自動的に構成されます。まだお持ちでない場合は、以下で無料の New Relic アカウントを作成して、今すぐデータの監視を開始してください。

<InlineSignup/>

インストールを開始するには、展開方法を選択します。

<TechTileGrid>
  <TechTile
    name="Amazon Linux"
    to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20"
    icon={<img src={infrastructureAmazonLinux} alt="Amazon Linux" variant="TechTile"/>}
  />

  <TechTile
    name="Ansible"
    to="/docs/infrastructure/new-relic-infrastructure/config-management-tools/configure-new-relic-infrastructure-using-ansible"
    icon={<img src={osAnsibleRed} alt="Ansible" variant="TechTile"/>}
  />

  <TechTile
    name="CentOS"
    to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20"
    icon={<img src={infrastructureCentos} alt="CentOS" variant="TechTile"/>}
  />

  <TechTile
    name="Debian"
    to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20"
    icon={<img src={infrastructureDebian} alt="Debian" variant="TechTile"/>}
  />

  <TechTile
    name="RHEL"
    to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20"
    icon={<img src={infrastructureRedhat} alt="Red Hat" variant="TechTile"/>}
  />

  <TechTile
    name="SLES"
    to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20"
    icon={<img src={infrastructureSuse} alt="SLES" variant="TechTile"/>}
  />

  <TechTile
    name="Ubuntu"
    to="https://one.newrelic.com/marketplace?state=8f14e646-461e-b010-4675-3a0658bb3d20"
    icon={<img src={infrastructureUbuntu} alt="Ubuntu" variant="TechTile"/>}
  />

  <TechTile
    name="Windows"
    to="https://one.newrelic.com/marketplace?state=a792b092-300f-a5a4-ff62-510f4e0c52a5"
    icon={<img src={infrastructureWindows} alt="Windows" variant="TechTile"/>}
  />
</TechTileGrid>

## 手動でインストールされたエージェントでログ転送を有効にする [#manual]

インフラストラクチャ エージェントを手動でインストールするには、 [チュートリアルに従ってパッケージ マネージャーをインストールする](/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-agent-linux-using-package-manager)か、 [MSI インストーラー](/docs/infrastructure/install-configure-manage-infrastructure/windows-installation/install-infrastructure-windows-server-using-msi-installer)(Windows) を確認してください。

### 手順 1.インフラストラクチャ エージェントを構成する

構成ファイルは、New Relic に表示するログ ソースをシステムに転送するように指示します。構成ファイルはいくつでも追加できます。インフラストラクチャ エージェントは、 `.yml`ファイルを使用してロギングを構成します。UI の \[[データの追加\]](https://one.newrelic.com/marketplace?state=78678a7f-91c5-ca40-ac55-e6b74a50085c)からインフラストラクチャ エージェントをインストールすると、ファイル`logging.yml`が自動的に作成されます。

ログ転送機能の新しい構成ファイルを追加するには、次のようにします。

1. ログフォワーダー構成フォルダーに移動します。

   * Linux： `/etc/newrelic-infra/logging.d/`
   * ウィンドウズ： `C:\Program Files\New Relic\newrelic-infra\logging.d\`

2. `logging.yml` 構成ファイルを作成し、必要なパラメータを追加します。 `logging.d` ディレクトリには、参照または開始点として使用できるさまざまな `.yml.example` ファイルがあります。Windows の例については、 [Github リポジトリを](https://github.com/newrelic/infrastructure-agent/tree/master/assets/examples/logging/windows)参照してください。

   ```yml
   # Log forwarder configuration file example
   # Source: file
   # Available customization parameters: attributes, max_line_kb, pattern
   logs:
     # Basic tailing of a single file
     - name: basic-file
       file: /var/log/logFile.log

     # File with spaces in its path. No need to use quotes.
     - name: file-with-spaces-in-path
       file: /var/log/folder with spaces/logFile.log

     # Specify a list of custom attributes, as key-value pairs, to be included
     # in each log record
     - name: file-with-attributes
       file: /var/log/logFile.log
       attributes:
         application: tomcat
         department: sales
         maintainer: example@mailprovider.com

     # Use wildcards to refer to multiple files having a common extension or
     # prefix. Newly generated files will be automatically detected every 60
     # seconds.
     #
     # WARNING: avoid using wildcards that include the file extension, since
     # it'll cause logs to be forwarded repeatedly if log rotation is enabled.
     - name: log-files-in-folder
       file: /var/log/logF*.log

     # Lines longer than 128 KB will be automatically skipped. Use 'max_line_kb'
     # to increase this limit.
     - name: log-file-with-long-lines
       file: /var/log/logFile.log
       max_line_kb: 256

     # Use 'pattern' to filter records using a regular expression
     - name: only-records-with-warn-and-error
       file: /var/log/logFile.log
       pattern: WARN|ERROR
   ```

エージェントは、インフラストラクチャ監視サービスを再起動しなくても、新しい構成ファイルを自動的に処理します。これに対する唯一の例外は、カスタムFluentBit構成を構成する場合です。

### ステップ 2. ログ転送パラメーターを設定する [#parameters]

ログ転送`.yml`構成ファイルで`name`およびログ ソース パラメータを設定する必要があります。まず、New Relic に転送するログの`name`を定義します。

ログ ソースに何を使用するかは、ログのソースとなる場所によって異なります。ログ ソースに使用できるオプションは次のとおりです。

<CollapserGroup>
  <Collapser
    id="file"
    title="ファイル"
  >
    ログ ファイルへのパス。エージェントは、 `tail -f`シェルと同様の方法でログ ファイルの変更を追跡します。

    **例：**

    ```yml
    logs:
      - name: example-log
        file: /var/log/example.log # Path to a single log file
      - name: example-log-two
        file: /var/log/example-two.log # Path to another single log file
    ```

    `file`パラメータは、名前と拡張子に適用されるワイルドカードを使用して、特定のログファイルまたは複数のファイルを指すことができます。たとえば、 `/logs/*.log` 。ファイルパス内のディレクトリの代わりにワイルドカードを使用できます。これを使用して、別のディレクトリにあるファイルを調整できます。

    **例：**

    ```yml
    logs:
      - name: docker-logs
        file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files
    ```

    <Callout variant="important">
      ワイルドカードを使用すると、ファイル記述子の数が大幅に増加し、Fluent Bitプロセスが開いたままになるのを監視します。これにより、ホストのファイル記述子の制限に達した場合にログの収集が妨げられる可能性があります。多数のファイルをテーリングするには、ファイル記述子の最大数を増やし、オペレーティングシステムで許可されているウォッチャーをinotifyする必要がある場合があります。ログファイルを増やす方法の詳細については[、大量のログファイルをテーリングするときのエラーを](#too-many-files)参照してください。
    </Callout>
  </Collapser>

  <Collapser
    id="systemd"
    title="systemd"
  >
    Linux環境で`journald`デーモンによって収集されたログメッセージを転送するには、 `systemd`パラメーターを使用します。この入力タイプでは、エージェントが[ルートモード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行されている必要があります。

    **例：**

    ```yml
    logs:
      - name: systemd-example
        systemd: cupsd
    ```
  </Collapser>

  <Collapser
    id="syslog"
    title="syslog"
  >
    Syslogデータソース。

    **パラメーター：**

    * `uri:` Syslogソケット。形式はプロトコルによって異なります。

      * TCP / UDPネットワークソケット： `[tcp/udp]://LISTEN_ADDRESS:PORT`
      * Unixドメインソケット： `unix_[tcp/udp]:// + /socket/path`

    * `parser:` Syslogパーサー。デフォルトは`rfc3164`です。メッセージに秒の小数部が含まれている場合は、 `rfc5424`を使用します。注： `rfc3164`は現在SuSEでは機能しません。

    * `unix_permissions:` ドメインソケットのデフォルトは`0644`です。これにより、エントリはルートとして実行されているプロセスに制限されます。`0666`を使用して、自己責任で非ルートプロセスをリッスンできます。

      エージェントを[特権モード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行する場合、他のプロセスがソケットにログを書き込めるように、ポートとソケットは`0666` `nri-agent`によって使用可能であるか、所有されている必要があります。

      ```yml
      logs:
        # TCP network socket
        - name: syslog-tcp-test
          syslog:
            uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format
            parser: rfc5424 # Default syslog parser is rfc3164
        # UDP network socket
        - name: syslog-udp-test
          syslog:
            uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format
          max_line_kb: 35
        # Unix TCP domain socket
        - name: syslog-unix-tcp-test
          syslog:
            uri: unix_tcp:///var/unix-tcp-socket-test
            unix_permissions: 0666 # Default is 0644. Change at your own risk
        # Unix UDP domain socket
        - name: syslog-unix-udp-test
          syslog:
            uri: unix_udp:///var/unix-udp-socket-test
            parser: rfc5424
      ```
  </Collapser>

  <Collapser
    id="tcp"
    title="tcp"
  >
    TCP接続を介して取得されたログ。

    **パラメーター：**

    * `uri:` 着信データをリッスンするTCP/IPソケット。URI形式は `tcp://LISTEN_ADDRESS:PORT`

    * `format:` データのフォーマット。`json`または`none`にすることができます。

    * `separator:` `format: none`を使用する場合は、レコードを分割するための区切り文字列を定義できます（デフォルト： `\n` ）。

      ```yml
      logs:
        - name: tcp-simple-test
          tcp:
            uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format
            format: none # Raw text - this is default for 'tcp'
            separator: \t # String for separating raw text entries
          max_line_kb: 32
        - name: tcp-json-test
          tcp:
            uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format
            format: json
      ```
  </Collapser>

  <Collapser
    id="winevtlog"
    title="winevtlog"
  >
    <Callout variant="important">
      インフラストラクチャ エージェント v.1.24.3 以降で利用可能Windows Server 2019 以降とのみ互換性があります。以前のバージョンでは、代わりに [winlog](https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/#winlog) を使用してください。
    </Callout>

    [winevtlog Fluent Bitプラグイン](https://docs.fluentbit.io/manual/pipeline/inputs/windows-event-log-winevtlog)を使用して、新しいWindowsイベントログAPIを使用してWindowsログチャネルからイベントを収集します。

    **パラメーター：**

    * `channel:` チャネルログの名前はから収集されます。

    * `collect-eventids:` 収集されてNewRelicに転送されるWindowsイベントIDのリスト。イベントIDの範囲がサポートされています。

    * `exclude-eventids:` コレクションから除外されるWindowsイベントIDのリスト。イベントIDの範囲がサポートされています。

    * `use-ansi:` winevtlog メッセージには ANSI エンコードを使用します。Windows Server 2016 以前のバージョンではデフォルトで ANSI エンコードを使用し、新しいバージョンでは UTF-8 を使用します。これらのデフォルトがユースケースに適合しない場合は、この構成パラメーターを使用してこの動作をオーバーライドできます。

      デフォルトでは、すべてのイベントは指定されたチャネルから収集されます。New Relicアカウントに不要なログが送信されないように、 `collect-eventids`セクションと`exclude-eventids`セクションを構成します。

      イベントIDまたは範囲を`collect-eventids`または`exclude-eventids`に追加して、特定のイベントを転送またはドロップします。同じイベントIDが両方のセクションに存在する場合、 `exclude-eventids`は`collect-eventids`よりも優先されます。

      **例：**

      ```yml
      logs:
        # Example winevtlog security log ingestion with eventId filters.
        - name: windows-security
          winevtlog:
            channel: Security
            collect-eventids:
              - 4624
              - 4265
              - 4700-4800
            exclude-eventids:
              - 4735
          attributes:
            logtype: windows_security

        # Example entries for the application and system channels
        - name: windows-application
          winevtlog:
            channel: Application
            attributes:
              logtype: windows_application
        - name: windows-system
          winevtlog:
            channel: System
            attributes:
              logtype: windows_system

        # Example/Optional entry for Windows Defender Logs
        #- name: windows-defender
        #  winevtlog:
        #    channel: Microsoft-Windows-Windows Defender/Operational

        # Example/Optional entry for Windows Clustering Logs
        #- name: windows-clustering
        #  winevtlog:
        #    channel: Microsoft-Windows-FailoverClustering/Operational
      ```
  </Collapser>

  <Collapser
    id="winlog"
    title="winlog"
  >
    <Callout variant="important">
      Winlog は従来のイベント ログのみを収集できます。他のユーザーをキャプチャしようとすると、サイレント モードでアプリケーション ログが収集されます。
    </Callout>

    Windowsログチャネルからイベントを収集します。

    **パラメーター：**

    * `channel:` チャネルログの名前はから収集されます。カスタムチャネルでは機能しません。

    * `collect-eventids:` 収集されてNewRelicに転送されるWindowsイベントIDのリスト。イベントIDの範囲がサポートされています。

    * `exclude-eventids:` コレクションから除外されるWindowsイベントIDのリスト。イベントIDの範囲がサポートされています。

    * `use-ansi:` winlog メッセージに ANSI エンコードを使用します。Windows Server 2016 以前のバージョンではデフォルトで ANSI エンコードを使用し、新しいバージョンでは UTF-8 を使用します。これらのデフォルトがユースケースに適合しない場合は、この構成パラメーターを使用してこの動作をオーバーライドできます。

      デフォルトでは、すべてのイベントは指定されたチャネルから収集されます。New Relicアカウントに不要なログが送信されないように、 `collect-eventids`セクションと`exclude-eventids`セクションを構成します。

      イベントIDまたは範囲を`collect-eventids`または`exclude-eventids`に追加して、特定のイベントを転送またはドロップします。同じイベントIDが両方のセクションに存在する場合、 `exclude-eventids`は`collect-eventids`よりも優先されます。

      **例：**

      ```yml
      logs:
        # Example winlog security log ingestion with eventId filters.
        - name: windows-security
          winlog:
            channel: Security
            collect-eventids:
              - 4624
              - 4265
              - 4700-4800
            exclude-eventids:
              - 4735
          attributes:
            logtype: windows_security

        # Example entries for the application and system channels
        - name: windows-application
          winlog:
            channel: Application
            attributes:
              logtype: windows_application
        - name: windows-system
          winlog:
            channel: System
            attributes:
              logtype: windows_system

        # Example/Optional entry for Windows Defender Logs
        #- name: windows-defender
        #  winlog:
        #    channel: Microsoft-Windows-Windows Defender/Operational

        # Example/Optional entry for Windows Clustering Logs
        #- name: windows-clustering
        #  winlog:
        #    channel: Microsoft-Windows-FailoverClustering/Operational
      ```
  </Collapser>
</CollapserGroup>

### ステップ 3. 主要な属性を定義する [#optional-config]

これらの構成パラメータは必須ではありませんが、これらの構成を`logging.yml`ファイルに適用して、ログ転送を最大限に活用することをお勧めします。

<CollapserGroup>
  <Collapser
    id="attributes"
    title="属性"
  >
    キーと値のペアとして指定されたカスタム属性のリスト。ログとともに追加のデータを送信するために使用でき、その後クエリを実行できます。`attributes`構成パラメーターは、任意のログソースで使用できます。

    <Callout variant="important">
      `attributes`構成パラメーターは、外部Fluent Bit構成を介して（たとえば、 `fluentbit`構成パラメーターを使用して）転送されるログにカスタム属性を追加しません。このシナリオでは、 [FluentBitドキュメント](https://docs.fluentbit.io/manual/)の`record_modifier`オプションを参照する必要があります。
    </Callout>

    `attributes`構成パラメーターの一般的な使用法の1つは、 `logtype`属性を指定することです。この属性により、NewRelicのログ管理機能でサポートされている[組み込みの解析ルール](https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/#built-in-rules)の1つを活用できます。

    **例：**

    ```yml
    logs:
      - name: example-file-attributes
        file: /var/log/example.log
        attributes:
          logtype: nginx
          region: example-us-02
          team: A-team
      - name: example-tcp-attributes
        tcp:
          uri: tcp://0.0.0.0:2345
          format: json
        attributes:
          logtype: nginx
          region: example-us-02
          team: B-team
    ```
  </Collapser>

  <Collapser
    id="automatically-inserted-attributess"
    title="インフラストラクチャエージェントによって自動的に挿入される属性"
  >
    インフラストラクチャエージェントは、便宜上、ログ属性を自動的に挿入します。それらのいくつかはログレコードに挿入されますが、その他はログフォワーダーのセットアップ中に使用した構成パラメーターに依存します。

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px" }}>
            属性名
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `entity.guids`
          </td>

          <td>
            常に挿入されます。

            インフラストラクチャエージェントは、New Relicによって割り当てられた[エンティティGUID](/attribute-dictionary/span/entityguid)を挿入して、実行されているホストを識別します。`entity.guids`フィールドで使用できます。

            注：キャプチャされたログがAPMを使用してインストルメント化されたアプリケーションに属している場合、 `entity.guids`フィールドには、インフラストラクチャのエンティティGUIDとAPMのGUIDの両方が、パイプ（|）区切り文字で区切られて含まれます。
          </td>
        </tr>

        <tr>
          <td>
            `fb.input`
          </td>

          <td>
            常に挿入されます。

            ログのキャプチャに使用される基になる[FluentBit入力プラグインタイプ](https://docs.fluentbit.io/manual/pipeline/inputs)。現在、その値は`tail` 、 `systemd` 、 `winlog` 、 `syslog` 、および`tcp`です。
          </td>
        </tr>

        <tr>
          <td>
            `filePath`
          </td>

          <td>
            `file`入力タイプを使用するときに挿入されます。

            監視対象のファイルの絶対ファイルパス。
          </td>
        </tr>

        <tr>
          <td>
            `hostname`
          </td>

          <td>
            常に挿入されます。

            インフラストラクチャエージェントを実行しているマシン/VM/コンテナのホスト名。
          </td>
        </tr>

        <tr>
          <td>
            `plugin.type`
          </td>

          <td>
            常に挿入されます。

            ログのキャプチャに使用されるユーティリティを示します。この場合、それはインフラストラクチャエージェント自体であるため、この属性の値は常に`nri-agent`です。
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="pattern"
    title="パターン"
  >
    レコードをフィルタリングするための正規表現。`tail` 、 `systemd` 、 `syslog` 、および`tcp` （形式`none`の場合のみ）のソースでのみサポートされます。

    このフィールドは、Unixシステムの`grep -E`と同じように機能します。たとえば、キャプチャされている特定のファイルについて、次を使用して`WARN`または`ERROR`のいずれかを含むレコードをフィルタリングできます。

    ```yml
    - name: only-records-with-warn-and-error
      file: /var/log/logFile.log
      pattern: WARN|ERROR
    ```

    デフォルトでは、フィルタリングは適用されません。
  </Collapser>

  <Collapser
    id="max_line_kb"
    title="max_line_kb"
  >
    ログエントリ/行の最大サイズ（KB単位）。ログエントリが制限を超えると、スキップされます。デフォルトは`128`です。
  </Collapser>

  <Collapser
    id="fluentbit"
    title="fluentbit"
  >
    外部[FluentBit](https://fluentbit.io/)構成およびパーサーファイル。定義されている場合、それらはインフラストラクチャエージェントによって生成された既存の構成ファイルおよびパーサーファイルとマージされます。

    インフラストラクチャエージェントは、 `logging.d`ディレクトリにある構成ファイルを処理し、適切な`[INPUT]` 、 `[FILTER]` 、および`[OUTPUT]`セクションを含むランタイムFluentBit構成ファイルを生成します。オプションで、 `fluentbit`オプションを介して外部Fluent Bit構成ファイルを提供した場合は、 `@INCLUDE`も宣言します。

    ランタイム ファイルで[`[SERVICE]`セクション](https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/configuration-file)が定義されていないため、すべてのデフォルトの Fluent Bit 構成値が残されています。外部の Fluent Bit 構成ファイルで独自の`[SERVICE]`セクションを定義し、 `fluentbit`オプションを介して含めることで、Fluent Bit のデフォルト設定をオーバーライドできます。

    **パラメーター：**

    `config_file:` 既存の Fluent Bit 構成ファイルへのパス。重複するソースがあると、ログ UI で重複したメッセージが表示されることに注意してください。

    `parsers_file:` 既存のFluentBitパーサーファイルへのパス。次のパーサー名が予約されています： `rfc3164` 、 `rfc3164-local` 、および`rfc5424` 。

    <Callout variant="important">
      インフラストラクチャエージェントでは、このドキュメントで説明されているように、 `logging.d/`ディレクトリのYAMLファイルで単純なログ転送構成を定義することにより、最も一般的なユースケースのログを転送できます。これらのファイルは、適切な形式と適切な構成デフォルトでFluentBit構成ファイルに内部的に変換されます。New Relicは、生成された構成ファイルが正しく機能することを保証するため、これらの構成オプションの公式サポートを提供します。

      それでも、サポートされている構成オプションでカバーされていないユースケースでは、 `fluentbit` 、 `config_file` 、および`parsers_file`オプションを使用して外部で生成されたFluentBit構成およびパーサーファイルを使用する可能性を提供します。

      この場合、提供された構成は完全に任意であり、エージェントによって生成/検証されていないため、転送されたログの正しい動作を保証できないことに注意してください。したがって、New Relicは、これらのオプションで指定された外部構成を公式にサポートしていません。
    </Callout>
  </Collapser>
</CollapserGroup>

### サンプル構成ファイル [#running-modes]

YAML形式の`logging.d/`構成ファイルの例を次に示します。その他の構成例[については、インフラストラクチャエージェントリポジトリを参照してください](https://github.com/newrelic/infrastructure-agent/tree/master/assets/examples/logging)。

<CollapserGroup>
  <Collapser
    id="configuration-file"
    title="logging.d/sample.yaml"
  >
    ```yml
    # Remember to only use spaces for indentation

    logs:
      # Example of 'file' source
      - name: file-with-attributes
        file: /var/log/test.log # Path to a single file or pattern
        attributes: # You can use custom attributes to enrich your data
          logtype: nginx
          team: The A Team
        pattern: Error # Regular expression to filter log entries

      # Example of 'systemd' source (Linux only)
      - name: systemd-example
        systemd: cupsd

      # Examples of 'syslog' source, one per protocol
      # TCP network socket
      - name: syslog-tcp-test
        syslog:
          uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format
          parser: rfc5424 # Default syslog parser is rfc3164
      # UDP network socket
      - name: syslog-udp-test
        syslog:
          uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format
        max_line_kb: 35

      # Paths for Unix sockets are defined by combining protocol and path:
      # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket
      # Unix TCP domain socket
      - name: syslog-unix-tcp-test
        syslog:
          uri: unix_tcp:///var/unix-tcp-socket-test
          unix_permissions: 0666 # Default is 0644. Change at your own risk
      # Unix UDP domain socket
      - name: syslog-unix-udp-test
        syslog:
          uri: unix_udp:///var/unix-udp-socket-test
          parser: rfc5424

      # Examples of 'tcp' source for formats 'none' and 'json'
      - name: tcp-simple-test
        tcp:
          uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format
          format: none # Raw text - this is default for 'tcp'
          separator: \t # String for separating raw text entries
        attributes: # You can add custom attributes to any source of logs
          tcpFormat: none
          someOtherAttribute: associatedValue
        max_line_kb: 32
      - name: tcp-json-test
        tcp:
          uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format
          format: json
        attributes:
          tcpFormat: json
          yetAnotherAttribute: 12345

      # Example of Fluent Bit configuration import
      - name: fluentbit-import
        fluentbit:
          config_file: /path/to/fluentbit.config
          parsers_file: /path/to/fluentbit/parsers.conf
    ```
  </Collapser>
</CollapserGroup>

### ステップ 4. ログデータを表示する [#find-data]

すべてが正しく構成され、データが収集されている場合は、次の場所にログと関連するテレメトリデータが表示されます。

* New Relic UI で選択したホストの**概要**ページ: **[one.newrelic.com](https://one.newrelic.com/all-capabilities) > Explorer**または**Infrastructure > Hosts > (エンティティを選択) > Logs**に移動します。
* [ログUI](https://one.newrelic.com/launcher/logger.log-launcher)
* [NRQL クエリ](/docs/chart-builder/use-chart-builder/choose-data/use-advanced-nrql-mode-specify-data)を実行するためのツール。たとえば、次のようなクエリを実行できます。

```sql
SELECT * FROM Log
```

## オンホスト統合のログを有効にする [#on-host]

インフラストラクチャエージェントをインストールすると、最も一般的なオンホスト統合の自動ログ解析と転送を1つのステップで有効にできます。この機能を有効にするには、 `on-host-log.yml.example`ファイルの名前を`on-host-log.yml`に変更します。完了すると、統合のログが自動的に解析され、NewRelicに送信されます。

このオプションは、[サポートされているLinuxプラットフォーム](#requirements)で使用できます。

オンホスト統合ログ転送機能を有効にするには：

<CollapserGroup>
  <Collapser
    id="elastic-search-logs"
    title="Elasticsearchログ"
  >
    `elasticsearch-log.yml.example`ファイルを`elasticsearch-log.yml`にコピー（または名前変更）して、ElasticsearchJSON形式の自動ログ解析とNewRelicへの転送を有効にします。エージェントを再起動する必要はありません。

    **例：**

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/elasticsearch-log.yml.example /etc/newrelic-infra/logging.d/elasticsearch-log.yml
    ```
  </Collapser>

  <Collapser
    id="mysql-logs"
    title="MySQLログ"
  >
    `mysql-log.yml.example`ファイルを`mysql-log.yml`にコピー（または名前変更）して、MySQLエラーログの自動解析とNewRelicへの転送を有効にします。エージェントを再起動する必要はありません。

    **例：**

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/mysql-log.yml.example /etc/newrelic-infra/logging.d/mysql-log.yml
    ```
  </Collapser>

  <Collapser
    id="nginx-logs"
    title="NGINXログ"
  >
    `nginx-log.yml.example`ファイルを`nginx-log.yml`にコピー（または名前変更）して、自動NGINXアクセスとエラーログの解析およびNewRelicへの転送を有効にします。エージェントを再起動する必要はありません。

    **例：**

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/nginx-log.yml.example /etc/newrelic-infra/logging.d/nginx-log.yml
    ```
  </Collapser>

  <Collapser
    id="rabbitmq-logs"
    title="Rabbitmqログ"
  >
    `rabbitmq-log.yml.example`ファイルを`rabbitmq-log.yml`にコピー（または名前変更）して、Rabbitmqエラーログの自動解析とNewRelicへの転送を有効にします。エージェントを再起動する必要はありません。

    **例：**

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/rabbitmq-log.yml.example /etc/newrelic-infra/logging.d/rabbitmq-log.yml
    ```
  </Collapser>

  <Collapser
    id="redis-logs"
    title="Redisログ"
  >
    `redis-log.yml.example`ファイルを`redis-log.yml`にコピー（または名前変更）して、Redisエラーログの自動解析とNewRelicへの転送を有効にします。エージェントを再起動する必要はありません。

    **例：**

    ```bash
    sudo cp /etc/newrelic-infra/logging.d/redis-log.yml.example /etc/newrelic-infra/logging.d/redis-log.yml
    ```
  </Collapser>
</CollapserGroup>

## Linuxtarballを使用してインストールされたエージェントでログ転送を有効にする [#tarball-install]

インフラストラクチャ監視用のカスタムLinuxインストールプロセスを使用すると、インストールプロセスのすべての側面を調整し、ファイルとフォルダーをマシンに配置できます。[支援](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-assisted-install-infrastructure-agent-linux)または[手動](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/linux-installation/tarball-manual-install-infrastructure-agent-linux)のtarballインストールプロセスを選択した場合は、次の手順に従ってログフォワーダー機能を実装します。

1. 次のディレクトリを作成します。

* `/var/db/newrelic-infra/newrelic-integrations/logging`
* `/etc/newrelic-infra/logging.d`

2. 次のようなコマンドを実行して、New Relicの[fluent-bit-package（RPM）](https://github.com/newrelic/fluent-bit-package/releases)をダウンロードしてインストールします。

   ```shell
   yum localinstall td-agent-bit-<some-version>.rpm`
   ```

3. New Relicの[fluentbitプラグイン](https://github.com/newrelic/newrelic-fluent-bit-output/releases)をダウンロードし、 `/var/db/newrelic-infra/newrelic-integrations/logging/out_newrelic.so`として保存します。

4. [この Github リポジトリ](https://github.com/newrelic/fluent-bit-package/blob/main/parsers.conf)から`parsers.conf`ファイルをダウンロードまたはコピーし、 `/var/db/newrelic-infra/newrelic-integrations/logging/parsers.conf`として保存します。

<InstallFeedback/>

## トラブルシューティング [#troubleshoot]

ログフォワーダーの構成で問題が発生した場合は、次のトラブルシューティングのヒントを試してください。

<CollapserGroup>
  <Collapser
    className="freq-link"
    id="log-data"
    title="ログデータなし"
  >
    ログ管理機能を有効にしてもデータが表示されない場合は、[標準のログトラブルシューティング手順](/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/)に従ってください。
  </Collapser>

  <Collapser
    className="freq-link"
    id="no-data"
    title="ファイルをテーリングするときにデータが表示されない"
  >
    ログ転送機能では、エージェントがデータソースを読み取るためのアクセス許可を持っている必要があります。インフラストラクチャエージェントを[特権モードまたは非特権モード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行する場合は、転送するログファイル（およびそのパス内の中間ディレクトリ）が、 `nri-agent`を実行しているユーザーが読み取れることを確認してください。

    **例：Linuxでのファイルアクセスの確認**

    `nri-agent`ユーザーがファイル`/var/log/restrictedLogs/logFile.log`を監視できるかどうかを確認しましょう。Linuxでは、 `namei`コマンドを使用して簡単なチェックを行うことができます。

    ```bash
    sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log
    f: /var/log/restrictedLogs/logFile.log
    drwxr-xr-x root root /
    drwxr-xr-x root root var
    drwxrwxr-x root syslog log
    drwxr--r-- root root restrictedLogs
    logFile.log - No such file or directory
    ```

    ファイルが`nri-agent`ユーザーに表示されないため、このコマンドは失敗しました。前の出力を調べることにより、 `restrictedLogs`ディレクトリに`others`の実行フラグがないことを検出できます。

    これを修正するには、次を実行します。

    ```bash
    sudo chmod 755 /var/log/restrictedLogs
    ```

    次に、ファイルアクセスを再度確認します。

    ```bash
    # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log
    f: /var/log/restrictedLogs/logFile.log
    drwxr-xr-x root root /
    drwxr-xr-x root root var
    drwxrwxr-x root syslog log
    drwxr-xr-x root root restrictedLogs
    -rw-r----- vagrant vagrant logFile.log
    ```

    これで、ファイルは`nri-agent`ユーザーに表示されます。`nri-agent`ユーザーもファイルを読み取れるようにする必要があります。これを確認するには、次を使用します。

    ```bash
    # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log
    head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied
    ```

    この例では、ファイルに`others`グループ（ `vagrant`および`vagrant`ユーザーグループ以外のユーザー）の読み取り権限がありません。`others`に読み取り権限を付与することでこれを修正できますが、アプリケーションは再起動時にこれらの権限を変更する可能性があります。

    これを回避するには、 `nri-agent`ユーザーを`vagrant`ユーザーグループに追加することをお勧めします。
  </Collapser>

  <Collapser
    className="freq-link"
    id="syslog"
    title="Syslogソケットを介してキャプチャするときにデータが表示されない"
  >
    ログ転送機能には、エージェントがデータソースを読み取る権限を持っている必要があります。インフラストラクチャエージェントを[特権モードまたは非特権モード](/docs/infrastructure/install-configure-infrastructure/linux-installation/linux-agent-running-modes)で実行する場合：

    * Unixドメインソケットファイルを使用している場合は、`nri-agent`ユーザーがこれらのファイルにアクセスできること（前のセクションを参照してください）と、他のユーザーが読み取りおよび書き込み権限（`666`）を持っていることを確認してください。 `nri-agent`よりも多くのユーザーが書き込み可能です。

    * IPソケットを使用している場合は、使用しているポートがシステムで予約されているポートではないことを確認してください（たとえば、ポート`80`など）。

      ログ管理を有効にしてもデータが表示されない場合は、[標準のログ管理のトラブルシューティング手順](/docs/logs/new-relic-logs/troubleshooting/no-data-appears-logs)に従ってください。
  </Collapser>

  <Collapser
    className="freq-link"
    id="proxy"
    title="インフラストラクチャエージェントプロキシを使用してデータが表示されない"
  >
    [インフラストラクチャ エージェントの構成ガイドライン](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings#proxy)で説明されているように、 `proxy`パラメータは HTTP または HTTPS のいずれかを使用し、https&#x3A;//user:password@hostname:port の形式にする必要があります。エージェントは HTTP または HTTPS なしでパラメーターを解析できますが、ログ フォワーダーはできません。エージェントの詳細ログに次のようなエラーが表示されます。

    ```
    [ERROR] building HTTP transport: parse \"hostname:port\":
    first path segment in URL cannot contain colon
    ```

    この問題を解決するには、 `newrelic-infra.yml`ファイルをチェックし、 `proxy`パラメータがこのフォームに準拠していることを確認してください。

    証明書を指定するために`caBundleFile`または`caBundleDir`を使用している場合は、OSごとに以下のルールに従うことをお勧めします。

    **Linux** `HTTP`プロキシの場合、証明書を設定する必要はありません。プラグインはシステム証明書をロードし、NewRelicはログをロギングエンドポイントに送信します。ただし、 `caBundleFile`または`caBundleDir`パラメータのいずれかを使用して、プロキシ自己署名証明書（PEMファイル）を指定できます。

    **ウィンドウズ**

    * `HTTP`プロキシの場合、証明書を設定する必要はありません。プラグインはシステム証明書をロードします。

    * `HTTPS`の場合、次のいずれかの方法で構成できます。

    * プロキシ証明書をシステムプールにインポートする（推奨）MMCツールを使用して、プロキシ自己署名証明書（PEMファイル）をインポートします。[このリンク](https://www.ssls.com/knowledgebase/how-to-import-intermediate-and-root-certificates-via-mmc/)を参照し、**ステップ2**で、 `Intermediate Certification Authorities`ではなく`Trusted Root Certification Authorities`にインポートしてください。

    * `caBundleFile`および`caBundleDir`パラメーターの使用Windowsでは、システム証明書プールからの証明書と`caBundleFile` `caBundleDir`パラメーターで指定された証明書の両方をロードすることはできません。したがって、 `caBundleFile`または`caBundleDir`を使用している場合は、次の証明書が同じPEMファイル（ `caBundleFile`を使用している場合）または同じディレクトリ（ `caBundleDir`を使用している場合）に配置されていることを確認してください。

    * プロキシ証明書 ( `HTTPS`プロキシであるため)。

    * ロギング エンドポイント証明書 (例:`https://log-api.newrelic.com/log/v1` )。

    * インフラストラクチャ エージェント証明書 (例:`https://infra-api.newrelic.com` )。

      次のコマンドを実行して、証明書を確認できます。

      ```bash
      # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com
      ```
  </Collapser>

  <Collapser
    className="freq-link"
    id="agent-logs"
    title="インフラストラクチャエージェントのログをNewRelicに送信する"
  >
    独自のログをNewRelicに送信するようにインフラストラクチャエージェントを設定できます。これは、ログ転送、エージェントに関する問題のトラブルシューティング、または[サポート](https://support.newrelic.com/)に連絡するときに役立ちます。

    <Callout variant="important">
      トレース ログは、大量のデータを非常に迅速に生成します。ディスク容量の消費とデータの取り込みを減らすために、ログの生成が終了したら、必ず`level: info` (またはそれ以下) を設定してください。
    </Callout>

    インフラストラクチャエージェントのログをNewRelicに転送するには：

    1. `newrelic-infra.yml`ファイルを編集します。

    2. 次の構成スニペットを追加して、New Relic へのログ転送を有効にします。

       ```yml
       log:
         level: trace # Recommended: Helps with troubleshooting
         forward: true # Enables sending logs to New Relic
         format: json # Recommended: Enable agent logging in JSON format
         stdout: false # On Windows and systems that don't use `systemd` or where `journald` is inaccessible
       ```

    3. [エージェントを再起動して](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)、新しい設定をロードします。

       この設定では、エージェントがトラブルシューティングモードに設定されますが、ログフォワーダ（ [Fluent Bit](https://fluentbit.io/)に基づく）は非冗長モードで続行されます。
  </Collapser>

  <Collapser
    className="freq-link"
    id="fluentbit-logs"
    title="ログ転送で詳細モードを有効にする (Fluent Bit)"
  >
    場合によっては、ログ フォワーダー自体に問題が発生することがあります。たとえば、Windows ログ イベントの送信時や特定のログ ファイルへのアクセス時に、特定のチャネルへのアクセスに問題が発生する場合があります。このような状況では、ログ フォワーダーの冗長モードを有効にすることもできます。

    <Callout variant="important">
      トレース ログは、大量のデータを非常に迅速に生成します。ディスク容量の消費とデータの取り込みを減らすために、ログの生成が終了したら、必ず`level: info` (またはそれ以下) を設定してください。
    </Callout>

    1. `newrelic-infra.yml`ファイルを編集します。

    2. 次の構成スニペットを追加して、Fluent Bit verbose ログを有効にします。

       ```yml
       log:
         level: trace
         forward: true # Enables sending logs to New Relic
         format: json # Recommended: Enable agent logging in JSON format
         stdout: false # On Windows and systems that don't use `systemd` or where `journald` is inaccessible
         include_filters:
           traces:
             - supervisor # Required to see verbose logs from Fluent Bit
       ```

    3. [エージェントを再起動して](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)、新しい設定をロードします。
  </Collapser>

  <Collapser
    className="freq-link"
    id="no-fb"
    title="FluentBitがインフラエージェントで開始しない"
  >
    <Callout variant="important">
      FluentBitのテールプラグインはネットワークドライブをサポートしていません。
    </Callout>

    2016より前のバージョンのLinuxの場合、OpenSSLライブラリを1.1.0に更新する必要がある場合があります（以上）。この問題があるかどうかを確認するには：

    1. 次のコマンドを実行して、 `infra-agent`がFluentBitを開始したかどうかを確認します。

       ```bash
       ps -aux | grep td-agent-bit
       ```

    2. 実行されていない場合は、 `/var/db/newrelic-infra/newrelic-integrations/logging`に移動して実行します。

       ```bash
       ./fluent-bit -i systemd -o stdout
       ```

    3. 次のエラーが発生した場合は、OpenSSLを1.1.0に更新してください以上：

       ```
       error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory
       ```
  </Collapser>

  <Collapser
    className="freq-link"
    id="windows-runtime-error"
    title="Windowsでのランタイムエラー"
  >
    Windowsでログ転送を有効にすると、次のエラーメッセージのいずれかが表示される場合があります。

    ```
    The code execution cannot proceed because VCRUNTIME140.dll was not found.
    ```

    また

    ```
    error="exit status 3221225781" process=log-forwarder
    ```

    これは、DLLが見つからないことが原因です。

    この問題を解決するには、必要に応じて[Microsoft VisualC++再頒布](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)可能パッケージをインストールします。

    * [x64](https://aka.ms/vs/16/release/vc_redist.x64.exe)
    * [x86](https://aka.ms/vs/16/release/vc_redist.x86.exe)
  </Collapser>

  <Collapser
    className="freq-link"
    id="too-many-files"
    title="大量のログファイルをテーリングするときのエラー（Linux）"
  >
    大量のファイルを追尾しようとすると、次のいずれかのエラーメッセージが表示されるのが一般的です。

    * `Too many open files`
    * `The user limit on the total number of inotify watches was reached or the kernel failed to allocate a needed resource`

    オペレーティングシステムは、割り当て可能なファイル記述子の最大量（通常はデフォルトで1024）と、割り当て可能なinotifyウォッチの最大量（通常はデフォルトで8192）を定義します。これらの制限を超えようとするプロセスは失敗し、上記のエラーの1つを返します。

    ログの転送に使用する基盤となるテクノロジーである[FluentBit](https://fluentbit.io/)は、1つのファイル記述子を開き、転送するように構成したファイルごとにinotifyウォッチを設定します。さらに、このセクションの執筆時点では、Fluent Bitは通常の操作に32個のファイル記述子の追加セットを使用し、シャットダウン時に別の追加ファイル記述子を使用します。したがって、**大量のファイルをキャプチャするには、ファイル記述子とinotifyの監視制限の両方が、調整するログファイルの量よりもわずかに大きいことを確認する必要があります**。

    次の手順は、10,000個のログファイルを追跡する場合にこれらの制限を増やす方法をまとめたものです。また、インフラストラクチャエージェントが`root` [実行モード](/docs/infrastructure/install-infrastructure-agent/linux-installation/linux-agent-running-modes/)でインストールされていることを前提としているため、 `root`ユーザーを使用して実行する必要があります。

    1. プロセスごとのファイル記述子の量の現在のハード制限を確認してください。通常、この制限は非常に高く、変更する必要はありません。

       ```bash
       ulimit -Hn
       ```

    2. 次の行を`/etc/security/limits.conf`に追加します。Fluent Bitが機能する必要のある追加のファイル記述子を割り当てることができるように、ここでは`10000`ではなく`10100`の制限を指定しました。

       ```bash
       root    soft    nofile  10100  # replace root by nri-agent for non-root (privileged and unprivileged) installations
       ```

    3. 再起動時に前の制限が適用されるように、次の行を`/etc/pam.d/common-session`に追加します。

       ```bash
       session required pam_limits.so
       ```

    4. 次の行を`/etc/sysctl.conf`に追加して、ユーザーごとに許可されるinotifyウォッチャーの数を増やします。ここでは、 `10000`ではなく`18192`の制限を指定して、 `root`ユーザーが引き続き`8192`のinotifyウォッチ（デフォルト値）を使用できるようにしました。

       ```bash
       fs.inotify.max_user_watches=18192
       ```

    5. システムを再起動します。

    6. 次のコマンドを実行して、新しい制限が適用されていることを確認します。

       ```bash
       ulimit -Sn                                    # Should return 10100
       cat /proc/sys/fs/inotify/max_user_watches     # Should return 18192
       ```

       [開いているファイルの制限を増やす](https://tecadmin.net/increase-open-files-limit-ubuntu/)[方法、またはinotifyウォッチを増やす](https://dev.to/rubiin/ubuntu-increase-inotify-watcher-file-watch-limit-kf4)方法の詳細をご覧ください。
  </Collapser>

  <Collapser
    className="freq-link"
    id="install-fb-version"
    title="特定のFluentBitバージョンをインストールする（Linux）"
  >
    バージョン[1.19.0](/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1190) （またはSLES 12.5の場合はバージョン1.20.3）より前は、Linuxインフラストラクチャエージェントに[FluentBit](/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1203)バイナリがバンドルされていました。このバージョン以降、FluentBitは個別の`recommended`パッケージ依存関係として含まれるようになりました。

    これは、Fluent Bitをエージェントとは別にインストール、更新、またはダウングレードできることを意味します。便宜上、インフラストラクチャが存在する同じリポジトリにいくつかのFluent Bitパッケージが含まれているため、FluentBitをアップグレードするために追加のリポジトリをインストールする必要はありません。

    エージェントは、最初にインストールしたときに、利用可能な最新バージョンを使用してFluentBitを自動的にインストールすることに注意してください。最初のインストール後、Linuxパッケージで通常行うようにFluentBitをアップグレードできます。

    次のコマンドを実行して、使用可能なFluentBitバージョンを一覧表示できます。

    RPM：

    ```bash
    sudo yum check-update
    yum list td-agent-bit --showduplicates
    ```

    DEB：

    ```bash
    sudo apt update
    apt-cache showpkg td-agent-bit
    ```

    特定のFluentBitバージョンにアップグレードするには、次のコマンドを実行します（次の例では、バージョン`1.8.12`が使用されています）。

    RPM：

    ```bash
    # Remove command only required when downgrading to a previous version
    sudo yum remove td-agent-bit
    sudo yum install td-agent-bit-1.8.12-1
    ```

    DEB：

    ```bash
    sudo apt install td-agent-bit=1.8.12
    ```
  </Collapser>

  <Collapser
    className="freq-link"
    id="rollback-after-fluent-bit-2"
    title="Linux 上のインフラストラクチャ エージェント 1.42.0 後の Fluent-bit 1.x へのロールバック"
  >
    td-agent-bit は次のディストリビューションでは使用できないため、ロールバックできないことに注意してください。

    * CentOS 9 ストリーム (Rocky Linux および AlmaLinux を含む)
    * レッドハット9
    * Ubuntu 22.04.x
    * オープン スース (SLES) 15.4
    * Amazon Linux 2023

    td-agent-bit に戻したい場合は、以下の手順に従ってください。

    1. 任意のテキスト エディタを使用してファイル `/etc/newrelic-infra.yml` を開きます。
    2. ファイルの最後に次の行を追加します: `fluent_bit_exe_path: /opt/td-agent-bit/bin/td-agent-bit`。
    3. 変更を保存します。
    4. コマンド `sudo systemctl restart newrelic-infra`を実行して、インフラストラクチャ エージェントを再起動します。

    これらの手順を完了すると、インフラストラクチャ エージェントは、fluent-bit の代わりに td-agent-bit を使用するように構成されます。
  </Collapser>
</CollapserGroup>

## 次は何ですか？ [#what-next]

[ログ UI](/docs/logs/log-management/ui-data/use-logs-ui/)を使用して、プラットフォーム全体のログ データを調べます。

* [ログインコンテキスト](/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/)機能を使用してログを転送することにより、アプリケーションとプラットフォームのパフォーマンスデータの両方をより深く把握できます。
* [アラートを](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions/)設定します。
* [データをクエリ](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/)し、[ダッシュボードを作成します](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/)。

## ログ転送を無効にする [#uninstall]

ログ転送機能を無効にするには、 `logging.d`ディレクトリに移動し、[構成](#configure)プロセス中に最初に追加された`.yml`拡張子のファイルを削除します。

* Linux： `/etc/newrelic-infra/logging.d/`
* ウィンドウズ： `C:\Program Files\New Relic\newrelic-infra\logging.d\`