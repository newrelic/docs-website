---
title: OpenLIT による LLM オブザーバビリティ
tags:
  - Integrations
  - LLM observability with OpenTelemetry
  - GenAI Observability with OpenTelemetry
  - OpenTelemetry
  - OpenLIT
metaDescription: Set up OpenTelemetry-based LLM observability with New Relic and OpenLIT.
freshnessValidatedDate: '2024-10-08T00:00:00.000Z'
translationType: machine
---

OpenTelemetry一般的なアプリケーション データ (トレース、メトリクス、ログ) を収集するための強力な標準を提供しますが、AI モデルに固有の主要パフォーマンス指標 (KPI) を取得する機能がありません。 パフォーマンス追跡、ローソンの使用状況、コスト、LLM プロンプトと応答の形式でのユーザー インタラクション データなどの重要なメトリクスは、効果的な LLM アプリケーション監視とトラブルシューティングに不可欠です。

LLM の監視におけるこのギャップを埋めるために、OpenLIT がカスタマイズされたソリューションとして登場しました。 OpenLIT は、OpenTelemetry フレームワーク上に構築されており、スムーズに統合され、機能を拡張するオープンソース ツールです。 OpenAI、Anthropic、Pinecone、LangChain など、広く使用されている AI フレームワークをサポートしています。 さらに、OpenTelemetry ベースの GPU 監視機能をすぐに使用できます。

OpenLIT の主な利点:

* **LLM と VectorDB のパフォーマンスの高度な監視**: OpenLIT は、LLM と VectorDB の使用状況の詳細なパフォーマンスとコスト分析のためのトレースとメトリクスを自動的に生成し、リソースの使用を最適化し、運用環境などのさまざまな環境にわたって効率的に拡張するのに役立ちます。

* **カスタムおよび微調整されたモデルのコスト追跡**: カスタム JSON ファイルを通じて正確なコスト追跡が可能になり、正確な予算編成とプロジェクト固有のニーズとの調整が可能になります。

* **OpenTelemetryネイティブ SDK とベンダーニュートラル SDK** : OpenLIT はOpenTelemetryのネイティブ サポートを使用して構築されており、プロジェクトとシームレスにブレンドできます。 このベンダーニュートラルのアプローチは統合への障壁を減らし、OpenLIT をさらに複雑にするのではなく、ソフトウェアスタックの直感的な部分にします。

OpenLIT により、開発者は OpenTelemetry の強みを活用しながら、効果的な LLM 監視とパフォーマンスの最適化に必要な追加機能を獲得できるようになります。

## 始める前に [#prereqs]

* New Relicアカウントに[サインアップ](https://newrelic.com/signup)します。
* データを報告するNewRelicアカウントの[ライセンスキー](https://one.newrelic.com/launcher/api-keys-ui.launcher)を取得します。

## OpenLIT で LLM モデルを計画する [#instrument]

を使用したOpenTelemetry ベースのAPM 監視の一般的なセットアップ手順に従います。New Relic

<Steps>
  <Step>
    ### トレースとメトリクスのルート [#route-traces]

    New Relic OpenTelemetryネイティブでサポートしているため、トレースとメトリクスをNew Relicのエンドポイントにルーティングし、 APIキーを設定するだけです。

    次のコマンドを実行して、 [OpenTelemetry Protocol](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md) (略して OTLP) エクスポーターが[New Relic OTLP エンドポイント](/docs/opentelemetry/best-practices/opentelemetry-otlp)にデータを送信できるようにします。

    ```env
    OTEL_EXPORTER_OTLP_ENDPOINT = https://otlp.nr-data.net:443
    OTEL_EXPORTER_OTLP_HEADERS = "api-key=YOUR_NEWRELIC_LICENSE_KEY"
    ```

    LangChain を使用した OpenAI LLM モデルの例をご覧ください。

    ```python
    import openlit
    import os
    from langchain_openai import ChatOpenAI

    os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'
    os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = 'https://otlp.nr-data.net:443'
    os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = 'api-key=YOUR_NEWRELIC_LICENSE_KEY'

    openlit.init()

    def add_prompt_context():
      llm = ChatOpenAI(
          model="gpt-3.5-turbo",
          temperature=0)
      chain = llm
      return chain

    def prep_prompt_chain():
      return add_prompt_context()

    def prompt_question():
      chain = prep_prompt_chain()
      return chain.invoke("explain the business of company Newrelic and it's advantages in a max of 50 words")

    if  __name__ == "__main__":
      print(prompt_question())
    ```
  </Step>

  <Step>
    ## NewRelicUIでデータを表示する [#view-data]

    アプリがインストゥルメント処理され、データをNew Relicにエクスポートするように設定されたら、 New Relic UIでデータを見つけることができるようになります。次の手順に従って、LLM オブザーバビリティの事前構築済みダッシュボードをインポートできます。

    1. <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; Dashboards**</DNT>に移動します。

    2. 右上隅にある<DNT>**Import dashboard**</DNT>をクリックします。

    3. [ここで](https://docs.openlit.io/latest/connections/new-relic#dashboard)提供されるダッシュボード JSON をコピーして貼り付けます。

    4. ダッシュボードのアカウントと権限設定を選択します。 一度設定したアカウントを変更することはできませんが、権限はいつでも変更できます。

    5. <DNT>**Import dashboard**</DNT>をクリックします。

    エンティティが見つからず、NRQL でデータが表示されない場合は、 [「OTLP トラブルシューティング」](/docs/opentelemetry/best-practices/opentelemetry-otlp-troubleshooting)を参照してください。

    <InstallFeedback />
  </Step>
</Steps>