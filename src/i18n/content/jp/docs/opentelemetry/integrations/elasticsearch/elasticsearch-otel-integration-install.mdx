---
title: Elasticsearch OpenTelemetry統合をインストールする
tags:
  - OpenTelemetry
  - Elasticsearch
  - Integrations
metaDescription: Install and configure the OpenTelemetry Collector to monitor Elasticsearch clusters and send data to New Relic.
freshnessValidatedDate: never
translationType: machine
---

New Relic Elasticsearch OpenTelemetryをインストールして、業界標準のプロトコルでElasticsearchクラスタを監視します。 このガイドでは、 Elasticsearchストラクチャからメトリクスとログを収集し、 New Relicに送信するようにOpenTelemetry Collector設定する方法について説明します。

インテグレーションをインストールするには、次の手順を実行します。

1. [始める前に](#prerequisites)- 要件と前提条件を確認してください
2. [OpenTelemetry Collector を構成する](#config)- データ収集を設定する
3. [環境変数を設定する](#start)- 認証を構成する
4. [データの検索と使用](#find-and-use)- New RelicでElasticsearchデータを表示する
5. [アラートの設定](#alerts)- プロアクティブな監視を構成する

## ステップ1: 始める前に [#prerequisites]

以下のものを用意してください:

* **必要なアクセス権限**- Elasticsearch クラスターの管理者権限と<InlinePopover type="licenseKey" />アクセス権を持つ New Relic アカウント

* **Elasticsearchバージョン 7.16 以降**- この統合には最新のElasticsearchクラスタが必要です

* **クラスタ権限の監視または管理**- セキュリティが有効な場合は、クラスタ権限の監視または管理のいずれかが必要です。 詳細については、 [Elasticsearchのセキュリティ権限に関する](https://www.elastic.co/docs/reference/elasticsearch/security-privileges)ドキュメントを参照してください。

* **ネットワーク接続**- [New Relic の OTLP 取り込みエンドポイント](/docs/opentelemetry/best-practices/opentelemetry-otlp)へのアウトバウンド HTTPS 接続 (ポート 443)

* **OpenTelemetry Collector** - ホストに[OpenTelemetry Collector Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/latest)がインストールされ、実行されています。systemd サービス ユニットが正しく作成されるように、公式パッケージ (.deb または .rpm) 経由でインストールします。

* **設定値の準備ができました**- 設定には 2 つのキーの値が必要です。

  * **Elasticsearch エンドポイント**- 実際の Elasticsearch URL (`https://localhost:9200`を置き換えてください)
  * **Cluster名**- New Relicでクラスターを識別するための一意の名前

## ステップ2: OpenTelemetry Collectorを構成する [#config]

Elasticsearchクラスタからメトリクスとログを収集するようにOpenTelemetry Collector構成します。 `/etc/otelcol-contrib/config.yaml`で設定ファイルを作成または更新します。

構成は、Elasticsearch の設定と監視要件によって異なります。以下から適切な設定を選択してください:

<CollapserGroup>
  <Collapser id="basic-config" title="メトリクスの基本設定">
    認証や SSL のない、セキュリティ保護されていない Elasticsearch クラスターが**ある場合は、ここから始めてください**。

    この設定は、認証なしでElasticsearchとホスト システムから包括的なメトリクスを収集します。

    <Callout variant="important">
      `endpoint`値を Elasticsearch クラスターのエンドポイントに置き換え、プロセッサ ブロック内の`elasticsearch.cluster.name`一意の名前で更新して、New Relic でクラスターを一意に識別します。
    </Callout>

    ```yaml
    # =================================================================================================
    # OpenTelemetry Collector Configuration for Elasticsearch and Host
    # This configuration collects metrics and logs for a complete observability solution.
    # =================================================================================================
    # -------------------------------------------------------------------------------------------------
    # Receivers
    # Receivers define how data gets into the Collector. This config uses four receivers:
    # - elasticsearch: to scrape metrics from the Elasticsearch API
    # - hostmetrics: to collect system-level metrics from the host itself
    # - filelog: to tail Elasticsearch log files
    # - otlp: to accept data from other OpenTelemetry-instrumented services
    # -------------------------------------------------------------------------------------------------
    receivers:
      elasticsearch:
        endpoint: "http://localhost:9200"
        collection_interval: 15s
        metrics:
          elasticsearch.breaker.tripped:
            enabled: true
          elasticsearch.cluster.data_nodes:
            enabled: true
          elasticsearch.cluster.health:
            enabled: true
          elasticsearch.cluster.in_flight_fetch:
            enabled: true
          elasticsearch.cluster.nodes:
            enabled: true
          elasticsearch.cluster.pending_tasks:
            enabled: true
          elasticsearch.cluster.shards:
            enabled: true
          elasticsearch.cluster.state_update.time:
            enabled: true
          elasticsearch.index.documents:
            enabled: true
          elasticsearch.index.operations.merge.current:
            enabled: true
          elasticsearch.index.operations.time:
            enabled: true
          elasticsearch.indexing_pressure.memory.total.primary_rejections:
            enabled: true
          elasticsearch.node.cache.count:
            enabled: true
          elasticsearch.node.cache.evictions:
            enabled: true
          elasticsearch.node.cache.memory.usage:
            enabled: true
          elasticsearch.node.cluster.io:
            enabled: true
          elasticsearch.node.documents:
            enabled: true
          elasticsearch.node.disk.io.read:
            enabled: true
          elasticsearch.node.disk.io.write:
            enabled: true
          elasticsearch.node.fs.disk.available:
            enabled: true
          elasticsearch.node.fs.disk.total:
            enabled: true
          elasticsearch.node.http.connections:
            enabled: true
          elasticsearch.node.ingest.documents.current:
            enabled: true
          elasticsearch.node.ingest.operations.failed:
            enabled: true
          elasticsearch.node.open_files:
            enabled: true
          elasticsearch.node.operations.completed:
            enabled: true
          elasticsearch.node.operations.current:
            enabled: true
          elasticsearch.node.operations.get.completed:
            enabled: true
          elasticsearch.node.operations.get.time:
            enabled: true
          elasticsearch.node.operations.time:
            enabled: true
          elasticsearch.node.shards.reserved.size:
            enabled: true
          elasticsearch.node.thread_pool.tasks.finished:
            enabled: true
          elasticsearch.os.cpu.load_avg.1m:
            enabled: true
          elasticsearch.os.cpu.load_avg.5m:
            enabled: true
          elasticsearch.os.cpu.load_avg.15m:
            enabled: true
          elasticsearch.os.memory:
            enabled: true
          jvm.gc.collections.count:
            enabled: true
          jvm.gc.collections.elapsed:
            enabled: true
          jvm.memory.heap.max:
            enabled: true
          jvm.memory.heap.used:
            enabled: true
          jvm.memory.heap.utilization:
            enabled: true
          jvm.threads.count:
            enabled: true
      hostmetrics:
        collection_interval: 60s # Recommended for cost savings and stability
        scrapers:
          cpu:
            metrics:
              # CPU Utilization and Time are the core metrics
              system.cpu.utilization: {enabled: true}
              system.cpu.time: {enabled: true}
          load:
            metrics:
              # Load Averages (used for system health dashboards)
              system.cpu.load_average.1m: {enabled: true}
              system.cpu.load_average.5m: {enabled: true}
              system.cpu.load_average.15m: {enabled: true}
          memory:
            metrics:
              # Memory Usage and Utilization
              system.memory.usage: {enabled: true}
              system.memory.utilization: {enabled: true}
          disk:
            metrics:
              # Disk I/O operations (throughput)
              system.disk.io: {enabled: true}
              system.disk.operations: {enabled: true}
          filesystem:
            metrics:
              # Filesystem usage (disk space capacity)
              system.filesystem.usage: {enabled: true}
              system.filesystem.utilization: {enabled: true} 
          network:
            # Since this was already working, keeping it simple is best.
            # But for completeness:
            metrics:
              system.network.io: {enabled: true}
              system.network.packets: {enabled: true}
          process:
               metrics:
                 process.cpu.utilization:
                   enabled: true
    # -------------------------------------------------------------------------------------------------
    # Processors
    # -------------------------------------------------------------------------------------------------
    processors:
      cumulativetodelta: {}
      resource/cluster_name_override:
        attributes:
          # Use the actual cluster name defined in your Elasticsearch config
          - key: elasticsearch.cluster.name
            value: "<elasticsearch-cluster-name>" # <-- REPLACE THIS WITH A UNIQUE CLUSTER NAME TO UNIQUELY IDENTIFY YOUR CLUSTER IN NEW RELIC 
            action: upsert
      # This processor adds resource attributes to all telemetry data.
      # 'service.name' is crucial for creating an entity in New Relic.
      resourcedetection:
        detectors: [ system ]
        system:
          resource_attributes:
            host.name:
              enabled: true
            host.id:
              enabled: true
            os.type:
              enabled: true 
      # This processor batches data for more efficient sending.
      batch:
        timeout: 10s
        send_batch_size: 1024
      # 1. CARDINALITY REDUCTION: Drops volatile or redundant attributes
      attributes/cardinality_reduction:
        actions:
          # Filter out VOLATILE PROCESS IDS (High churn)
          - key: process.pid
            action: delete
          - key: process.parent_pid
            action: delete
          # Filter out REDUNDANT/STATIC METADATA (Already known at the Resource level)
          - key: elasticsearch.node.version
            action: delete
          - key: os.type
            action: delete
      transform/metadata_nullify:
        # We use 'metric_statements' to run OTTL logic on the metric signal
        metric_statements:
          - context: metric  # <-- Targets the high-level Metric structure itself
            statements:
              # Sets the 'description' field to an empty string ("")
              - set(description, "")
              # Sets the 'unit' field to an empty string ("")
              - set(unit, "")      
    exporters:
      # This exporter sends all data to New Relic via OTLP/HTTP.
      otlphttp:
        endpoint: ${env:NEWRELIC_OTLP_ENDPOINT}
        headers:
          api-key: ${env:NEWRELIC_LICENSE_KEY}
    # -------------------------------------------------------------------------------------------------
    # Service
    # The service block defines the pipelines.
    # -------------------------------------------------------------------------------------------------
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [resourcedetection, resource/cluster_name_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [resourcedetection,batch]
          exporters: [otlphttp]
    ```
  </Collapser>

  <Collapser id="secure-config" title="認証＆SSL設定">
    **以下をお持ちの場合はこれを使用してください:**認証および/または SSL 証明書を備えた安全なElasticsearchクラスタ。

    上記の基本設定に認証資格情報と SSL 設定を追加します。

    ```yaml
    receivers:
      elasticsearch:
        endpoint: "https://localhost:9200"
        username: "elastic"
        password: "your_password"
        tls:
          ca_file: "/etc/elasticsearch/certs/http_ca.crt"
          insecure_skip_verify: false
        collection_interval: 15s
    ```
  </Collapser>

  <Collapser id="logging-config" title="ログを有効にする（ファイルログレシーバー）">
    **オプション:** ElasticsearchファイルをMetrixに加えてNew Relicに送信する場合は、これを含めます。

    Elasticsearchログを収集して転送するための`filelog`レシーバー設定を追加します。 `otelcol-contrib`ユーザーがログ ファイルへの`read`アクセス権を持っていることを確認してください。

    ###### Linux (ホスト) で Elasticsearch を実行している場合:

    ```yaml
    receivers:
      filelog:
        include:
          - /var/log/elasticsearch/elasticsearch.log #Replace with path of the elasticsearch log file.
          - /var/log/elasticsearch/*.log             #We can send multiple log files using regex.
    ```

    ###### Docker で Elasticsearch を実行している場合:

    ```yaml
    receivers:
      filelog:
        include:
          - /var/lib/docker/containers/*/*.log       # Replace with the container log file path. 
        operators:
          - type: move
            from: attributes.log
            to: body
    ```

    ###### サービス パイプラインにファイルログ レシーバーを追加します。

    ```yaml
    service:
      pipelines:
        logs:
          receivers: [filelog]
          processors: [resource/cluster_name_override]
          exporters: [otlphttp]
    ```

    ユーザーをグループに追加して権限を付与します。

    ```bash
    sudo usermod -a -G elasticsearch otelcol-contrib
    ```
  </Collapser>

  <Collapser id="custom-attributes" title="カスタムメタデータを追加する">
    **オプション:**環境、チーム、地域などのカスタムアトリビュートを使用してデータをタグ付けする場合は、これを含めます。

    `resource/static_override`プロセッサを使用して、カスタム メタデータ タグをすべてのメトリクスに追加します。

    ```yaml
    processors:
      resource/static_override:
        attributes:
          - key: env
            value: "production"
            action: upsert
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [resourcedetection, resource/cluster_name_override, resource/static_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [resourcedetection, resource/static_override, batch]
          exporters: [otlphttp]        

    ```
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  **APMとElasticsearchを関連付ける**: APMアプリケーションとElasticsearchを接続するには、 APMメトリクスにリソース プロパティ`es.cluster.name="your-cluster-name"`を含めます。 これにより、New Relic 内でのサービス間の可視性とトラブルシューティングの高速化が可能になります。
</Callout>

## ステップ3: 環境変数を設定する [#start]

New Relic <InlinePopover type="licenseKey" />と OTLP エンドポイントをコレクター サービスに追加して認証を構成します。

1. systemd オーバーライド ディレクトリを作成します。

   ```bash
   sudo mkdir -p /etc/systemd/system/otelcol-contrib.service.d
   ```

2. OTLP エンドポイントを使用して`environment.conf`を書き込みます。`YOUR_LICENSE_KEY` New Relicライセンスキーに置き換え、 `YOUR_OTLP_ENDPOINT`地域の適切なエンドポイントに置き換えます。 適切なエンドポイントを選択するには、OTLP エンドポイント設定[ドキュメント](https://docs.newrelic.com/docs/opentelemetry/best-practices/opentelemetry-otlp/#configure-endpoint-port-protocol)を参照してください。

   ```bash
   cat <<EOF | sudo tee /etc/systemd/system/otelcol-contrib.service.d/environment.conf
   [Service]
   Environment="NEWRELIC_OTLP_ENDPOINT=YOUR_OTLP_ENDPOINT"
   Environment="NEWRELIC_LICENSE_KEY=YOUR_LICENSE_KEY"
   EOF
   ```

3. systemd をリロードし、コレクターを再起動します。

   ```bash
   sudo systemctl daemon-reload
   sudo systemctl restart otelcol-contrib.service
   ```

## ステップ4: Elasticsearchデータを表示する [#find-and-use]

コレクターが実行されてデータが送信されると、 New RelicでElasticsearchメトリクスを表示できます。

1. **[one.newrelic.com](https://one.newrelic.com)** &gt;**Integrations &amp; Agents**に移動します
2. **Elasticsearch (OpenTelemetry)**を検索
3. **Dashboards**で、 **Elasticsearch OpenTelemetry Dashboard** \[Elasticsearch OpenTelemetryダッシュボード]をクリックします。
4. アカウントを選択し、 **View dashboard** \[ダッシュボードを表示]をクリックします

クラスタの健全性、パフォーマンス メトリクス、およびリソースの使用状況を示すダッシュボードが表示されます。

<Callout variant="tip">
  **データが表示されませんか?**データが表示されるまで数分かかる場合があります。10 分経ってもメトリクスが表示されない場合は、 [トラブルシューティング ガイドを](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-otel/troubleshooting)確認してください。
</Callout>

**データの次のステップ:**

* **メトリクスの探索**: すべての Elasticsearch メトリクスは`Metric`[イベント タイプ](/docs/data-apis/understand-data/new-relic-data-types)として保存されます
* **カスタムクエリの作成**: [NRQL](/docs/nrql/get-started/introduction-nrql-new-relics-query-language)を使用してカスタムチャートとダッシュボードを構築します
* **アラートの設定**: 手順5に進み、プロアクティブな監視を構成します。

## ステップ5: アラートを設定する [#alerts]

アラートによるプロアクティブな監視により、問題がユーザーに影響を与える前にそれを検出できます。New Relic でアラート条件を作成するには:

1. **[one.newrelic.com](https://one.newrelic.com)** &gt; **Alerts** &gt; **Alert Conditions**に移動します。
2. クリック **条件の作成**.
3. **Guided mode** \[ガイド モード]または**NRQL**書き込みビルダーのいずれかを使用して、積算を設定します。

堅牢なElasticsearch監視には、以下のまとめ設定が推奨されます。

### 重要なアラート（高優先度）

これらのアラートは、データ損失やサービス停止を引き起こす可能性のある重大なクラスタの健全性問題を監視します。

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        まとめ名
      </th>

      <th>
        閾値の根拠（条件例）
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **未割り当てのシャード数**
      </td>

      <td>
        メトリクス

        `elasticsearch.cluster.shards`

         (

        `state = 'unassigned'`

        ) は少なくとも 5 分間 0 を超えています。
      </td>
    </tr>

    <tr>
      <td>
        **健全なデータノード集計**
      </td>

      <td>
        メトリクス

        `elasticsearch.cluster.data_nodes`

        は少なくとも 5 分間、必要な最小ノード数を下回っています。
      </td>
    </tr>

    <tr>
      <td>
        **ヒープ使用量が多すぎます**
      </td>

      <td>
        ヒープ使用率 (使用済み/最大) が 5 分以上 90% を超えています。
      </td>
    </tr>

    <tr>
      <td>
        **保留中のタスクまとめ**
      </td>

      <td>
        メトリクス

        `elasticsearch.cluster.pending_tasks`

        は少なくとも 5 分間は 5 を超えています。
      </td>
    </tr>
  </tbody>
</table>

### 追加の監視アラート

これらのアラートは、パフォーマンスと運用上の問題を監視するのに役立ちます。

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        まとめ名
      </th>

      <th>
        閾値の根拠（条件例）
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **タイムスローまとめ**
      </td>

      <td>
        `elasticsearch.node.operations.time`

        の 95 パーセンタイルは、少なくとも 2 分間 5 ミリ秒を超えています。
      </td>
    </tr>

    <tr>
      <td>
        **シャードの初期化に時間がかかりすぎます**
      </td>

      <td>
        メトリクス

        `elasticsearch.cluster.shards`

         (

        `state = 'initializing'`

        ) は少なくとも 5 分間 0 を超えています。
      </td>
    </tr>

    <tr>
      <td>
        **破片の移動に時間がかかりすぎる**
      </td>

      <td>
        メトリクス

        `elasticsearch.cluster.shards`

         (

        `state = 'relocating'`

        ) は少なくとも 5 分間 0 を超えています。
      </td>
    </tr>
  </tbody>
</table>

## トラブルシューティング

インストール中に問題が発生した場合、またはNew Relicにデータが表示されない場合は、一般的な問題に対する段階的な解決策についての包括的な[トラブルシューティング ガイド](/docs/opentelemetry/integrations/elasticsearch/troubleshooting)を参照してください。