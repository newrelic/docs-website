---
title: Intégration cloudconfluente
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

New Relic propose une intégration pour collecter vos données [de streaming gérées par Confluent Cloud pour Apache Kafka](https://www.confluent.io/confluent-cloud/) . Ce document explique comment activer cette intégration et décrit les données qui peuvent être signalées.

## Prérequis

* Un compte New Relic
* Un compte Confluent Cloud actif
* Une clé API et un secret Confluent Cloud
* `MetricsViewer` accès sur le compte Confluent Cloud

## Activer l&apos;intégration [#activate]

Pour activer cette intégration, accédez à <DNT>**Integrations &amp; Agents**</DNT>, sélectionnez <DNT>**Confluent Cloud -&gt; API Polling**</DNT> et suivez les instructions.

<Callout variant="important">
  Si vous avez configuré le filtrage IP, ajoutez les adresses IP suivantes à votre filtre.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  Pour plus d&apos;informations sur les plages IP New Relic pour l&apos;intégration cloud, reportez-vous [à ce document](/docs/new-relic-solutions/get-started/networks/#webhooks). Pour obtenir des instructions sur la manière d&apos;effectuer cette tâche, reportez-vous [à ce document](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html).
</Callout>

## configuration et sondage [#polling]

Informations d&apos;interrogation par défaut pour l&apos;intégration Confluent Cloud Kafka :

* Intervalle d&apos;interrogation de New Relic : 5 minutes
* Intervalle de données Confluent Cloud : 1 minute

Vous ne pouvez modifier la fréquence d&apos;interrogation que lors de la configuration initiale.

## Afficher et utiliser les données [#find-data]

Vous pouvez [interroger et explorer vos données](/docs/using-new-relic/data/understand-data/query-new-relic-data) en utilisant le [type d&apos;événement](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels) suivant :

<table>
  <thead>
    <tr>
      <th>
        Entité
      </th>

      <th>
        Type de données
      </th>

      <th>
        Fournisseur
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Cluster
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        connecteur
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        ksql
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

Pour en savoir plus sur l’utilisation de vos données, consultez [Comprendre et utiliser les données d’intégration](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## données métriques [#metrics]

Cette intégration enregistre les données Confluent cloud Kafka pour cluster, le connecteur et ksql.

### Données Cluster

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        métrique
      </th>

      <th style={{ width: "150px" }}>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Une mesure de l&apos;utilisation du cluster. La valeur est comprise entre 0,0 et 1,0. Seul le cluster de niveau dédié possède ces données métriques.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Un indicateur de la présence d’une partition chaude causée par le débit d’entrée. La valeur est 1,0 lorsqu&apos;une partition chaude est détectée et vide lorsqu&apos;aucune partition chaude n&apos;est détectée.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Un indicateur de la présence d&apos;une partition chaude causée par le débit de sortie. La valeur est 1,0 lorsqu&apos;une partition chaude est détectée et vide lorsqu&apos;aucune partition chaude n&apos;est détectée.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de requête totaux provenant des types de requêtes spécifiés envoyés sur le réseau. Chaque échantillon correspond au nombre d&apos;octets envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de réponse totaux provenant des types de réponse spécifiés envoyés sur le réseau. Chaque échantillon correspond au nombre d&apos;octets envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de données des clients reçues du réseau. Chaque échantillon correspond au nombre d&apos;octets reçus depuis l&apos;échantillon de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de données des clients envoyés sur le réseau. Chaque échantillon correspond au nombre d&apos;octets envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;enregistrements reçus. Chaque échantillon correspond au nombre d&apos;enregistrements reçus depuis l&apos;échantillon de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;enregistrements envoyés. Chaque échantillon correspond au nombre d&apos;enregistrements envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre de partitions.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Le décalage entre le décalage validé d&apos;un membre du groupe et le niveau d&apos;eau élevé de la partition.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;authentifications réussies. Chaque échantillon correspond au nombre d&apos;authentifications réussies depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre de connexions authentifiées actives.
      </td>
    </tr>
  </tbody>
</table>

### Données du connecteur

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        métrique
      </th>

      <th style={{ width: "150px" }}>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta du nombre total d&apos;enregistrements envoyés à partir des transformations et écrits dans Kafka pour le connecteur source. Chaque échantillon correspond au nombre d&apos;enregistrements envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `connector_status`
      </td>

      <td>
        Bit
      </td>

      <td>
        L&apos;état d&apos;un connecteur dans le système. Sa valeur est toujours fixée à 1, signifiant la présence du connecteur. L&apos;état opérationnel actuel du connecteur est identifié via la tag métrique.status.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_status`
      </td>

      <td>
        Bit
      </td>

      <td>
        L&apos;état de la tâche d&apos;un connecteur au sein du système. Sa valeur est toujours définie sur 1, signifiant la présence de la tâche du connecteur. L&apos;état opérationnel actuel du connecteur est identifié via la tag métrique.status.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_avg`
      </td>

      <td>
        Compter
      </td>

      <td>
        La taille moyenne du lot (mesurée par le nombre d&apos;enregistrements) par minute. Pour un connecteur source, il indique la taille moyenne du lot envoyé à Kafka. Pour un connecteur de récepteur, il indique la taille moyenne du lot lu par la tâche de récepteur.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_max`
      </td>

      <td>
        Compter
      </td>

      <td>
        La taille maximale du lot (mesurée par le nombre d&apos;enregistrements) par minute. Pour un connecteur source, il indique la taille maximale du lot envoyé à Kafka. Pour un connecteur de récepteur, il indique la taille maximale du lot lu par la tâche du récepteur.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta du nombre total d&apos;enregistrements reçus par le connecteur récepteur. Chaque échantillon correspond au nombre d’enregistrements reçus depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta du nombre total d&apos;enregistrements reçus par le connecteur récepteur. Chaque échantillon correspond au nombre d’enregistrements reçus depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets totaux reçus par le connecteur récepteur. Chaque échantillon correspond au nombre d&apos;octets reçus depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `dead_letter_queue_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;enregistrements de file d&apos;attente de lettres mortes écrits dans Kafka pour le connecteur de récepteur. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>
  </tbody>
</table>

### données ksql

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        métrique
      </th>

      <th style={{ width: "150px" }}>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `streaming_unit_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre d&apos;unités de streaming confluentes (CSU) pour cette instance KSQL. Le comptage est échantillonné toutes les 60 secondes. L&apos;agrégation temporelle implicite pour cette métrique est MAX.
      </td>
    </tr>

    <tr>
      <td>
        `query_saturation`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        La saturation maximale pour une requête ksqlDB donnée sur tous les nœuds. Renvoie une valeur comprise entre 0 et 1, une valeur proche de 1 indique que le traitement des requêtes ksqlDB est goulot d&apos;étranglement sur les ressources disponibles.
      </td>
    </tr>

    <tr>
      <td>
        `task_stored_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        La taille de l&apos;état d&apos;une tâche donnée est stockée en octets.
      </td>
    </tr>

    <tr>
      <td>
        `storage_utilization`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        L&apos;utilisation totale du stockage pour une application ksqlDB donnée.
      </td>
    </tr>

    <tr>
      <td>
        `consumed_total_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets consommés par Kafka par requête continue sur la période demandée.
      </td>
    </tr>

    <tr>
      <td>
        `produced_total_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets produits vers Kafka par requête continue sur la période demandée.
      </td>
    </tr>

    <tr>
      <td>
        `offsets_processed_total`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta de décalages traités par une requête, une tâche, un sujet ou un décalage donné.
      </td>
    </tr>

    <tr>
      <td>
        `committed_offset_lag`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Le décalage actuel entre le décalage validé et le décalage de fin pour une requête, une tâche, une rubrique ou un décalage donné.
      </td>
    </tr>

    <tr>
      <td>
        `processing_errors_total`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre delta du nombre d&apos;erreurs de traitement d&apos;enregistrement d&apos;une requête sur la période demandée.
      </td>
    </tr>

    <tr>
      <td>
        `query_restarts`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre delta du nombre d&apos;échecs qui provoquent le redémarrage d&apos;une requête sur la période demandée.
      </td>
    </tr>
  </tbody>
</table>

## Et ensuite ?

<DocTiles>
  <DocTile title="Données et interface utilisateur" path="/docs/message-queues-streaming/ui-data/understand-ui">
    Découvrez comment utiliser New Relic pour monitorer votre cluster Kafka
  </DocTile>
</DocTiles>