---
title: Intégration cloudconfluente
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

New Relic propose une intégration pour collecter vos données [de streaming gérées par Confluent Cloud pour Apache Kafka](https://www.confluent.io/confluent-cloud/) . Ce document explique comment activer cette intégration et décrit les données qui peuvent être signalées.

## Prérequis

* Un compte New Relic
* Un compte Confluent Cloud actif
* Une clé API et un secret Confluent Cloud
* `MetricsViewer` accès sur le compte Confluent Cloud

## Activer l&apos;intégration [#activate]

Pour activer cette intégration, accédez à <DNT>**Integrations &amp; Agents**</DNT>, sélectionnez <DNT>**Confluent Cloud -&gt; API Polling**</DNT> et suivez les instructions.

<Callout variant="important">
  Si vous avez configuré le filtrage IP, ajoutez les adresses IP suivantes à votre filtre.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  Pour plus d&apos;informations sur les plages IP New Relic pour l&apos;intégration cloud, reportez-vous [à ce document](/docs/new-relic-solutions/get-started/networks/#webhooks). Pour obtenir des instructions sur la manière d&apos;effectuer cette tâche, reportez-vous [à ce document](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html).
</Callout>

## configuration et sondage [#polling]

Informations d&apos;interrogation par défaut pour l&apos;intégration Confluent Cloud Kafka :

* Intervalle d&apos;interrogation de New Relic : 5 minutes
* Intervalle de données Confluent Cloud : 1 minute

Vous ne pouvez modifier la fréquence d&apos;interrogation que lors de la configuration initiale.

## Afficher et utiliser les données [#find-data]

Vous pouvez [interroger et explorer vos données](/docs/using-new-relic/data/understand-data/query-new-relic-data) en utilisant le [type d&apos;événement](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels) suivant :

<table>
  <thead>
    <tr>
      <th>
        Entité
      </th>

      <th>
        Type de données
      </th>

      <th>
        Fournisseur
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Cluster
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

Pour en savoir plus sur l’utilisation de vos données, consultez [Comprendre et utiliser les données d’intégration](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## données métriques [#metrics]

Cette intégration enregistre les données Amazon Managed Kafka pour cluster, la partition et l&apos;entité de rubrique.

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        métrique
      </th>

      <th style={{ width: "150px" }}>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Une mesure de l&apos;utilisation du cluster. La valeur est comprise entre 0,0 et 1,0. Seul le cluster de niveau dédié possède ces données métriques.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Un indicateur de la présence d’une partition chaude causée par le débit d’entrée. La valeur est 1,0 lorsqu&apos;une partition chaude est détectée et vide lorsqu&apos;aucune partition chaude n&apos;est détectée.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Un indicateur de la présence d&apos;une partition chaude causée par le débit de sortie. La valeur est 1,0 lorsqu&apos;une partition chaude est détectée et vide lorsqu&apos;aucune partition chaude n&apos;est détectée.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de requête totaux provenant des types de requêtes spécifiés envoyés sur le réseau. Chaque échantillon correspond au nombre d&apos;octets envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de réponse totaux provenant des types de réponse spécifiés envoyés sur le réseau. Chaque échantillon correspond au nombre d&apos;octets envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de données des clients reçues du réseau. Chaque échantillon correspond au nombre d&apos;octets reçus depuis l&apos;échantillon de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Le nombre delta d&apos;octets de données des clients envoyés sur le réseau. Chaque échantillon correspond au nombre d&apos;octets envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;enregistrements reçus. Chaque échantillon correspond au nombre d&apos;enregistrements reçus depuis l&apos;échantillon de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;enregistrements envoyés. Chaque échantillon correspond au nombre d&apos;enregistrements envoyés depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre de partitions.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Le décalage entre le décalage validé d&apos;un membre du groupe et le niveau d&apos;eau élevé de la partition.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre delta d&apos;authentifications réussies. Chaque échantillon correspond au nombre d&apos;authentifications réussies depuis le point de données précédent. Le comptage est échantillonné toutes les 60 secondes.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre de connexions authentifiées actives.
      </td>
    </tr>
  </tbody>
</table>

## Et ensuite ?

<DocTiles>
  <DocTile title="Data and UI" path="/docs/message-queues-streaming/ui-data/understand-ui">Découvrez comment utiliser New Relic pour monitorer votre cluster Kafka</DocTile>
</DocTiles>