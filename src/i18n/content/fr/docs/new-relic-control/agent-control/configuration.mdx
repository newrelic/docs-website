---
title: Gestion de la configuration
metaDescription: Overview of the Agent Control configuration
freshnessValidatedDate: never
translationType: machine
---

<Callout variant="important">
  Agent Control et New Relic Control sont désormais **généralement disponibles** pour Kubernetes ! Le support des hôtes Linux est également disponible dans le programme **d&apos;aperçu public**, conformément à nos [politiques de pré-sortie](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy).
</Callout>

Agent Control fournit une approche transparente pour configuration indépendamment de l&apos;environnement dans lequel il est déployé. Deux méthodes de gestion de la configuration de l&apos;agent sont disponibles :

* **Configuration locale :** un fichier `values.yaml` complet utilisé lors de l&apos;installation initiale Helm .

* **Configuration à distance :** une configuration centralisée basée sur YAML que vous créez dans New Relic Control et qui est déployée à distance sur l&apos;ensemble de votre flotte.

La configuration à distance est la méthode recommandée pour la gestion quotidienne. Il garantit un comportement cohérent de l&apos;agent dans votre environnement, simplifie la gestion des changements et vous permet d&apos;évoluer sans mettre à jour manuellement les fichiers YAML locaux sur chaque hôte.

<Callout variant="tip">
  Le fichier `values-newrelic.yaml` , qui définissait traditionnellement les paramètres de l&apos;agent New Relic, inclut désormais également la configuration du contrôle de l&apos;agent. Les paramètres que vous définissez dans ce fichier déterminent le fonctionnement d&apos;Agent Control et de ses agents gérés. Ce fichier est appelé configuration locale.
</Callout>

## Comprendre les deux couches de configuration

La configuration d&apos;Agent Control est structurée en deux couches :

1. **Configuration principale d&apos;Agent Control :** il s&apos;agit des paramètres de niveau supérieur qui contrôlent le fonctionnement d&apos;Agent Control, tels que sa connexion à New Relic, son identité et les détails de gestion de flotte.

2. **Configuration des agents gérés :** il s&apos;agit des `chart_values` individuels pour chaque sous-agent (par exemple, agent d&apos;infrastructure, Fluent Bit) que Agent Control déploie et gère.

Lorsqu&apos;une configuration locale et une configuration distante sont toutes deux présentes, Agent Control applique la logique suivante :

1. La configuration à distance est prioritaire. Tous les paramètres définis dans une configuration distante à partir de New Relic Control remplaceront les paramètres correspondants dans le fichier `values.yaml` local.
2. Pour remplacer intentionnellement les paramètres distants par votre configuration locale, vous pouvez déployer une configuration distante vide via New Relic Control. Ce changement s&apos;appliquera à tous les clusters de la flotte sélectionnée.

## configurationKubernetes

Ces instructions et exemples s’appliquent à Agent Control exécuté sur un cluster Kubernetes.

### configuration locale `values.yaml` pour Kubernetes

Le fichier de configuration local pour Kubernetes, utilisé lors de l&apos;installation, contient tous les paramètres d&apos;Agent Control et de ses agents gérés.

Cet exemple montre les deux couches de configuration dans un seul fichier.

<CollapserGroup>
  <Collapser id="agent-control-config" title="Configuration du contrôle des agents">
    ```yaml
    # Layer 1: Agent Control's Core Configuration
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"
      userKey: "YOUR_USER_KEY"

    # Values related to the Agent Control's Helm chart release.
    # `https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml`
    agent-control-deployment:
      identityClientId: ""
      identityClientSecret: ""
      config:
        fleet_control:
          # Optional: Specify a fleet_id (entity guid) to automatically connect to an existing fleet.
          fleet_id: ""
          auth:
            # New Relic organization ID where agent will connect to.
            organizationId: "YOUR_ORGANIZATION_ID"

        # Layer 2: Managed Agents' Configurations
        # List of managed agents that will be deployed. The key represents the name of the agent and the value holds the configuration.
        subAgents:
          infrastructure:
            type: newrelic/com.newrelic.infrastructure:0.1.0
            content:
              # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/nri-bundle`
              # Recommended: check and define an explicit chart version (latest stable)
              chart_version: "*"
              chart_values:
                newrelic-infrastructure:
                enableProcessMetrics: true
          logs:
            type: newrelic/io.fluentbit:0.1.0
            content:
              # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging`
              # Recommended: check and define an explicit chart version (latest stable)
              chart_version: "*"
              chart_values:
                newrelic-logging:
                  sendMetrics: true
          agent-operator:
            type: com.newrelic.k8s_agent_operator:0.1.0
            content:
              chart_version: "*"
    ```
  </Collapser>
</CollapserGroup>

L&apos;exemple montre comment configurer Agent Control avec deux agents gérés :Kubernetes infrastructure l&apos;agent et Fluent Bit pour le transfert de log . Par exemple, si vous ne souhaitez pas envoyer de mesures de santé pour votre Fluent Bit log collecteur, définissez simplement `sendMetrics: false` dans le fichier YAML avant d&apos;exécuter la commande d&apos;installation.

### configuration à distance pour Kubernetes

La configuration à distance garantit un comportement cohérent de l&apos;agent dans votre environnement, simplifie la gestion des changements et vous permet de faire évoluer l&apos;observabilité sans gérer manuellement les fichiers YAML locaux.

Pour déployer la configuration de manière centralisée sur le cluster, définissez ce même contenu YAML dans la section de **Configurations** de [contrôle de la flotte](/docs/new-relic-control/fleet-control/overview). Vous pouvez ensuite appliquer la configuration à une flotte entière de clusters dans le cadre d’un déploiement à distance. Il s’agit du fichier de **configuration à distance** .

<Callout variant="tip">
  Lorsque vous définissez une configuration dans l’interface utilisateur de contrôle New Relic, la structure YAML est différente. Vous fournissez uniquement le YAML correspondant au bloc `content` pour un seul agent.
</Callout>

### Exemple de configuration : Contrôle des agents sur Kubernetes

configuration : Agent Control sur Kubernetes Les exemples suivants montrent comment configurer Agent Control pour gérer différents ensembles d&apos;agents. Ces configurations peuvent être utilisées soit lors de l&apos;installation initiale, soit dans le cadre d&apos;une configuration à distance dans le contrôle de la flotte.

Pour explorer tous les paramètres de configuration disponibles, reportez-vous à [`values-newrelic.yaml`](https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml).

Les exemples suivants montrent comment configurer Agent Control avec un ensemble de sous-agents à l&apos;aide du fichier `values.yaml` local.

#### Contrôle des agents avec New Relic Infrastructure et Fluent Bit

Cet exemple déploie Agent Control avec monitoring d&apos;infrastructure et Fluent Bit pour la collecte log .

<CollapserGroup>
  <Collapser id="agent-control-config" title="Configuration locale pour l'infrastructure et Fluent Bit">
    ```yaml
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"
      userKey: "YOUR_USER_KEY"

    # See `https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml`
    agent-control-deployment:
      identityClientId: ""
      identityClientSecret: ""
      config:
        fleet_control:
          # Optional
          # fleet_id: YOUR_FLEET_ENTITY_GUID
          auth:
            organizationId: "YOUR_ORGANIZATION_ID"
        subAgents:
          infrastructure:
            type: newrelic/com.newrelic.infrastructure:0.1.0
            content:
              # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/nri-bundle`
              # Recommended: check and define an explicit chart version (latest stable)
              chart_version: "*"

              #chart_values:
              #  newrelic-infrastructure:
              #    enableProcessMetrics: true
          logs:
            type: newrelic/io.fluentbit:0.1.0
            content:
              # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging`
              # Recommended: check and define an explicit chart version (latest stable)
              chart_version: "*"

              #chart_values:
              #  newrelic-logging:
              #    sendMetrics: true
          agent-operator:
            type: com.newrelic.k8s_agent_operator:0.1.0
            chart_version: "*"
    ```
  </Collapser>
</CollapserGroup>

#### Contrôle des agents avec OpenTelemetry et paramètres de collecteur personnalisés

avec OpenTelemetry et les paramètres de collecteur personnalisés Cet exemple déploie Agent Control avec la distribution New Relic d&apos; OpenTelemetry (NRDOT) collecteur et désactive le `filelog` Récepteur dans le [graphique Helm `nr-k8s-otel-collector` ](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector#values)géré.

<Callout variant="important">
  Meilleure pratique de sécurité : ne stockez pas de valeurs sensibles comme votre clé de licence directement dans la configuration. Nous vous recommandons d’utiliser un secret Kubernetes. Agent Control peut ensuite extraire en toute sécurité ces valeurs du secret au moment de l&apos;exécution.
</Callout>

<CollapserGroup>
  <Collapser id="otel-config" title="OpenTelemetry configuration">
    ```yaml
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"
    # Values related to the Agent Control's Helm chart release.
    # `https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml`
    agent-control-deployment:
      identityClientId: ""
      identityClientSecret: ""
      config:
        fleet_control:
          # Optional: Specify a fleet_id (entity guid) to automatically connect to an existing fleet.
          fleet_id: ""
          auth:
            # New Relic organization ID where agent will connect to.
            organizationId: "YOUR_ORGANIZATION_ID"

        # List of managed agents that will be deployed. The key represents the name of the agent and the value holds the configuration.
        subAgents:
          infrastructure:
            type: newrelic/com.newrelic.infrastructure:0.1.0
            content:
              # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/nri-bundle%60
              # Recommended: check and define an explicit chart version (latest stable)
              chart_version: "*"
          agent-operator:
            type: newrelic/com.newrelic.k8s_agent_operator:0.1.0
            content:
              chart_version: "*"
          fluentbit:
            type: newrelic/io.fluentbit:0.1.0
            content:
              # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging`
              # Recommended: check and define an explicit chart version (latest stable)
              chart_version: "*"
              chart_values:
                global:
                  lowDataMode: true
          prometheus:
            type: newrelic/com.newrelic.prometheus:0.1.0
            content:
              chart_version: "*"
              chart_values:
                global:
                  lowDataMode: true
                newrelic-prometheus-agent:
                  config:
                    kubernetes:
                      integrations_filter:
                        enabled: false
    ```
  </Collapser>
</CollapserGroup>

### Exemple de configuration : configuration de l&apos;agent distant sur Kubernetes

Les exemples suivants montrent comment configurer des agents individuels à distance à partir de l&apos;interface utilisateur de **New Relic Control** .

#### Configuration à distance : infrastructure New Relic

Cet exemple montre comment configurer à distance l&apos;agent New Relic Infrastructure pour Kubernetes à l&apos;aide du contrôle de la flotte. Il permet la collecte de métriques de processus en définissant `enableProcessMetrics: true`.

<CollapserGroup>
  <Collapser id="infra-remote-config" title="Configuration à distance de l'infrastructure">
    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-infrastructure:
        enableProcessMetrics: true
    ```
  </Collapser>
</CollapserGroup>

#### Configuration à distance : Fluent Bit

Cet exemple a configuré Fluent Bit à distance via le contrôle de la flotte. Il active les rapports de métriques de santé à partir du collecteur log en définissant `sendMetrics: true`.

<CollapserGroup>
  <Collapser id="fluentbit-remote-config" title="Fluent Bit configuration">
    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-logging:
        sendMetrics: true
    ```
  </Collapser>
</CollapserGroup>

#### Configuration à distance : Prometheus

Cet exemple configure l&apos;agent Prometheus à distance à l&apos;aide du contrôle de la flotte. Il permet à `low-data mode` de réduire le volume de télémétrie et de désactiver l&apos;intégration par défaut.

<CollapserGroup>
  <Collapser id="prometheus-config" title="Configuration de Prometheus">
    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-prometheus-agent:
        lowDataMode: true
    ```
  </Collapser>
</CollapserGroup>

#### Configuration à distance : OpenTelemetry

Cet exemple configure le collecteur New Relic OpenTelemetry et active `lowDataMode` comme option valide.

<Callout variant="important">
  Meilleure pratique de sécurité : ne stockez pas de valeurs sensibles comme votre clé de licence directement dans la configuration. Nous vous recommandons d’utiliser un secret Kubernetes. Agent Control peut ensuite extraire en toute sécurité ces valeurs du secret au moment de l&apos;exécution.
</Callout>

<CollapserGroup>
  <Collapser id="otel-config" title="configurationà distance OpenTelemetry">
    <Callout variant="important">
      Créez un secret Kubernetes pour stocker en toute sécurité la clé de licence New Relic et utilisez-le dans le `chart_values` en remplacement de la valeur `licenseKey` :

      ```yaml
      customSecretName: "your-secret-name"
      customSecretLicenseKey: "your-secret-key"
      ```
    </Callout>

    Nous vous recommandons d&apos;utiliser le contrôle de la flotte pour définir et déployer OpenTelemetry configuration sur vos flottes. Pour configurer OpenTelemetry à distance, créez une configuration dans contrôle de la flotte avec la structure indiquée ci-dessous. Vous pouvez ajuster des valeurs telles que `lowDataMode` ou `receivers.filelog.enabled` et inclure tout autre paramètre de graphique Helm pertinent en fonction de vos besoins.

    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-prometheus-agent:
        lowDataMode: true
    ```
  </Collapser>
</CollapserGroup>

### configuration du proxy pour Kubernetes

Agent Control prend en charge la configuration du proxy pour acheminer le trafic via les proxys d&apos;entreprise. Les paramètres proxy peuvent être définis via des variables d&apos;environnement ou directement dans le fichier de configuration.

#### Préséance de proxy

Agent Control utilisera les paramètres proxy dans l&apos;ordre de priorité suivant :

1. `proxy` Champ de configuration dans la configuration de Agent Control
2. `HTTP_PROXY` variable d&apos;environnement
3. `HTTPS_PROXY` variable d&apos;environnement

<Callout variant="important">
  La configuration du proxy n&apos;est actuellement pas compatible avec la récupération du certificat pour la validation de la signature. Si vous devez configurer un proxy, vous disposez des options suivantes :

  * Ajoutez une exception pare-feu à `https://newrelic.com` afin que requests à ce point de terminaison puissent ignorer le proxy (recommandé)
  * Utiliser un certificat local via `fleet_control.signature_validation.certificate_pem_file_path` (la rotation des certificats doit être gérée manuellement)
  * Désactivez la validation de signature en définissant `fleet_control.signature_validation.enabled: false` (fortement déconseillé pour des raisons de sécurité)
</Callout>

#### Configuration du proxy avec des certificats auto-signés

Pour les configurations de proxy utilisant l&apos;authentification HTTPS avec des certificats auto-signés, vous devez fournir le bundle de certificats CA et configurer l&apos;authentification proxy :

<CollapserGroup>
  <Collapser id="k8s-proxy-config" title="Exemple de configuration de proxy Kubernetes">
    ```yaml
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"

    agent-control-deployment:
      config:
        agentControl:
          content:
            proxy:
              url: https://proxy-service:8080
        subAgents: {}

      # Mount CA certificate bundle to Agent Control
      extraVolumeMounts:
        - mountPath: /etc/ssl/certs/
          name: ca-certs
      extraVolumes:
        - name: ca-certs
          secret:
            secretName: ca-certs

    # Configure Flux components to use proxy
    agent-control-cd:
      flux2:
        sourceController:
          extraEnv:
            # Configure Flux source-controller to proxy all requests
            - name: HTTPS_PROXY
              value: https://proxy-service:8080
            # Except for in-cluster requests
            - name: "NO_PROXY"
              value: ".cluster.local.,.cluster.local,cluster.local,.svc,127.0.0.0/8,10.0.0.0/8"
          volumeMounts:
            # Mount CA certificate bundle to source-controller trust root store. The bundle should contain the
            # proxy CA cert.
            - mountPath: /etc/ssl/certs/
              name: ca-certs
          volumes:
            - name: ca-certs
              secret:
                secretName: ca-certs


    ```
  </Collapser>
</CollapserGroup>

#### Configuration du proxy pour les agents gérés

<Callout variant="caution">
  La configuration d&apos;un proxy dans Agent Control ne configure **pas** automatiquement les mêmes paramètres de proxy pour les agents qu&apos;il gère. Chaque agent possède sa propre configuration proxy qui doit être définie séparément en fonction du format de configuration et des exigences spécifiques de cet agent.
</Callout>

Lorsque vous utilisez un proxy, vous devez également configurer les paramètres de proxy pour chaque agent géré individuellement. Reportez-vous à la documentation spécifique de chaque agent pour les options de configuration du proxy.

### Gestion des secrets

Agent Control fournit un mécanisme robuste pour gérer les données sensibles, telles que les mots de passe et les clés API, en les récupérant auprès de fournisseurs de secrets dédiés. Cela garantit que les informations sensibles ne sont pas codées en dur directement dans les fichiers de configuration. Le système prend actuellement en charge les fournisseurs secrets suivants :

* HashiCorp Vault : appelé `nr-vault` dans la configuration.
* Secrets Kubernetes : appelés `nr-kubesec` dans la configuration.

### Définition des secrets dans la configuration

Pour utiliser les secrets, définissez-les dans votre fichier YAML de configuration Agent Control en suivant ces étapes :

1. **Définissez la section `secrets_providers` :** configurez vos fournisseurs de secrets de manière centralisée dans cette section. Assurez-vous que chaque entrée correspond à un fournisseur pris en charge.
2. **Configurer les sources secrètes :** pour chaque fournisseur, spécifiez une ou plusieurs sources. Une source inclut les détails de configuration nécessaires (par exemple, URL, jeton) pour que Agent Control se connecte et récupère un groupe de secrets.
3. **Utiliser l&apos;espace réservé dans la configuration de l&apos;agent :** Au lieu des données sensibles réelles, utilisez une chaîne espace réservé dans configuration de votre agent. Agent Control remplace automatiquement ces espaces réservés par les secrets récupérés lors du processus de rendu.

<Callout variant="important">
  Si Agent Control ne parvient pas à récupérer un secret, le rendu de la configuration échouera et l&apos;agent ne sera pas exécuté. Il s’agit d’une fonctionnalité de sécurité essentielle pour empêcher les agents de s’exécuter avec une configuration incomplète ou incorrecte.
</Callout>

L&apos;exemple de configuration d&apos;agent Control suivant montre comment récupérer des secrets à partir de deux sources Vault dans la section `secrets_providers` :

```yaml
secrets_providers:
  vault:
    sources:
      local-instance:
        url: http://localhost:8200/v1/
        token: root
        engine: kv2
      remote:
        url: http://my-remote-server:8200/v1/
        token: root
        engine: kv1

fleet_control:
  ...

agents:
  ...
```

#### Utilisation des secrets dans une configuration d&apos;agent

Une fois les sources définies, vous pouvez référencer le secret dans une configuration d&apos;agent à l&apos;aide d&apos;une syntaxe d&apos;espace réservé spécifique avec le chemin correct. Agent Control récupère le secret et l&apos;utilise pour restituer le fichier de configuration final que l&apos;agent utilisera.

Exemple de configuration d&apos;agent utilisant des secrets avec espace réservé :

```yaml
config_agent: |+
  enable_process_metrics: true
  custom_attributes:
    username: "${nr-vault:local-instance:secret:my_secret:username}"
    organization: "${nr-vault:remote:my_mount:my_path:organization}"
```

Dans cet exemple :

L&apos;espace réservé `${nr-vault:local-instance:secret:my_secret:username}` demande à Agent Control de récupérer la valeur associée à la clé `username` à partir du secret du chemin `secret/my_secret` à l&apos;aide de la source du fournisseur de secret d&apos;instance locale. L&apos;espace réservé `${nr-vault:remote:my_mount:my_path:organization}` récupère de la même manière la valeur de la clé `organization` à partir de la source distante.

Après une récupération réussie, Agent Control restitue ces secrets à partir de la source et du chemin spécifiés, en stockant le résultat dans un secret Kubernetes ou un fichier de configuration privé à utiliser par l&apos;agent correspondant.

### Les secrets du coffre-fort

Configurez les sources HashiCorp Vault avec les paramètres suivants :

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        Clé YAML
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `url`
      </td>

      <td>
        URL pour demander des données
      </td>
    </tr>

    <tr>
      <td>
        `token`
      </td>

      <td>
        Utilisé pour s&apos;authentifier auprès du point de terminaison.
      </td>
    </tr>

    <tr>
      <td>
        `engine`
      </td>

      <td>
        Spécifiez **`kv1`** ou **`kv2`**.
      </td>
    </tr>
  </tbody>
</table>

Dans le fichier de configuration, chaque secret stocké dans Vault est accessible en définissant un espace réservé avec :

* **source\_name**: Le nom de la source Vault définie dans `secrets_providers`.
* **mount**: Le nom du support moteur secret.
* **path**: Le chemin spécifique vers le secret.
* **specific key**: La clé spécifique dans le secret à récupérer.

Exemple de format d&apos;espace réservé complet :

```
"${nr-vault:source_name:my_mount:my_path:my_value}"
```

### Les secrets de Kubernetes

Si le pod de contrôle d&apos;agent dispose d&apos;autorisations, par exemple via un compte de service et un contrôle d&apos;accès basé sur les rôles (RBAC), pour accéder aux secrets et à l&apos;espace de nommage requis, le contrôle d&apos;agent peut accéder directement aux secrets de l&apos;API Kubernetes sans avoir besoin d&apos;une configuration de sources distincte.

Dans le fichier de configuration de l&apos;agent, récupérez chaque valeur secrète à l&apos;aide d&apos;un espace réservé en spécifiant :

* **namespace**: L&apos;espace de nommage Kubernetes où se trouve le secret.
* **name**: le nom de l&apos;objet secret Kubernetes.
* **specific key**: La clé spécifique dans le secret à partir de laquelle récupérer la valeur.

Par exemple, utilisez le format d&apos;espace réservé :

```
"${nr-kubesec:my_namespace:my_secret:my_value}"
```

### Configuration du référentiel privé

Agent Control prend en charge la configuration de Helm privé pour déployer à la fois Agent Control lui-même et les agents gérés. Cela permet des environnements dans lesquels les cartes New Relic Helm ne sont pas directement accessibles.

<Callout variant="caution">
  Lors de l&apos;utilisation du référentiel privé Helm, les cartes doivent être compatibles et les images référencées dans les cartes doivent être accessibles. Dans le cas contraire, les agents ne fonctionneront pas comme prévu.
</Callout>

### 1. Activer le référentiel privé pour les agents

Pour des raisons de sécurité, seuls les référentiels explicitement activés sont autorisés en configuration à distance. Pour activer un référentiel spécifique, mettez à jour la configuration du contrôle de l&apos;agent comme suit :

<CollapserGroup>
  <Collapser id="k8s-private-repository-config" title="Activer le référentiel privé">
    ```yaml
    # values-newrelic.yaml

    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"

    # ...

    agent-control-deployment:
      config:
        allowedChartRepositoryUrl:
          - https://my-private-repository-1
          - https://my-private-repository-2
        # ...
    ```
  </Collapser>
</CollapserGroup>

La configuration référentielle autorisée peut ensuite être utilisée dans votre configuration à distance au sein de New Relic Control. Exemple:

```yaml
chart_version: "1.2.3"
chart_repository:
  url: "https://my-private-repository-1"
  name: "my-chart-name" # Optional: use only if the chart name doesn't match New Relic's chart name
```

De plus, vous devez configurer l&apos;installation Helm d&apos;Agent Control pour utiliser votre référentiel privé si le graphique `agent-control-bootstrap` lui-même se trouve dans un référentiel privé. Ceci est distinct de la configuration des agents gérés. Reportez-vous au fichier `agent-control-bootstrap` Helm chart [values.yaml](https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml) pour configurer la section `installationJob` comme suit :

* `chartRepositoryUrl`: L&apos;URL contenant l&apos;emplacement de votre référentiel.
* `name`: Le nom du graphique si vous utilisez un nom de graphique différent.
* `repositorySecretReferenceName` et `repositoryCertificateSecretReferenceName`: les secrets requis pour l’authentification auprès de votre référentiel. Consultez la section authentification ci-dessous pour plus de détails.

### 2. Configurer l&apos;authentification pour le référentiel privé

Vous devez configurer des ressources supplémentaires pour activer l’authentification afin d’accéder à votre référentiel privé comme suit :

<CollapserGroup>
  <Collapser id="k8s-private-repository-basic-auth" title="Authentification de base">
    Pour vous authentifier à l&apos;aide de l&apos;authentification de base (nom d&apos;utilisateur et mot de passe), vous devez créer un secret dans l&apos;espace de nommage Agent Control contenant les valeurs attendues dans `data.username` et `data.password`.

    Exemple:

    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: my-secret
    stringData:
      username: "myUser"
      password: "myPassword"
    ```

    Pour plus de détails, consultez la [documentation Flux](https://fluxcd.io/flux/components/source/helmrepositories/#secret-reference).

    Lors de l&apos;utilisation de l&apos;authentification de base, la configuration à distance doit être configurée comme suit :

    ```yaml
    chart_repository:
      url: "https://my-private-repository-1"
      secret_reference:
        name: my-secret
    ```
  </Collapser>

  <Collapser id="k8s-private-repository-tls-cert" title="Authentification par certificat TLS">
    Pour vous authentifier à l’aide de TLS, vous devez créer un secret contenant :

    * `tls.crt` et `tls.key`: certificat client et clé privée utilisés pour l&apos;authentification client TLS
    * `ca.crt`: Certificat CA utilisé pour vérifier le serveur (requis si le serveur utilise un certificat auto-signé)

    Le secret doit être de type `Opaque` ou `kubernetes.io/tls`. Tous les fichiers du Secret doivent être codés en PEM.

    Exemple:

    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: my-secret
      namespace: newrelic-agent-control
    type: kubernetes.io/tls # or Opaque
    data:
      tls.crt: <BASE64>
      tls.key: <BASE64>
      # NOTE: Can be supplied without the above values
      ca.crt: <BASE64>
    ```

    Pour plus de détails, consultez la [documentation Flux](https://fluxcd.io/flux/components/source/helmrepositories/#secret-reference).

    Lors de l&apos;utilisation de l&apos;authentification par certificat TLS, la configuration à distance doit être configurée comme suit :

    ```yaml
    chart_repository:
      url: "https://my-private-repository-1"
      certificate_secret_reference:
        name: my-secret
    ```
  </Collapser>
</CollapserGroup>

## configurationLinux

Voici les chemins par défaut pour la configuration du contrôle des agents :

* `Local` fichier de configuration: `/etc/newrelic-agent-control/config.yaml`
* `Remote` fichier configuration : `/var/lib/newrelic-agent-control/config.yaml` (si activé via le contrôle de la flotte déployée)
* Définition du service : `/lib/systemd/system/newrelic-agent-control.service`
* Fichier d&apos;environnement de service : `/etc/newrelic-agent-control/newrelic-agent-control.conf`

Par défaut, l&apos;agent peut orchestrer l&apos;agent d&apos;infrastructure et le collecteur OpenTelemetry :

```yml
# Configures the integration with Fleet Control
fleet_control:
  # EU region? Use: https://opamp.service.eu.newrelic.com/v1/opamp
  endpoint: https://opamp.service.newrelic.com/v1/opamp
  headers:
    api-key: YOUR_INGEST_KEY
  auth_config:
    # EU region? Use: https://system-identity-oauth.service.eu.newrelic.com/oauth2/token
    token_url: "https://system-identity-oauth.service.newrelic.com/oauth2/token"
    client_id: "YOUR_CLIENT_ID
    provider: "local"
    private_key_path: "path/to/key"

# Configures the agents to be supervised by Agent Control
agents:
  # Agent name (RFC-1035 valid label)
  nr-infra-agent:
    # The supported agent type and agent type version
    agent_type: "newrelic/com.newrelic.infrastructure:0.1.0"
  nr-otel-collector:
    agent_type: "newrelic/io.opentelemetry.collector:0.1.0"
```

Vous pouvez renommer ou supprimer l’un ou l’autre des agents en fonction de vos besoins d’observabilité. Le nom de l&apos;agent doit être un nom d&apos;étiquette [RFC-1035 valide](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#rfc-1035-label-names).

Vous pouvez également utiliser des variables d’environnement pour définir les paramètres de l’agent :

* Utilisez le préfixe `NR_` (soulignement simple) pour cibler la configuration principale du contrôle de l&apos;agent.
* Utilisez `__` (double trait de soulignement) pour cibler les paramètres disponibles dans Agent Control. Ceci est nécessaire pour éviter les collisions avec les clés de configuration qui contiennent des traits de soulignement.
* Les variables d&apos;environnement n&apos;ont priorité que sur le fichier de configuration local. Si la configuration à distance est activée, les variables d&apos;environnement ne sont pas prises en compte.
* Par exemple, pour définir une configuration dynamique pour le `fleet_control::endpoint`, ajoutez le `NR_FLEET_CONTROL__ENDPOINT=https://opamp.service.newrelic.com/v1/opamp` dans le fichier de définition de service.

### Configurer les agents

```
agents:
  # Agent name (RFC-1035 valid label)
  nr-infra-agent:
    # The supported agent type and agent type version
    agent_type: "newrelic/com.newrelic.infrastructure:0.1.0"
  nr-otel-collector:
    agent_type: "newrelic/io.opentelemetry.collector:0.1.0"
```

Vous pouvez renommer ou supprimer l’un ou l’autre des agents en fonction de vos besoins d’observabilité. Le nom de l&apos;agent doit être un nom d&apos;étiquette [RFC-1035 valide](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#rfc-1035-label-names).

Vous pouvez également utiliser des variables d’environnement pour définir les paramètres de l’agent :

* Utilisez le préfixe `NR_` (soulignement simple) pour cibler la configuration principale du contrôle de l&apos;agent.
* Utilisez `__` (double trait de soulignement) pour cibler les paramètres disponibles dans Agent Control. Ceci est nécessaire pour éviter les collisions avec les clés de configuration qui contiennent des traits de soulignement.
* Les variables d&apos;environnement n&apos;ont priorité que sur le fichier de configuration local. Si la configuration à distance est activée, les variables d&apos;environnement ne sont pas prises en compte.
* Par exemple, pour définir une configuration dynamique pour le `fleet_control::endpoint`, ajoutez le `NR_FLEET_CONTROL__ENDPOINT=https://opamp.service.newrelic.com/v1/opamp` dans le fichier de définition de service.

### Configurer les agents [#agents-config]

Agent Control peut actuellement gérer les types d&apos;agents sur hôte prédéfinis suivants :

* Agent d&apos;infrastructure New Relic : `newrelic/com.newrelic.infrastructure`. Toutes les fonctionnalités existantes de l&apos; [agentinfrastructure ](/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring)sont prises en charge, y compris l&apos;orchestration [de l&apos;intégration sur hôte](/docs/infrastructure/host-integrations/get-started/introduction-host-integrations/) et [l&apos;intégration de notre redirecteur de log](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/) basé sur FluentBit.
* Distribution New Relic pour OpenTelemetry : `newrelic/io.opentelemetry.collector`

Chaque type d&apos;agent offre un ensemble de variables facultatives qui peuvent être personnalisées pour adapter son comportement. Pour personnaliser la configuration locale de l’agent :

1. Créez un fichier `values.yml` : ce fichier contiendra les valeurs de configuration souhaitées.
2. Placez le fichier `values.yml` dans le répertoire `/etc/newrelic-agent-control/fleet/agents.d/YOUR-AGENT-NAME/values/`. Ici, `YOUR-AGENT-NAME` est le nom réel de votre agent (par exemple, `nr-infra-agent`).

Voici une liste des variables disponibles pour les dernières versions de type d&apos;agent :

* Agent d&apos;infrastructure New Relic : `0.1.0`
* Distribution New Relic pour OpenTelemetry : `0.1.0`

<table>
  <thead>
    <tr>
      <th>
        Type d&apos;agent
      </th>

      <th>
        Variable
      </th>

      <th>
        Type
      </th>

      <th>
        Défaut
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `config_agent`
      </td>

      <td>
        Un fichier contenant la configuration de l&apos;agent infrastructure
      </td>

      <td>
        (vide)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `config_integrations`
      </td>

      <td>
        Une mappe de chaînes contenant la configuration d&apos;intégration sur hôte
      </td>

      <td>
        (vide)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `config_logging`
      </td>

      <td>
        Une carte de chaîne contenant la configuration du transfert de log
      </td>

      <td>
        (vide)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `health_port`
      </td>

      <td>
        Port pour le serveur d&apos;état local de l&apos;agent d&apos;infrastructure
      </td>

      <td>
        `/health/status`
      </td>
    </tr>

    <tr>
      <td>
        `io.opentelemetry.collector`
      </td>

      <td>
        `config`
      </td>

      <td>
        configuration du collecteur OpenTelemetry (au format yaml)
      </td>

      <td>
        (vide)
      </td>
    </tr>

    <tr>
      <td>
        `io.opentelemetry.collector`
      </td>

      <td>
        `health_check.path` `health_check.port`
      </td>

      <td>
        Chemin et port pour l&apos; [extension de vérification de l&apos;état de santé](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/healthcheckv2extension/README.md#configuration) du Collecteur Otel, point de terminaison http local
      </td>

      <td>
        `localhost:13133/health/status`
      </td>
    </tr>

    <tr>
      <td>
        Tous les agents gérés
      </td>

      <td>
        `backoff_delay`
      </td>

      <td>
        Temps jusqu&apos;à la prochaine tentative si le collecteur ne parvient pas à démarrer (en secondes).
      </td>

      <td>
        `20s`
      </td>
    </tr>
  </tbody>
</table>

<Callout variant="tip">
  Vous pouvez configurer les [paramètres de l&apos;agent d&apos;infrastructure](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/) et [les paramètres du collecteur OpenTelemetry](https://docs-preview.newrelic.com/docs/new-relic-distribution-of-opentelemetry#configure) selon vos besoins en fonction des configurations prises en charge.
</Callout>

### Exemple de configuration

#### Configuration à distance avec contrôle de la flotte

Les exemples suivants contiennent des cas d’utilisation courants prêts à être copiés et collés en tant que configuration valide pour Agent Control et les agents gérés.

<CollapserGroup>
  <Collapser id="remote-config-infra-agent" title="Agent d'infrastructure, intégration sur hôte et redirecteur de log (FluentBit intégré)">
    paramètres de l&apos;agent d&apos;infrastructure, paramètres d&apos;intégration Redis et paramètres de transfert de logs pour notre intégration FluentBit. Le `config_agent` avec un `license_key` valide est toujours obligatoire. Les autres sections sont facultatives (supprimez ou mettez à jour selon vos besoins) :

    ```yml
    config_agent: |
      license_key: YOUR_LICENSE_KEY
      custom_attributes:
        env: demo
    config_integrations: 
      nri-redis-example.yml: |
        integrations:
          - name: nri-redis
            env:
              hostname: localhost
              port: 6380
              keys: '{"0":["<KEY_1>"],"1":["<KEY_2>"]}'
              remote_monitoring: true
    config_logging:
      fluentbit-example.yml: |
        logs:
          - name: syslog
            file: /var/log/syslog
            attributes:
              logtype: linux_syslog
    ```
  </Collapser>

  <Collapser id="remote-config-nrdot" title="Hôtel New Relic Collecteur">
    monitoring de base de l&apos;hôte à l&apos;aide du Collecteur Otel ( monitoring des processus désactivée) et du Récepteur OTLP activé pour recevoir les traces, les métriques et les logs des services APM :

    ```yml
    config: |   
      receivers:
        otlp:
          protocols:
            grpc:
            http:
      
        hostmetrics:
          collection_interval: 20s
          scrapers:
            cpu:
              metrics:
                system.cpu.time:
                  enabled: false
                system.cpu.utilization:
                  enabled: true
            load:
            memory:
              metrics:
                system.memory.utilization:
                  enabled: true
            paging:
              metrics:
                system.paging.utilization:
                  enabled: false
                system.paging.faults:
                  enabled: false
            filesystem:
              metrics:
                system.filesystem.utilization:
                  enabled: true
            disk:
              metrics:
                system.disk.merged:
                  enabled: false
                system.disk.pending_operations:
                  enabled: false
                system.disk.weighted_io_time:
                  enabled: false
            network:
              metrics:
                system.network.connections:
                  enabled: false
      
        filelog:
          include:
            - /var/log/syslog
      
      processors:
        # group system.cpu metrics by cpu
        metricstransform:
          transforms:
            - include: system.cpu.utilization
              action: update
              operations:
                - action: aggregate_labels
                  label_set: [ state ]
                  aggregation_type: mean
            - include: system.paging.operations
              action: update
              operations:
                - action: aggregate_labels
                  label_set: [ direction ]
                  aggregation_type: sum
        # remove system.cpu metrics for states
        filter/exclude_cpu_utilization:
          metrics:
            datapoint:
              - 'metric.name == "system.cpu.utilization" and attributes["state"] == "interrupt"'
              - 'metric.name == "system.cpu.utilization" and attributes["state"] == "nice"'
              - 'metric.name == "system.cpu.utilization" and attributes["state"] == "softirq"'
        filter/exclude_memory_utilization:
          metrics:
            datapoint:
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_unreclaimable"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "inactive"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "cached"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "buffered"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_reclaimable"'
        filter/exclude_memory_usage:
          metrics:
            datapoint:
              - 'metric.name == "system.memory.usage" and attributes["state"] == "slab_unreclaimable"'
              - 'metric.name == "system.memory.usage" and attributes["state"] == "inactive"'
        filter/exclude_filesystem_utilization:
          metrics:
            datapoint:
              - 'metric.name == "system.filesystem.utilization" and attributes["type"] == "squashfs"'
        filter/exclude_filesystem_usage:
          metrics:
            datapoint:
              - 'metric.name == "system.filesystem.usage" and attributes["type"] == "squashfs"'
              - 'metric.name == "system.filesystem.usage" and attributes["state"] == "reserved"'
        filter/exclude_filesystem_inodes_usage:
          metrics:
            datapoint:
              - 'metric.name == "system.filesystem.inodes.usage" and attributes["type"] == "squashfs"'
              - 'metric.name == "system.filesystem.inodes.usage" and attributes["state"] == "reserved"'
        filter/exclude_system_disk:
          metrics:
            datapoint:
              - 'metric.name == "system.disk.operations" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.merged" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.io" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.io_time" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.operation_time" and IsMatch(attributes["device"], "^loop.*") == true'
        filter/exclude_system_paging:
          metrics:
            datapoint:
              - 'metric.name == "system.paging.usage" and attributes["state"] == "cached"'
              - 'metric.name == "system.paging.operations" and attributes["type"] == "cached"'
        filter/exclude_network:
          metrics:
            datapoint:
              - 'IsMatch(metric.name, "^system.network.*") == true and attributes["device"] == "lo"'
      
        attributes/exclude_system_paging:
          include:
            match_type: strict
            metric_names:
              - system.paging.operations
          actions:
            - key: type
              action: delete
      
        transform:
          trace_statements:
            - context: span
              statements:
                - truncate_all(attributes, 4095)
                - truncate_all(resource.attributes, 4095)
          log_statements:
            - context: log
              statements:
                - truncate_all(attributes, 4095)
                - truncate_all(resource.attributes, 4095)
      
        # used to prevent out of memory situations on the collector
        memory_limiter:
          check_interval: 1s
          limit_mib: 100
      
        batch:
      
        resourcedetection:
          detectors: ["env", "system"]
          system:
            hostname_sources: ["os"]
            resource_attributes:
              host.id:
                enabled: true
      
        resourcedetection/cloud:
          detectors: ["gcp", "ec2", "azure"]
          timeout: 2s
          ec2:
            resource_attributes:
              host.name:
                enabled: false
      
      exporters:
        otlp:
          endpoint: otlp.nr-data.net:4317
          headers:
            api-key: ${NEW_RELIC_LICENSE_KEY}
      
      service:
        pipelines:
          metrics:
            receivers: [otlp, hostmetrics]
            processors:
              - memory_limiter
              - metricstransform
              - filter/exclude_cpu_utilization
              - filter/exclude_memory_utilization
              - filter/exclude_memory_usage
              - filter/exclude_filesystem_utilization
              - filter/exclude_filesystem_usage
              - filter/exclude_filesystem_inodes_usage
              - filter/exclude_system_disk
              - filter/exclude_network
              - attributes/exclude_system_paging
              - batch
              - resourcedetection
              - resourcedetection/cloud
            exporters: [otlp]
          traces:
            receivers: [otlp]
            processors: [transform, resourcedetection, resourcedetection/cloud, batch]
            exporters: [otlp]
          logs:
            receivers: [otlp, filelog]
            processors: [transform, resourcedetection, resourcedetection/cloud, batch]
            exporters: [otlp]
    ```
  </Collapser>

  <Collapser id="remote-config-agent-control" title="Contrôle des agents New Relic">
    Une configuration valide pour Agent Control lui-même montrant comment désactiver les agents, par exemple, le Collecteur Otel :

    ```yml
    agents:
      nr-infra-agent:
        agent_type: "newrelic/com.newrelic.infrastructure:0.1.0"
      #nr-otel-collector:
      #  agent_type: "newrelic/io.opentelemetry.collector:0.1.0"
    ```
  </Collapser>
</CollapserGroup>