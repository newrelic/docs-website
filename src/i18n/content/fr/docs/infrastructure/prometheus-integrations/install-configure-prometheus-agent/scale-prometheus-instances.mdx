---
title: Mise à l'échelle de l'instance de l'agent Prometheus
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure Prometheus agent
metaDescription: Scaling Prometheus agent instances
freshnessValidatedDate: never
translationType: machine
---

À mesure que la taille du cluster augmente, davantage de données sont collectées par Prometheus et, à un moment donné, les limites de la quantité de données que l&apos;agent Prometheus peut traiter sont atteintes. Le mode de défaillance le plus courant est le manque de mémoire en raison de la cardinalité accrue de la série temporelle. Lorsque cela se produit, votre instance Prometheus commence à mourir car elle a besoin de plus de mémoire, ce qui signifie que vous devez commencer à évoluer.

Pour analyser la solution en détail, nous fournissons un dashboard avec différents graphiques qui nous aident à savoir quand nous devons faire évoluer notre solution Prometheus .

Il existe deux approches de mise à l&apos;échelle différentes pour l&apos;agent Prometheus de New Relic : verticale ou horizontale.

## Mise à l&apos;échelle verticale [#vertical]

Ce type de mise à l’échelle ne présente aucune complexité. C&apos;est aussi simple que de mettre à jour la mémoire ou le processeur de la machine correspondante sur laquelle se trouve le nœud du cluster.

Cependant, cette approche peut ne pas être évolutive pour un grand cluster, ou nous ne voulons tout simplement pas avoir un seul pod qui consomme autant de Go de mémoire dans notre nœud. Si tel est le cas, vous devrez peut-être utiliser une mise à l’échelle horizontale.

## Mise à l&apos;échelle horizontale [#horizontal]

La mise à l&apos;échelle horizontale, également connue sous le nom de sharding, est prise en charge par la configuration d&apos;un paramètre configuration qui permet d&apos;exécuter plusieurs serveurs Prometheus en mode agent pour collecter vos données.

Si vous définissez la valeur `sharding.total_shards_count` , l&apos;exécution `StatefulSet` inclura autant de répliques que vous définissez. Lorsque vous l&apos;utilisez, le composant *configurateur* inclut automatiquement des règles de réétiquetage supplémentaires, de sorte que chaque cible n&apos;est récupérée que par un seul serveur Prometheus. Ces règles s&apos;appuient sur l&apos;adresse de la cible [hacher-mod](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config).

Pour définir les règles de réétiquetage pour chaque cible, l&apos;agent calcule un hacher pour la cible donnée `__address__` puis il applique le `modulus` au hacher, le module étant le nombre total de fragments. Ensuite, il connaît le fragment dans lequel la cible récupérée doit être incluse.

Par exemple, si vous incluez les éléments suivants dans le fichier `custom-values.yaml` :

```yaml
# (...)
sharding:
  total_shards_count: 2
# (...)
```

Et ensuite, vous mettez à niveau la sortie en exécutant :

```shell
helm upgrade my-prometheus-release newrelic-prometheus-configurator/newrelic-prometheus-agent -f custom-values.yaml
```

Ensuite, deux serveurs Prometheus seront exécutés et chaque cible ne sera scrapée que par l&apos;un d&apos;entre eux.

Un exemple de diagramme serait le suivant :

<img src="/images/infrastructure_diagram_prometheus-sharding.webp" alt="Prometheus sharding" title="Prometheus sharding" />

### Identification du grattoir cible [#target-scraper-id]

L&apos;identification du fragment (nom du `StatefulSet Pod`) est ajoutée en tant qu&apos;étiquette `prometheus_server` à toutes les métriques et vous pouvez l&apos;utiliser pour comprendre quelle instance Prometheus récupère chaque cible.

Pour identifier de manière unique une instance de serveur Prometheus au sein d&apos;un compte, vous devez utiliser une combinaison des étiquettes `cluster_name` et `prometheus_server` .

### Auto-métriques [#self-metrics]

Les auto-métriques du serveur Prometheus doivent être collectées à partir de tous les serveurs Prometheus, donc les règles supplémentaires lors de la configuration sharding ne s&apos;appliquent pas au travail de collecte des auto-métriques Prometheus. Cela est possible car l&apos;agent accepte l&apos;indicateur `skip_sharding` dans les tâches `static_target` . Ce paramètre est déjà défini dans la tâche d&apos;auto-métriques par défaut.

### Limites [#limitations]

Si vous incluez des tâches de scraping supplémentaires dans la configuration en tant `extra_scrape_configs` que, étant donné que ce champ contient la définition brute des tâches Prometheus, l&apos;agent n&apos;inclura pas les règles correspondant à sharding configuration et, par conséquent, la cible correspondante sera supprimée par tous les serveurs Prometheus.

Actuellement, la mise à l&apos;échelle automatique n&apos;est pas prise en charge. Pour augmenter ou diminuer le nombre de fragments, vous devez mettre à jour les paramètres du graphique, ce qui redémarre le pod Prometheus.