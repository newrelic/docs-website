---
title: Configurer l'intégration de Prometheus OpenMetrics
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure OpenMetrics
metaDescription: Configuration options and examples for your Prometheus OpenMetrics integration with New Relic in Docker and Kubernetes environments.
freshnessValidatedDate: never
translationType: machine
---

Sauf indication contraire, les options de configuration de votre intégration Prometheus OpenMetrics avec New Relic s&apos;appliquent aux environnements Docker et Kubernetes. Au minimum, les valeurs de configuration suivantes sont <DNT>**required**</DNT>:

* <InlinePopover type="licenseKey" />
* [Nom Cluster](#definitions-configuration-file)

Recommandation : configurez votre clé de licence New Relic en tant que variable d’environnement nommée `LICENSE_KEY`. Cela fournit un environnement plus sécurisé, car New Relic peut charger votre variable d&apos;environnement à partir d&apos;un [secret d&apos;authentification TLS mutuel](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints).

## Configurer nri-prometheus-latest.yaml [#general-config]

Le fichier manifeste `nri-prometheus-latest.yaml` inclut la carte `nri-prometheus-cfg` montrant un exemple de configuration. Utilisez le fichier manifeste pour configurer les paramètres suivants.

<CollapserGroup>
  <Collapser id="example-configuration-file" title="Exemple de fichier de configuration">
    Voici un exemple de fichier de configuration que vous pouvez enregistrer et modifier pour l&apos;adapter à vos besoins. Pour plus d&apos;informations, consultez la documentation sur [l&apos;authentification TLS mutuelle](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) et [la traduction de PromQL en NRQL](/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql).

    ```
    # The name of your cluster. It's important to match other New Relic products to relate the data.
    cluster_name: "<YOUR_CLUSTER_NAME>"

    # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true
    # standalone: true

    # How often the integration should run. Defaults to 30s.
    # scrape_duration: "30s"

    # The HTTP client timeout when fetching data from targets. Defaults to 5s.
    # scrape_timeout: "5s"

    # How old must the entries used for calculating the counters delta be
    # before the telemetry emitter expires them. Defaults to 5m.
    # telemetry_emitter_delta_expiration_age: "5m"

    # How often must the telemetry emitter check for expired delta entries.
    # Defaults to 5m.
    # telemetry_emitter_delta_expiration_check_interval: "5m"

    # Wether the integration should run in verbose mode or not. Defaults to false.
    verbose: false

    # Whether the integration should run in audit mode or not. Defaults to false.
    # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent.
    # It does not include verbose mode. This can lead to a high log volume, use with care.
    audit: false

    # Wether the integration should skip TLS verification or not. Defaults to false.
    insecure_skip_verify: false

    # The label used to identify scrapable targets. Defaults to "prometheus.io/scrape".
    scrape_enabled_label: "prometheus.io/scrape"

    # scrape_services Allows to enable scraping the service and not the endpoints behind.
    # When endpoints are scraped this is no longer needed
    scrape_services: true

    # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does.
    # Please notice that depending on the number of endpoints behind a service the load can increase considerably
    scrape_endpoints: false

    # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true.
    require_scrape_enabled_label_for_nodes: true

    # Number of worker threads used for scraping targets.
    # For large clusters with many (>400) targets, slowly increase until scrape
    # time falls between the desired `scrape_duration`.
    # Increasing this value too much will result in huge memory consumption if too
    # many metrics are being scraped.
    # Default: 4
    # worker_threads: 4

    # Maximum number of metrics to keep in memory until a report is triggered.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # max_stored_metrics: 10000

    # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # min_emitter_harvest_period: 200ms

    # targets:
    #   - description: Secure etcd example
    #     urls: ["https://192.168.3.1:2379", "https://192.168.3.2:2379", "https://192.168.3.3:2379"]
    #     tls_config:
    #       ca_file_path: "/etc/etcd/etcd-client-ca.crt"
    #       cert_file_path: "/etc/etcd/etcd-client.crt"
    #       key_file_path: "/etc/etcd/etcd-client.key"

    # Proxy to be used by the emitters when submitting metrics. It should be
    # in the format [scheme]://[domain]:[port].
    # The emitter is the component in charge of sending the scraped metrics.
    # This proxy won't be used when scraping metrics from the targets.
    # By default it's empty, meaning that no proxy will be used.
    # emitter_proxy: "http://localhost:8888"

    # Certificate to add to the root CA that the emitter will use when
    # verifying server certificates.
    # If left empty, TLS uses the host's root CA set.
    # emitter_ca_file: "/path/to/cert/server.pem"

    # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account
    # having limited privileges. Defaults to false.
    # disable_autodiscovery: false

    # Whether the emitter should skip TLS verification when submitting data.
    # Defaults to false.
    # emitter_insecure_skip_verify: false

    # Histogram support is based on New Relic's guidelines for higher
    # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md.
    # To better support visualization of this data, percentiles are calculated
    # based on the histogram metrics and sent to New Relic.
    # By default, the following percentiles are calculated: 50, 95 and 99.
    #
    # percentiles:
    #   - 50
    #   - 95
    #   - 99

    # transformations:
    #   - description: "General processing rules"
    #     rename_attributes:
    #       - metric_prefix: ""
    #         attributes:
    #           container_name: "containerName"
    #           pod_name: "podName"
    #           namespace: "namespaceName"
    #           node: "nodeName"
    #           container: "containerName"
    #           pod: "podName"
    #           deployment: "deploymentName"
    #     ignore_metrics:
    #       # Ignore all the metrics except the ones listed below.
    #       # This is a list that complements the data retrieved by the New
    #       # Relic Kubernetes Integration, that's why Pods and containers are
    #       # not included, because they are already collected by the
    #       # Kubernetes Integration.
    #       - except:
    #         - kube_hpa_
    #         - kube_daemonset_
    #         - kube_statefulset_
    #         - kube_endpoint_
    #         - kube_service_
    #         - kube_limitrange
    #         - kube_node_
    #         - kube_poddisruptionbudget_
    #         - kube_resourcequota
    #         - nr_stats
    #     copy_attributes:
    #       # Copy all the labels from the time series with metric name
    #       # `kube_hpa_labels` into every time series with a metric name that
    #       # starts with `kube_hpa_` only if they share the same `namespace`
    #       # and `hpa` labels.
    #       - from_metric: "kube_hpa_labels"
    #         to_metrics: "kube_hpa_"
    #         match_by:
    #           - namespace
    #           - hpa
    #       - from_metric: "kube_daemonset_labels"
    #         to_metrics: "kube_daemonset_"
    #         match_by:
    #           - namespace
    #           - daemonset
    #       - from_metric: "kube_statefulset_labels"
    #         to_metrics: "kube_statefulset_"
    #         match_by:
    #           - namespace
    #           - statefulset
    #       - from_metric: "kube_endpoint_labels"
    #         to_metrics: "kube_endpoint_"
    #         match_by:
    #           - namespace
    #           - endpoint
    #       - from_metric: "kube_service_labels"
    #         to_metrics: "kube_service_"
    #         match_by:
    #           - namespace
    #           - service
    #       - from_metric: "kube_node_labels"
    #         to_metrics: "kube_node_"
    #         match_by:
    #           - namespace
    #           - node
    # integration definition files required to map metrics to entities
    # definition_files_path: /etc/newrelic-infra/definition-files
    ```
  </Collapser>

  <Collapser id="definitions-configuration-file" title="Noms clés et définitions">
    Voici quelques noms et définitions clés pour votre fichier de configuration Prometheus OpenMetrics.

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px" }}>
            Nom de la clé
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr id="cluster-name">
          <td>
            `cluster_name`

            <DNT>
              **Required.**
            </DNT>
          </td>

          <td>
            Le nom du cluster. Cette valeur sera incluse comme attribut `clusterName` pour toutes les métriques.
          </td>
        </tr>

        <tr id="verbose">
          <td>
            `verbose`
          </td>

          <td>
            Booléen stringifié.

            * `true` (par défaut) : enregistrer les informations de débogage.
            * `false`: Enregistrer uniquement les messages d&apos;erreur.
          </td>
        </tr>

        <tr id="targets">
          <td>
            `targets`
          </td>

          <td>
            configuration du point de terminaison statique à gratter par l&apos;intégration. Il contient une liste d&apos;objets. Pour plus d&apos;informations sur cette structure, consultez la documentation sur [la configuration cible](#target-config).
          </td>
        </tr>

        <tr id="scrape-enabled-label">
          <td>
            `scrape_enabled_label`

            <img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

            <DNT>**Kubernetes**</DNT>
          </td>

          <td>
            Chaîne. L&apos;intégration vérifiera si le pod et le service Kubernetes sont annotés ou ont une étiquette avec cette valeur pour décider s&apos;ils doivent être récupérés.

            Cela est particulièrement utile lorsque vous souhaitez limiter la quantité de données en ignorant les métriques ou en incluant des métriques spécifiques envoyées à New Relic. Étant donné que par défaut nous utilisons la même étiquette que Prometheus utilise pour découvrir les cibles qui peuvent être récupérées, la plupart des exportateurs que vous installez définissent automatiquement cette étiquette.

            Pour garder un contrôle précis sur la cible que vous souhaitez que l&apos;intégration récupère, vous pouvez définir cette option sur une autre valeur (telle que `newrelic/scrape`), puis ajouter l&apos;annotation ou l&apos;étiquette `newrelic/scrape: "true"` à vos objets Kubernetes . Si les deux sont définis, les annotations ont la priorité sur les étiquettes.

            Défaut: `"prometheus.io/scrape"`
          </td>
        </tr>

        <tr id="scrape-duration">
          <td>
            `scrape_duration`
          </td>

          <td>
            À quelle fréquence le grattoir doit-il fonctionner ?

            * Pour réduire l&apos;utilisation de la mémoire, augmentez cette valeur.

            * Pour augmenter l&apos;utilisation de la mémoire, diminuez cette valeur.

              L&apos;impact sur l&apos;utilisation de la mémoire est dû à la répartition de la récupération de la cible sur l&apos;intervalle de récupération pour éviter d&apos;interroger (et de mettre en mémoire tampon) toutes les données à la fois.

              La valeur par défaut est `30s`. Les valeurs valides incluent `1s`, `15s`, `30s`, `1m`, `5m`, etc.
          </td>
        </tr>

        <tr id="scrape-timeout">
          <td>
            `scrape_timeout`
          </td>

          <td>
            Le délai d&apos;expiration du client HTTP lors de la récupération des données à partir du point de terminaison.

            Par défaut : `5s`. Les valeurs valides incluent `1s`, `15s`, `30s`, `1m`, `5m`, etc.
          </td>
        </tr>

        <tr>
          <td>
            `worker_threads`
          </td>

          <td>
            Nombre de threads de travail utilisés pour le scraping de la cible. Peut être augmenté dans les environnements avec un nombre élevé de cibles ou des cibles avec une latence élevée, mais peut augmenter la consommation de mémoire.

            Par défaut : `4`. Il n&apos;est pas recommandé d&apos;en utiliser plus de 10.
          </td>
        </tr>

        <tr>
          <td>
            `require_scrape_enabled_label_for_nodes`

            <img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

            <DNT>**Kubernetes**</DNT>
          </td>

          <td>
            Si les nœuds Kubernetes ont besoin ou non d&apos;étiquettes à récupérer.

            Par défaut : `true`.
          </td>
        </tr>

        <tr id="percentiles">
          <td>
            `percentiles`
          </td>

          <td>
            La prise en charge de l&apos;histogramme est basée sur [les directives de New Relic pour les abstractions de métriques de niveau supérieur](https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md).

            Pour mieux prendre en charge la visualisation de ces données, les centiles sont calculés sur la base des métriques de l&apos;histogramme et envoyés à New Relic. Les valeurs valides incluent `50`, `95` et `99`.
          </td>
        </tr>

        <tr>
          <td id="emitter-proxy">
            `emitter_proxy`
          </td>

          <td>
            Proxy utilisé par l&apos;intégration lors de la soumission des métriques :

            `[scheme]://[domain]:[port]`

            Ce proxy ne sera pas utilisé lors de la récupération des métriques de la cible.

            Par défaut, ce champ est vide et aucun proxy ne sera utilisé.
          </td>
        </tr>

        <tr>
          <td id="emitter-ca-file">
            `emitter_ca_file`
          </td>

          <td>
            Certificat à ajouter à l&apos;autorité de certification racine que l&apos;émetteur utilisera lors de la vérification des certificats du serveur. Si ce champ est laissé vide, TLS utilise l&apos;ensemble d&apos;autorités de certification racine de l&apos;hôte.
          </td>
        </tr>

        <tr id="emitter-insecure-skip-verify">
          <td>
            `emitter_insecure_skip_verify`
          </td>

          <td>
            Si l&apos;émetteur doit ignorer la vérification TLS lors de la soumission des données. Par défaut : `false`.
          </td>
        </tr>

        <tr id="disable-autodiscovery">
          <td>
            `disable_autodiscovery`
          </td>

          <td>
            Définissez sur vrai afin de désactiver la découverte automatique dans le cluster k8s. Cela peut être utile lors de l’exécution du pod avec un compte de service disposant de privilèges limités. Par défaut : `false`.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Configurer les objets dans la clé cible [#target-config]

Si vous souhaitez que la clé cible dans le fichier de configuration contienne un ou plusieurs objets, utilisez la structure suivante dans la liste YAML :

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        Nom de la clé
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr id="description">
      <td>
        `description`
      </td>

      <td>
        Une description des URL dans cette cible.
      </td>
    </tr>

    <tr id="urls">
      <td>
        `urls`
      </td>

      <td>
        Une liste de chaînes contenant les URL à extraire.
      </td>
    </tr>

    <tr id="tls-config">
      <td>
        `tls_config`
      </td>

      <td>
        configuration d&apos;authentification utilisée pour envoyer requests. Il prend en charge TLS et Mutual TLS. Pour plus d&apos;informations, consultez la documentation sur [l&apos;authentification TLS mutuelle](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints).
      </td>
    </tr>
  </tbody>
</table>

<CollapserGroup>
  <Collapser
    id="specify-path-port"
    title={<><img src="/images/os_icon_k8.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ width: '30px', height: '25px' }} /></>
    }
  >
    L&apos;intégration Prometheus OpenMetrics de New Relic découvre automatiquement quelle cible gratter. Pour spécifier le port et le chemin du point de terminaison à utiliser lors de la construction de la cible, vous pouvez utiliser les annotations ou l&apos;étiquette `prometheus.io/port` et `prometheus.io/path` dans votre pod et vos services Kubernetes . Les annotations ont priorité sur les étiquettes.

    * Si `prometheus.io/port` n&apos;est pas présent, l&apos;intégration tentera de récupérer chaque `port` ou `ContainerPort` défini pour le service.
    * Si `prometheus.io/path` n&apos;est pas présent, l&apos;intégration sera par défaut `/metrics`.
    * Si un service ne s&apos;exécute pas sur le chemin par défaut `/my-metrics-path` , ajoutez une étiquette au pod `prometheus.io/path=my-metrics-path`. Si le chemin d’accès au point de terminaison des métriques est plus complexe et ne peut pas être une valeur d’étiquette valide (par exemple, `foo/bar`), utilisez plutôt des annotations.
  </Collapser>

  <Collapser
    id="example-port-path"
    title={<><img src="/images/os_icon_k8.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ width: '30px', height: '25px' }} /></>
    }
  >
    Dans cet exemple, vous avez un déploiement dans votre cluster, et le pod expose les métriques Prometheus sur le port `8080` et dans le chemin `my-metrics.`

    Dans les métadonnées `PodSpec` du manifeste de déploiement, définissez les étiquettes `prometheus.io/port: "8080"` et `prometheus.io/path: "my-metrics"`. Lorsque l&apos;intégration tente de récupérer les métriques de votre pod, elle enverra une requête à `http://<pod-ip>:8080/my-metrics`.

    ```
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-deployment
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: my-app
      template:
        metadata:
          labels:
            app: my-app
            prometheus.io/scrape: "true"
            prometheus.io/port: "8080"
            prometheus.io/path: "my-metrics"
    ```
  </Collapser>
</CollapserGroup>

## Comportement de grattage des services et des points de terminaison

Par défaut, les services sont récupérés directement au lieu du point de terminaison sous-jacent puisque `scrape_services` est défini sur `true` et `scrape_endpoints` sur `false`.

Afin de modifier ce comportement, définissez `scrape_endpoints` sur `true` en configurant `Prometheus OpenMetrics integrations` pour récupérer le point de terminaison sous-jacent, comme le fait nativement le serveur Prometheus , au lieu de récupérer directement les services.

Veuillez noter qu&apos;en fonction du nombre de points de terminaison derrière les services du cluster , la charge et les données ingérées peuvent augmenter considérablement, monitorer et, si nécessaire, augmenter les besoins en ressources.

De plus, même s&apos;il est possible de définir à la fois `scrape_services` et `scrape_endpoints` sur vrai pour assurer la rétrocompatibilité, cela conduirait à des données en double.

## Recharger la configuration [#reload-config]

L&apos;intégration Prometheus OpenMetrics <DNT>**does not**</DNT> recharge automatiquement la configuration lorsque vous apportez des modifications au fichier de configuration.

<img style={{ width: '30px', height: '25px'}} class="inline" title="Docker icon" alt="Docker icon" src="/images/os_icon_docker.webp" />

<DNT>**Docker**</DNT>

Pour recharger la configuration, redémarrez le conteneur exécutant l&apos;intégration :

```
docker restart nri-prometheus
```

<img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

<DNT>**Kubernetes**</DNT>

Pour recharger la configuration, redémarrez l&apos;intégration. Recommandation : réduisez le déploiement à zéro réplique, puis réduisez-le à une seule réplique :

```
kubectl scale deployment nri-prometheus --replicas=0
kubectl scale deployment nri-prometheus --replicas=1
```

## Docker : exécuter le fichier de configuration précédent [#run-previous]

<img style={{ width: '30px', height: '25px'}} class="inline" title="Docker icon" alt="Docker icon" src="/images/os_icon_docker.webp" />

<DNT>**Docker:**</DNT> Pour exécuter l’intégration avec le fichier de configuration précédent :

1. Copiez le contenu et enregistrez-le dans un fichier `config.yaml` .

2. Depuis le même répertoire, exécutez la commande :

   ```
   docker run -d --restart unless-stopped \
       --name nri-prometheus \
       -e CLUSTER_NAME="YOUR_CLUSTER_NAME" \
       -e LICENSE_KEY="YOUR_LICENSE_KEY" \
       -v "$(pwd)/config.yaml:/config.yaml" \
       newrelic/nri-prometheus:latest --configfile=/config.yaml
   ```