---
title: Intégration monitoring Amazon EFS
tags:
  - Integrations
  - Amazon integrations
  - AWS integrations list
metaDescription: 'New Relic''s Amazon EFS monitoring integration: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

<Callout variant="important">
  Activez l&apos; [intégrationAWS CloudWatch Metric Streams ](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/)pour monitorer toutes les métriques CloudWatch de vos services AWS, y compris l&apos;espace de nommage personnalisé. L’intégration individuelle n’est plus notre option recommandée.
</Callout>

[L&apos;intégration de New Relic](/docs/infrastructure/introduction-infra-monitoring) inclut une intégration Amazon EFS pour signaler vos données EFS à New Relic. Ce document explique la fonctionnalité de l&apos;intégration, comment l&apos;activer et quelles données peuvent être signalées.

## Caractéristiques [#features]

Avec l&apos;intégration de New Relic pour monitoring [du système de fichiers AWS Elastic (EFS)](http://docs.aws.amazon.com/efs/latest/ug/whatisefs.html), vous pouvez monitorer la taille du système de fichiers EFS, les opérations de lecture/écriture, la capacité d&apos;I/O , le débit, etc. Les données d&apos;intégration AWS sont également disponibles pour [l&apos;analyse, la requête et la création de graphiques](/docs/infrastructure/infrastructure-integrations/getting-started/connect-aws-integrations-infrastructure#insights).

Si vous êtes connecté via un [VPC](/docs/infrastructure/amazon-integrations/amazon-integrations/aws-vpc-monitoring-integration), vous pouvez également utiliser le système de fichiers EFS avec vos propres serveurs sur site, ce qui vous permet de partager le système de fichiers entre différentes applications hébergées sur des solutions hybrides.

## Activer l&apos;intégration [#activate]

Pour activer cette intégration, suivez les procédures standard pour [connecter les services AWS à New Relic](/docs/infrastructure/infrastructure-integrations/getting-started/connect-aws-integrations-infrastructure).

## configuration et sondage [#polling]

Vous pouvez modifier la fréquence d&apos;interrogation et filtrer les données à l&apos;aide [des options de configuration](/docs/integrations/new-relic-integrations/getting-started/configure-polling-frequency-data-collection-cloud-integrations).

Informations [d&apos;interrogation par défaut](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-polling-intervals-infrastructure-integrations) pour l&apos;intégration Amazon EFS :

* Intervalle d&apos;interrogation de New Relic : 5 minutes
* Intervalle de données Amazon CloudWatch : 1 minute ou 5 minutes

## Rechercher et utiliser des données [#find-data]

Pour trouver les données de cette intégration, accédez à <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Infrastructure &amp;gt; AWS**</DNT> et sélectionnez l’un des liens d’intégration Amazon EFS.

Vous pouvez [interroger et explorer vos données](/docs/using-new-relic/data/understand-data/query-new-relic-data) en utilisant le [type d&apos;événement](/docs/data-apis/understand-data/new-relic-data-types/#event-data) `BlockDeviceSample`, avec une valeur `provider` de `EfsFileSystem`.

Pour en savoir plus sur la recherche et l’utilisation des données d’intégration, consultez [Comprendre les données d’intégration](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## données métriques [#metrics]

Cette intégration collecte les métriques Amazon EFS suivantes :

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        métrique
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `BurstCreditBalance`
      </td>

      <td>
        Le nombre de crédits en rafale dont dispose un système de fichiers.

        Les crédits en rafale permettent à un système de fichiers d&apos;atteindre des niveaux de débit supérieurs au niveau de base de référence d&apos;un système de fichiers pendant un certain temps. Pour plus d’informations, consultez [Mise à l’échelle du débit dans Amazon EFS](http://docs.aws.amazon.com/efs/latest/ug/performance.html#bursting).

        La statistique `Minimum` est le plus petit solde de crédit en rafale pour une minute quelconque au cours de la période. La statistique `Maximum` représente le solde de crédit le plus élevé pour une minute donnée au cours de la période. La statistique `Average` correspond au solde moyen du crédit d&apos;éclatement au cours de la période.

        Unités : octets

        Statistiques valides : `Minimum, Maximum, Average`
      </td>
    </tr>

    <tr>
      <td>
        `ClientConnections`
      </td>

      <td>
        Le nombre de connexions client à un système de fichiers. Lors de l&apos;utilisation d&apos;un client standard, il existe une connexion par instanceAmazon EC2 montée.

        Remarque : pour calculer la moyenne `ClientConnections` pour les périodes supérieures à une minute, divisez la statistique `Sum` par le nombre de minutes de la période.

        Unités : Nombre de connexions client

        Statistiques valides : `Sum`
      </td>
    </tr>

    <tr>
      <td>
        `DataReadIOBytes`
      </td>

      <td>
        Le nombre d&apos;octets pour chaque opération de lecture du système de fichiers.

        La statistique `Sum` est le nombre total d&apos;octets associés aux opérations de lecture. La statistique `Minimum` est la taille de la plus petite opération de lecture pendant la période. La statistique `Maximum` correspond à la taille de la plus grande opération de lecture au cours de la période. La statistique `Average` est la taille moyenne des opérations de lecture au cours de la période. La statistique `SampleCount` fournit un décompte des opérations de lecture.

        Unités:

        * Octets pour `Minimum, Maximum, Average,` et `Sum`.

        * Comptez pour `SampleCount`.

          Statistiques valides : `Minimum, Maximum, Average, Sum, SampleCount`
      </td>
    </tr>

    <tr>
      <td>
        `DataWriteIOBytes`
      </td>

      <td>
        Le nombre d&apos;octets pour chaque opération d&apos;écriture du système de fichiers.

        La statistique `Sum` est le nombre total d&apos;octets associés aux opérations d&apos;écriture. La statistique `Minimum` est la taille de la plus petite opération d&apos;écriture pendant la période. La statistique `Maximum` correspond à la taille de la plus grande opération d’écriture au cours de la période. La statistique `Average` est la taille moyenne des opérations d&apos;écriture au cours de la période. La statistique `SampleCount` fournit un décompte des opérations d&apos;écriture.

        Unités:

        * Les octets sont les unités des statistiques `Minimum, Maximum, Average` et `Sum` .

        * Comptez pour `SampleCount`.

          Statistiques valides : `Minimum, Maximum, Average, Sum, SampleCount`
      </td>
    </tr>

    <tr>
      <td>
        `MetadataIOBytes`
      </td>

      <td>
        Le nombre d&apos;octets pour chaque opération de métadonnées.

        La statistique `Sum` est le nombre total d&apos;octets associés aux opérations de métadonnées. La statistique `Minimum` correspond à la taille de la plus petite opération de métadonnées au cours de la période. La statistique `Maximum` correspond à la taille de la plus grande opération de métadonnées au cours de la période. La statistique `Average` correspond à la taille de l’opération moyenne de métadonnées au cours de la période. La statistique `SampleCount` fournit un décompte des opérations de métadonnées.

        Unités:

        * Les octets sont les unités des statistiques `Minimum, Maximum, Average,` et `Sum` .

        * Comptez pour `SampleCount`.

          Statistiques valides : `Minimum, Maximum, Average, Sum, SampleCount`
      </td>
    </tr>

    <tr>
      <td>
        `PercentIOLimit`
      </td>

      <td>
        Affiche à quel point un système de fichiers est proche d&apos;atteindre la limite d&apos;I/O du mode de performance à usage général. Si cette métrique est à 100 % la plupart du temps, envisagez de déplacer votre application vers un système de fichiers utilisant le mode de performance I/O max.

        Remarque : cette métrique est uniquement soumise pour le système de fichiers utilisant le mode de performance à usage général.

        Unités : Pourcentage
      </td>
    </tr>

    <tr>
      <td>
        `PermittedThroughput`
      </td>

      <td>
        La quantité maximale de débit autorisée par un système de fichiers, compte tenu de la taille du système de fichiers et `BurstCreditBalance`. Pour plus d’informations, consultez [Performances d’Amazon EFS](http://docs.aws.amazon.com/efs/latest/ug/performance.html).

        La statistique `Minimum` est le plus petit débit autorisé pour une minute au cours de la période. La statistique `Maximum` correspond au débit le plus élevé autorisé pour une minute au cours de la période. La statistique `Average` est le débit moyen autorisé pendant la période.

        Unités : octets par seconde

        Statistiques valides : `Minimum, Maximum, Average`
      </td>
    </tr>

    <tr>
      <td>
        `TotalIOBytes`
      </td>

      <td>
        Le nombre d&apos;octets pour chaque opération du système de fichiers, y compris les opérations de lecture de données, d&apos;écriture de données et de métadonnées.

        La statistique `Sum` est le nombre total d&apos;octets associés à toutes les opérations du système de fichiers. La statistique `Minimum` correspond à la taille de la plus petite opération au cours de la période. La statistique `Maximum` correspond à la taille de la plus grande opération au cours de la période. La statistique `Average` est la taille moyenne d’une opération au cours de la période. La statistique `SampleCount` fournit un décompte de toutes les opérations.

        Remarque : pour calculer le nombre moyen d&apos;opérations par seconde pour une période, divisez la statistique `SampleCount` par le nombre de secondes de la période. Pour calculer le débit moyen (octets par seconde) pour une période, divisez la statistique `Sum` par le nombre de secondes de la période.

        Unités:

        * Octets pour les statistiques `Minimum, Maximum, Average,` et `Sum` .

        * Comptez pour `SampleCount`.

          Statistiques valides : `Minimum, Maximum, Average, Sum, SampleCount`
      </td>
    </tr>
  </tbody>
</table>