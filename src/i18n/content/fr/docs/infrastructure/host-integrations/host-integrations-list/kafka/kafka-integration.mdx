---
title: Intégration monitoring Kafka
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: 'New Relic''s Kafka integration: how to install it and configure it, and what data it reports.'
freshnessValidatedDate: never
translationType: machine
---

L&apos;[intégration sur hôte](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) de New Relic Kafka génère des rapports sur les métriques et les données de configuration de votre service Kafka. Nous instrumentons tous les éléments clés de votre cluster, y compris les courtiers (ZooKeeper et Bootstrap), les producteurs, les consommateurs et les sujets.

Pour installer l&apos;intégration monitoring Kafka, vous devez suivre les étapes suivantes :

1. [Préparez l&apos;installation](#prepare).
2. [Installer et activer l&apos;intégration](#install).
3. [Configurer l&apos;intégration](#config).
4. [Rechercher et utiliser des données](#find-and-use).
5. En option, consultez [les paramètres de configuration de Kafka](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config).

<Callout variant="tip">
  Pour en savoir plus sur les bonnes pratiques lors monitoring de Kafka, consultez [cet article de blog](https://newrelic.com/blog/best-practices/new-relic-kafkapocalypse).
</Callout>

## Compatibilité et exigences [#req]

### Versions de Kafka [#kafka-versions]

Notre intégration est compatible avec Kafka version 3 ou inférieure.

Veuillez noter [la politique EOL d&apos;Apache Kafka](https://cwiki.apache.org/confluence/display/KAFKA/Time+Based+Release+Plan#TimeBasedReleasePlan-WhatIsOurEOLPolicy) car vous pouvez rencontrer des résultats inattendus si vous utilisez une version Kafka [en fin de vie](https://docs.confluent.io/platform/current/installation/versions-interoperability.html#cp-and-apache-ak-compatibility) .

### Système d&apos;exploitation pris en charge [#supported-os]

* Windows<img style={{ width: '32px', height: '32px'}} class="inline" title="Windows" alt="Windows" src="/images/os_icon_windows.webp" />
* Linux<img style={{ width: '32px', height: '32px'}} class="inline" title="Linux" alt="Linux" src="/images/os_icon_linux.webp" />

Pour une liste complète des versions spécifiques Windows et Linux, consultez le tableau des [systèmes d&apos;exploitation compatibles](/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/#operating-systems).

### exigences système [#system-reqs]

* Un compte New Relic. Vous n&apos;en avez pas ? [Inscrivez-vous gratuitement !](https://newrelic.com/signup) Aucune carte de crédit requise.

* Si Kafka ne s&apos;exécute pas sur Kubernetes ou Amazon ECS, vous pouvez [installer l&apos;agent d&apos;infrastructure](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) sur un hôte Linux ou Windows OS ou sur un hôte capable d&apos;accéder à distance à l&apos;endroit où Kafka est installé. Sinon:

  * Si vous exécutez sur<img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src="/images/os_icon_k8.webp">Kubernetes, voir [ces exigences](/docs/monitor-service-running-kubernetes#requirements).</img>
  * Si vous exécutez sur<img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src="/images/os_icon_ecs.webp">Amazon ECS, consultez [ces exigences](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).</img>

* Java version 8 ou supérieure.

* JMX activé sur tous les courtiers.

* Consommateur et producteurs basés sur Java uniquement, et avec JMX activé.

* Le nombre total de sujets de monitoring doit être inférieur à 10 000.

### Exigences de connectivité [#connectivity-requirements]

L&apos;intégration doit être configurée et autorisée à se connecter à :

* Hôtes répertoriés dans `zookeeper_hosts` via le protocole Zookeeper, en utilisant le mécanisme d&apos;authentification Zookeeper, si `autodiscover_strategy` est défini sur `zookeeper`.
* Hôtes définis dans `bootstrap_broker_host` sur le protocole Kafka, en utilisant les mécanismes d&apos;authentification/transport du courtier Kafka, si `autodiscover_strategy` est défini sur `bootstrap`.
* Tous les courtiers du cluster via le protocole et le port Kafka, utilisant les mécanismes d&apos;authentification/transport des courtiers Kafka.
* Tous les courtiers du cluster via le protocole et le port JMX, utilisant les mécanismes d&apos;authentification/transport spécifiés dans la configuration JMX des courtiers.
* Tous les producteurs/consommateurs spécifiés dans les producteurs et consommateurs via le protocole et le port JMX, si vous souhaitez monitoring des producteurs/consommateurs. Les paramètres JMX pour le consommateur doivent être les mêmes que pour les courtiers.

<Callout variant="important">
  Par défaut, les groupes de sécurité et leurs équivalents dans d&apos;autres fournisseurs de cloud, dans AWS, n&apos;ont pas les ports requis ouverts par défaut. JMX nécessite deux ports pour fonctionner : le port JMX et le port RMI. Ceux-ci peuvent être définis sur la même valeur lors de la configuration de la JVM pour activer JMX et doivent être ouverts pour que l&apos;intégration puisse se connecter et collecter des métriques auprès des courtiers.
</Callout>

## Préparez l&apos;installation [#prepare]

Kafka est un logiciel complexe construit comme un système distribué. Pour cette raison, vous devez vous assurer que l&apos;intégration peut contacter tous les hôtes et services requis afin que les données soient collectées correctement.

<CollapserGroup>
  <Collapser id="autodiscovery" title="Découverte automatique">
    Étant donné la nature distribuée de Kafka, le nombre réel et la liste des courtiers ne sont généralement pas fixés par la configuration, et sont plutôt dynamiques. Pour cette raison, l&apos;intégration Kafka propose deux mécanismes pour effectuer la découverte automatique de la liste des courtiers du cluster : Bootstrap et Zookeeper. Le mécanisme que vous utilisez dépend de la configuration du cluster Kafka monitoré.

    ### Bootstrap

    Avec le [mécanismebootstrap ](#bootstrap), l&apos;intégration utilise un courtier bootstrap pour effectuer la découverte automatique. Il s&apos;agit d&apos;un courtier dont l&apos;adresse est bien connue et qui sera sollicité pour tout autre courtier qu&apos;il connaît. L&apos;intégration doit pouvoir contacter ce courtier à l&apos;adresse fournie dans le paramètre bootstrap\_broker\_host pour que la découverte d&apos;amorçage fonctionne.

    ### Zookeeper

    Alternativement, l&apos;intégration Kafka peut également communiquer avec un [serveur Zookeeper](#zookeeper) afin d&apos;obtenir la liste des courtiers. Pour ce faire, l’intégration doit être dotée des éléments suivants :

    * La liste des hôtes Zookeeper, `zookeeper_hosts`, à contacter.

    * Les secrets d&apos;authentification appropriés pour se connecter aux hôtes.

      En plus de la liste des courtiers qu&apos;il connaît, Zookeeper annoncera également les mécanismes de connexion pris en charge par chaque courtier.

      Vous pouvez configurer l&apos;intégration Kafka pour essayer directement avec l&apos;un de ces mécanismes avec le paramètre `preferred_listener` . Si ce paramètre n&apos;est pas fourni, l&apos;intégration tentera de contacter les courtiers avec toutes les configurations annoncées jusqu&apos;à ce que l&apos;un d&apos;entre eux réussisse.

      <Callout variant="tip">
        L&apos;intégration utilisera Zookeeper uniquement pour découvrir les courtiers et n&apos;en récupérera pas les métriques.
      </Callout>
  </Collapser>

  <Collapser id="topic-listing" title="Liste des sujets">
    Pour répertorier correctement les sujets traités par les courtiers, l&apos;intégration doit contacter les courtiers via le protocole Kafka. Selon la façon dont les courtiers sont configurés, cela peut nécessiter la configuration de SSL et/ou SASL pour correspondre à la configuration du courtier. Les sujets doivent avoir l&apos;accès DESCRIBE.
  </Collapser>

  <Collapser id="broker-monitoring" title="monitoring des courtiers (JMX)">
    La requête d&apos;intégration Kafka JMX, une extension Java standard pour l&apos;échange de métriques dans les applications Java . JMX n&apos;est pas activé par défaut dans les courtiers Kafka et vous devez l&apos;activer pour que la collecte de métriques fonctionne correctement. JMX nécessite que RMI soit activé et le port RMI doit être défini sur le même port que JMX.

    Vous pouvez configurer JMX pour utiliser l’authentification par nom d’utilisateur/mot de passe, ainsi que SSL. Si une telle fonctionnalité a été activée dans les paramètres JMX du courtier, vous devez configurer l&apos;intégration en conséquence.

    Si la découverte automatique est définie sur bootstrap, les paramètres JMX définis pour le courtier bootstrap seront appliqués à tous les autres courtiers découverts. Le port et les autres paramètres doivent donc être les mêmes sur tous les courtiers. <Callout variant="important">Nous ne recommandons pas d&apos;activer l&apos;accès JMX/RMI anonyme et/ou non chiffré sur des segments de réseau publics ou non fiables, car cela présente un risque de sécurité important.</Callout>
  </Collapser>

  <Collapser id="consumer-offset" title="consommateur décalé">
    Le décalage des groupes consommateur et consommateur des sujets ainsi que le décalage peuvent être récupérés sous forme de [KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection) avec l&apos;indicateur `CONSUMER_OFFSET=true` mais doivent être dans une instance distincte car lorsque cet indicateur est activé, l&apos;nstance ne collectera pas d&apos;autres échantillons.
  </Collapser>

  <Collapser id="producer" title="monitoring des producteurs et des consommateurs (JMX)">
    Les producteurs et consommateurs écrits en Java peuvent également être monitorés pour obtenir des métadonnées plus spécifiques via le même mécanisme (JMX). Cela générera [KafkaConsumerSamples et KafkaProducerSamples](#KafkaConsumerSample-collection). JMX doit être activé et configuré sur les applications où il n&apos;est pas activé par défaut.

    Les producteurs et consommateurs non Java ne prennent pas en charge JMX et ne sont donc pas pris en charge par l&apos;intégration Kafka.
  </Collapser>
</CollapserGroup>

## Installer et activer l&apos;intégration [#install]

Pour installer l&apos;intégration Kafka, suivez les instructions correspondant à votre environnement :

### Installation de Linux [#linux-install]

1. Suivez les instructions pour [installer une intégration](/docs/install-integrations-package) et remplacez la variable `INTEGRATION_FILE_NAME` par `nri-kafka`.

2. Modifiez le répertoire vers le dossier configuration de l&apos;intégration en exécutant :

   ```shell
   cd /etc/newrelic-infra/integrations.d
   ```

3. Copiez l’exemple de fichier de configuration en exécutant :

   ```shell
   sudo cp kafka-config.yml.sample kafka-config.yml
   ```

4. Modifiez le fichier de configuration `kafka-config.yml` avec votre éditeur préféré. Découvrez quelques [exemples de fichiers de configuration.](#examples).

### Autres environnements [#other-env]

<CollapserGroup>
  <Collapser
    id="windows-install"
    title={<><img src="/images/os_icon_windows.webp" title="Windows installation" alt="Windows installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }} /></>
    }
  >
    1. [Téléchargez le programme .exe d&apos;installation pour l&apos;intégration de Kafka de New Relic](https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-kafka/nri-kafka-amd64-installer.exe).

    2. Pour installer à partir de l’invite de commande Windows, exécutez :

       ```shell
       PATH\TO\nri-kafka-amd64-installer.exe
       ```

    3. Dans le répertoire d’intégration, `C:\Program Files\New Relic\newrelic-infra\integrations.d\`, créez une copie du fichier configuration d’exemple en exécutant :

       ```shell
       cp kafka-config.yml.sample kafka-config.yml
       ```

    4. Modifiez le fichier `kafka-config.yml` en utilisant l’un des [fichiers d’exemple`kafka-config.yml` ](#examples).
  </Collapser>

  <Collapser
    id="ecs-install"
    title={<>
      <img src="/images/os_icon_ecs.webp" title="Amazon ECS installation" alt="Amazon ECS installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}>{' '} Installation d'Amazon ECS</img>
    </>
    }
  >
    Voir [le service de monitoring exécuté sur ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
  </Collapser>

  <Collapser
    id="k8s-install"
    title={<><img src="/images/os_icon_k8.webp" title="Kubernetes installation" alt="Kubernetes installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }} /></>
    }
  >
    Voir [le service de monitoring exécuté sur Kubernetes](/docs/monitor-service-running-kubernetes).
  </Collapser>
</CollapserGroup>

Notes supplémentaires :

* <DNT>**Advanced:**</DNT> les intégrations sont également disponibles au [formattarball ](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball)pour permettre une installation en dehors d&apos;un gestionnaire de paquets.
* <DNT>**On-host integrations do not automatically update.**</DNT> Pour de meilleurs résultats, mettez régulièrement [à jour le package d&apos;intégration](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package) et [l&apos;agent d&apos;infrastructure](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent).

<InstallFeedback />

## Configurer l&apos;intégration [#config]

Il existe plusieurs façons de configurer l&apos;intégration, selon la manière dont elle a été installée :

* Si activé via<img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src="/images/os_icon_k8.webp" />Kubernetes, voir [services de monitoring exécutés sur Kubernetes](/docs/monitor-service-running-kubernetes).
* Si activé via<img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src="/images/os_icon_ecs.webp" />Amazon ECS, voir [les services de monitoring exécutés sur ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
* Si installé sur l&apos;hôte, modifiez la configuration dans le fichier de configuration YAML de l&apos;intégration, `kafka-config.yml`. La configuration au format YAML d&apos;une intégration est l&apos;endroit où vous pouvez placer les informations de connexion requises et configurer la manière dont les données sont collectées. Les options que vous modifiez dépendent de votre configuration et de vos préférences. Le fichier configuration contient des paramètres communs applicables à toutes les intégrations telles que `interval`, `timeout`, `inventory_source`. Pour tout savoir sur ces paramètres courants, reportez-vous à notre document [Format de configuration](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/#configuration-basics) .

<Callout variant="important">
  Si vous utilisez toujours nos anciens fichiers configuration et de définition, reportez-vous à ce [document](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/) pour obtenir de l&apos;aide.
</Callout>

Comme pour toute autre intégration, un fichier configuration `kafka-config.yml` peut contenir de nombreuses instances de l&apos;intégration collectant différentes mesures de courtiers, de consommateurs et de producteurs. Vous pouvez voir des exemples de configuration avec une ou plusieurs instances dans les [fichiers d&apos;exemple`kafka-config.yml`](#examples)

Les paramètres spécifiques liés à Kafka sont définis à l&apos;aide de la section `env` de chaque instance dans le fichier de configuration `kafka-config.yml` . Ces paramètres contrôlent la connexion à vos Brokers, Zookeeper et JMX ainsi que d&apos;autres paramètres et fonctionnalités de sécurité. La liste des paramètres valides est décrite dans [les paramètres de configuration de Kafka](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config).

L&apos;intégration dispose de deux modes de fonctionnement sur chaque instance, qui s&apos;excluent mutuellement, que vous pouvez configurer avec le paramètre `CONSUMER_OFFSET` :

* Collecte de décalages de consommateur : définissez `CONSUMER_OFFSET = true` pour collecter [KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection).
* Mode de collecte de base : définissez `CONSUMER_OFFSET = false` pour collecter le reste des échantillons : [KafkaBrokerSample, KafkaTopicSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#broker-collection), [KafkaProducerSample, KafkaConsumerSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaConsumerSample-collection).

<Callout variant="important">
  Ces modes s&apos;excluent mutuellement car la collecte des décalages du consommateur prend beaucoup de temps à exécuter et a des exigences de performances élevées. Afin de collecter les deux groupes d&apos;échantillons, définissez deux instances, une avec chaque mode.
</Callout>

Les valeurs de ces paramètres peuvent être définies de plusieurs manières :

* Ajout de la valeur directement dans le fichier de configuration. C&apos;est la manière la plus courante.

* Remplacement des valeurs des variables d’environnement à l’aide de la notation `{{ }}` . En savoir plus sur [l&apos;utilisation des passthroughs de variables d&apos;environnement avec l&apos;intégration sur hôte](/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent/#passthrough) ou voir l&apos;exemple de [remplacement des variables d&apos;environnement](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch/elasticsearch-integration#envvar-replacement).

* Utilisation de la gestion des secrets. Utilisez ceci pour protéger les informations sensibles, telles que les mots de passe qui seraient exposés en texte brut dans le fichier de configuration. Pour plus d&apos;informations, voir [gestion des secrets](/docs/integrations/host-integrations/installation/secrets-management).

### monitoringdécalages

Lors du réglage de `CONSUMER_OFFSET = true`, par défaut, seules les métriques des groupes de consommateurs avec consommateur actif (et les métriques de consommateur) seront collectées. Pour collecter également les métriques des groupes de consommateurs avec des consommateurs inactifs, vous devez définir `INACTIVE_CONSUMER_GROUP_OFFSET` sur `true`.

Lorsqu&apos;un groupe de consommateurs monitoring plus d&apos;un sujet, il est utile d&apos;avoir des mesures de groupe de consommateurs séparées par sujet, en particulier si l&apos;un des sujets a des consommateurs inactifs, car il est alors possible de repérer dans quel sujet le groupe de consommateurs est en retard et s&apos;il y a des consommateurs actifs pour ce groupe de consommateurs et ce sujet.

Pour obtenir les mesures du groupe de consommateurs séparées par sujet, vous devez définir `CONSUMER_GROUP_OFFSET_BY_TOPIC` sur `true` (la valeur par défaut est `false`).

Pour plus d&apos;informations sur la configuration monitoring des décalages, consultez [Configurer la collection KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection).

## Fichiers d&apos;exemple kafka-config.yml [#examples]

<CollapserGroup>
  <Collapser id="zookeeper" title="Découverte Zookeeper">
    Cette configuration collecte les métriques et l&apos;inventaire, y compris tous les sujets découvrant les courtiers de deux hôtes JMX différents :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}, {"host": "localhost2", "port": 2181}]'
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: all
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="zookeeper-jmx-ssl" title="Découverte de Zookeeper avec connexion JMX basée sur SSL">
    Cette configuration collecte les Métriques et l&apos;Inventaire en découvrant les brokers à partir d&apos;un hôte JMX avec SSL :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password

          KEY_STORE: "/path/to/your/keystore"
          KEY_STORE_PASSWORD: keystore_password
          TRUST_STORE: "/path/to/your/truststore"
          TRUST_STORE_PASSWORD: truststore_password

          TIMEOUT: 10000  #The timeout for individual JMX queries in milliseconds.
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="bootstrap" title="Découverte Bootstrap">
    Cette configuration collecte les métriques et l&apos;inventaire, y compris tous les sujets découvrant les courtiers à partir d&apos;un courtier bootstrap :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          BOOTSTRAP_BROKER_JMX_PORT: 9999  # This same port will be used to connect to all discover broker JMX
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          LOCAL_ONLY_COLLECTION: false

          COLLECT_BROKER_TOPIC_DATA: true
          TOPIC_MODE: "all"
          COLLECT_TOPIC_SIZE: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="bootstrap-tls" title="Découverte TLS Bootstrap">
    Cette configuration collecte uniquement les métriques découvrant les brokers à partir d&apos;un broker bootstrap écoutant avec le protocole TLS :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          TLS_CA_FILE: "/path/to/CA.pem"
          TLS_CERT_FILE: "/path/to/cert.pem"
          TLS_KEY_FILE: "/path/to/key.pem"
          TLS_INSECURE_SKIP_VERIFY: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="boostrap-kerberos" title="Authentification Kerberos de découverte Bootstrap">
    Cette configuration collecte uniquement les métriques découvrant les courtiers d&apos;un courtier bootstrap dans un Cluster authentification Kerberos :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT # Currently support PLAINTEXT and SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          SASL_MECHANISM: GSSAPI
          SASL_GSSAPI_REALM: SOMECORP.COM
          SASL_GSSAPI_SERVICE_NAME: Kafka
          SASL_GSSAPI_USERNAME: kafka
          SASL_GSSAPI_KEY_TAB_PATH: /etc/newrelic-infra/kafka.keytab
          SASL_GSSAPI_KERBEROS_CONFIG_PATH: /etc/krb5.conf
          SASL_GSSAPI_DISABLE_FAST_NEGOTIATION: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="zookeeper-topic-bucket" title="Thème de découverte Zookeeper">
    Cette configuration collecte les métriques en divisant la collection de sujets entre 3 instances différentes :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host1", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '1/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster2
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host2", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '2/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster3
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host3", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '3/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="java-consumer-producer" title="Java consommateur et producteur">
    Ceci donne un exemple de collecte de métriques JMX auprès des consommateurs et producteurs Java :

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: "true"
          CLUSTER_NAME: "testcluster3"
          PRODUCERS: '[{"host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          CONSUMERS: '[{"host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          DEFAULT_JMX_HOST: "localhost"
          DEFAULT_JMX_PORT: "9999"
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser id="consumer-offset" title="consommateur décalé">
    Cette configuration collecte les compensations consommateur Métriques et Inventaire pour le cluster:

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CONSUMER_OFFSET: true
          CLUSTER_NAME: testcluster3
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          # A regex pattern that matches the consumer groups to collect metrics from
          CONSUMER_GROUP_REGEX: '.*'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>
</CollapserGroup>

## Options de configuration pour l&apos;intégration [#config-options]

Pour en savoir plus sur la recherche et l&apos;utilisation de vos données, consultez [les paramètres de configuration de Kafka](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config).

## Rechercher et utiliser des données [#find-and-use]

Les données de ce service sont signalées à un [dashboard d&apos;intégration](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts).

Les données Kafka sont attachées aux [types d&apos;événements](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic) suivants :

* [`KafkaBrokerSample`](#broker-sample)
* [`KafkaTopicSample`](#topic-sample)
* [`KafkaProducerSample`](#producer-sample)
* [`KafkaConsumerSample`](#consumer-sample)
* [`KafkaOffsetSample`](#offset-sample)

Vous pouvez [interroger ces données](/docs/using-new-relic/data/understand-data/query-new-relic-data) à des fins de dépannage ou pour créer des graphiques et des dashboards.

Pour en savoir plus sur la recherche et l&apos;utilisation de vos données, consultez comment [comprendre les données d&apos;intégration](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Métriques collectées par l&apos;intégration [#metrics]

L&apos;intégration Kafka collecte les métriques suivantes. Chaque nom de métrique est préfixé par un indicateur de catégorie et un point, tel que `broker.` ou `consumer.`.

<CollapserGroup>
  <Collapser id="broker-sample" title="Exemple d'événement KafkaBroker">
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            métrique
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `broker.bytesWrittenToTopicPerSecond`
          </td>

          <td>
            Nombre d&apos;octets écrits sur une rubrique par le courtier par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `broker.IOInPerSecond`
          </td>

          <td>
            E/S réseau dans les courtiers du cluster en octets par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `broker.IOOutPerSecond`
          </td>

          <td>
            E/S réseau sortant des courtiers du cluster en octets par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `broker.logFlushPerSecond`
          </td>

          <td>
            taux de chasse d&apos;eau logarithmique.
          </td>
        </tr>

        <tr>
          <td>
            `broker.messagesInPerSecond`
          </td>

          <td>
            Messages entrants par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `follower.requestExpirationPerSecond`
          </td>

          <td>
            Taux d&apos;expiration des demandes sur les abonnés en expulsions par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `net.bytesRejectedPerSecond`
          </td>

          <td>
            Octets rejetés par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `replication.isrExpandsPerSecond`
          </td>

          <td>
            Taux de répliques rejoignant le pool ISR.
          </td>
        </tr>

        <tr>
          <td>
            `replication.isrShrinksPerSecond`
          </td>

          <td>
            Taux de répliques quittant le pool ISR.
          </td>
        </tr>

        <tr>
          <td>
            `replication.leaderElectionPerSecond`
          </td>

          <td>
            Taux d&apos;élection des dirigeants.
          </td>
        </tr>

        <tr>
          <td>
            `replication.uncleanLeaderElectionPerSecond`
          </td>

          <td>
            Taux d’élection de dirigeants impurs.
          </td>
        </tr>

        <tr>
          <td>
            `replication.unreplicatedPartitions`
          </td>

          <td>
            Nombre de partitions non répliquées.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeFetch`
          </td>

          <td>
            Temps moyen par demande de récupération en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeMetadata`
          </td>

          <td>
            Temps moyen de demande de métadonnées en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeMetadata99Percentile`
          </td>

          <td>
            Temps de requests métadonnées pour le 99ème percentile en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeOffset`
          </td>

          <td>
            Temps moyen pour une demande de décalage en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeOffset99Percentile`
          </td>

          <td>
            Délai de requests de décalage pour le 99e percentile en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeProduceRequest`
          </td>

          <td>
            Temps moyen pour une demande de production en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeUpdateMetadata`
          </td>

          <td>
            Temps moyen d&apos;une demande de mise à jour des métadonnées en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeUpdateMetadata99Percentile`
          </td>

          <td>
            Temps de mise à jour requests mémorisables pour le 99e percentile en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.clientFetchesFailedPerSecond`
          </td>

          <td>
            Échecs de demande de récupération du client par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `request.fetchTime99Percentile`
          </td>

          <td>
            Temps de récupération requests pour le 99e percentile en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `request.handlerIdle`
          </td>

          <td>
            Fraction moyenne de temps pendant lequel les threads du gestionnaire de requêtes sont inactifs.
          </td>
        </tr>

        <tr>
          <td>
            `request.produceRequestsFailedPerSecond`
          </td>

          <td>
            Échec de la production requests par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `request.produceTime99Percentile`
          </td>

          <td>
            Il est temps de produire requests pour le 99e percentile.
          </td>
        </tr>

        <tr>
          <td>
            `topic.diskSize`
          </td>

          <td>
            Taille du disque de sujet par courtier et par sujet. Présent uniquement si `COLLECT_TOPIC_SIZE` est activé.
          </td>
        </tr>

        <tr>
          <td>
            `topic.offset`
          </td>

          <td>
            Décalage thématique par courtier et par thème. Présent uniquement si `COLLECT_TOPIC_OFFSET` est activé.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="consumer-sample" title="KafkaConsumerSample événement">
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            métrique
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `consumer.avgFetchSizeInBytes`
          </td>

          <td>
            Nombre moyen d&apos;octets récupérés par requête pour un sujet spécifique.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.avgRecordConsumedPerTopic`
          </td>

          <td>
            Nombre moyen d&apos;enregistrements dans chaque demande pour un sujet spécifique.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.avgRecordConsumedPerTopicPerSecond`
          </td>

          <td>
            Nombre moyen d&apos;enregistrements consommés par seconde pour un sujet spécifique en enregistrements par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.bytesInPerSecond`
          </td>

          <td>
            consommateur octets par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.fetchPerSecond`
          </td>

          <td>
            Le débit minimum auquel le consommateur envoie requests de récupération à un client en requests par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.maxFetchSizeInBytes`
          </td>

          <td>
            Nombre maximal d&apos;octets récupérés par requête pour une rubrique spécifique.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.maxLag`
          </td>

          <td>
            Retard maximal du consommateur.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.messageConsumptionPerSecond`
          </td>

          <td>
            Taux de consommation des messages du consommateur en messages par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.offsetKafkaCommitsPerSecond`
          </td>

          <td>
            Taux de validations décalées vers Kafka en validations par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.offsetZooKeeperCommitsPerSecond`
          </td>

          <td>
            Taux de validations de décalage sur ZooKeeper en écritures par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.requestsExpiredPerSecond`
          </td>

          <td>
            Taux d&apos;expiration tardive des demandes de consommateurs dans les expulsions par seconde.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="producer-sample" title="Exemple d'événement KafkaProducer">
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            métrique
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `producer.ageMetadataUsedInMilliseconds`
          </td>

          <td>
            Âge en secondes des métadonnées du producteur actuel utilisées.
          </td>
        </tr>

        <tr>
          <td>
            `producer.availableBufferInBytes`
          </td>

          <td>
            Quantité totale de mémoire tampon qui n&apos;est pas utilisée en octets.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgBytesSentPerRequestInBytes`
          </td>

          <td>
            Nombre moyen d&apos;octets envoyés par partition et par requête.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgCompressionRateRecordBatches`
          </td>

          <td>
            Taux de compression moyen des lots d&apos;enregistrements.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordAccumulatorsInMilliseconds`
          </td>

          <td>
            Temps moyen en ms par lot d&apos;enregistrement passé dans l&apos;accumulateur d&apos;enregistrements.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordSizeInBytes`
          </td>

          <td>
            Taille moyenne d&apos;un enregistrement en octets.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordsSentPerSecond`
          </td>

          <td>
            Nombre moyen d&apos;enregistrements envoyés par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordsSentPerTopicPerSecond`
          </td>

          <td>
            Nombre moyen d&apos;enregistrements envoyés par seconde pour un sujet.
          </td>
        </tr>

        <tr>
          <td>
            `producer.AvgRequestLatencyPerSecond`
          </td>

          <td>
            Latence moyenne des requêtes du producteur.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgThrottleTime`
          </td>

          <td>
            Temps moyen pendant lequel une demande a été limitée par un courtier en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `producer.bufferMemoryAvailableInBytes`
          </td>

          <td>
            Quantité maximale de mémoire tampon que le client peut utiliser en octets.
          </td>
        </tr>

        <tr>
          <td>
            `producer.bufferpoolWaitTime`
          </td>

          <td>
            Faction de temps pendant laquelle un appender attend l&apos;allocation d&apos;espace.
          </td>
        </tr>

        <tr>
          <td>
            `producer.bytesOutPerSecond`
          </td>

          <td>
            Octets de sortie du producteur par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `producer.compressionRateRecordBatches`
          </td>

          <td>
            Taux de compression moyen des lots d&apos;enregistrements pour une rubrique.
          </td>
        </tr>

        <tr>
          <td>
            `producer.iOWaitTime`
          </td>

          <td>
            Temps d&apos;attente I/O du producteur en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxBytesSentPerRequestInBytes`
          </td>

          <td>
            Nombre maximal d&apos;octets envoyés par partition et par requête.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxRecordSizeInBytes`
          </td>

          <td>
            Taille maximale de l&apos;enregistrement en octets.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxRequestLatencyInMilliseconds`
          </td>

          <td>
            Latence maximale de la requête en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxThrottleTime`
          </td>

          <td>
            Durée maximale pendant laquelle une demande a été limitée par un courtier en millisecondes.
          </td>
        </tr>

        <tr>
          <td>
            `producer.messageRatePerSecond`
          </td>

          <td>
            Messages du producteur par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `producer.responsePerSecond`
          </td>

          <td>
            Nombre de réponses du producteur par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `producer.requestPerSecond`
          </td>

          <td>
            Nombre de requests de producteurs par seconde.
          </td>
        </tr>

        <tr>
          <td>
            `producer.requestsWaitingResponse`
          </td>

          <td>
            Nombre actuel de requests en cours en attente d&apos;une réponse.
          </td>
        </tr>

        <tr>
          <td>
            `producer.threadsWaiting`
          </td>

          <td>
            Nombre de threads utilisateur bloqués en attente de mise en file d&apos;attente de leurs enregistrements par la mémoire tampon.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="topic-sample" title="Exemple d'événement KafkaTopic">
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            métrique
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `topic.partitionsWithNonPreferredLeader`
          </td>

          <td>
            Nombre de partitions par sujet qui ne sont pas dirigées par leur réplique préférée.
          </td>
        </tr>

        <tr>
          <td>
            `topic.respondMetaData`
          </td>

          <td>
            Nombre de sujets répondant aux requests métadonnées.
          </td>
        </tr>

        <tr>
          <td>
            `topic.retentionSizeOrTime`
          </td>

          <td>
            Si une partition est conservée par taille ou à la fois par taille et par temps. Une valeur de 0 = temps et une valeur de 1 = taille et temps.
          </td>
        </tr>

        <tr>
          <td>
            `topic.underReplicatedPartitions`
          </td>

          <td>
            Nombre de partitions par rubrique qui sont sous-répliquées.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="offset-sample" title="Exemple d'événement KafkaOffset">
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            métrique
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `consumer.offset`
          </td>

          <td>
            Le dernier offset consommé sur une partition par le groupe consommateur.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.lag`
          </td>

          <td>
            La différence entre la marque haute d&apos;un courtier et la compensation du consommateur (`consumer.hwm` - `consumer.offset`).
          </td>
        </tr>

        <tr>
          <td>
            `consumer.hwm`
          </td>

          <td>
            Le décalage du dernier message écrit sur une partition (limite haute).
          </td>
        </tr>

        <tr>
          <td>
            `consumer.totalLag`
          </td>

          <td>
            La somme des décalages entre les partitions consommées par un consommateur.
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.totalLag`
          </td>

          <td>
            La somme des décalages sur toutes les partitions consommées par un `consumerGroup`.
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.maxLag`
          </td>

          <td>
            Le décalage maximal sur toutes les partitions consommées par un `consumerGroup`.
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.activeConsumers`
          </td>

          <td>
            Le nombre de consommateurs actifs dans ce `consumerGroup`.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>