---
title: Intégration monitoring Google VertexAI
tags:
  - Integrations
  - Google Cloud Platform integrations
  - GCP integrations list
metaDescription: 'New Relic Google VertexAI integration: the data it reports and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

[L&apos;intégration de New Relic](/docs/infrastructure/introduction-infra-monitoring) inclut une intégration permettant de signaler vos données GCP Run à nos produits. Ici, nous expliquons comment activer l&apos;intégration et quelles données elle collecte.

## Activer l&apos;intégration [#activate]

Pour activer l&apos;intégration, suivez les procédures standard pour [connecter votre service GCP à New Relic](/docs/connect-google-cloud-platform-services-infrastructure).

## configuration et sondage [#polling]

Vous pouvez modifier la fréquence d&apos;interrogation et filtrer les données à l&apos;aide [des options de configuration](/docs/integrations/new-relic-integrations/getting-started/configure-polling-frequency-data-collection-cloud-integrations).

Informations [d&apos;interrogation](/docs/integrations/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations) par défaut pour l&apos;intégration GCP Run :

* Intervalle d&apos;interrogation de New Relic : 5 minutes

## Rechercher et utiliser des données [#find-data]

Pour trouver vos données d’intégration, accédez à <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; Infrastructure &gt; GCP**</DNT> et sélectionnez une intégration.

Les données sont attachées aux [types d’événements](/docs/data-apis/understand-data/new-relic-data-types/#event-data) suivants :

<table>
  <thead>
    <tr>
      <th>
        Entité
      </th>

      <th>
        Type d&apos;événement
      </th>

      <th>
        Fournisseur
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Point de terminaison
      </td>

      <td>
        `GcpVertexAiEndpointSample`
      </td>

      <td>
        `GcpVertexAiEndpoint`
      </td>
    </tr>

    <tr>
      <td>
        magasin de fonctionnalités
      </td>

      <td>
        `GcpVertexAiFeaturestoreSample`
      </td>

      <td>
        `GcpVertexAiFeaturestore`
      </td>
    </tr>

    <tr>
      <td>
        Fonctionnalité Boutique en ligne
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStoreSample`
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStore`
      </td>
    </tr>

    <tr>
      <td>
        Emplacement
      </td>

      <td>
        `GcpVertexAiLocationSample`
      </td>

      <td>
        `GcpVertexAiLocation`
      </td>
    </tr>

    <tr>
      <td>
        Indice
      </td>

      <td>
        `GcpVertexAiIndexSample`
      </td>

      <td>
        `GcpVertexAiIndex`
      </td>
    </tr>

    <tr>
      <td>
        PipelineJob
      </td>

      <td>
        `GcpVertexAiPipelineJobSample`
      </td>

      <td>
        `GcpVertexAiPipelineJob`
      </td>
    </tr>
  </tbody>
</table>

Pour en savoir plus sur l’utilisation de vos données, consultez [Comprendre et utiliser les données d’intégration](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## données métriques [#metrics]

Cette intégration collecte des données GCP pour VertexAI.

### Données du point de terminaison VertexAI

<table>
  <thead>
    <tr>
      <th>
        métrique
      </th>

      <th>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `prediction.online.accelerator.duty_cycle`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        Fraction moyenne de temps au cours de la période d&apos;échantillonnage précédente pendant laquelle les accélérateurs étaient en cours de traitement actif.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.accelerator.memory.bytes_used`
      </td>

      <td>
        Octets
      </td>

      <td>
        Quantité de mémoire accélératrice allouée par la réplique du modèle Dél.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.error_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre d&apos;erreurs de prédiction en ligne.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.memory.bytes_used`
      </td>

      <td>
        Octets
      </td>

      <td>
        Quantité de mémoire allouée par la réplique du modèle Décal et actuellement utilisée.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.received_bytes_count`
      </td>

      <td>
        Octets
      </td>

      <td>
        Nombre d&apos;octets reçus sur le réseau par la réplique du modèle Déploy.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.sent_bytes_count`
      </td>

      <td>
        Octets
      </td>

      <td>
        Nombre d&apos;octets envoyés sur le réseau par la réplique du modèle déployé.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de prédictions en ligne.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_latencies`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Latence de prédiction en ligne du modèle déployé.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.private.prediction_latencies`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Latence de prédiction en ligne du modèle de déploiement privé.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.replicas`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de répliques actives utilisées par le modèle déployé.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.response_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de codes de réponse de prédiction en ligne différents.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.target_replicas`
      </td>

      <td>
        Compter
      </td>

      <td>
        nombre cible de répliques actives nécessaires pour le modèle déployé.
      </td>
    </tr>
  </tbody>
</table>

### Données du magasin de fonctionnalités VertexAI

<table>
  <thead>
    <tr>
      <th>
        métrique
      </th>

      <th>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featurestore.cpu_load`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        La charge CPU moyenne pour un nœud dans le stockage en ligne Featuresstore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.cpu_load_hottest_node`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        La charge CPU pour le nœud le plus chaud du stockage en ligne Featuresstore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.node_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre de nœuds pour le stockage en ligne Featuresstore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_entities_updated`
      </td>

      <td>
        Compter
      </td>

      <td>
        Numéro d&apos;entité mis à jour sur le stockage en ligne Featuresstore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.latencies`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Latence de service en ligne par EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_bytes_count`
      </td>

      <td>
        Octets
      </td>

      <td>
        Taille de la demande par EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de services en ligne de Featuresstore par EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.response_size`
      </td>

      <td>
        Octets
      </td>

      <td>
        Taille de la réponse par EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.billable_processed_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Nombre d&apos;octets facturés pour les données hors ligne traitées.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.stored_bytes`
      </td>

      <td>
        Octets
      </td>

      <td>
        Octets stockés dans Featuresstore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_processed_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de requests d&apos;écriture en streaming traitées pour le stockage hors ligne.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_write_delays`
      </td>

      <td>
        Secondes
      </td>

      <td>
        Temps (en secondes) écoulé depuis que l&apos;API d&apos;écriture est appelée jusqu&apos;à ce qu&apos;elle soit écrite dans le stockage hors ligne.
      </td>
    </tr>
  </tbody>
</table>

### Données de VertexAI FeatureOnlineStore

<table>
  <thead>
    <tr>
      <th>
        métrique
      </th>

      <th>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featureonlinestore.online_serving.request_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de portions par FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_bytes_count`
      </td>

      <td>
        Octets
      </td>

      <td>
        Taille de la réponse de diffusion par FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_latencies`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Latence de service en ligne par FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.running_sync`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        Nombre de synchronisations en cours d&apos;exécution à un moment donné.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_ages`
      </td>

      <td>
        Secondes
      </td>

      <td>
        Mesure de l&apos;âge des données de service en secondes.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_by_sync_time`
      </td>

      <td>
        Compter
      </td>

      <td>
        Répartition des données de la fonctionnalité Boutique en ligne par horaire synchronisé.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        La charge CPU moyenne des nœuds dans la fonctionnalité Boutique en ligne.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load_hottest_node`
      </td>

      <td>
        Pour cent
      </td>

      <td>
        La charge CPU du nœud le plus chaud de la fonctionnalité Online Store.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_nodes`
      </td>

      <td>
        Compter
      </td>

      <td>
        Le nombre de nœuds pour la fonctionnalité Boutique en ligne (Bigtable).
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.stored_bytes`
      </td>

      <td>
        Compter
      </td>

      <td>
        Octets stockés dans la fonctionnalité Online Store.
      </td>
    </tr>
  </tbody>
</table>

### Données de localisation VertexAI

<table>
  <thead>
    <tr>
      <th>
        métrique
      </th>

      <th>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `online_prediction_requests_per_base_model`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de requests par modèle de base.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.exceeded`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de tentatives de dépassement de la limite de la métrique de quota.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.limit`
      </td>

      <td>
        Compter
      </td>

      <td>
        Limite actuelle sur la métrique de quota.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.usage`
      </td>

      <td>
        Compter
      </td>

      <td>
        Utilisation actuelle de la métrique de quota.
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_jobs`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de tâches de pipeline en cours d&apos;exécution.
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_tasks`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de tâches de pipeline en cours d&apos;exécution.
      </td>
    </tr>
  </tbody>
</table>

### Données de l&apos;index VertexAI

<table>
  <thead>
    <tr>
      <th>
        métrique
      </th>

      <th>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `matching_engine.stream_update.datapoint_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de points de données insérés ou supprimés avec succès.
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.latencies`
      </td>

      <td>
        Millisecondes
      </td>

      <td>
        La latence entre l&apos;utilisateur reçoit un UpsertDatapointsResponse ou RemoveDatapointsResponse et cette mise à jour prend effet.
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.request_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre de requests de mise à jour de flux.
      </td>
    </tr>
  </tbody>
</table>

### Données sur les tâches Pipeline VertexAI

<table>
  <thead>
    <tr>
      <th>
        métrique
      </th>

      <th>
        Unité
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `pipelinejob.duration`
      </td>

      <td>
        Secondes
      </td>

      <td>
        Secondes d&apos;exécution du travail du pipeline en cours d&apos;exécution (de la création à la fin).
      </td>
    </tr>

    <tr>
      <td>
        `pipelinejob/task_completed_count`
      </td>

      <td>
        Compter
      </td>

      <td>
        Nombre total de tâches Pipeline terminées.
      </td>
    </tr>
  </tbody>
</table>