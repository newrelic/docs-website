---
title: moniteur Apache Airflow avec OpenTelemetry
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Airflow
  - Quickstart
metaDescription: Monitor Airflow data with New Relic using OpenTelemetry.
freshnessValidatedDate: '2023-11-16T00:00:00.000Z'
translationType: machine
---

Monitorez les données Apache Airflow en configurant [OpenTelemetry](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry) pour envoyer des données à New Relic, où vous pouvez visualiser les tâches, les opérateurs et les exécutions DAG sous forme de métriques.

<img title="Screenshot showing sample Airflow DAG runs in New Relic" alt="Screenshot showing sample Airflow DAG runs in New Relic" src="/images/opentelemetry_screenshot_airflow_01.webp" />

## Prérequis [#prerequisites]

Avant d&apos;activer OpenTelemetry dans Apache Airflow, vous devez installer le package Airflow avec le supplément `otel` . La méthode d&apos;installation dépend de votre approche de déploiement Airflow :

### Option 1 : Installation à partir de PyPi [#install-pypi]

1. Suivez les instructions d&apos;installation de [la documentation d&apos;Airflow](https://airflow.apache.org/docs/apache-airflow/stable/installation/installing-from-pypi.html).

2. Lors de l&apos;installation avec pip, ajoutez le `otel` supplémentaire à la commande. Par exemple:

   ```sh
   pip install "apache-airflow[otel]"
   ```

### Option 2 : Installation à partir de Docker [#install-docker]

1. Configurez l&apos;image Docker Airflow en suivant les instructions de [la documentation d&apos;Airflow](https://airflow.apache.org/docs/docker-stack/index.html).

2. Étendez l’image Docker prédéfinie en utilisant un Dockerfile pour installer le `otel` supplémentaire. Vous pouvez remplacer la dernière tag par la version souhaitée de l&apos;image.

   ```dockerfile
   FROM apache/airflow:latest
   RUN pip install --no-cache-dir "apache-airflow[otel]==$AIRFLOW_VERSION"
   ```

<Callout variant="tip">
  `$AIRFLOW_VERSION` est déjà défini par le conteneur apache/airflow, mais peut être remplacé par un numéro de version pour d&apos;autres images de base.
</Callout>

## Configuration [#configuration]

Pour envoyer des métriques Airflow à New Relic, configurez les OpenTelemetry métriques pour exporter les données vers un [OpenTelemetry Collector](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-intro/), qui transmettra ensuite les données à un [point de terminaison OTLP New](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/#note-endpoints) Relic à l&apos;aide <InlinePopover type="licenseKey" />d&apos;un.

<Callout variant="important">
  En raison du manque actuel de prise en charge d&apos;Airflow pour l&apos;envoi OpenTelemetry de données avec des en-têtes OpenTelemetry Collector d&apos;authentification, le est essentiel pour l&apos;authentification avec New Relic.
</Callout>

### Configurer le OpenTelemetry Collector [#configuration-collector]

1. Suivez [l&apos;Collector exemple de base](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-basic/) pour configurer votre OpenTelemetry Collector.
2. Configurez le Collector avec votre point de terminaison OTLP approprié, tel que `https://otlp.nr-data.net:4317`.
3. Pour l&apos;authentification, ajoutez votre <InlinePopover type="licenseKey" />à la variable d&apos;environnement `NEW_RELIC_LICENSE_KEY` afin qu&apos;elle remplisse l&apos;en-tête `api-key` .
4. Assurez-vous que le port 4318 sur le Collector est accessible à partir de l&apos; instance Airflow en cours d&apos;exécution. (Pour Docker, vous devrez peut-être utiliser un [réseau Docker](https://docs.docker.com/network/).)
5. lancement du Collector.

### Configurer les métriques Airflow [#configuration-airflow]

Airflow envoie des métriques à l&apos;aide d&apos;OTLP sur HTTP, qui utilise le port `4318`. Airflow dispose de plusieurs méthodes pour [définir les options de configuration](https://airflow.apache.org/docs/apache-airflow/stable/howto/set-config.html).

<Callout variant="important">
  Si votre environnement exécute Airflow dans un conteneur Docker à côté du OpenTelemetry Collector, vous devrez modifier le `otel_host` paramètre de `localhost` à l&apos;adresse du conteneur du Collector.
</Callout>

Choisissez l’une des méthodes suivantes pour définir les options requises pour Airflow.

1. Définissez les options requises dans le fichier `airflow.cfg` .

   ```ini
   [metrics]
   otel_on = True
   otel_host = localhost
   otel_port = 4318
   otel_ssl_active = False
   ```

2. Ou définissez les options requises comme variables d’environnement.

   ```sh
   export AIRFLOW__METRICS__OTEL_ON=True
   export AIRFLOW__METRICS__OTEL_HOST=localhost
   export AIRFLOW__METRICS__OTEL_PORT=4318
   export AIRFLOW__METRICS__OTEL_SSL_ACTIVE=False
   ```

<Callout variant="tip">
  Airflow dispose [de paramètres supplémentaires](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry) pour les métriques qui peuvent être utiles. Cela inclut la possibilité de [renommer les métriques](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#rename-metrics) avant l&apos;envoi, ce qui est utile si les noms de métriques dépassent la limite de 63 octets pour OpenTelemetry.
</Callout>

## Les données de validation sont envoyées à New Relic [#validation]

Pour confirmer que New Relic collecte vos données Airflow, exécutez un DAG ou un pipeline :

1. Connectez-vous à Airflow.
2. Cliquez sur le bouton Exécuter sur l’un des DAG du didacticiel existants ou sur le vôtre.
3. Attendez que le pipeline termine son exécution.
4. Allez à <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; APM &amp;amp; services &gt; Services - OpenTelemetry &gt; Airflow**</DNT>.
5. Cliquez sur <DNT>**Metrics Explorer**</DNT> pour visualiser les métriques des exécutions de pipeline.

## Construire des Dashboards [#building-dashboards]

Avec les métriques Airflow, vous pouvez créer un dashboard autour d&apos;un pipeline individuel, des performances globales ou afficher une comparaison entre différents pipelines. Cliquez ici pour en savoir plus sur [l&apos;interrogation de vos métriques](/docs/data-apis/understand-data/metric-data/query-metric-data-type/).

Cette requête récupère une liste de toutes les métriques signalées pour Airflow :

```sql
SELECT uniques(metricName) FROM Metric WHERE entity.name = 'Airflow' 
AND metricName LIKE 'airflow.%' SINCE 30 MINUTES AGO LIMIT 100
```

Assurez-vous de modifier la limite (`100`) si vos noms métriques la dépassent.

Cette requête montre une comparaison de différents temps d&apos;exécution pour les exécutions réussies de différents DAG :

```sql
SELECT latest(airflow.dagrun.duration.success) FROM Metric 
FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img title="Screenshot showing sample Airflow DAG runs in New Relic" alt="Screenshot showing sample Airflow DAG runs in New Relic" src="/images/opentelemetry_screenshot_airflow_01.webp" />

Cette requête affiche le nombre d&apos;exécutions DAG ayant échoué, qui peuvent être utilisées pour créer <InlinePopover type="alerts" />pour le pipeline critique :

```sql
SELECT count(airflow.dagrun.duration.failed) FROM Metric 
FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img title="Screenshot showing sample Airflow failures in New Relic" alt="Screenshot showing sample Airflow failures in New Relic" src="/images/opentelemetry_screenshot_airflow_02.webp" />

<Callout variant="important">
  Les métriques OpenTelemetry d&apos;Airflow ne sont pas maintenues par New Relic, donc si vous rencontrez des problèmes avec l&apos; instrumentation, [créez un nouveau problème dans le référentiel GitHub d&apos;Airflow (référentiel)](https://github.com/apache/airflow/issues).
</Callout>

<InstallFeedback />