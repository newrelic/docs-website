---
title: Intégration d'Amazon SageMaker
metaDescription: Send your machine learning model data from Amazon SageMaker to New Relic to understand your model's performance.
freshnessValidatedDate: never
translationType: machine
---

En intégrant l&apos;intégration d&apos;Amazon SageMaker avec New Relic, vous serez en mesure d&apos; intrumenter, d&apos;analyser, de dépanner et d&apos;optimiser les performances de votre machine learning sur l&apos;ensemble de votre système. Observez rigoureusement vos capacités à réagir rapidement aux changements dans l’entrée ou la sortie du modèle et la relation entre les deux.

Suivez les étapes suivantes pour monitorer vos métriques et objets Amazon SageMaker (qui sont envoyés à AWS CloudWatch) et les afficher en tant qu&apos;[entité](/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/) et [dashboard](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/) dans New Relic.

Pour un aperçu de notre intégration SageMaker en action, regardez cette courte vidéo YouTube (2:57 minutes).

<Video id="U3ttUZhiuJ0" type="youtube" />

## Diffusez les métriques AWS CloudWatch vers New Relic [#set-up-cloudwatch]

Commencez à bénéficier du [monitoring des performances des modèles](/docs/alerts-applied-intelligence/mlops/get-started/intro-mlops/) d&apos;entité New Relic en une seule étape simple (et seulement quelques minutes !) :

<Callout variant="important">
  Chaque métrique envoyée à CloudWatch est automatiquement envoyée à la table métrique de New Relic dans NRDB, selon le filtre espace de nommage. Vous pouvez toujours les interroger en utilisant NRQL:

  ```sql
  FROM Metric SELECT * WHERE aws.Namespace = '/aws/sagemaker/Endpoints' LIMIT MAX SINCE 1 WEEK AGO
  ```
</Callout>

### Option manuelle [#set-up-manual]

Suivez nos documents pour configurer [le flux de métriques CloudWatch](/docs/integrations/amazon-integrations/aws-integrations-list/aws-metric-stream).

### Option automatisée [#set-up-automated]

Vous pouvez automatiser la configuration avec le [code Terraform](https://github.com/newrelic-experimental/terraform-cloudwatch-metric-streams):

```hcl
module "example_usage" {
  source = "modules/nr-cloudwatch-metric-stream"

  name_suffix    = "suffix" # optional
  aws_account_id = "your-aws-account-id"

  newrelic_collector_endpoint = "newrelic-endpoint-url"
  newrelic_trusted_account_id = "12345678"
  newrelic_license_key        = "YOUR_INGEST_LICENSE_KEY"
}
```

Lors de l&apos;appel du module, veuillez écrire le `newrelic_collector_endpoint` correct :

* URL du point de terminaison HTTP - Centre de données américain : `https://aws-api.newrelic.com/cloudwatch-metrics/v1`
* URL du point de terminaison HTTP - Centre de données de l&apos;UE : `https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1`

Lorsque vous définissez le flux métrique, vous pouvez choisir de diffuser le flux métrique à partir de tout l&apos;espace de nommage, ou vous pouvez spécifier l&apos;espace de nommage.

<Callout variant="important">
  Vous pouvez afficher les métriques de chaque entité dans un dashboard créé automatiquement lorsque les métriques arrivent à New Relic.
</Callout>

## Monitorez vos données et votre modèle dans Amazon SageMaker et envoyez les métriques à CloudWatch [#model-monitor]

SageMaker monitore automatiquement les performances de votre point de terminaison et envoie des mesures statistiques à CloudWatch. Pour plus d&apos;informations, consultez [point de terminaison métriques CloudWatch](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html).

Pour bénéficier davantage de l’intégration d’Amazon SageMaker, utilisez les outils de monitoring du modèle Amazon SageMaker. Vous devrez définir des tâches monitoring planifiées pour monitorer la qualité de vos modèles d&apos;apprentissage machine en production et envoyer des métriques à CloudWatch.

Le <DNT>**[Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)**</DNT> fournit les types de monitoring suivants :

* [Monitorer Data Quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html): dérive du moniteur dans la qualité des données.

  * Exemple de bloc-notes : [moniteur de modèles Amazon SageMaker](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/introduction/SageMaker-ModelMonitoring.html)
  * espace de nommage: `aws/sagemaker/Endpoints/data-metrics`

* [Monitorer Model Quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html): dérive du moniteur dans les mesures de qualité du modèle, telles que la précision.

  * Exemple de bloc-notes : [moniteur de qualité des modèles Amazon SageMaker](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/model_quality/model_quality_churn_sdk.html)
  * espace de nommage: `aws/sagemaker/Endpoints/model-metrics`

* [Dérive du biais du moniteur pour les modèles en production](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-bias-drift.html): biais du moniteur dans les prédictions de votre modèle.

  * Exemple de bloc-notes : [monitoring de la dérive des biais et de la dérive d&apos;attribution des fonctionnalités Amazon SageMaker Clarify](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html)
  * espace de nommage: `aws/sagemaker/Endpoints/bias-metrics`

* [Monitorer la dérive d&apos;attribution des fonctionnalités pour les modèles en production](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-monitor-feature-attribution-drift.html): monitorer la dérive dans l&apos;attribution des fonctionnalités.

  * Exemple de bloc-notes : [monitoring de la dérive des biais et de la dérive d&apos;attribution des fonctionnalités Amazon SageMaker Clarify](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html)
  * espace de nommage: `aws/sagemaker/Endpoints/explainability-metrics`

<InstallFeedback />

### Options avancées [#model-monitor-advanced]

Vous pouvez également publier des points de données métriques sur Amazon CloudWatch et définir l&apos;espace de nommage et l&apos;un des éléments ci-dessus à l&apos;aide de la [fonction`put_metric_data` ](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/cloudwatch.html#CloudWatch.Client.put_metric_data).

Si vous utilisez votre propre algorithme pour le réglage des hyperparamètres, assurez-vous qu&apos;il envoie au moins une métrique en écrivant des données d&apos;évaluation dans `stderr` ou `stdout`. En savoir plus sur [la façon de définir des métriques dans le réglage automatique du modèle](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html). Voir également l&apos;exemple de bloc-notes [Développer, former, optimiser et déployer Scikit-Learn Random Forest](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb).

## Explorez votre entité et votre dashboard [#explore-entities-dashboards]

Nous générons `aws-entities` (sous le domaine de l&apos;entité MLOps) pour l&apos;espace de nommage détaillé. Pour ces entités, vous pouvez obtenir des <InlinePopover type="dashboards" />et des vues prêts à l&apos;emploi. Vous pouvez également créer votre propre dashboard pour afficher les métriques qui ne sont pas affichées dans le cadre des vues de l&apos;entité.

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        Entité de New Relic
      </th>

      <th>
        Espace de nommage
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Point de terminaison du Machine Learning
      </td>

      <td>
        `/aws/sagemaker/Endpoints`, `AWS/SageMaker`
      </td>
    </tr>

    <tr>
      <td>
        Données du modèle d&apos;apprentissage machine
      </td>

      <td>
        `aws/sagemaker/Endpoints/data-metrics`
      </td>
    </tr>

    <tr>
      <td>
        Modèle d&apos;apprentissage machine
      </td>

      <td>
        `aws/sagemaker/Endpoints/model-metrics`, `aws/sagemaker/Endpoints/explainability-metrics`
      </td>
    </tr>
  </tbody>
</table>

Accédez à <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Model performance**</DNT> pour voir :

* Le dashboard des métriques du point de terminaison d&apos;une des entités Amazon SageMaker

<img title="Dashboard for the for the machine learning endpoint" alt="Dashboard for the machine learning endpoint" src="/images/model-performance-monitoring_screenshot-crop_amazon-sagemaker-dashboard.webp" />

* Le dashboard de l&apos;entité de données du modèle

<img title="Dashboard for the model data entity.png" alt="Dashboard for the model data entity" src="/images/model-performance-monitoring_screenshot-crop_amazon-sagemaker-model-data-entity.webp" />