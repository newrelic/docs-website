---
title: Introduction au monitoring des performances des modèles (MLOps)
metaDescription: Use New Relic ML model performance monitoring to monitor and observe the performance of your machine learning models.
freshnessValidatedDate: never
translationType: machine
---

Les opérations d&apos;apprentissage machine sont un ensemble de pratiques conçues pour augmenter la qualité, simplifier le processus de gestion et automatiser le déploiement de modèles d&apos;apprentissage machine dans un environnement de production à grande échelle.

Alors que de plus en plus d’entreprises investissent dans l’intelligence artificielle et l’apprentissage machine, il existe un fossé de compréhension entre les équipes de science des données qui développent des modèles d’apprentissage machine et les équipes DevOps qui exploitent les applications qui alimentent ces modèles. À ce jour, seulement 15 % des entreprises déploient l’IA pour englober l’ensemble de leurs activités. Le fait que 75 % des modèles d’apprentissage machine en production ne soient jamais utilisés en raison de problèmes de déploiement, monitoring, de gestion et de gouvernance n’aide pas. En fin de compte, cela conduit à une énorme perte de temps pour les ingénieurs et les data scientists travaillant sur les modèles, à une perte nette importante d’argent investi par l’entreprise et à un manque général de confiance lorsque les modèles d’apprentissage machine permettent une croissance quantifiable.

Notre monitoring des performances des modèles offre aux data scientists et aux professionnels du MLOps une visibilité sur les performances de leurs applications de machine learning en monitoring le comportement et l&apos;efficacité des modèles en production. Il permet aux équipes de données de collaborer directement avec les équipes DevOps , ce qui crée un processus continu de développement, de test et monitoring opérationnelle.

## Comment monitorer vos modèles d&apos;apprentissage machine [#use-mlops]

Pour utiliser monitoring des performances des modèles dans [les alertes New Relic](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/), vous disposez de plusieurs options différentes :

1. <DNT>**Bring your own data (BYOD):**</DNT> Il s’agit de l’approche recommandée par New Relic. Notre monitoring ML des performances des modèles fournit une observabilité approfondie de la manière dont vos modèles ML fonctionnent en production. BYOD peut être utilisé depuis n&amp;apos;importe quel environnement (script Python, conteneur, fonction Lambda, SageMaker, etc.) et peut être facilement intégré à n&amp;apos;importe quel framework de machine learning (Scikit-learn, Keras, Pytorch, Tensorflow, Jax, etc.). Grâce à BYOD, vous pouvez intégrer votre propre télémétrie de modèle ML dans New Relic et commencer à tirer profit des données de votre modèle ML. En quelques minutes seulement, vous pouvez obtenir la distribution des fonctionnalités, les données statistiques et la distribution des prédictions ainsi que toutes les autres métriques personnalisées que vous souhaitez monitorer. Pour en savoir plus sur BYOD, consultez [notre documentation](/docs/alerts-applied-intelligence/mlops/bring-your-own/mlops-byo).

2. <DNT>**Integrations:**</DNT> New Relic s&amp;apos;est également associé à Amazon SageMaker, vous offrant une vue des mesures de performances de SageMaker dans New Relic et élargissant l&amp;apos;accès à l&amp;apos;observabilité pour les ingénieurs ML et les équipes de science des données. En savoir plus sur notre [intégration Amazon SageMaker](/docs/mlops/integrations/aws-sagemaker-mlops-integration/).

3. <DNT>**Partnerships:**</DNT> New Relic s&amp;apos;est associé à sept fournisseurs MLOps différents qui proposent des cas d&amp;apos;utilisation et des capacités monitoring spécifiques. Les partenaires sont un excellent moyen d&amp;apos;accéder à des performances organisées <InlinePopover type="dashboards" />et à d&amp;apos;autres outils d&amp;apos;observabilité, en fournissant un dashboard prêt à l&amp;apos;emploi qui vous donne une visibilité instantanée sur vos modèles.

   Nous travaillons actuellement en partenariat avec :

   * [Datarobot (Algorithmie)](/docs/alerts-applied-intelligence/mlops/integrations/datarobot-mlops-integration/)
   * [Aporia](/docs/alerts-applied-intelligence/mlops/integrations/aporia-mlops-integration/)
   * [Comet](/docs/alerts-applied-intelligence/mlops/integrations/comet-mlops-integration/)
   * [DagsHub](/docs/alerts-applied-intelligence/mlops/integrations/dagshub-mlops-integration/)
   * [Mona](/docs/alerts-applied-intelligence/mlops/integrations/mona-mlops-integration/)
   * [Superwise](/docs/alerts-applied-intelligence/mlops/integrations/superwise-mlops-integration/)
   * [TruEra](/docs/alerts-applied-intelligence/mlops/integrations/truera-mlops-integration/)

Pour commencer à mesurer les performances des modèles d&apos;apprentissage machine en quelques minutes à l&apos;aide de l&apos;une de ces options, consultez les [démarrages rapidesmonitoring des performances des modèles](https://newrelic.com/instant-observability/?category=machine-learning-ops).

## Comment monitorer les applications OpenAI GPT [#monitor-openai-gtp]

Avec l&apos; [intégration de l&apos;application de la série GPT](/docs/mlops/integrations/openai-integration/), vous aurez la possibilité de monitorer les requêtes d&amp;apos;achèvement OpenAI et log des statistiques utiles dans un dashboard personnalisable New Relic sur vos requests. En ajoutant seulement deux lignes de code, vous pouvez accéder à des indicateurs de performance clés tels que le coût, le temps de réponse et les exemples d&amp;apos;entrées/sorties. Le dashboard entièrement personnalisable permet également à l&amp;apos;utilisateur de suivre le nombre total requests, le nombre moyen de jetons/requests et les noms de modèles. Pour en savoir plus ou installer l&amp;apos;intégration, visitez notre [guide de démarrage rapide New Relic OpenAI ](https://newrelic.com/instant-observability/openai).