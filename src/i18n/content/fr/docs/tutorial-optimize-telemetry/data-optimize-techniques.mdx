---
title: Optimisez vos données d'ingestion
metaDescription: Taking your ingested and reported ingest data and optimizing it.
freshnessValidatedDate: never
translationType: machine
---

À l’étape précédente, vous avez créé et affiné votre plan d’optimisation des données en comparant votre rapport de base de référence aux objectifs de votre organisation. Une fois que vous avez aligné vos données et les avez mesurées par rapport à vos facteurs de valeur, vous pouvez commencer à optimiser, et potentiellement à réduire, vos données ingérées. Il existe deux manières principales de procéder :

* Optimiser l&apos;efficacité des données
* Optimiser en utilisant des règles de dépôt

Nous aborderons les deux méthodes ci-dessous, ainsi que toutes les configurations possibles fournies par chaque option.

## Optimiser l&apos;efficacité des données [#optimize-efficiency]

Cette section comprend différentes manières de configurer la fonctionnalité New Relic pour optimiser le reporting des données et l&apos;ingestion :

<CollapserGroup>
  <Collapser id="apm-agent" title="Agent APM">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Transactions monitorées
      * Activité d&apos;erreur
      * Événements personnalisés
    </Callout>

    Le volume de données généré par l&apos;agent APM sera déterminé par plusieurs facteurs :

    * La quantité de trafic organique générée par l&apos;application (par exemple, toutes choses étant égales par ailleurs, une application appelée un million de fois par jour générera plus de données qu&apos;une application appelée mille fois par jour)
    * Certaines des caractéristiques des données de transaction sous-jacentes elles-mêmes (longueur et complexité des URL)
    * Si l&apos;application rapporte une requête de base de données
    * Si l&apos;application a des transactions avec de nombreux (ou aucun) attribut personnalisé
    * Le volume d&apos;erreur pour l&apos;application
    * Si l&apos;agent d&apos;application est configuré pour le tracing distribué

    ### Gestion du volume

    Bien que vous puissiez supposer que tous les appels à une application sont nécessaires, il est possible de rendre votre architecture globale plus efficace. Vous pouvez avoir un microservices de profil utilisateur appelé toutes les 10 secondes par ses clients. Cela permet de réduire la latence si certaines informations utilisateur sont mises à jour par d’autres clients. Vous avez toutefois la possibilité de réduire la fréquence des appels vers ce service à chaque minute, par exemple.

    ### Les attributs personnalisés

    Tout [attribut personnalisé](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/) ajouté à l’aide d’un appel à une API APM [`addCustomParameter`](https://developer.newrelic.com/collect-data/custom-attributes/) ajoutera un attribut supplémentaire aux frais de transaction. Ces données sont souvent utiles, mais à mesure que les choses changent, elles peuvent devenir moins précieuses, voire obsolètes.

    L&apos;agent Java capture les éléments `request.headers` suivants par défaut :

    * `request.headers.referer`
    * `request.headers.accept`
    * `request.headers.contentLength`
    * `request.headers.host`
    * `request.headers.userAgent`

    Les développeurs peuvent également utiliser `addCustomParameter` pour capturer plus d’informations à l’aide d’en-têtes plus détaillés.

    Pour un exemple de la riche configuration disponible par rapport à APM, consultez notre [documentation sur l&apos;agent Java](/docs/apm/agents/java-agent/attributes/java-agent-attributes/#requestparams)

    ### Événement d&apos;erreur

    Il est possible de réduire le volume de données en trouvant comment APM gérera les erreurs. Par exemple, il peut y avoir une erreur inoffensive mais à volume élevé que vous ne pouvez pas supprimer pour le moment.

    Pour ce faire, vous pouvez utiliser `collect`, `ignore` ou `mark as expected` pour les erreurs. Pour plus d&apos;informations, voir [Gérer les erreurs APM](/docs/apm/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected).

    ### requête de base de données

    Un aspect très variable de l&apos;instance APM est le nombre d&apos;appels de base de données et la configuration de l&apos;ensemble. Pour vous aider, vous pouvez contrôler le degré de détail monitoring des requêtes de base de données. Ces requêtes apparaîtront sur la page <DNT>**Transaction traces**</DNT> .

    Les modifications courantes des paramètres de requête de base de données incluent :

    * [Collecte de données de requête brutes au lieu de les obscurcir ou de désactiver la collecte de requêtes](/docs/apm/transactions/transaction-traces/configure-transaction-traces#record-sql).
    * Modification du seuil de trace d&apos;appels.
    * Activation de la requête expliquant la collection de plans.

    Pour plus de détails, voir [la page trace de transaction requête de base de données](/docs/apm/transactions/transaction-traces/transaction-traces-database-queries-page/#settings).

    ### Définition des limites d&apos;événements

    Nos agents APM et mobiles ont des limites quant au nombre d&apos;événements qu&apos;ils peuvent signaler par cycle de collecte. S&apos;il n&apos;y avait pas de limite, un nombre suffisamment important d&apos;événements envoyés pourrait impacter les performances de votre application ou de New Relic. Une fois la limite atteinte, les agents commencent à échantillonner l&apos;événement pour donner une représentation de l&apos;événement à travers le cycle de collecte. Différents agents ont des limites différentes.

    événement qui, avec des limites et sous réserve d&apos;échantillonnage, comprend :

    * événement personnalisé signalé via l&apos;API d&apos;agent (par exemple, le `RecordCustomEvent` de l&apos;agent .NET)
    * `Mobile`
    * `MobileCrash`
    * `MobileHandledException`
    * `MobileRequest`
    * `Span` (voir l&apos;échantillonnage de tracing distribué)
    * `Transaction`
    * `TransactionError`

    La plupart des agents disposent d&apos;options configuration permettant de modifier la limite d&apos;événements sur les transactions échantillonnées. Par exemple, l&apos;agent Java utilise [`max_samples_stored`](/docs/apm/agents/java-agent/configuration/java-agent-configuration-config-file/#ae-max_samples_stored). La valeur par défaut pour `max_samples_stored` est `2000` et la valeur maximale est `10000`. Cette valeur régit le nombre d&apos;événements échantillonnés pouvant être signalés toutes les 60 secondes à partir d&apos;une instance d&apos;agent. Pour une explication complète des limites d&apos;échantillonnage d&apos;événement, voir [limites d&apos;événement](/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling).

    Vous pouvez compenser l&apos;événement échantillonné via NRQL [`EXTRAPOLATE` ](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#extrapolate)l&apos;opérateur.

    Avant de tenter de modifier la manière dont l’échantillonnage se déroule, gardez à l’esprit les points suivants :

    * Plus vous signalez d&apos;événements, plus votre agent utilisera de mémoire.
    * Vous pouvez généralement obtenir les données dont vous avez besoin sans augmenter la limite de rapport d&apos;événements d&apos;un agent.
    * La limite de taille de charge est de 1 Mo (10^6 octets) (compressé), donc le nombre d&apos;événements peut toujours être affecté par cette limite. Pour savoir si des événements sont supprimés, consultez le log de l&apos;agent pour un message d&apos;état `413 HTTP`.

    ### taux d&apos;échantillonnage logarithmique

    Les versions plus récentes des agents de langage New Relic APM peuvent transférer les logs directement vers New Relic. Parfois, vous souhaiterez peut-être définir certaines limites quant à l&apos;ampleur des pics de logging de chaque instance d&apos;agent APM.

    Pour plus de détails sur l&apos;échantillonnage log de l&apos;agent APM, voir [redirecteur de logs](#log-forwarders).

    ### Trace de transaction

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de services connectés
      * Nombre d&apos;appels de méthode monitorés par services connectés
    </Callout>

    Dans APM, [tracez les enregistrements de transactions](/docs/apm/transactions/transaction-traces/transaction-traces) en détail sur les transactions de votre application et les appels de base de données. Vous pouvez modifier les paramètres par défaut pour le suivi de transaction.

    Ceci est également hautement configurable via la [trace de transaction configuration](/docs/apm/transactions/transaction-traces/configure-transaction-traces). Le niveau et le mode de configurabilité seront spécifiques à la langue.

    Les paramètres trace de transaction disponibles à l&apos;aide de configuration côté serveur diffèrent en fonction de l&apos;agent New Relic que vous utilisez. L&apos;interface utilisateur comprend des descriptions de chacun. Les paramètres de l&apos;interface utilisateur peuvent inclure :

    * Traçage des transactions et seuil
    * Enregistrement SQL, y compris le niveau d&apos;enregistrement et les champs de saisie
    * Seuil de Log SQL et trace d&apos;appels
    * Plans et seuils de requêtes SQL
    * Collecte d&apos;erreurs, y compris le code HTTP et la classe d&apos;erreur
    * requête de traçage de lentille
    * Profileur de filetage

    ### Tracing distribué

    Configuration du tracing distribuée présente certaines différences spécifiques à chaque langue. Vous pouvez désactiver le tracing distribué selon vos besoins. Ceci est un exemple pour l&apos;agent Java `newrelic.yml`:

    ```yml
    distributed_tracing:
        enabled: false
    ```

    Ceci est un exemple de node.js pour `newrelic.js`

    ```js
    distributed_tracing: {
      enabled: false
    }
    ```

    Le volume de données varie également selon que vous utilisez ou non [Infinite Tracing](/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing). Le tracing distribué standard pour les agents APM (ci-dessus) capture jusqu&apos;à 10 % de votre trace, mais si vous souhaitez analyser toutes vos données et trouver la trace la plus pertinente, vous pouvez configurer l&apos;Infinite Tracing. Cette alternative au tracing distribué standard est disponible pour tous les agents de langage APM. Les principaux paramètres qui pourraient entraîner une légère augmentation de l&apos;ingestion mensuelle sont :

    * Configurer le monitoring de l&apos;observateur de trace
    * Configurer le filtre de trace d’attribut span
    * Configurer un filtre de trace aléatoire
  </Collapser>

  <Collapser id="browser-agent" title="Agent Browser">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Chargement des pages
      * Appels Ajax
      * Activité d&apos;erreur
    </Callout>

    Pour [la version 1211 ou supérieure de l&apos;agent de navigateur](/docs/release-notes/new-relic-browser-release-notes/browser-agent-release-notes) , toutes requests réseau effectuées par une page sont enregistrées comme événement `AjaxRequest`. Vous pouvez utiliser les options configuration de la liste de refus dans la page d&apos;interface utilisateur des paramètres de l&apos;application pour filtrer requests qui enregistrent l&apos;événement. Quel que soit ce filtre, toutes requests réseau sont capturées sous forme de métriques et disponibles dans la page AJAX.

    ### Utilisation de la liste de refus

    Vous pouvez bloquer requests de trois manières :

    * Pour bloquer l&apos;enregistrement de tous `AjaxRequest` événements, ajoutez un astérisque `*` comme caractère générique.
    * Pour bloquer l&apos;enregistrement de `AjaxRequest` événement sur un domaine, entrez simplement le nom du domaine. Exemple: `example.com`
    * Pour bloquer l&apos;enregistrement de l&apos;événement `AjaxRequest` dans un domaine et un chemin spécifiques, entrez le domaine et le chemin. Exemple: `example.com/path`
    * Le protocole, le port, la recherche et le hachage d&apos;une URL sont ignorés par la liste de refus.

    Pour valider si les filtres que vous avez ajoutés fonctionnent comme prévu, exécutez une requête NRQL pour `AjaxRequest` événement correspondant à votre filtre.

    ### Accéder à la liste de refus

    Pour mettre à jour la liste de refus des URL que votre application filtrera pour empêcher la création d&apos;événements, accédez à la page d&apos;interface utilisateur des paramètres de l&apos;application :

    1. Allez à <DNT>**[one.newrelic.com](https://one.newrelic.com/all-capabilities)**</DNT> et cliquez sur <DNT>**Browser**</DNT>.
    2. Sélectionnez une application.
    3. Dans la navigation de gauche, cliquez sur <DNT>**App settings**</DNT>.
    4. Sous <DNT>**Ajax request deny list**</DNT>, ajoutez les filtres que vous souhaitez appliquer.
    5. Sélectionnez <DNT>**Save application settings**</DNT> pour mettre à jour la configuration de l&apos;agent.
    6. Redéployez l&apos;agent du navigateur en redémarrant l&apos;agent APM associé ou en mettant à jour l&apos;installation du navigateur par copier/coller.

    ### Validation

    ```sql
    FROM AjaxRequest SELECT * WHERE requestUrl LIKE `%example.com%`
    ```
  </Collapser>

  <Collapser id="mobile-agent" title="Agent mobile">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Utilisateurs actifs mensuels
      * Crash événement
      * Nombre d&apos;événement par utilisateur
    </Callout>

    ### Android

    Tous les paramètres, y compris l&apos;appel pour invoquer l&apos;agent, sont appelés dans la méthode `onCreate` de la classe `MainActivity` . Pour modifier les paramètres, appelez le paramètre de l&apos;une des deux manières suivantes (si le paramètre le prend en charge) :

    ```java
    NewRelic.disableFeature(FeatureFlag.DefaultInteractions);
    NewRelic.enableFeature(FeatureFlag.CrashReporting);
    NewRelic.withApplicationToken(NEW_RELIC_TOKEN).start(this.getApplication());
    ```

    [Les paramètres d&apos;analyse](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#analytics-settings) activent ou désactivent la collecte de données d&apos;événement. Ces événements sont signalés et utilisés dans la page <DNT>**Crash analysis**</DNT> .

    Il est également possible de configurer [le logging de l&apos;agent](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#logging-settings-logging) pour qu&apos;il soit plus ou moins détaillé.

    ### iOS

    Comme avec Android, configuration iOS de New Relic permet d&apos;activer et de désactiver [les indicateurs de fonctionnalité](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags).

    Vous pouvez configurer les indicateurs de fonctionnalité suivants :

    #### Rapports de plantage et d&apos;erreurs

    * `NRFeatureFlag_CrashReporting`
    * `NRFeatureFlag_HandleExceptionEvents`
    * `NRFeatureFlag_CrashReporting`

    #### Tracing distribué

    * `NRFeatureFlag_DistributedTracing`

    #### interaction

    * `NRFeatureFlag_DefaultInteractions`
    * `NRFeatureFlag_InteractionTracing`
    * `NRFeatureFlag_SwiftInteractionTracing`

    #### Drapeaux de fonctionnalité du réseau

    * `NRFeatureFlag_ExperimentalNetworkInstrumentation`
    * `NRFeatureFlag_NSURLSessionInstrumentation`
    * `NRFeatureFlag_NetworkRequestEvents`
    * `NRFeatureFlag_RequestErrorEvents`
    * `NRFeatureFlag_HttpResponseBodyCapture`

    Pour plus de détails, voir [les indicateurs de fonctionnalité](/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/ios-agent-configuration-feature-flags).
  </Collapser>

  <Collapser id="infrastructure-agent" title="Agent d'infrastructure">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Hôtes et conteneurs monitorés
      * Taux d&apos;échantillonnage pour l&apos;événement principal
      * Configuration de l&apos;échantillon de processus
      * Les attributs personnalisés
      * Nombre et type d&apos;intégration sur hôte installée
      * Configuration du transfert des logs
    </Callout>

    Le [fichier de configuration de l&apos;agent d&apos;infrastructure](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings) contient deux manières de contrôler le volume d&apos;ingestion. Le contrôle d’ingestion le plus important est la configuration des taux d’échantillonnage. Il existe plusieurs configurations de fréquence d&apos;échantillonnage distinctes que vous pouvez ajuster. Il est également possible de créer des expressions régulières pour contrôler ce qui est collecté à partir de certains collecteurs, tels que `ProcessSample` et `NetworkSample`.

    ### Taux d&apos;échantillonnage configurables

    Il existe un certain nombre de taux d&apos;échantillonnage que vous pouvez configurer dans l&apos;infrastructure, mais ceux-ci sont les plus couramment utilisés.

    | paramètres                    | Défaut | Désactiver |
    | ----------------------------- | ------ | ---------- |
    | `metrics_storage_sample_rate` | 5      | -1         |
    | `metrics_process_sample_rate` | 20     | -1         |
    | `metrics_network_sample_rate` | 10     | -1         |
    | `metrics_system_sample_rate`  | 5      | -1         |
    | `metrics_nfs_sample_rate`     | 5      | -1         |

    ### Échantillons de processus

    Les échantillons de processus constituent souvent la source de données la plus volumineuse provenant de l’agent d’infrastructure, car ils envoient des informations sur tout processus en cours d’exécution sur un hôte. Ils sont désactivés par défaut, mais vous pouvez les activer comme suit :

    ```yaml
    enable_process_metrics: true
    ```

    Cela a le même effet que de définir `metrics_process_sample_rate` sur `-1`. Par défaut, les processus utilisant une faible mémoire sont exclus de l&apos;échantillonnage. Pour plus d&apos;informations, voir `disable-zero-mem-process-filter`.

    Vous pouvez contrôler la quantité de données que vous envoyez en configurant `include_matching_metrics`, ce qui vous permet de restreindre la transmission de données métriques en fonction des valeurs de [l&apos;attribut](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql#naming-conventions) métrique. Vous incluez des données métriques en définissant des valeurs littérales ou partielles pour l&apos;un des attributs de la métrique. Par exemple, vous pouvez choisir d&apos;envoyer le `host.process.cpuPercent` de tous les processus dont le `process.name` correspond aux `^java` expressions régulières.

    Dans cet exemple, nous incluons les métriques de processus à l&apos;aide de fichiers exécutables et de noms :

    ```yaml
      include_matching_metrics:             # You can combine attributes from different metrics
        process.name:
          - regex "^java"                   # Include all processes starting with "java"
        process.executable:
          - "/usr/bin/python2"              # Include the Python 2.x executable
          - regex "\\System32\\svchost"     # Include all svchost executables
    ```

    Vous pouvez également utiliser ce filtre pour l&apos;intégration Kubernetes :

    ```yaml
      env:
        - name: NRIA_INCLUDE_MATCHING_METRICS
          value: |
            process.name:
              - regex "^java"
            process.executable:
              - "/usr/bin/python2"
              - regex "\\System32\\svchost"
    ```

    ### Filtre d&apos;interface réseau

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre d&apos;interfaces réseau monitorées
    </Callout>

    La configuration utilise un mécanisme de recherche de modèles simple qui peut rechercher des interfaces commençant par une séquence spécifique de lettres ou de chiffres suivant l&apos;un ou l&apos;autre modèle :

    * `{name}[other characters]`
    * `[number]{name}[other characters]`, où vous spécifiez le nom à l&apos;aide de l&apos;option `index-1`

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    Filtres d&apos;interface réseau par défaut pour Linux :

    * Interfaces réseau commençant par `dummy`, `lo`, `vmnet`, `sit`, `tun`, `tap` ou `veth`
    * Interfaces réseau contenant `tun` ou `tap`

    Filtres d’interface réseau par défaut pour Windows :

    * Interfaces réseau commençant par `Loop`, `isatap` ou `Local`

    Pour remplacer les valeurs par défaut, incluez votre propre filtre dans le fichier de configuration :

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    ### Les attributs personnalisés

    [Les attributs personnalisés](/docs/data-apis/custom-data/custom-events/collect-custom-attributes) sont des paires valeur-clé similaires aux balises dans d&apos;autres outils utilisés pour annoter les données de l&apos;agent infrastructure . Vous pouvez utiliser ces métadonnées pour créer des ensembles de filtres, regrouper vos résultats et annoter vos données. Par exemple, vous pouvez indiquer l&apos;environnement d&apos;une machine (simulation ou production), le service hôte d&apos;une machine (service de connexion, par exemple) ou l&apos;équipe responsable de cette machine.

    Exemple d&apos;attribut personnalisé de `newrelic.yml`

    ```yaml
    custom_attributes:
      environment: production
      service: billing
      team: alpha-team
    ```

    <Callout variant="tip">
      Si les données ne sont pas bien organisées ou sont devenues obsolètes de quelque façon que ce soit, vous devriez envisager de les rationaliser.
    </Callout>
  </Collapser>

  <Collapser id="k8s-integration" title="Intégration Kubernetes">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de moniteurs `pods` et `containers`
      * Fréquence et nombre de métriques d&apos;état de kube collectées
      * Logs généré par cluster
    </Callout>

    Les systèmes complexes et décentralisés comme Kubernetes ont le potentiel de générer beaucoup de télémétrie en peu de temps. Il existe quelques bonnes approches pour gérer l’ingestion de données dans Kubernetes. Ceux-ci seront très simples si vous utilisez l&apos;observabilité comme code dans votre déploiement K8s.

    Nous vous recommandons vivement d&apos;installer ce Kubernetes d&apos;analyse d&apos;ingestion de données dashboard avant de prendre toute décision concernant la réduction de l&apos;ingestion. Pour obtenir ce dashboard, consultez le [quickstart de l&apos;intégration de l&apos;infrastructure](https://newrelic.com/instant-observability/infrastructure-integrations-data-analysis/8e31a0ae-81c0-4df0-a119-a0ada9ec16fa).

    ### Intervalle de grattage

    En fonction de vos objectifs d&apos;observabilité, vous pouvez envisager d&apos;ajuster l&apos;intervalle de grattage, qui a une durée par défaut de 15 secondes. L&apos;explorateur de cluster Kubernetes ne s&apos;actualise que toutes les 45 s. Si votre utilisation principale des données Kubernetes est de prendre en charge les visualisations KCE, vous pouvez envisager de modifier votre intervalle de scraping à 20 s. Passer de 15 à 20 ans peut avoir un impact considérable.

    Pour plus de détails sur la gestion de cela, consultez notre [documentation sur l&apos;intervalle de scraping de l&apos;intégration Helm](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#scrape-interval).

    ### Filtrage de l&apos;espace de nommage

    L&apos;intégration Kubernetes version 3 et supérieure permet de filtrer les espaces de nommage récupérés en les étiquetant. Par défaut, tous les espaces de nommage sont scrapés.

    Nous utilisons le `namespaceSelector` de la même manière que Kubernetes. Pour inclure uniquement l&apos;espace de nommage correspondant à une étiquette, modifiez le `namespaceSelector` en ajoutant ce qui suit à votre `values-newrelic.yaml`, sous la section `newrelic-infrastructure` :

    ```yaml
    common:
      config:
        namespaceSelector:
          matchLabels:
            key1 : "value1"
    ```

    Dans cet exemple, seul l&apos;espace de nommage avec l&apos;étiquette `newrelic.com/scrape` définie sur `true` sera récupéré :

    ```yaml
    global:
      licenseKey: _YOUR_NEW_RELIC_LICENSE_KEY_
      cluster: _K8S_CLUSTER_NAME_

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchLabels:
              newrelic.com/scrape: "true"
    ```

    Vous pouvez également utiliser des expressions de correspondance Kubernetes pour inclure ou exclure l&apos;espace de nommage. Les opérateurs valides sont :

    * Dans
    * Pas dans
    * Existe
    * N&apos;existe pas

    La structure générale de la section `matchExpressions` est constituée d&apos;une ou plusieurs des lignes suivantes :

    ```yaml
    {key: VALUE, operator: OPERATOR, values: LIST_OF_VALUES}
    ```

    Voici un exemple complet :

    ```yaml
    common:
      config:
        namespaceSelector:
          matchExpressions:
          - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    <Callout variant="tip">
      Vous pouvez inclure plusieurs lignes dans la section `matchExpresions` et les expressions sont concaténées. Tout doit être vrai pour que le filtre soit appliqué. Les étiquettes et les expressions de correspondance sont expliquées plus en détail [ici](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
    </Callout>

    Dans cet exemple, l&apos;espace de nommage avec l&apos;étiquette `newrelic.com/scrape` définie sur `false` sera exclu :

    ```yaml
    global:
      licenseKey: _YOUR_NEW_RELIC_LICENSE_KEY_
      cluster: _K8S_CLUSTER_NAME_

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchExpressions:
            - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    Consultez la liste complète des paramètres que vous pouvez définir dans le [fichier README du graphique](https://github.com/newrelic/nri-kubernetes/tree/main/charts/newrelic-infrastructure).

    #### Comment puis-je savoir quels espaces de nommage sont exclus ? [#excluded-namespaces]

    Tous les espaces de nommage au sein du cluster sont répertoriés grâce à l&apos;échantillon `K8sNamespace`. L&apos;attribut `nrFiltered` détermine si les données relatives à l&apos;espace de nommage vont être récupérées.

    Utilisez cette requête pour savoir quels espaces de nommage sont monitorés :

    ```sql
    FROM K8sNamespaceSample SELECT displayName, nrFiltered
    WHERE clusterName = INSERT_NAME_OF_CLUSTER SINCE
    2 MINUTES AGO
    ```

    #### Quelles données sont supprimées de l’espace de nommage exclu ? [#namespaces-discarded-data]

    Les échantillons suivants ne seront pas disponibles pour l&apos;espace de nommage exclu :

    * `K8sContainerSample`
    * `K8sDaemonsetSample`
    * `K8sDeploymentSample`
    * `K8sEndpointSample`
    * `K8sHpaSample`
    * `K8sPodSample`
    * `K8sReplicasetSample`
    * `K8sServiceSample`
    * `K8sStatefulsetSample`
    * `K8sVolumeSample`

    ### Métriques d&apos;état de Kubernetes

    L&apos;explorateur cluster Kubernetes ne nécessite que les métriques d&apos;état Kube (KSM) suivantes :

    * données du conteneur
    * Données Cluster
    * Données du nœud
    * Données du pod
    * Données de volume
    * Données du serveur API<sup>1</sup>
    * Données du responsable du traitement<sup>1</sup>
    * Données ETCD<sup>1</sup>
    * Données du planificateur<sup>1</sup>

    <sup>1</sup> Non collecté dans un environnement Kubernetes géré (EKS, GKE, AKS, etc.)

    Vous pouvez envisager de désactiver certains des éléments suivants :

    * Données DaemonSet
    * Données de déploiement
    * données de point de terminaison
    * espace de données de nommage
    * Données du ReplicaSet<sup>2</sup>
    * Données de service
    * Données StatefulSet

    <sup>2</sup> Utilisé dans l&apos;alerte par défaut : « Le ReplicaSet n&apos;a pas la quantité souhaitée de pod »

    #### Exemple de mise à jour des métriques d&apos;état dans le manifeste (déploiement)

    ```shell
    [spec]
      [template]
        [spec]
          [containers]
            [name=kube-state-metrics]
            [args]
            #- --collectors=daemonsets
            #- --collectors=deployments
            #- --collectors=endpoints
            #- --collectors=namespaces
            #- --collectors=replicasets
            #- --collectors=services
            #- --collectors=statefulsets
    ```

    *Exemple de mise à jour des métriques d&apos;état dans le manifeste (ClusterRole)*

    ```shell
    [rules]
    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - daemonsets
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - deployments
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - endpoints
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - namespaces
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - replicasets
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - services
    #   verbs: ["list", "watch"]

    # - apiGroups: ["apps"]
    #   resources:
    #   - statefulsets
    #   verbs: ["list", "watch"]
    ```

    ### Configurer `lowDataMode` dans le graphique `nri-bundle`

    Nos cartes Helm prennent en charge l&apos;option permettant de réduire la quantité de données ingérées au prix de la suppression d&apos;informations détaillées. Pour l&apos;activer, définissez `global.lowDataMode` sur `true` dans le graphique `nri-bundle` .

    `lowDataMode` affecte trois composants spécifiques du graphique `nri-bundle` :

    1. Augmentez l’intervalle de l’agent d’infrastructure de `15` à `30` secondes.
    2. L&apos;intégration de Prometheus OpenMetrics exclura quelques métriques comme indiqué dans la documentation Helm ci-dessous.
    3. Les détails des étiquettes et des annotations seront supprimés des logs.

    Vous pouvez trouver plus de détails sur cette configuration dans notre [documentation Helm](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#reducedataingest).
  </Collapser>

  <Collapser id="on-host-integrations" title="Intégrations sur hôte">
    Les intégrations sur hôte de New Relic représentent un ensemble diversifié d&apos;intégrations pour des services tiers tels que Postgresql, MySQL, Kafka, RabbitMQ, etc. Il est impossible de fournir toutes les techniques d&apos;optimisation dans le cadre de ce document, mais ces techniques s&apos;appliquent généralement :

    * Gérer le taux d&apos;échantillonnage
    * Gérer les parties de la configuration qui peuvent augmenter ou diminuer l&apos;étendue de la collection
    * Gérer les parties de la configuration qui permettent des requêtes personnalisées
    * Gérez l&apos;attribut personnalisé des agents infrastructure à appliquer à toutes les données d&apos;intégration sur hôte.

    Nous utiliserons quelques exemples pour le démontrer.

    ### [Intégration PostgreSQL](/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration/#example-postgresSQL-collection-config)

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de tables monitorées
      * Nombre d&apos;indices monitorés
    </Callout>

    La configuration de l&apos;intégration PostgreSQL sur l&apos;hôte fournit ces paramètres réglables qui peuvent aider à gérer le volume de données :

    * `interval`: La valeur par défaut est 15 s
    * `COLLECTION_LIST`: liste des tables à monitorer (utilisez ALL pour monitorer TOUTES)
    * `COLLECT_DB_LOCK_METRICS`: Collecter `dblock` métriques
    * `PGBOUNCER`: Collecter `pgbouncer` métriques
    * `COLLECT_BLOAT_METRICS`: Collecter les métriques de gonflement
    * `METRICS`: Définissez sur `true` pour collecter uniquement les métriques
    * `INVENTORY`: Définissez sur `true` pour activer uniquement la collecte d&apos;inventaire
    * `CUSTOM_METRICS_CONFIG`:Fichier de configuration contenant une requête de collection personnalisée

    <DNT>
      **Sample config:**
    </DNT>

    ```yaml
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres
          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

    ### [Intégration de Kafka](/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration/)

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de courtiers dans le cluster
      * Nombre de sujets dans le cluster
    </Callout>

    La configuration de l&apos;intégration Kafka sur l&apos;hôte fournit ces paramètres réglables qui peuvent aider à gérer le volume de données :

    * `interval`: La valeur par défaut est 15 s
    * `TOPIC_MODE`:Détermine le nombre de sujets que nous collectons. Les options sont `all`, `none`, `list` ou `regex`.
    * `METRICS`: Définissez sur `true` pour collecter uniquement les métriques
    * `INVENTORY`: Définissez sur `true` pour activer uniquement la collecte d&apos;inventaire
    * `TOPIC_LIST`: Éventail JSON de noms de sujets à monitorer. Uniquement en vigueur si topic\_mode est défini sur liste.
    * `COLLECT_TOPIC_SIZE`: Collectez la taille du sujet métrique. Les options sont `true` ou `false`, la valeur par défaut est `false`.
    * `COLLECT_TOPIC_OFFSET`:Collectez le décalage du sujet métrique. Les options sont `true` ou `false`, la valeur par défaut est `false`.

    La collecte de mesures au niveau du sujet, en particulier les décalages, peut nécessiter beaucoup de ressources et peut avoir un impact sur le volume de données. L&apos;ingestion d&apos;un cluster peut augmenter d&apos;un ordre de grandeur simplement par l&apos;ajout de nouvelles rubriques Kafka au cluster.

    ### [Intégration de MongoDB](/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration)

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de bases de données monitorées
    </Callout>

    L&apos;intégration MongoDB fournit ces paramètres réglables qui peuvent aider à gérer le volume de données :

    * `interval`: La valeur par défaut est 15 s
    * `METRICS`: Définissez sur `true` pour collecter uniquement les métriques
    * `INVENTORY`: Définissez sur `true` pour activer uniquement la collecte d&apos;inventaire
    * `FILTERS`: Une cartographie JSON des noms de base de données vers un éventail de noms de collections. Si vide, la valeur par défaut est toutes les bases de données et collections.

    Pour toute intégration sur hôte que vous utilisez, il est important de connaître les paramètres tels que `FILTERS` , où la valeur par défaut est de collecter les métriques de toutes les bases de données. Il s’agit d’un domaine dans lequel vous pouvez utiliser vos priorités monitoring pour rationaliser les données collectées.

    <DNT>
      **Example configuration with different intervals for METRIC and INVENTORY:**
    </DNT>

    ```yaml
    integrations:
      - name: nri-mongodb
        env:
          METRICS: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 15s
        labels:
          environment: production

      - name: nri-mongodb
        env:
          INVENTORY: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 60s
        labels:
          environment: production
        inventory_source: config/mongodb
    ```

    ### [Intégration Elasticsearch](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration)

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de nœuds dans le cluster
      * Nombre d&apos;indices dans le cluster
    </Callout>

    L&apos;intégration Elasticsearch fournit ces paramètres réglables qui peuvent aider à gérer le volume de données :

    * `interval`: La valeur par défaut est 15 s
    * `METRICS`: Définissez sur `true` pour collecter uniquement les métriques
    * `INVENTORY`: Définissez sur `true` pour activer uniquement la collecte d&apos;inventaire
    * `COLLECT_INDICES`: Indique s&apos;il faut collecter ou non les métriques d&apos;index.
    * `COLLECT_PRIMARIES`:Indique s&apos;il faut collecter ou non des métriques primaires.
    * `INDICES_REGEX`: Filtrez les indices collectés.
    * `MASTER_ONLY`:Collectez les métriques de cluster sur le maître élu uniquement.

    <DNT>
      **Example configuration with different intervals for `METRICS` and `INVENTORY`:**
    </DNT>

    ```yaml
    integrations:
      - name: nri-elasticsearch
        env:
          METRICS: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          REMOTE_MONITORING: true
        interval: 15s
        labels:
          environment: production

      - name: nri-elasticsearch
        env:
          INVENTORY: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          CONFIG_PATH: /etc/elasticsearch/elasticsearch.yml
        interval: 60s
        labels:
          environment: production
        inventory_source: config/elasticsearch
    ```

    ### [Intégration JMX](/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration)

    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Métriques répertoriées dans `COLLECTION_CONFIG`
    </Callout>

    L&apos;intégration JMX est intrinsèquement générique. Il vous permet d&apos;extraire des métriques de n&apos;importe quelle instance JMX. Vous avez le contrôle sur ce qui est collecté par cette intégration. Dans certaines entreprises, les métriques JMX des environnements New Relic représentent une proportion relativement élevée de toutes les données collectées.

    L&apos;intégration JMX fournit ces paramètres réglables qui peuvent aider à gérer le volume de données :

    * `interval`: La valeur par défaut est 15 s
    * `METRICS`: Définissez sur `true` pour collecter uniquement les métriques
    * `INVENTORY`: Définissez sur `true` pour activer uniquement la collecte d&apos;inventaire
    * `METRIC_LIMIT`:Nombre de métriques pouvant être collectées par entité. Si cette limite est dépassée, l&apos;entité ne sera pas signalée. Une limite de 0 implique aucune limite.
    * `LOCAL_ENTITY`:Collectez toutes les métriques sur l’entité locale. Utilisé uniquement lors de monitoring de localhost.
    * `COLLECTION_FILES`:Une liste séparée par des virgules des chemins d&apos;accès complets aux fichiers de définition de la collection métrique. Pour l&apos;installation sur l&apos;hôte, le fichier de collecte de métriques JVM par défaut se trouve à `/etc/newrelic-infra/integrations.d/jvm-metrics.yml`.
    * `COLLECTION_CONFIG`: configuration de la collection métriques en JSON.

    Ce sont les entrées `COLLECTION_CONFIG` qui régissent le plus la quantité de données ingérées. Comprendre le modèle JMX que vous récupérez vous aidera à l&apos;optimiser.

    *`COLLECTION_CONFIG` exemple pour les métriques JVM*

    ```java
    COLLECTION_CONFIG='{"collect":[{"domain":"java.lang","event_type":"JVMSample","beans":[{"query":"type=GarbageCollector,name=*","attributes":["CollectionCount","CollectionTime"]},{"query":"type=Memory","attributes":["HeapMemoryUsage.Committed","HeapMemoryUsage.Init","HeapMemoryUsage.Max","HeapMemoryUsage.Used","NonHeapMemoryUsage.Committed","NonHeapMemoryUsage.Init","NonHeapMemoryUsage.Max","NonHeapMemoryUsage.Used"]},{"query":"type=Threading","attributes":["ThreadCount","TotalStartedThreadCount"]},{"query":"type=ClassLoading","attributes":["LoadedClassCount"]},{"query":"type=Compilation","attributes":["TotalCompilationTime"]}]}]}'
    ```

    L’omission d’une entrée de cette configuration, telle que `NonHeapMemoryUsage.Init` , aura un impact tangible sur le volume global de données collectées.

    *`COLLECTION_CONFIG` exemple pour les métriques Tomcat*

    ```java
    COLLECTION_CONFIG={"collect":[{"domain":"Catalina","event_type":"TomcatSample","beans":[{"query":"type=UtilityExecutor","attributes":["completedTaskCount"]}]}]}
    ```

    ### Autre intégration sur hôte

    Il existe de nombreuses autres intégrations sur hôte avec des options configuration qui vous aideront à optimiser la collecte. Certains des plus couramment utilisés sont :

    * [NGINX](/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/)
    * [MySQL](/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration)
    * [Redis](/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration)
    * [Apache](/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration)
    * [RabbitMQ](/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration)

    C&apos;est un bon [point de départ](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations#on-host) pour en savoir plus.
  </Collapser>

  <Collapser id="network-performance-monitoring" title="monitoring des performances du réseau (NPM)">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      Dispositifs monitorés pilotés par :

      * appareils configurés de manière rigide
      * Portée du CIDR dans la section découverte
      * pièges configurés
    </Callout>

    Cette section se concentre sur monitoring des performances du réseau de New Relic qui s&apos;appuie sur l&apos;agent `ktranslate` de Kentik. Cet agent est assez sophistiqué et il est important de bien comprendre les [documents de configuration avancés](/docs/network-performance-monitoring/advanced/advanced-config) avant de procéder à des efforts d&apos;optimisation majeurs. Les options de configuration incluent :

    * `mibs_enabled`: éventail de tous les MIB actifs que l&apos;image docker KTranslate va interroger. Cette liste est générée automatiquement lors de la découverte si l&apos;attribut `discovery_add_mibs` est `true`. Les MIB non répertoriés ici ne seront interrogés sur aucun périphérique dans le fichier de configuration. Vous pouvez spécifier une table SNMP directement dans un fichier MIB en utilisant la syntaxe `MIB-NAME.tableName` . Ex : `HOST-RESOURCES-MIB.hrProcessorTable`.

    * `user_tags`: valeur clé paire d&apos;attributs pour donner plus de contexte à l&apos;appareil. La balise à ce niveau sera appliquée à tous les périphériques du fichier configuration .

    * `devices`: Section répertoriant les appareils à monitorer pour le débit

    * `traps`: configure l&apos;IP et les ports à monitorer avec des interruptions SNMP (la valeur par défaut est `127.0.0.1:1162`)

    * `discovery`: configure la manière dont le point de terminaison peut être découvert. Dans cette section, les paramètres suivants contribueront le plus à augmenter ou à diminuer la portée :

      * `cidrs`: éventail de plages d&apos;adresses IP cibles en [notation CIDR](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation).
      * `ports`: éventail de ports cibles à analyser lors de l&apos;interrogation SNMP.
      * `debug`: Indique s&apos;il faut activer le logging au niveau de débogage pendant la découverte. Par défaut, il est défini sur `false`
      * `default_communities`: éventail de chaînes de communauté SNMPv1/v2c à analyser pendant l&apos;interrogation SNMP. Cet éventail est évalué dans l&apos;ordre et la découverte accepte la première communauté passante.

    Pour prendre en charge le filtrage des données qui ne créent pas de valeur pour vos besoins d&apos;observabilité, vous pouvez définir la carte d&apos;attributs `global.match_attributes.{}` et/ou `devices.<deviceName>.match_attributes.{}` .

    Cela fournira un filtrage au niveau de KTranslate, avant d&apos;envoyer des données à New Relic, vous donnant un contrôle précis sur monitoring d&apos;éléments tels que les interfaces.

    Pour plus de détails, voir [des performances du réseau monitoring configuration](/docs/network-performance-monitoring/advanced/advanced-config/#match_attributes-attribute).
  </Collapser>

  <Collapser id="log-forwarders" title="Redirecteur de logs">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Logs transmis
      * Taille moyenne des enregistrements log de transfert
    </Callout>

    Les logs représentent l&apos;une des sources de télémétrie les plus flexibles dans la mesure où nous acheminons généralement les logs via une couche de transfert dédiée avec ses propres règles de routage et de transformation. Comme il existe une grande variété de transitaires, nous nous concentrerons sur les plus couramment utilisés :

    * Agents linguistiques APM (versions récentes)
    * Fluentd
    * Fluentbit
    * Agent d&apos;infrastructure New Relic ( Fluentbit intégré)
    * Logstash

    ### Échantillonnage log de l&apos;agent APM

    Les versions récentes des agents de langage New Relic peuvent transmettre les logs directement à New Relic. Vous souhaiterez peut-être définir certaines limites quant à l&apos;ampleur des pics de logging de chaque instance d&apos;agent APM.

    Vous pouvez activer l&apos;échantillonnage avec la variable d&apos;environnement `NEW_RELIC_APPLICATION_LOGGING_FORWARDING_MAX_SAMPLES_STORED` et la configurer en fournissant le nombre maximal de logs que la file d&apos;attente de logging des agents APM stockera. Il fonctionne sur la base d&apos;une file d&apos;attente de priorité personnalisée et donne à tous les messages du log une priorité. les logs qui se produisent dans une transaction obtiennent la priorité de la transaction.

    La file d&apos;attente des logs est triée en fonction de la priorité et du moment où le log arrive. La priorité la plus élevée passe en premier et, si nécessaire, le log le plus récent a la priorité. Les logs sont ajoutés individuellement à la file d&apos;attente (même ceux d&apos;une transaction), et une fois la limite atteinte, le log à la fin de la file d&apos;attente est poussé vers l&apos;extérieur en faveur du log le plus récent.

    Dans la section ressources ci-dessous, il existe un qui vous aide à [quickstart dashboard](https://onenr.io/0Bj3BlEZkRX) suivre log le volume de manière simple. Le volume log de suivi vous permettra d&apos;ajuster ou de désactiver le taux d&apos;échantillonnage en fonction de vos besoins d&apos;observabilité.

    ### Configuration des filtres dans Fluentd ou Fluentbit

    La plupart des transitaires généraux fournissent un [workflowde routage](https://docs.fluentd.org/configuration/routing-examples) assez complet qui inclut le filtrage et la transformation. Notre agent infrastructure fournit des modèles très simples pour filtrer les logs indésirables.

    expressions régulières pour filtrer les enregistrements. Uniquement pris en charge pour les sources `tail`, `systemd`, `syslog` et `tcp` (uniquement avec le format `none`). Ce champ fonctionne de manière similaire à `grep -E` dans le système Unix. Par exemple, pour un fichier donné en cours de capture, vous pouvez filtrer les enregistrements contenant soit `WARN` soit `ERROR` en utilisant :

    ```yaml
      - name: only-records-with-warn-and-error
        file: /var/log/logFile.log
        pattern: WARN|ERROR
    ```

    Si vous avez une configuration Fluentd pré-écrite pour Fluentbit qui effectue un filtrage ou une analyse précieuse, vous pouvez les importer dans notre configuration de logging. Pour ce faire, utilisez les paramètres `config_file` et `parsers` dans n&apos;importe quel fichier `.yaml` de votre dossier `logging.d` :

    * `config_file`: chemin vers un fichier de configuration Fluent Bit existant. Tout chevauchement de source entraîne des messages en double dans <InlinePopover type="logs" />de New Relic.
    * `parsers_file`: chemin vers un fichier d&apos;analyse Fluent Bit existant.

    Les noms d’analyseurs suivants sont réservés : `rfc3164`, `rfc3164-local` et `rfc5424`.

    Apprendre à injecter un attribut ou une balise dans vos logs dans votre pipeline de données et à effectuer des transformations peut vous aider à supprimer les fonctionnalités en aval à l&apos;aide des règles de suppression New Relic. En augmentant vos logs avec des métadonnées sur la source, nous pouvons prendre des décisions centralisées et réversibles sur ce qu&apos;il faut déposer sur le backend. Au minimum, assurez-vous que les attributs suivants sont présents dans vos logs sous une forme ou une autre :

    * Équipe
    * Environnement (développement/stage/production)
    * Application
    * centre de données
    * niveau de log

    Vous trouverez ci-dessous quelques ressources détaillées de routage et de filtrage :

    * [Filtres et modèles de routage courants dans Fluentd](https://docs.fluentd.org/configuration/routing-examples)
    * [Fluentbit de données pipeline](https://docs.fluentbit.io/manual/concepts/data-pipeline)
    * [Transfert des logs avec l&apos;agent New Relic Infrastructure](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/)

    ### Ajuster l&apos;ensemble d&apos;attributs par défaut de l&apos;agent infrastructure

    L&apos;agent infrastructure ajoute certains attributs par défaut, y compris toute balise personnalisée ajoutée à l&apos;hôte. Il est possible que votre configuration en intègre bien plus, y compris un grand nombre de balises AWS, qui apparaissent dans New Relic sous la forme `aws.[attributename]`. Ces attributs sont importants, il est donc fortement recommandé d&apos;évaluer vos besoins en matière de visualisation, d&apos;analyse et d&apos;alerte par rapport aux modifications configuration prévues. Par exemple, les logs d&apos;un cluster Kubernetes ne seront probablement pas utiles sans métadonnées telles que :

    * `cluster_name`
    * `pod_name`
    * `container_name`
    * `node_name`
  </Collapser>

  <Collapser id="prometheus-metrics-sources" title="Sources des métriques Prometheus">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de métriques exportées à partir des applications
      * Nombre de métriques transférées via l&apos;écriture à distance ou POMI
    </Callout>

    New Relic fournit deux options principales pour envoyer des métriques Prometheus à New Relic. Les bonnes pratiques pour la gestion de l&apos;ingestion métrique se concentrent principalement sur la deuxième option - l&apos;intégration Prometheus OpenMetrics (POMI) - car ce composant a été créé par New Relic.

    ### Option 1 : [Intégration de l&apos;écriture à distancePrometheus](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)

    Pour les options de configuration du scraping du serveur Prometheus, consultez [la documentation de configuration de Prometheus](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config). Ces configurations de scraping déterminent quelles métriques sont collectées par le serveur Prometheus. En configurant le paramètre [`remote_write`](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration) , vous pouvez écrire les métriques collectées dans la base de données New Relic (NRDB) via l&apos;API métrique New Relic.

    ### Option 2 : [intégration dePrometheus OpenMetrics (POMI)](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration)

    POMI est une intégration autonome qui récupère les métriques des points de terminaison Prometheus découverts dynamiquement et statiques. POMI envoie ensuite ces données à NRDB via l&apos;API métrique New Relic. Cette intégration est idéale pour les clients qui n&apos;utilisent pas actuellement le serveur Prometheus.

    #### POMI : gratter l&apos;étiquette

    POMI découvrira tout point de terminaison Prometheus contenant l&apos;étiquette ou l&apos;annotation `prometheus.io/scrape=true` par défaut. Cela peut être un grand nombre de points de terminaison et donc, un grand nombre de métriques ingérées, en fonction de ce qui est déployé dans le cluster.

    Il est suggéré de modifier le paramètre `scrape_enabled_label` en quelque chose de personnalisé (par exemple `newrelic/scrape`) et que vous étiquetiez de manière sélective le point de terminaison Prometheus lorsque l&apos;ingestion de données est de la plus haute importance.

    Pour la dernière configuration de référence, voir [nri-prometheus-latest.yaml](https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml).

    <DNT>
      **POMI config parameter:**
    </DNT>

    ```yaml
    # Label used to identify scrapable targets. 
    # Defaults to "prometheus.io/scrape"
      scrape_enabled_label: "prometheus.io/scrape"
    ```

    POMI découvrira tout point de terminaison Prometheus exposé au niveau du nœud par défaut. Cela inclut généralement des métriques provenant de Kubelet et de cAdvisor. Si vous exécutez le Daemonset New Relic Kubernetes, il est important de définir `require_scrape_enabled_label_for_nodes: true` afin que POMI ne collecte pas de métriques en double.

    Pour le point de terminaison cible du Daemonset New Relic Kubernetes , consultez [notre Kubernetes README sur GitHub](https://github.com/newrelic/nri-kubernetes/blob/main/README.md).

    #### POMI : étiquette de scraping pour les nœuds

    POMI découvrira tout point de terminaison Prometheus exposé au niveau du nœud par défaut. Cela inclut généralement des métriques provenant de Kubelet et de cAdvisor. Si vous exécutez le Daemonset New Relic Kubernetes, il est important de définir `require_scrape_enabled_label_for_nodes: true` afin que POMI ne collecte pas de métriques en double.

    Pour le point de terminaison cible du Daemonset New Relic Kubernetes , consultez [notre Kubernetes README sur GitHub](https://github.com/newrelic/nri-kubernetes/blob/main/README.md).

    *Paramètres de configuration POMI*

    ```yaml
    # Whether k8s nodes need to be labeled to be scraped or not. 
    # Defaults to false.
      require_scrape_enabled_label_for_nodes: false
    ```

    #### POMI : coexister avec `nri-kubernetes`

    [L&apos;intégration Kubernetes ](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)de New Relic collecte un [certain nombre de mesures](/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data#metrics) prêtes à l&apos;emploi. Cependant, il ne collecte pas toutes les métriques possibles disponibles à partir d&apos;un cluster Kubernetes.

    Dans la configuration POMI, vous verrez une section similaire à celle-ci qui collectera <DNT>**disable**</DNT> métriques pour un sous-ensemble de métriques que l&apos;intégration New Relic Kubernetes collecte déjà à partir de <DNT>**Kube State Metrics**</DNT>.

    Il est également très important de définir `require_scrape_enabled_label_for_node: true` afin que les métriques Kubelet et cAdvisor ne soient pas dupliquées.

    <DNT>
      **POMI config parameters:**
    </DNT>

    ```yaml
      transformations:
        - description: "Uncomment if running New Relic Kubernetes integration"
          ignore_metrics:
            - prefixes:
              - kube_daemonset_
              - kube_deployment_
              - kube_endpoint_
              - kube_namespace_
              - kube_node_
              - kube_persistentvolume_
              - kube_persistentvolumeclaim_
              - kube_pod_
              - kube_replicaset_
              - kube_service_
              - kube_statefulset_

    ```

    #### POMI : paramètres de demande/limite

    Lors de l&apos;exécution de POMI, il est recommandé d&apos;appliquer les [limites de ressources](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/) suivantes pour un cluster générant environ 500 000 DPM :

    * Limite du processeur : 1 cœur (1000 m)
    * Limite de mémoire : 1 Go 1024 (1 Go)

    Vous devez définir la demande de ressources pour le processeur et la mémoire afin de fournir à POMI suffisamment de ressources du cluster. Régler ceci sur quelque chose d&apos;extrêmement bas (par exemple cpu: 50m) peut entraîner la consommation de ressources de cluster par des « voisins bruyants ».

    <DNT>
      **POMI config parameter:**
    </DNT>

    ```yaml
    spec:
      serviceAccountName: nri-prometheus
      containers:
      - name: nri-prometheus
        image: newrelic/nri-prometheus:2.2.0
        resources:
          requests:
            memory: 512Mi
            cpu: 500m
          limits:
            memory: 1G
            cpu: 1000m
    ```

    ### POMI : estimation du DPM et de la cardinalité

    Bien que la cardinalité ne soit pas directement associée à l&apos;ingestion facturable par Go, New Relic maintient certaines limites de débit sur la cardinalité et les points de données par minute. Être capable de visualiser la cardinalité et le DPM d&apos;un cluster Prometheus peut être très important.

    <Callout variant="tip">
      Les comptes New Relic ont une limite de DPM et de cardinalité de 1 M, mais vous pouvez demander jusqu&apos;à 15 M de DPM et 15 M de cardinalité. Pour demander des modifications, contactez votre représentant de compte New Relic. Pour plus d&apos;informations, consultez [Limites de l&apos;API métrique](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes).
    </Callout>

    Si vous exécutez déjà Prometheus Server, vous pouvez exécuter des estimations DPM et de cardinalité avant d&apos;activer POMI ou `remote_write`.

    <DNT>
      **Data points per minute (DPM):**
    </DNT>

    ```promql
    rate(prometheus_tsdb_head_samples_appended_total[10m]) * 60
    ```

    <DNT>
      **Top 20 metrics (highest cardinality):**
    </DNT>

    ```promql
    topk(20, count by (<DNT>**name**</DNT>, job)({__name__=~".+"}))
    ```
  </Collapser>

  <Collapser id="cloud-integration" title="Intégration dans le cloud">
    <Callout variant="IMPORTANT" title="Les moteurs de la croissance">
      * Nombre de métriques exportées par intégration
      * Fréquence d&apos;interrogation (pour l&apos;intégration basée sur l&apos;interrogation)
    </Callout>

    Certaines intégrations cloud New Relic obtiennent des données à partir des API des fournisseurs cloud . Avec cette implémentation, les données sont collectées à partir d&apos;API monitoring telles que AWS CloudWatch, Azure Monitor et GCP Stackdriver, et les métadonnées d&apos;inventaire sont collectées à partir des API des services spécifiques.

    D&apos;autres cloud d&apos;intégration obtiennent leurs données à partir de métriques en streaming (ou métriques « poussées ») qui sont poussées via un service de streaming tel qu&apos;AWS Kinesis.

    ### Intégration basée sur l&apos;API de sondage

    Si vous souhaitez signaler plus ou moins de données de votre cloud d&apos;intégration, ou si vous devez contrôler l&apos;utilisation des API des fournisseurs cloud pour éviter d&apos;atteindre le débit limite et les limites de limitation de votre compte cloud , vous pouvez modifier les paramètres de configuration pour modifier la quantité de données qu&apos;ils signalent. Les deux principaux contrôles sont :

    * [Modifier la fréquence de sondage](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#polling)
    * [Modifier les données rapportées](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#filter-data)

    Voici quelques exemples de raisons commerciales pour lesquelles vous souhaitez modifier la fréquence de vos sondages :

    * <DNT>**Billing**</DNT>:Si vous devez gérer votre facture AWS CloudWatch, vous souhaiterez peut-être diminuer la fréquence d&apos;interrogation. Avant de faire cela, assurez-vous que les conditions d&apos;alerte définies pour votre cloud d&apos;intégration ne sont pas affectées par cette réduction.
    * <DNT>**New services**</DNT>:Si vous déployez un nouveau service ou une nouvelle configuration et que vous souhaitez collecter des données plus souvent, vous souhaiterez peut-être augmenter temporairement la fréquence d&apos;interrogation.

    <Callout variant="caution">
      La modification des paramètres configuration de votre intégration peut avoir un impact sur l&apos;état d&apos;alerte et les tendances des graphiques.
    </Callout>

    Pour plus de détails, voir [Configurer l&apos;interrogation](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations).

    ### Métriques « streaming » ou « poussées »

    De plus en plus cloud d&apos;intégration offrent la possibilité de faire circuler les données via un [service de streaming](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream) au lieu d&apos;utiliser l&apos;interrogation API, ce qui réduit considérablement la latence. Un problème que certains utilisateurs ont observé est qu&apos;il n&apos;est pas aussi facile de contrôler le volume car vous ne pouvez pas configurer la fréquence d&apos;échantillonnage.

    Les règles New Relic pour la suppression des données sont le principal moyen de filtrer les métriques de streaming avec un volume trop élevé. Cependant, il existe certaines choses que vous pouvez faire du côté du fournisseur de cloud pour aider à limiter le volume de flux.

    Par exemple, dans AWS, il est possible d&apos;utiliser des clés de condition pour [limiter l&apos;accès à l&apos;espace de nommage CloudWatch](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/iam-cw-condition-keys-namespace.html).

    La politique suivante limite l&apos;utilisateur à publier des métriques uniquement dans l&apos;espace de nommage nommé `MyCustomNamespace`:

    ```json
    {
        "Version": "2012-10-17",
        "Statement": {
            "Effect": "Allow",
            "Resource": "*",
            "Action": "cloudwatch:PutMetricData",
            "Condition": {
                "StringEquals": {
                    "cloudwatch:namespace": "MyCustomNamespace"
                }
            }
        }
    }
    ```

    La politique suivante permet à l&apos;utilisateur de publier des métriques dans n&apos;importe quel espace de nommage à l&apos;exception de `CustomNamespace2`:

    ```json
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData"
            },
            {
                "Effect": "Deny",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData",
                "Condition": {
                    "StringEquals": {
                        "cloudwatch:namespace": "CustomNamespace2"
                    }
                }
            }
        ]
    }
    ```
  </Collapser>
</CollapserGroup>

## Optimiser avec des règles de dépôt [#optimize-with-drop-rules]

Une règle simple pour comprendre ce que vous pouvez faire avec les règles de dépôt est : <DNT>**If you can query it you can drop it.**</DNT> Les règles de filtrage de dépôt vous aident à atteindre plusieurs objectifs importants :

* Réduisez les coûts en stockant uniquement le log correspondant à votre compte.
* Protégez la confidentialité et la sécurité en supprimant les informations personnelles identifiables (PII).
* Réduisez le bruit en supprimant les événements et attributs non pertinents.

<Callout variant="tip">
  Lors de la création de règles de suppression, vous êtes responsable de vous assurer que les règles identifient et suppriment avec précision les données qui répondent aux conditions que vous avez établies. Vous êtes également responsable de monitoring de la règle, ainsi que des données que vous divulguez à New Relic. Testez et retestez toujours votre requête et, après avoir installé la règle de suppression, assurez-vous qu&apos;elle fonctionne comme prévu. La création d&apos;un dashboard pour monitorer vos données avant et après le dépôt vous aidera.
</Callout>

Voici quelques conseils sur l&apos;utilisation des règles de suppression pour optimiser l&apos;ingestion de données pour des outils spécifiques :

<CollapserGroup>
  <Collapser id="logs" title="Logs">
    Toutes les règles de dépôt de New Relic sont implémentées par le même modèle de données backend et la même API. Notre gestion des logs fournit une interface utilisateur puissante qui facilite grandement la création et le monitoring des règles de dépôt.

    Précédemment dans cette série de didacticiels, nous avons abordé la priorisation de la télémétrie en exécutant quelques exercices pour montrer comment nous pourrions déprécier certaines données. Reprenons cet exemple :

    ```
    Omit debug logs (knowing they can be turned on if there is an issue) (saves 5%)
    ```

    #### Méthode 1 : [UI des logs](/docs/logs/ui-data/drop-data-drop-filter-rules)

    * Identifiez les logs qui nous intéressent à l’aide d’un filtre dans l’interface utilisateur des logs : `level: DEBUG`.
    * Assurez-vous qu&apos;il trouve les logs que nous voulons supprimer.
    * Vérifiez quelques syntaxes alternatives telles que `level:debug` et `log_level:Debug`. Ces variations sont courantes.
    * Sous <DNT>**Manage data**</DNT>, cliquez sur <DNT>**Drop filters**</DNT>, puis créez et activez un filtre nommé « Supprimer les logs de débogage ».
    * Vérifiez que la règle fonctionne.

    #### Méthode 2 : [Notre API NerdGraph](/docs/data-apis/manage-data/drop-data-using-nerdgraph/)

    * Créez la requête NRQL pertinente :
      ```sql
      SELECT count(*) FROM Log WHERE `level` = 'DEBUG'
      ```
    * Assurez-vous qu&apos;il trouve les logs que vous souhaitez supprimer.
    * Vérifiez les variations sur le nom et la valeur de l&apos;attribut (`Debug` vs `DEBUG`).
    * Exécutez l’instruction NerdGraph suivante et assurez-vous qu’elle fonctionne :

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_DATA
                nrql: "SELECT * FROM Log WHERE `level` = 'DEBUG'"
                description: "Drops DEBUG logs.  Disable if needed for troubleshooting."
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser id="process-samples" title="Échantillons de processus">
    Implémentons la recommandation : `Drop process sample data in DEV environments`.

    * Créez la requête pertinente :

      ```sql
      SELECT * FROM ProcessSample WHERE `env` = 'DEV'
      ```

    * Assurez-vous qu’il trouve les échantillons de processus que nous voulons supprimer.

    * Recherchez d’autres variantes de `env` telles que `ENV` et `Environment`.

    * Vérifiez différents types de `DEV` tels que `Dev` et `Development`.

    * Utilisez notre API NerdGraph pour exécuter l’instruction suivante et vous assurer qu’elle fonctionne :

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM ProcessSample WHERE `env` = 'DEV'"
                  description: "Drops ProcessSample from development environments"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser id="cloud-metrics" title="Métriques du cloud">
    Vous pouvez souvent réduire votre consommation de données en réduisant les données avec une couverture redondante. Par exemple : dans un environnement où l&apos;intégration AWS RDS est en cours d&apos;exécution ainsi que l&apos;une des intégrations New Relic sur l&apos;hôte qui monitore la base de données SQL telle que `nri-mysql` ou `nri-postgresql`, vous pourrez peut-être ignorer certaines métriques qui se chevauchent.

    Par exemple, vous pouvez exécuter une requête comme celle-ci :

    ```sql
    FROM Metric select count(*) where metricName like 'aws.rds%' facet metricName limit max
    ```

    Cela affichera toutes les valeurs `metricName` correspondant au modèle.

    Vous pouvez voir à partir des résultats qu&apos;il existe un volume élevé de métriques du modèle `aws.rds.cpu%`. Vous pouvez les abandonner car vous avez d&apos;autres instruments pour ceux-là :

    * Créez la requête pertinente :

      ```sql
      FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago
      ```

    * Assurez-vous qu&apos;il trouve les échantillons de processus que vous souhaitez supprimer.

    * Utilisez l&apos;API NerdGraph pour exécuter l&apos;instruction suivante et assurez-vous qu&apos;elle fonctionne :

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago"
                  description: "Drops rds cpu related metrics"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser id="drop-specific-attributes" title="Supprimer un attribut spécifique">
    Un aspect important des règles de suppression est que vous pouvez configurer une règle qui supprime un attribut spécifique tout en préservant l’intégrité du reste des données. Utilisez ceci pour supprimer des données privées de NRDB ou pour supprimer des attributs excessivement volumineux, tels que des traces d&apos;appels ou de gros morceaux de JSON dans des enregistrements log excessivement volumineux.

    Pour définir ces règles de suppression, modifiez le champ `action` en `DROP_ATTRIBUTES` au lieu de `DROP_DATA`.

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_ATTRIBUTES
                nrql: "SELECT stack_trace, json_data FROM Log where appName='myApp'"
                description: "Drops large fields from logs for myApp"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser id="drop-random-sample-of-events" title="Déposer un échantillon aléatoire de l'événement">
    <Callout variant="caution">
      Utilisez cette approche avec précaution et uniquement dans les situations où il n’existe pas d’autres options, car elle peut modifier les conclusions tirées de vos données. Cependant, pour les événements avec un échantillon de grande taille, vous pouvez vous contenter d&apos;une partie seulement de vos données, à condition de bien comprendre les conséquences.
    </Callout>

    Dans cet exemple, vous pouvez tirer parti de la distribution relative de certains identifiants de trace pour approximer l&apos;échantillonnage aléatoire. Vous pouvez utiliser l&apos;opérateur `rlike` pour vérifier les valeurs principales de l&apos;attribut `trace.id` d&apos;un span. L&apos;exemple suivant pourrait supprimer environ 25 % des portées :

    ```sql
    SELECT * FROM Span WHERE trace.id rlike r'.*[0-3]' and appName = 'myApp'
    ```

    Les expressions utiles incluent :

    * `r'.*0'` environ 6,25 %

    * `r'.*[0-1]'` environ 12,5 %

    * `r'.*[0-2]'` environ 18,75 %

    * `r'.*[0-3]'` environ 25,0 %

      Après avoir épuisé les chiffres, vous pouvez utiliser des lettres, par exemple :

    * `r'.*[a0-9]'` environ 68,75 %

    * `r'.*[a-b0-9]'` environ 75,0 %

      Voici un exemple de mutation complète :

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM Span WHERE trace.id rlike r'.*[0-3]' and appName = 'myApp'"
                  description: "Drops approximately 25% of spans for myApp"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```

      <Callout variant="tip">
        Étant donné que les `trace.id`sont des nombres hexadécimaux, chaque caractère de `trace.id` est une valeur de `0123456789abcdef`. Chaque caractère que vous ajoutez au modèle `RLIKE` correspondra à 1/16 supplémentaire des lignes de l&apos;événement span, en supposant que les caractères finaux aient une distribution uniforme. Si vous ajoutez des lettres au-delà de F qui ne sont pas utilisées en hexadécimal, les chiffres ajoutés n&apos;affecteront pas le pourcentage correspondant.
      </Callout>
  </Collapser>

  <Collapser id="other-events-and-metrics" title="Autres événements et métriques">
    Les exemples précédents devraient vous montrer tout ce que vous devez savoir pour utiliser ces techniques sur tout autre événement ou métrique dans NRDB. N&apos;oubliez pas : si vous pouvez le demander, vous pouvez le supprimer. Contactez-nous si vous avez des questions sur la manière précise de structurer une requête pour une règle de suppression.
  </Collapser>
</CollapserGroup>

### Quelle est la prochaine étape ? [#whats-next]

L&apos;étape d&apos;optimisation terminée, vous avez terminé le tutoriel d&apos;optimisation des données télémétriques ! Si votre compte dispose d&apos;un responsable de compte, vous pouvez le contacter pour obtenir des conseils supplémentaires sur la marche à suivre et pour vous assurer que vous êtes optimisé.

Si vous êtes nouveau sur la plateforme New Relic, vous pouvez consulter notre autre série de tutoriels pour en savoir plus sur l&apos;optimisation de votre système à l&apos;aide de notre plateforme :

* [Répondre aux pannes de service](/docs/tutorial-errors/respond-outages/)
* [Gestion de grandes quantités de logs](/docs/tutorial-large-logs/get-started-managing-large-logs/)
* [Se préparer à la demande de pointe](/docs/tutorial-peak-demand/get-started/)
* [Créer et gérer des alertes](/docs/tutorial-create-alerts/create-new-relic-alerts/)