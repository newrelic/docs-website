---
title: Alertes bonnes pratiques
tags:
  - New Relic solutions
  - Best practices guides
  - Alerts
metaDescription: 'Best practices for deciding what to alert on, when to trigger notifications, and who receives them.'
freshnessValidatedDate: never
translationType: machine
---

Grâce aux alertes, vous pouvez commencer à détecter les problèmes avant qu&apos;ils ne deviennent critiques. En utilisant NRQL, notre langage de requête New Relic, vous pouvez [créer et personnaliser votre condition d&apos;alerte](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/your-first-nrql-condition/) qui se concentre sur ce qui vous préoccupe le plus. Utilisez <InlinePopover type="alerts" />pour être informé des comportements inhabituels dans vos données, acheminer les notifications aux personnes qui doivent les voir et prendre des décisions efficaces tout en connaissant la cause première de votre problème.

Améliorez votre couverture d&apos;alerte en utilisant nos recommandations sur la meilleure façon d&apos;utiliser la réponse aux alertes, la maintenance, la qualité et les paramètres avancés. Consultez notre guide [de gestion de la qualité des alertes](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide) pour savoir comment mesurer et améliorer la qualité de vos alertes.

Vous pouvez suivre ces actions recommandées pour améliorer et tirer le meilleur parti de votre configuration d’alerte.

<Callout variant="tip">
  Avez-vous déjà créé votre première alerte ? Sinon, consultez notre [série de tutoriels](/docs/tutorial-create-alerts/create-new-relic-alerts/) pour connaître toutes les étapes dont vous avez besoin pour commencer.
</Callout>

## Améliorer la réponse aux alertes [#alert-response]

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Que dois-je faire
      </th>

      <th>
        Avantage
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Donnez un nom explicatif à l&apos;alerte
      </td>

      <td>
        La description et la balise doivent vous donner des alertes autodescriptives pour savoir quel service est erroné, quel environnement est impliqué, quelle équipe en est propriétaire et si cela a un impact sur l&apos;utilisateur final. Cela vous aide à répondre plus rapidement et à décider quoi faire.
      </td>
    </tr>

    <tr>
      <td>
        Ajoutez une balise à votre état d&apos;alerte
      </td>

      <td>
        Vos problèmes et incidents ont ces tags dans leurs métadonnées. Utilisez-les pour effectuer des filtres flexibles dans le workflow ou ajoutez-les à vos frais notification .

        Les problèmes ont 3 sources de balises :

        * La [balise](/docs/new-relic-solutions/new-relic-one/core-concepts/use-tags-help-organize-find-your-data/#add-via-ui-api) définie sur la condition d&apos;alerte.
        * Les valeurs actuelles de la [clause`facet/where` ](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/#syntax)de la condition d&apos;alerte.
        * L&apos;étiquette de l&apos;entité en infraction si les résultats des alertes sont limités à une entité unique. Si l&apos; incident n&apos;est pas limité à l&apos;entité, la balise d&apos;entité ne sera pas transférée.

        Ces événements sont stockés dans NRDB. Ne vous inquiétez pas de la consommation de tables nr\* car elles ne sont pas comptabilisées comme ingérées.
      </td>
    </tr>

    <tr>
      <td>
        Catégoriser la condition d&apos;alerte
      </td>

      <td>
        Dans votre organisation, définissez des catégories d&apos;alertes, des attentes en matière de gestion de leurs notifications et une destination unique. Par exemple, proactif pour Slack pour notifier avant que l&apos;incident ne se produise ; réactif pour PagerDuty pour détecter et notifier un incident en cours ; ou informatif pour Jira.
      </td>
    </tr>

    <tr>
      <td>
        Définir la méthode de communication et d&apos;escalade
      </td>

      <td>
        Décider des moyens de [notifications](/docs/alerts-applied-intelligence/notifications/notification-integrations/). Certaines méthodes de notifications sont : [e-mail](/docs/alerts-applied-intelligence/notifications/notification-integrations/#email), [Slack](/docs/alerts-applied-intelligence/notifications/notification-integrations/#slack), [PagerDuty](/docs/alerts-applied-intelligence/notifications/notification-integrations/#pagerduty) ou [Jira](/docs/alerts-applied-intelligence/notifications/notification-integrations/#jira).
      </td>
    </tr>

    <tr>
      <td>
        Ajoutez une équipe responsable
      </td>

      <td>
        Cette équipe est en charge de gérer la première notification.
      </td>
    </tr>

    <tr>
      <td>
        Ajoutez une [URLrunbook ](/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/provide-runbook-instructions-alert-activity/)à chaque condition d&apos;alerte
      </td>

      <td>
        Le runbook doit décrire les étapes de correction à suivre et les personnes à impliquer ou à contacter.
      </td>
    </tr>

    <tr>
      <td>
        Utiliser [des enrichissements](/docs/alerts-applied-intelligence/applied-intelligence/incident-workflows/incident-workflows/#enrichments)
      </td>

      <td>
        Priorisez et triez vos notifications d&apos;alerte plus rapidement en fournissant des mesures supplémentaires spécifiques au problème.
      </td>
    </tr>
  </tbody>
</table>

## Améliorer la maintenance des alertes [#alert-maintenance]

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Que dois-je faire
      </th>

      <th>
        Avantage
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Organisez vos [politiques](/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/create-edit-or-find-alert-policy/)
      </td>

      <td>
        Nous vous recommandons de créer une politique pour chaque destination ou public distinct qui doit recevoir une notification. Envisagez de regrouper par entité, service ou technologie pour correspondre à l’orientation de vos équipes respectives.
      </td>
    </tr>

    <tr>
      <td>
        Ajoutez une équipe propriétaire à chaque condition d&apos;alerte
      </td>

      <td>
        L&apos;équipe propriétaire garantit que l&apos;alerte reste pertinente. Ils approuvent toute modification de la condition.
      </td>
    </tr>

    <tr>
      <td>
        Planifier un examen périodique de l&apos;état d&apos;alerte
      </td>

      <td>
        Utilisez la [page d’aperçu des alertes](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/alerts-ai-overview-page/) pour vérifier l’incident créé et décider de l’action à effectuer. Nous vous recommandons de tagger l&apos;état avec la date de la dernière révision, ce qui vous permettra d&apos;identifier les alertes obsolètes.
      </td>
    </tr>

    <tr>
      <td>
        Automatisez la création de vos alertes avec [Terraform](https://newrelic.com/blog/how-to-relic/observability-as-code-new-relic-terraform-provider)
      </td>

      <td>
        Vous éviterez les modifications non documentées et clarifierez la traçabilité.
      </td>
    </tr>
  </tbody>
</table>

## Améliorer la qualité des alertes [#alert-quality]

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Que dois-je faire
      </th>

      <th>
        Avantages
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Avoir des SLI et des SLO dans un [rapport](/docs/service-level-management/consume-slm/)
      </td>

      <td>
        Les violations [des SLI et des SLO](/docs/service-level-management/intro-slm/#what-sli-slo) ne sont pas toujours des incidents et ne nécessitent pas d&apos;alerte, sauf si vous avez documenté des mesures pour les empêcher. SLI/SLO <InlinePopover type="dashboards" />peut mettre en évidence le domaine sur lequel l&apos;équipe doit se concentrer pour apporter des améliorations plutôt que de répondre à un événement.
      </td>
    </tr>

    <tr>
      <td>
        [Désactiver les alertes](/docs/alerts-applied-intelligence/new-relic-alerts/alert-notifications/muting-rules-suppress-notifications/) pendant la maintenance
      </td>

      <td>
        Cela supprimera les notifications bruyantes.
      </td>
    </tr>

    <tr>
      <td>
        Adopter une approche systémique lors de la définition des alertes pour un service
      </td>

      <td>
        Vous aide à vous assurer de couvrir l&apos;intégralité de votre stack de manière cohérente. Vous pouvez organiser vos alertes par technologie, équipes impliquées, etc.
      </td>
    </tr>

    <tr>
      <td>
        Examiner [les décisions suggérées](/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions/#suggested-decisions)
      </td>

      <td>
        Chaque jour, nous analysons vos données d&apos;alerte et fournissons des suggestions de décisions ainsi que des commentaires sur les décisions existantes. Cela améliorera la réduction du bruit.
      </td>
    </tr>

    <tr>
      <td>
        Identifier et régler les alertes de bagottement
      </td>

      <td>
        Ces alertes indiquent une mauvaise configuration de l&apos;état d&apos;alerte qui crée du bruit. Ils peuvent encore indiquer un problème de longue date dans votre système, mais il ne s’agit pas d’un incident.
      </td>
    </tr>

    <tr>
      <td>
        Augmentez le seuil ou la durée de la fenêtre et utilisez l&apos;agrégation de fenêtres glissantes
      </td>

      <td>
        Les alertes qui se résolvent d&apos;elles-mêmes avant que votre équipe ne puisse prendre des mesures peuvent encombrer votre boîte de réception et créer du bruit. Utilisez un [tableau de bord](/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/) si vous souhaitez voir les pics de courte durée et lisser les pics temporaires.

        Vous comprendrez l’impact que cela aura sur [la clôture de votre incident](/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/how-alert-condition-incidents-are-closed/).
      </td>
    </tr>

    <tr>
      <td>
        Utiliser [les décisions](/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions/)
      </td>

      <td>
        Tirez parti de votre balise personnalisée et de vos métadonnées dans les décisions.

        Les incidents connexes seront regroupés dans un seul [numéro](/docs/alerts-applied-intelligence/overview/#concepts-terms) complet.

        Gardez les [décisions par défaut](/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions/#global-decisions) activées lorsque vous démarrez. Dans quelques semaines, vous serez en mesure d’évaluer l’efficacité de ces décisions.
      </td>
    </tr>

    <tr>
      <td>
        Si vous utilisez [des décisions](/docs/alerts-applied-intelligence/applied-intelligence/incident-intelligence/change-applied-intelligence-correlation-logic-decisions/), augmentez le délai de grâce de notification
      </td>

      <td>
        Vous obtiendrez davantage d’incidents liés à vos problèmes. Vous obtiendrez un contexte plus riche et plus exploitable dès la première notification. Plus le délai de grâce est long, plus la notification est tardive.
      </td>
    </tr>

    <tr>
      <td>
        Consultez régulièrement le [flux des problèmes](/docs/alerts-applied-intelligence/applied-intelligence/anomaly-detection/anomaly-detection-applied-intelligence/#issue-feed)
      </td>

      <td>
        Faites défiler la colonne <DNT>**Notified**</DNT> pour vous assurer que tous les problèmes sont acheminés vers au moins une destination. Si aucun routage n&apos;est nécessaire, envisagez de supprimer la condition car il peut s&apos;agir de bruit.
      </td>
    </tr>
  </tbody>
</table>

## création de conditions d&apos;alerte et paramètres avancés [#alert-condition-creation]

Si vous êtes nouveau dans le domaine des alertes ou si vous souhaitez des suggestions pour optimiser votre couverture d&apos;alerte, prêtez attention à ces recommandations :

* [Recevez des alertes recommandées par technologie](https://newrelic.com/instant-observability)
* [Laissez New Relic trouver vos lacunes de couverture](https://one.newrelic.com/nrai/detection-gaps/home)
* [Obtenez des recommandations sur l&apos;état](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/condition-recommendations/)

### Comprendre le signal [#understand-signal]

Chaque condition d’alerte génère un signal ou plusieurs signaux si la condition contient une clause de facette. Chaque valeur de facette possible créera un signal distinct.

Vous pouvez interroger tous les signaux dans [`NrAiSignal`](/attribute-dictionary/?event=NrAiSignal). Cela vous permet d&apos;obtenir des détails sur la valeur observée, le nombre de points de données pris en compte et, dans le cas de conditions d&apos;anomalie, la valeur attendue et l&apos;écart type. Il fournit également des informations sur le delta de temps entre l&apos;heure New Relic et l&apos;heure de vos données brutes (si vos données sont des horodatages), ce qui peut vous aider à trouver le paramètre de délai le plus précis lors de la création de vos conditions.

### Maintenir la santé de l&apos;entité [#maintaining-entity-health]

Nous utilisons des signaux pour déduire la santé et la couverture d’alerte d’une entité. Si les résultats d&apos;une condition d&apos;alerte contiennent des données provenant d&apos;une seule entité, New Relic les liera à la santé de cette entité, et ces événements s&apos;afficheront en contexte dans l&apos;interface utilisateur de New Relic.

Il est recommandé, dans la plupart des conditions, de maintenir l’existence d’un signal. L&apos;absence de signal peut entraîner l&apos;affichage par New Relic d&apos;un état de santé gris (inconnu) pour certaines entités, ainsi que l&apos;ajout de ces entités à la liste des entités non couvertes.

Si la clause `where` de votre condition exclut toutes les données, il ne restera plus de données. Il s&apos;agit d&apos;une [perte de signal](https://forum.newrelic.com/s/hubtopic/aAX8W0000008bEyWAI/relic-solution-how-can-i-figure-out-when-to-use-gap-filling-and-loss-of-signal) pour New Relic et la condition d&apos;alerte NE PEUT être évaluée par rapport à AUCUN seuil. Cela signifie que le résultat de la requête NRQL ne contient pas de données, mais cela ne signifie pas que New Relic ne reçoit pas de données. Si vous souhaitez recevoir une notification, vous devez ajouter un seuil de perte de signal.

Utilisez les filtres les plus génériques dans votre section `where` et les plus spécifiques dans votre section `select` . Utilisez la fonction de filtre pour mesurer avec précision ce qui vous intéresse. Par exemple:

```sql
Select filter(count(*), where ErrorCode=123) from Transaction where AppName='Application1' and Environment='Production'
```

### Délai d&apos;alerte ou durée de la minuterie [#alert-delay]

Essayez d&apos;ajuster le [délai/temps](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/#delay-timer) avec le comportement de vos données. Un court délai peut déclencher de fausses alertes en raison de données incomplètes et un délai important peut augmenter le temps pendant lequel vous êtes averti. New Relic ne sait pas quelle quantité de données attendre ni à quel moment ces données pourraient atteindre un point de terminaison de New Relic. En fonction de l&apos;expéditeur log et configuration, les données log peuvent être regroupées et entraîner un retard important pour les logs à faible volume.

### Définissez votre seuil de condition [#condition-thresholds]

Définissez des niveaux [de seuil](/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/advanced-techniques/set-thresholds-alert-condition/) significatifs pour optimiser les alertes pour votre entreprise. Voici quelques lignes directrices suggérées :

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Action
      </th>

      <th>
        Recommandations
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Définir des niveaux de seuil
      </td>

      <td>
        Évitez de régler le seuil trop bas. Par exemple, si vous définissez un seuil de condition CPU de 75 % pendant 5 minutes sur vos serveurs de production et que ce niveau est régulièrement dépassé, cela augmentera la probabilité d&apos;alertes non exploitables ou de faux positifs.
      </td>
    </tr>

    <tr>
      <td>
        Expérimenter avec les paramètres
      </td>

      <td>
        Vous n’avez pas besoin de modifier les fichiers ou de redémarrer le logiciel, alors n’hésitez pas à apporter des modifications rapides à vos niveaux de seuil et à les ajuster si nécessaire.
      </td>
    </tr>

    <tr>
      <td>
        Ajuster les paramètres
      </td>

      <td>
        Ajustez vos conditions au fil du temps.

        * Resserrez votre seuil tant que vous utilisez New Relic pour suivre le rythme de vos performances améliorées.
        * Si vous déployez quelque chose dont vous savez qu&apos;il aura un impact négatif sur vos performances pendant un certain temps, desserrez votre seuil pour en tenir compte.
      </td>
    </tr>

    <tr>
      <td>
        Désactiver les paramètres
      </td>

      <td>
        Vous pouvez <DNT>**disable any condition**</DNT> dans une politique, si nécessaire. Cela est utile, par exemple, si vous souhaitez continuer à utiliser d’autres conditions dans la politique pendant que vous expérimentez d’autres métriques ou seuils.
      </td>
    </tr>
  </tbody>
</table>

L&apos; [indicateur d&apos;état de santé](/docs/new-relic-solutions/get-started/glossary/#health-status) à code couleur dans l&apos;interface utilisateur de New Relic change à mesure que le seuil d&apos;alerte augmente ou revient à la normale. Cela vous permet de monitorer une situation via l&apos;interface utilisateur avant d&apos;avoir un seuil critique, sans avoir besoin de recevoir de notification spécifique à ce sujet. Il existe deux seuils incident : critique (rouge) et avertissement (jaune). Définissez ces seuils avec différents critères, en gardant à l&apos;esprit les suggestions mentionnées ci-dessus.

### Assurez l&apos;exécution de vos tâches quotidiennes par lots [#batch-jobs]

Vous pouvez configurer une condition d’alerte pour recevoir une notification si vos tâches par lots échouent.

En supposant que vous envoyez un événement à New Relic dans le cadre de votre tâche par lots, vous pouvez configurer une condition d&apos;alerte pour vous avertir si vos tâches par lots ne parviennent pas à s&apos;exécuter.

1. Configurer une requête de comptage simple sur l&apos;événement.

   ```sql
   SELECT count(*) FROM MyBatchEvent
   ```

2. Définissez la perte de signal pour ouvrir un nouvel incident après 24 heures et 30 minutes. Vous pouvez ajuster cela, mais c&apos;est une bonne idée d&apos;autoriser un travail par lots à exécution tardive.

3. Assurez-vous d&apos;utiliser la méthode d&apos;agrégation de streaming [événement Timer](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/choose-your-aggregation-method/#event-timer-detail) . Étant donné que vous n&apos;obtiendrez qu&apos;un seul point de données toutes les 24 heures, vous pouvez régler la minuterie sur son réglage le plus bas, 5 secondes.

## Utiliser des valeurs non nulles lorsqu&apos;il n&apos;y a pas de signal

Par défaut, les lacunes dans les signaux de données sont comblées par des valeurs nulles. Dans les cas où vous devez pouvoir créer des conditions basées sur ces lacunes de données, vous pouvez combler les lacunes avec une valeur personnalisée ou la dernière valeur connue. Vous pouvez configurer ce paramètre par condition dans l&apos;interface utilisateur ou [configurer des valeurs de remplissage des espaces via NerdGraph](/docs/apis/nerdgraph/examples/nerdgraph-api-loss-signal-gap-filling/#loss-of-signal).

<Callout variant="important">
  La configuration du remplissage des espaces n&apos;empêche pas le déclenchement de la « Perte de signal ».
</Callout>

## Définissez vos préférences de création de problèmes [#issue-creation]

Décidez quand vous recevez une notification de problème afin de pouvoir répondre aux problèmes lorsqu&apos;ils surviennent.

Si vous n&apos;êtes pas familier avec les alertes, découvrez-en plus sur vos [options de préférences de problème](/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/specify-when-alerts-create-incidents/).

Le paramètre de préférence de problème par défaut combine toutes les conditions d&apos;une politique en un seul problème. Modifiez votre paramètre de préférence de problème par défaut pour augmenter ou diminuer le nombre de problèmes et la notification de problème que vous recevez.

Chaque équipe au sein de votre organisation peut avoir des besoins différents. Posez à votre équipe deux questions importantes pour déterminer vos préférences en matière de problèmes :

* Voulons-nous être avertis chaque fois que quelque chose ne va pas ?
* Souhaitons-nous regrouper toutes les notifications similaires et être avertis une seule fois ?

Lorsqu&apos;une politique et ses conditions ont une portée plus large, comme la gestion de la performance de plusieurs entités, augmentez le nombre de problèmes que vous recevez. Vous aurez peut-être besoin de plus de notifications car deux problèmes ne peuvent pas nécessairement être liés l&apos;un à l&apos;autre.

Lorsqu&apos;une politique et ses conditions ont une portée ciblée, comme la gestion des performances d&apos;une entité, optez pour la préférence de problème par défaut. Vous avez besoin de moins de notifications lorsque 2 problèmes sont liés l’un à l’autre ou lorsque l’équipe est déjà notifiée et corrige un problème existant.

## Quelle est la prochaine étape ?

Pour en savoir plus sur l’utilisation des alertes :

* Découvrez [les concepts et les termes d&apos;alerte](/docs/alerts-applied-intelligence/overview/#concepts-terms).
* En savoir plus sur l&apos;[API](/docs/alerts/rest-api-alerts/new-relic-alerts-rest-api/rest-api-calls-new-relic-alerts).
* Lisez les détails techniques sur [les limites min/max et les règles](/docs/alerts/new-relic-alerts/getting-started/minimum-maximum-values).
* En savoir plus sur les [cas dans lesquels vous pourriez avoir besoin d&apos;utiliser les paramètres de perte de signal et de remplissage d&apos;espace](https://discuss.newrelic.com/t/relic-solution-how-can-i-figure-out-when-to-use-gap-filling-and-loss-of-signal/120401).