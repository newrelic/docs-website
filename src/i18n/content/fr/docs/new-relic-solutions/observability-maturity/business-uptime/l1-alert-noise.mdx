---
title: Niveau 1 - Règle de score d'alerte sonore
tags:
  - Observability maturity
  - Intelligent observability
  - Instrumentation
  - Implementation guide
metaDescription: Reduce alert fatigue by identifying noisy alert policies that generate excessive incidents
freshnessValidatedDate: never
translationType: machine
---

Un bruit d&apos;alerte se produit lorsque le système monitoring génère trop d&apos;alertes, ce qui rend difficile l&apos;identification des problèmes réels. Cette règle de dashboard vous aide à identifier les politiques qui créent des alertes excessives afin que vous puissiez vous concentrer sur les problèmes réels.

## À propos de cette règle de dashboard

Cette règle de bruit d&apos;alerte fait partie du niveau 1 (réactif) du [modèle de maturité des temps de disponibilité de l&apos;entreprise](/docs/new-relic-solutions/observability-maturity/business-uptime/introduction). Il vous aide à identifier les règles d&apos;alerte qui génèrent trop d&apos;incidents, ce qui peut submerger votre équipe et masquer des problèmes critiques.

**Pourquoi cela est important :** la fatigue due aux alertes réduit le temps de réponse et peut amener les équipes à manquer de véritables problèmes critiques. Les équipes qui reçoivent trop d’alertes deviennent souvent désensibilisées et peuvent ignorer ou retarder les réponses aux problèmes légitimes.

## Comment fonctionne cette règle

Cette règle évalue les incidents sur une période de 7 jours pour identifier les règles d&apos;alerte qui génèrent plus de 14 incidents pendant cette période. Ce seuil représente environ 2 incidents par jour, que la plupart des équipes peuvent gérer efficacement sans ressentir de fatigue due aux alertes auxiliaires.

## Comprendre votre score

* **Pass (Vert) :** Aucune règle d&apos;alerte n&apos;a généré plus de 14 incidents au cours des 7 derniers jours
* **Échec (rouge) :** une ou plusieurs politiques ont dépassé le seuil de 14incident
* **Cible :** Toutes les règles d&apos;alerte doivent générer des volumes incident gérables auxquels votre équipe peut répondre efficacement

**Ce que cela signifie pour votre équipe :**

* **Score de réussite :** vos règles d&apos;alerte sont bien réglées et génèrent des alertes exploitables
* **Score d&apos;échec :** certaines politiques peuvent être trop sensibles ou nécessiter un ajustement pour réduire les faux positifs

## Comment réduire le bruit des alertes

Si votre score indique un bruit d&apos;alerte excessif, suivez ces étapes pour optimiser votre règle d&apos;alerte :

### 1. Identifier les politiques problématiques

1. **Examinez les politiques défaillantes :** examinez quelles politiques spécifiques ont déclenché plus de 14 incidents.
2. **Analyser les schémas incident :** vérifier si les incidents se produisent à intervalles réguliers ou dans des conditions spécifiques
3. **Évaluer la validité incident :** déterminer si l&apos;incident représente de véritables problèmes qui nécessitent une attention particulière

### 2. Optimiser la condition d&apos;alerte

**Ajuster le seuil :**

* Augmentez les valeurs de seuil pour réduire la sensibilité si les alertes se déclenchent lors de fluctuations normales
* Utiliser un seuil basé sur un pourcentage au lieu de valeurs absolues lorsque cela est approprié
* Tenez compte de la plage de fonctionnement normale de votre système

**Modifier les fenêtres d’évaluation :**

* Prolongez la fenêtre de temps pour éviter les alertes sur les pics temporaires
* Utiliser des périodes d’évaluation plus longues pour les métriques qui fluctuent naturellement

**Mettre en œuvre une détection plus intelligente :**

* Envisagez d&apos;utiliser la détection d&apos;anomalies au lieu du seuil statique
* Utiliser des comparaisons de base de référence pour les métriques avec des modèles prévisibles

### 3. consolider et rationaliser les alertes

* **Conditions liées au groupe :** combinez plusieurs conditions d&apos;alerte liées en une seule politique
* **Utiliser la corrélation des alertes :** définissez des règles pour regrouper les incidents liés et réduire les notifications en double
* **Donner la priorité à la critique des alertes :** s&apos;assurer que les alertes hautement prioritaires sont clairement distinguées des alertes informatives

### 4. Validez vos modifications

Après avoir effectué les ajustements :

1. Monitorer le volume incident pour les 7 prochains jours
2. Vérifiez que des problèmes légitimes sont toujours détectés
3. Confirmez que votre équipe peut répondre efficacement aux alertes restantes

## Mesurer l&apos;amélioration

Suivez ces mesures pour vérifier que vos efforts d’optimisation des alertes fonctionnent :

* **Volume incident réduit :** Moins d&apos;incidents totaux générés par votre règle d&apos;alerte
* **Temps de réponse améliorés :** les équipes peuvent réagir plus rapidement lorsque les alertes sont plus ciblées
* **Confiance accrue dans les alertes :** les membres de l&apos;équipe font confiance aux alertes et réagissent de manière appropriée
* **Moins de faux positifs :** incidents qui nécessitent une véritable action plutôt qu&apos;un licenciement

## Scénarios et solutions courants

**Alertes à haute fréquence et à faible impact :**

* **Problème :** des alertes se déclenchent sur des fluctuations métriques mineures
* **Solution :** augmenter le seuil ou utiliser des fenêtres d’évaluation plus longues

**Alertes en cascade :**

* **Problème :** un problème déclenche plusieurs alertes liées
* **Solution :** mettre en œuvre une corrélation d’alertes ou créer des alertes basées sur la dépendance

**Modèles saisonniers ou prévisibles :**

* **Problème :** les alertes se déclenchent pendant les périodes de pointe connues
* **Solution :** Utiliser une base de référence dynamique ou une condition d&apos;alerte temporelle

## Considérations importantes

* **Équilibrer la sensibilité avec le bruit :** s&apos;assurer que la réduction du bruit n&apos;élimine pas la détection de problèmes réels
* **Révision régulière :** la règle d&apos;alerte doit être revue et ajustée à mesure que votre système évolue
* **Commentaires de l&apos;équipe :** impliquez votre équipe d&apos;intervention dans l&apos;évaluation de l&apos;efficacité des alertes
* **Seuil personnalisé :** Le seuil de 14incident peut nécessiter un ajustement en fonction de la taille de votre équipe et de votre capacité de réponse

## Prochaines étapes

1. **Action immédiate :** traiter toutes les politiques qui ne respectent pas actuellement cette règle
2. **monitoring continue :** Révisez cette règle de dashboard chaque semaine pour détecter de nouvelles sources de bruit d&apos;alerte
3. **Passer au niveau 2 :** une fois le bruit d&apos;alerte sous contrôle, concentrez-vous sur [les pratiques monitoring proactive](/docs/new-relic-solutions/observability-maturity/business-uptime/introduction#level-2-proactive-approach)

Pour obtenir des conseils supplémentaires sur l’optimisation des alertes, consultez notre [guide de mise en œuvre de la gestion de la qualité des alertes](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/aqm-implementation-guide/).