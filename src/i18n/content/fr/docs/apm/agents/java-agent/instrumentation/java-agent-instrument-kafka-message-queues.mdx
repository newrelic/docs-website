---
title: 'Agent Java: instrumenter les message de file d''attente Kafka'
tags:
  - Agents
  - Java agent
  - Instrumentation
metaDescription: 'New Relic for Java includes built-in Kafka monitoring, as well as advanced event and distributed tracing data collection.'
freshnessValidatedDate: never
translationType: machine
---

L&apos;agent Java New Relic collecte automatiquement les données de la bibliothèque de clients Java de [Kafka](https://kafka.apache.org/documentation/). Étant donné que Kafka est un système de messagerie hautes performances qui génère beaucoup de données, vous pouvez personnaliser l&apos;agent en fonction du débit et des cas d&apos;utilisation spécifiques de votre application.

Ce document explique comment collecter et afficher ces types de données Kafka :

* [Métriques Kafka](#view-kafka-metrics)
* [L&apos;événement Kafka](#collect-kafka-events)
* [Transactions Kafka Streams](#collect-kafka-streams-transactions)
* [Les traces de Kafka distribuées](#collect-kafka-distributed-traces)

<Callout variant="tip">
  Nous avons également une intégration Kafka. Pour plus de détails à ce sujet, voir [Intégration monitoring Kafka](/docs/integrations/host-integrations/host-integrations-list/kafka-monitoring-integration).
</Callout>

## Exigences [#requirements]

L&apos;instrumentation des clients Kafka est disponible dans les versions d&apos;agent Java 4.12.0 ou supérieures. instrumentation des flux Kafka est disponible dans les versions 8.1.0 de l&apos;agent Java ou supérieur. Pour voir toutes les bibliothèques Kafka prises en charge, consultez la [page de compatibilité et d&apos;exigencesJava ](/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent). Notez que Kafka Streams s&apos;exécute sur les clients Kafka, donc toute l&apos;instrumentation qui s&apos;applique aux clients Kafka s&apos;applique également à Streams.

## Afficher les métriques Kafka

Après [l&apos;installation](/docs/agents/java-agent/installation/install-java-agent), l&apos;agent Java signale automatiquement des métriques Kafka riches avec des informations sur les taux de messagerie, la latence, le décalage, etc. L&apos;agent collecte toutes [les métriques Kafka consommateur et producteur](https://kafka.apache.org/documentation/#monitoring) (mais pas les métriques connect ou stream).

Pour visualiser ces métriques, créez un dashboard personnalisé :

1. Accédez à l&apos;[explorateur métriqueNew Relic ](/docs/insights/use-insights-ui/explore-data/metric-explorer-search-chart-metrics-sent-new-relic-agents).

2. Utilisez l&apos;explorateur de métriques pour localiser vos métriques. Voici quelques dossiers dans lesquels vous pouvez trouver des métriques :

   * Métriques Kafka :

     ```
     MessageBroker/Kafka/Internal/KafkaMetricName
     ```

     Par exemple, la métrique `request-rate` :

     ```
     MessageBroker/Kafka/Internal/consumer-metrics/request-rate
     ```

   * Flux Kafka :

     ```
     Kafka/Streams/KafkaStreamsMetricName
     ```

     Par exemple, la métrique `poll-latency-avg` :

     ```
     Kafka/Streams/stream-thread-metrics/poll-latency-avg
     ```

   * Kafka Connect :

     ```
     Kafka/Connect/KafkaConnectMetricName
     ```

     Par exemple, la métrique `connector-count` :

     ```
     Kafka/Connect/connect-worker-metrics/connector-count
     ```

3. Ajoutez les métriques que vous souhaitez monitorer à un dashboard en cliquant sur <DNT>**Add to dashboard**</DNT>.

<Callout variant="tip">
  Pour une liste complète des métriques du consommateur, du producteur et des flux Kafka, consultez la [documentation Kafka](https://kafka.apache.org/documentation/#remote_jmx). Les métriques de ces documents sont consultables via JMX. Gardez à l’esprit que toutes les métriques mentionnées dans la documentation ne seront pas exportées dans New Relic. Cela pourrait être dû à l’une de ces raisons :

  * La métrique n&apos;est pas réellement générée par les clients Kafka ou Kafka Streams. Cela peut être dû à l&apos;utilisation d&apos;une ancienne version des clients ou de Streams ou à la façon dont vous configurez et utilisez votre bibliothèque Kafka.
  * La métrique n&apos;est pas numérique ou sa valeur est `NaN`. New Relic accepte uniquement les métriques avec une valeur numérique.
</Callout>

## Voir la collection d&apos;événements Kafka [#collect-kafka-events]

Vous pouvez configurer l&apos;agent pour collecter des données d&apos;événement au lieu des données d&apos;intervalle de temps métrique (pour la différence entre l&apos;intervalle de temps métrique et les données d&apos;événement, voir [collecte de données](/docs/using-new-relic/metrics/analyze-your-metrics/data-collection-metric-timeslice-event-data#overview)). Cela vous permet d&apos;utiliser [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) pour filtrer et facetter les métriques Kafka par défaut. Lorsque cette option est activée, l&apos;agent collecte un événement Kafka toutes les 30 secondes. Cet événement contient toutes les données de [Kafka consommateur et produit les métriques](https://kafka.apache.org/documentation/#monitoring) capturées depuis l&apos;événement précédent.

Si vous utilisez Kafka Streams, l&apos;agent génère un événement distinct qui contient toutes les données des [métriques de flux Kafka](https://kafka.apache.org/documentation/#remote_jmx) capturées depuis l&apos;événement précédent. L&apos;événement est également collecté toutes les 30 secondes.

<Callout variant="important">
  L&apos;agent enregistre jusqu&apos;à 2000 événements par [cycle de collecte](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#harvest-cycle), bien que vous puissiez modifier cette valeur avec [`max_samples_stored`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored). Les données d’événement Kafka sont incluses dans ce pool. Si vous utilisez l&apos;appel d&apos;API `recordCustomEvent()` pour envoyer [des événements personnalisés](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents) à New Relic et que vous envoyez plus de 2000 événements, l&apos;agent rejettera certains événements Kafka ou personnalisés.
</Callout>

Pour activer la collection d&apos;événements Kafka :

1. Ajoutez l&apos;élément `kafka.metrics.as_events.enabled` à votre fichier de configuration `newrelic.yml` :

   ```yml
   kafka.metrics.as_events.enabled: true
   ```

2. Redémarrez votre JVM.

3. Utilisez l&apos;[explorateur d&apos;événements](/docs/insights/use-insights-ui/explore-data/event-explorer-query-chart-your-event-data) pour afficher votre événement Kafka, situé dans le type d&apos;événement `KafkaMetrics` . Ou utilisez [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) pour requêter directement votre événement. Par exemple:

   ```sql
   SELECT average('producer-metrics.record-send-rate') FROM KafkaMetrics SINCE 30 minutes ago TIMESERIES
   ```

   Si vous interrogez les métriques Kafka Streams, utilisez le type d&apos;événement `KafkaStreamsMetrics` pour accéder aux métriques spécifiques aux flux.

<Callout variant="important">
  Gardez à l’esprit que les limitations concernant le type de métriques Kafka que vous pouvez envoyer à New Relic en tant que métriques de tranche de temps s’appliquent également à événement. Autrement dit, les mesures non numériques et NaN ne sont pas incluses comme attribut d&apos;événement.
</Callout>

## Activer les métriques du nœud Kafka [#kafka-node-metrics]

<Callout variant="important">
  L&apos;instrumentation Kafka Clients Node Metrics peut ne pas se charger pour lesutilisateurs de la bibliothèque `kafka-clients` versions 3.7.0-3.8.x et Java Agent versions 8.15.0-8.17.0.

  Pour activer Kafka Clients Node Metrics pour `kafka-clients` 3.7.0-3.8.x, veuillez mettre à niveau votre agent Java vers la version 8.18.0 ou supérieure.
</Callout>

Il existe un module d&apos;instrumentation alternatif pour les clients Kafka qui fournira plus de granularité pour les métriques Kafka. Ce module d&apos;instrumentation est disponible depuis l&apos;agent 8.6.0 et est désactivé par défaut.

Pour activer ce module d&apos;instrumentation, vous devez désactiver le module d&apos;instrumentation existant et activer le nouveau en ajoutant ce qui suit à votre fichier de configuration `newrelic.yml` :

```yml
class_transformer:
  kafka-clients-metrics:
    enabled: false
  kafka-clients-node-metrics:
    enabled: true
```

## Événement de configuration Kafka [#kafka-config]

Le module instrumentation `kafka-clients-config` enverra périodiquement un événement avec le contenu de votre configuration client Kafka. Ce module est disponible depuis l&apos;agent 8.6.0 et est désactivé par défaut.

Pour activer `kafka-clients-config` ajoutez ce qui suit à votre fichier de configuration `newrelic.yml` :

```yml
class_transformer:
  kafka-clients-config:
    enabled: true
```

## Transactions Kafka Streams [#collect-kafka-streams-transactions]

Si vous utilisez Kafka Streams, par défaut, nous n&apos;activons pas les transactions. Cela permet d&apos;éviter des frais généraux inutiles, car les applications Kafka ont tendance à avoir un débit élevé.

Contrairement aux transactions JMS, les transactions Kafka Streams ne sont pas traitées par enregistrement. Au lieu de cela, une transaction commence lorsqu&apos;un consommateur Kafka interroge les enregistrements, puis les données résultantes sont traitées.

Si vous souhaitez créer des transactions, vous devez activer un module `kafka-streams-spans` :

```yml
class_transformer:
  kafka-streams-spans:
    enabled: true
```

## Activer la transaction Kafka Connect [#collect-kafka-connect-transactions]

Si vous utilisez Kafka Connect, par défaut, nous n&apos;activons pas les transactions. Cela permet d&apos;éviter des frais généraux inutiles, car les applications Kafka ont tendance à avoir un débit élevé.

Les transactions Kafka Connect sont enregistrées pour chaque itération de la tâche sink/source. Pour une tâche sink, une transaction consiste à interroger un consommateur Kafka, à convertir chaque message et à envoyer des données à la cible. Pour une tâche source, une transaction consiste à lire la cible, à convertir les données en messages et à envoyer chaque message avec un producteur Kafka.

Si vous souhaitez collecter ces transactions, vous devez activer un module `kafka-connect-spans` :

```yml
class_transformer:
  kafka-connect-spans:
    enabled: true
```

## Les traces de Kafka distribuées [#collect-kafka-distributed-traces]

L&apos;agent Java peut également collecter [des traces distribuées](/docs/apm/distributed-tracing/getting-started/introduction-distributed-tracing) à partir des clients Kafka. Étant donné que Kafka Streams s’exécute sur des clients Kafka, les étapes de gestion du tracing distribué s’appliquent également. L&apos;activation de la trace n&apos;affecte pas les opérations normales de l&apos;agent; il continuera à signaler les données métriques ou d&apos;événements de Kafka.

Impacts et exigences à prendre en compte avant d’activer :

* <DNT>**The instrumentation adds a 150 to 200 byte payload to message headers.**</DNT> Si vos messages Kafka sont très petits, la trace peut ajouter une surcharge de traitement et de stockage importante. Cette taille de charge utile supplémentaire peut amener Kafka à supprimer des messages s&apos;ils dépassent votre limite de taille de messagerie Kafka. Pour cette raison, nous recommandons de tester les traces distribuées Kafka dans un environnement de développement avant de les activer en production.
* Le tracing distribué n&apos;est disponible que pour les versions client Kafka 0.11.0.0 ou supérieures.
* Si vous n’avez **pas** encore activé le tracing distribué pour votre application, lisez le [guide de transition](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) avant de l’activer.
* Pour propager le contexte de trace W3C via les en-têtes de message Kafka, consultez le [guide d&apos;utilisation d&apos;API de tracing distribué](/docs/agents/java-agent/api-guides/guide-using-java-agent-api#trace-calls) pour plus de détails sur API qui ont été publiées dans agent Java 6.4.0. Notez que l’ajout d’en-têtes supplémentaires aux messages Kafka augmentera encore la taille de la charge utile. Pour voir ces API en action, consultez [Utilisation des API de trace d’agent Java avec Kafka](https://github.com/newrelic/newrelic-java-examples/tree/main/newrelic-java-agent/distributed-tracing/kafka-examples).
* Si vous utilisez Kafka Streams, vous devez activer un module d&apos;instrumentation SPAN (reportez-vous à la [section Transaction Kafka Streams](#collect-kafka-streams-transactions)). Étant donné qu&apos;une transaction n&apos;est pas enregistrée par enregistrement, l&apos;acceptation des en-têtes tracedistribués ne fonctionnera que pour un seul enregistrement.

Le processus complet d&apos;activation de cette fonction est décrit ci-dessous, mais à un niveau élevé, il implique les étapes de base suivantes : 1) activer le tracing via la configuration de l&apos;agent et 2) appeler [l&apos;API de l&apos;agent Java](/docs/agents/java-agent/api-guides/guide-using-java-agent-api) pour instrumenter les transactions du côté du producteur et du côté du consommateur.

Pour collecter les traces distribuées à partir de Kafka :

<CollapserGroup>
  <Collapser id="enable-dt-kafka" title="1. Activer le tracing distribué dans le fichier de configuration">
    Si vous n’avez pas encore activé le tracing distribué pour votre application, lisez le [guide de transition du tracing distribué](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) avant de l’activer.

    Pour activer le tracing distribué Kafka, ces deux paramètres doivent être activés dans votre [fichier de configuration`newrelic.yml` ](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Structure):

    * Assurez-vous que l&apos;élément [`distributed_tracing`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#distributed-tracing) est activé :

      ```yml
      distributed_tracing:
        enabled: true
      ```

    * Activez la fonctionnalité de tracing distribué spécifique à Kafka en ajoutant ce qui suit à votre fichier de configuration :

      ```yml
      class_transformer:
        com.newrelic.instrumentation.kafka-clients-spans-0.11.0.0:
          enabled: true
      ```

    * Activer l&apos;instrumentation Spring-Kafka pour les versions d&apos;agent `8.21` et supérieures.

      <Callout variant="important">
        Cela peut provoquer un pic d&apos;ingestion et d&apos;utilisation de la mémoire, il est donc désactivé
      </Callout>

      ```yml
      class_transformer:
        com.newrelic.instrumentation.spring-kafka-2.2.0:
          enabled: true
      ```

    * Activer le tracing distribué pour les appels par lots pour Kafka pour les versions d&apos;agent `8.21` et supérieures. (Les traces distribuées par appel par lots sont désactivées par défaut car les transactions ne peuvent accepter qu&apos;une seule trace parent d&apos;un message) :

      ```yml
      kafka:
        spans:
          distributed_trace: 
            consume_many:
              enabled: true
      ```
  </Collapser>

  <Collapser id="instrument-kafka-producer" title="2. instrumenter le producteur Kafka">
    Pour instrumenter votre producteur Kafka, vous devrez démarrer une transaction avant tout appel à `Producer.send(ProducerRecord<K, V> record)`. Pour ce faire, ajoutez l’annotation de l’agent Java `@Trace(dispatcher = true)` à la méthode.

    Par exemple:

    ```java
    @Trace(dispatcher = true)
    public static void createAndSend(KafkaProducer<String, String> producer){
      ProducerRecord<String, String> data = new ProducerRecord<String, String>("topic", "key", "value");
      producer.send(data);
    }
    ```

    <Callout variant="important">
      Si vous utilisez Kafka Streams, vous n&apos;avez pas besoin de démarrer directement une transaction ou d&apos;envoyer des données à un producteur.
    </Callout>
  </Collapser>

  <Collapser id="instrument-kafka-consumer" title="3. instrumenter le Kafka consommateur">
    ### Scénario 1 : Utilisation de l&apos;instrumentation manuelle avec le client Kafka

    Pour instrument votre consommateur Kafka via une installation manuelle, vous devrez démarrer une transaction lorsque le message est en cours de traitement. L&apos;agent stocke l&apos;en-tête de frais de tracing distribué sous la clé `newrelic` ou sous les clés `traceparent` et `tracestate` du W3C. Récupérez l’en-tête, puis appelez l’API de transaction New Relic pour accepter la charge utile.

    Par exemple:

    ```java
    @Trace(dispatcher = true)
    private static void processMessage(ConsumerRecord<String, String> rec) {
      // create a distributed trace headers map
      Headers dtHeaders = ConcurrentHashMapHeaders.build(HeaderType.MESSAGE);

      // Iterate through each record header and insert the trace headers into the dtHeaders map
      for (Header header : rec.headers()) {
        String headerValue = new String(header.value(), StandardCharsets.UTF_8);

        // using the newrelic key
        if (header.key().equals("newrelic")) {
          dtHeaders.addHeader("newrelic", headerValue);
        }

        // or using the W3C keys
        if (header.key().equals("traceparent")) {
          dtHeaders.addHeader("traceparent", headerValue);
        }

        if (header.key().equals("tracestate")) {
          dtHeaders.addHeader("tracestate", headerValue);
        }
      }

      // Accept distributed tracing headers to link this request to the originating request
      NewRelic.getAgent().getTransaction().acceptDistributedTraceHeaders(TransportType.Kafka, dtHeaders);
    }
    ```

    ### Scénario 2 : Utilisation de l&apos;auto-instrumentation pour les clients Kafka

    Ceci ne s&apos;appliquera qu&apos;aux versions d&apos;agent `8.21` et supérieures. Vous pouvez également exploiter l&apos;auto-instrumentation pour lire le tracing distribué pour Kafka Consommateur. Cela se fait en démarrant une transaction et en appelant la méthode `poll(...)` d&apos;un consommateur lorsque la transaction a lieu.

    Ceci est désactivé par défaut car l&apos;interrogation du consommateur accepte par défaut plusieurs messages et les transactions ne peuvent avoir qu&apos;une seule trace parent, donc un seul message sera lu.

    Pour activer l&apos;acceptation automatique des traces distribuées pour les sondages consommateurs Kafka, vous devez activer le tracing distribué pour les appels par lots comme indiqué à l&apos;étape 1.

    Exemple de sondages instrumenté kafka consommateur :

    ```java
    @Trace(dispatcher = true)
    private void consumeMessage(KafkaConsumer<String, String> consumer) {
      final ConsumerRecords<String, String> records = consumer.poll(1000);
      // Process your records ....
    }
    ```

    ### Scénario 3 : Utilisation de Spring Kafka

    Si vous utilisez Spring Kafka, vous pouvez activer l&apos;auto-instrumentation pour les méthodes instrumentées avec `@KafkaListener` si vous utilisez les versions d&apos;agent `8.21.0` et supérieures. Cela crée des transactions et accepte automatiquement les traces distribuées pour le consommateur. Étant donné que Kafka est une plateforme à haut débit, elle est désactivée pour éviter une ingestion et une surcharge de mémoire excessives. Vous pouvez activer l&apos;instruction Spring-Kafka avec la configuration indiquée à l&apos;étape 1.

    Exemple:

    ```java
    @KafkaListener(id = "foo", topics = "myTopic", clientIdPrefix = "myClientId")
    public void listen(String data) {
      ...
    }
    ```

    <Callout variant="important">
      Si vous avez activé les transactions avec Kafka Streams (reportez-vous à la [section Transaction Kafka Streams](#collect-kafka-streams-transactions)), même si une transaction s&apos;applique à plusieurs enregistrements, l&apos;acceptation des en-têtes tracedistribués ne s&apos;appliquera qu&apos;à un seul enregistrement.
    </Callout>
  </Collapser>
</CollapserGroup>