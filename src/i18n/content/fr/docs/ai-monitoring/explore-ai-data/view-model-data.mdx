---
title: Analyser les données du modèle
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: '2024-06-12T00:00:00.000Z'
translationType: machine
---

monitoring de l&apos;IA fait apparaître des données sur votre modèle d&apos;IA afin que vous puissiez analyser les performances du modèle d&apos;IA ainsi que les performances de l&apos;application IA. Vous pouvez trouver des données sur votre modèle d&apos;IA dans deux domaines :

* <DNT>**Model inventory**</DNT>:Une vue centralisée qui affiche les performances et les données d&apos;achèvement de tous les modèles d&apos;IA de votre compte. Isolez l&apos;utilisation des jetons, suivez les performances globales ou explorez les finitions individuelles réalisées par vos modèles.
* <DNT>**Compare models**</DNT>:Effectuer une analyse comparative des performances entre deux modèles au fil du temps. Cette page affiche des données pour une analyse agrégée des performances de votre modèle au fil du temps.

<img title="Model data overview" alt="A screenshot of the model inventory page" src="/images/ai_screenshot-crop_intro-to-model-data.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring</DNT>**: Depuis monitoring de l&apos;IA, vous pouvez choisir entre l&apos;inventaire des modèles ou la comparaison des modèles.
</figcaption>

## Page d&apos;inventaire des modèles [#model-inventory]

<img title="Model inventory overview" alt="A screenshot of the overview page when you go to Model inventory" src="/images/ai_screenshot-full_model-inventory-overview-page.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model inventory</DNT>**: affichez les données sur l&apos;interaction avec votre modèle d&apos;IA.
</figcaption>

La page <DNT>model inventory</DNT> fournit des informations détaillées sur les performances globales et l&apos;utilisation de votre modèle d&apos;IA. Vous pouvez analyser les données des appels effectués sur votre modèle, afin de comprendre comment le modèle d&apos;IA affecte votre application d&apos;IA.

Depuis l&apos;onglet Aperçu, explorez le nombre de requests adressées à un modèle par rapport à son temps de réponse, ou analysez les graphiques de séries chronologiques pour voir quand le comportement du modèle a changé. À partir de là, examinez les onglets d’erreurs, de performances ou de coûts.

### Onglet Erreurs [#errors-inventory]

<img title="Model inventory: Errors" alt="A screenshot of the Errors time series and chart" src="/images/ai_screenshot-crop_model-inventory-errors.webp" />

<figcaption>
  Accéder à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model inventory &gt; Errors</DNT>**: Afficher les données sur les erreurs du modèle d&apos;IA.
</figcaption>

L&apos;onglet Erreurs utilise des graphiques et des tableaux de séries chronologiques pour organiser les erreurs du modèle.

* <DNT>**Response errors**</DNT>:Suivez le nombre d&apos;erreurs globales provenant de votre modèle d&apos;IA.
* <DNT>**Response errors by model**</DNT>:Déterminez si un modèle spécifique produit plus d’erreurs en moyenne ou si une erreur spécifique se produit dans vos modèles.
* <DNT>**Response errors by type**</DNT>:Voir la fréquence à laquelle certaines erreurs apparaissent.
* <DNT>**Errors table**</DNT>: Afficher le type d’erreur et le message dans le contexte de la demande et de la réponse.

### onglet performances [#performance-inventory]

<img title="Model inventory: Performance" alt="A screenshot of the Errors time series and chart" src="/images/ai_screenshot-crop_model-inventory-performance-page.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model inventory &gt; Performance</DNT>**: Affichez les données sur les performances de votre modèle d&apos;IA.
</figcaption>

L&apos;onglet Performances regroupe les métriques de réponse et de demande sur tous vos modèles. Consultez les modèles qui prennent le plus de temps pour traiter une demande ou créer une réponse avec les graphiques à secteurs, ou reportez-vous aux graphiques de séries chronologiques pour suivre les augmentations des demandes ou des temps de réponse. Vous pouvez utiliser des graphiques de performances pour localiser la valeur hors norme dans vos modèles.

### Onglet Coût [#cost-inventory]

<img title="Model inventory: Performance" alt="A screenshot of the Errors time series and chart" src="/images/ai_screenshot-crop_model-inventory-cost.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model inventory &gt; Cost</DNT>**: Consultez les données sur le coût de votre modèle d&apos;IA.
</figcaption>

L&apos;onglet Coût utilise une combinaison de graphiques de séries chronologiques et de diagrammes à secteurs pour identifier les facteurs de coût parmi vos modèles. Déterminez le nombre de jetons provenant de l&apos;invite ou des complétions, ou si certains modèles coûtent plus cher en moyenne que d&apos;autres.

* <DNT>**Tokens used and token limit**</DNT>:Évaluez la fréquence à laquelle vos modèles approchent d’une limite de jeton donnée.
* <DNT>**Total tokens by models**</DNT>:Déterminez lequel de vos modèles utilise le plus de jeton en moyenne.
* <DNT>**Total usage by prompt and completion tokens**</DNT>:Comprenez quel rapport de jeton provient de l&apos;invite que votre modèle accepte par rapport au jeton utilisé par complétion.

Comprendre les coûts vous permet d’améliorer la manière dont votre application d’IA utilise un ou plusieurs de vos modèles afin que votre chaîne d’outils d’IA soit plus rentable.

## Page de comparaison des modèles [#model-comparison]

<img title="Model inventory overview" alt="A screenshot of the overview page when you go to Model inventory" src="/images/ai_screenshot-full_ai-model-comparison-page.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model comparison</DNT>**: Comparez les données sur les différents modèles d&apos;IA de votre stack.
</figcaption>

La page de comparaison de modèles organise votre monitoring des données IA pour vous aider à mener des analyses comparatives. Cette page limite vos données de comparaison de modèles à un seul compte, vous fournissant des données agrégées sur le coût et les performances du modèle sur une ou plusieurs applications. Pour générer des données :

1. Choisissez vos modèles dans la liste déroulante.
2. Accédez à un service pour voir les performances dans le contexte d&apos;une application particulière, ou conservez la requête sur `Service = All` pour voir comment un modèle se comporte en moyenne.
3. Choisissez le paramètre de temps. Cet outil est flexible : vous pouvez effectuer des comparaisons sur différentes périodes, ce qui vous permet de voir comment les performances ou les coûts ont évolué avant et après un déploiement.

### Comparer les performances des modèles [#compare-performance]

<img title="Model comparison page: Performance" alt="A screenshot of model comparison" src="/images/ai_screenshot-crop_model-comparison-performance.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model comparison</DNT>**: Comparez les performances entre les différents modèles d&apos;IA de votre stack.
</figcaption>

Pour commencer à effectuer une analyse comparative, choisissez un service, un modèle et une période spécifiques. Lorsque vous comparez des modèles, vous pouvez évaluer différentes métriques agrégées au fil du temps, en fonction de vos propres paramètres. Voici quelques exemples de cas d’utilisation pour l’analyse comparative :

* **Comparez deux modèles dans le même service**: le service X utilise le modèle A pendant la première semaine, puis utilise le modèle B pendant la deuxième semaine. Vous pouvez comparer les performances en choisissant le service X, en sélectionnant le modèle A et en définissant les dates de la première semaine. Sur le deuxième côté, choisissez le service X, sélectionnez le modèle B et définissez les dates de la deuxième semaine.
* **Comparez les performances d&apos;un modèle au fil du temps**: sélectionnez le service X, sélectionnez le modèle A et définissez les dates de la première semaine. Sur le deuxième côté, choisissez le service X, sélectionnez le modèle A et définissez les dates de la deuxième semaine.
* **Évaluer les performances du modèle dans deux services différents**: Vous avez deux applications différentes qui utilisent deux modèles différents. Pour comparer le total des jetons au cours du dernier mois, choisissez le paramètre pertinent pour le service spécifique et les modèles spécifiques, puis définissez les dates pour la même période.
* **Comparez deux modèles**: Vous avez application qui utilise le modèle A et vous souhaitez mesurer le modèle A par rapport au modèle B. Pour chaque prompt de l&apos;utilisateur, vous appelez le modèle B en tant que processus d&apos;arrière-plan. Comparez les performances du modèle A par rapport au modèle B sur le même service pendant la même période.

### Comparer les coûts des modèles [#compare-cost]

<img title="Model comparison page: Cost" alt="A screenshot of model comparison" src="/images/ai_screenshot-crop_model-comparison-cost.webp" />

<figcaption>
  Accédez à **<DNT>[one.newrelic.com](https://one.newrelic.com) &gt; All Capabilities &gt; AI monitoring &gt; Model comparison</DNT>**: comparez les coûts entre les différents modèles d&apos;IA de votre stack.
</figcaption>

La colonne coût du modèle décompose l&apos;événement d&apos;achèvement en deux parties : la prompt donnée au modèle et la réponse finale que le modèle fournit à l&apos;utilisateur final.

* <DNT>**Tokens per completion**</DNT>: La moyenne du jeton pour tous les événements d&apos;achèvement.
* <DNT>**Prompt tokens**</DNT>:La moyenne des jetons pour l&apos;invite. Cette moyenne jeton inclut l&apos;invite créée par l&apos;ingénieur prompt et l&apos;utilisateur final.
* <DNT>**Completion tokens**</DNT>: Le nombre de jeton consommé par le modèle lorsqu&apos;il génère la réponse délivrée à l&apos;utilisateur final.

Lors de l&apos;analyse de cette colonne, la valeur du jeton d&apos;achèvement et du jeton prompt doit être égale à la valeur du jeton par achèvement.

## Quelle est la prochaine étape ? [#whats-next]

Maintenant que vous savez comment trouver vos données, vous pouvez explorer d&apos;autres fonctionnalités que monitoring de l&apos;IA a à offrir.

* Vous souhaitez analyser les performances de votre application d&apos;IA ? Consultez notre documentation sur [les pages de réponse des applications d&apos;IA](/docs/ai-monitoring/explore-ai-data/view-ai-responses).
* Vous êtes préoccupé par des informations sensibles ? [Apprenez à configurer des filtres de dépôt](/docs/ai-monitoring/drop-sensitive-data).
* Si vous souhaitez transmettre des informations de retour d&apos;utilisateur sur les réponses de l&apos;IA de votre application à New Relic, suivez nos procédures pour [mettre à jour le code de votre application afin d&apos;obtenir les commentaires des utilisateurs dans l&apos;UI](/docs/ai-monitoring/customize-agent-ai-monitoring).