---
title: Erreurs d'intégration de Kubernetes (version 2)
type: troubleshooting
tags:
  - Integrations
  - Kubernetes integration
  - Troubleshooting
metaDescription: Some of the more common error messages found in the infrastructure agent logs for New Relic Kubernetes integration v2.
freshnessValidatedDate: '2024-07-22T00:00:00.000Z'
translationType: machine
---

Si vous exécutez la version 2, consultez ces erreurs d’intégration Kubernetes courantes. Ces erreurs apparaissent dans le log standard non détaillé de l’agent infrastructure . Si vous avez besoin d&apos;un log plus détaillé, consultez [les logs Kubernetes ](/docs/kubernetes-pixie/kubernetes-integration/troubleshooting/get-logs-version/).

<CollapserGroup>
  <Collapser id="unable-find-kube-state-metrics-v2" title="Impossible de découvrir les métriques de l'état de kube">
    L&apos;intégration de Kubernetes nécessite [`kube-state-metrics`](https://github.com/kubernetes/kube-state-metrics). Si cela manque, vous verrez une erreur comme celle-ci dans le log du conteneur `newrelic-infra` :

    ```shell
    2018-04-11T08:02:41.765236022Z time="2018-04-11T08:02:41Z" level=error 
    msg="executing data source" data prefix="integration/com.newrelic.kubernetes" 
    error="exit status 1" plugin name=nri-kubernetes stderr="time=\"2018-04-11T08:02:41Z\" 
    level=fatal msg=\"failed to discover kube-state-metrics endpoint, 
    got error: no service found by label k8s-app=kube-state-metrics\"\n"
    ```

    Les raisons courantes de cette erreur incluent :

    * `kube-state-metrics` n&apos;a pas été déployé dans le cluster.
    * `kube-state-metrics` est déployé à l&apos;aide d&apos;un déploiement personnalisé.
    * Il existe plusieurs versions de `kube-state-metrics` en cours d&apos;exécution et l&apos;intégration Kubernetes ne trouve pas la bonne.

    L&apos;intégration Kubernetes détecte automatiquement `kube-state-metrics` dans votre cluster à l&apos;aide de cette logique :

    1. Il recherche un service `kube-state-metrics` exécuté sur l&apos;espace de nommage `kube-system` .
    2. Si cela n&apos;est pas trouvé, il recherche une balise de service avec l&apos;étiquette `"k8s-app: kube-state-metrics"`.

    L&apos;intégration nécessite également que le pod kube-state-métriques ait l&apos;étiquette `k8s-app: kube-state-metrics` ou `app: kube-state-metrics`. Si aucun de ces éléments n&apos;est trouvé, il y aura une entrée log comme celle-ci :

    ```shell
    2018-04-11T09:25:00.825532798Z time="2018-04-11T09:25:00Z" level=error 
    msg="executing data source" data prefix="integration/com.newrelic.kubernetes" 
    error="exit status 1" plugin name=nri-kubernetes stderr="time=\"2018-04-11T09:25:00Z\" 
    level=fatal msg=\"failed to discover nodeIP with kube-state-metrics, 
    got error: no pod found by label k8s-app=kube-state-metrics\"\n
    ```

    Pour résoudre ce problème, ajoutez l’étiquette `k8s-app=kube-state-metrics` au pod `kube-state-metrics` .
  </Collapser>

  <Collapser id="metrics-missing" title="Métriques manquantes pour l'espace de nommage, la déploiement et les ReplicaSets">
    Si les métriques des nœuds Kubernetes , du pod et du conteneur s&apos;affichent mais que les métriques de l&apos;espace de nommage, de la déploiement et de `ReplicaSets` sont manquantes, l&apos;intégration Kubernetes ne parvient pas à se connecter à `kube-state-metrics`.

    <CollapserGroup>
      <Collapser id="indicators" title="Indicateurs de données manquantes">
        Indicateurs d&apos;espace de nommage, de déploiement et de données `ReplicaSet` manquants :

        * Dans le graphique <DNT>**# of K8s objects**</DNT> , ces données sont manquantes.
        * les requêtes pour `K8sNamespaceSample`, `K8sDeploymentSample` et `K8sReplicasetSample` n&apos;affichent aucune donnée.
      </Collapser>
    </CollapserGroup>

    Il y a plusieurs raisons possibles à cela :

    1. `kube-state-metrics` le service a été personnalisé pour écouter sur le port 80. Si vous utilisez un port différent, vous pouvez voir une erreur comme celle-ci dans le log `verbose` :

       ```shell
       time="2018-04-04T09:35:47Z" level=error msg="executing data source" 
       data prefix="integration/com.newrelic.kubernetes" error="exit status 1" 
       plugin name=nri-kubernetes stderr="time=\"2018-04-04T09:35:47Z\" 
       level=fatal msg=\"Non-recoverable error group: error querying KSM. 
       Get http://kube-state-metrics.kube-system.svc.cluster.local:0/metrics: 
       net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\"\n"
       ```

       Il s&apos;agit d&apos;un problème connu qui se produit dans certains clusters où il faut trop de temps à `kube-state-metrics` pour collecter toutes les informations du cluster avant de les envoyer à l&apos;intégration.

       Pour contourner ce problème, [augmentez le délai d&apos;expiration du client kube-state-métriques](/docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration#kube-state-metrics-timeout-change).

    2. `kube-state-metrics` l&apos;instance s&apos;exécute derrière `kube-rbac-proxy`. New Relic ne prend actuellement pas en charge cette configuration. Vous pouvez voir une erreur comme celle-ci dans le log `verbose` :

       ```shell
       time="2018-03-28T23:09:12Z" level=error msg="executing data source" 
       data prefix="integration/com.newrelic.kubernetes" error="exit status 1" 
       plugin name=nri-kubernetes stderr="time=\"2018-03-28T23:09:12Z\" 
       level=fatal msg=\"Non-recoverable error group: error querying KSM. 
       Get http://192.168.132.37:8443/metrics: net/http: HTTP/1.x 
       transport connection broken: malformed HTTP response \\\"\\\\x15\\\\x03\\\\x01\\\\x00\\\\x02\\\\x02\\\"\"\n"
       ```

    3. La charge utile KSM est assez importante et l&apos;intégration Kubernetes qui traite la date est en train d&apos;être interrompue. Étant donné que l’intégration n’est pas le processus principal du conteneur, le pod n’est pas redémarré. Cette situation peut être repérée dans le log du pod `newrelic-infra` exécuté dans le même nœud de KSM :

       ```shell
       time="2020-12-10T17:40:44Z" level=error msg="Integration command failed" error="signal: killed" instance=nri-kubernetes integration=com.newrelic.kubernetes
       ```

       Pour contourner ce problème, augmentez les limites de mémoire de DaemonSet afin que le processus ne soit pas arrêté.
  </Collapser>

  <Collapser id="cannot-list-pods-for-cluster" title="Impossible de répertorier le pod au niveau du cluster">
    Le pod Newrelic et le compte de service newrelic ne sont pas déployés dans le même espace de nommage. C&apos;est généralement parce que le contexte actuel spécifie un espace de nommage. Si tel est le cas, vous verrez une erreur comme celle-ci :

    ```shell
    time=\"2018-05-31T10:55:39Z\" level=panic msg=\"p
    ods is forbidden: User \\\"system:serviceaccount:kube-system:newrelic\\\" cannot list pods at the cluster scope\"
    ```

    Pour vérifier si c&apos;est le cas, exécutez :

    ```shell
    kubectl describe serviceaccount newrelic | grep Namespace
    kubectl get pods -l name=newrelic-infra --all-namespaces
    kubectl config get-contexts
    ```

    Pour résoudre ce problème, modifiez l&apos;espace de nommage du compte de service dans le fichier YAML New Relic `DaemonSet` pour qu&apos;il soit identique à l&apos;espace de nommage du contexte actuel :

    ```yaml
    - kind: ServiceAccount
      name: newrelic
      namespace: default
    ---
    ```
  </Collapser>
</CollapserGroup>

## Ne pas voir les données control plane [#control-plane-data]

<CollapserGroup>
  <Collapser id="invalid-license" title="Vérifiez que les nœuds control plane ont les étiquettes correctes">
    Exécutez les commandes suivantes pour rechercher manuellement les nœuds control plane :

    ```shell
    kubectl get nodes -l node-role.kubernetes.io/control-plane=""
    ```

    Si les nœuds control plane suivent la convention d&apos;étiquetage définie dans le [composant du plan de contrôle](/docs/kubernetes-pixie/kubernetes-integration/advanced-configuration/configure-control-plane-monitoring/#component), vous devriez obtenir une sortie comme :

    ```shell
    NAME                         STATUS  ROLES          AGE   VERSION
    ip-10-42-24-4.ec2.internal   Ready   control-plane  42d   v1.14.8
    ```

    Si aucun nœud n&apos;est trouvé, il existe deux scénarios :

    Vos nœuds control plane n’ont pas les étiquettes requises qui les identifient comme plan de contrôle. Dans ce cas, vous devez ajouter les deux étiquettes à vos nœuds control plane .

    Vous êtes dans un cluster géré et votre fournisseur gère les nœuds control plane pour vous. Dans ce cas, vous ne pouvez rien faire, car votre fournisseur limite l&apos;accès à ces nœuds.
  </Collapser>

  <Collapser id="unable-connect" title="Vérifiez que l'intégration est en cours d'exécution sur les nœuds control plane">
    Pour identifier un pod d’intégration exécuté sur un nœud control plane , remplacez `NODE_NAME` dans la commande suivante par l’un des noms de nœud répertoriés à l’étape précédente :

    ```shell
    kubectl get pods --field-selector spec.nodeName=NODE_NAME -l name=newrelic-infra --all-namespaces
    ```

    La commande suivante est la même que la précédente, sauf qu&apos;elle sélectionne le nœud pour vous :

    ```shell
    kubectl get pods --field-selector spec.nodeName=$(kubectl get nodes -l node-role.kubernetes.io/control-plane="" -o jsonpath="{.items[0].metadata.name}") -l name=newrelic-infra --all-namespaces
    ```

    Si tout est correct, vous devriez obtenir un résultat comme :

    ```shell
    NAME                   READY   STATUS    RESTARTS   AGE
    newrelic-infra-whvzt   1/1     Running   0          6d20h
    ```

    Si l&apos;intégration n&apos;est pas en cours d&apos;exécution sur vos nœuds control plane , vérifiez que le daemonset dispose de toutes les instances souhaitées en cours d&apos;exécution et prêtes.

    ```shell
    kubectl get daemonsets -l app=newrelic-infra --all-namespaces
    ```
  </Collapser>

  <Collapser id="indicators" title="Vérifiez que les composants control plane ont les étiquettes requises">
    Reportez-vous à la [section de documentation sur la découverte des nœuds et des composants control plane ](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#discover-nodes-components)et recherchez les étiquettes que l&apos;intégration utilise pour découvrir les composants. Exécutez ensuite les commandes suivantes pour voir s’il existe des pods avec de telles étiquettes et les nœuds sur lesquels ils s’exécutent :

    ```shell
    kubectl get pods -l k8s-app=kube-apiserver --all-namespaces
    ```

    S&apos;il y a un composant avec l&apos;étiquette donnée, vous devriez voir quelque chose comme :

    ```shell
    NAMESPACE    NAME                                        READY  STATUS   RESTARTS  AGE
    kube-system  kube-apiserver-ip-10-42-24-42.ec2.internal  1/1    Running  3         49d
    ```

    La même chose devrait être faite avec le reste des composants :

    ```shell
    kubectl get pods -l k8s-app=etcd-manager-main --all-namespaces
    ```

    ```shell
    kubectl get pods -l k8s-app=kube-scheduler --all-namespaces
    ```

    ```shell
    kubectl get pods -l k8s-app=kube-kube-controller-manager --all-namespaces
    ```
  </Collapser>

  <Collapser id="cannot-list-pods-for-cluster" title="Récupérez le log détaillé de l'une des intégrations exécutées sur un nœud control plane et vérifiez les tâches des composants control plane">
    Pour récupérer le log, suivez les instructions sur [obtenir le log à partir d&apos; pod exécuté sur un nœud control plane ](/docs/integrations/kubernetes-integration/troubleshooting/get-logs-version). Le log d&apos;intégration pour chaque composant le message suivant `Running job: COMPONENT_NAME`. Par exemple :

    ```shell
    Running job: scheduler
    ```

    ```shell
    Running job: etcd
    ```

    ```shell
    Running job: controller-manager
    ```

    ```shell
    Running job: api-server
    ```

    Si vous n&apos;avez pas spécifié l&apos;option configuration `ETCD_TLS_SECRET_NAME`, vous trouverez ce message dans le log :

    ```shell
    Skipping job creation for component etcd: etcd requires TLS configuration, none given
    ```

    Si une erreur se produit lors de l&apos;interrogation des métriques d&apos;un composant, elle sera enregistrée après le message `Running job` .
  </Collapser>

  <Collapser id="cannot-list-pods-for-cluster" title="Requête manuelle des métriques des composants">
    Pour obtenir le point de terminaison du composant du control plane que vous souhaitez interroger, consultez le [composant du plan de contrôle](/docs/kubernetes-pixie/kubernetes-integration/advanced-configuration/configure-control-plane-monitoring/#component). Avec le point de terminaison, vous pouvez utiliser le pod d&apos;intégration qui s&apos;exécute sur le même nœud que le composant à interroger. Consultez ces exemples pour savoir comment interroger le planificateur Kubernetes :

    ```shell
    kubectl exec -ti POD_NAME -- wget -O - localhost:10251/metrics
    ```

    La commande suivante fait la même chose que la précédente, mais choisit également le pod pour vous :

    ```shell
    kubectl exec -ti $(kubectl get pods --all-namespaces --field-selector spec.nodeName=$(kubectl get nodes -l node-role.kubernetes.io/control-plane="" -o jsonpath="{.items[0].metadata.name}") -l name=newrelic-infra -o jsonpath="{.items[0].metadata.name}") -- wget -O - localhost:10251/metrics
    ```

    Si tout est correct, vous devriez obtenir des métriques sur le format Prometheus, quelque chose comme ceci :

    ```shell
    Connecting to localhost:10251 (127.0.0.1:10251)
    # HELP apiserver_audit_event_total Counter of audit events generated and sent to the audit backend.
    # TYPE apiserver_audit_event_total counter
    apiserver_audit_event_total 0
    # HELP apiserver_audit_requests_rejected_total Counter of apiserver requests rejected due to an error in audit logging backend.
    # TYPE apiserver_audit_requests_rejected_total counter
    apiserver_audit_requests_rejected_total 0
    # HELP apiserver_client_certificate_expiration_seconds Distribution of the remaining lifetime on the certificate used to authenticate a request.
    # TYPE apiserver_client_certificate_expiration_seconds histogram
    apiserver_client_certificate_expiration_seconds_bucket{le="0"} 0
    apiserver_client_certificate_expiration_seconds_bucket{le="1800"} 0
    apiserver_client_certificate_expiration_seconds_bucket{le="3600"} 0
    ```
  </Collapser>
</CollapserGroup>