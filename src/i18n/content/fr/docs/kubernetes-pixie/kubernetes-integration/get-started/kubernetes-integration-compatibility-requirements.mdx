---
title: 'Intégration Kubernetes : compatibilité et exigences'
tags:
  - Integrations
  - Kubernetes integration
  - Get started
metaDescription: Compatibility and requirements of the New Relic Kubernetes integration.
freshnessValidatedDate: never
translationType: machine
---

L&apos;[intégration Kubernetes ](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)est compatible avec de nombreuses plateformes différentes, notamment GKE, EKS, AKS, OpenShift, etc. Chacun a une compatibilité différente avec notre intégration. Vous trouverez plus d&apos;informations sur cette page.

## Exigences [#reqs]

L&apos;intégration New Relic Kubernetes nécessite un compte New Relic. Si vous ne l&apos;avez pas déjà fait, créez votre compte New Relic gratuit ci-dessous pour commencer monitoring vos données dès aujourd&apos;hui.

Vous aurez également besoin d&apos;une distribution Linux [compatible avec l&apos;agent New Relic Infrastructure](/docs/infrastructure/new-relic-infrastructure/getting-started/compatibility-requirements-new-relic-infrastructure#operating-systems).

<Callout variant="important">
  * `kube-state-metrics` La version v2 ou supérieure est prise en charge à partir de la version d&apos;intégration 3.6.0 ou supérieur.

  * Installer l&apos;intégration Kubernetes jusqu&apos;à la version 3.5.0 si vous utilisez `kube-state-metrics` 1.9.8 ou une version antérieure.

  * Vérifiez le fichier `values.yaml` si vous mettez à jour `kube-state-metrics` de la version 1.9.8 vers la version 2 ou supérieure, car certaines variables peuvent avoir changé.
</Callout>

### Compatibilité et exigences pour Helm [#req-helm]

* Assurez-vous que [Helm](https://github.com/helm/helm?tab=readme-ov-file#install) est installé et que la version minimale prise en charge est la v3. La version 3 de l&apos;intégration Kubernetes nécessite Helm version 3.

* Choisissez un nom d’affichage pour votre cluster. Par exemple, vous pouvez utiliser cette sortie :

  ```shell
  kubectl config current-context
  ```

### Compatibilité et exigences pour Manifest [#req-manifest]

Si des manifestes personnalisés ont été utilisés à la place de Helm, vous devrez d&apos;abord supprimer l&apos;ancienne installation à l&apos;aide de `kubectl delete -f previous-manifest-file.yml`, puis suivre à nouveau le programme d&apos;installation guidé. Cela générera un ensemble mis à jour de manifestes qui peuvent être déployés à l&apos;aide de `kubectl apply -f manifest-file.yml`.

## Exécution du conteneur [#containers]

Notre intégration Kubernetes est indépendante [du CRI](https://kubernetes.io/docs/concepts/architecture/cri) . Il a été spécifiquement testé pour être compatible avec Containerd. Notez que Dockershim a été supprimé du projet Kubernetes à partir de la sortie 1.24. Lisez la [FAQ sur la suppression de Dockershim](https://kubernetes.io/blog/2022/02/17/dockershim-faq/) pour plus de détails.

## Compatibilité [#compatibility]

<Callout variant="important">
  Si vous utilisez Openshift, vous pouvez également utiliser `kubectl` la plupart du temps, mais faites attention à ce que `kubectl` ne contienne pas de commandes comme `oc login` ou `oc adm`. Vous devrez peut-être utiliser `oc` au lieu de `kubectl`.
</Callout>

Notre intégration est compatible et testée en continu sur les versions de Kubernetes suivantes :

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }} />

      <th>
        Versions
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Cluster Kubernetes
      </td>

      <td>
        1,28 à 1,32
      </td>
    </tr>
  </tbody>
</table>

<Callout variant="important">
  À partir de la version 1.26 de Kubernetes, `@autoscaling/v2` a remplacé l&apos;API `@autoscaling/v2beta2` . Pour un reporting métrique `HorizontalPodAutoscaling` continu, vous devez installer la version 2.7+ de `kube-state-metrics` sur le cluster Kubernetes version 1.26+, car seule la version 2.7+ de `kube-state-metrics` peut prendre en charge l&apos;API `@autoscaling/v2`.
</Callout>

### Saveurs de Kubernetes

L&apos;intégration de Kubernetes est compatible avec différentes versions. Nous avons testé l&apos;intégration avec les éléments suivants :

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        Saveur
      </th>

      <th>
        Remarques
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Minikube
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Gentil
      </td>

      <td />
    </tr>

    <tr>
      <td>
        K3
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Kubeadm
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Amazon Elastic Kubernetes Service (EKS)
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Amazon Elastic Kubernetes Service Anywhere (EKS-Anywhere)
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Service Amazon Elastic Kubernetes sur Fargate (EKS-Fargate)
      </td>

      <td>
        [Documents d&apos;installation de Fargate](/docs/kubernetes-pixie/kubernetes-integration/installation/kubernetes-eks-fargate)
      </td>
    </tr>

    <tr>
      <td>
        Moteur Kubernetes Rancher (RKE1)
      </td>

      <td>
        [configurationsupplémentaire](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#rancher) est nécessaire pour instrumenter les composants control plane
      </td>
    </tr>

    <tr>
      <td>
        Azure Kubernetes Service (AKS)
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Google Kubernetes Engine (GKE)
      </td>

      <td>
        Compatible avec [les modes standard et pilote automatique](https://cloud.google.com/kubernetes-engine/docs/concepts/choose-cluster-mode).
      </td>
    </tr>

    <tr>
      <td>
        OpenShift
      </td>

      <td>
        Testé avec la version 4.14
      </td>
    </tr>

    <tr>
      <td>
        VMware Tanzu
      </td>

      <td>
        Compatible avec VMware Tanzu (plateforme Pivotal) version 2.5 à 2.11 et Ops Manager version 2.5 à 2.10
      </td>
    </tr>
  </tbody>
</table>

Selon la méthode d&apos;installation, la n&apos;est pas disponible ou peut [control plane monitoring](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring) nécessiter configuration supplémentaire.

Par exemple:

* Seules les métriques du serveur API sont récupérables et disponibles pour intrumenter du cluster géré par (GKE, EKS, AKS), control plane car aucun point de terminaison n&apos;expose les métriques nécessaires pour etcd, le planificateur et le gestionnaire de contrôleur.
* Pour intrumenter control plane Rancher, étant donné que les composants `/metrics` ne sont pas toujours accessibles par défaut et ne peuvent pas être détectés automatiquement, une [configurationsupplémentaire](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#rancher) est nécessaire.

## Besoins en ressources

Lors du déploiement de l&apos;intégration de New Relic Kubernetes , il est important d&apos;allouer des ressources appropriées pour garantir que les composants monitoring fonctionnent efficacement.

Voici les requests et limites de ressources minimales recommandées pour chacun des composants déployés par le graphique [d&apos;infrastructure](https://github.com/newrelic/nri-kubernetes/blob/main/charts/newrelic-infrastructure/values.yaml) .

### [Composant Kubelet](/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-kubelet)

Les conteneurs suivants sont inclus dans le pod du composant Kubelet déployé dans chaque nœud.

**Conteneur Kubelet**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

**Agent conteneur**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

### [Composant métrique de l&apos;état de Kube](https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-ksm)

**Conteneur KSM**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `850M`

**Conteneur transitaire**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `850M`

### [composant du plan de contrôle](https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-kubelet)

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

**Agent conteneur**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

Voici les requests de ressources recommandées et les limites requises par d&apos;autres composants déployés dans le cadre du [nri-bundle](https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#components)

### [injectionméta](https://github.com/newrelic/k8s-metadata-injection/tree/main/charts/nri-metadata-injection)

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `30M`
  * **Limite**: `80M`

### [Enregistrement](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging)

Les conteneurs suivants sont inclus dans le pod de logging New Relic déployé dans chaque nœud.

* **Processeur**:

  * **Demande**: `250m`
  * **Limite**: `500m`

* **Mémoire**:

  * **Demande**: `64M`
  * **Limite**: `128M`

### Considérations

* **Taille de Cluster **: ces recommandations de ressources concernent les tailles cluster typiques. Un cluster plus grand avec plus de nœuds et de pods peut nécessiter des allocations de ressources accrues pour gérer le volume de données supplémentaire.

* **Configuration personnalisée**: si vous activez une fonctionnalité supplémentaire ou une configuration personnalisée, pensez à ajuster les ressources en conséquence.

* **Monitoring et ajustement**: Après le déploiement, monitorez l&apos;utilisation des ressources de ces pods et ajustez les requests et les limites en fonction de l&apos;utilisation réelle pour optimiser les performances et les coûts.

Ces spécifications de ressources peuvent être ajustées dans le fichier `values.yaml` du graphique Helm utilisé pour déployer l&apos;intégration New Relic Kubernetes. En garantissant que ces exigences en matière de ressources sont satisfaites, vous pouvez maintenir monitoring efficace et efficiente de votre cluster Kubernetes avec New Relic.