---
title: 'Intégration Kubernetes : compatibilité et exigences'
tags:
  - Integrations
  - Kubernetes integration
  - Get started
metaDescription: Compatibility and requirements of the New Relic Kubernetes integration.
freshnessValidatedDate: never
translationType: machine
---

L&apos;[intégration Kubernetes ](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)est compatible avec de nombreuses plateformes différentes, notamment GKE, EKS, AKS, OpenShift, etc. Chacun a une compatibilité différente avec notre intégration. Vous trouverez plus d&apos;informations sur cette page.

## Exigences [#reqs]

L&apos;intégration New Relic Kubernetes nécessite un compte New Relic. Si vous ne l&apos;avez pas déjà fait, créez votre compte New Relic gratuit ci-dessous pour commencer monitoring vos données dès aujourd&apos;hui.

Vous aurez également besoin d&apos;une distribution Linux [compatible avec l&apos;agent New Relic Infrastructure](/docs/infrastructure/new-relic-infrastructure/getting-started/compatibility-requirements-new-relic-infrastructure#operating-systems).

<Callout variant="important">
  * `kube-state-metrics` La version v2 ou supérieure est prise en charge à partir de la version d&apos;intégration 3.6.0 ou supérieur.

  * Installer l&apos;intégration Kubernetes jusqu&apos;à la version 3.5.0 si vous utilisez `kube-state-metrics` 1.9.8 ou une version antérieure.

  * Vérifiez le fichier `values.yaml` si vous mettez à jour `kube-state-metrics` de la version 1.9.8 vers la version 2 ou supérieure, car certaines variables peuvent avoir changé.
</Callout>

### Compatibilité et exigences pour Helm [#req-helm]

* Assurez-vous que [Helm](https://github.com/helm/helm?tab=readme-ov-file#install) est installé et que la version minimale prise en charge est la v3. La version 3 de l&apos;intégration Kubernetes nécessite Helm version 3.

* Choisissez un nom d’affichage pour votre cluster. Par exemple, vous pouvez utiliser cette sortie :

  ```shell
  kubectl config current-context
  ```

### Compatibilité et exigences pour Manifest [#req-manifest]

Si des manifestes personnalisés ont été utilisés à la place de Helm, vous devrez d&apos;abord supprimer l&apos;ancienne installation à l&apos;aide de `kubectl delete -f previous-manifest-file.yml`, puis suivre à nouveau le programme d&apos;installation guidé. Cela générera un ensemble mis à jour de manifestes qui peuvent être déployés à l&apos;aide de `kubectl apply -f manifest-file.yml`.

### Compatibilité et exigences pour Windows [#req-windows]

<Callout title="Aperçu">
  Nous travaillons toujours sur cette fonctionnalité, mais nous aimerions que vous l&apos;essayiez !

  Cette fonctionnalité est actuellement fournie dans le cadre d&apos;un programme d&apos;aperçu conformément à nos [politiques de pré-sortie](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy). Consultez le [guide d’installation de l’intégration Kubernetes](/install/kubernetes) pour obtenir les dernières instructions.
</Callout>

Pour surveiller les nœuds Windows avec l’intégration New Relic Kubernetes, votre environnement doit répondre aux exigences suivantes.

**Exigences du nœud :**

* Pour le nœud Linux : votre cluster Kubernetes doit inclure au moins un nœud Linux. Les composants principaux de l&apos;intégration sont déployés sur un nœud Linux pour permettre monitoring de l&apos;ensemble du cluster.

* Pour le nœud Windows : nous prenons en charge monitoring des nœuds exécutant les versions 2019 et 2022 de Windows Server LTSC.

  <Callout variant="important">
    Votre fournisseur de cloud peut prendre en charge différentes versions de Windows en fonction de la version de Kubernetes exécutée par votre cluster. Vérifiez toujours que la version du système d’exploitation de votre nœud est prise en charge par votre fournisseur de cloud.
  </Callout>

En raison des limitations des offres des fournisseurs de cloud et de Kubernetes lui-même, plusieurs scénarios d&apos;installation clés ne sont pas pris en charge pour les nœuds Windows, notamment :

* Nœuds Windows exécutés dans un cluster Red Hat OpenShift.
* Cluster Amazon EKS Fargate, car Fargate ne prend en charge que les nœuds Linux.
* Cluster Google GKE Autopilot, car Autopilot ne prend en charge que les nœuds Linux.

## Exécution du conteneur [#containers]

Notre intégration Kubernetes est indépendante [du CRI](https://kubernetes.io/docs/concepts/architecture/cri) . Il a été spécifiquement testé pour être compatible avec Containerd. Notez que Dockershim a été supprimé du projet Kubernetes à partir de la sortie 1.24. Lisez la [FAQ sur la suppression de Dockershim](https://kubernetes.io/blog/2022/02/17/dockershim-faq/) pour plus de détails.

## Compatibilité [#compatibility]

<Callout variant="important">
  Si vous utilisez Openshift, vous pouvez également utiliser `kubectl` la plupart du temps, mais faites attention à ce que `kubectl` ne contienne pas de commandes comme `oc login` ou `oc adm`. Vous devrez peut-être utiliser `oc` au lieu de `kubectl`.
</Callout>

Notre intégration est compatible et testée en continu sur les versions de Kubernetes suivantes :

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }} />

      <th>
        Versions
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Cluster Kubernetes
      </td>

      <td>
        1.30 à 1.34
      </td>
    </tr>
  </tbody>
</table>

<Callout variant="important">
  À partir de la version 1.26 de Kubernetes, `@autoscaling/v2` a remplacé l&apos;API `@autoscaling/v2beta2` . Pour un reporting métrique `HorizontalPodAutoscaling` continu, vous devez installer la version 2.7+ de `kube-state-metrics` sur le cluster Kubernetes version 1.26+, car seule la version 2.7+ de `kube-state-metrics` peut prendre en charge l&apos;API `@autoscaling/v2`.
</Callout>

### Saveurs de Kubernetes

L&apos;intégration de Kubernetes est compatible avec différentes versions. Nous avons testé l&apos;intégration avec les éléments suivants :

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        Saveur
      </th>

      <th>
        Remarques
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Minikube
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Gentil
      </td>

      <td />
    </tr>

    <tr>
      <td>
        K3
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Kubeadm
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Amazon Elastic Kubernetes Service (EKS)
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Amazon Elastic Kubernetes Service Anywhere (EKS-Anywhere)
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Service Amazon Elastic Kubernetes sur Fargate (EKS-Fargate)
      </td>

      <td>
        [Documents d&apos;installation de Fargate](/docs/kubernetes-pixie/kubernetes-integration/installation/kubernetes-eks-fargate)
      </td>
    </tr>

    <tr>
      <td>
        Moteur Kubernetes Rancher (RKE1)
      </td>

      <td>
        [configuration supplémentaire](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#rancher) est nécessaire pour instrumenter les composants control plane
      </td>
    </tr>

    <tr>
      <td>
        Azure Kubernetes Service (AKS)
      </td>

      <td />
    </tr>

    <tr>
      <td>
        Google Kubernetes Engine (GKE)
      </td>

      <td>
        Compatible avec [les modes standard et pilote automatique](https://cloud.google.com/kubernetes-engine/docs/concepts/choose-cluster-mode).
      </td>
    </tr>

    <tr>
      <td>
        OpenShift
      </td>

      <td>
        Testé avec la version 4.19
      </td>
    </tr>

    <tr>
      <td>
        VMware Tanzu
      </td>

      <td>
        Compatible avec VMware Tanzu (plateforme Pivotal) version 2.5 à 2.11 et Ops Manager version 2.5 à 2.10
      </td>
    </tr>
  </tbody>
</table>

Selon la méthode d&apos;installation, la n&apos;est pas disponible ou peut [control plane monitoring](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring) nécessiter configuration supplémentaire.

Par exemple:

* Seules les métriques du serveur API sont récupérables et disponibles pour intrumenter du cluster géré par (GKE, EKS, AKS), control plane car aucun point de terminaison n&apos;expose les métriques nécessaires pour etcd, le planificateur et le gestionnaire de contrôleur.
* Pour intrumenter control plane Rancher, étant donné que les composants `/metrics` ne sont pas toujours accessibles par défaut et ne peuvent pas être détectés automatiquement, une [configuration supplémentaire](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#rancher) est nécessaire.

## Besoins en ressources

Lors du déploiement de l&apos;intégration de New Relic Kubernetes , il est important d&apos;allouer des ressources appropriées pour garantir que les composants monitoring fonctionnent efficacement.

Voici les requests et limites de ressources minimales recommandées pour chacun des composants déployés par le graphique [d&apos;infrastructure](https://github.com/newrelic/nri-kubernetes/blob/main/charts/newrelic-infrastructure/values.yaml) .

### [Composant Kubelet](/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-kubelet)

Les conteneurs suivants sont inclus dans le pod de composants Kubelet déployé dans chaque nœud Linux.

**Conteneur Kubelet**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

**Agent conteneur**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

### [Composant Kubelet - Windows](/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-kubelet-windows)

Les conteneurs suivants sont inclus dans le pod de composants Kubelet déployé dans chaque nœud Windows, lorsque Windows est activé.

**Conteneur Kubelet**

* **Processeur**:
* **Demande**: `100m`
* **Mémoire**:
* **Demande**: `150M`
* **Limite**: `300M`

**Agent conteneur**

* **Processeur**:
* **Demande**: `100m`
* **Mémoire**:
* **Demande**: `150M`
* **Limite**: `300M`

### [Composant métrique de l&apos;état de Kube](https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-ksm)

**Conteneur KSM**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `850M`

**Conteneur transitaire**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `850M`

### [composant du plan de contrôle](https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#nrk8s-kubelet)

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

**Agent conteneur**

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `150M`
  * **Limite**: `300M`

Voici les requests de ressources recommandées et les limites requises par d&apos;autres composants déployés dans le cadre du [nri-bundle](https://docs.newrelic.com/docs/kubernetes-pixie/kubernetes-integration/get-started/kubernetes-components/#components)

### [injectionméta](https://github.com/newrelic/k8s-metadata-injection/tree/main/charts/nri-metadata-injection)

* **Processeur**:
  * **Demande**: `100m`

* **Mémoire**:

  * **Demande**: `30M`
  * **Limite**: `80M`

### [Enregistrement](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging)

Les conteneurs suivants sont inclus dans le pod de logging New Relic déployé dans chaque nœud.

* **Processeur**:

  * **Demande**: `250m`
  * **Limite**: `500m`

* **Mémoire**:

  * **Demande**: `64M`
  * **Limite**: `128M`

### Considérations

* **Taille de Cluster **: ces recommandations de ressources concernent les tailles cluster typiques. Un cluster plus grand avec plus de nœuds et de pods peut nécessiter des allocations de ressources accrues pour gérer le volume de données supplémentaire.

* **Configuration personnalisée**: si vous activez une fonctionnalité supplémentaire ou une configuration personnalisée, pensez à ajuster les ressources en conséquence.

* **Monitoring et ajustement**: Après le déploiement, monitorez l&apos;utilisation des ressources de ces pods et ajustez les requests et les limites en fonction de l&apos;utilisation réelle pour optimiser les performances et les coûts.

Ces spécifications de ressources peuvent être ajustées dans le fichier `values.yaml` du graphique Helm utilisé pour déployer l&apos;intégration New Relic Kubernetes. En garantissant que ces exigences en matière de ressources sont satisfaites, vous pouvez maintenir monitoring efficace et efficiente de votre cluster Kubernetes avec New Relic.