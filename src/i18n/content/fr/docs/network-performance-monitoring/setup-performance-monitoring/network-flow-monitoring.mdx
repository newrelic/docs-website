---
title: Configurer monitoringdes données de flux réseau
tags:
  - Integrations
  - Network monitoring
  - Installation
  - Setup
metaDescription: Set up network flow data monitoring.
freshnessValidatedDate: never
translationType: machine
---

Vous pouvez utiliser notre processus d&apos;installation guidé pour installer l&apos;agent de monitoring du flux réseau ou installer l&apos;agent manuellement. Ce document couvre les prérequis pour démarrer ce processus d&apos;installation et une procédure étape par étape de vos options d&apos;installation.

## Prérequis [#prerequisites]

Avant de pouvoir commencer, vous devez [créer un compte New Relic](https://newrelic.com/signup). Si vous choisissez d&apos;installer l&apos;agent manuellement, vous avez également besoin de :

<Callout variant="important">
  #### Exigence de fuseau horaire

  Le serveur exécutant `ktranslate` **doit** être défini sur le fuseau horaire **UTC** . Si un fuseau horaire différent est configuré, cela peut entraîner des incohérences d&apos;horodatage et empêcher les données de s&apos;afficher correctement dans New Relic.
</Callout>

* Un [identifiant de compte](/docs/accounts/accounts-billing/account-setup/account-id) New Relic.
* Une New Relic <InlinePopover type="licenseKey" />.

<CollapserGroup>
  <Collapser id="docker" title="Prérequis Docker">
    Nous vous recommandons d&apos;utiliser un conteneur Docker pour déployer l&apos;agent de collecte de flux réseau. Pour l&apos;utiliser, vous aurez besoin de :

    * [Docker](https://docs.docker.com/engine/install) installé sur un hôte Linux
    * Possibilité de lancer un nouveau conteneur via ligne de commande
  </Collapser>

  <Collapser id="podman" title="Prérequis pour Podman">
    Si vous utilisez un conteneur Podman pour lancer l&apos;agent, vous avez besoin de :

    * [Podman](https://podman.io/docs/installation) installé sur un hôte Linux
    * Possibilité de lancer un nouveau conteneur via ligne de commande
  </Collapser>

  <Collapser id="linux" title="Prérequis pour l'hôte Linux">
    Si vous utilisez Linux pour installer l&apos;agent en tant que service, vous aurez besoin de :

    * Accès SSH à l&apos;hôte

    * Accès pour installer/supprimer des applications et des services

    * L&apos;un de ces systèmes d&apos;exploitation pris en charge :

      * CentOS 8
      * Debian 12 (Bookworm)
      * Debian 11 (Bullseye)
      * Debian 10 (Buster)
      * RedHat Enterprise Linux 9
      * Ubuntu 20.04 (Focal LTS)
      * Ubuntu 22.04 (Jammy LTS)
      * Ubuntu 23.04 (lunaire)
      * Ubuntu 24.04 (Noble LTS)
  </Collapser>

  <Collapser id="net-flow" title="Prérequis pour les périphériques de données de flux réseau">
    * Vous devez configurer les périphériques sources pour envoyer des données de flux à l&apos;hôte exécutant l&apos;agent monitoring du réseau. Voici comment configurer l’exportation du flux réseau sur certains appareils (cette liste n’est pas exhaustive) :

      * Données NetFlow

        * [Cisco - IOS](https://www.cisco.com/c/en/us/td/docs/ios/netflow/configuration/guide/12_2sr/nf_12_2sr_book/cfg_nflow_data_expt.html#wp1087069)
        * [Cisco-Meraki](https://documentation.meraki.com/MX/Monitoring_and_Reporting/NetFlow_Overview)
        * [Cisco - Système d&apos;exploitation NX](https://www.cisco.com/c/en/us/td/docs/switches/datacenter/nexus9000/sw/7-x/system_management/configuration/guide/b_Cisco_Nexus_9000_Series_NX-OS_System_Management_Configuration_Guide_7x/b_Cisco_Nexus_9000_Series_NX-OS_System_Management_Configuration_Guide_7x_chapter_011100.html#task_52D8A0952B06404197D2536B6E33EE80)
        * [Fortinet Fortigate](https://kb.fortinet.com/kb/documentLink.do?externalID=FD36460)
        * [Palo Alto - PAN-OS](https://docs.paloaltonetworks.com/pan-os/8-1/pan-os-admin/monitoring/netflow-monitoring/configure-netflow-exports)

      * Données sFlow
        * [F5 - BIG-IP](https://techdocs.f5.com/kb/en-us/products/big-ip_ltm/manuals/product/bigip-external-monitoring-implementations-12-0-0/15.html)

      * Données jFlow
        * [Genévrier - Junos](https://www.juniper.net/documentation/us/en/software/junos/flow-monitoring/flow-monitoring.pdf)
  </Collapser>

  <Collapser id="net-sec" title="Prérequis de sécurité du réseau">
    Vérifiez les [conditions préalables de sécurité du réseau pour le flux réseau](/install/npm).
  </Collapser>
</CollapserGroup>

## Types de données de flux réseau pris en charge [#supported-network-flow-data-types]

monitoring du flux réseau prend en charge les quatre principaux types de données de flux réseau et leurs dérivés. Lors de l&apos;exécution de l&apos;agent, vous pouvez spécifier le type majeur que vous souhaitez monitorer à l&apos;aide de l&apos;option `-nf.source` .

<Callout variant="tip">
  La collection de modèles `NetFlow v5`, `NetFlow v9`, `sFlow` et `IPFIX` peut être gérée à l&apos;aide de `-nf.source.=auto` sur un seul agent. Cette option est activée par défaut lors de l&apos;utilisation de l&apos;argument `nr1.flow` au moment de l&apos;exécution.
</Callout>

<Collapser id="flow-types" title="Types de flux de réseau">
  <table>
    <thead>
      <tr>
        <th style={{ width: '300px' }}>
          Type de flux réseau
        </th>

        <th>
          Activé avec `auto`?
        </th>

        <th>
          `-nf.source` valeur
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <td>
          AppFlow
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          Argus
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          Cisco ASA
        </td>

        <td />

        <td>
          `asa`
        </td>
      </tr>

      <tr>
        <td>
          Cisco NBAR
        </td>

        <td />

        <td>
          `nbar`
        </td>
      </tr>

      <tr>
        <td>
          cflowd
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          IPFIX
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `ipfix`
        </td>
      </tr>

      <tr>
        <td>
          J-Flow
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          NetFlow v5
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          NetFlow v9
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow9`
        </td>
      </tr>

      <tr>
        <td>
          NetStream
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          Palo Alto Networks
        </td>

        <td />

        <td>
          `pan`
        </td>
      </tr>

      <tr>
        <td>
          Flux RF
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `netflow5`
        </td>
      </tr>

      <tr>
        <td>
          sFlow
        </td>

        <td>
          ✓
        </td>

        <td>
          `auto` | `sflow`
        </td>
      </tr>
    </tbody>
  </table>
</Collapser>

## Quand faut-il dimensionner la collecte de flux réseau ? [#scale]

Lors de la planification de votre stratégie de collecte des flux réseau à grande échelle, les éléments suivants doivent être pris en compte :

* L&apos;agent `ktranslate` ne peut effectuer qu&apos;une seule tâche à la fois. Un agent exécutant une collecte SNMP ne peut pas également écouter les flux réseau.
* L&apos;agent `ktranslate` ne peut écouter les flux réseau entrants que sur un seul port d&apos;écoute à la fois (par défaut : `9995`). Si vous souhaitez que plusieurs ports soient ouverts, chacun nécessite un agent dédié, en utilisant l&apos;option de configuration [-nf.port](/docs/network-performance-monitoring/advanced/ktranslate-container-management/#container-runtime-options) lors de l&apos;exécution pour modifier le port.
* La configuration par défaut `-nf.source=auto` permet au conteneur d&apos;écouter plusieurs types de flux standard. Si vous devez analyser d&apos;autres types de données de flux comme les modèles Cisco ASA, Cisco NBAR ou Palo Alto Networks, chacun nécessitera son propre agent.
* New Relic recommande 1 CPU pour 2 000 flux par seconde (120 000 flux par minute). Déterminer s&apos;il faut faire évoluer horizontalement plusieurs agents pour répartir la charge ou faire évoluer verticalement quelques agents plus grands pour consolider la gestion est une question de préférence personnelle.

## Configurer monitoringdes données de flux réseau [#setup-network-flow-monitoring]

Pour la plupart des cas d&apos;utilisation, nous recommandons notre guide d&apos;installation pour configurer monitoring des données de flux réseau. Si votre configuration est plus avancée avec des configurations personnalisées, nous vous recommandons de l&apos;installer manuellement.

<CollapserGroup>
  <Collapser id="guided-install-setup" title="Configuration de l'installation guidée">
    1. Aller à <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; Add more data**</DNT>

    2. Faites défiler vers le bas jusqu’à ce que vous voyiez <DNT>**Network**</DNT> et cliquez sur <DNT>**Network Flows**</DNT>.

    3. Suivez les étapes décrites dans le processus d’installation guidée. Vous pouvez utiliser Docker, Podman ou Linux.

       <ButtonLink role="button" to="https://one.newrelic.com/nr1-core?state=01bc12b8-758e-cc28-a93f-a93970485d99" variant="primary">
         Ajouter des données de flux réseau
       </ButtonLink>

       <img title="Network Flows guided setup" alt="Network Flows guided setup" src="/images/network_screenshot-full_network-flows-guided-install.webp" />

       <figcaption>
         <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/ll-capabilities) &gt; Add more data &gt; Network &gt; Network Flows**</DNT> pour mettre en place monitoring des données de flux réseau.
       </figcaption>

    4. Examinez vos données de flux réseau dans l&apos;interface utilisateur New Relic <InlinePopover type="networkMonitoring" />.
  </Collapser>

  <Collapser id="manual-container-setup" title="Configuration manuelle du conteneur">
    Avant de lire l&apos;article sur l&apos;installation manuelle de l&apos;agent de flux réseau, pensez à utiliser notre processus d&apos;installation guidée pour éviter les erreurs :

    <ButtonLink role="button" to="https://one.newrelic.com/nr1-core?state=01bc12b8-758e-cc28-a93f-a93970485d99" variant="primary">
      Ajouter des données de flux réseau
    </ButtonLink>

    <Tabs>
      <TabsBar>
        <TabsBarItem id="dockerInstall">
          Conteneur Docker
        </TabsBarItem>

        <TabsBarItem id="podmanInstall">
          Conteneur Podman
        </TabsBarItem>

        <TabsBarItem id="linuxInstall">
          Service Linux
        </TabsBarItem>
      </TabsBar>

      <TabsPages>
        <TabsPageItem id="dockerInstall">
          1. Sur un hôte Linux avec Docker installé, téléchargez l’image <DNT>**ktranslate**</DNT> en exécutant l’une des opérations suivantes :

             * [Centre Docker](https://hub.docker.com/):
               ```shell
               docker pull kentik/ktranslate:v2
               ```
             * [Quay.io](https://quay.io/):
               ```shell
               docker pull quay.io/kentik/ktranslate:v2
               ```

          2. Copiez le fichier `snmp-base.yaml` dans le répertoire local `$HOME` de votre utilisateur Docker et supprimez le conteneur en exécutant :

             ```shell
             cd ~
             id=$(docker create kentik/ktranslate:v2)
             docker cp $id:/etc/ktranslate/snmp-base.yaml .
             docker rm -v $id
             ```

          3. Modifiez le fichier `snmp-base.yaml` et ajoutez vos périphériques de flux réseau dans la clé de dictionnaire `devices` avec la structure suivante :

             ```yaml
             devices:
               # This key and the corresponding 'device_name'
               # need to be unique for each device
               flow_device1:
                 device_name: flow_device1
                 device_ip: x.x.x.x/yy
                 flow_only: true
                 # Optional user tags
                 user_tags:
                   owning_team: net_eng
                   environment: production
             ```

             <Callout variant="important">
               Si vous monitoring déjà des périphériques de données SNMP qui enverront également des flux réseau, vous souhaiterez vous assurer que la valeur de `device_name` est identique pour les deux fichiers configuration afin de garantir que la télémétrie du flux est attribuée à la bonne entité dans l&apos;interface utilisateur de New Relic.
             </Callout>

          4. Exécutez `ktranslate` pour écouter les flux réseau avec la commande :

             ```shell
             docker run -d --name ktranslate-$CONTAINER_SERVICE \
               --restart unless-stopped --pull=always --net=host \
               -v `pwd`/snmp-base.yaml:/snmp-base.yaml \
               -e NEW_RELIC_API_KEY=$YOUR_NR_LICENSE_KEY \
               kentik/ktranslate:v2 \
               -snmp /snmp-base.yaml \
               -nr_account_id=$YOUR_NR_ACCOUNT_ID \
               -metrics=jchf \
               -tee_logs=true \
               # Use this field to create a unique value for `tags.container_service` inside of New Relic
               -service_name=$CONTAINER_SERVICE \
               -flow_only=true \
               nr1.flow
             ```

          5. Examinez vos données de flux réseau dans l&apos;interface utilisateur New Relic <InlinePopover type="networkMonitoring" />.
        </TabsPageItem>

        <TabsPageItem id="podmanInstall">
          1. Sur un hôte sur lequel Podman est installé, téléchargez l&apos;image <DNT>**ktranslate**</DNT> en exécutant la commande suivante :

             * [Centre Docker](https://hub.docker.com/):
               ```shell
               podman pull docker.io/kentik/ktranslate:v2
               ```

          2. Copiez le fichier `snmp-base.yaml` dans le répertoire local `$HOME` de votre utilisateur Podman et supprimez le conteneur en exécutant :

             ```shell
             cd ~
             id=$(podman create kentik/ktranslate:v2)
             podman cp $id:/etc/ktranslate/snmp-base.yaml .
             podman rm -v $id
             ```

          3. Modifiez le fichier `snmp-base.yaml` et ajoutez vos périphériques de flux réseau dans la clé de dictionnaire `devices` avec la structure suivante :

             ```yaml
             devices:
               # This key and the corresponding 'device_name'
               # need to be unique for each device
               flow_device1:
                 device_name: flow_device1
                 device_ip: x.x.x.x/yy
                 flow_only: true
                 # Optional user tags
                 user_tags:
                   owning_team: net_eng
                   environment: production
             ```

             <Callout variant="important">
               Si vous monitoring déjà des périphériques de données SNMP qui enverront également des flux réseau, vous souhaiterez vous assurer que la valeur de `device_name` est identique pour les deux fichiers configuration afin de garantir que la télémétrie du flux est attribuée à la bonne entité dans l&apos;interface utilisateur de New Relic.
             </Callout>

          4. Exécutez `ktranslate` pour écouter les flux réseau avec la commande :

             ```shell
             podman run -d --name ktranslate-$CONTAINER_SERVICE \
               --userns=keep-id --restart unless-stopped --pull=always --net=host \
               -v `pwd`/snmp-base.yaml:/snmp-base.yaml \
               -e NEW_RELIC_API_KEY=$YOUR_NR_LICENSE_KEY \
               kentik/ktranslate:v2 \
               -snmp /snmp-base.yaml \
               -nr_account_id=$YOUR_NR_ACCOUNT_ID \
               -metrics=jchf \
               -tee_logs=true \
               # Use this field to create a unique value for `tags.container_service` inside of New Relic
               -service_name=$CONTAINER_SERVICE \
               -flow_only=true \
               nr1.flow
             ```

             <Callout variant="tip">
               Les conteneurs Podman sans racine ne peuvent pas se lier aux ports inférieurs à 1024. Si vos flux réseau sont envoyés sur un port inférieur à 1024 au lieu de la valeur par défaut (9995), vous devrez créer une règle `iptables` pour gérer la redirection de paquets avec la commande :

               ```shell
               sudo iptables -t nat -A PREROUTING -p udp --dport $srcPort -j REDIRECT --to-port 9995
               ```
             </Callout>

          5. Examinez vos données de flux réseau dans l&apos;interface utilisateur New Relic <InlinePopover type="networkMonitoring" />.
        </TabsPageItem>

        <TabsPageItem id="linuxInstall">
          1. En fonction de votre gestionnaire de paquets, utilisez l&apos;une des commandes ci-dessous pour installer `ktranslate`

          * Yum:
            ```shell
            curl -s https://packagecloud.io/install/repositories/kentik/ktranslate/script.rpm.sh | sudo bash && \
              sudo yum install ktranslate
            ```
          * Apt:
            ```shell
            curl -s https://packagecloud.io/install/repositories/kentik/ktranslate/script.deb.sh | sudo bash && \
              sudo apt-get install ktranslate
            ```

          2. Définir les variables d’environnement utilisées par `ktranslate`:

             ```shell
             sudo tee "/etc/default/ktranslate.env" > /dev/null <<'EOF'
             NR_ACCOUNT_ID=$YOUR_NR_ACCOUNT_ID
             NEW_RELIC_API_KEY=$YOUR_NR_LICENSE_KEY
             KT_FLAGS="-snmp /etc/ktranslate/snmp-base.yaml \
               -metrics=jchf \
               -flow_only=true \
               -tee_logs=true \
               -service_name=$CONTAINER_SERVICE \
               nr1.flow"
             EOF

             # ensure /etc/default/ktranslate.env is owned by ktranslate user
             sudo chown ktranslate:ktranslate /etc/default/ktranslate.env
             ```

          3. Si vous n&apos;avez pas de fichier de configuration `snmp-base.yaml` existant, créez-en un avec :

             ```shell
             cd ~
             touch snmp-base.yaml
             ```

          4. Modifiez le fichier `snmp-base.yaml` et ajoutez vos périphériques de flux réseau dans la clé de dictionnaire `devices` avec la structure suivante :

             ```yaml
             devices:
               # This key and the corresponding 'device_name'
               # need to be unique for each device
               flow_device1:
                 device_name: flow_device1
                 device_ip: x.x.x.x/yy
                 flow_only: true
                 # Optional user tags
                 user_tags:
                   owning_team: net_eng
                   environment: production
             ```

          5. Redémarrez le service `ktranslate` pour appliquer vos modifications au fichier `snmp-base.yaml` :

             ```shell
             sudo systemctl restart ktranslate
             ```

          6. Examinez vos données de flux réseau dans l&apos;interface utilisateur New Relic <InlinePopover type="networkMonitoring" />.
        </TabsPageItem>
      </TabsPages>
    </Tabs>
  </Collapser>
</CollapserGroup>

## Trouvez et utilisez vos métriques [#find-your-metrics]

Tous les logs de flux réseau exportés depuis le conteneur `ktranslate` utilisent l&apos;espace de nommage `KFlow` , via l&apos;[API d&apos;événement New Relic](/docs/telemetry-data-platform/ingest-apis/introduction-event-api). Actuellement, voici les champs par défaut renseignés à partir de cette intégration :

<CollapserGroup>
  <Collapser id="kflow-fields-collapser" title="Champs KFlow">
    <table>
      <thead>
        <tr>
          <th style={{ width: '150px' }}>
            Attribut
          </th>

          <th style={{ width: '150px' }}>
            Type
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `application`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            La classe du programme générant le trafic dans cet enregistrement de flux. Ceci est dérivé de la valeur numérique la plus basse entre `l4_dst_port` et `l4_src_port`. Les exemples courants incluent `http`, `ssh` et `ftp`.
          </td>
        </tr>

        <tr>
          <td>
            `device_name`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            Le nom d’affichage du dispositif d’échantillonnage pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `dst_addr`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            L&apos;adresse IP cible pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `dst_as`
          </td>

          <td>
            Numérique
          </td>

          <td>
            La cible \[Autonomous System Number]\([https://www.iana.org/assignments/](https://www.iana.org/assignments/) (comme-numéros/comme-numéros.xhtml) pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `dst_as_name`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            La cible \[Autonomous System Name]\([https://www.iana.org/assignments/](https://www.iana.org/assignments/) as-numbers/as-numbers.xhtml) pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `dst_endpoint`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            L&apos;uplet cible `IP:Port` pour cet enregistrement de flux. Il s’agit d’une combinaison de `dst_addr` et `l4_dst_port`.
          </td>
        </tr>

        <tr>
          <td>
            `dst_geo`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            Le pays cible de cet enregistrement de flux, s&apos;il est connu.
          </td>
        </tr>

        <tr>
          <td>
            `in_bytes`
          </td>

          <td>
            Numérique
          </td>

          <td>
            Le nombre d&apos;octets transférés pour les enregistrements de flux entrants.
          </td>
        </tr>

        <tr>
          <td>
            `in_pkts`
          </td>

          <td>
            Numérique
          </td>

          <td>
            Le nombre de paquets transférés pour les enregistrements de flux entrants.
          </td>
        </tr>

        <tr>
          <td>
            `input_port`
          </td>

          <td>
            Numérique
          </td>

          <td>
            `If_Index` valeur pour l&apos;interface à la source de cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `l4_dst_port`
          </td>

          <td>
            Numérique
          </td>

          <td>
            Le port cible pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `l4_src_port`
          </td>

          <td>
            Numérique
          </td>

          <td>
            Le port source de cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `output_port`
          </td>

          <td>
            Numérique
          </td>

          <td>
            `If_Index` valeur pour l&apos;interface à la destination de cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `protocol`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            Le nom d&apos;affichage du protocole utilisé dans cet enregistrement de flux, dérivé du \[numeric IANA protocol number]\([https://www.iana.org/assignments/](https://www.iana.org/assignments/) protocol-numbers/protocol-numbers.xhtml).
          </td>
        </tr>

        <tr>
          <td>
            `provider`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            Cet attribut est utilisé pour identifier de manière unique différentes sources de données de `ktranslate`. Le log de flux réseau aura toujours la valeur `kentik-flow-device`.
          </td>
        </tr>

        <tr>
          <td>
            `sample_rate`
          </td>

          <td>
            Numérique
          </td>

          <td>
            Taux d&apos;échantillonnage appliqué soit par la configuration du périphérique d&apos;échantillonnage, soit par l&apos;argument `sample_rate` dans `ktranslate`.
          </td>
        </tr>

        <tr>
          <td>
            `src_addr`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            L&apos;adresse IP source de cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `src_as`
          </td>

          <td>
            Numérique
          </td>

          <td>
            La source \[Autonomous System Number]\([https://www.iana.org/assignments/](https://www.iana.org/assignments/) as-numbers/as-numbers.xhtml) pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `src_as_name`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            La source \[Autonomous System Name]\([https://www.iana.org/assignments/](https://www.iana.org/assignments/) as-numbers/as-numbers.xhtml) pour cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `src_endpoint`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            L&apos;uplet source `IP:Port` pour cet enregistrement de flux. C&apos;est une combinaison de `src_addr` et `l4_src_port`.
          </td>
        </tr>

        <tr>
          <td>
            `src_geo`
          </td>

          <td>
            Chaîne
          </td>

          <td>
            Le pays source de cet enregistrement de flux, s&apos;il est connu.
          </td>
        </tr>

        <tr>
          <td>
            `tcp_flags`
          </td>

          <td>
            Numérique
          </td>

          <td>
            Drapeaux TCP dans cet enregistrement de flux.
          </td>
        </tr>

        <tr>
          <td>
            `timestamp`
          </td>

          <td>
            Numérique
          </td>

          <td>
            L&apos;heure, en secondes Unix, à laquelle cet enregistrement de flux a été reçu par l&apos;API d&apos;événement New Relic.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

<InstallFeedback />

## Quelle est la prochaine étape ?

Vous pouvez configurer des agents supplémentaires pour compléter vos données de flux réseau :

* Pour obtenir une meilleure visibilité sur les performances de votre périphérique réseau, [configurez le monitoring des données SNMP](/docs/network-performance-monitoring/setup-performance-monitoring/snmp-performance-monitoring).
* Pour obtenir une meilleure visibilité sur les messages syslog de votre réseau, [configurez le monitoring syslog du réseau](/docs/network-performance-monitoring/setup-performance-monitoring/network-syslog-monitoring).