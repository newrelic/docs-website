---
title: Métriques cumulées (OTel et Prometheus)
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
metaDescription: How New Relic handles cumulative metrics from OpenTelemetry and Prometheus.
freshnessValidatedDate: never
translationType: machine
---

export const year = 2023;
export const gaDate = 'April 4';
export const gaDateAndYear = gaDate + ', ' + year;

Si vous signalez des métriques cumulatives à partir de [notre intégration OpenTelemetry ](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-introduction)ou de notre [intégration d&apos;écriture à distancePrometheus ](/docs/infrastructure/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration), cela vous aidera à comprendre comment New Relic gère ces données (par exemple, comment nous les convertissons en mesures delta). Cela vous aidera à comprendre les vues de votre UI New Relic, à interroger vos données et à comprendre les problèmes de reporting des données.

## Explication des mesures cumulatives et delta [#explained]

Lors de la collecte de données métriques à partir d&apos;une application, il est important de prendre en compte *la manière dont* ces données ont été mesurées au moment de décider comment les utiliser et les interpréter au moment de la requête. Le [type de métrique](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) est un facteur important, certaines fonctions d&apos;agrégation New Relic fonctionnant avec certains types et pas avec d&apos;autres. Mais un autre facteur important est le <DNT>**temporality**</DNT> de la métrique.

Les deux temporalités sont <DNT>**delta**</DNT> et <DNT>**cumulative**</DNT>. `Delta` indique que les mesures sont réinitialisées entre les intervalles de rapport. `Cumulative` indique qu&apos;il n&apos;y a pas de réinitialisation et que les mesures sont accumulées. Prometheus est un exemple courant de collecteur de métriques cumulatives ([documentation Prometheus sur les types de données](https://prometheus.io/docs/concepts/metric_types)), et OpenTelemetry définit également des moyens de collecter des métriques cumulatives ([documentation OpenTelemetry sur la temporalité](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#temporality)).

New Relic prend en charge les données cumulatives Prometheus et OpenTelemetry et effectuera une conversion delta lors de l&apos;ingestion pour les rendre plus alignées avec d&apos;autres métriques sur notre plateforme et plus faciles à interagir avec ces données via [NRQL](/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language). Les compteurs cumulatifs sont stockés sous la forme de New Relic[`cumulativeCount`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) et l&apos;histogramme cumulatif est stocké sous la forme de New Relic [`distribution`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types).

## Prise en charge de l&apos;écriture à distance de Prometheus [#prom-support]

Pour plus d&apos;informations, voir [Intégration de l&apos;écriture à distancePrometheus ](/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic).

## Prise en charge d&apos;OpenTelemetry [#otel-support]

Pour en savoir plus sur le support OpenTelemetry, voir [OpenTelemetry métriques : bonnes pratiques](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-metrics).

## Détails de conversion cumulatif en delta [#delta-conversion]

À un niveau élevé, la conversion delta est effectuée en prenant deux points de données séquentiels dans le temps de l&apos;événement et en calculant une différence. Mais dans la pratique, les choses ne sont jamais aussi simples. Voici quelques scénarios courants que nous anticipons et comment nous les gérons.

### Réinitialisations [#resets]

Si les données d&apos;une [série temporelle](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#timeseries-model) diminuent soudainement en valeur, nous traitons cela comme une réinitialisation et émettrons cette nouvelle mesure comme sa propre valeur delta (en d&apos;autres termes, comme si elle était précédée d&apos;une mesure `0` ).

[OpenTelemetry définit également](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#resets-and-gaps) les situations dans lesquelles une diminution de valeur est inattendue, et nous faisons de notre mieux pour détecter ces cas et vous avertir via [des erreurs d&apos;intégration New Relic](/docs/data-apis/manage-data/nrintegrationerror) (voir [le dépannage](#troubleshooting) ci-dessous).

### Réorganiser les données [#reorder-data]

Nous comprenons que de nombreux facteurs peuvent entraîner l&apos;arrivée de points de données dans le désordre dans New Relic. Ainsi, nous mettrons en mémoire tampon les points de données et les réorganiserons si nous détectons un écart inattendu dans la série chronologique des rapports. Les lacunes sont déduites d’un intervalle de rapport prévu déterminé par la vitesse à laquelle nous recevons des données pour une série chronologique donnée. La mise en mémoire tampon est limitée et nous finirons par considérer qu&apos;un point de données est « trop tard pour le reséquençage ». Dans ce cas, un delta est calculé sur l&apos;écart détecté et le traitement de la série temporelle se poursuit.

### Données obsolètes [#stale-data]

La conversion delta étant une opération à état, nous devons être conscients des séries temporelles qui peuvent cesser de produire des rapports et éventuellement abandonner leur état. Si une série chronologique n&apos;a signalé aucun nouveau point de données pour <DNT>**5 minutes**</DNT>, nous viderons l&apos;état dont nous disposons, y compris le calcul des deltas sur les éventuels écarts mis en mémoire tampon. Cela signifie que si un point de données arrive à un moment ultérieur, il sera traité comme s&apos;il s&apos;agissait du début de cette série chronologique, perdant ainsi efficacement le delta entre le dernier point de données avant le vidage et le premier point de données après le vidage. Cela signifie que les intervalles de rapport métrique doivent être inférieurs à <DNT>**5 minutes**</DNT> pour bénéficier de la conversion delta.

### Remarque spéciale sur les sommes cumulées [#cumulative-sums]

Même si les données ont été enregistrées par votre application et envoyées sous la forme d&apos;une séquence de valeurs croissantes de façon monotone, l&apos;appel de `sum()` les traitera comme s&apos;il s&apos;agissait d&apos;une séquence de valeurs delta ; pas besoin de calculer de `derivative()`!

Lors de la conversion d&apos;une somme en delta, New Relic émettra également la valeur cumulée à côté du delta pour vous permettre d&apos;interroger la dernière valeur cumulée. Pour accéder à la valeur cumulée, vous pouvez utiliser [`getField()`](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#func-getfield) (voir [Comment interroger les métriques](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-metrics/#query) pour des exemples).

Notez que les points de données sont tracés à leurs `timestamps` associés qui sont le début d&apos;un intervalle. Cependant, les valeurs cumulatives sont associées au `endTimestamp` du point de données, vous devrez donc peut-être prendre en compte la largeur d&apos;un point de données lors de l&apos;interprétation de la requête cumulative.

## Dépannage [#troubleshooting]

Dans certains cas, nous signalerons une [erreur d&apos;intégration New Relic](/docs/data-apis/manage-data/nrintegrationerror) suite au processus de conversion cumulative en delta. Voici quelques raisons courantes.

### Erreurs de traduction [#translation-errors]

La conversion delta implique l&apos;hypothèse selon laquelle deux points de données séquentiels dans le temps de l&apos;événement auront des valeurs cumulatives augmentant de manière monotone. Le seul moment où cette hypothèse est censée être rompue est lorsque le processus monitoré est redémarré. Si la monotonie est rompue pour une autre raison, nous traiterons toujours cela comme une réinitialisation, mais nous tenterons de vous en informer en générant un événement [d&apos;erreur d&apos;intégration New Relic](/docs/data-apis/manage-data/nrintegrationerror) dans votre compte. Ceci est possible pour les données OpenTelemetry <DNT>**but not Prometheus**</DNT>, car OpenTelemetry inclut davantage d&apos;informations qui peuvent être utilisées pour détecter de telles situations. La cause la plus courante d&apos;une rupture inattendue de la monotonie survient lorsque l&apos;application côté client atteint les limites de cardinalité et supprime des données pour soulager la pression de la mémoire. Dans certains cas, cela agit comme une réinitialisation inattendue et peut entraîner une diminution inattendue des valeurs envoyées à New Relic. Il est recommandé de rechercher un exemple de ceci dans votre log OTLP :

```
Instrument % has exceeded the maximum allowed accumulations (2000)
```

Le SDK OpenTelemetry vous permet de [configurer ses limites de cardinalité](https://opentelemetry.io/docs/specs/otel/metrics/sdk/#cardinality-limits). OpenTelemetry fournit également un moyen de réduire la cardinalité côté client en utilisant [<DNT>**Views**</DNT>](https://opentelemetry.io/docs/reference/specification/metrics/sdk/#view) et constitue le chemin recommandé pour résoudre ces problèmes. Une autre option consiste à explorer l’exportation de vos [métriques OTLP à l’aide de la temporalité Delta,](https://opentelemetry.io/docs/reference/specification/metrics/sdk_exporters/otlp/#additional-configuration) ce qui peut vous aider à économiser de la mémoire.

### Limites de cardinalité [#card-limits]

Lors de la traduction, nous appliquons également des limites de cardinalité métrique basées sur vos droits métriques en tant que protection du système. Plutôt que d&apos;appliquer la limite [par jour, comme nous le faisons avec les cumuls](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes/#incident-unique-timeseries), cette limite est appliquée en fonction du nombre de séries chronologiques simultanées suivies. Une fois qu&apos;il y a trop [de séries temporelles métriques uniques](/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/#what-why) simultanées, nous abandonnerons les nouvelles séries temporelles entrantes jusqu&apos;à ce qu&apos;une ancienne soit obsolète (voir [Données obsolètes](#stale-data)).

### Réinitialisations métriques cumulatives [#cumulative-resets]

Les réinitialisations métriques cumulatives se produisent généralement lorsque le service ou l&apos;application qui les signale redémarre. Lors de l&apos;interrogation d&apos;une métrique qui a été réinitialisée, il peut sembler que la valeur de la métrique a diminué, mais il s&apos;agit d&apos;un comportement attendu tel que décrit dans la [spécification de métrique OpenTelemetry](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#resets-and-gaps). Pour faire la différence entre les réinitialisations métriques normales et une métrique problématique qui diminue <DNT>**is**</DNT> manière inattendue, vérifiez votre compte pour détecter d&apos;éventuelles [erreurs d&apos;intégration New Relic](/docs/data-apis/manage-data/nrintegrationerror). Si aucune erreur d&apos;intégration n&apos;est signalée par rapport aux métriques avec des valeurs décroissantes, il est probable que votre application signalant les métriques cumulatives redémarre et réinitialise la valeur de la métrique.