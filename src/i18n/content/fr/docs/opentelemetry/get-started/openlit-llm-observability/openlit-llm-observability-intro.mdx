---
title: Observabilité LLM avec OpenLIT
tags:
  - Integrations
  - LLM observability with OpenTelemetry
  - GenAI Observability with OpenTelemetry
  - OpenTelemetry
  - OpenLIT
metaDescription: Set up OpenTelemetry-based LLM observability with New Relic and OpenLIT.
freshnessValidatedDate: '2024-10-08T00:00:00.000Z'
translationType: machine
---

Bien OpenTelemetry offre une norme puissante pour la collecte de données d&apos;application générales (trace, métriques, log), il lui manque la capacité de capturer des indicateurs de performances clés (KPI) spécifiques au modèle d&apos;IA. Les mesures essentielles telles que le suivi des performances, l&apos;utilisation des jetons, les coûts et les données d&apos;interaction des utilisateurs sous forme d&apos;invites et de réponses LLM sont cruciales pour monitoring efficace des applications LLM et un dépannage.

Pour combler cette lacune dans l’observabilité du LLM, OpenLIT est apparu comme une solution sur mesure. Construit sur le framework OpenTelemetry, OpenLIT est un outil open source qui s&apos;intègre parfaitement et étend ses capacités. Il prend en charge les frameworks d&apos;IA largement utilisés tels que OpenAI, Anthropic, Pinecone, LangChain, entre autres. De plus, il fournit des capacités de monitoring GPU prêtes à l&apos;emploi basées sur OpenTelemetry.

Principaux avantages d’OpenLIT :

* **Monitoring avancé des performances de LLM et VectorDB**: OpenLIT génère automatiquement des traces et des métriques pour une analyse approfondie des performances et des coûts de l&apos;utilisation de LLM et VectorDB, vous aidant à optimiser l&apos;utilisation des ressources et à évoluer efficacement dans divers environnements, tels que la production.

* **Suivi des coûts pour les modèles personnalisés et affinés**: permet un suivi précis des coûts via un fichier JSON personnalisé, permettant une budgétisation précise et un alignement avec les besoins spécifiques du projet.

* **OpenTelemetry- SDK natif et sans fournisseur associé**: OpenLIT est conçu avec un support natif pour OpenTelemetry, ce qui lui permet de s&apos;intégrer parfaitement à vos projets. Cette approche sans fournisseur associé réduit les obstacles à l’intégration, faisant d’OpenLIT une partie intuitive de votre stack logicielle plutôt qu’une complexité supplémentaire.

OpenLIT permet aux développeurs d&apos;exploiter les atouts d&apos;OpenTelemetry tout en acquérant les fonctionnalités supplémentaires requises pour monitoring efficace du LLM et une optimisation des performances.

## Avant de commencer [#prereqs]

* [Créez](https://newrelic.com/signup) un compte New Relic.
* Obtenez la [clé de licence](https://one.newrelic.com/launcher/api-keys-ui.launcher) pour le compte New Relic auquel vous souhaitez signaler des données.

## instrumentez votre modèle LLM avec OpenLIT [#instrument]

Suivez ces étapes de configuration courantes pour OpenTelemetry APM monitoring basée sur avec New Relic.

<Steps>
  <Step>
    ### Acheminer la trace et les métriques [#route-traces]

    Étant donné que New Relic prend en charge nativement OpenTelemetry, il vous suffit d&apos;acheminer la trace et les métriques vers le point de terminaison de New Relic et de définir la clé API.

    Exécutez les commandes suivantes pour que l&apos;exportateur [OpenTelemetry Protocol](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md) (OTLP en abrégé) envoie des données au [point de terminaison New Relic OTLP](/docs/opentelemetry/best-practices/opentelemetry-otlp).

    ```env
    OTEL_EXPORTER_OTLP_ENDPOINT = https://otlp.nr-data.net:443
    OTEL_EXPORTER_OTLP_HEADERS = "api-key=YOUR_NEWRELIC_LICENSE_KEY"
    ```

    Voir cet exemple sur le modèle OpenAI LLM avec LangChain :

    ```python
    import openlit
    import os
    from langchain_openai import ChatOpenAI

    os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'
    os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = 'https://otlp.nr-data.net:443'
    os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = 'api-key=YOUR_NEWRELIC_LICENSE_KEY'

    openlit.init()

    def add_prompt_context():
      llm = ChatOpenAI(
          model="gpt-3.5-turbo",
          temperature=0)
      chain = llm
      return chain

    def prep_prompt_chain():
      return add_prompt_context()

    def prompt_question():
      chain = prep_prompt_chain()
      return chain.invoke("explain the business of company Newrelic and it's advantages in a max of 50 words")

    if  __name__ == "__main__":
      print(prompt_question())
    ```
  </Step>

  <Step>
    ## Affichez vos données dans l&apos;interface utilisateur de New Relic [#view-data]

    Une fois votre application instrumentée et configurée pour exporter des données vers New Relic, vous devriez pouvoir retrouver vos données dans l&apos;interface utilisateur de New Relic. Vous pouvez importer le dashboard pré-construit d&apos;observabilité LLM en suivant ces étapes :

    1. Allez à <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; Dashboards**</DNT>.

    2. Dans le coin supérieur droit, cliquez sur <DNT>**Import dashboard**</DNT>.

    3. Copiez le dashboard JSON fourni [ici](https://docs.openlit.io/latest/connections/new-relic#dashboard) et collez-le.

    4. Choisissez les paramètres de compte et d&apos;autorisation pour le dashboard. Vous ne pouvez pas modifier le compte une fois que vous l&apos;avez configuré, mais vous pouvez modifier les autorisations à tout moment.

    5. Cliquez sur <DNT>**Import dashboard**</DNT>.

    Si vous ne trouvez pas votre entité et ne voyez pas vos données avec NRQL, consultez [le dépannage OTLP](/docs/opentelemetry/best-practices/opentelemetry-otlp-troubleshooting).

    <InstallFeedback />
  </Step>
</Steps>