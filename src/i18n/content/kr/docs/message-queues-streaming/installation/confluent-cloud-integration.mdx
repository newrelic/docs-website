---
title: Confluent 클라우드 통합
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

뉴렐릭은 [아파치 Kafka 데이터에 대한 Confluent Cloud 관리형 스트리밍을](https://www.confluent.io/confluent-cloud/) 수집하기 위한 통합을 제공합니다. 이 문서에서는 이러한 통합을 활성화하는 방법과 보고할 수 있는 데이터에 대해 설명합니다.

## 전제 조건

* 뉴렐릭 계정
* 활성화된 Confluent Cloud 계정
* Confluent Cloud API 키 및 비밀
* `MetricsViewer` Confluent Cloud 계정에 액세스

## 통합 활성화 [#activate]

이 통합을 활성화하려면 <DNT>**Integrations &amp; Agents**</DNT> 로 이동하여 <DNT>**Confluent Cloud -&gt; API Polling**</DNT> 선택하고 지침을 따르세요.

<Callout variant="important">
  IP 필터링을 설정한 경우 다음 IP 주소를 필터에 추가하세요.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  클라우드 통합을 위한 뉴렐릭 IP 범위에 대한 자세한 내용은 [이 문서를](/docs/new-relic-solutions/get-started/networks/#webhooks) 참조하세요. 이 작업을 수행하기 위한 지침은 [이 문서를](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html) 참조하세요.
</Callout>

## 구성 및 폴링 [#polling]

Confluent Cloud Kafka 통합을 위한 기본 폴링 정보:

* New Relic 폴링 간격: 5분
* Confluent Cloud 데이터 간격: 1분

폴링 빈도는 초기 설정에서만 변경할 수 있습니다.

## 데이터 보기 및 사용 [#find-data]

다음 [이벤트](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels) 유형을 [사용하여 데이터를 쿼리하고 탐색 할](/docs/using-new-relic/data/understand-data/query-new-relic-data) 수 있습니다.

<table>
  <thead>
    <tr>
      <th>
        실재
      </th>

      <th>
        데이터 형식
      </th>

      <th>
        공급자
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        무리
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        커넥터
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        ksql
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

데이터 사용 방법에 대한 자세한 내용은 [통합 데이터 이해 및 사용](/docs/infrastructure/integrations/find-use-infrastructure-integration-data) 을 참조하십시오.

## 측정항목 데이터 [#metrics]

이 통합은 클러스터, 커넥터 및 ksql에 대한 Confluent cloud Kafka 데이터를 기록합니다.

### 클러스터 데이터

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        미터법
      </th>

      <th style={{ width: "150px" }}>
        유닛
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        클러스터 활용도 측정. 값은 0.0과 1.0 사이입니다. 전용 타이어 클러스터에만 이 인덱스 데이터가 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        유입 처리량으로 인해 핫 파티션이 존재함을 나타내는 지표입니다. 핫 파티션이 감지되면 값은 1.0이고, 핫 파티션이 감지되지 않으면 값은 비어 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        이탈 처리량으로 인해 핫 파티션이 존재함을 나타내는 지표입니다. 핫 파티션이 감지되면 값은 1.0이고, 핫 파티션이 감지되지 않으면 값은 비어 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크를 통해 전송된 지정된 요청 유형의 총 요청 바이트의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크를 통해 전송된 지정된 응답 유형의 총 응답 바이트의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크에서 수신한 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 샘플 이후 수신된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크를 통해 전송된 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        세다
      </td>

      <td>
        수신된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 샘플 이후에 수신된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        세다
      </td>

      <td>
        전송된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        세다
      </td>

      <td>
        파티션의 수.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        밀리초
      </td>

      <td>
        그룹 구성원의 커밋된 오프셋과 파티션의 상위 워터마크 사이의 지연입니다.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        세다
      </td>

      <td>
        성공한 인증의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 성공한 인증 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        세다
      </td>

      <td>
        활성 인증 연결 수입니다.
      </td>
    </tr>
  </tbody>
</table>

### 커넥터 데이터

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        미터법
      </th>

      <th style={{ width: "150px" }}>
        유닛
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        세다
      </td>

      <td>
        소스 커넥터에 대해 변환에서 전송되어 Kafka에 기록된 총 레코드 수의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 레코드 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `connector_status`
      </td>

      <td>
        조금
      </td>

      <td>
        시스템 내 커넥터의 상태입니다. 해당 값은 항상 1로 설정되어 커넥터의 존재를 나타냅니다. 커넥터의 현재 작동 상태는 Indicator.status 태그를 통해 식별됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_status`
      </td>

      <td>
        조금
      </td>

      <td>
        시스템 내에서 커넥터의 작업 상태입니다. 해당 값은 항상 1로 설정되어 커넥터 작업이 존재함을 나타냅니다. 커넥터의 현재 작동 상태는 Indicator.status 태그를 통해 식별됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_avg`
      </td>

      <td>
        세다
      </td>

      <td>
        분당 평균 배치 크기(레코드 수로 측정)입니다. 소스 커넥터의 경우 Kafka로 전송된 평균 배치 크기를 나타냅니다. 싱크 커넥터의 경우 싱크 작업에서 읽은 평균 배치 크기를 나타냅니다.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_max`
      </td>

      <td>
        세다
      </td>

      <td>
        분당 최대 배치 크기(레코드 수로 측정)입니다. 소스 커넥터의 경우 Kafka로 전송되는 최대 배치 크기를 나타냅니다. 싱크 커넥터의 경우 싱크 작업에서 읽은 최대 배치 크기를 나타냅니다.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        세다
      </td>

      <td>
        싱크 커넥터가 수신한 총 레코드 수의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 수신된 레코드 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        싱크 커넥터가 수신한 총 레코드 수의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 수신된 레코드 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        싱크 커넥터가 수신한 총 바이트의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 수신된 바이트 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `dead_letter_queue_records`
      </td>

      <td>
        세다
      </td>

      <td>
        싱크 커넥터에 대해 Kafka에 기록된 데드 레터 큐 레코드의 델타 카운트입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>
  </tbody>
</table>

### ksql 데이터

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        미터법
      </th>

      <th style={{ width: "150px" }}>
        유닛
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `streaming_unit_count`
      </td>

      <td>
        세다
      </td>

      <td>
        이 KSQL 인스턴스의 Confluent 스트리밍 단위(CSU) 수입니다. 60초마다 카운트가 샘플링됩니다. 이 지표의 암묵적 시간 집계는 MAX입니다.
      </td>
    </tr>

    <tr>
      <td>
        `query_saturation`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        모든 노드에서 주어진 ksqlDB 쿼리에 대한 최대 포화도입니다. 0과 1 사이의 값을 반환하며, 1에 가까운 값은 ksqlDB 쿼리 처리가 사용 가능한 리소스에 대한 병목현상, 병목지점임을 나타냅니다.
      </td>
    </tr>

    <tr>
      <td>
        `task_stored_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        주어진 작업의 상태 저장소 크기(바이트)입니다.
      </td>
    </tr>

    <tr>
      <td>
        `storage_utilization`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        주어진 ksqlDB 애플리케이션의 총 저장소 사용량입니다.
      </td>
    </tr>

    <tr>
      <td>
        `consumed_total_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        요청 기간 동안 Kafka에서 연속 쿼리로 소비된 바이트의 델타 수입니다.
      </td>
    </tr>

    <tr>
      <td>
        `produced_total_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        요청 기간 동안 지속적인 쿼리를 통해 Kafka에 생성된 바이트의 델타 수입니다.
      </td>
    </tr>

    <tr>
      <td>
        `offsets_processed_total`
      </td>

      <td>
        세다
      </td>

      <td>
        주어진 쿼리 또는 작업 또는 주제 또는 오프셋에 의해 처리된 오프셋의 델타 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        `committed_offset_lag`
      </td>

      <td>
        밀리초
      </td>

      <td>
        주어진 쿼리, 작업, 주제 또는 오프셋에 대한 커밋된 오프셋과 종료 오프셋 사이의 현재 지연입니다.
      </td>
    </tr>

    <tr>
      <td>
        `processing_errors_total`
      </td>

      <td>
        세다
      </td>

      <td>
        요청 기간 동안 쿼리의 레코드 처리 오류 수를 델타로 계산합니다.
      </td>
    </tr>

    <tr>
      <td>
        `query_restarts`
      </td>

      <td>
        세다
      </td>

      <td>
        요청 기간 동안 쿼리를 다시 시작하게 하는 실패 횟수의 델타 카운트입니다.
      </td>
    </tr>
  </tbody>
</table>

## 무엇 향후 계획

<DocTiles>
  <DocTile title="데이터 및 UI" path="/docs/message-queues-streaming/ui-data/understand-ui">
    뉴렐릭를 사용하여 Kafka 클러스터를 모니터링하는 방법을 알아보세요.
  </DocTile>
</DocTiles>