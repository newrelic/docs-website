---
title: Confluent 클라우드 통합
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

뉴렐릭은 [아파치 Kafka 데이터에 대한 Confluent Cloud 관리형 스트리밍을](https://www.confluent.io/confluent-cloud/) 수집하기 위한 통합을 제공합니다. 이 문서에서는 이러한 통합을 활성화하는 방법과 보고할 수 있는 데이터에 대해 설명합니다.

## 전제 조건

* 뉴렐릭 계정
* 활성화된 Confluent Cloud 계정
* Confluent Cloud API 키 및 비밀
* `MetricsViewer` Confluent Cloud 계정에 액세스

## 통합 활성화 [#activate]

이 통합을 활성화하려면 <DNT>**Integrations &amp; Agents**</DNT> 로 이동하여 <DNT>**Confluent Cloud -&gt; API Polling**</DNT> 선택하고 지침을 따르세요.

<Callout variant="important">
  IP 필터링을 설정한 경우 다음 IP 주소를 필터에 추가하세요.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  클라우드 통합을 위한 뉴렐릭 IP 범위에 대한 자세한 내용은 [이 문서를](/docs/new-relic-solutions/get-started/networks/#webhooks) 참조하세요. 이 작업을 수행하기 위한 지침은 [이 문서를](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html) 참조하세요.
</Callout>

## 구성 및 폴링 [#polling]

Confluent Cloud Kafka 통합을 위한 기본 폴링 정보:

* New Relic 폴링 간격: 5분
* Confluent Cloud 데이터 간격: 1분

폴링 빈도는 초기 설정에서만 변경할 수 있습니다.

## 데이터 보기 및 사용 [#find-data]

통합 데이터를 보려면 <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Infrastructure &amp;gt; AWS**</DNT> 으로 이동하여 통합을 선택하세요.

다음 [이벤트](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels) 유형을 [사용하여 데이터를 쿼리하고 탐색 할](/docs/using-new-relic/data/understand-data/query-new-relic-data) 수 있습니다.

<table>
  <thead>
    <tr>
      <th>
        실재
      </th>

      <th>
        데이터 형식
      </th>

      <th>
        공급자
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        무리
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

데이터 사용 방법에 대한 자세한 내용은 [통합 데이터 이해 및 사용](/docs/infrastructure/integrations/find-use-infrastructure-integration-data) 을 참조하십시오.

## 측정항목 데이터 [#metrics]

이 통합은 클러스터, 파티션 및 주제에 대한 Amazon Managed Kafka 데이터를 기록합니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        미터법
      </th>

      <th style={{ width: "150px" }}>
        유닛
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        클러스터 활용도 측정. 값은 0.0과 1.0 사이입니다. 전용 타이어 클러스터에만 이 인덱스 데이터가 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        유입 처리량으로 인해 핫 파티션이 존재함을 나타내는 지표입니다. 핫 파티션이 감지되면 값은 1.0이고, 핫 파티션이 감지되지 않으면 값은 비어 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        퍼센트
      </td>

      <td>
        이탈 처리량으로 인해 핫 파티션이 존재함을 나타내는 지표입니다. 핫 파티션이 감지되면 값은 1.0이고, 핫 파티션이 감지되지 않으면 값은 비어 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크를 통해 전송된 지정된 요청 유형의 총 요청 바이트의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크를 통해 전송된 지정된 응답 유형의 총 응답 바이트의 델타 카운트입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 60초마다 카운트가 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크에서 수신한 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 샘플 이후 수신된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        바이트
      </td>

      <td>
        네트워크를 통해 전송된 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        세다
      </td>

      <td>
        수신된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 샘플 이후에 수신된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        세다
      </td>

      <td>
        전송된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        세다
      </td>

      <td>
        파티션의 수.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        밀리초
      </td>

      <td>
        그룹 구성원의 커밋된 오프셋과 파티션의 상위 워터마크 사이의 지연입니다.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        세다
      </td>

      <td>
        성공한 인증의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 성공한 인증 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        세다
      </td>

      <td>
        활성 인증 연결 수입니다.
      </td>
    </tr>
  </tbody>
</table>