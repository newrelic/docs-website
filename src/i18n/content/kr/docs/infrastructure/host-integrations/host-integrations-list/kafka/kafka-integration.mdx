---
title: Kafka 모니터링 통합
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: 'New Relic''s Kafka integration: how to install it and configure it, and what data it reports.'
freshnessValidatedDate: never
translationType: machine
---

New Relic Kafka [온-호스트 통합](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) 은 Kafka 서비스의 메트릭 및 구성 데이터를 보고합니다. 브로커(ZooKeeper 및 Bootstrap 모두), 생산자, 소비자 및 주제를 포함하여 클러스터의 모든 핵심 요소를 계측합니다.

Kafka 모니터링 통합을 설치하려면 다음 단계를 실행해야 합니다.

1. [설치를 준비합니다](#prepare) .
2. [통합을 설치하고 활성화합니다](#install) .
3. [통합을 구성합니다](#config) .
4. [데이터를 찾아 사용합니다](#find-and-use) .
5. 선택적으로 [Kafka의 구성 설정](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config) 을 참조하십시오.

<Callout variant="tip">
  Kafka를 모니터링할 때 모범 사례에 대해 읽으려면 [이 블로그 게시물](https://newrelic.com/blog/best-practices/new-relic-kafkapocalypse) 을 확인하십시오.
</Callout>

## 호환성 및 요구 사항 [#req]

### 카프카 버전 [#kafka-versions]

통합은 Kafka 버전 3 이하와 호환됩니다.

[수명 종료](https://docs.confluent.io/platform/current/installation/versions-interoperability.html#cp-and-apache-ak-compatibility) Kafka 버전을 사용하는 경우 예기치 않은 결과가 발생할 수 있으므로 [Apache Kafka EOL 정책](https://cwiki.apache.org/confluence/display/KAFKA/Time+Based+Release+Plan#TimeBasedReleasePlan-WhatIsOurEOLPolicy) 에 유의하십시오.

### 지원되는 운영 체제 [#supported-os]

* 윈도우

  <img
    style={{ width: '32px', height: '32px'}}
    class="inline"
    title="Windows"
    alt="Windows"
    src="/images/os_icon_windows.webp"
  />

* 리눅스

  <img
    style={{ width: '32px', height: '32px'}}
    class="inline"
    title="Linux"
    alt="Linux"
    src="/images/os_icon_linux.webp"
  />

특정 Windows 및 Linux 버전의 전체 목록은 [호환되는 운영 체제](/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/#operating-systems) 표를 확인하세요.

### 시스템 요구 사항 [#system-reqs]

* New Relic 계정. 하나가 없습니까? [무료 가입!](https://newrelic.com/signup) 신용 카드가 필요하지 않습니다.

* Kafka가 Kubernetes 또는 Amazon ECS에서 실행되지 않는 경우 Linux 또는 Windows OS 호스트 또는 Kafka가 설치된 위치에 원격으로 액세스할 수 있는 호스트에 [인프라 에이전트를 설치할](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) 수 있습니다. 그렇지 않으면:

  * 실행 중인 경우

    <img
      style={{ width: '32px', height: '32px'}}
      class="inline"
      title="Kubernetes"
      alt="Kubernetes"
      src="/images/os_icon_k8.webp"
    />

    Kubernetes, [이러한 요구 사항 ](/docs/monitor-service-running-kubernetes#requirements)참조.

  * 실행 중인 경우

    <img
      style={{ width: '32px', height: '32px'}}
      class="inline"
      title="ECS"
      alt="ECS"
      src="/images/os_icon_ecs.webp"
    />

    Amazon ECS, [이러한 요구 사항 ](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs)참조.

* 자바 버전 8 이상.

* 모든 브로커에서 활성화된 JMX.

* Java 기반 소비자 및 생산자 전용이며 JMX가 활성화되어 있습니다.

* 모니터링되는 총 주제 수는 10000개 미만이어야 합니다.

### 연결 요구 사항 [#connectivity-requirements]

다음 항목에 연결하려면 통합을 구성하고 허용해야 합니다.

* `autodiscover_strategy` 이 `zookeeper` 로 설정된 경우 Zookeeper 인증 메커니즘을 사용하여 Zookeeper 프로토콜을 통해 `zookeeper_hosts` 에 나열된 호스트.
* `autodiscover_strategy` 이 `bootstrap` 로 설정된 경우 Kafka 브로커의 인증/전송 메커니즘을 사용하여 Kafka 프로토콜을 통해 `bootstrap_broker_host` 에 정의된 호스트
* Kafka 브로커의 인증/전송 메커니즘을 사용하는 Kafka 프로토콜 및 포트를 통한 클러스터의 모든 브로커.
* 브로커의 JMX 구성에 지정된 인증/전송 메커니즘을 사용하는 JMX 프로토콜 및 포트를 통한 클러스터의 모든 브로커.
* 생산자/소비자 모니터링을 원하는 경우 JMX 프로토콜 및 포트를 통해 생산자 및 소비자에 지정된 모든 생산자/소비자. 소비자에 대한 JMX 설정은 브로커에 대한 설정과 동일해야 합니다.

<Callout variant="important">
  기본적으로 AWS의 다른 클라우드 공급자에 있는 보안 그룹 및 이에 상응하는 항목에는 기본적으로 필요한 포트가 열려 있지 않습니다. JMX가 작동하려면 JMX 포트와 RMI 포트라는 두 개의 포트가 필요합니다. JMX를 사용하도록 JVM을 구성할 때 동일한 값으로 설정할 수 있으며 브로커에 연결하고 브로커에서 메트릭을 수집할 수 있도록 통합을 위해 열려 있어야 합니다.
</Callout>

## 설치 준비 [#prepare]

Kafka는 분산 시스템으로 구축된 복잡한 소프트웨어입니다. 이러한 이유로 데이터가 올바르게 수집되도록 통합에서 필요한 모든 호스트 및 서비스에 연결할 수 있는지 확인해야 합니다.

<CollapserGroup>
  <Collapser
    id="autodiscovery"
    title="자동 검색"
  >
    Kafka의 분산 특성을 감안할 때 실제 브로커 수와 목록은 일반적으로 구성에 의해 고정되지 않으며 대신 매우 동적입니다. 이러한 이유로 Kafka 통합은 클러스터에 있는 브로커 목록의 자동 검색을 수행하는 두 가지 메커니즘인 부트스트랩과 주키퍼를 제공합니다. 사용하는 메커니즘은 모니터링 중인 Kafka 클러스터 설정에 따라 다릅니다.

    ### 부트스트랩

    [부트스트랩 메커니즘](#bootstrap) 으로 통합은 부트스트랩 브로커를 사용하여 자동 검색을 수행합니다. 이것은 주소가 잘 알려진 브로커이며 알고 있는 다른 브로커를 요청합니다. 부트스트랩 검색이 작동하려면 통합에서 bootstrap_broker_host 매개변수에 제공된 주소로 이 브로커에 연결할 수 있어야 합니다.

    ### 사육사

    또는 Kafka 통합은 브로커 목록을 얻기 위해 [Zookeeper 서버](#zookeeper) 와 통신할 수도 있습니다. 이렇게 하려면 다음과 함께 통합이 제공되어야 합니다.

    * 연락할 Zookeeper 호스트 `zookeeper_hosts` 의 목록입니다.

    * 호스트와 연결하기 위한 적절한 인증 비밀.

      Zookeeper는 알고 있는 브로커 목록과 함께 각 브로커가 지원하는 연결 메커니즘도 알립니다.

      `preferred_listener` 매개변수를 사용하여 이러한 메커니즘 중 하나로 직접 시도하도록 Kafka 통합을 구성할 수 있습니다. 이 매개변수가 제공되지 않으면 통합은 그 중 하나가 성공할 때까지 알려진 모든 구성으로 브로커에 연결을 시도합니다.

      <Callout variant="tip">
        통합은 브로커 검색에만 Zookeeper를 사용하고 메트릭을 검색하지 않습니다.
      </Callout>
  </Collapser>

  <Collapser
    id="topic-listing"
    title="주제 목록"
  >
    브로커가 처리하는 주제를 올바르게 나열하려면 통합에서 Kafka 프로토콜을 통해 브로커에 연결해야 합니다. 브로커 구성 방법에 따라 브로커 구성과 일치하도록 SSL 및/또는 SASL을 설정해야 할 수 있습니다. 주제에는 DESCRIBE 액세스 권한이 있어야 합니다.
  </Collapser>

  <Collapser
    id="broker-monitoring"
    title="브로커 모니터링(JMX)"
  >
    Kafka 통합은 Java 애플리케이션에서 메트릭을 교환하기 위한 표준 Java 확장인 JMX를 쿼리합니다. JMX는 Kafka 브로커에서 기본적으로 활성화되어 있지 않으며 메트릭 수집이 제대로 작동하려면 활성화해야 합니다. JMX를 사용하려면 RMI가 활성화되어야 하며 RMI 포트는 JMX와 동일한 포트로 설정되어야 합니다.

    SSL뿐만 아니라 사용자 이름/암호 인증을 사용하도록 JMX를 구성할 수 있습니다. 브로커의 JMX 설정에서 이러한 기능이 활성화된 경우 이에 따라 통합을 구성해야 합니다.

    autodiscovery가 부트스트랩으로 설정되면 부트스트랩 브로커에 대해 정의된 JMX 설정이 검색된 다른 모든 브로커에 적용되므로 포트 및 기타 설정은 모든 브로커에서 동일해야 합니다. <Callout variant="important">공개 또는 신뢰할 수 없는 네트워크 세그먼트에서 익명 및/또는 암호화되지 않은 JMX/RMI 액세스를 활성화하는 것은 큰 보안 위험을 야기하므로 권장하지 않습니다.</Callout>
  </Collapser>

  <Collapser
    id="consumer-offset"
    title="소비자 오프셋"
  >
    주제의 소비자 및 소비자 그룹의 오프셋과 지연은 `CONSUMER_OFFSET=true` 플래그를 사용하여 [KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection) 로 검색할 수 있지만 이 플래그가 활성화되면 인스턴스가 다른 샘플을 수집하지 않기 때문에 별도의 인스턴스에 있어야 합니다.
  </Collapser>

  <Collapser
    id="producer"
    title="생산자 및 소비자 모니터링(JMX)"
  >
    Java로 작성된 생산자와 소비자는 동일한 메커니즘(JMX)을 통해 보다 구체적인 메타데이터를 얻기 위해 모니터링할 수도 있습니다. 그러면 [KafkaConsumerSamples 및 KafkaProducerSamples](#KafkaConsumerSample-collection) 가 생성됩니다. JMX는 기본적으로 활성화되어 있지 않은 애플리케이션에서 활성화하고 구성해야 합니다.

    Java가 아닌 생산자 및 소비자는 JMX를 지원하지 않으므로 Kafka 통합에서 지원되지 않습니다.
  </Collapser>
</CollapserGroup>

## 통합 설치 및 활성화 [#install]

Kafka 통합을 설치하려면 환경에 대한 지침을 따르세요.

### 리눅스 설치 [#linux-install]

1. [통합 설치](/docs/install-integrations-package) 지침을 따르고 `INTEGRATION_FILE_NAME` 변수를 `nri-kafka` 로 바꿉니다.

2. 다음을 실행하여 디렉토리를 통합 구성 폴더로 변경하십시오.

   ```shell
   cd /etc/newrelic-infra/integrations.d
   ```

3. 다음을 실행하여 샘플 구성 파일을 복사합니다.

   ```shell
   sudo cp kafka-config.yml.sample kafka-config.yml
   ```

4. 선호하는 편집기로 `kafka-config.yml` 구성 파일을 편집합니다. 일부 [구성 파일 예제를 확인하십시오.](#examples).

### 기타 환경 [#other-env]

<CollapserGroup>
  <Collapser
    id="windows-install"
    title={<><img src="/images/os_icon_windows.webp" title="Windows installation" alt="Windows installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/>윈도우 설치</>}
  >
    1. [뉴렐릭의 Kafka 통합용 .exe 설치 설치러를 다운로드하세요](https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-kafka/nri-kafka-amd64-installer.exe).

    2. Windows 명령 프롬프트에서 설치하려면 다음을 실행하십시오.

       ```shell
       PATH\TO\nri-kafka-amd64-installer.exe
       ```

    3. Integrations 디렉터리 `C:\Program Files\New Relic\newrelic-infra\integrations.d\` 에서 다음을 실행하여 샘플 구성 파일의 복사본을 만듭니다.

       ```shell
       cp kafka-config.yml.sample kafka-config.yml
       ```

    4. [`kafka-config.yml` 샘플 파일](#examples) 중 하나를 사용하여 `kafka-config.yml` 파일을 편집합니다.
  </Collapser>

  <Collapser
    id="ecs-install"
    title={<><img src="/images/os_icon_ecs.webp" title="Amazon ECS installation" alt="Amazon ECS installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/>' ' Amazon ECS 설치</>}
  >
    [ECS에서 실행 중인 모니터링 서비스를](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs) 참조하십시오.
  </Collapser>

  <Collapser
    id="k8s-install"
    title={<><img src="/images/os_icon_k8.webp" title="Kubernetes installation" alt="Kubernetes installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/>쿠버네티스 설치</>}
  >
    [Kubernetes에서 실행 중인 서비스 모니터링을](/docs/monitor-service-running-kubernetes) 참조하세요.
  </Collapser>
</CollapserGroup>

추가 참고 사항:

* <DNT>
    **Advanced:**
  </DNT>

  통합은 [Tarball 형식](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball) 으로도 제공되므로 헤드셋 매니저 외부에 설치할 수 있습니다.

* <DNT>
    **On-host integrations do not automatically update.**
  </DNT>

  최상의 결과를 얻으 [려면 통합 패키지](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package) 및 [인프라 에이전트](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent) 를 정기적으로 업데이트하십시오.

<InstallFeedback/>

## 통합 구성 [#config]

설치 방법에 따라 통합을 구성하는 몇 가지 방법이 있습니다.

* 다음을 통해 활성화된 경우

  <img
    style={{ width: '32px', height: '32px'}}
    class="inline"
    title="Kubernetes"
    alt="Kubernetes"
    src="/images/os_icon_k8.webp"
  />

  Kubernetes, [Kubernetes에서 실행 중인 모니터링 서비스 ](/docs/monitor-service-running-kubernetes)참조.

* 다음을 통해 활성화된 경우

  <img
    style={{ width: '32px', height: '32px'}}
    class="inline"
    title="ECS"
    alt="ECS"
    src="/images/os_icon_ecs.webp"
  />

  Amazon ECS, [ECS에서 실행되는 모니터링 서비스 참조 ](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).

* 호스트에 설치된 경우 통합의 YAML 구성 파일 `kafka-config.yml` 에서 구성을 편집합니다. 통합의 YAML 형식 구성은 필수 로그인 자격 증명을 배치하고 데이터 수집 방법을 구성할 수 있는 곳입니다. 변경하는 옵션은 설정 및 기본 설정에 따라 다릅니다. 구성 파일에는 `interval` , `timeout` , `inventory_source` 같은 모든 통합에 적용할 수 있는 공통 설정이 있습니다. 이러한 공통 설정에 대한 모든 내용을 읽으려면 [구성 형식](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/#configuration-basics) 문서를 참조하십시오.

<Callout variant="important">
  레거시 구성 및 정의 파일을 계속 사용하는 경우 이 [문서](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/) 에서 도움말을 참조하세요.
</Callout>

다른 통합과 마찬가지로 하나의 `kafka-config.yml` 구성 파일에는 다양한 브로커, 소비자 및 생산자 측정항목을 수집하는 통합 인스턴스가 여러 개 있을 수 있습니다.[`kafka-config.yml` 샘플 파일](#examples) 에서 하나 이상의 인스턴스가 있는 구성 예를 볼 수 있습니다.

Kafka와 관련된 특정 설정은 `kafka-config.yml` 구성 파일에 있는 각 인스턴스의 `env` 섹션을 사용하여 정의됩니다.이러한 설정은 Brokers, Zookeeper 및 JMX에 대한 연결과 기타 보안 설정 및 기능을 제어합니다.유효한 설정 목록은 [Kafka의 구성 설정](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config) 에 설명되어 있습니다.

통합에는 각 인스턴스에 대해 상호 배타적인 두 가지 작동 모드가 있으며 `CONSUMER_OFFSET` 매개변수로 설정할 수 있습니다.

* 소비자 오프셋 수집: [KafkaOffsetSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection) 을 수집하도록 `CONSUMER_OFFSET = true` 을 설정합니다.
* 코어 수집 모드: `CONSUMER_OFFSET = false` 을 설정하여 나머지 샘플 [(KafkaBrokerSample, KafkaTopicSample](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#broker-collection) , [KafkaProducerSample, KafkaConsumerSample)](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaConsumerSample-collection) 을 수집합니다.

<Callout variant="important">
  소비자 오프셋 수집은 실행하는 데 오랜 시간이 걸리고 고성능 요구 사항이 있기 때문에 이러한 모드는 상호 배타적입니다. 두 샘플 그룹을 수집하려면 각 모드에 하나씩 두 개의 인스턴스를 설정합니다.
</Callout>

이러한 설정의 값은 여러 가지 방법으로 정의할 수 있습니다.

* 구성 파일에 직접 값을 추가합니다. 이것은 가장 일반적인 방법입니다.
* `{{ }}` 표기법을 사용하여 환경 변수의 값을 바꿉니다. [온호스트 통합과 함께 환경 변수 패스스루 사용](/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent/#passthrough) 에 대해 자세히 알아보거나 [환경 변수 대체](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch/elasticsearch-integration#envvar-replacement)에 대한 예제를 참조하십시오.
* 비밀 관리를 사용합니다. 이를 사용하여 구성 파일에서 일반 텍스트로 노출될 암호와 같은 민감한 정보를 보호하십시오. 자세한 내용은 [비밀 관리](/docs/integrations/host-integrations/installation/secrets-management) 를 참조하십시오.

### 오프셋 모니터링

`CONSUMER_OFFSET = true` 을 설정하면 기본적으로 활성 소비자(및 소비자 측정항목)가 있는 소비자 그룹의 측정항목만 수집됩니다.또한 비활성 소비자가 있는 소비자 그룹에서 측정항목을 수집하려면 `INACTIVE_CONSUMER_GROUP_OFFSET` 을 `true` 로 설정해야 합니다.

소비자 그룹이 둘 이상의 주제를 모니터링할 때, 특히 주제 중 하나에 비활성 소비자가 있는 경우 소비자 그룹 메트릭을 주제별로 구분하는 것이 중요합니다. 그러면 소비자 그룹에 지연이 있는 주제와 해당 소비자 그룹 및 주제에 대한 활성 소비자입니다.

주제별로 구분된 소비자 그룹 측정항목을 가져오려면 `CONSUMER_GROUP_OFFSET_BY_TOPIC` 을 `true` (기본값은 `false` )로 설정해야 합니다.

오프셋 모니터링을 설정하는 방법에 대한 자세한 내용은 [KafkaOffsetSample 컬렉션 구성](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection) 을 참조하세요.

## kafka-config.yml 샘플 파일 [#examples]

<CollapserGroup>
  <Collapser
    id="zookeeper"
    title="Zookeeper discovery"
  >
    이 구성은 두 개의 다른 JMX 호스트에서 브로커를 검색하는 모든 주제를 포함하여 메트릭 및 인벤토리를 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}, {"host": "localhost2", "port": 2181}]'
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: all
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="zookeeper-jmx-ssl"
    title="SSL 기반 JMX 연결을 통한 Zookeeper 검색"
  >
    이 구성은 SSL을 사용하여 JMX 호스트에서 브로커를 검색하는 메트릭 및 인벤토리를 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "localhost", "port": 2181}]'
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password

          KEY_STORE: "/path/to/your/keystore"
          KEY_STORE_PASSWORD: keystore_password
          TRUST_STORE: "/path/to/your/truststore"
          TRUST_STORE_PASSWORD: truststore_password

          TIMEOUT: 10000  #The timeout for individual JMX queries in milliseconds.
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="bootstrap"
    title="부트스트랩 검색"
  >
    이 구성은 하나의 부트스트랩 브로커에서 브로커를 검색하는 모든 주제를 포함하여 메트릭 및 인벤토리를 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          BOOTSTRAP_BROKER_JMX_PORT: 9999  # This same port will be used to connect to all discover broker JMX
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          LOCAL_ONLY_COLLECTION: false

          COLLECT_BROKER_TOPIC_DATA: true
          TOPIC_MODE: "all"
          COLLECT_TOPIC_SIZE: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="bootstrap-tls"
    title="부트스트랩 검색 TLS"
  >
    이 구성은 TLS 프로토콜을 수신하는 하나의 부트스트랩 브로커에서 브로커를 검색하는 메트릭만 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          TLS_CA_FILE: "/path/to/CA.pem"
          TLS_CERT_FILE: "/path/to/cert.pem"
          TLS_KEY_FILE: "/path/to/key.pem"
          TLS_INSECURE_SKIP_VERIFY: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="boostrap-kerberos"
    title="부트스트랩 검색 kerberos 인증"
  >
    이 구성은 Kerberos 인증 클러스터의 한 부트스트랩 브로커에서 브로커를 검색하는 메트릭만 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT # Currently support PLAINTEXT and SSL
          BOOTSTRAP_BROKER_JMX_PORT: 9999
          BOOTSTRAP_BROKER_JMX_USER: admin
          BOOTSTRAP_BROKER_JMX_PASSWORD: password

          # Kerberos authentication arguments
          SASL_MECHANISM: GSSAPI
          SASL_GSSAPI_REALM: SOMECORP.COM
          SASL_GSSAPI_SERVICE_NAME: Kafka
          SASL_GSSAPI_USERNAME: kafka
          SASL_GSSAPI_KEY_TAB_PATH: /etc/newrelic-infra/kafka.keytab
          SASL_GSSAPI_KERBEROS_CONFIG_PATH: /etc/krb5.conf
          SASL_GSSAPI_DISABLE_FAST_NEGOTIATION: false
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="zookeeper-topic-bucket"
    title="Zookeeper 검색 주제 버킷"
  >
    이 구성은 3개의 서로 다른 인스턴스 간에 주제 컬렉션을 분할하는 지표를 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster1
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host1", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '1/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster2
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host2", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '2/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
      - name: nri-kafka
        env:
          METRICS: true
          CLUSTER_NAME: testcluster3
          KAFKA_VERSION: "1.0.0"
          AUTODISCOVER_STRATEGY: zookeeper
          ZOOKEEPER_HOSTS: '[{"host": "host3", "port": 2181}]'
          ZOOKEEPER_AUTH_SECRET: "username:password"
          ZOOKEEPER_PATH: "/kafka-root"
          DEFAULT_JMX_USER: username
          DEFAULT_JMX_PASSWORD: password
          TOPIC_MODE: regex
          TOPIC_REGEX: 'topic\d+'
          TOPIC_BUCKET: '3/3'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="java-consumer-producer"
    title="자바 소비자 및 생산자"
  >
    다음은 Java 소비자 및 생산자로부터 JMX 메트릭을 수집하는 예입니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          METRICS: "true"
          CLUSTER_NAME: "testcluster3"
          PRODUCERS: '[{"host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          CONSUMERS: '[{"host": "localhost", "port": 24, "username": "me", "password": "secret"}]'
          DEFAULT_JMX_HOST: "localhost"
          DEFAULT_JMX_PORT: "9999"
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>

  <Collapser
    id="consumer-offset"
    title="소비자 오프셋"
  >
    이 구성은 클러스터에 대한 소비자 오프셋 지표 및 인벤토리를 수집합니다.

    ```yml
    integrations:
      - name: nri-kafka
        env:
          CONSUMER_OFFSET: true
          CLUSTER_NAME: testcluster3
          AUTODISCOVER_STRATEGY: bootstrap
          BOOTSTRAP_BROKER_HOST: localhost
          BOOTSTRAP_BROKER_KAFKA_PORT: 9092
          BOOTSTRAP_BROKER_KAFKA_PROTOCOL: PLAINTEXT
          # A regex pattern that matches the consumer groups to collect metrics from
          CONSUMER_GROUP_REGEX: '.*'
        interval: 15s
        labels:
          env: production
          role: kafka
        inventory_source: config/kafka
    ```
  </Collapser>
</CollapserGroup>

## 통합을 위한 구성 옵션 [#config-options]

데이터를 찾고 사용하는 방법에 대한 자세한 내용은 [Kafka의 구성 설정](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config) 을 참조하십시오.

## 데이터 찾기 및 사용 [#find-and-use]

이 서비스의 데이터는 [통합 대시보드](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts) 에 보고됩니다.

Kafka 데이터는 다음 [이벤트 유형](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic) 에 첨부됩니다.

* [`KafkaBrokerSample`](#broker-sample)
* [`KafkaTopicSample`](#topic-sample)
* [`KafkaProducerSample`](#producer-sample)
* [`KafkaConsumerSample`](#consumer-sample)
* [`KafkaOffsetSample`](#offset-sample)

문제 해결을 위해 또는 차트 및 대시보드를 생성하기 위해 [이 데이터를 쿼리](/docs/using-new-relic/data/understand-data/query-new-relic-data) 할 수 있습니다.

데이터를 찾고 사용하는 방법에 대한 자세한 내용은 [통합 데이터를 이해](/docs/infrastructure/integrations/find-use-infrastructure-integration-data) 하는 방법을 참조하세요.

## 통합으로 수집된 측정항목 [#metrics]

Kafka 통합은 다음 메트릭을 수집합니다. 각 측정항목 이름 앞에는 카테고리 표시기 및 마침표(예: `broker.` 또는 `consumer.` )가 붙습니다.

<CollapserGroup>
  <Collapser
    id="broker-sample"
    title="KafkaBrokerSample 이벤트"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            미터법
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `broker.bytesWrittenToTopicPerSecond`
          </td>

          <td>
            브로커가 초당 토픽에 쓴 바이트 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `broker.IOInPerSecond`
          </td>

          <td>
            클러스터의 브로커에 대한 네트워크 IO(초당 바이트 수).
          </td>
        </tr>

        <tr>
          <td>
            `broker.IOOutPerSecond`
          </td>

          <td>
            클러스터에 있는 브로커의 네트워크 IO(초당 바이트)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `broker.logFlushPerSecond`
          </td>

          <td>
            로그 플러시 비율.
          </td>
        </tr>

        <tr>
          <td>
            `broker.messagesInPerSecond`
          </td>

          <td>
            초당 수신 메시지입니다.
          </td>
        </tr>

        <tr>
          <td>
            `follower.requestExpirationPerSecond`
          </td>

          <td>
            초당 축출에서 팔로어에 대한 요청 만료 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `net.bytesRejectedPerSecond`
          </td>

          <td>
            거부된 초당 바이트 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `replication.isrExpandsPerSecond`
          </td>

          <td>
            ISR 풀에 참여하는 복제본의 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `replication.isrShrinksPerSecond`
          </td>

          <td>
            ISR 풀에서 나가는 복제본의 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `replication.leaderElectionPerSecond`
          </td>

          <td>
            리더 선출률.
          </td>
        </tr>

        <tr>
          <td>
            `replication.uncleanLeaderElectionPerSecond`
          </td>

          <td>
            부정한 지도자 선출률.
          </td>
        </tr>

        <tr>
          <td>
            `replication.unreplicatedPartitions`
          </td>

          <td>
            복제되지 않은 파티션의 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeFetch`
          </td>

          <td>
            가져오기 요청당 평균 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeMetadata`
          </td>

          <td>
            메타데이터 요청의 평균 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeMetadata99Percentile`
          </td>

          <td>
            99번째 백분위수에 대한 메타데이터 요청 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeOffset`
          </td>

          <td>
            오프셋 요청의 평균 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeOffset99Percentile`
          </td>

          <td>
            99번째 백분위수에 대한 오프셋 요청 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeProduceRequest`
          </td>

          <td>
            생산 요청의 평균 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeUpdateMetadata`
          </td>

          <td>
            메타데이터 업데이트 요청의 평균 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.avgTimeUpdateMetadata99Percentile`
          </td>

          <td>
            99번째 백분위수에 대한 업데이트 메타데이터 요청 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.clientFetchesFailedPerSecond`
          </td>

          <td>
            초당 클라이언트 가져오기 요청 실패 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.fetchTime99Percentile`
          </td>

          <td>
            99번째 백분위수에 대한 가져오기 요청 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.handlerIdle`
          </td>

          <td>
            요청 처리기 스레드가 유휴 상태인 평균 시간 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.produceRequestsFailedPerSecond`
          </td>

          <td>
            초당 생성 요청에 실패했습니다.
          </td>
        </tr>

        <tr>
          <td>
            `request.produceTime99Percentile`
          </td>

          <td>
            99번째 백분위수에 대한 생산 요청 시간입니다.
          </td>
        </tr>

        <tr>
          <td>
            `topic.diskSize`
          </td>

          <td>
            브로커 및 주제당 주제 디스크 크기입니다. `COLLECT_TOPIC_SIZE` 활성화된 경우에만 존재합니다.
          </td>
        </tr>

        <tr>
          <td>
            `topic.offset`
          </td>

          <td>
            브로커별 및 주제별 주제 오프셋입니다. `COLLECT_TOPIC_OFFSET` 활성화된 경우에만 존재합니다.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="consumer-sample"
    title="KafkaConsumerSample 이벤트"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            미터법
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `consumer.avgFetchSizeInBytes`
          </td>

          <td>
            특정 주제에 대한 요청당 가져온 평균 바이트 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.avgRecordConsumedPerTopic`
          </td>

          <td>
            특정 주제에 대한 각 요청의 평균 레코드 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.avgRecordConsumedPerTopicPerSecond`
          </td>

          <td>
            초당 레코드의 특정 주제에 대해 초당 소비된 평균 레코드 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.bytesInPerSecond`
          </td>

          <td>
            초당 소비자 바이트입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.fetchPerSecond`
          </td>

          <td>
            소비자가 요청을 중단 요청에 보내는 초당 최소 속도입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.maxFetchSizeInBytes`
          </td>

          <td>
            특정 주제에 대한 요청당 가져온 최대 바이트 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.maxLag`
          </td>

          <td>
            최대 소비자 지연.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.messageConsumptionPerSecond`
          </td>

          <td>
            초당 메시지의 소비자 메시지 소비 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.offsetKafkaCommitsPerSecond`
          </td>

          <td>
            초당 커밋에서 Kafka에 대한 오프셋 커밋 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.offsetZooKeeperCommitsPerSecond`
          </td>

          <td>
            초당 쓰기에서 ZooKeeper에 대한 오프셋 커밋 비율입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.requestsExpiredPerSecond`
          </td>

          <td>
            초당 축출에서 지연된 소비자 요청 만료 비율입니다.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="producer-sample"
    title="KafkaProducerSample 이벤트"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            미터법
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `producer.ageMetadataUsedInMilliseconds`
          </td>

          <td>
            현재 사용 중인 생산자 메타데이터의 기간(초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.availableBufferInBytes`
          </td>

          <td>
            사용되지 않는 버퍼 메모리의 총량(바이트)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgBytesSentPerRequestInBytes`
          </td>

          <td>
            요청당 파티션당 보낸 평균 바이트 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgCompressionRateRecordBatches`
          </td>

          <td>
            레코드 배치의 평균 압축률입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordAccumulatorsInMilliseconds`
          </td>

          <td>
            레코드 누산기에서 소요된 ms 레코드 배치의 평균 시간입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordSizeInBytes`
          </td>

          <td>
            평균 레코드 크기(바이트)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordsSentPerSecond`
          </td>

          <td>
            초당 전송된 평균 레코드 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgRecordsSentPerTopicPerSecond`
          </td>

          <td>
            주제에 대해 초당 전송된 평균 레코드 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.AvgRequestLatencyPerSecond`
          </td>

          <td>
            생산자 평균 요청 지연 시간.
          </td>
        </tr>

        <tr>
          <td>
            `producer.avgThrottleTime`
          </td>

          <td>
            요청이 브로커에 의해 조절된 평균 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.bufferMemoryAvailableInBytes`
          </td>

          <td>
            클라이언트가 사용할 수 있는 최대 버퍼 메모리 양(바이트)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.bufferpoolWaitTime`
          </td>

          <td>
            어펜더가 공간 할당을 기다리는 시간의 분파.
          </td>
        </tr>

        <tr>
          <td>
            `producer.bytesOutPerSecond`
          </td>

          <td>
            초당 생산자 바이트 출력.
          </td>
        </tr>

        <tr>
          <td>
            `producer.compressionRateRecordBatches`
          </td>

          <td>
            주제에 대한 레코드 배치의 평균 압축률입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.iOWaitTime`
          </td>

          <td>
            생산자 I/O 대기 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxBytesSentPerRequestInBytes`
          </td>

          <td>
            요청당 파티션당 전송된 최대 바이트 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxRecordSizeInBytes`
          </td>

          <td>
            최대 레코드 크기(바이트).
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxRequestLatencyInMilliseconds`
          </td>

          <td>
            최대 요청 지연 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.maxThrottleTime`
          </td>

          <td>
            요청이 브로커에 의해 조절된 최대 시간(밀리초)입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.messageRatePerSecond`
          </td>

          <td>
            초당 생산자 메시지입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.responsePerSecond`
          </td>

          <td>
            초당 생산자 응답 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.requestPerSecond`
          </td>

          <td>
            초당 생산자 요청 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.requestsWaitingResponse`
          </td>

          <td>
            응답을 기다리는 진행 중인 요청의 현재 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `producer.threadsWaiting`
          </td>

          <td>
            버퍼 메모리가 레코드를 대기열에 넣을 때까지 기다리는 차단된 사용자 스레드 수입니다.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="topic-sample"
    title="KafkaTopicSample 이벤트"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            미터법
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `topic.partitionsWithNonPreferredLeader`
          </td>

          <td>
            선호하는 복제본이 주도하지 않는 주제당 파티션 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `topic.respondMetaData`
          </td>

          <td>
            메타 데이터 요청에 응답하는 주제의 수입니다.
          </td>
        </tr>

        <tr>
          <td>
            `topic.retentionSizeOrTime`
          </td>

          <td>
            파티션이 크기별로 유지되는지 또는 크기와 시간에 따라 유지되는지 여부입니다. 값 0 = 시간 및 값 1 = 크기와 시간 모두입니다.
          </td>
        </tr>

        <tr>
          <td>
            `topic.underReplicatedPartitions`
          </td>

          <td>
            과소 복제된 주제당 파티션 수입니다.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="offset-sample"
    title="KafkaOffsetSample 이벤트"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            미터법
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `consumer.offset`
          </td>

          <td>
            소비자 그룹이 파티션에서 마지막으로 사용한 오프셋입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumer.lag`
          </td>

          <td>
            브로커의 상위 워터마크와 소비자 오프셋 간의 차이( `consumer.hwm` - `consumer.offset` ).
          </td>
        </tr>

        <tr>
          <td>
            `consumer.hwm`
          </td>

          <td>
            파티션에 기록된 마지막 메시지의 오프셋(하이 워터 마크).
          </td>
        </tr>

        <tr>
          <td>
            `consumer.totalLag`
          </td>

          <td>
            소비자가 사용하는 파티션의 지연 합계입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.totalLag`
          </td>

          <td>
            `consumerGroup` 에서 사용하는 모든 파티션의 지연 합계입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.maxLag`
          </td>

          <td>
            `consumerGroup` 에서 사용하는 모든 파티션의 최대 지연 시간입니다.
          </td>
        </tr>

        <tr>
          <td>
            `consumerGroup.activeConsumers`
          </td>

          <td>
            이 `consumerGroup` 의 활성 소비자 수입니다.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>
