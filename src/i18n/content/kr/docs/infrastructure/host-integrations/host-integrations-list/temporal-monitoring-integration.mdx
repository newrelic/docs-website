---
title: Temporal 모니터링 통합
tags:
  - Temporal integration
  - Temporal monitoring
  - New Relic integrations
metaDescription: Install our Temporal dashboards and see your Temporal data in New Relic.
freshnessValidatedDate: never
translationType: machine
---

import infrastructureTemporalDashboard from 'images/infrastructure_screenshot-full_temporal-dashboard.webp'

Temporal 통합은 Temporal 데이터의 성능을 모니터링하여 쓰기 분산, 내결함성 및 확장 가능한 애플리케이션의 문제를 진단하는 데 도움을 줍니다. Temporal 통합은 가장 중요한 Temporal SDK 앱 지표가 포함된 사전 구축된 대시보드를 제공합니다.

<img
  title="Temporal"
  alt="A screenshot depicting the Temporal dashboard"
  src={infrastructureTemporalDashboard}
/>

<figcaption>
  New Relic과의 통합을 설정한 후 즉시 사용 가능한 것과 같은 대시보드에서 데이터를 확인하십시오.
</figcaption>

## 인프라 에이전트 설치 [#infra]

New Relic 인프라 에이전트는 Temporal 데이터를 New Relic으로 가져오기 위한 기반입니다.아직 설치하지 않은 경우 다음 옵션 중 하나를 사용하여 에이전트를 설치하세요.

* [설치 안내](https://one.newrelic.com/marketplace?state=15321ec0-7cd8-0c04-52bf-7b65778f2e8c) 는 시스템을 검사하고 시스템에 가장 적합한 애플리케이션 모니터링 에이전트와 함께 인프라 에이전트를 설치하는 CLI 도구입니다. 안내 설치 작동 방식에 대해 자세히 알아보려면 [안내 설치 개요를](/docs/infrastructure/host-integrations/installation/new-relic-guided-install-overview) 확인하세요.
* 인프라 에이전트를 수동으로 설치하려면 [Linux](/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux), [Windows](/docs/infrastructure/install-infrastructure-agent/windows-installation/install-infrastructure-monitoring-agent-windows/)또는 [macOS](/docs/infrastructure/install-infrastructure-agent/macos-installation/install-infrastructure-monitoring-agent-macos/)용 수동 설치에 대한 자습서를 따를 수 있습니다.

## Temporal 측정항목 노출 [#expose-temporal-metrics]

Temporal 측정항목을 얻으려면 다음과 같은 몇 가지 단계를 수행해야 합니다.

호스트에 docker 및 docker-compose를 설치합니다.

```yml
sudo apt-get update
sudo apt install docker
sudo apt install docker-compose
```

다음 단계에서는 기본 구성 파일 `docker-compose.yml` 을 사용하여 Temporal Server의 로컬 인스턴스를 실행합니다.

1. 저장소를 복제합니다.

   ```yml
   git clone https://github.com/temporalio/docker-compose.git
   ```

2. 디렉터리를 프로젝트 루트로 변경하고 `docker-compose.yml` 파일에 Prometheus 엔드포인트와 포트를 추가합니다.

   ```yml
   sudo nano docker-compose/docker-compose.yml
   ```

   * 환경 섹션의 `container_name: temporal` 아래에 다음과 같이 Prometheus 엔드포인트를 포함합니다. `- PROMETHEUS_ENDPOINT=0.0.0.0:8000`.
   * 마찬가지로 동일한 컨테이너 내에서 포트 섹션 아래에 포트를 `- 8000:8000` 으로 지정합니다.
   * 다음은 로컬 docker-compose 임시 클러스터 설정에서 Prometheus 엔드포인트를 노출하는 방법에 대한 예입니다.

   ```yml
   Environment:
     - PROMETHEUS_ENDPOINT=0.0.0.0:8000
   ports:
     - 8000:8000
   ```

3. `docker-compose up` 명령을 실행합니다.

   ```yml
   sudo docker-compose up
   ```

   아래 URL에서 실행 중인 Temporal 서버를 확인할 수 있습니다.

* Temporal Server 은 `localhost:7233` 에 출시됩니다.
* Temporal Web UI는 다음에서 사용할 수 있습니다. `http://<YOUR_DOMAIN>:8080`
* Temporal 서버 측정항목은 다음에서 사용할 수 있습니다 `http://<YOUR_DOMAIN>:8000/metrics`

## Java SDK 지표 노출 [#expose-java-sdk-metrics]

다음과 같은 방법으로 Prometheus 레지스트리 및 Micrometer 통계 보고자를 설정하고, 범위를 설정하고, Prometheus가 SDK 클라이언트 지표를 스크랩할 수 있는 엔드포인트를 노출할 수 있습니다.

1. Java SDK 임시에 대한 지표를 설정하려면 프로젝트의 루트 디렉터리에 `MetricsWorker.java` 파일을 생성합니다.

   ```java
   package <add_your_project_main_directory>; // please add your java application main directory name.

   import com.sun.net.httpserver.HttpServer;
   import com.uber.m3.tally.RootScopeBuilder;
   import com.uber.m3.tally.Scope;
   import com.uber.m3.tally.StatsReporter;
   import com.uber.m3.util.ImmutableMap;
   import io.micrometer.prometheus.PrometheusConfig;
   import io.micrometer.prometheus.PrometheusMeterRegistry;
   import io.temporal.client.WorkflowClient;
   import io.temporal.client.WorkflowClientOptions;
   import io.temporal.common.reporter.MicrometerClientStatsReporter;
   import io.temporal.serviceclient.WorkflowServiceStubs;
   import io.temporal.serviceclient.WorkflowServiceStubsOptions;
   import io.temporal.worker.Worker;
   import io.temporal.worker.WorkerFactory;

   public class MetricsWorker {
       static final String WORK_FLOW_TASK_QUEUE = "WORK_FLOW_TASK_QUEUE"; //This can be a work flow task name used to differentiate the metrics logs from other work flow

       public static void main(String[] args) {

           PrometheusMeterRegistry registry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
           StatsReporter reporter = new MicrometerClientStatsReporter(registry);

           // set up a new scope, report every 10 seconds
           Scope scope = new RootScopeBuilder()
                   .tags(ImmutableMap.of(
                           "workerCustomTag1",
                           "workerCustomTag1Value",
                           "workerCustomTag2",
                           "workerCustomTag2Value"))
                   .reporter(reporter)
                   .reportEvery(com.uber.m3.util.Duration.ofSeconds(10));

           // For Prometheus collection, expose the scrape endpoint at port 8077. See Micrometer documentation for details on starting the Prometheus scrape endpoint. For example,
           HttpServer scrapeEndpoint = MetricsUtils.startPrometheusScrapeEndpoint(registry, 8077); //note: MetricsUtils is a utility file with the scrape endpoint configuration. See Micrometer docs for details on this configuration.
           // Stopping the starter stops the HTTP server that exposes the scrape endpoint.
           //Runtime.getRuntime().addShutdownHook(new Thread(() -> scrapeEndpoint.stop(1)));

           //Create Workflow service stubs to connect to the Frontend Service.
           WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(
                   WorkflowServiceStubsOptions.newBuilder()
                           .setMetricsScope(scope) //set the metrics scope for the WorkflowServiceStubs
                           .build());

           //Create a Workflow service client, which can be used to start, signal, and query Workflow Executions.
           WorkflowClient yourClient = WorkflowClient.newInstance(service,
                   WorkflowClientOptions.newBuilder().build());


           Runtime.getRuntime().addShutdownHook(new Thread(() -> scrapeEndpoint.stop(1)));
           // Add metrics scope to workflow service stub options
           WorkerFactory factory = WorkerFactory.newInstance(yourClient);

           Worker worker = factory.newWorker(WORK_FLOW_TASK_QUEUE);
           worker.registerWorkflowImplementationTypes(SampleWorkflowImpl.class);//Design a workflow incorporating temporal elements and invoking activities within it. Determine where to capture metrics logs and register them with the worker
           worker.registerActivitiesImplementations(new SampleActivityImpl());  // Develop an Activity interface utilizing temporal annotations, proceed to its implementation, and establish a connection with the worker by mapping it to registerActivities

           factory.start();
       }
   }
   ```

2. 스크래핑 엔드포인트에 대한 설정을 포함하는 `MetricsUtils.java` 파일을 프로젝트의 기본 디렉터리에 생성합니다.

   ```java
   package <add_your_project_main_directory>; // please add your java application main directory name.

   import com.sun.net.httpserver.HttpServer;
   import io.micrometer.prometheus.PrometheusMeterRegistry;
   import static java.nio.charset.StandardCharsets.UTF_8;
   import java.io.IOException;
   import java.io.OutputStream;
   import java.net.InetSocketAddress;

   public class MetricsUtils {
      public static HttpServer startPrometheusScrapeEndpoint(
              PrometheusMeterRegistry registry, int port) {
          try {
              HttpServer server = HttpServer.create(new InetSocketAddress(port), 0);
              server.createContext(
                      "/metrics",
                      httpExchange -> {
                          String response = registry.scrape();
                          httpExchange.sendResponseHeaders(200, response.getBytes(UTF_8).length);
                          try (OutputStream os = httpExchange.getResponseBody()) {
                              os.write(response.getBytes(UTF_8));
                          }
                      });

              server.start();
              return server;
          } catch (IOException e) {
              throw new RuntimeException(e);
          }
      }
   }
   ```

3. `dependency section` 아래의 `build.gradle` 파일에 의존성/종속성을 추가합니다.

   ```java
   implementation "io.micrometer:micrometer-registry-prometheus"
   ```

4. 아래 스니펫을 복사하고 `build.gradle` 파일 작업에서 프로젝트와 관련된 디렉터리로 `mainClass` 를 수정하여 작업자를 시작합니다.

   ```java
   task startMetricsWorker(type: JavaExec) {
      mainClass = '<ProjectRoot.MetricsWorker>' // Add your MetricsWorker file directory.
      classpath = sourceSets.main.runtimeClasspath
   }
   ```

5. 프로젝트 디렉토리로 이동하여 빌드하십시오.

   ```yml
   ./gradlew build
   ```

6. 작업자를 시작합니다.

   ```yml
   ./gradlew startMetricsWorker
   ```

7. 노출된 Prometheus Scrape 엔드포인트의 작업자 지표를 확인하세요: `http://<YOUR_DOMAIN>:8077/metrics`.

<Callout
  title="메모"
  variant="tip"
>
  SDK 지표 설정에 대한 자세한 내용은 Temporal 공식 [문서를](https://docs.temporal.io/self-hosted-guide/monitoring#sdk-metrics-setup) 참조하세요.
</Callout>

## NRI-프로메테우스 구성 [#configure-prometheus]

성공적으로 설치되면 블루베리 인프라 에이전트가 실행됩니다. nri-prometheus 설정 파일을 생성하려면 다음 단계를 따르십시오.

1\. 이 경로에 이름이 `nri-prometheus-temporal-config.yml` 인 파일을 만듭니다.

```yml
cd /etc/newrelic-infra/integrations.d/
```

`nri-prometheus-temporal-config.yml` 파일을 생성한 후 `YOUR_HOST_IP` 사용하여 URL을 업데이트해야 합니다.

URL: `["http://<YOUR_HOST_IP>:8000/metrics", "http://<YOUR_HOST_IP>:8077/metrics"]`

```yml
integrations:
  - name: nri-prometheus
    config:
      standalone: false
      # Defaults to true. When standalone is set to `false`, `nri-prometheus` requires an infrastructure agent to send data.
      emitters: infra-sdk
      # When running with infrastructure agent emitters will have to include infra-sdk
      cluster_name: Temporal_Server_Metrics
      # Match the name of your cluster with the name seen in New Relic.
      targets:
        - description: Temporal_Server_Metrics
          urls: ["http://<YOUR_DOMAIN>:8000/metrics", "http://<YOUR_DOMAIN>:8077/metrics"]
      #    tls_config:
      #      ca_file_path: "/etc/etcd/etcd-client-ca.crt"
      #      cert_file_path: "/etc/etcd/etcd-client.crt"
      #      key_file_path: "/etc/etcd/etcd-client.key"
      verbose: false
      # Defaults to false. This determines whether or not the integration should run in verbose mode.
      audit: false
      # Defaults to false and does not include verbose mode. Audit mode logs the uncompressed data sent to New Relic and can lead to a high log volume.
      # scrape_timeout: "YOUR_TIMEOUT_DURATION"
      # `scrape_timeout` is not a mandatory configuration and defaults to 30s. The HTTP client timeout when fetching data from endpoints.
      scrape_duration: "5s"
      # worker_threads: 4
      # `worker_threads` is not a mandatory configuration and defaults to `4` for clusters with more than 400 endpoints. Slowly increase the worker thread until scrape time falls between the desired `scrape_duration`. Note: Increasing this value too much results in huge memory consumption if too many metrics are scraped at once.
      insecure_skip_verify: false
      # Defaults to false. Determins if the integration should skip TLS verification or not.
    timeout: 10s
```

### 임시 로그 설정 [#temporal-logs-configuration]

임시 로그를 구성하려면 아래 설명된 단계를 따르세요.

1. 다음 docker 명령을 실행하여 실행 중인 컨테이너의 상태를 확인합니다.

```shell
sudo docker ps
```

2. **임시UI** 컨테이너의 컨테이너 ID를 복사하고 제공된 명령을 실행합니다.

```shell
sudo docker logs -f <container_id> &> /tmp/temporal.log &
```

그런 다음 `temporal.log` 이라는 `/tmp/` 디렉터리에 있는 로그 파일을 확인합니다.

### 뉴렐릭으로 임시 로그 전달 중 [#temporal-logs-to-newrelic]

우리의 [로그 포워딩을](https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/) 사용하여 임시 로그를 뉴렐릭으로 전달할 수 있습니다. Linux 시스템에서는 log.yml이라는 로그 파일이 다음 경로에 있어야 합니다.

```shell
cd /etc/newrelic-infra/logging.d/
```

로그 파일이 생성되면 후속 스크립트를 `logging.yml` 파일에 포함합니다.

```yml
logs:
  - name: temporal_logs
    file: /tmp/temporal.log
    attributes:
      logtype: temporal_logs
```

### 인프라 에이전트 다시 시작

데이터 읽기를 시작하기 전에 [인프라 에이전트 문서](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/) 의 지침을 사용하여 인프라 에이전트를 다시 시작하세요.

```bash
sudo systemctl restart newrelic-infra.service
```

몇 분 안에 귀하의 Temporal이 지표를 [one.newrelic.com](https://one.newrelic.com/) 으로 보낼 것입니다.

## 데이터 찾기 [#find-your-data]

Temporal 이라는 사전 구축된 대시보드 템플릿을 선택하여 Temporal 지표를 모니터링할 수 있습니다. 사전 구축된 대시보드 템플릿을 사용하려면 다음 단계를 따르세요.

1. [one.newrelic.com](https://one.newrelic.com/) 에서, **+ Add data** \[+ 데이터 추가] 페이지로 이동합니다.
2. **대시보드 를**클릭합니다.
3. 검색창에 **Temporal** 를 입력합니다.
4. Temporal 대시보드가 나타나야 합니다. 그것을 클릭하여 설치하십시오.

Temporal 대시보드는 사용자 정의 대시보드로 간주되며 대시보드 UI에서 찾을 수 있습니다.대시보드 사용 및 편집에 대한 문서는 [대시보드 문서 를](https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/) 참조하세요.

다음은 Temporal 요청 대기 시간 합계를 확인하는 NRQL 쿼리입니다:

```sql
SELECT sum(temporal_request_latency_sum) FROM Metric

```