---
title: 아파치 플링크 통합
tags:
  - Integrations
  - Configure Prometheus OpenMetrics for Flink
  - Apache Flink integration on New Relic
metaDescription: Get a dashboard of all your most important Flink metrics with our quickstart.
translationType: machine
---

import dashboardsApacheFlinkQuickstart from 'images/dashboards_screenshot-full_apache-flink-quickstart.webp'

Apache Flink 대시보드를 사용하면 로그를 쉽게 추적하고 계측 소스를 주시하고 모든 애플리케이션 인스턴스의 가동 시간 및 가동 중지 시간에 대한 개요를 얻을 수 있습니다. 인프라 에이전트와 Prometheus OpenMetrics 통합으로 구축된 Flink <InlinePopover type="dashboards"/>OpenMetrics 엔드포인트 스크래핑을 활용하여 가장 중요한 모든 데이터를 한 곳에서 볼 수 있습니다.

<img
  src={dashboardsApacheFlinkQuickstart}
  title="Apache Flink dashboard landing page"
  alt="A screenshot of a dashboard with Apache Flink metrics."
/>

<figcaption>
  Flink를 New Relic으로 설정하면 데이터가 이와 같은 대시보드에 바로 표시됩니다.
</figcaption>

## 인프라 에이전트 설치 [#install]

Flink 데이터를 New Relic으로 가져오기 전에 먼저 인프라 에이전트를 설치한 다음 Prometheus OpenMetrics를 설치하여 메트릭을 노출하십시오.

인프라 에이전트를 설치하는 방법에는 두 가지가 있습니다.

* [가이드 설치를](https://one.newrelic.com/nr1-core?state=5e236fa2-fbfd-1f53-e55d-9241d2a73068)통해 .
* 명령줄을 통해 인프라 에이전트를 [수동으로](/docs/infrastructure/install-infrastructure-agent/linux-installation/install-infrastructure-monitoring-agent-linux)설치합니다.

## 메트릭을 노출하도록 Apache Flink 구성 [#expose-apache-flink-metrics]

구성된 포트에서 메트릭을 노출하려면 Apache Flink prometheus jar 파일이 필요합니다. 이상적으로는 Apache Flink를 다운로드할 때 `flink-metrics-prometheus-VERSION.jar` 라는 파일이 아래 경로에 배치됩니다.

파일 경로: `FLINK-DIRECTORY/plugins/metrics-prometheus/`

위에서 언급한 jar 파일이 다운로드한 flink 디렉터리에 없으면 다른 maven jar 아티팩트에서 다운로드할 수 있습니다. 아래 예시 URL을 사용하여 `flink-metrics-prometheus-VERSION.jar` 파일을 다운로드합니다. 아래는 다운로드할 수 있는 외부 URL입니다.

외부 URL: [https://jar-download.com/artifacts/org.apache.flink/flink-metrics-prometheus](https://jar-download.com/artifacts/org.apache.flink/flink-metrics-prometheus)

flink 구성 파일을 업데이트하여 포트 9250-9260에서 메트릭을 노출합니다.

Apache Flink 구성 파일 경로: `FLINK-DIRECTORY/conf/flink-conf.yaml`

```yml
metrics.reporters: prom
metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter
metrics.reporter.prom.factory.class: org.apache.flink.metrics.prometheus.PrometheusReporterFactory
metrics.reporter.prom.host: localhost
metrics.reporter.prom.port: 9250-9260
```

아래 명령에 따라 Apache Flink 클러스터를 시작합니다.

```bash
./bin/start-cluster.sh
```

이제 아래 URL에서 측정항목을 볼 수 있습니다.

* 작업 관리자 지표

```yml
http://YOUR_DOMAIN:9250
```

* 작업 관리자 메트릭

```yml
http://YOUR_DOMAIN:9251
```

아래 명령을 실행하여 PC에서 실행 중인 다른 작업 관리자 포트가 있는지 교차 확인할 수도 있습니다.

```yml
sudo lsof -i -P -n | grep LISTEN
```

## Apache Flink용 `nri-prometheus` 구성 [#configure]

먼저 아래 경로에 `nri-prometheus-config.yml` 이라는 파일을 생성합니다.

길: `/etc/newrelic-infra/integrations.d`

이제 아래 나열된 필드를 업데이트합니다.

* cluster_name: “YOUR_DESIRED_CLUSTER_NAME”, 예: `cluster_name: "apache_flink"`
* URL: \["http&#x3A;//YOUR_DOMAIN:9250", "http&#x3A;//YOUR_DOMAIN:9251"], 예: `urls: [“http://localhost:9250”, “http://localhost:9251”]`

`nri-prometheus-config.yml` 파일은 다음과 같아야 합니다.

```yml
integrations:
  - name: nri-prometheus
    config:
      standalone: false
      # Defaults to true. When standalone is set to `false`, `nri-prometheus` requires an infrastructure agent to send data.
      emitters: infra-sdk
      # When running with infrastructure agent emitters will have to include infra-sdk
      cluster_name: "YOUR_DESIRED_CLUSTER_NAME"
      # Match the name of your cluster with the name seen in New Relic. 
      targets:
        - description: "YOUR_DESIRED_DESCRIPTION_HERE"
          urls: ["http://YOUR_DOMAIN:9250", "http://YOUR_DOMAIN:9251"]
      #    tls_config:
      #      ca_file_path: "/etc/etcd/etcd-client-ca.crt"
      #      cert_file_path: "/etc/etcd/etcd-client.crt"
      #      key_file_path: "/etc/etcd/etcd-client.key"

      verbose: false
      # Defaults to false. This determines whether or not the integration should run in verbose mode.
      audit: false
      # Defaults to false and does not include verbose mode. Audit mode logs the uncompressed data sent to New Relic and can lead to a high log volume.
      # scrape_timeout: "YOUR_TIMEOUT_DURATION"
      # `scrape_timeout` is not a mandatory configuration and defaults to 30s. The HTTP client timeout when fetching data from endpoints.
      scrape_duration: "5s"
      # worker_threads: 4
      # `worker_threads` is not a mandatory configuration and defaults to `4` for clusters with more than 400 endpoints. Slowly increase the worker thread until scrape time falls between the desired `scrape_duration`. Note: Increasing this value too much results in huge memory consumption if too many metrics are scraped at once.
      insecure_skip_verify: false
      # Defaults to false. Determins if the integration should skip TLS verification or not.
    timeout: 10s
```

## 수동으로 로그 전달 설정 [#logs]

[로그 전달](https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/) 문서를 사용하여 애플리케이션별 로그를 New Relic에 전달할 수 있습니다.

Linux 머신에 인프라 에이전트를 설치할 때 이름이 `logging.yml` 인 로그 파일이 `/etc/newrelic-infra/logging.d/`경로에 있어야 합니다.

위의 경로에서 로그 파일이 보이지 않으면 위의 로그 전달 문서에 따라 로그 파일을 생성해야 합니다.

다음은 아래와 유사한 로그 이름의 예입니다.

```yml
- name: flink-u1-taskexecutor-0-u1-VirtualBox.log
```

`logging.yml` 파일에 아래 스크립트를 추가하여 New Relic에 Apache Flink 로그를 보냅니다.

```yml
logs:
  - name: flink-<REST_OF_THE_FILE_NAME>.log 
    file: <FLINK-DIRECTORY>/log/flink-<REST_OF_THE_FILE_NAME>.log
    attributes:
      logtype: flink_logs
```

## New Relic 인프라 에이전트 다시 시작 [#restart-infrastructure-agent]

데이터 읽기를 시작하기 전에 [인프라 에이전트를 다시 시작하십시오](/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/).

## New Relic에서 Apache Flink 모니터링

Apache Flink라는 사전 빌드된 대시보드 템플릿을 사용하여 Apache Flink 지표를 모니터링하려면 다음 단계를 따르십시오.

1. **[one.newrelic.com](https://one.newrelic.com/)** 으로 이동하여 **+ Add Data** \[+ 데이터 추가를]클릭합니다.
2. **대시보드** 탭을 클릭합니다.
3. 검색 상자에서 **Apache Flink** 를검색합니다.
4. Apache Flink 대시보드를 클릭하여 계정에 설치합니다.

위의 단계에 따라 애플리케이션이 통합되면 대시보드에 메트릭이 반영되어야 합니다.

Apache Flink 빠른 시작을 계측하고 메트릭 및 경고를 보려면 지금 설치 버튼을 [클릭하여 Apache Flink](https://newrelic.com/instant-observability/apache-flink) **Install now** \[빠른 시작] 페이지를 따를 수도 있습니다.

## NRQL을 사용하여 데이터 쿼리

NRQL을 사용하여 [데이터를 쿼리](/docs/apis/nerdgraph/examples/nerdgraph-nrql-tutorial/)할 수 있습니다. 예를 들어 New Relic의 쿼리 빌더에서 완료된 총 체크포인트 수를 보려면 다음 NRQL 쿼리를 사용하십시오.

```sql
FROM Metric SELECT latest(flink_jobmanager_job_numberOfCompletedCheckpoints) AS 'Number of Completed Checkpoints'
```

## 다음은 뭐지?

Apache Flink 대시보드를 추가로 사용자 정의하려면 NRQL 쿼리 작성 및 관리에 대해 자세히 알아볼 수 있습니다. <InlinePopover type="dashboards"/>New Relic UI에서:

* 기본 및 고급 쿼리를 생성 [하기 위한 쿼리 빌더 소개](/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder)
* [대시보드를 사용자 지정하고 다양한 작업을 수행하기 위한 대시보드 소개](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards)
* 대시보드를 [관리하여 대시](/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard) 보드 표시 모드를 조정하거나 대시보드에 더 많은 콘텐츠를 추가합니다.