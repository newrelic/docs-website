---
title: Prometheus OpenMetrics 통합 구성
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure OpenMetrics
metaDescription: Configuration options and examples for your Prometheus OpenMetrics integration with New Relic in Docker and Kubernetes environments.
freshnessValidatedDate: never
translationType: machine
---

달리 명시하지 않는 한, 뉴렐릭과 Prometheus OpenMetrics 통합에 대한 설정 옵션은 docker 및 Kubernetes 환경 모두에 적용됩니다. 최소한 다음 설정 값은 <DNT>**required**</DNT> 입니다.

* <InlinePopover type="licenseKey" />
* [클러스터 이름](#definitions-configuration-file)

권장 사항: 뉴렐릭 클러스터 키를 `LICENSE_KEY` 환경 변수로 구성하세요. 뉴렐릭이 [상호 TLS 인증 비밀](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) 에서 환경 변수를 로드할 수 있으므로 이는 보다 안전한 환경을 제공합니다.

## nri-prometheus-latest.yaml 구성 [#general-config]

`nri-prometheus-latest.yaml` 매니페스트 파일에는 예시 구성을 보여주는 `nri-prometheus-cfg` 맵이 포함되어 있습니다. 매니페스트 파일을 사용하여 다음 매개변수를 구성합니다.

<CollapserGroup>
  <Collapser id="example-configuration-file" title="예제 구성 파일">
    다음은 필요에 맞게 저장하고 수정할 수 있는 구성 파일의 예입니다. 자세한 내용은 [상호 TLS 인증](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) 및 [PromQL을 NRQL로 변환](/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql) 에 대한 설명서를 참조하십시오.

    ```yml
    # The name of your cluster. It's important to match other New Relic products to relate the data.
    cluster_name: "YOUR_CLUSTER_NAME"

    # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true
    # standalone: true

    # How often the integration should run. Defaults to 30s.
    # scrape_duration: "30s"

    # The HTTP client timeout when fetching data from targets. Defaults to 5s.
    # scrape_timeout: "5s"

    # How old must the entries used for calculating the counters delta be
    # before the telemetry emitter expires them. Defaults to 5m.
    # telemetry_emitter_delta_expiration_age: "5m"

    # How often must the telemetry emitter check for expired delta entries.
    # Defaults to 5m.
    # telemetry_emitter_delta_expiration_check_interval: "5m"

    # Wether the integration should run in verbose mode or not. Defaults to false.
    verbose: false

    # Whether the integration should run in audit mode or not. Defaults to false.
    # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent.
    # It does not include verbose mode. This can lead to a high log volume, use with care.
    audit: false

    # Wether the integration should skip TLS verification or not. Defaults to false.
    insecure_skip_verify: false

    # The label used to identify scrapable targets. Defaults to "prometheus.io/scrape".
    scrape_enabled_label: "prometheus.io/scrape"

    # scrape_services Allows to enable scraping the service and not the endpoints behind.
    # When endpoints are scraped this is no longer needed
    scrape_services: true

    # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does.
    # Please notice that depending on the number of endpoints behind a service the load can increase considerably
    scrape_endpoints: false

    # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true.
    require_scrape_enabled_label_for_nodes: true

    # Number of worker threads used for scraping targets.
    # For large clusters with many (>400) targets, slowly increase until scrape
    # time falls between the desired `scrape_duration`.
    # Increasing this value too much will result in huge memory consumption if too
    # many metrics are being scraped.
    # Default: 4
    # worker_threads: 4

    # Maximum number of metrics to keep in memory until a report is triggered.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # max_stored_metrics: 10000

    # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # min_emitter_harvest_period: 200ms

    # targets:
    #   - description: Secure etcd example
    #     urls: ["https://192.168.3.1:2379", "https://192.168.3.2:2379", "https://192.168.3.3:2379"]
    #     tls_config:
    #       ca_file_path: "/etc/etcd/etcd-client-ca.crt"
    #       cert_file_path: "/etc/etcd/etcd-client.crt"
    #       key_file_path: "/etc/etcd/etcd-client.key"

    # Proxy to be used by the emitters when submitting metrics. It should be
    # in the format [scheme]://[domain]:[port].
    # The emitter is the component in charge of sending the scraped metrics.
    # This proxy won't be used when scraping metrics from the targets.
    # By default it's empty, meaning that no proxy will be used.
    # emitter_proxy: "http://localhost:8888"

    # Certificate to add to the root CA that the emitter will use when
    # verifying server certificates.
    # If left empty, TLS uses the host's root CA set.
    # emitter_ca_file: "/path/to/cert/server.pem"

    # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account
    # having limited privileges. Defaults to false.
    # disable_autodiscovery: false

    # Whether the emitter should skip TLS verification when submitting data.
    # Defaults to false.
    # emitter_insecure_skip_verify: false

    # Histogram support is based on New Relic's guidelines for higher
    # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md.
    # To better support visualization of this data, percentiles are calculated
    # based on the histogram metrics and sent to New Relic.
    # By default, the following percentiles are calculated: 50, 95 and 99.
    #
    # percentiles:
    #   - 50
    #   - 95
    #   - 99

    # transformations:
    #   - description: "General processing rules"
    #     rename_attributes:
    #       - metric_prefix: ""
    #         attributes:
    #           container_name: "containerName"
    #           pod_name: "podName"
    #           namespace: "namespaceName"
    #           node: "nodeName"
    #           container: "containerName"
    #           pod: "podName"
    #           deployment: "deploymentName"
    #     ignore_metrics:
    #       # Ignore all the metrics except the ones listed below.
    #       # This is a list that complements the data retrieved by the New
    #       # Relic Kubernetes Integration, that's why Pods and containers are
    #       # not included, because they are already collected by the
    #       # Kubernetes Integration.
    #       - except:
    #         - kube_hpa_
    #         - kube_daemonset_
    #         - kube_statefulset_
    #         - kube_endpoint_
    #         - kube_service_
    #         - kube_limitrange
    #         - kube_node_
    #         - kube_poddisruptionbudget_
    #         - kube_resourcequota
    #         - nr_stats
    #     copy_attributes:
    #       # Copy all the labels from the time series with metric name
    #       # `kube_hpa_labels` into every time series with a metric name that
    #       # starts with `kube_hpa_` only if they share the same `namespace`
    #       # and `hpa` labels.
    #       - from_metric: "kube_hpa_labels"
    #         to_metrics: "kube_hpa_"
    #         match_by:
    #           - namespace
    #           - hpa
    #       - from_metric: "kube_daemonset_labels"
    #         to_metrics: "kube_daemonset_"
    #         match_by:
    #           - namespace
    #           - daemonset
    #       - from_metric: "kube_statefulset_labels"
    #         to_metrics: "kube_statefulset_"
    #         match_by:
    #           - namespace
    #           - statefulset
    #       - from_metric: "kube_endpoint_labels"
    #         to_metrics: "kube_endpoint_"
    #         match_by:
    #           - namespace
    #           - endpoint
    #       - from_metric: "kube_service_labels"
    #         to_metrics: "kube_service_"
    #         match_by:
    #           - namespace
    #           - service
    #       - from_metric: "kube_node_labels"
    #         to_metrics: "kube_node_"
    #         match_by:
    #           - namespace
    #           - node
    # integration definition files required to map metrics to entities
    # definition_files_path: /etc/newrelic-infra/definition-files
    ```
  </Collapser>

  <Collapser id="definitions-configuration-file" title="키 이름 및 정의">
    다음은 Prometheus OpenMetrics 구성 파일에 대한 몇 가지 주요 이름과 정의입니다.

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px" }}>
            키 이름
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr id="cluster-name">
          <td>
            `cluster_name`

            <DNT>
              **Required.**
            </DNT>
          </td>

          <td>
            클러스터의 이름입니다. 이 값은 모든 측정항목에 대한 `clusterName` 속성으로 포함됩니다.
          </td>
        </tr>

        <tr id="verbose">
          <td>
            `verbose`
          </td>

          <td>
            문자열화된 부울.

            * `true` (기본값): 디버깅 정보를 기록합니다.
            * `false`: 오류 메시지만 기록합니다.
          </td>
        </tr>

        <tr id="targets">
          <td>
            `targets`
          </td>

          <td>
            통합에서 스크랩할 정적 끝점의 구성입니다. 여기에는 개체 목록이 포함되어 있습니다. 이 구조에 대한 자세한 내용은 [대상 구성](#target-config) 에 대한 설명서를 참조하십시오.
          </td>
        </tr>

        <tr id="scrape-enabled-label">
          <td>
            `scrape_enabled_label`

            <img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

            <DNT>**Kubernetes**</DNT>
          </td>

          <td>
            끈. 통합은 Kubernetes 포드 및 서비스에 주석이 달렸는지 또는 스크랩해야 하는지 결정하기 위해 이 값이 포함된 레이블이 있는지 확인합니다.

            이는 메트릭을 무시하거나 New Relic으로 전송되는 특정 메트릭을 포함하여 데이터 양을 제한하려는 경우에 특히 유용합니다. 기본적으로 Prometheus가 스크랩할 수 있는 대상을 검색하는 데 사용하는 것과 동일한 레이블을 사용하기 때문에 설치하는 대부분의 내보내기는 이 레이블을 자동으로 설정합니다.

            통합을 스크레이핑할 대상에 대한 세부적인 제어를 유지하려면 이 옵션을 다른 값(예: `newrelic/scrape` )으로 설정한 다음 주석 또는 레이블 `newrelic/scrape: "true"` 을 Kubernetes 객체에 추가할 수 있습니다. 둘 다 설정되면 주석이 레이블보다 우선합니다.

            기본: `"prometheus.io/scrape"`
          </td>
        </tr>

        <tr id="scrape-duration">
          <td>
            `scrape_duration`
          </td>

          <td>
            스크레이퍼를 얼마나 자주 실행해야 합니다.

            * 메모리 사용량을 줄이려면 이 값을 늘리십시오.

            * 메모리 사용량을 높이려면 이 값을 줄이십시오.

              메모리 사용량에 대한 영향은 모든 데이터를 한 번에 쿼리(및 버퍼링)하는 것을 피하기 위해 스크랩 간격에 걸쳐 대상 가져오기를 분산하기 때문입니다.

              기본값은 `30s` 입니다. 유효한 값은 `1s` , `15s` , `30s` , `1m` , `5m` 등입니다.
          </td>
        </tr>

        <tr id="scrape-timeout">
          <td>
            `scrape_timeout`
          </td>

          <td>
            엔드포인트에서 데이터를 가져올 때 HTTP 클라이언트 시간이 초과되었습니다.

            기본값: `5s` . 유효한 값은 `1s` , `15s` , `30s` , `1m` , `5m` 등입니다.
          </td>
        </tr>

        <tr>
          <td>
            `worker_threads`
          </td>

          <td>
            스크래핑 대상에 사용되는 작업자 스레드 수입니다. 대기 시간이 긴 대상 또는 대상 수가 많은 환경에서 늘릴 수 있지만 메모리 소비가 증가할 수 있습니다.

            기본값: `4` . 10개 이상 사용하지 않는 것이 좋습니다.
          </td>
        </tr>

        <tr>
          <td>
            `require_scrape_enabled_label_for_nodes`

            <img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

            <DNT>**Kubernetes**</DNT>
          </td>

          <td>
            Kubernetes 노드에 레이블을 스크랩해야 하는지 여부.

            기본값: `true` .
          </td>
        </tr>

        <tr id="percentiles">
          <td>
            `percentiles`
          </td>

          <td>
            히스토그램 지원은 [더 높은 수준의 메트릭 추상화에 대한 New Relic의 지침을](https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md) 기반으로 합니다.

            이 데이터의 시각화를 더 잘 지원하기 위해 히스토그램 메트릭을 기반으로 백분위수가 계산되어 New Relic으로 전송됩니다. 유효한 값은 `50` , `95` 및 `99` 입니다.
          </td>
        </tr>

        <tr>
          <td id="emitter-proxy">
            `emitter_proxy`
          </td>

          <td>
            측정항목을 제출할 때 통합에서 사용하는 프록시:

            `[scheme]://[domain]:[port]`

            이 프록시는 대상에서 메트릭을 가져올 때 사용되지 않습니다.

            기본적으로 비어 있으며 프록시가 사용되지 않습니다.
          </td>
        </tr>

        <tr>
          <td id="emitter-ca-file">
            `emitter_ca_file`
          </td>

          <td>
            서버 인증서를 확인할 때 이미터가 사용할 루트 CA에 추가할 인증서입니다. 비워 두면 TLS는 호스트의 루트 CA 세트를 사용합니다.
          </td>
        </tr>

        <tr id="emitter-insecure-skip-verify">
          <td>
            `emitter_insecure_skip_verify`
          </td>

          <td>
            데이터를 제출할 때 이미터가 TLS 확인을 건너뛸지 여부입니다. 기본값: `false` .
          </td>
        </tr>

        <tr id="disable-autodiscovery">
          <td>
            `disable_autodiscovery`
          </td>

          <td>
            k8s 클러스터에서 자동 검색을 비활성화하려면 true로 설정하십시오. 제한된 권한을 가진 서비스 계정으로 Pod를 실행할 때 유용할 수 있습니다. 기본값: `false` .
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## 대상 키의 개체 구성 [#target-config]

구성 파일의 대상 키에 하나 이상의 개체가 포함되도록 하려면 YAML 목록에서 다음 구조를 사용합니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        키 이름
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr id="description">
      <td>
        `description`
      </td>

      <td>
        이 대상의 URL에 대한 설명입니다.
      </td>
    </tr>

    <tr id="urls">
      <td>
        `urls`
      </td>

      <td>
        스크랩할 URL이 있는 문자열 목록입니다.
      </td>
    </tr>

    <tr id="tls-config">
      <td>
        `tls_config`
      </td>

      <td>
        요청을 보내는 데 사용되는 인증 구성입니다. TLS 및 상호 TLS를 지원합니다. 자세한 내용은 [상호 TLS 인증](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) 에 대한 설명서를 참조하십시오.
      </td>
    </tr>
  </tbody>
</table>

<CollapserGroup>
  <Collapser
    id="specify-path-port"
    title={<><img src="/images/os_icon_k8.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ width: '30px', height: '25px' }} /></>
    }
  >
    New Relic의 Prometheus OpenMetrics 통합은 스크래핑할 대상을 자동으로 검색합니다. 대상을 구성할 때 사용할 포트 및 엔드포인트 경로를 지정하려면 Kubernetes 포드 및 서비스에서 `prometheus.io/port` 및 `prometheus.io/path` 주석 또는 레이블을 사용할 수 있습니다. 주석이 레이블보다 우선합니다.

    * `prometheus.io/port` 이 없으면 통합은 서비스에 대해 정의된 각 `port` 또는 `ContainerPort` 를 스크랩하려고 시도합니다.
    * `prometheus.io/path` 이 없으면 통합은 기본적으로 `/metrics` 로 설정됩니다.
    * 서비스가 기본 `/my-metrics-path` 경로에서 실행되고 있지 않으면 포드 `prometheus.io/path=my-metrics-path` 에 레이블을 추가합니다. 메트릭 엔드포인트에 대한 경로가 더 복잡하고 유효한 레이블 값이 될 수 없는 경우(예: `foo/bar` ) 대신 주석을 사용하십시오.
  </Collapser>

  <Collapser
    id="example-port-path"
    title={<><img src="/images/os_icon_k8.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ width: '30px', height: '25px' }} /></>
    }
  >
    이 예에서는 클러스터에 배포가 있고 포드는 포트 `8080` 및 경로에서 Prometheus 측정항목을 노출합니다. `my-metrics.`

    배포 매니페스트의 `PodSpec` 메타데이터에서 `prometheus.io/port: "8080"` 및 `prometheus.io/path: "my-metrics"` 라벨을 설정합니다. 통합이 포드에서 측정항목을 검색하려고 하면 `http://<pod-ip>:8080/my-metrics` 에 요청을 보냅니다.

    ```yml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-deployment
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: my-app
      template:
        metadata:
          labels:
            app: my-app
            prometheus.io/scrape: "true"
            prometheus.io/port: "8080"
            prometheus.io/path: "my-metrics"
    ```
  </Collapser>
</CollapserGroup>

## 서비스 및 엔드포인트 스크래핑 동작

기본적으로 서비스는 `scrape_services` 이 `true` 로, `scrape_endpoints` 가 `false` 으로 설정되어 있으므로 기본 엔드포인트 대신 직접 스크래핑됩니다.

이 동작을 변경하려면 `scrape_endpoints` 를 `true` 로 설정하여 서비스를 직접 사용하는 대신 Prometheus 서버가 기본적으로 수행하는 것처럼 기본 엔드포인트를 긁어내도록 `Prometheus OpenMetrics integrations` 를 구성합니다.

클러스터의 서비스 뒤에 있는 엔드포인트 수에 따라 로드 및 수집된 데이터가 상당히 증가할 수 있으며, 모니터링하고 필요한 경우 리소스 요구 사항을 증가시킬 수 있습니다.

또한 `scrape_services` 및 `scrape_endpoints` 을 모두 true로 설정하여 역호환성을 보장할 수 있더라도 데이터가 중복될 수 있습니다.

## 구성 다시 로드 [#reload-config]

Prometheus OpenMetrics 통합 <DNT>**does not**</DNT> 설정 파일을 변경할 때 설정을 자동으로 다시 로드합니다.

<img style={{ width: '30px', height: '25px'}} class="inline" title="Docker icon" alt="Docker icon" src="/images/os_icon_docker.webp" />

<DNT>**Docker**</DNT>

구성을 다시 로드하려면 통합을 실행하는 컨테이너를 다시 시작합니다.

```sh
docker restart nri-prometheus
```

<img style={{ width: '30px', height: '25px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src="/images/os_icon_k8.webp" />

<DNT>**Kubernetes**</DNT>

설정을 다시 로드하려면 통합을 다시 시작하세요. 권장 사항: 배포를 복제본 0개로 축소한 다음 다시 복제본 1개로 축소합니다.

```sh
kubectl scale deployment nri-prometheus --replicas=0
kubectl scale deployment nri-prometheus --replicas=1
```

## Docker: 이전 구성 파일 실행 [#run-previous]

<img style={{ width: '30px', height: '25px'}} class="inline" title="Docker icon" alt="Docker icon" src="/images/os_icon_docker.webp" />

<DNT>**Docker:**</DNT> 이전 설정 파일로 통합을 실행하려면:

1. 콘텐츠를 복사하여 `config.yaml` 파일에 저장합니다.

2. 동일한 디렉토리 내에서 다음 명령을 실행합니다.

   ```sh
   docker run -d --restart unless-stopped \
       --name nri-prometheus \
       -e CLUSTER_NAME="YOUR_CLUSTER_NAME" \
       -e LICENSE_KEY="YOUR_LICENSE_KEY" \
       -v "$(pwd)/config.yaml:/config.yaml" \
       newrelic/nri-prometheus:latest --configfile=/config.yaml
   ```