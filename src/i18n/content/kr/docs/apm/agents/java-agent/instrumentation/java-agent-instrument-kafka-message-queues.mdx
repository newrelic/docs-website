---
title: 'Java 에이전트: Kafka 메시지 큐 계측'
tags:
  - Agents
  - Java agent
  - Instrumentation
metaDescription: 'New Relic for Java includes built-in Kafka monitoring, as well as advanced event and distributed tracing data collection.'
translationType: machine
---

New Relic Java 에이전트는 [Kafka](https://kafka.apache.org/documentation/) 의 Java 클라이언트 라이브러리에서 자동으로 데이터를 수집합니다. Kafka는 많은 데이터를 생성하는 고성능 메시징 시스템이므로 앱의 특정 처리량 및 사용 사례에 맞게 에이전트를 사용자 지정할 수 있습니다.

이 문서에서는 세 가지 유형의 Kafka 데이터를 수집하고 보는 방법을 설명합니다.

* [카프카 메트릭](#view-kafka-metrics)
* [카프카 이벤트](#collect-kafka-events)
* [Kafka 분산 추적](#collect-kafka-distributed-traces)

Kafka 계측은 Java 에이전트 버전 4.12.0 이상에서 사용할 수 있습니다. 지원되는 Kafka 클라이언트 버전은 [Java 호환성 및 요구 사항](/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent) 을 참조하십시오.

<Callout variant="tip">
  Kafka 통합에 대해서는 [Kafka 모니터링 통합](/docs/integrations/host-integrations/host-integrations-list/kafka-monitoring-integration) 을 참조하십시오.
</Callout>

## Kafka 측정항목 보기

[설치](/docs/agents/java-agent/installation/install-java-agent) 후 에이전트는 메시징 속도, 대기 시간, 지연 등에 대한 정보와 함께 풍부한 Kafka 메트릭을 자동으로 보고합니다. Java 에이전트는 모든 [Kafka 소비자 및 생산자 메트릭](https://kafka.apache.org/documentation/#monitoring) (연결 또는 스트림 메트릭은 아님)을 수집합니다.

이러한 측정항목을 보려면 사용자 정의 대시보드를 만드십시오.

1. [New Relic 메트릭 탐색기](/docs/insights/use-insights-ui/explore-data/metric-explorer-search-chart-metrics-sent-new-relic-agents) 로 이동합니다.

2. 측정항목 탐색기를 사용하여 측정항목을 찾습니다. 이 메트릭 폴더에서 Kafka 메트릭을 찾을 수 있습니다.

   ```
   MessageBroker/Kafka/Internal/<var>KafkaMetricName</var>
   ```

   예를 들어 `request-rate` 측정항목은 다음 위치에 있습니다.

   ```
   MessageBroker/Kafka/Internal/consumer-metrics/request-rate
   ```

   <Callout variant="tip">
     Kafka 소비자 및 생산자 메트릭의 전체 목록은 [Kafka 설명서](https://kafka.apache.org/documentation/#monitoring) 를 참조하십시오.
   </Callout>

3. 대시보드에 **추가 를** 클릭하여 모니터링할 메트릭을 대시보드에 추가합니다.

## Kafka 이벤트 수집 활성화 [#collect-kafka-events]

메트릭 타임슬라이스 데이터 대신 이벤트 데이터를 수집하도록 에이전트를 구성할 수 있습니다(메트릭 타임슬라이스와 이벤트 데이터의 차이점은 [데이터 수집](/docs/using-new-relic/metrics/analyze-your-metrics/data-collection-metric-timeslice-event-data#overview) 참조). 이를 통해 [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) 을 사용하여 기본 Kafka 메트릭을 필터링하고 패싯할 수 있습니다. 활성화된 경우 에이전트는 30초마다 하나의 Kafka 이벤트를 수집합니다. 이 이벤트는 [Kafka 소비자의 모든 데이터를 포함하고 이전 이벤트 이후 캡처된 메트릭을 생성](https://kafka.apache.org/documentation/#monitoring) 합니다.

<Callout variant="important">
  에이전트는 [수집 주기](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#harvest-cycle) 당 최대 2000개의 이벤트를 기록하지만 [`max_samples_stored`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored) 을(를) 사용하여 이 값을 변경할 수 있습니다. Kafka 이벤트 데이터는 이 풀에 포함됩니다. `recordCustomEvent()` API 호출을 사용하여 [사용자 지정 이벤트](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents) 를 New Relic에 보내고 2000개 이상의 이벤트를 보내는 경우 에이전트는 일부 Kafka 또는 사용자 지정 이벤트를 삭제합니다.
</Callout>

Kafka 이벤트 수집을 활성화하려면:

1. `newrelic.yml` 구성 파일에 `kafka.metrics.as_events.enabled` 요소를 추가합니다.

   ```
   kafka.metrics.as_events.enabled: true
   ```

2. JVM을 다시 시작하십시오.

3. [이벤트 탐색기](/docs/insights/use-insights-ui/explore-data/event-explorer-query-chart-your-event-data) 를 사용하여 `KafkaMetrics` 이벤트 유형에 있는 Kafka 이벤트를 봅니다. 또는 [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) 을 사용하여 이벤트를 직접 쿼리합니다. 예를 들어:

   ```
   SELECT average('producer-metrics.record-send-rate') from KafkaMetrics SINCE 30 minutes ago timeseries
   ```

## Kafka 분산 추적 사용 [#collect-kafka-distributed-traces]

Java 에이전트는 Kafka 클라이언트에서 [분산 추적](/docs/apm/distributed-tracing/getting-started/introduction-distributed-tracing) 을 수집할 수도 있습니다. 추적을 활성화해도 에이전트의 일반 작업에는 영향을 미치지 않습니다. 여전히 Kafka의 메트릭 또는 이벤트 데이터를 보고합니다.

활성화하기 전에 고려해야 할 영향 및 요구 사항:

* **계측은 메시지 헤더에 150-200바이트 페이로드를 추가합니다.** Kafka 메시지가 매우 작은 경우 추적으로 인해 상당한 처리 및 저장 오버헤드가 추가될 수 있습니다. 이 추가 페이로드 크기로 인해 Kafka 메시징 크기 제한을 초과하는 경우 Kafka에서 메시지를 삭제할 수 있습니다. 이러한 이유로 프로덕션 환경에서 활성화하기 전에 개발 환경에서 Kafka 분산 추적을 테스트하는 것이 좋습니다.
* 분산 추적은 Kafka 클라이언트 버전 0.11.0.0 이상에서만 사용할 수 있습니다.
* 이전에 앱에 대해 분산 추적을 활성화 **하지 않은** 경우 활성화하기 전에 [전환 가이드](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) 를 읽으십시오.
* Kafka 메시지 헤더를 통해 W3C 추적 컨텍스트를 전파하려면 Java 에이전트 6.4.0에서 릴리스된 API에 대한 자세한 내용은 [분산 추적 API 사용 안내서](/docs/agents/java-agent/api-guides/guide-using-java-agent-api#trace-calls) 를 참조하십시오. Kafka 메시지에 추가 헤더를 추가하면 페이로드 크기가 더 늘어납니다. 작동 중인 이러한 API를 보려면 [Kafka와 함께 Java 에이전트 추적 API 사용](https://github.com/newrelic/newrelic-java-examples/tree/main/newrelic-java-agent/distributed-tracing/kafka-examples) 을 참조하십시오.

이를 활성화하는 전체 프로세스는 아래에 있지만 상위 수준에서는 1) 에이전트 구성을 통해 추적을 활성화하고 2) 생산자와 소비자 측 모두에서 트랜잭션을 계측하기 위해 [Java 에이전트 API](/docs/agents/java-agent/api-guides/guide-using-java-agent-api) 를 호출하는 기본 단계를 포함합니다.

Kafka에서 분산 추적을 수집하려면 다음을 수행합니다.

<CollapserGroup>
  <Collapser
    id="enable-dt-kafka"
    title="1. 구성 파일에서 분산 추적 활성화"
  >
    이전에 앱에 대해 분산 추적을 활성화하지 않은 경우 활성화하기 전에 [분산 추적 전환 가이드](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) 를 읽으십시오.

    Kafka 분산 추적을 활성화하려면 [`newrelic.yml` 구성 파일](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Structure) 에서 다음 두 가지 설정을 활성화해야 합니다.

    * [`distributed_tracing`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#distributed-tracing) 요소가 활성화되어 있는지 확인합니다.

      ```
      distributed_tracing:
        enabled: true
      ```

    * 구성 파일에 다음을 추가하여 Kafka 관련 분산 추적 기능을 활성화합니다.

      ```
      class_transformer:
        com.newrelic.instrumentation.kafka-clients-spans-0.11.0.0:
          enabled: true
      ```
  </Collapser>

  <Collapser
    id="instrument-kafka-producer"
    title="2. Kafka 생산자 계측"
  >
    Kafka 생산자를 계측하려면 `Producer.send(ProducerRecord<K, V> record)` 을 호출하기 전에 트랜잭션을 시작해야 합니다. 이렇게 하려면 메소드에 Java 에이전트 `@Trace(dispatcher = true)` 주석을 추가하십시오.

    예를 들어:

    ```
    @Trace(dispatcher = true)
    public static void createAndSend(KafkaProducer<String, String> producer){
        ProducerRecord<String, String> data = new ProducerRecord<String, String>("topic", "key", "value");
        producer.send(data);
    }
    ```
  </Collapser>

  <Collapser
    id="instrument-kafka-consumer"
    title="3. Kafka 소비자 계측"
  >
    Kafka 소비자를 계측하려면 메시지가 처리될 때 트랜잭션을 시작해야 합니다. 에이전트는 `newrelic` 키 또는 W3C의 `traceparent` 및 `tracestate` 키 아래에 분산 추적 페이로드 헤더를 저장합니다. 헤더를 검색한 다음 New Relic 트랜잭션 API를 호출하여 페이로드를 수락합니다.

    예를 들어:

    ```
    @Trace(dispatcher = true)
    private static void <var>processMessage</var>(ConsumerRecord<String, String> rec) {
      // create a distributed trace headers map
      Headers dtHeaders = ConcurrentHashMapHeaders.build(HeaderType.MESSAGE);

      // Iterate through each record header and insert the trace headers into the dtHeaders map
      for (Header header : rec.headers()) {
        String headerValue = new String(header.value(), StandardCharsets.UTF_8);

        // using the newrelic key
        if (header.key().equals("newrelic")) {
          dtHeaders.addHeader("newrelic", headerValue);
        }

        // or using the W3C keys
        if (header.key().equals("traceparent")) {
          dtHeaders.addHeader("traceparent", headerValue);
        }

        if (header.key().equals("tracestate")) {
          dtHeaders.addHeader("tracestate", headerValue);
        }
      }

      // Accept distributed tracing headers to link this request to the originating request
      NewRelic.getAgent().getTransaction().acceptDistributedTraceHeaders(TransportType.Kafka, dtHeaders);
    }
    ```
  </Collapser>
</CollapserGroup>