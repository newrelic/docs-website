---
title: Confluent Cloud 및 Kafka 모니터링을 위한 수집기
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector.
freshnessValidatedDate: never
translationType: machine
---

OpenTelemetry Collector를 사용하여 Confluent Cloud 관리 Kafka 배포에 대한 지표를 수집할 수 있습니다. 수집기는 원격 측정 데이터를 수집, 처리 및 New Relic(또는 관측 가능성 백엔드)으로 내보내는 OpenTelemetry의 구성 요소입니다.

이 통합은 OpenTelemetry 수집기 내에서 prometheus 수신기 구성을 실행하여 작동합니다. 이는 [Confluent Cloud의 메트릭 API를](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w) 스크랩하고 해당 데이터를 New Relic으로 내보냅니다.

Confluent에서 Kafka 측정항목을 수집하고 New Relic으로 내보내려면 아래 단계를 완료하세요.

<Steps>
  <Step>
    ## 설정되었는지 확인하세요.

    시작하기 전에 <InlinePopover type="licenseKey"/>데이터를 보고하려는 계정에 대해 또한 다음 사항도 확인해야 합니다.

    * 도커 데몬이 실행 중입니다.
    * [Docker Compose가](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) 설치되어 있습니다.
    * [Confluent Cloud 계정이](https://www.confluent.io/get-started/)있습니다
    * [Confluent Cloud API 키와 비밀번호를](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html) 사용할 수 있습니다.
  </Step>

  <Step>
    ## 예제 저장소 다운로드 또는 복제

    이 설정에서는 예제 수집기 구성을 사용하므로 [New Relic의 OpenTelemetry 예제 저장소를](https://github.com/newrelic/newrelic-opentelemetry-examples) 다운로드하세요. 설치가 완료되면 [Confluent Cloud 예제](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) 디렉터리를 엽니다. 자세한 내용은 여기에서 `README` 를 확인하세요.
  </Step>

  <Step>
    ## 환경 변수 설정 및 수집기 실행

    * `.env` 파일에서 Confluent Cloud와 New relic 모두에 대한 API 키 및 비밀 변수를 설정합니다.
    * 대상 Kafka 클러스터 ID로 `Cluster_ID` 변수를 설정합니다.
    * (선택사항) Confluent Cloud에서 관리하는 커넥터 또는 스키마 레지스트리를 모니터링하려면 `collector.yaml` 파일에서 구성의 주석 처리를 취소하고 `.env` 파일에서 해당 ID를 설정할 수 있습니다.

    ```bash
    # Open the confluent cloud example directory
    cd newrelic-opentelemetry-examples/other-examples/collector/confluentcloud

    # Set environment variables.

    # run the collector in docker
    docker compose up
    ```

    ### 지역변수 정보

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px"}}>
            변하기 쉬운
          </th>

          <th>
            설명
          </th>

          <th>
            문서
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic 수집 API 키
          </td>

          <td>
            [API 키 문서](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            기본 US New Relic OTLP 엔드포인트는 [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)입니다.
          </td>

          <td>
            [OTLP 엔드포인트 구성 문서](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/get-started/opentelemetry-set-up-your-app/#review-settings)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            Confluent Cloud의 클러스터 ID
          </td>

          <td>
            [클러스터 ID 목록 명령에 대한 문서](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            클라우드 API 키
          </td>

          <td>
            [Cloud API 키 문서](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            클라우드 API 비밀
          </td>

          <td>
            [Cloud API 키 문서](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (선택 사항) 여기에서 ID를 지정하여 Confluent 커넥터를 모니터링할 수 있습니다
          </td>

          <td>
            [커넥터 ID 목록 명령에 대한 문서](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (선택 사항) 여기에 ID를 지정하여 Confluent Schema Registry를 모니터링할 수 있습니다.
          </td>

          <td>
            [커넥터 ID 목록 명령에 대한 문서](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ## New Relic에서 데이터 보기

    몇 가지 다른 방법으로 Confluent Cloud 데이터를 볼 수 있습니다.

    * [New Relic 마켓플레이스](https://one.newrelic.com/marketplace) 로 이동하여 `Confluent` 를) 검색하세요. 사용 가능한 대시보드를 귀하의 계정에 바로 설치할 수 있습니다!
    * 측정항목 탐색기로 이동하여 `confluent_kafka` 을(를) 필터링합니다. 이 데이터는 모든 사용자 정의 경고 또는 대시보드에 추가될 수 있습니다.
  </Step>
</Steps>

### Confluent Cloud 측정항목 [#confluent-metrics]

[이 통합은 Confluent Cloud Metrics API 내에서 내보낼](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud) 수 있는 모든 __측정항목을 다룹니다. 아래에는 _내보낼 수 있는_ 측정항목의 일부 목록이 있습니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        이름
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        네트워크에서 수신한 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 샘플 이후 수신된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        네트워크를 통해 전송된 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        수신된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 샘플 이후에 수신된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        전송된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        클러스터에서 보유하고 있는 현재 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        활성 인증 연결 수입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        네트워크를 통해 수신된 요청의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 수신된 요청 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        파티션 수
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        성공한 인증의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 성공한 인증 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        그룹 구성원의 커밋된 오프셋과 파티션의 상위 워터마크 사이의 지연입니다.
      </td>
    </tr>
  </tbody>
</table>