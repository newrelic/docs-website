---
title: Confluent Cloud 및 Kafka 모니터링을 위한 수집기
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector.
freshnessValidatedDate: never
translationType: machine
---

OpenTelemetry Collector를 사용하여 Confluent Cloud 관리 Kafka 배포에 대한 지표를 수집할 수 있습니다. 수집기는 원격 측정 데이터를 수집, 처리 및 New Relic(또는 관측 가능성 백엔드)으로 내보내는 OpenTelemetry의 구성 요소입니다.

docker에서 실행되는 OpenTelemetry 수집기를 사용하여 Confluent에서 Kafka 측정항목을 수집하려면 아래 단계를 완료하세요.

<Steps>
  <Step>
    ## 설정되었는지 확인하세요.

    시작하기 전에 <InlinePopover type="licenseKey"/>데이터를 보고하려는 계정에 대해 또한 다음 사항도 확인해야 합니다.

    * 도커 데몬이 실행 중입니다.
    * [Docker Compose가](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) 설치되어 있습니다.
    * [Confluent Cloud 계정이](https://www.confluent.io/get-started/)있습니다
  </Step>

  <Step>
    ## 예제 저장소 다운로드 또는 복제

    이 설정에서는 예제 수집기 구성을 사용하므로 [New Relic의 OpenTelemetry 예제 저장소를](https://github.com/newrelic/newrelic-opentelemetry-examples)다운로드하세요. 설치가 완료되면 [Confluent Cloud 예제](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) 디렉터리를 엽니다. 자세한 내용은 여기에서 `README` 를 확인하세요.
  </Step>

  <Step>
    ## 인증 파일 추가

    이 예제 설정에서는 TLS를 사용하여 Confluent Cloud에 대한 요청을 인증합니다. 인증 방법에는 여러 가지가 있으므로 회사의 모범 사례와 인증 방법을 따라야 합니다.

    * TLS/SSL을 사용하려면 키와 인증서를 만들고, 자체 CA(인증 기관)를 만들고, 인증서에 서명해야 합니다.

    * 이렇게 하면 이 디렉터리에 추가해야 하는 세 개의 파일이 남게 됩니다.

    * 이 예에서는 이러한 파일을 다음 파일로 참조합니다: `key.pem`, `cert.pem`, `ca.pem`.

      <Callout variant="important">
        Confluent Cloud를 사용한 TLS 인증에 대한 자세한 내용은 [TLS 인증 문서](https://docs.confluent.io/platform/current/kafka/authentication_ssl.html) 와 [보안 튜토리얼을](https://docs.confluent.io/platform/current/security/security_tutorial.html) 확인하세요.

        개발/테스트 Confluent 환경의 경우 일반 텍스트 인증을 사용하여 이를 단순화할 수 있습니다.
      </Callout>
  </Step>

  <Step>
    ## 환경 변수 설정 및 수집기 실행

    다음 변수를 내보내거나 `.env` 파일에 추가한 후 `docker compose up` 명령을 실행합니다.

    ```bash
    # Open the confluent cloud example directory
    cd newrelic-opentelemetry-examples/other-examples/collector/confluentcloud

    # Set environment variables.
    export NEW_RELIC_API_KEY=<YOUR_API_KEY>
    export NEW_RELIC_OTLP_ENDPOINT=https://otlp.nr-data.net
    export CLUSTER_ID=<YOUR_CLUSTER_ID>
    export CLUSTER_API_KEY=<YOUR_CLUSTER_API_KEY>
    export CLUSTER_API_SECRET=<YOUR_CLUSTER_API_SECRET>
    export CLUSTER_BOOTSTRAP_SERVER=<YOUR_CLUSTER_BOOTSTRAP_SERVER>

    # run the collector in docker
    docker compose up
    ```

    ### 지역변수 정보

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px"}}>
            변하기 쉬운
          </th>

          <th>
            설명
          </th>

          <th>
            문서
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic 수집 API 키
          </td>

          <td>
            [API 키 문서](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            New Relic OTLP 엔드포인트는 [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)입니다.
          </td>

          <td>
            [OTLP 엔드포인트 구성 문서](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/get-started/opentelemetry-set-up-your-app/#review-settings)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            Confluent Cloud의 클러스터 ID
          </td>

          <td>
            Confluent 클러스터 설정에서 사용 가능
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_ID`
          </td>

          <td>
            클라우드 API 키
          </td>

          <td>
            [Cloud API 키 문서](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            클라우드 API 비밀
          </td>

          <td>
            [Cloud API 키 문서](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_BOOTSTRAP_SERVER`
          </td>

          <td>
            클러스터용 부트스트랩 서버
          </td>

          <td>
            클러스터 설정에서 사용 가능
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ## New Relic에서 데이터 보기

    몇 가지 다른 방법으로 Confluent Cloud 데이터를 볼 수 있습니다.

    * [New Relic 마켓플레이스](https://one.newrelic.com/marketplace) 로 이동하여 `Confluent` 를) 검색하세요. 사용 가능한 대시보드를 귀하의 계정에 바로 설치할 수 있습니다!
    * 측정항목 탐색기로 이동하여 `confluent_kafka` 을(를) 필터링합니다. 이 데이터는 모든 사용자 정의 경고 또는 대시보드에 추가될 수 있습니다.
  </Step>
</Steps>

### Confluent Cloud 측정항목 [#confluent-metrics]

[이 통합은 Confluent Cloud Metrics API 내에서 내보낼](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud) 수 있는 모든 __측정항목을 다룹니다. 아래에는 _내보낼 수 있는_ 측정항목의 일부 목록이 있습니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        이름
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        네트워크에서 수신한 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 샘플 이후 수신된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        네트워크를 통해 전송된 고객 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        수신된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 샘플 이후에 수신된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        전송된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        클러스터에서 보유하고 있는 현재 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        활성 인증 연결 수입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        네트워크를 통해 수신된 요청의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 수신된 요청 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        파티션 수
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        성공한 인증의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 성공한 인증 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        그룹 구성원의 커밋된 오프셋과 파티션의 상위 워터마크 사이의 지연입니다.
      </td>
    </tr>
  </tbody>
</table>