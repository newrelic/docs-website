---
title: Confluent Cloud 및 Kafka 모니터링을 위한 수집기
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
  - kubernetes
  - helm
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector on Kubernetes.
freshnessValidatedDate: '2024-05-28T00:00:00.000Z'
translationType: machine
---

OpenTelemetry Collector를 사용하여 Confluent Cloud 관리 Kafka 배포에 대한 지표를 수집할 수 있습니다. 수집기는 원격 측정 데이터를 수집, 처리 및 New Relic(또는 관측 가능성 백엔드)으로 내보내는 OpenTelemetry의 구성 요소입니다.

이 통합은 OpenTelemetry 수집기 내에서 Prometheus 수신기 설정을 실행하여 작동합니다. 이는 [Confluent Cloud의 지표 API](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w) 스크랩하고 해당 데이터를 뉴렐릭으로 내보냅니다.

## 모니터링 설정 [#set-up-monitoring]

Confluent에서 Kafka 측정항목을 수집하고 New Relic으로 내보내려면 아래 단계를 완료하세요.

<Steps>
  <Step>
    ### 시작할 준비가 되었는지 확인하세요. [#get-started]

    시작하기 전에 데이터를 보고하려는 계정에 대한 <InlinePopover type="licenseKey"/>가 있어야 합니다. 또한 다음 사항도 확인해야 합니다.

    * 쿠버네티스 클러스터가 실행 중입니다.
    * (Helm 사용자의 경우) [Helm이](https://helm.sh/docs/intro/quickstart/) 설치되어 있는지 확인하십시오.
    * 클러스터가 실행 중인 [Confluent Cloud 계정이](https://www.confluent.io/get-started/) 있습니다.
    * [Confluent Cloud API 키와 비밀번호를](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html) 사용할 수 있습니다.
  </Step>

  <Step>
    ### OpenTelemetry 기술 파트너 예제 저장소 다운로드 또는 복제 [#download-repo]

    이 설정에서는 예제 수집기 설정을 사용하므로 [뉴렐릭의 OpenTelemetry 기술 파트너십 예제를](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations) 다운로드하세요. 설치가 완료되면 [Confluent Cloud 예제](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations/confluent-cloud) 디렉터리를 엽니다. 자세한 내용은 여기에서 `README` 확인하세요.
  </Step>

  <Step>
    ### 예제 실행 [#run-the-example]

    환경에 따라 아래의 Helm 또는 Kubernetes 지침을 완료하세요.

    #### 투구 예 [#run-helm-example]

    1. `./confluent-cloud/helm` 디렉터리에서 `values.yaml` 파일의 변수를 업데이트합니다. 개별 변수에 대한 자세한 내용은 아래 [지역 변수](#local-variables) 표를 참조하세요.

    2. 다음 명령을 사용하여 수집기를 실행합니다.

       ```bash
       # Open the confluent cloud helm example directory
       cd ./confluent-cloud/helm

       # Make sure to set environment variables.

       # Install and run helm
       helm install ./helm
       ```

    #### 쿠버네티스 예시 [#run-kubernetes-example]

    1. `./confluent-cloud/k8s` 디렉터리에서 `./k8s/deployment.yaml` 파일의 변수를 업데이트합니다. 개별 변수에 대한 자세한 내용은 아래 [지역 변수](#local-variables) 표를 참조하세요.

    2. 변수가 설정되면 다음 명령을 실행하여 쿠버네티스 클러스터에 수집기를 적용합니다.

       ```bash
       # Open the Confluent Cloud k8s example directory
       cd ./confluent-cloud/k8s

       # Make sure to set environment variables

       # Apply the collector to the cluster
       kubectl apply -f ./k8s
       ```

    #### Helm 및 Kubernetes용 지역 변수 [#local-variables]

    <table>
      <thead>
        <tr>
          <th style={{ width: "275px"}}>
            변하기 쉬운
          </th>

          <th>
            설명
          </th>

          <th>
            문서
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic 수집 API 키
          </td>

          <td>
            [API 키 문서](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            기본 US New Relic OTLP 엔드포인트는 [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)입니다.
          </td>

          <td>
            [OTLP 엔드포인트 구성 문서](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            Confluent Cloud의 클러스터 ID
          </td>

          <td>
            [클러스터 ID 목록 명령에 대한 문서](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            클라우드 API 키
          </td>

          <td>
            [Cloud API 키 문서](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            클라우드 API 비밀
          </td>

          <td>
            [Cloud API 키 문서](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (선택 사항) 여기에서 ID를 지정하여 Confluent 커넥터를 모니터링할 수 있습니다
          </td>

          <td>
            [커넥터 ID 목록 명령에 대한 문서](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (선택 사항) 여기에 ID를 지정하여 Confluent Schema Registry를 모니터링할 수 있습니다.
          </td>

          <td>
            [커넥터 ID 목록 명령에 대한 문서](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ### New Relic에서 데이터 보기 [#view-your-data]

    몇 가지 다른 방법으로 Confluent Cloud 데이터를 볼 수 있습니다.

    * [뉴렐릭 마켓플레이스](https://one.newrelic.com/marketplace) 로 이동하여 `Confluent`(를) 검색하세요. 사용 가능한 대시보드를 계정에 바로 설치할 수 있습니다!
    * 측정항목 탐색기로 이동하여 `confluent_kafka` 을(를) 필터링합니다. 이 데이터는 모든 사용자 정의 경고 또는 대시보드에 추가될 수 있습니다.
  </Step>
</Steps>

## Confluent Cloud 측정항목 [#confluent-metrics]

[이 통합은 Confluent Cloud Metrics API 내에서 내보낼](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud) 수 있는 모든 __측정항목을 다룹니다. 아래에는 _내보낼 수 있는_ 측정항목의 일부 목록이 있습니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        이름
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        네트워크에서 수신된 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 샘플 이후 수신된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        네트워크를 통해 전송된 데이터의 델타 바이트 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        수신된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 샘플 이후에 수신된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        전송된 레코드의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 전송된 레코드 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        클러스터에서 보유하고 있는 현재 바이트 수입니다. 카운트는 60초마다 샘플링됩니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        활성 인증 연결 수입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        네트워크를 통해 수신된 요청의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 수신된 요청 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        파티션 수
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        성공한 인증의 델타 수입니다. 각 샘플은 이전 데이터 포인트 이후 성공한 인증 수입니다. 60초마다 샘플링된 카운트입니다.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        그룹 구성원의 커밋된 오프셋과 파티션의 상위 워터마크 사이의 지연입니다.
      </td>
    </tr>
  </tbody>
</table>