---
title: 설정 관리
metaDescription: Overview of the Agent Control configuration
freshnessValidatedDate: never
translationType: machine
---

<Callout variant="important">
  Agent Control과 뉴렐릭 Control이 이제 Kubernetes 에서 **정식 출시됩니다** ! Linux 호스트에 대한 지원은 [사전 출시 정책](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy) 에 따라 **공개 미리보기** 프로그램에서도 제공됩니다.
</Callout>

에이전트 Control은 구현, 배포되는 환경의 독립성을 설정하기 위한 원활한 접근 방식을 제공합니다. 에이전트 설정을 관리하는 방법에는 두 가지가 있습니다:

* **로컬 설정:** 초기 Helm 설치 중에 사용된 포괄적인 `values.yaml` 파일입니다.

* **원격 설정:** 뉴렐릭 Control에서 생성하는 중앙 집중식 YAML 기반 설정으로 전체 차량에 원격으로 구현되고 배포됩니다.

일상적인 관리에는 원격 설정이 권장됩니다. 이를 통해 환경 전반에서 일관된 에이전트 동작이 보장되고, 변경 관리가 간소화되며, 각 호스트의 로컬 YAML 파일을 수동으로 업데이트하지 않고도 확장할 수 있습니다.

<Callout variant="tip">
  전통적으로 뉴렐릭 에이전트 설정을 정의했던 `values-newrelic.yaml` 파일에는 이제 에이전트 제어에 대한 설정도 포함되어 있습니다. 이 파일에서 정의한 지표는 에이전트 제어와 해당 관리 에이전트의 작동 방식을 결정합니다. 이 파일을 로컬 설정이라고 합니다.
</Callout>

## 설정의 두 가지 계층 이해하기

Agent Control의 설정은 두 가지 계층으로 구성됩니다.

1. **Agent Control의 핵심 설정:** Agent Control의 작동 방식(예: 뉴렐릭에 대한 연결, ID 및 차량 관리 세부 정보)을 제어하는 최상위 설정입니다.

2. **관리형 에이전트 설정:** 에이전트 Control 구현하다, 배포하다 및 관리하는 각 하위 에이전트(예: 에이전트 에이전트, Fluent Bit)에 대한 개별 `chart_values` 입니다.

로컬 및 원격 설정이 모두 있는 경우 에이전트 Control은 다음 논리를 적용합니다.

1. 원격 설정이 우선합니다. 뉴렐릭 Control의 원격 설정에서 정의된 모든 설정은 로컬 `values.yaml` 파일의 해당 설정을 재정의합니다.
2. 의도적으로 로컬 설정으로 원격 설정을 재정의하려면 뉴렐릭 Control을 통해 빈 원격 설정을 구현, 배포할 수 있습니다. 이 변경 사항은 선택한 함대의 모든 클러스터에 적용됩니다.

## Kubernetes 설정

이 지침과 예시는 쿠버네티스 클러스터에서 실행되는 Agent Control에 적용됩니다.

### Kubernetes용 로컬 `values.yaml` 설정

설치 중에 사용되는 Kubernetes 의 로컬 설정 파일에는 에이전트 제어 및 관리 에이전트에 대한 모든 설정이 포함되어 있습니다.

이 예에서는 하나의 파일 내에 두 개의 설정 계층이 있는 것을 보여줍니다.

<CollapserGroup>
  <Collapser id="agent-control-config" title="에이전트 Control 설정">
    ```yaml
    # Layer 1: Agent Control's Core Configuration
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"

    # Values related to the Agent Control's Helm chart release.
    # `https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml`
    agentControlDeployment:
      chartValues:
        systemIdentity:
          organizationId: "****"
          parentIdentity:
            clientId: "****"
            clientSecret: "****"
        config:
          fleet_control:
            # Optional: Specify a fleet_id (entity guid) to automatically connect to an existing fleet.
            fleet_id: "****"

          # Layer 2: Managed Agents' Configurations
          # List of managed agents that will be deployed. The key represents the name of the agent and the value holds the configuration.
          agents:
            infrastructure:
              agent_type: newrelic/com.newrelic.infrastructure:0.1.0
            logs:
              agent_type: newrelic/io.fluentbit:0.1.0
            agent-operator:
              agent_type: com.newrelic.k8s_agent_operator:0.1.0

        agentsConfig:
          infrastructure:
            # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/nri-bundle`
            # Recommended: check and define an explicit chart version (latest stable)
            chart_version: "*"
            chart_values:
              newrelic-infrastructure:
              enableProcessMetrics: true
          logs:
            # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging`
            # Recommended: check and define an explicit chart version (latest stable)
            chart_version: "*"
            chart_values:
              newrelic-logging:
                sendMetrics: true
          agent-operator:
            chart_version: "*"
    ```
  </Collapser>
</CollapserGroup>

이 샘플은 두 가지 관리 에이전트( Kubernetes 에이전트 에이전트 및 포워딩용 Fluent Bit 와 함께 에이전트 제어를 구성하는 방법을 보여줍니다. 예를 들어 Fluent Bit 로그 수집기에 대한 상태 지표를 보내지 않으려면 설치 명령을 실행하기 전에 YAML 파일에서 `sendMetrics: false` 설정하기만 하면 됩니다.

### Kubernetes에 대한 원격 설정

원격 설정을 사용하면 환경 전반에서 일관된 에이전트 동작이 보장되고, 변경 관리가 간소화되며, 로컬 YAML 파일을 수동으로 관리하지 않고도 옵저버빌리티를 확장할 수 있습니다.

클러스터 전체에 구성을 중앙에서 배포하려면 [Fleet Control](/docs/new-relic-control/fleet-control/overview)의 **Configurations** \[구성] 섹션에서 동일한 YAML 콘텐츠를 정의합니다.그런 다음 원격 구현, 배포의 일부로 클러스터의 전체 집합에 설정을 적용할 수 있습니다. 이것을 **원격 설정** 파일이라고 합니다.

<Callout variant="tip">
  뉴렐릭 Control UI 에서 setup을 정의하면 YAML 구조가 다릅니다. 단일 에이전트의 `content` 블록에 해당하는 YAML만 제공합니다.
</Callout>

### 샘플 설정: Kubernetes의 에이전트 제어

설정: Kubernetes 의 에이전트 제어 다음 예에서는 에이전트 제어를 구성하여 다양한 에이전트 세트를 관리하는 방법을 보여줍니다. 이 설정은 초기 설치 중이나 플릿위험의 원격 설정의 일부로 사용될 수 있습니다.

사용 가능한 모든 구성 설정을 살펴보려면 [`values-newrelic.yaml`](https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml) 을 참조하세요.

다음 예제에서는 로컬 `values.yaml` 파일을 사용하여 하위 에이전트 세트로 에이전트 제어를 구성하는 방법을 보여줍니다.

#### 뉴렐릭 인프라 및 Fluent Bit사용한 에이전트 제어

이 예시에서는 배포하다 에이전트 제어를 부하 모니터링 및 Fluent Bit 통해 생성 수집에 사용합니다.

<CollapserGroup>
  <Collapser id="agent-control-config" title="인프라 및 Fluent Bit에 대한 로컬 구성">
    ```yaml
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"

    # See `https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml`
    agentControlDeployment:
      chartValues:
        systemIdentity:
          organizationId: "****"
          parentIdentity:
            clientId: "****"
            clientSecret: "****"
        config:
          fleet_control:
            # Optional: Specify a fleet_id (entity guid) to automatically connect to an existing fleet.
            fleet_id: "****"
          agents:
            infrastructure:
              agent_type: newrelic/com.newrelic.infrastructure:0.1.0
            logs:
              agent_type: newrelic/io.fluentbit:0.1.0
            agent-operator:
              agent_type: com.newrelic.k8s_agent_operator:0.1.0
        agentsConfig:
          infrastructure:
            # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/nri-bundle`
            # Recommended: check and define an explicit chart version (latest stable)
            chart_version: "*"

            #chart_values:
            #  newrelic-infrastructure:
            #    enableProcessMetrics: true
          logs:
            # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging`
            # Recommended: check and define an explicit chart version (latest stable)
            chart_version: "*"

            #chart_values:
            #  newrelic-logging:
            #    sendMetrics: true
          agent-operator:
            chart_version: "*"
    ```
  </Collapser>
</CollapserGroup>

#### OpenTelemetry 및 사용자 정의 수집기 설정을 사용한 에이전트 제어

OpenTelemetry 및 사용자 정의 수집기 설정 사용 이 예제는 OpenTelemetry (NRDOT) 수집기의 뉴렐릭 분포를 사용하여 배포하다 에이전트 제어하고 관리되는 [`nr-k8s-otel-collector` Helm 차트](https://github.com/newrelic/helm-charts/tree/master/charts/nr-k8s-otel-collector#values) 에서 `filelog` 수신기를 비활성화합니다.

<Callout variant="important">
  보안 모범 사례: 볼륨 키와 같은 민감한 값을 설정에 직접 저장하지 마세요. Kubernetes 비밀번호를 사용하는 것이 좋습니다. 그러면 에이전트 제어가 런타임에 비밀에서 이러한 값을 안전하게 가져올 수 있습니다.
</Callout>

<CollapserGroup>
  <Collapser id="otel-config" title="OpenTelemetry 설정">
    ```yaml
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"
    # Values related to the Agent Control's Helm chart release.
    # `https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml`
    agentControlDeployment:
      chartValues:
        systemIdentity:
          organizationId: "****"
          parentIdentity:
            clientId: "****"
            clientSecret: "****"
        config:
          fleet_control:
            # Optional: Specify a fleet_id (entity guid) to automatically connect to an existing fleet.
            fleet_id: "****"

          # List of managed agents that will be deployed. The key represents the name of the agent and the value holds the configuration.
          agents:
            infrastructure:
              agent_type: newrelic/com.newrelic.infrastructure:0.1.0
            agent-operator:
              agent_type: newrelic/com.newrelic.k8s_agent_operator:0.1.0
            fluentbit:
              agent_type: newrelic/io.fluentbit:0.1.0
            prometheus:
              agent_type: newrelic/com.newrelic.prometheus:0.1.0
        # List of managed agents that will be deployed. The key represents the name of the agent and the value holds the configuration.
        agentsConfig:
          infrastructure:
            # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/nri-bundle%60
            # Recommended: check and define an explicit chart version (latest stable)
            chart_version: "*"
          agent-operator:
            chart_version: "*"
          fluentbit:
            # Ref: `https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging`
            # Recommended: check and define an explicit chart version (latest stable)
            chart_version: "*"
            chart_values:
              global:
                lowDataMode: true
          prometheus:
            chart_version: "*"
            chart_values:
              global:
                lowDataMode: true
              newrelic-prometheus-agent:
                config:
                  kubernetes:
                    integrations_filter:
                      enabled: false
    ```
  </Collapser>
</CollapserGroup>

### 샘플 설정: Kubernetes의 원격 에이전트 설정

다음 예에서는 **Newrelic Control** UI 에서 개별 에이전트를 원격으로 구성하는 방법을 보여줍니다.

#### 원격 설정: 뉴렐릭 인프라 

이 예에서는 플릿 위험을 사용하여 Kubernetes 용 뉴렐릭 인프라 에이전트를 원격으로 구성하는 방법을 보여줍니다. `enableProcessMetrics: true` 설정하여 프로세스 메트릭 수집을 활성화합니다.

<CollapserGroup>
  <Collapser id="infra-remote-config" title="원격 설정">
    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-infrastructure:
        enableProcessMetrics: true
    ```
  </Collapser>
</CollapserGroup>

#### 원격 설정: Fluent Bit

이 예에서는 플로릿 위험을 통해 원격으로 Fluent Bit 구성했습니다. `sendMetrics: true` 설정하여 로그 수집기에서 상태 지표 보고를 활성화합니다.

<CollapserGroup>
  <Collapser id="fluentbit-remote-config" title="Fluent Bit 설정">
    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-logging:
        sendMetrics: true
    ```
  </Collapser>
</CollapserGroup>

#### 원격 설정: Prometheus

이 예에서는 플릿위험을 사용하여 원격으로 Prometheus 에이전트를 구성합니다. `low-data mode` 사용하여 Telmetri 볼륨을 줄이고 기본 통합을 비활성화할 수 있습니다.

<CollapserGroup>
  <Collapser id="prometheus-config" title="프로메테우스 설정">
    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-prometheus-agent:
        lowDataMode: true
    ```
  </Collapser>
</CollapserGroup>

#### 원격 설정: OpenTelemetry

이 예제에서는 뉴렐릭 OpenTelemetry 수집기를 구성하고 `lowDataMode` 유효한 옵션으로 활성화합니다.

<Callout variant="important">
  보안 모범 사례: 볼륨 키와 같은 민감한 값을 설정에 직접 저장하지 마세요. Kubernetes 비밀번호를 사용하는 것이 좋습니다. 그러면 에이전트 제어가 런타임에 비밀에서 이러한 값을 안전하게 가져올 수 있습니다.
</Callout>

<CollapserGroup>
  <Collapser id="otel-config" title="OpenTelemetry 원격 설정">
    <Callout variant="important">
      Kubernetes 비밀번호를 생성하여 Newrelrik 라이선스 키를 안전하게 저장하고 `licenseKey` 값을 대체하여 `chart_values` 에서 사용합니다.

      ```yaml
      customSecretName: "your-secret-name"
      customSecretLicenseKey: "your-secret-key"
      ```
    </Callout>

    플릿 전체에 걸쳐 구현하다, 배포하다 OpenTelemetry 설정을 정의하고 구현하려면 플릿 컨트롤을 사용하는 것이 좋습니다. OpenTelemetry 원격으로 구성하려면 아래 표시된 구조를 사용하여 플릿 확률에서 설정을 만듭니다. `lowDataMode` 또는 `receivers.filelog.enabled` 과 같은 값을 조정하고 필요에 따라 다른 관련 Helm 차트 설정을 포함할 수 있습니다.

    ```yaml
    chart_version: "*"
    chart_values:
      newrelic-prometheus-agent:
        lowDataMode: true
    ```
  </Collapser>
</CollapserGroup>

### Kubernetes에 대한 프록시 설정

에이전트 제어는 기업 프록시를 통해 트래픽을 라우팅하기 위한 프록시 설정을 지원합니다. 프록시 설정은 환경 변수를 통해 설정하거나 구성 파일에서 직접 설정할 수 있습니다.

#### 프록시 우선순위

에이전트 제어는 다음 우선순위에 따라 프록시 설정을 사용합니다.

1. `proxy` 에이전트 Control 설정의 설정 필드
2. `HTTP_PROXY` 환경 변수
3. `HTTPS_PROXY` 환경 변수

#### 자체 서명 인증서를 사용한 프록시 설정

자체 서명 인증서를 사용하여 HTTPS 인증을 사용하는 프록시 설정의 경우 CA 인증서 번들을 제공하고 프록시 인증을 구성해야 합니다.

<CollapserGroup>
  <Collapser id="k8s-proxy-config" title="Kubernetes 프록시 설정 예시">
    ```yaml
    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"

    agentControlDeployment:
      proxy:
        url: https://proxy-service:8080

      # Mount CA certificate bundle to Agent Control
      extraVolumeMounts:
        - mountPath: /etc/ssl/certs/
          name: ca-certs
      extraVolumes:
        - name: ca-certs
          secret:
            secretName: ca-certs

    # Configure Flux components to use proxy
    agentControlCd:
      flux2:
        sourceController:
          extraEnv:
            # Configure Flux source-controller to proxy all requests
            - name: HTTPS_PROXY
              value: https://proxy-service:8080
            # Except for in-cluster requests
            - name: "NO_PROXY"
              value: ".cluster.local.,.cluster.local,cluster.local,.svc,127.0.0.0/8,10.0.0.0/8"
          volumeMounts:
            # Mount CA certificate bundle to source-controller trust root store. The bundle should contain the
            # proxy CA cert.
            - mountPath: /etc/ssl/certs/
              name: ca-certs
          volumes:
            - name: ca-certs
              secret:
                secretName: ca-certs


    ```
  </Collapser>
</CollapserGroup>

#### 관리형 에이전트에 대한 프록시 설정

<Callout variant="caution">
  에이전트 제어에서 프록시를 구성하면 관리하는 에이전트에 대해 동일한 프록시 설정이 자동으로 구성되지 **않습니다** . 각 에이전트에는 해당 에이전트의 특정 설정 형식 및 요구 사항에 따라 별도로 설정해야 하는 자체 프록시 설정이 있습니다.
</Callout>

프록시를 사용하는 경우 각 관리 에이전트에 대한 프록시 설정도 개별적으로 구성해야 합니다. 프록시 설정 옵션은 각 에이전트의 특정 문서를 참조하세요.

### 비밀 관리

에이전트 Control은 전담 비밀 공급자로부터 비밀번호 및 API 키와 같은 민감한 데이터를 검색하여 관리하는 강력한 메커니즘을 제공합니다. 이렇게 하면 민감한 정보가 설정 파일에 직접 하드코딩되지 않습니다. 현재 이 시스템은 다음과 같은 비밀 공급자를 지원합니다.

* HashiCorp Vault: 설정에서 `nr-vault` 으로 참조됨.
* Kubernetes 비밀: 설정에서 `nr-kubesec` 이라고 합니다.

### 설정에서 비밀 정의

비밀을 활용하려면 다음 단계에 따라 에이전트 제어 설정 YAML 파일에서 비밀을 정의하세요.

1. **`secretsProviders` 섹션 정의:** 이 섹션에서 중앙에서 비밀 공급자를 구성합니다. 각 항목이 지원되는 공급자에 해당하는지 확인하세요.
2. **비밀 소스 구성:** 각 공급자에 대해 하나 이상의 소스를 지정합니다. 소스에는 에이전트 컨트롤이 비밀 그룹에 연결하고 검색하는 데 필요한 설정 세부 정보(예: URL, 인증서)가 포함됩니다.
3. **에이전트 설정에서 플레이스홀더 사용:** 실제 민감한 데이터 대신 에이전트 설정 내에서 플레이스홀더 문자열을 사용하세요. Agent Control은 렌더링 프로세스 중에 이러한 플레이스홀더를 검색된 비밀로 자동 교체합니다.

<Callout variant="important">
  에이전트 제어가 비밀 검색에 실패하면 설정 렌더링이 실패하고 에이전트가 실행되지 않습니다. 에이전트가 불완전하거나 잘못된 설정으로 실행되는 것을 방지하는 중요한 보안 기능입니다.
</Callout>

다음 에이전트 제어 설정 예제는 `secrets_providers` 섹션 내에서 두 개의 Vault 소스에서 비밀을 검색하는 방법을 보여줍니다.

```yaml
secretsProviders:
  vault:
    sources:
      local-instance:
        url: http://localhost:8200/v1/
        token: root
        engine: kv2
      remote:
        url: http://my-remote-server:8200/v1/
        token: root
        engine: kv1

fleet_control:
  ...

agents:
  ...
```

#### 에이전트 설정에서 비밀 사용

소스가 정의된 후 올바른 경로와 함께 특정 플레이스홀더 구문을 사용하여 에이전트 설정에서 비밀을 참조할 수 있습니다. 에이전트 제어는 비밀을 검색하고 이를 사용하여 에이전트가 사용할 최종 설정 파일을 렌더링합니다.

플레이스홀더에서 비밀을 사용하는 에이전트 설정의 예:

```yaml
config_agent:
  enable_process_metrics: true
  custom_attributes:
    username: "${nr-vault:local-instance:secret:my_secret:username}"
    organization: "${nr-vault:remote:my_mount:my_path:organization}"
```

이 예에서:

플레이스홀더 `${nr-vault:local-instance:secret:my_secret:username}` 는 로컬 인스턴스 비밀 공급자 소스를 사용하여 경로 `secret/my_secret` 의 비밀에서 키 `username` 과 연관된 값을 검색하도록 에이전트 제어에 지시합니다. 플레이스홀더 `${nr-vault:remote:my_mount:my_path:organization}` 마찬가지로 원격 소스에서 `organization` 키의 값을 검색합니다.

성공적으로 검색한 후, 에이전트 Control은 지정된 소스와 경로에서 이러한 비밀을 렌더링하고, 해당 에이전트에서 사용할 수 있도록 결과를 Kubernetes 비밀 또는 개인 구성 파일에 저장합니다.

### 금고 비밀

다음 설정으로 HashiCorp Vault 소스를 설정합니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        YAML 키
      </th>

      <th>
        설명
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `url`
      </td>

      <td>
        데이터를 요청할 URL
      </td>
    </tr>

    <tr>
      <td>
        `token`
      </td>

      <td>
        엔드포인트에 대한 인증에 사용됩니다.
      </td>
    </tr>

    <tr>
      <td>
        `engine`
      </td>

      <td>
        **`kv1`** 또는 **`kv2`** 지정하세요.
      </td>
    </tr>
  </tbody>
</table>

구성 파일에서 Vault에 저장된 각 비밀은 다음과 같은 플레이스홀더를 설정하여 액세스할 수 있습니다.

* **source\_name**: `secrets_providers` 에 정의된 Vault 소스의 이름입니다.
* **mount \[마운트]**: 시크릿 엔진 마운트의 이름입니다.
* **path \[경로]**: 비밀에 대한 구체적인 경로입니다.
* **specific key \[특정 키]**: 검색할 비밀 내의 특정 키입니다.

전체 플레이스홀더 형식의 예:

```
"${nr-vault:source_name:my_mount:my_path:my_value}"
```

### Kubernetes 비밀

에이전트 제어 파드에 서비스 계정 및 역할 기반 액세스 제어(RBAC) 등을 통해 필요한 비밀과 네임스페이스에 액세스할 수 있는 권한이 있는 경우 에이전트 제어는 별도의 소스를 설정하지 않고도 Kubernetes API 에서 비밀에 직접 액세스할 수 있습니다.

에이전트 설정 파일에서 다음을 지정하여 플레이스홀더를 사용하여 각 비밀 값을 검색합니다.

* **namespace \[네임스페이스]**: 비밀이 있는 Kubernetes 네임스페이스입니다.
* **name**: Kubernetes 비밀 객체의 이름입니다.
* **specific key \[특정 키]**: 비밀 내에서 값을 검색할 특정 키입니다.

예를 들어, 다음 플레이스홀더 형식을 사용합니다.

```
"${nr-kubesec:my_namespace:my_secret:my_value}"
```

### 비공개 설정

Agent Control은 Agent Control 자체와 관리 에이전트 모두에 구현, 배포에 대한 개인 Helm 렌즈 구성을 지원합니다. 이를 통해 Helm 차트에 직접 접근할 수 있습니다.

<Callout variant="caution">
  개인 Helm 저장소를 사용하는 경우 차트가 호환되어야 하며 차트 내에서 참조된 이미지에 접근할 수 있어야 합니다. 그렇지 않으면 에이전트가 예상대로 작동하지 않습니다.
</Callout>

### 1. 에이전트에 대한 개인 저장소 활성화

보안상의 이유로 원격 설정에서는 명시적으로 활성화된만 허용됩니다. 특정 경찰을 활성화하려면 다음과 같이 에이전트 제어 설정을 업데이트하세요:

<CollapserGroup>
  <Collapser id="k8s-private-repository-config" title="개인 저장소 활성화">
    ```yaml
    # values-newrelic.yaml

    global:
      cluster: "YOUR_CLUSTER_NAME"
      licenseKey: "YOUR_LICENSE_KEY"

    # ...

    agentControlDeployment:
      config:
        allowedChartRepositoryUrl:
          - https://my-private-repository-1
          - https://my-private-repository-2
        # ...
    ```
  </Collapser>
</CollapserGroup>

그런 다음 허용된 클럽 설정을 뉴렐릭 Control 내의 원격 설정에서 사용할 수 있습니다. 예:

```yaml
chart_version: "1.2.3"
chart_repository:
  url: "https://my-private-repository-1"
  name: "my-chart-name" # Optional: use only if the chart name doesn't match New Relic's chart name
```

또한, `agent-control-bootstrap` 차트 자체가 비공개 위치에 있는 경우 비공개 위치를 사용하도록 에이전트 제어의 Helm 설치를 구성해야 합니다. 이는 관리 에이전트의 설정과는 별개입니다. `agent-control-bootstrap` Helm 차트 [values.yaml](https://github.com/newrelic/helm-charts/blob/master/charts/agent-control-bootstrap/values.yaml) 을 참조하여 다음과 같이 `installationJob` 섹션을 구성하세요.

* `chartRepositoryUrl`: 저장소 위치가 포함된 URL입니다.
* `chartName`: 다른 차트 이름을 사용하는 경우 차트 이름입니다.
* `repositorySecretReferenceName` 및 `repositoryCertificateSecretReferenceName`: 저장소 인증에 필요한 비밀번호입니다. 자세한 내용은 아래 인증 섹션을 참조하세요.

### 2. 개인 저장소에 대한 인증 설정

개인 저장소에 액세스하기 위한 인증을 활성화하려면 다음과 같이 추가 리소스를 설정해야 합니다.

<CollapserGroup>
  <Collapser id="k8s-private-repository-basic-auth" title="기본 인증">
    기본 인증(사용자 이름 및 비밀번호)을 사용하여 인증하려면 에이전트 제어 네임스페이스에 `data.username` 및 `data.password` 에 예상 값이 포함된 비밀을 생성해야 합니다.

    예시:

    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: my-secret
    stringData:
      username: "myUser"
      password: "myPassword"
    ```

    자세한 내용은 [Flux 문서를](https://fluxcd.io/flux/components/source/helmrepositories/#secret-reference) 참조하세요.

    기본 인증을 사용하는 경우 원격 설정은 다음과 같이 구성해야 합니다.

    ```yaml
    chart_repository:
      url: "https://my-private-repository-1"
      secret_reference:
        name: my-secret
    ```
  </Collapser>

  <Collapser id="k8s-private-repository-tls-cert" title="TLS 인증서 인증">
    TLS를 사용하여 인증하려면 다음이 포함된 비밀을 만들어야 합니다.

    * `tls.crt` 및 `tls.key`: TLS 클라이언트 인증에 사용되는 클라이언트 인증서 및 개인 키
    * `ca.crt`: 서버를 검증하는 데 사용되는 CA 인증서(서버가 자체 서명 인증서를 사용하는 경우 필요)

    비밀은 `Opaque` 또는 `kubernetes.io/tls` 유형이어야 합니다. Secret에 있는 모든 파일은 PEM으로 인코딩되어야 합니다.

    예시:

    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: my-secret
      namespace: newrelic-agent-control
    type: kubernetes.io/tls # or Opaque
    data:
      tls.crt: <BASE64>
      tls.key: <BASE64>
      # NOTE: Can be supplied without the above values
      ca.crt: <BASE64>
    ```

    자세한 내용은 [Flux 문서를](https://fluxcd.io/flux/components/source/helmrepositories/#secret-reference) 참조하세요.

    TLS 인증서 인증을 사용하는 경우 원격 설정은 다음과 같이 구성해야 합니다.

    ```yaml
    chart_repository:
      url: "https://my-private-repository-1"
      certificate_secret_reference:
        name: my-secret
    ```
  </Collapser>
</CollapserGroup>

## 리눅스 설정

에이전트 제어 설정의 기본 경로는 다음과 같습니다.

* `Local` 설정 파일: `/etc/newrelic-agent-control/config.yaml`
* `Remote` 설정 파일: `/var/lib/newrelic-agent-control/config.yaml` (플랫 변형 구현, 배포를 통해 활성화된 경우)
* 서비스 정의: `/lib/systemd/system/newrelic-agent-control.service`
* 서비스 환경 파일: `/etc/newrelic-agent-control/newrelic-agent-control.conf`

기본적으로 에이전트는 인프라 에이전트와 OpenTelemetry 수집기를 조정할 수 있습니다.

```yml
# Configures the integration with Fleet Control
fleet_control:
  # EU region? Use: https://opamp.service.eu.newrelic.com/v1/opamp
  endpoint: https://opamp.service.newrelic.com/v1/opamp
  headers:
    api-key: YOUR_INGEST_KEY
  auth_config:
    # EU region? Use: https://system-identity-oauth.service.eu.newrelic.com/oauth2/token
    token_url: "https://system-identity-oauth.service.newrelic.com/oauth2/token"
    client_id: "YOUR_CLIENT_ID
    provider: "local"
    private_key_path: "path/to/key"

# Configures the agents to be supervised by Agent Control
agents:
  # Agent name (RFC-1035 valid label)
  nr-infra-agent:
    # The supported agent type and agent type version
    agent_type: "newrelic/com.newrelic.infrastructure:0.1.0"
  nr-otel-collector:
    agent_type: "newrelic/com.newrelic.opentelemetry.collector:0.1.0"
```

옵저버빌리티 요구 사항에 따라 요원의 이름을 바꾸거나 제거할 수 있습니다. 에이전트 이름은 [유효한 RFC-1035](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#rfc-1035-label-names) 레이블 이름이어야 합니다.

환경 변수를 사용하여 에이전트 설정을 정의할 수도 있습니다.

* 주요 에이전트 Control 설정에 `NR_` (단일 밑줄) 접두사를 사용하세요.
* 에이전트 제어에서 사용 가능한 설정을 유도하려면 `__` (이중 밑줄)을 사용하세요. 이는 밑줄이 포함된 설정 키와의 충돌을 피하기 위해 필요합니다.
* 환경 변수는 로컬 설정 파일보다 우선합니다. 원격 설정이 활성화된 경우 환경 변수는 고려되지 않습니다.
* 예를 들어, `fleet_control::endpoint` 에 대한 동적 설정을 정의하려면 서비스 정의 파일에 `NR_FLEET_CONTROL__ENDPOINT=https://opamp.service.newrelic.com/v1/opamp` 을 추가합니다.

### 에이전트 구성

```
agents:
  # Agent name (RFC-1035 valid label)
  nr-infra-agent:
    # The supported agent type and agent type version
    agent_type: "newrelic/com.newrelic.infrastructure:0.1.0"
  nr-otel-collector:
    agent_type: "newrelic/com.newrelic.opentelemetry.collector:0.1.0"
```

옵저버빌리티 요구 사항에 따라 요원의 이름을 바꾸거나 제거할 수 있습니다. 에이전트 이름은 [유효한 RFC-1035](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#rfc-1035-label-names) 레이블 이름이어야 합니다.

환경 변수를 사용하여 에이전트 설정을 정의할 수도 있습니다.

* 주요 에이전트 Control 설정에 `NR_` (단일 밑줄) 접두사를 사용하세요.
* 에이전트 제어에서 사용 가능한 설정을 유도하려면 `__` (이중 밑줄)을 사용하세요. 이는 밑줄이 포함된 설정 키와의 충돌을 피하기 위해 필요합니다.
* 환경 변수는 로컬 설정 파일보다 우선합니다. 원격 설정이 활성화된 경우 환경 변수는 고려되지 않습니다.
* 예를 들어, `fleet_control::endpoint` 에 대한 동적 설정을 정의하려면 서비스 정의 파일에 `NR_FLEET_CONTROL__ENDPOINT=https://opamp.service.newrelic.com/v1/opamp` 을 추가합니다.

### 에이전트 구성 [#agents-config]

Agent Control은 현재 다음과 같은 사전 정의된 호스트 내 에이전트 유형을 관리할 수 있습니다.

* 뉴렐릭 인프라 에이전트: `newrelic/com.newrelic.infrastructure`. [온호스트 통합 오케스트레이션](/docs/infrastructure/host-integrations/get-started/introduction-host-integrations/) 및 FluentBit 기반의 [리소스 전달자 통합을](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/) 포함하여 전투기 [에이전트](/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring) 의 모든 기존 기능이 지원됩니다.
* OpenTelemetry 용 뉴렐릭 배포: `newrelic/com.newrelic.opentelemetry.collector`

각 에이전트 유형은 해당 에이전트의 동작을 맞춤화하기 위해 사용자 정의할 수 있는 선택적 변수 세트를 제공합니다. 에이전트 로컬 설정을 사용자 정의하려면:

1. `values.yml` 파일을 만듭니다. 이 파일에는 원하는 설정 값이 포함됩니다.
2. `values.yml` 파일을 `/etc/newrelic-agent-control/fleet/agents.d/YOUR-AGENT-NAME/values/` 디렉토리에 넣으세요. 여기서 `YOUR-AGENT-NAME` 에이전트의 실제 이름입니다(예: `nr-infra-agent`).

최신 에이전트 유형 버전에 사용 가능한 변수 목록은 다음과 같습니다.

* 뉴렐릭 인프라 에이전트: `0.1.0`
* OpenTelemetry 용 뉴렐릭 배포: `0.1.0`

<table>
  <thead>
    <tr>
      <th>
        에이전트 유형
      </th>

      <th>
        변하기 쉬운
      </th>

      <th>
        유형
      </th>

      <th>
        기본값
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `config_agent`
      </td>

      <td>
        군사 에이전트 설정을 포함하는 YAML
      </td>

      <td>
        (비어 있는)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `config_integrations`
      </td>

      <td>
        온-호스트 통합 설정을 포함하는 YAML 맵(키는 파일 이름)
      </td>

      <td>
        (비어 있는)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `config_logging`
      </td>

      <td>
        로그인 포워딩 설정을 포함하는 YAML 맵(키는 파일 이름)
      </td>

      <td>
        (비어 있는)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.infrastructure`
      </td>

      <td>
        `health_port`
      </td>

      <td>
        인프라 에이전트 로컬 상태 서버용 포트
      </td>

      <td>
        `/health/status`
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.opentelemetry.collector`
      </td>

      <td>
        `config`
      </td>

      <td>
        OpenTelemetry 수집기 설정(YAML 형식)
      </td>

      <td>
        (비어 있는)
      </td>
    </tr>

    <tr>
      <td>
        `com.newrelic.opentelemetry.collector`
      </td>

      <td>
        `health_check.path` `health_check.port`
      </td>

      <td>
        OTel 수집기 [상태 점검 확장](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/healthcheckv2extension/README.md#configuration) 로컬 http 엔드포인트에 대한 경로 및 포트
      </td>

      <td>
        `localhost:13133/health/status`
      </td>
    </tr>

    <tr>
      <td>
        모든 관리 에이전트
      </td>

      <td>
        `backoff_delay`
      </td>

      <td>
        수집기가 시작에 실패할 경우 다음 재시도까지 걸리는 시간(초)입니다.
      </td>

      <td>
        `20s`
      </td>
    </tr>
  </tbody>
</table>

<Callout variant="tip">
  지원되는 구성에 따라 필요에 따라 [인프라 에이전트 설정](https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/) 및 [OpenTelemetry 수집기 설정을](https://docs-preview.newrelic.com/docs/new-relic-distribution-of-opentelemetry#configure) 구성할 수 있습니다.
</Callout>

### 샘플 설정

#### 플릿의 가능성을 이용한 원격 설정

다음 예에는 에이전트 제어 및 관리 에이전트에 대한 유효한 설정으로 복사하여 붙여넣을 준비가 된 일반적인 사용 사례가 포함되어 있습니다.

<CollapserGroup>
  <Collapser id="remote-config-infra-agent" title="인프라 에이전트, 온호스트 통합 및 쿠킹 전달자(내장 FluentBit)">
    FluentBit 통합을 위한 군대 에이전트 설정, 레디스 통합 설정 및 로그 포워딩 설정입니다. 유효한 `license_key` 있는 `config_agent` 은 항상 필수입니다. 다른 섹션은 선택 사항입니다(필요에 따라 제거하거나 업데이트하세요):

    ```yml
    config_agent:
      license_key: YOUR_LICENSE_KEY
      custom_attributes:
        env: demo
    config_integrations:
      nri-redis-example.yml:
        integrations:
          - name: nri-redis
            env:
              hostname: localhost
              port: 6380
              keys: '{"0":["<KEY_1>"],"1":["<KEY_2>"]}'
              remote_monitoring: true
    config_logging:
      fluentbit-example.yml:
        logs:
          - name: syslog
            file: /var/log/syslog
            attributes:
              logtype: linux_syslog
    ```
  </Collapser>

  <Collapser id="remote-config-nrdot" title="뉴렐릭 Otel 수집기">
    APM 서비스에서 트레이스, 지표 및 로그를 수신하기 위해 활성화된 OTel 수집기(프로세스 모니터링 비활성화) 및 OTLP 수신기를 사용하는 기본 호스트 모니터링:

    ```yml
    config:
      receivers:
        otlp:
          protocols:
            grpc:
            http:

        hostmetrics:
          collection_interval: 20s
          scrapers:
            cpu:
              metrics:
                system.cpu.time:
                  enabled: false
                system.cpu.utilization:
                  enabled: true
            load:
            memory:
              metrics:
                system.memory.utilization:
                  enabled: true
            paging:
              metrics:
                system.paging.utilization:
                  enabled: false
                system.paging.faults:
                  enabled: false
            filesystem:
              metrics:
                system.filesystem.utilization:
                  enabled: true
            disk:
              metrics:
                system.disk.merged:
                  enabled: false
                system.disk.pending_operations:
                  enabled: false
                system.disk.weighted_io_time:
                  enabled: false
            network:
              metrics:
                system.network.connections:
                  enabled: false

        filelog:
          include:
            - /var/log/syslog

      processors:
        # group system.cpu metrics by cpu
        metricstransform:
          transforms:
            - include: system.cpu.utilization
              action: update
              operations:
                - action: aggregate_labels
                  label_set: [ state ]
                  aggregation_type: mean
            - include: system.paging.operations
              action: update
              operations:
                - action: aggregate_labels
                  label_set: [ direction ]
                  aggregation_type: sum
        # remove system.cpu metrics for states
        filter/exclude_cpu_utilization:
          metrics:
            datapoint:
              - 'metric.name == "system.cpu.utilization" and attributes["state"] == "interrupt"'
              - 'metric.name == "system.cpu.utilization" and attributes["state"] == "nice"'
              - 'metric.name == "system.cpu.utilization" and attributes["state"] == "softirq"'
        filter/exclude_memory_utilization:
          metrics:
            datapoint:
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_unreclaimable"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "inactive"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "cached"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "buffered"'
              - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_reclaimable"'
        filter/exclude_memory_usage:
          metrics:
            datapoint:
              - 'metric.name == "system.memory.usage" and attributes["state"] == "slab_unreclaimable"'
              - 'metric.name == "system.memory.usage" and attributes["state"] == "inactive"'
        filter/exclude_filesystem_utilization:
          metrics:
            datapoint:
              - 'metric.name == "system.filesystem.utilization" and attributes["type"] == "squashfs"'
        filter/exclude_filesystem_usage:
          metrics:
            datapoint:
              - 'metric.name == "system.filesystem.usage" and attributes["type"] == "squashfs"'
              - 'metric.name == "system.filesystem.usage" and attributes["state"] == "reserved"'
        filter/exclude_filesystem_inodes_usage:
          metrics:
            datapoint:
              - 'metric.name == "system.filesystem.inodes.usage" and attributes["type"] == "squashfs"'
              - 'metric.name == "system.filesystem.inodes.usage" and attributes["state"] == "reserved"'
        filter/exclude_system_disk:
          metrics:
            datapoint:
              - 'metric.name == "system.disk.operations" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.merged" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.io" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.io_time" and IsMatch(attributes["device"], "^loop.*") == true'
              - 'metric.name == "system.disk.operation_time" and IsMatch(attributes["device"], "^loop.*") == true'
        filter/exclude_system_paging:
          metrics:
            datapoint:
              - 'metric.name == "system.paging.usage" and attributes["state"] == "cached"'
              - 'metric.name == "system.paging.operations" and attributes["type"] == "cached"'
        filter/exclude_network:
          metrics:
            datapoint:
              - 'IsMatch(metric.name, "^system.network.*") == true and attributes["device"] == "lo"'

        attributes/exclude_system_paging:
          include:
            match_type: strict
            metric_names:
              - system.paging.operations
          actions:
            - key: type
              action: delete

        transform:
          trace_statements:
            - context: span
              statements:
                - truncate_all(attributes, 4095)
                - truncate_all(resource.attributes, 4095)
          log_statements:
            - context: log
              statements:
                - truncate_all(attributes, 4095)
                - truncate_all(resource.attributes, 4095)

        # used to prevent out of memory situations on the collector
        memory_limiter:
          check_interval: 1s
          limit_mib: 100

        batch:

        resourcedetection:
          detectors: ["env", "system"]
          system:
            hostname_sources: ["os"]
            resource_attributes:
              host.id:
                enabled: true

        resourcedetection/cloud:
          detectors: ["gcp", "ec2", "azure"]
          timeout: 2s
          ec2:
            resource_attributes:
              host.name:
                enabled: false

      exporters:
        otlp:
          endpoint: otlp.nr-data.net:4317
          headers:
            api-key: ${NEW_RELIC_LICENSE_KEY}

      service:
        pipelines:
          metrics:
            receivers: [otlp, hostmetrics]
            processors:
              - memory_limiter
              - metricstransform
              - filter/exclude_cpu_utilization
              - filter/exclude_memory_utilization
              - filter/exclude_memory_usage
              - filter/exclude_filesystem_utilization
              - filter/exclude_filesystem_usage
              - filter/exclude_filesystem_inodes_usage
              - filter/exclude_system_disk
              - filter/exclude_network
              - attributes/exclude_system_paging
              - batch
              - resourcedetection
              - resourcedetection/cloud
            exporters: [otlp]
          traces:
            receivers: [otlp]
            processors: [transform, resourcedetection, resourcedetection/cloud, batch]
            exporters: [otlp]
          logs:
            receivers: [otlp, filelog]
            processors: [transform, resourcedetection, resourcedetection/cloud, batch]
            exporters: [otlp]
    ```
  </Collapser>

  <Collapser id="remote-config-agent-control" title="뉴렐릭 에이전트 Control">
    에이전트를 비활성화하는 방법을 보여주는 에이전트 제어 자체에 대한 유효한 구성(예: OTel 수집기):

    ```yml
    agents:
      nr-infra-agent:
        agent_type: "newrelic/com.newrelic.infrastructure:0.1.0"
      #nr-otel-collector:
      #  agent_type: "newrelic/com.newrelic.opentelemetry.collector:0.1.0"
    ```
  </Collapser>
</CollapserGroup>