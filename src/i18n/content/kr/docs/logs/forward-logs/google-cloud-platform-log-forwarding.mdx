---
title: Google Cloud Platform에서 로그 전달
tags:
  - Logs
  - Enable log management in New Relic
  - Enable log monitoring in New Relic
  - GCP
  - Dataflow
metaDescription: 'Configure New Relic logging for a Google Cloud Platform Pub/Sub topic, so you can use enhanced log management capabilities.'
translationType: machine
---

import logsGCPLogsCreateTopic from 'images/logs_screenshot-full_GCP-logs-create-topic.webp'

import logsGCPCreateSubscription from 'images/logs_screenshot-crop_GCP-create-subscription.webp'

import logsGCPCreateSubscriptionType from 'images/logs_screenshot-crop_GCP-create-subscription-type.webp'

import logsGCPCreateSink from 'images/logs_screenshot-crop_GCP-create-sink.webp'

Google Cloud Platform Pub/Sub 주제에서 New Relic으로 로그를 전달하는 두 가지 방법을 지원합니다.

## 옵션을 선택하세요 [#gcp-options]

다음은 비즈니스 요구 사항에 가장 적합한 옵션을 결정하는 데 도움이 될 수 있습니다.

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        GCP 로그 전달 옵션
      </th>

      <th>
        고려 사항
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        헤더 없는 API
      </td>

      <td>
        * 전송하는 각 로그 레코드에 대해 하나의 API 호출을 수행하기 때문에 적은 로그 볼륨에 가장 적합합니다.
        * GCP 구독에 추가 비용이 발생하지 않습니다.
        * 로그 볼륨이 증가하면 이 솔루션이 New Relic 계정의 할당량 제한에 도달할 수 있습니다.
      </td>
    </tr>

    <tr>
      <td>
        데이터 흐름 작업
      </td>

      <td>
        * 로그 레코드를 New Relic으로 보내기 전에 일괄 처리로 그룹화하므로 더 큰 로그 볼륨에 가장 적합합니다.
        * API 호출 수를 줄이고 할당량 사용량을 줄일 수 있습니다.
        * 구내에서 Dataflow 작업 실행으로 인해 GCP 구독에 추가 비용이 발생할 수 있습니다.
      </td>
    </tr>
  </tbody>
</table>

## 헤더 없는 API 사용 [#gcp-headerless-api]

헤더 없는 API를 사용하여 GCP 로그를 New Relic으로 보내려면:

<CollapserGroup>
  <Collapser
    id="ingest-url"
    title="1. GCP Pub/Sub 수집 URL을 생성합니다."
  >
    GCP Pub/Sub 주제에 대한 수집 URL을 생성하여 시작합니다.

    1. [**데이터 추가** UI](https://one.newrelic.com/marketplace) 로 이동하여 **로깅** 을 클릭하고 **Google Cloud Platform** 을 클릭합니다.

    2. 로그를 전달할 New Relic 계정을 선택하고 **계속** 을 클릭합니다.

    3. 선택 사항: 다음 단계에서 생성할 수집 URL로 전송되는 모든 로그 이벤트에 포함할 메타데이터(속성-값 쌍)를 구성합니다.

    4. **URL 생성** 을 클릭합니다.

    5. 새로 생성된 **수집 URL** 을 복사하여 안전한 장소에 보관하십시오.

       새 수집 URL을 사용하여 New Relic에 로그를 보내는 Pub/Sub 주제를 구성합니다.
  </Collapser>

  <Collapser
    id="create-gcp-topic"
    title="2. GCP Pub/Sub 주제를 생성합니다."
  >
    다음으로 수집 URL이 사용할 GCP Pub/Sub 주제를 생성합니다.

    <img
      title="Create GCP topic"
      alt="Create GCP topic"
      src={logsGCPLogsCreateTopic}
    />

    1. [GCP Pub/Sub 콘솔](https://console.cloud.google.com/cloudpubsub/topic/list) 로 이동합니다.
    2. **주제 만들기** 를 클릭합니다.
    3. 의미 있는 **주제 ID** 를 입력한 다음 필요에 따라 다른 옵션을 구성합니다.
    4. **주제 만들기** 를 클릭합니다.
  </Collapser>

  <Collapser
    id="configure-gcp-log-forwarding"
    title="3. 로그를 New Relic에 전달할 GCP Pub/Sub Topic을 준비합니다."
  >
    Pub/Sub 주제를 생성했으면 해당 주제에 대한 구독을 생성합니다.

    <img
      title="Create GCP Pub/Sub topic subscription"
      alt="Create GCP Pub/Sub topic subscription"
      src={logsGCPCreateSubscription}
    />

    1. [GCP Pub/Sub 콘솔](https://console.cloud.google.com/cloudpubsub/topic/list) 로 돌아갑니다.

    2. 이전에 만든 [Pub/Sub 주제](#create-gcp-topic) 를 클릭합니다.

    3. 아래로 스크롤하여 **구독** 탭을 선택한 다음 **구독 만들기** 를 클릭 **하고 간단한 구독 만들기** 를 선택합니다.

       <img
         title="Select GCP Pub/Sub topic subscription type"
         alt="Select GCP Pub/Sub topic subscription type"
         src={logsGCPCreateSubscriptionType}
       />

    4. **구독 ID** 를 입력합니다. 그런 다음 **배달 유형** 에서 **푸시** 를 선택합니다.

    5. **엔드포인트 URL** 필드에 이전에 생성한 [수집 URL](#ingest-url) 을 붙여넣습니다.

    6. 필요에 따라 나머지 설정을 구성하고 **만들기** 를 클릭합니다.
  </Collapser>

  <Collapser
    id="forward-logs"
    title="4. 로그를 New Relic으로 전달할 라우팅 싱크를 생성합니다."
  >
    설정을 완료하려면 로그를 New Relic으로 전달할 GCP Pub/Sub 주제에 대한 라우팅 싱크를 만드세요.

    <img
      title="Create GCP Pub/Sub logs router sink"
      alt="Create GCP Pub/Sub logs router sink"
      src={logsGCPCreateSink}
    />

    1. [GCP 로그 라우터 콘솔](https://console.cloud.google.com/logs/router) 로 이동합니다.
    2. **싱크 만들기** 를 클릭합니다.
    3. **싱크 이름** 과 **싱크 설명** 을 입력하고 **다음** 을 클릭합니다.
    4. **싱크 서비스** 선택 에서 **Cloud Pub/Sub 주제** 를 선택하고 이전에 생성한 [Pub/Sub 주제](#create-gcp-topic) 를 선택합니다.
    5. 필요에 따라 나머지 필터를 구성한 다음 **싱크 만들기** 를 클릭하여 설정을 완료합니다.
  </Collapser>
</CollapserGroup>

## Dataflow 작업 사용 [#gcp-dataflow]

Dataflow 작업을 사용하여 GCP 로그를 New Relic으로 보내려면 Dataflow 템플릿을 사용합니다. 시작하기 전에 로컬 컴퓨터에 다음 도구가 있는지 확인하십시오.

* Linux 또는 macOS용 Unix 터미널
* [힘내](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
* [자바 JDK 8](https://adoptopenjdk.net/index.html)
* [Apache Maven 3.2 이상](https://maven.apache.org/) . 컴파일 과정에서 이전 버전이 실패하는 것을 보았습니다.
* `gcloud` 및 `gsutil` 명령줄 도구가 포함된 [Google Cloud SDK](https://cloud.google.com/sdk/docs/install)

<CollapserGroup>
  <Collapser
    id="dataflow-login-gcp"
    title="1. Google Cloud Platform 계정에 로그인합니다."
  >
    다음 명령어를 실행하고 프롬프트에 따라 GCP에 로그인하고 클라우드 프로젝트를 선택합니다.

    ```
    gcloud init
    ```

    마법사를 사용하여 사용할 클라우드 프로젝트를 선택하고 `gcloud` 또는 `gsutil` 을 사용하여 생성한 리소스에 대한 기본 컴퓨팅 지역 및 영역을 선택적으로 선택할 수 있습니다. 다음 명령에 대한 기본 프로젝트, 위치 또는 지역을 가정하지 않습니다.
  </Collapser>

  <Collapser
    id="dataflow-repo"
    title="2. DataflowTemplates GitHub 리포지토리를 복제합니다."
  >
    1. 다음 명령어를 사용하여 DataflowTemplates GitHub 리포지토리를 복제합니다.

       ```
       git clone https://github.com/newrelic-forks/DataflowTemplates.git
       ```

    2. 방금 만든 디렉터리를 입력합니다.

       ```
       cd DataflowTemplates
       ```

       그런 다음 다음 섹션을 계속하여 추가 명령을 실행합니다.
  </Collapser>

  <Collapser
    id="dataflow-configuration"
    title="3. Dataflow 전달자를 컴파일하고 실행합니다."
  >
    Dataflow 전달자를 컴파일하고 실행하는 데 필요한 구성을 설정하려면 `DataflowTemplates` 디렉터리에서 다음 명령어를 실행하세요. 유일한 필수 값은 다음과 같습니다.

    * `PROJECT_ID`

    * `BUCKET_NAME`

    * `NR_LICENSE_KEY`

    * `INPUT_SUBSCRIPTION_NAME`

      다른 기본값은 그대로 둘 수 있습니다.

      ```bash
      # The Google Cloud Platform project id where your logs are and where the Dataflow log forwarder will run
      PROJECT_ID=<your_project_id>
      # Temporary bucket that will store intermediary files as a result of compiling the Dataflow template. Its name must be unique.
      BUCKET_NAME=<a_nonexisting_gcs_bucket_name>
      # New Relic license key
      NR_LICENSE_KEY=<your_newrelic_license_key>
      # Input PubSub subscription to read logs from
      INPUT_SUBSCRIPTION_NAME=<your_pubsub_input_subscription_name>

      # Region where the created resources will be placed
      REGION=us-west1
      # Service account used to execute the Dataflow template
      SERVICE_ACCOUNT_NAME=nr-dataflow-forwarder-sa
      # File name where the service account credentials will be stored
      SERVICE_ACCOUNT_KEY_FILENAME=service-account-key.json
      # The name your Dataflow log forwarder job will have
      JOB_NAME=nr-log-forwarder
      ```
  </Collapser>

  <Collapser
    id="dataflow-bucket"
    title="4. Dataflow 템플릿용 GCP 버킷을 생성합니다."
  >
    다음 명령어를 실행하여 생성된 Dataflow 템플릿을 보관할 버킷을 GCP에 만듭니다.

    ```bash
    gsutil mb -p ${PROJECT_ID} -l ${REGION} gs://${BUCKET_NAME}
    ```
  </Collapser>

  <Collapser
    id="dataflow-account"
    title="5. 서비스 계정을 생성합니다."
  >
    다음 명령을 실행합니다.

    1. 서비스 계정 만들기:

       ```bash
       gcloud iam service-accounts create ${SERVICE_ACCOUNT_NAME}
       ```

    2. 서비스 계정에 권한 부여:

       ```bash
       gcloud projects add-iam-policy-binding ${PROJECT_ID} --member="serviceAccount:${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com" --role="roles/owner"
       ```

    3. 서비스 계정 키 파일 생성:

       ```bash
       gcloud iam service-accounts keys create ${SERVICE_ACCOUNT_KEY_FILENAME} --iam-account=${SERVICE_ACCOUNT_NAME}@${PROJECT_ID}.iam.gserviceaccount.com
       ```

    4. 후속 명령에서 사용되므로 `GOOGLE_APPLICATION_CREDENTIALS` 환경 변수를 사용하여 서비스 계정 키 파일을 참조하십시오.

       ```bash
       export GOOGLE_APPLICATION_CREDENTIALS=${SERVICE_ACCOUNT_KEY_FILENAME}
       ```
  </Collapser>

  <Collapser
    id="dataflow-compile"
    title="6. PubsubToNewRelic 템플릿을 컴파일하고 게시합니다."
  >
    다음 명령을 실행합니다.

    ```bash
    mvn compile exec:java \
        -Dexec.mainClass=com.google.cloud.teleport.templates.PubsubToNewRelic \
        -Dexec.cleanupDaemonThreads=false \
        -Dexec.args=" \
            --project=${PROJECT_ID} \
            --region=${REGION} \
            --enableStreamingEngine \
            --stagingLocation=gs://${BUCKET_NAME}/staging/ \
            --gcpTempLocation=gs://${BUCKET_NAME}/temp/ \
            --templateLocation=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
            --runner=DataflowRunner \
        "
    ```
  </Collapser>

  <Collapser
    id="dataflow-job"
    title="7. 템플릿을 Dataflow 작업으로 실행합니다."
  >
    다음 명령어를 실행하여 Pub/Sub 주제에서 읽는 Dataflow 작업을 사용하여 로그 전달을 시작합니다.

    ```bash
    gcloud dataflow jobs run ${JOB_NAME} \
        --gcs-location=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
        --region=${REGION} \
        --parameters "inputSubscription=projects/${PROJECT_ID}/subscriptions/${INPUT_SUBSCRIPTION_NAME},licenseKey=${NR_LICENSE_KEY}"
    ```

    이 명령에는 다음 두 값만 필요합니다.

    * 로그 메시지를 읽는 데 사용되는 입력 PubSub 구독

    * New Relic

      <InlinePopover type="licenseKey"/>

      로그를 보내는 데 사용

    <CollapserGroup>
      <Collapser
        id="eu-customers-gcp-dataflow"
        title="유럽 지역 계정"
      >
        유럽 계정은 값으로 `https://log-api.eu.newrelic.com/log/v1` 를 사용하여 `logsApiUrl` 매개변수도 추가해야 합니다.

        ```bash
        gcloud dataflow jobs run ${JOB_NAME} \
            --gcs-location=gs://${BUCKET_NAME}/template/PubsubToNewRelic \
            --region=${REGION} \
            --parameters "inputSubscription=projects/${PROJECT_ID}/subscriptions/${INPUT_SUBSCRIPTION_NAME},licenseKey=${NR_LICENSE_KEY},logsApiUrl=https://log-api.eu.newrelic.com/log/v1"
        ```
      </Collapser>
    </CollapserGroup>

    <Callout variant="tip">
      다른 값의 경우 이 명령은 [필요에 따라 추가로 사용자 지정할](#dataflow-config) 수 있는 기본 구성 설정을 사용합니다.
    </Callout>
  </Collapser>

  <Collapser
    id="dataflow-config"
    title="8. 선택 사항: Dataflow 로그 전달자 작업을 조정합니다."
  >
    다음은 Dataflow 로그 전달자 작업의 실행을 추가로 조정하는 데 사용할 수 있는 사용 가능한 옵션에 대한 참조입니다.

    <table>
      <thead>
        <tr>
          <th style={{ width: "250px" }}>
            구성 매개변수
          </th>

          <th>
            설명
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `licenseKey` **필수의.**
          </td>

          <td>
            New Relic <InlinePopover type="licenseKey"/>.
          </td>
        </tr>

        <tr>
          <td>
            `inputSubscription` **필수의.**
          </td>

          <td>
            로그를 사용하는 데 사용되는 Cloud Pub/Sub 구독입니다. 다음 형식을 사용하십시오.

            ```
            projects/<project-id>/subscriptions/<subscription-name>
            ```
          </td>
        </tr>

        <tr>
          <td>
            `logsApiUrl`
          </td>

          <td>
            Log API에 대한 New Relic의 URL입니다. 이는 Dataflow 파이프라인이 실행되는 VPC에서 라우팅됩니다.

            기본:

            ```
            https://log-api.newrelic.com/log/v1
            ```

            유럽 지역:

            ```
            https://log-api.eu.newrelic.com/log/v1
            ```
          </td>
        </tr>

        <tr>
          <td>
            `batchCount`
          </td>

          <td>
            단일 HTTP POST 요청에서 New Relic으로 보내기 전에 일괄 처리로 집계할 최대 로그 레코드 수입니다.

            기본: `100`
          </td>
        </tr>

        <tr>
          <td>
            `flushDelay`
          </td>

          <td>
            전체가 아닌 배치의 마지막 로그 레코드를 수신한 후 New Relic으로 플러시하기 전에 추가 로그(최대 `batchCount` )를 기다리는 시간(초)입니다.

            기본: `2`
          </td>
        </tr>

        <tr>
          <td>
            `parallelism`
          </td>

          <td>
            최대 병렬 요청 수입니다.

            기본: `1`
          </td>
        </tr>

        <tr>
          <td>
            `disableCertificateValidation`
          </td>

          <td>
            SSL 인증서 유효성 검사를 비활성화합니다.

            기본: `false`
          </td>
        </tr>

        <tr>
          <td>
            `useCompression`
          </td>

          <td>
            New Relic의 Logs API로 전송된 페이로드를 압축(GZIP으로)합니다.

            기본: `true`
          </td>
        </tr>

        <tr>
          <td>
            `tokenKMSEncryptionKey`
          </td>

          <td>
            토큰에 대한 KMS 암호화 키입니다. 다음 형식을 사용하십시오.

            ```
            projects/{gcp_project}/locations/{key_region}/keyRings/{key_ring}/cryptoKeys/{kms_key_name}
            ```

            기본: `null`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

<InstallFeedback/>

## 다음은 뭐지? [#what-next]

[로그 UI를](/docs/logs/log-management/ui-data/use-logs-ui/)사용하여 플랫폼 전체에서 로깅 데이터를 탐색합니다.

* [컨텍스트에서 로그](/docs/logs/enable-log-management-new-relic/configure-logs-context/configure-logs-context-apm-agents/) 기능을 사용하여 로그를 전달하여 애플리케이션 및 플랫폼 성능 데이터 모두에 대한 가시성을 확보하십시오.
* [경보](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-alert-conditions/)를 설정하십시오.
* [데이터를 조회](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/) 하고 [대시보드를 작성](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/)하십시오.

## 로그 전달 사용 안함 [#disable]

로그 전달 기능을 비활성화하려면 [Google Cloud Platform 문서](https://cloud.google.com/sdk/docs/) 의 표준 절차를 따르세요. New Relic에서는 다른 작업을 수행할 필요가 없습니다.