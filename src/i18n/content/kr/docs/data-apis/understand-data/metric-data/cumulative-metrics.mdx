---
title: 누적 지표(OTel 및 Prometheus)
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
metaDescription: How New Relic handles cumulative metrics from OpenTelemetry and Prometheus.
freshnessValidatedDate: never
translationType: machine
---

수출 const 연도 = 2023; 수출 const gaDate = '4월 4일'; 내보내기 const gaDateAndYear = gaDate + ', ' + 연도;

[OpenTelemetry 통합](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-introduction) 또는 [Prometheus 원격 쓰기 통합](/docs/infrastructure/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration) 에서 누적 메트릭을 보고하면 New Relic이 해당 데이터를 처리하는 방법(예: 데이터를 델타 측정으로 변환하는 방법)을 이해하는 데 도움이 됩니다. 이를 통해 New Relic UI 보기를 이해하고, 데이터를 쿼리하고, 데이터 보고 문제를 이해하는 데 도움이 됩니다.

## 누적 및 델타 메트릭 설명 [#explained]

애플리케이션에서 메트릭 데이터를 수집할 때 쿼리 시 데이터를 사용하고 해석하는 방법을 결정할 때 해당 데이터가 측정된 _방식을_ 고려하는 것이 중요합니다. [지표 유형](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) 은 중요한 요소 중 하나이며, 특정 New Relic 집계 함수는 일부 유형에서만 작동하고 다른 유형에서는 작동하지 않습니다. 그러나 또 다른 중요한 요소는 지표의 <DNT>**temporality**</DNT> 입니다.

두 가지 시간성은 <DNT>**delta**</DNT> 및 <DNT>**cumulative**</DNT> 입니다. `Delta` 보고 간격 사이에 측정값이 재설정됨을 나타냅니다. `Cumulative` 재설정이 없으며 측정값이 누적되었음을 나타냅니다. Prometheus는 누적 메트릭 수집기([데이터 유형에 대한 Prometheus 문서](https://prometheus.io/docs/concepts/metric_types))의 일반적인 예이며 OpenTelemetry는 누적 메트릭을 수집하는 방법([시간성에 대한 OpenTelemetry 문서](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#temporality))도 정의합니다.

New Relic은 Prometheus 및 OpenTelemetry 누적 데이터를 모두 지원하며 수집 시 델타 변환을 수행하여 플랫폼의 다른 메트릭과 더 잘 일치하고 [NRQL](/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language)을 통해 해당 데이터와 더 쉽게 상호 작용할 수 있도록 합니다. 누적 카운터는 New Relic [`cumulativeCount`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types)으로 저장되고 누적 히스토그램은 New Relic [`distribution`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types)로 저장됩니다.

## Prometheus 원격 쓰기 지원 [#prom-support]

자세한 내용은 [Prometheus 원격 쓰기 통합](/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic) 을 참조하세요.

## OpenTelemetry 지원 [#otel-support]

OpenTelemetry 지원에 대한 자세한 내용은 [OpenTelemetry 메트릭: 모범 사례를](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-metrics)참조하십시오.

## 누적 델타 변환 세부 정보 [#delta-conversion]

높은 수준에서 델타 변환은 이벤트 시간에 두 개의 데이터 포인트를 순차적으로 취하고 차이를 계산하여 수행됩니다. 그러나 실제로는 이렇게 간단하지 않습니다. 다음은 우리가 예상하는 몇 가지 일반적인 시나리오와 이를 처리하는 방법입니다.

### 재설정 [#resets]

[시계열](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#timeseries-model) 데이터의 값이 갑자기 감소하는 경우 이를 재설정으로 처리하고 해당 새 측정값을 자체 델타 값으로 내보냅니다(즉, 앞에 `0` 측정값이 있는 것처럼).

[OpenTelemetry는 또한 예상치 못한 가치 감소 상황을 정의하며](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#resets-and-gaps) 이러한 경우를 감지하고 [New Relic 통합 오류](/docs/data-apis/manage-data/nrintegrationerror) 를 통해 알려드리기 위해 최선을 다하고 있습니다(아래 [문제 해결](#troubleshooting) 참조).

### 데이터 재정렬 [#reorder-data]

우리는 많은 요인으로 인해 데이터 포인트가 뉴렐릭에 순서 없이 도착할 수 있다는 점을 이해하고 있습니다. 따라서 보고 시계열에서 예상치 못한 차이가 감지되면 데이터 포인트를 버퍼링하고 다시 정렬합니다. 격차는 특정 시계열에 대한 데이터 수신 속도에 따라 결정되는 예상 보고 간격에 따라 추론됩니다. 버퍼링은 제한되어 있으며 결국에는 "재배열하기에는 너무 늦은" 데이터 포인트를 고려하게 됩니다. 이 경우 감지된 간격에 걸쳐 델타가 컴퓨트되고 시계열 처리가 계속됩니다.

### 오래된 데이터 [#stale-data]

델타 변환은 상태 저장 작업이므로 보고를 중지하고 결국 상태를 삭제할 수 있는 시계열을 인식해야 합니다. 시계열이 <DNT>**5 minutes**</DNT> 에 대한 새로운 데이터 포인트를 보고하지 않은 경우 버퍼링된 간격에 대한 델타 계산을 포함하여 현재 상태를 플러시합니다. 즉, 데이터 포인트가 나중에 도착하면 해당 시계열의 시작인 것처럼 처리되어 플러시 전 마지막 데이터 포인트와 플러시 후 첫 번째 데이터 포인트 사이의 델타가 사실상 손실됩니다. . 이는 델타 변환의 이점을 얻으려면 지표 보고 간격이 <DNT>**5 minutes**</DNT> 보다 작아야 함을 의미합니다.

### 누적 합계에 대한 특별 참고 사항 [#cumulative-sums]

데이터가 애플리케이션에 의해 기록되고 단조롭게 증가하는 값의 시퀀스로 전송되더라도 데이터에서 `sum()` 를 호출하면 델타 값의 시퀀스인 것처럼 처리됩니다. `derivative()` 를 계산할 필요가 없습니다!

합계를 델타로 변환할 때 New Relic은 델타와 함께 누적 값도 방출하여 최신 누적 값을 쿼리할 수 있는 기능을 유지합니다. 누적 값에 액세스하려면 [getField()를](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#func-getfield) 사용할 수 있습니다(예제는 [지표를 쿼리하는 방법](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-metrics/#query) 참조).

데이터 포인트는 간격의 시작인 관련 `timestamps` 에 표시됩니다. 그러나 누적 값은 데이터 포인트의 `endTimestamp` 과 연결되므로 누적 쿼리를 해석할 때 데이터 포인트의 너비를 고려해야 할 수 있습니다.

## 문제점 해결 [#troubleshooting]

경우에 따라 누적에서 델타로의 변환 프로세스의 결과로 [New Relic 통합 오류](/docs/data-apis/manage-data/nrintegrationerror) 를 보고합니다. 다음은 몇 가지 일반적인 이유입니다.

### 번역 오류 [#translation-errors]

델타 변환에는 이벤트 시간에 순차적인 두 데이터 포인트의 누적 값이 단조롭게 증가한다는 가정이 포함됩니다. 이 가정이 깨질 것으로 예상되는 유일한 시간은 모니터링 중인 프로세스가 다시 시작될 때입니다. 다른 이유로 인해 단조로움이 깨지는 경우에도 이를 재설정으로 처리하지만 계정에 [New Relic 통합 오류](/docs/data-apis/manage-data/nrintegrationerror) 이벤트를 생성하여 알림을 시도합니다. OpenTelemetry 데이터 <DNT>**but not Prometheus**</DNT> 에 대해 이 작업을 수행할 수 있습니다. OpenTelemetry에는 이러한 상황을 감지하는 데 사용할 수 있는 더 많은 정보가 포함되어 있기 때문입니다. 단조성이 예기치 않게 중단되는 가장 일반적인 원인은 클라이언트 측 애플리케이션이 카디널리티 제한에 도달하고 메모리 부족을 완화하기 위해 데이터를 삭제하는 경우입니다. 경우에 따라 이는 예기치 않은 재설정으로 작용하여 New Relic으로 전송되는 값이 예기치 않게 감소할 수 있습니다. OTLP 로그에서 이에 대한 인스턴스를 찾는 것이 좋습니다.

```
Instrument % has exceeded the maximum allowed accumulations (2000)
```

OpenTelemetry SDK를 사용하면 [카디널리티 제한을 구성](https://opentelemetry.io/docs/specs/otel/metrics/sdk/#cardinality-limits) 할 수 있습니다. OpenTelemetry는 또한 [<DNT>**Views**</DNT>](https://opentelemetry.io/docs/reference/specification/metrics/sdk/#view) 사용하여 클라이언트 측 카디널리티를 줄이는 방법을 제공하며 이러한 문제를 해결하는 데 권장되는 경로입니다. 또 다른 옵션은 메모리 절약에 도움이 될 수 있는 [Delta 시간성을 사용하여 OTLP 지표를](https://opentelemetry.io/docs/reference/specification/metrics/sdk_exporters/otlp/#additional-configuration) 내보내는 것입니다.

### 카디널리티 제한 [#card-limits]

변환하는 동안 시스템 보호를 위해 메트릭 자격을 기반으로 하는 메트릭 카디널리티 제한도 느슨하게 적용합니다. [롤업과 같이 일일](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes/#incident-unique-timeseries) 제한을 적용하는 대신 이 제한은 추적되는 동시 시계열 수로 적용됩니다. 동시 [고유 지수 시계열이](/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/#what-why) 너무 많으면 이전 시계열이 만료될 때까지 새로운 수신 시계열을 삭제합니다( [부실 데이터](#stale-data) 참조).

### 누적 메트릭 재설정 [#cumulative-resets]

누적 메트릭 재설정은 일반적으로 이를 보고하는 서비스 또는 애플리케이션이 다시 시작될 때 발생합니다. 재설정된 지표를 쿼리할 때 지표 값이 감소한 것처럼 나타날 수 있지만 이는 [OpenTelemetry 지표 사양](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#resets-and-gaps) 에 설명된 대로 예상되는 동작입니다. 정상적인 지표 재설정과 <DNT>**is**</DNT> 이 예기치 않게 감소하는 문제가 있는 지표를 구별하려면 계정에 [New Relic 통합 오류가](/docs/data-apis/manage-data/nrintegrationerror) 있는지 확인하세요. 값이 감소하는 지표와 관련하여 통합 오류가 보고되지 않는 경우 누적 지표를 보고하는 기능이 다시 시작되어 지표 값을 재설정하는 중일 가능성이 높습니다.
