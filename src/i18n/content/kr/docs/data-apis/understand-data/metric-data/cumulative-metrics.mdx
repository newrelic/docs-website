---
title: 누적 측정항목(미리보기)
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
metaDescription: Support for cumulative metrics at New Relic
translationType: machine
---

import moreintegrationsOtlpFacetQuery from 'images/more-integrations_screenshot-crop_otlp-facet-query.webp'

[OpenTelemetry 통합](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-introduction) 또는 [Prometheus 원격 쓰기 통합](/docs/infrastructure/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration) 에서 누적 메트릭을 보고하면 New Relic이 해당 데이터를 처리하는 방법(예: 데이터를 델타 측정으로 변환하는 방법)을 이해하는 데 도움이 됩니다. 이를 통해 New Relic UI 보기를 이해하고, 데이터를 쿼리하고, 데이터 보고 문제를 이해하는 데 도움이 됩니다.

## 시사 [#preview]

이 문서는 현재 미리보기에 있는 [`cumulativeCount`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) 측정항목 유형에 대한 것입니다.

## 누적 및 델타 메트릭 설명 [#explained]

애플리케이션에서 메트릭 데이터를 수집할 때 쿼리 시간에 데이터를 사용하고 해석하는 방법을 결정할 때 해당 데이터가 측정된 _방법_ 을 고려하는 것이 중요합니다. [지표 유형](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) 은 특정 New Relic 집계 기능이 일부 유형과 함께 작동하고 다른 유형과는 작동하지 않는 중요한 요소 중 하나입니다. 그러나 또 다른 중요한 요소는 측정항목의 **시간성** 입니다.

두 시간 **성은 델타** 및 **누적** 입니다. `Delta` 는 보고 간격 사이에 측정값이 재설정되었음을 나타냅니다. `Cumulative` 은 재설정이 없고 측정값이 누적되었음을 나타냅니다. Prometheus는 누적 메트릭 수집기( [데이터 유형에 대한 Prometheus 문서](https://prometheus.io/docs/concepts/metric_types) )의 일반적인 예이며 OpenTelemetry는 누적 메트릭을 수집하는 방법( [시간성에 대한 OpenTelemetry 문서](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#temporality) )도 정의합니다.

New Relic은 Prometheus 및 OpenTelemetry 누적 데이터 전송을 지원하고 수집 시 델타 변환을 수행하여 플랫폼의 다른 메트릭과 더 잘 일치하고 [NRQL](/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language) 을 통해 해당 데이터와 더 쉽게 상호 작용할 수 있도록 합니다. 누적 카운터는 New Relic [`cumulativeCount`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) 으로 저장되고 누적 히스토그램은 New Relic [`distribution`](/docs/data-apis/understand-data/metric-data/metric-data-type/#metric-types) 로 저장됩니다.

## Prometheus 원격 쓰기 지원 [#prom-support]

자세한 내용은 [Prometheus 원격 쓰기 통합](/docs/infrastructure/prometheus-integrations/get-started/send-prometheus-metric-data-new-relic) 을 참조하세요.

## OpenTelemetry 지원 [#otel-support]

자세한 내용은 [OpenTelemetry 지표: 모범 사례](https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-metrics/) 를 참조하십시오.

## 누적 델타 변환 세부 정보 [#delta-conversion]

높은 수준에서 델타 변환은 이벤트 시간에 두 개의 데이터 포인트를 순차적으로 취하고 차이를 계산하여 수행됩니다. 그러나 실제로는 이렇게 간단하지 않습니다. 다음은 우리가 예상하는 몇 가지 일반적인 시나리오와 이를 처리하는 방법입니다.

### 재설정 [#resets]

[시계열](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#timeseries-model) 데이터의 값이 갑자기 감소하면 이를 재설정으로 처리하고 새 측정값을 자체 델타 값으로 내보냅니다(즉, 앞에 `0` 측정값이 있는 것처럼).

[OpenTelemetry는 또한 예상치 못한 가치 감소 상황을 정의하며](https://opentelemetry.io/docs/reference/specification/metrics/data-model/#resets-and-gaps) 이러한 경우를 감지하고 [New Relic 통합 오류](/docs/data-apis/manage-data/nrintegrationerror) 를 통해 알려드리기 위해 최선을 다하고 있습니다(아래 [문제 해결](#troubleshooting) 참조).

### 데이터 재정렬 [#reorder-data]

우리는 데이터 포인트가 순서 없이 New Relic에 도착하게 만드는 원인이 많다는 것을 이해합니다. 따라서 보고 시계열에서 예기치 않은 간격이 감지되면 데이터 포인트를 버퍼링하고 재정렬합니다. 격차는 주어진 시계열에 대한 데이터를 수신하는 속도로 결정되는 예상 보고 간격으로 추론됩니다. 버퍼링은 제한적이며 결국 데이터 포인트를 "재시퀀싱하기에는 너무 늦음"으로 간주합니다. 이 경우 감지된 간격에서 델타가 계산되고 시계열 처리가 계속됩니다.

### 오래된 데이터 [#stale-data]

델타 변환은 상태 저장 작업이므로 보고를 중지하고 결국 해당 상태를 삭제할 수 있는 시계열을 인식해야 합니다. 시계열이 **5분 동안** 새로운 데이터 포인트를 보고하지 않으면 버퍼링된 간격에서 델타 계산을 포함하여 현재 상태를 플러시합니다. 즉, 데이터 포인트가 나중에 도착하면 해당 시계열의 시작인 것처럼 처리되어 플러시 전 마지막 데이터 포인트와 플러시 후 첫 번째 데이터 포인트 사이의 델타를 효과적으로 잃게 됩니다. 즉, 델타 변환의 이점을 얻으려면 지표 보고 간격이 **5분** 미만이어야 합니다.

### 누적 합계에 대한 특별 참고 사항 [#cumulative-sums]

데이터가 애플리케이션에 의해 기록되고 단조롭게 증가하는 값의 시퀀스로 전송되더라도 데이터에서 `sum()` 를 호출하면 델타 값의 시퀀스인 것처럼 처리됩니다. `derivative()` 를 계산할 필요가 없습니다!

합계를 델타로 변환할 때 New Relic은 델타와 함께 누적 값을 방출하여 최신 누적 값을 쿼리할 수 있는 기능을 유지합니다. 누적 값에 액세스하려면 [getField()](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#func-getfield) 를 사용할 수 있습니다(예를 보려면 [메트릭을 쿼리하는 방법](https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-metrics/#query) 참조).

데이터 포인트는 간격의 시작인 관련 `timestamps` 에 표시됩니다. 그러나 누적 값은 데이터 포인트의 `endTimestamp` 과 연결되므로 누적 쿼리를 해석할 때 데이터 포인트의 너비를 고려해야 할 수 있습니다.

## 문제점 해결 [#troubleshooting]

경우에 따라 누적에서 델타로의 변환 프로세스의 결과로 [New Relic 통합 오류](/docs/data-apis/manage-data/nrintegrationerror) 를 보고합니다. 다음은 몇 가지 일반적인 이유입니다.

### 번역 오류 [#translation-errors]

델타 변환에는 이벤트 시간에 순차적인 두 데이터 포인트의 누적 값이 단조롭게 증가한다는 가정이 포함됩니다. 이 가정이 깨질 것으로 예상되는 유일한 시간은 모니터링 중인 프로세스가 다시 시작될 때입니다. 다른 이유로 단조로움이 깨진 경우에도 이를 재설정으로 처리하지만 계정에 [New Relic 통합 오류](/docs/data-apis/manage-data/nrintegrationerror) 이벤트를 생성하여 알림을 시도합니다. 이는 OpenTelemetry 데이터에 대해 수행할 수 **있지만 Prometheus** 에는 수행할 수 없습니다. OpenTelemetry에는 이러한 상황을 감지하는 데 사용할 수 있는 더 많은 정보가 포함되어 있기 때문입니다. 단조로움이 예기치 않게 중단되는 가장 일반적인 원인은 클라이언트 측 애플리케이션이 카디널리티 한계에 도달하고 메모리 압력을 완화하기 위해 데이터를 삭제하는 경우입니다. 경우에 따라 이는 예기치 않은 재설정으로 작용하여 New Relic으로 전송되는 값이 예기치 않게 감소할 수 있습니다. OTLP 로그에서 이에 대한 인스턴스를 찾는 것이 좋습니다.

```
Instrument % has exceeded the maximum allowed accumulations (2000)
```

OpenTelemetry는 [**보기**](https://opentelemetry.io/docs/reference/specification/metrics/sdk/#view) 를 사용하여 카디널리티 클라이언트 측을 줄이는 방법을 제공하며 이러한 문제를 해결하기 위해 권장되는 경로입니다. 또 다른 옵션은 메모리 절약에 도움이 될 수 있는 [델타 임시성을 사용하여 OTLP 메트릭](https://opentelemetry.io/docs/reference/specification/metrics/sdk_exporters/otlp/#additional-configuration) 내보내기를 탐색하는 것입니다.

### 카디널리티 제한 [#card-limits]

변환하는 동안 시스템 보호를 위해 메트릭 권한을 기반으로 하는 메트릭 카디널리티 제한을 느슨하게 적용합니다. [롤업과 마찬가지로 일일](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes/#violation-unique-timeseries) 한도를 적용하는 대신 이 한도는 추적 중인 동시 시계열 수로 적용됩니다. 동시 [고유 메트릭 시계열](/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/#what-why) 이 너무 많으면 이전 시계열이 만료될 때까지 새 수신 시계열을 삭제합니다( [부실 데이터](#stale-data) 참조).