---
title: '신뢰성 엔지니어링 진단: 애플리케이션 성능 문제 해결을 위한 초보자 가이드'
tags:
  - Observability maturity
  - 'Uptime, performance, and reliability'
  - Site reliability engineering
  - SRE
metaDescription: 'New Relic observability maturity series: A beginner''s guide on identifying common application performance issues.'
translationType: machine
---

import solutionsOmaUprPatternNormal from 'images/solutions_screenshot-full_oma-upr-pattern-normal.webp'

import solutionsNormalPercentilePattern from 'images/solutions_screenshot-full_normal-percentile-pattern.webp'

import solutionsPatternAbnormal from 'images/solutions_screenshot-full_pattern-abnormal.webp'

import solutionsPatternAbnormalCompare from 'images/solutions_screenshot-full_pattern-abnormal-compare.webp'

이 가이드는 고객에게 영향을 미치는 문제를 진단하는 기술을 향상시키는 방법을 소개합니다. 이 가이드의 절차를 따르면 애플리케이션 성능 문제를 보다 빠르게 복구할 수 있습니다.

이 가이드는 [관찰 가능성 성숙도에 대한 시리즈](/docs/new-relic-solutions/observability-maturity/introduction) 의 일부입니다.

## 전제 조건

이 가이드를 사용하기 위한 몇 가지 요구 사항과 권장 사항은 다음과 같습니다.

* New Relic 관측 가능성 적용 범위:

  * **필수** : [분산 추적](/docs/apm/apm-ui-pages/monitoring/apm-summary-page-view-transaction-apdex-usage-data) 이 있는 [APM, 컨텍스트에 있는 APM 로그인](/docs/apm/new-relic-apm/getting-started/get-started-logs-context) 및 [인프라 에이전트](/docs/infrastructure/infrastructure-monitoring/get-started/get-started-infrastructure-monitoring)
  * **권장사항** : [로그](/docs/logs/get-started/get-started-log-management) 및 [네트워크 모니터링](/docs/network-performance-monitoring/get-started/npm-introduction) (NPM)

* **필수** : [서비스 수준 관리](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)

* **권장 사항** : New Relic APM, 분산 추적, NRQL 쿼리 및 로그 관리 UI 사용 경험

* **권장 사항** : 다음 가이드를 읽었습니다.

  * [경보 품질 관리](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide)
  * [서비스 수준 관리](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)

## 개요 [#overview]

이 안내서를 사용하기 전에 학습할 내용을 이해하는 데 도움이 됩니다. 이 가이드는 다음을 이해하는 데 도움이 됩니다.

* 진단 기술 향상이 비즈니스에 미치는 영향.

* 성공을 측정하는 데 사용되는 운영 핵심 성과 지표.

* 최종 사용자가 다양한 유형의 안정성 문제를 인식하는 방법.

* 문제의 _직접적인 원인_ 과 _근본 원인_ 사이의 차이.

* 문제를 찾고 해결하기 위한 기본 진단 단계에는 다음이 포함됩니다.

  * 문제 정의 - 문제 진술 만들기
  * 문제의 원인 찾기
  * 문제의 직접적인 원인 찾기

* 일부 성능 문제 범주(출력 성능, 입력 성능 및 클라이언트 성능)와 이러한 문제를 진단하는 데 사용되는 New Relic 기능(APM, 합성, 브라우저 및 모바일 모니터링).

* 일반적인 문제와 가능한 원인을 이해하기 위한 치트 시트인 문제 매트릭스를 사용하는 방법.

마지막으로 이러한 개념을 더 잘 이해하는 데 도움이 되는 몇 가지 성능 문제의 예를 검토할 것입니다.

## 원하는 결과 [#desired-outcomes]

### 요약

비즈니스 가치는 다음과 같습니다.

* 업무 중단 사고의 수 감소
* 문제 해결에 필요한 시간 단축(MTTR)
* 사고의 운영 비용 절감

IT 운영 및 SRE의 가치는 다음과 같습니다.

* 이해하고 해결하는 시간 단축

### 사업성과 [#business-outcome]

2014년 [Gartner는 IT 다운타임의 평균 비용이 분당 $5,600인 것으로 추정](https://blogs.gartner.com/andrew-lerner/2014/07/16/the-cost-of-downtime) 했습니다. 비즈니스에 영향을 미치는 인시던트의 누적 비용은 파악 시간, 빈도, 복구 시간, 수익 영향 및 인시던트를 분류하고 해결하는 엔지니어 수와 같은 요인에 따라 결정됩니다. 간단히 말해 비즈니스에 영향을 미치는 인시던트가 적고, 인시던트 기간이 짧으며, 진단이 빨라지고 성능 영향을 해결하는 데 필요한 인력이 더 적습니다.

궁극적으로 비즈니스 목표는 가동 시간을 최대화하고 가동 중지 시간 비용이 다음과 같은 가동 중지 시간을 최소화하는 것입니다.

**`Downtime minutes x Cost per minute = Downtime cost`**

다운타임은 비즈니스 중단 사고의 수와 기간에 따라 결정됩니다. 다운타임 비용에는 많은 요소가 포함되지만 가장 직접적으로 측정할 수 있는 것은 운영 비용과 수익 손실입니다.

비즈니스는 다음을 줄여야 합니다.

* 업무에 지장을 주는 사건의 수
* 사고의 운영 비용

### 운영 결과 [#operational-outcome]

필요한 운영 결과는 제품 계층 서비스 수준 목표 준수를 유지하는 것입니다. 저하된 서비스 수준을 진단하고, 진단 내용을 전달하고, 신속한 해결을 수행하여 이를 수행합니다. 그러나 예상치 못한 성능 저하와 사고는 항상 발생하므로 신속하고 효과적으로 대응해야 합니다.

이 시리즈의 다른 가이드에서는 **알아야 할 시간을** 개선하는 데 중점을 둡니다. [경보 품질 관리 가이드](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide) 에서는 파악 시간을 개선하기 위한 **사후 대응** 방법에 중점을 두고 있으며 [서비스 수준 관리 가이드](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide) 에서는 **사전 예방적** 방법에 중점을 둡니다.

지금 읽고 있는 가이드에서는 **이해하는** 데 걸리는 **시간과 해결** 하는 데 걸리는 시간을 개선하는 데 중점을 둡니다.

## 핵심 성과 지표 - 운영 [#operational-kpis]

"사고 관리" 및 SRE 이론의 세계에서 많은 메트릭이 논의되고 논의됩니다. 그러나 대부분은 핵심 성과 지표의 작은 집합에 집중하는 것이 중요하다는 데 동의합니다.

아래 KPI는 성공적인 SRE 및 인시던트 관리 관행에 사용되는 가장 일반적인 지표입니다.

<CollapserGroup>
  <Collapser
    id="slo-compliance"
    title="SLO(서비스 수준 목표) 규정 준수"
  >
    이것은 주요 지표입니다. 서비스 수준은 성능 저하의 시작, 성능 추세, 영향 범위 및 문제가 해결된 시기를 측정합니다.

    이 프로세스에 대한 자세한 내용은 [서비스 수준 관리 가이드](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide) 를 참조하십시오.
  </Collapser>

  <Collapser
    id="time-to-know"
    title="알 시간"
  >
    이 사건이 처음으로 인간에 의해 기록된 시간입니다. 서비스 수준 저하가 시작된 시점과 성능 문제에 대한 기록이 생성된 시점 사이의 파악 시간 측정입니다. [경보 품질 관리 가이드](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide) 는 이 운영 메트릭을 측정하고 개선하는 방법을 보여줍니다.
  </Collapser>

  <Collapser
    id="time-to-understand"
    title="이해하는 시간"
  >
    이것은 사건의 기록(알고 있는 시간)과 영향의 해결(해결하는 데 걸리는 시간) 사이의 시간입니다.
  </Collapser>

  <Collapser
    id="time-to-resolve"
    title="해결 시간"
  >
    해결 시간은 종종 MTTR(평균 복원/수리/해결 시간)이라고 합니다. 성능 저하의 시작(서비스 수준에 따라 결정됨)부터 서비스 수준이 예상 성능 수준으로 돌아올 때까지 측정됩니다.

    **참고** : 해결 시간이 근본 원인이 식별되어 영구적으로 수정되었음을 의미하지는 않습니다. 영구 수정은 사고가 해결된 후 "문제 관리" 프로세스의 일부입니다. 근본 원인 대 직접 원인 및 "근본 원인의 증상"에 대한 연구를 수행하십시오.
  </Collapser>
</CollapserGroup>

## 신뢰성에 대한 최종 사용자의 인식 [#end-user-perception]

고객이 제품의 성능을 인식하는 방식은 긴급성과 우선 순위를 측정하는 방법을 이해하는 데 중요합니다. 또한 고객의 관점을 이해하면 비즈니스에서 문제를 보는 방식을 이해하고 영향을 받는 기능을 지원하는 데 필요한 워크플로를 이해하는 데 도움이 됩니다. 고객과 비즈니스에 대한 인식을 이해하면 해당 기능의 안정성에 영향을 미칠 수 있는 것이 무엇인지 더 잘 이해할 수 있습니다.

궁극적으로 고객 관점의 관찰 가능성은 신뢰성 엔지니어링에서 능동적이고 능숙해지기 위한 첫 번째 단계입니다.

디지털 제품의 성능과 기능에 대한 최종 사용자의 인식에 영향을 미치는 두 가지 주요 경험이 있습니다. 아래 용어는 공통 고객 언어를 사용하는 고객의 관점에서 작성된 것입니다.

<CollapserGroup>
  <Collapser
    id="availability"
    title="가용성, 일명 작동하지 않음"
  >
    가용성은 연결성, 가동 시간, 도달 가능성이라고도 합니다. 그러나 그것은 또한 성공(비 오류)과도 관련이 있습니다.

    최종 사용자는 로그인, 찾아보기, 검색, 인벤토리 보기와 같은 필수 기능에 액세스할 수 없다고 말할 수 있습니다. 또는 단순히 전체 서비스를 사용할 수 없다고 명시할 수도 있습니다. 이것은 서비스에 연결할 수 없거나 오류를 반환하는 서비스의 증상입니다.

    전통적으로 "가용성" 또는 "가동 시간"은 서비스 연결 능력을 측정함으로써 이진 "UP/DOWN" 방법론으로 측정되었습니다. 기존의 방법은 전체 서비스를 완전히 사용할 수 없게 된 경우에만 측정한다는 점에서 중요한 격차가 있습니다. 신뢰성에 대한 이 고전적인 측정은 상당한 관찰 가능성 격차, 어려운 진단 및 최종 사용자가 대응하기 전에 심각한 영향을 받는 결과를 낳습니다.

    가용성은 "가동 시간"이라고도 하는 "서비스에 도달할 수 있는 능력"과 "예상된 응답을 반환하는 서비스 능력"(즉, "오류 없음")으로 측정됩니다. New Relic의 관찰 가능성 성숙도 프레임워크는 **입력 성능** (연결성)과 **출력 성능** (성공 및 응답 지연)으로 둘을 구분합니다.
  </Collapser>

  <Collapser
    id="performance"
    title="성능, 일명 너무 느림"
  >
    성능은 대기 시간 및 응답 시간이라고도 합니다.

    최종 사용자는 서비스가 너무 느리다고 말할 수 있습니다.

    IT 리더와 비즈니스 리더 모두에게 "성능"이라는 용어는 일련의 문제를 포괄할 수 있습니다. New Relic의 서비스 수준 관리에서 "느림"은 "출력" 및 "클라이언트" 범주 모두에서 측정됩니다. 그러나 대부분의 속도 저하 문제는 전통적으로 "백엔드 서비스"라고 하는 출력 문제로 인해 발생합니다.
  </Collapser>
</CollapserGroup>

## 근본 원인 vs 직접 원인 [#root-cause-vs-direct-cause]

문제의 근본 원인은 **그** 문제의 직접적인 원인과 다릅니다. 마찬가지로 직접적인 원인(단기적)을 수정한다고 해서 일반적으로 문제의 근본 원인(장기적)을 수정했다는 의미는 아닙니다. **이 구분을 하는 것이 매우 중요합니다.**

성능 문제를 찾을 때 먼저 "무엇이 변경되었습니까?"라는 질문을 하여 문제의 직접적인 원인을 찾으려고 시도해야 합니다. 변경된 구성 요소 또는 동작은 일반적으로 근본 원인이 아니지만 실제로 먼저 해결해야 하는 직접적인 원인입니다. 근본 원인을 해결하는 것이 중요하지만 일반적으로 사고 후 소급 논의 및 장기적인 문제 관리가 필요합니다.

예: 로그인 기능의 서비스 수준이 갑자기 떨어집니다. 트래픽 패턴이 평소보다 훨씬 높다는 것을 즉시 알 수 있습니다. 성능 문제를 훨씬 더 큰 TCP 연결 대기열을 유발하는 열린 TCP 연결 제한 구성으로 추적합니다. TCP 제한 증가 및 일부 추가 서버 인스턴스를 배포하여 문제를 즉시 해결합니다. 단기적으로는 문제의 직접적인 원인을 해결했지만 근본 원인은 부적절한 용량 계획, 마케팅 커뮤니케이션 누락 또는 업스트림 부하에 의도하지 않은 결과를 초래하는 관련 배포 등이 될 수 있습니다.

이러한 구분은 ITIL/ITSM **인시던트 관리** 대 **문제 관리** 에서도 이루어집니다. 근본 원인은 사고 후 대화에서 논의된 다음 장기적인 문제 관리 프로세스에서 해결됩니다.

## 진단 단계(개요) [#diagnostic-steps]

### 1단계: 문제 정의 [#create-problem-statement]

첫 번째 규칙은 문제 설명을 신속하게 설정하는 것입니다. 문제 진술 작성에 대한 많은 지침이 있지만 간단하고 효과적인 것이 가장 좋습니다. 잘 구성된 문제 진술은 다음을 수행합니다.

1. 최종 사용자가 경험하는 것을 설명하십시오. 최종 사용자가 겪고 있는 문제는 무엇입니까?
2. 제품 기능의 예상 동작을 설명합니다. 최종 사용자가 경험해야 하는 것은 무엇입니까?
3. 제품 기능의 현재 동작을 설명합니다. 사용자가 경험하는 것에 대한 기술적 평가는 무엇입니까?

문제 진술에서 가정을 피하십시오. 사실에 충실하십시오.

### 2단계: 출처 찾기 [#find-source]

"소스"는 문제의 직접적인 원인에 가장 가까운 구성 요소 또는 코드입니다.

많은 접합부, 스플리터 및 밸브를 통해 연결된 많은 수도관을 생각해 보십시오. 용수 출력 서비스 수준이 저하되었다는 경고를 받습니다. 어떤 접합부, 분할, 밸브 또는 파이프가 문제를 일으키는지 확인할 때까지 파이프를 통한 물 출력에서 문제를 추적합니다. 전기 밸브 중 하나가 단락된 것을 발견했습니다. 그 밸브가 문제의 원인입니다. 짧은 것은 문제의 직접적인 원인입니다. 값을 교체하여 직접적인 원인을 쉽게 해결할 수 있습니다. 근본 원인은 기상 조건, 수중 화학 물질 또는 제조와 같이 더 복잡한 것일 수 있음을 명심하십시오.

이것은 복잡한 기술 스택을 진단하는 것과 동일한 개념입니다. 로그인 기능이 제한된 경우(출력) 해당 제한을 유발하는 구성 요소(소스)로 다시 문제를 추적하고 수정해야 합니다. API 소프트웨어(서비스 경계), 미들웨어 서비스, 데이터베이스, 리소스 제약, 타사 서비스 등이 될 수 있습니다.

IT에는 응답 시간을 개선하기 위한 세 가지 주요 중단점 범주가 있습니다.

1. **산출**
2. **입력**
3. **고객**

[서비스 수준](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide) 이라고도 하는 이러한 범주 내에서 성능 지표를 정의하면 문제의 원인이 어디인지 판단할 때 응답 시간이 크게 향상됩니다. 이러한 범주 측정은 [서비스 수준 관리 가이드](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide) 에서 다룹니다. 진단에 사용하는 방법을 이해하려면 계속 읽으십시오.

### 3단계: 직접적인 원인 찾기 [#find-direct-cause]

문제의 원인에 가까우면 무엇이 변경되었는지 확인합니다. 이렇게 하면 단기간에 문제를 즉시 해결하는 방법을 신속하게 결정할 수 있습니다. [2단계](#find-source) 의 예에서 변경 사항은 단락을 유발하는 하드웨어 성능 저하로 인해 밸브가 더 이상 작동하지 않는다는 것이었습니다.

IT의 일반적인 변경 사항의 예는 다음과 같습니다.

1. 처리량(트래픽)
2. 코드(배포)
3. 리소스(하드웨어 할당)
4. 업스트림 또는 다운스트림 종속성 변경
5. 데이터 볼륨

성능에 영향을 미치는 문제의 다른 일반적인 예는 아래의 [문제 매트릭스](#problem-matrix) 를 참조하십시오.

## 건강 데이터 포인트 사용 [#health-data-points]

앞서 언급한 바와 같이 진단 여정을 빠르게 시작하는 세 가지 기본 성능 범주가 있습니다. 이러한 건강 데이터 포인트를 이해하면 문제의 원인을 이해하는 데 걸리는 시간을 크게 줄일 수 있습니다.

<CollapserGroup>
  <Collapser
    id="output-perf"
    title="출력 성능"
  >
    **여기에는** 다음이 필요합니다.

    출력 성능은 예상 응답(출력)을 최종 사용자에게 전달하는 내부 기술 스택의 능력입니다. 이를 전통적으로 "백엔드" 서비스라고 합니다.

    대부분의 시나리오에서 출력 성능은 단순히 응답 속도와 응답 품질로 측정됩니다(즉, 오류가 없음). 위에서 설명한 사용자 관점을 기억하십시오. 최종 사용자는 서비스가 느리거나 작동하지 않거나 액세스할 수 없다고 말합니다.

    가장 일반적인 문제는 최종 사용자 요청에 적시 **에** 성공적인 방식으로 응답하는 능력입니다.

    이는 문제가 있는 제품 기능을 지원하는 서비스의 대기 시간 이상 또는 오류 이상으로 쉽게 식별됩니다.
  </Collapser>

  <Collapser
    id="input-perf"
    title="입력 성능"
  >
    **여기에는 다음이 필요합니다** . 합성

    입력 성능은 단순히 클라이언트로부터 요청을 수신하는 서비스의 능력입니다. 이것은 요청을 보내는 클라이언트의 능력과는 다릅니다.

    출력 성능(백엔드 서비스)이 예상 성능 수준을 초과할 수 있습니다. 그러나 클라이언트와 서비스 사이의 무언가가 요청-응답 수명 주기를 깨뜨리고 있습니다. 클라이언트와 서비스 사이의 모든 것이 될 수 있습니다.
  </Collapser>

  <Collapser
    id="client-perf"
    title="클라이언트 성능"
  >
    **이를 위해서는** 브라우저 모니터링 및/또는 모바일 모니터링이 필요합니다.

    클라이언트 성능은 브라우저 및/또는 모바일 애플리케이션이 요청하고 응답을 렌더링하는 기능입니다. 출력(백엔드)과 입력 성능(합성)이 모두 배제되면 브라우저 및/또는 모바일이 문제의 원인으로 쉽게 식별됩니다.

    출력 및 입력 성능은 상대적으로 배제(또는 배제)하기 쉽습니다. 입력 및 출력 진단의 진단 깊이로 인해 브라우저 및 모바일은 향후 고급 진단 가이드에서 다룰 예정입니다.
  </Collapser>
</CollapserGroup>

## 문제 매트릭스 [#problem-matrix]

문제 매트릭스는 세 가지 건강 데이터 포인트로 분류된 일반적인 문제의 치트 시트입니다.

문제의 원인은 빈도에 따라 정렬되며 가장 일반적인 것은 맨 위 행과 왼쪽에 있습니다. 자세한 분류는 아래에 나와 있습니다. 서비스 수준 관리를 잘 수행하면 이러한 데이터 요소 중 3개 중 2개를 신속하게 배제하는 데 도움이 됩니다.

이 테이블은 건강 데이터 포인트별로 정렬된 문제 매트릭스입니다.

| 데이터 포인트 | New Relic 기능      | 일반적인 문제 소스                                                 |
| ------- | ----------------- | ---------------------------------------------------------- |
| 산출      | APM, 인프라, 로그, NPM | 애플리케이션, 데이터 소스, 하드웨어 구성 변경, 인프라, 내부 네트워킹, 타사 공급자(AWS, GCP) |
| 입력      | 합성, 통나무           | 외부 라우팅(CDN, 게이트웨이 등), 내부 라우팅, 인터넷 상의 사물(ISP 등)             |
| 고객      | 브라우저, 모바일         | 브라우저 또는 모바일 코드                                             |

문제는 복잡해지는 경향이 있지만 목표는 서비스 수준을 신속하게 복원하기 위해 "원인을 찾고" "변경된 사항"을 파악하는 것입니다.

### 예제 문제 [#example-problem]

예제 문제를 살펴보겠습니다. 회사에서 새 제품을 배포하고 요청이 크게 증가하여 허용할 수 없는 응답 시간이 발생했다고 가정해 보겠습니다. 소스는 로그인 미들웨어 서비스에서 검색됩니다. 문제는 TCP 대기열 시간의 점프입니다.

이 상황을 분석하면 다음과 같습니다.

* **카테고리** : 출력 성능
* **출처** : 로그인 미들웨어
* **직접적인 원인** : 추가 요청 부하로 인한 TCP queue 시간
* **솔루션** : 증가된 TCP 연결 제한 및 확장된 리소스
* **근본 원인** : 로그인 미들웨어에 영향을 미치는 다운스트림 서비스에 대한 불충분한 용량 계획 및 품질 보증 테스트

### 또 다른 예시 문제 [#example-problem-2]

다음은 또 다른 예제 문제입니다.

* 로그인 시 게이트웨이 오류가 500개 갑자기 증가했습니다...
* 로그인 API 응답 시간이 시간 초과가 시작된 지점까지 증가했습니다...
* 시간 초과는 미들웨어 계층의 데이터베이스 연결로 추적되었습니다...
* 트랜잭션 추적을 통해 로그인 요청당 데이터베이스 쿼리 수가 크게 증가한 것으로 나타났습니다...
* 문제 직전에 발생한 배포에 대한 배포 마커가 발견되었습니다.

이 상황을 분석하면 다음과 같습니다.

* **범주** : 입력 성능 저하로 이어지는 출력 성능 저하
* **출처** : 미들웨어 서비스 호출 데이터베이스
* **직접적인 원인** : 코드 배포 후 데이터베이스 쿼리 10배 증가
* **솔루션** : 배포 롤백
* **근본 원인** : 불충분한 품질 보증 테스트

### 소스별 문제 매트릭스 [#problem-matrix-sources]

다음은 소스별로 정렬된 문제 행렬이 있는 표입니다.

<table>
  <thead>
    <tr>
      <th>
        **원천**
      </th>

      <th>
        **일반적인 직접 원인**
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        애플리케이션
      </td>

      <td>
        1. 최근 배포(코드)
        2. 하드웨어 리소스 제약
        3. 데이터베이스 제약 조건
        4. 구성 변경(하드웨어/라우팅/네트워킹)
        5. 타사 종속성
      </td>
    </tr>

    <tr>
      <td>
        데이터 소스
      </td>

      <td>
        1. 데이터베이스 제약 조건
        2. 쿼리 로직 변경(n+1)
        3. 메시지 대기열(일반적으로 생산자 또는 소비자 성능이 저하됨)
      </td>
    </tr>

    <tr>
      <td>
        내부 네트워킹 및 라우팅
      </td>

      <td>
        1. 로드 밸런서
        2. 프록시
        3. API 게이트웨이
        4. 라우터(희귀)
        5. ISP/CDN(희귀)
      </td>
    </tr>
  </tbody>
</table>

## 성능 패턴 이상 식별 [#pattern-anomalies]

<Callout variant="tip">
  주요 트랜잭션(기능)과 관련된 서비스 경계에 잘 구성된 [서비스 수준](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide) 이 있으면 문제가 있는 종단 간 워크플로를 더 빨리 식별하는 데 도움이 됩니다.
</Callout>

패턴 이상을 식별하면 문제의 직접적인 원인이 무엇이고 어디에 있는지 식별하는 능력이 향상됩니다.

패턴 식별에 대한 많은 훌륭한 정보와 무료 온라인 수업이 있지만 일반적인 개념은 다소 단순하며 강력한 진단 능력을 발휘할 수 있습니다.

성능 데이터의 패턴과 이상을 식별하는 핵심은 서비스가 어떻게 수행되어야 하는지 알 필요가 없다는 것 **입니다. 최근 동작이 변경되었는지만 확인하면 됩니다.**

이 섹션에 제공된 예제에서는 응답 시간 또는 대기 시간을 메트릭으로 사용하지만 오류, 처리량, 하드웨어 리소스 메트릭, 대기열 깊이 등과 같은 거의 모든 데이터 세트에 동일한 분석을 적용할 수 있습니다.

### 정상 [#normal]

다음은 APM의 변동성이 있어 보이는 응답 시간 차트(7일)의 예입니다. 자세히 보면 응답 시간의 동작이 반복적임을 알 수 있습니다. 즉, 7일 동안 행동에 급격한 변화가 없습니다. 스파이크는 반복적이며 나머지 타임라인과 비교하여 이상하지 않습니다.

<img
  alt="normal pattern"
  title="Normal pattern"
  src={solutionsOmaUprPatternNormal}
/>

사실, 데이터 보기를 시간 경과에 **따른 평균에서 시간 경과** 에 따른 **백분위수** 로 변경하면 응답 시간의 변경이 얼마나 "정기적"인지 훨씬 더 명확해집니다.

<img
  alt="normal pattern with percentile"
  title="Normal pattern with percentile"
  src={solutionsNormalPercentilePattern}
/>

### 이상 [#abnormal]

이 차트는 최근 동작에 비해 비정상적으로 증가한 것으로 보이는 애플리케이션 응답 시간을 보여줍니다.

<img
  alt="abnormal pattern"
  title="Abnormal pattern"
  src={solutionsPatternAbnormal}
/>

이는 주별 비교를 사용하여 확인할 수 있습니다.

<img
  alt="abnormal pattern week-over-week"
  title="Abnormal pattern week-over-week comparison"
  src={solutionsPatternAbnormalCompare}
/>

패턴이 변경되었으며 지난주 비교에서 악화되는 것으로 보입니다.

## 출처 찾기 [#finding-source]

다음으로 New Relic에서 소스를 찾는 방법을 살펴보겠습니다. 이 워크플로우는 분산 추적에 의존합니다.

먼저 최종 사용자가 경험하는 대기 시간 또는 오류와 관련된 애플리케이션을 찾습니다. 이것은 응용 프로그램이나 코드가 문제라는 것을 의미하지는 않지만 흐름 내에서 응용 프로그램을 찾으면( _첫 번째_ ) 소스에 더 빨리 접근할 수 있습니다. 이 응용 프로그램이 발견되면 코드, 호스트, 데이터베이스, 구성 및 네트워크와 같은 구성 요소를 빠르게 배제할 수 있습니다.

애플리케이션이 식별되면 문제는 해당 애플리케이션 내의 어떤 트랜잭션이 문제의 일부인지입니다. 성능 문제가 발생한 것으로 확인한 애플리케이션을 사용하고 영향을 받는 트랜잭션을 식별합니다. 여기에서 [Identif performance pattern anomalies](#pattern-anomalies) 에서 위에서 설명한 성능 패턴 이상 기술을 반복할 수 있지만 이번에는 트랜잭션 자체에 대해 수행합니다.

다음 문서는 New Relic을 사용하여 문제 트랜잭션을 식별하는 데 도움이 됩니다.

1. [거래 페이지: 특정 성능 문제 찾기](/docs/apm/apm-ui-pages/monitoring/transactions-page-find-specific-performance-problems/)
2. [서비스 요약 페이지의 느린 트랜잭션](/whats-new/2021/03/slow-transactions)

문제가 있는 트랜잭션이 식별되면 분산 추적을 사용하여 해당 트랜잭션을 지원하는 종단 간 구성 요소를 검토할 수 있습니다. 분산 추적은 하나의 보기 내에서 전체 스택에서 대기 시간이 있는 위치 및/또는 오류가 발생하는 위치를 신속하게 식별하는 데 도움이 됩니다.

다음 리소스는 분산 추적을 사용하여 소스 문제 구성 요소를 식별하는 방법을 배우는 데 도움이 됩니다.

1. [분산 추적 소개](/docs/distributed-tracing/concepts/introduction-distributed-tracing)
2. [분산 추적 UI를 사용하는 방법](/docs/distributed-tracing/ui-data/understand-use-distributed-tracing-ui/)
3. [분산 추적에 대한 무료 온라인 웨비나](https://learn.newrelic.com/new-relic-distributed-tracing-tracking-across-your-application-stacks)
4. [직접적인 원인 분석을 위한 분산 추적 사용에 대한 비디오](https://www.youtube.com/watch?v=r9ImAQ5J5h4)

소스 찾기 단계에 대한 간략한 요약은 다음과 같습니다.

1. 영향을 받는 성능과 관련된 애플리케이션을 검사합니다.
2. 문제의 원인이 되는 트랜잭션을 식별합니다.
3. 분산 추적을 사용하여 종단 간 흐름 내에서 문제 구성 요소를 식별합니다.

이제 직접적인 원인을 식별하는 마지막 단계로 넘어갈 수 있습니다.

## 직접적인 원인 찾기 [#finding-direct-cause]

소스 구성 요소가 발견되면 직접적인 원인을 결정할 수 있습니다.

이전 단계의 지식을 사용하면 문제가 대기 시간, 성공 또는 둘 다인지 알 수 있습니다.

대기 시간 문제는 트랜잭션 추적 및/또는 분산 추적 내의 "진행 중인 범위"를 사용하여 찾을 수 있습니다.

성공 문제 오류 메시지는 추적에서도 볼 수 있지만 성공 문제에 대한 최상의 세부 정보는 일반적으로 애플리케이션 로그에서 찾을 수 있습니다.

어느 쪽이든 1계층 사고 대응자 또는 SRE인 경우 직접적인 원인을 찾는 것은 일반적으로 발견된 소스 구성 요소를 담당하는 개발자 및 엔지니어인 주제 전문가(SME)에게 맡겨질 것입니다.

소스 구성 요소를 발견한 후 가장 효과적인 다음 단계는 해당 구성 요소에 대해 주제 전문가에게 문의하는 것입니다. 문제 해결을 시작하기 위해 완료한 분류 및 진단에서 발견한 데이터를 그들에게 보여주십시오.

<Callout variant="tip">
  Log-in-Context 및 분산 추적은 최신 버전에서 기본적으로 활성화됩니다. <InlinePopover type="apm"/>자치령 대표. (한 동안 에이전트를 업데이트하지 않은 경우 [에이전트를 정기적으로 업데이트하는](/docs/new-relic-solutions/new-relic-one/install-configure/update-new-relic-agent)것이 좋습니다.)

  로그인 컨텍스트 및 분산 추적은 분류, 진단 및 장기적인 문제 해결 시간을 줄이는 데 필요한 중요한 기능입니다.
</Callout>

이제 New Relic과 함께 최고의 사이트 신뢰성 엔지니어가 되어보세요!

## 다음 단계 [#next-steps]

아직 읽지 않았다면 다음을 포함하여 관련 [관측 가능성 성숙도 가이드](/docs/new-relic-solutions/observability-maturity/introduction) 를 읽어볼 수 있습니다.

* [경보 품질 관리](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/alert-quality-management-guide)
* [서비스 수준 관리](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/optimize-slm-guide)