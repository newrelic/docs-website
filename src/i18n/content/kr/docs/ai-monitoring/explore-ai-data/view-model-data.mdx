---
title: 모델 데이터 분석
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: '2024-06-12T00:00:00.000Z'
translationType: machine
---

AI 모니터링은 AI 모델에 대한 데이터를 표면화하므로 AI 앱 성능과 함께 AI 모델 성능을 분석할 수 있습니다. 다음 두 가지 영역에서 AI 모델에 대한 데이터를 찾을 수 있습니다.

* <DNT>
    **Model inventory**
  </DNT>

  : 계정의 모든 AI 모델에 대한 성능 및 완료 데이터를 보여주는 중앙 집중식 보기입니다. 토큰 사용을 분리하고, 전체 성능을 추적하거나, 모델이 수행하는 개별 완료를 자세히 살펴보세요.

* <DNT>
    **Compare models**
  </DNT>

  : 시간 경과에 따른 두 모델 간의 성능 비교 분석을 수행합니다. 이 페이지에는 시간 경과에 따른 모델 성능의 집계 분석을 위한 데이터가 표시됩니다.

<img
  title="Model data overview"
  alt="A screenshot of the model inventory page"
  src="/images/ai_screenshot-crop_intro-to-model-data.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring</DNT>** 으로 이동: AI 모니터링에서 모델 인벤토리 또는 모델 비교 중에서 선택할 수 있습니다.
</figcaption>

## 모델 인벤토리 페이지 [#model-inventory]

<img
  title="Model inventory overview"
  alt="A screenshot of the overview page when you go to Model inventory"
  src="/images/ai_screenshot-full_model-inventory-overview-page.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory</DNT>** 으로 이동: AI 모델과의 상호작용에 대한 데이터를 봅니다.
</figcaption>

<DNT>model inventory</DNT> 페이지에서는 AI 모델의 전반적인 성능과 사용법에 대한 인사이트를 제공합니다. 모델에 대한 호출의 데이터를 분석하여 AI 모델이 AI 앱에 미치는 영향을 이해할 수 있습니다.

개요 탭에서 응답 시간을 기준으로 모델에 대한 요청 수를 탐색하거나 시계열 그래프를 분석하여 모델 동작이 변경된 시기를 확인하세요. 여기에서 오류, 성능 또는 비용 탭을 조사합니다.

### 오류 탭 [#errors-inventory]

<img
  title="Model inventory: Errors"
  alt="A screenshot of the Errors time series and chart"
  src="/images/ai_screenshot-crop_model-inventory-errors.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Errors</DNT>** 으로 이동: AI 모델 오류에 대한 데이터를 봅니다.
</figcaption>

오류 탭에서는 시계열 그래프와 표를 사용하여 모델 오류를 정리합니다.

* <DNT>
    **Response errors**
  </DNT>

  : AI 모델에서 발생하는 총 오류 수를 추적합니다.

* <DNT>
    **Response errors by model**
  </DNT>

  : 하나의 특정 모델이 평균적으로 더 많은 오류를 생성하는지, 아니면 모델 전체에서 하나의 특정 오류가 발생하는지 확인합니다.

* <DNT>
    **Response errors by type**
  </DNT>

  : 특정 오류가 얼마나 자주 나타나는지 확인합니다.

* <DNT>
    **Errors table**
  </DNT>

  : 요청 및 응답의 맥락에서 오류 유형과 메시지를 봅니다.

### 성능 탭 [#performance-inventory]

<img
  title="Model inventory: Performance"
  alt="A screenshot of the Errors time series and chart"
  src="/images/ai_screenshot-crop_model-inventory-performance-page.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Performance</DNT>** 으로 이동: AI 모델 성능에 대한 데이터를 확인하세요.
</figcaption>

성능 탭은 모든 모델의 응답 및 요청 지표를 집계합니다. 요청을 처리하거나 원형 차트를 사용하여 응답을 생성하는 데 가장 많은 시간이 걸리는 모델을 살펴보거나 시계열 그래프를 참조하여 요청 또는 응답 시간의 증가를 추적하세요. 성능 차트를 사용하여 모델 전체에서 이상치를 찾을 수 있습니다.

### 비용 탭 [#cost-inventory]

<img
  title="Model inventory: Performance"
  alt="A screenshot of the Errors time series and chart"
  src="/images/ai_screenshot-crop_model-inventory-cost.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Cost</DNT>** 으로 이동: AI 모델 비용에 대한 데이터를 확인하세요.
</figcaption>

비용 탭에서는 시계열 그래프와 원형 차트의 조합을 사용하여 모델 간의 비용 동인을 식별합니다. 프롬프트 또는 완료에서 나온 토큰 수를 확인하거나 특정 모델이 다른 모델보다 평균적으로 더 많은 비용이 드는지 확인합니다.

* <DNT>
    **Tokens used and token limit**
  </DNT>

  : 모델이 주어진 토큰 한도에 얼마나 자주 접근하는지 평가합니다.

* <DNT>
    **Total tokens by models**
  </DNT>

  : 평균적으로 가장 많은 토큰을 사용하는 모델을 결정합니다.

* <DNT>
    **Total usage by prompt and completion tokens**
  </DNT>

  : 완료 시 사용되는 토큰에 대해 모델이 수락하는 프롬프트에서 나오는 토큰의 비율을 이해합니다.

비용을 이해하면 AI 앱이 하나 이상의 모델을 사용하는 방식을 개선하여 AI 도구 체인의 비용 효율성을 높일 수 있습니다.

## 모델 비교 페이지 [#model-comparison]

<img
  title="Model inventory overview"
  alt="A screenshot of the overview page when you go to Model inventory"
  src="/images/ai_screenshot-full_ai-model-comparison-page.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DNT>** 으로 이동: 스택에 있는 다양한 AI 모델에 대한 데이터를 비교합니다.
</figcaption>

모델 비교 페이지에서는 AI 모니터링 데이터를 정리하여 비교 분석에 도움을 줍니다. 이 페이지에서는 모델 비교 데이터의 범위를 단일 계정으로 지정하여 하나 이상의 앱에서 모델 비용 및 성능에 대한 집계 데이터를 제공합니다. 데이터를 생성하려면:

1. 드롭다운에서 모델을 선택하세요.
2. 특정 앱의 컨텍스트에서 성능을 확인하려면 하나의 서비스로 범위를 지정하거나, 모델이 평균적으로 어떻게 작동하는지 확인하려면 쿼리를 `Service = All` 로 유지하세요.
3. 시간을 선택하세요. 이 도구는 유연합니다. 다양한 기간에 걸쳐 비교할 수 있으므로 배포 전후에 성능이나 비용이 어떻게 변했는지 확인할 수 있습니다.

### 모델 성능 비교 [#compare-performance]

<img
  title="Model comparison page: Performance"
  alt="A screenshot of model comparison"
  src="/images/ai_screenshot-crop_model-comparison-performance.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DNT>** 으로 이동: 스택에 있는 다양한 AI 모델 간의 성능을 비교하세요.
</figcaption>

비교 분석을 시작하려면 특정 서비스, 모델 및 기간을 선택하세요. 모델을 비교할 때 자신의 설정에 따라 시간 경과에 따라 집계된 다양한 지표를 평가할 수 있습니다. 비교 분석을 위한 몇 가지 사용 사례는 다음과 같습니다.

* **동일한 서비스의 두 모델 비교**: 서비스 X는 첫 번째 주에는 모델 A를 사용하고 두 번째 주에는 모델 B를 사용합니다. 서비스 X를 선택하고, 모델 A를 선택하고, 1주차 날짜를 설정하여 성능을 비교할 수 있습니다. 두 번째 측면에서는 서비스 X를 선택하고 모델 B를 선택한 후 2주차 날짜를 설정합니다.
* **시간 경과에 따른 한 모델의 성능 비교**: 서비스 X를 선택하고, 모델 A를 선택한 후 1주차 날짜를 설정합니다. 두 번째 측면에서는 서비스 X를 선택하고 모델 A를 선택한 후 2주차 날짜를 설정합니다.
* **두 가지 다른 서비스에서 모델 성능을 평가합니다**. 두 가지 다른 모델을 사용하는 두 가지 다른 애플리케이션이 있습니다. 지난 달의 총 개수를 비교하려면 특정 서비스 및 특정 모델에 대한 관련 포럼을 선택한 다음 동일한 기간에 대한 날짜를 설정하세요.
* **두 모델 비교**: 모델 A를 사용하는 애플리케이션이 있고 모델 B에 대해 모델 A를 측정하려고 합니다. 모든 사용자의 프롬프트에 대해 모델 B를 백그라운드 프로세스로 호출합니다. 동일한 기간 동안 동일한 서비스에서 모델 A가 모델 B에 비해 어떻게 수행되는지 비교합니다.

### 모델 비용 비교 [#compare-cost]

<img
  title="Model comparison page: Cost"
  alt="A screenshot of model comparison"
  src="/images/ai_screenshot-crop_model-comparison-cost.webp"
/>

<figcaption>
  **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DNT>** 으로 이동: 스택에 있는 다양한 AI 모델 간 비용을 비교하세요.
</figcaption>

모델 비용 열은 완료 이벤트를 두 부분, 즉 모델에 제공되는 프롬프트와 모델이 최종 사용자에게 전달하는 최종 응답으로 분류합니다.

* <DNT>
    **Tokens per completion**
  </DNT>

  : 모든 완료 이벤트에 대한 토큰 평균입니다.

* <DNT>
    **Prompt tokens**
  </DNT>

  : 프롬프트의 토큰 평균입니다. 이 평균에는 헤드폰 엔지니어 및 최적 사용자가 만든 항목이 포함됩니다.

* <DNT>
    **Completion tokens**
  </DNT>

  : 최종 사용자에게 전달되는 응답을 생성할 때 모델이 소비하는 토큰 수입니다.

이 열을 분석할 때 완료 토큰 및 프롬프트 토큰 값은 완료당 토큰 값과 동일해야 합니다.

## 다음은 뭐지? [#whats-next]

이제 데이터를 찾는 방법을 알았으므로 AI 모니터링이 제공하는 다른 기능을 탐색할 수 있습니다.

* AI 앱의 성능을 분석하고 싶으신가요? [AI 앱 응답 페이지](/docs/ai-monitoring/explore-ai-data/view-ai-responses) 에 대한 문서를 확인하세요.
* 민감한 정보가 걱정되시나요? [드롭 필터를 설정하는 방법을 알아보세요](/docs/ai-monitoring/drop-sensitive-data).
* 뉴렐릭에 대한 앱의 AI 반응에 대한 사용자 피드백 정보를 전달하려면 절차에 따라 [앱 코드를 업데이트하여 UI에서 사용자 피드백을 받으세요](/docs/ai-monitoring/customize-agent-ai-monitoring).
