---
title: Integração a Confluent cloud
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

O New Relic oferece uma integração para coletar seus dados [de streaming gerenciados pelo Confluent Cloud para Apache Kafka](https://www.confluent.io/confluent-cloud/) . Este documento explica como ativar essa integração e descreve os dados que podem ser relatados.

## Pré-requisitos

* Uma conta New Relic
* Uma conta ativa do Confluent Cloud
* Uma chave de API e segredo da Confluent Cloud
* `MetricsViewer` acesso na conta Confluent Cloud

## Ativar integração [#activate]

Para habilitar esta integração, vá para <DNT>**Integrations &amp; Agents**</DNT>, selecione <DNT>**Confluent Cloud -&gt; API Polling**</DNT> e siga as instruções.

<Callout variant="important">
  Se você tiver a filtragem de IP configurada, adicione os seguintes endereços IP ao seu filtro.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  Para obter mais informações sobre as faixas IP New Relic para integração na nuvem, consulte [este documento](/docs/new-relic-solutions/get-started/networks/#webhooks). Para obter instruções sobre como executar esta tarefa, consulte [este documento](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html).
</Callout>

## Configuração e polling [#polling]

Informações de pesquisa padrão para a integração do Confluent Cloud Kafka:

* Intervalo de sondagem New Relic : 5 minutos
* Intervalo de dados da Confluent Cloud: 1 minuto

Você pode alterar a frequência de pesquisa somente durante a configuração inicial.

## Visualizar e usar dados [#find-data]

Você pode [consultar e explorar seus dados](/docs/using-new-relic/data/understand-data/query-new-relic-data) usando o seguinte [tipo de evento](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels):

<table>
  <thead>
    <tr>
      <th>
        Entidade
      </th>

      <th>
        Tipo de dados
      </th>

      <th>
        Fornecedor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Cluster
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        Conector
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        ksql
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

Para saber mais sobre como usar seus dados, consulte [Compreender e usar dados de integração](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Dados métricos [#metrics]

Esta integração registra dados do Confluent cloud Kafka para cluster, conector e ksql.

### Dados de cluster

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Uma medida da utilização do cluster. O valor está entre 0,0 e 1,0. Apenas o cluster de nível dedicado possui esses dados métricos.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Um indicador da presença de uma partição quente causada por taxas de transferência de ingresso. O valor é 1,0 quando uma partição ativa é detectada e vazio quando nenhuma partição ativa é detectada.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Um indicador da presença de uma partição quente causada por taxas de transferência de egresso. O valor é 1,0 quando uma partição ativa é detectada e vazio quando nenhuma partição ativa é detectada.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta do total de bytes de solicitação dos tipos de solicitação especificados enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta do total de bytes de resposta dos tipos de resposta especificados enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta de bytes dos dados dos clientes recebidos da rede. Cada amostra é o número de bytes recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta de bytes dos dados dos clientes enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de registros recebidos. Cada amostra é o número de registros recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de registros enviados. Cada amostra é o número de registros enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        O número de partições.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        O atraso entre o deslocamento confirmado de um membro do grupo e o limite máximo da partição.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de autenticações bem-sucedidas. Cada amostra é o número de autenticações bem-sucedidas desde o ponto de dados anterior. A contagem amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem de conexões autenticadas ativas.
      </td>
    </tr>
  </tbody>
</table>

### Dados do conector

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta do número total de registros enviados das transformações e gravados no Kafka para o conector de origem. Cada amostra é o número de registros enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `connector_status`
      </td>

      <td>
        Bit
      </td>

      <td>
        O status de um conector dentro do sistema. Seu valor é sempre definido como 1, significando a presença do conector. O estado operacional atual do conector é identificado por meio da tag métrica.status.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_status`
      </td>

      <td>
        Bit
      </td>

      <td>
        O status da tarefa de um conector dentro do sistema. Seu valor é sempre definido como 1, significando a presença da tarefa do conector. O estado operacional atual do conector é identificado por meio da tag métrica.status.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_avg`
      </td>

      <td>
        Contar
      </td>

      <td>
        O tamanho médio do lote (medido pela contagem de registros) por minuto. Para um conector de origem, indica o tamanho médio do lote enviado ao Kafka. Para um conector de coletor, indica o tamanho médio do lote lido pela tarefa de coletor.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_max`
      </td>

      <td>
        Contar
      </td>

      <td>
        O tamanho máximo do lote (medido pela contagem de registros) por minuto. Para um conector de origem, indica o tamanho máximo do lote enviado ao Kafka. Para um conector de coletor, indica o tamanho máximo do lote lido pela tarefa de coletor.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta do número total de registros recebidos pelo conector do coletor. Cada amostra é o número de registros recebidos desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta do número total de registros recebidos pelo conector do coletor. Cada amostra é o número de registros recebidos desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta do total de bytes recebidos pelo conector do coletor. Cada amostra é o número de bytes recebidos desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `dead_letter_queue_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de registros de fila de letras mortas gravados no Kafka para o conector de recebimento. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>
  </tbody>
</table>

### dados ksql

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `streaming_unit_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem de Unidades de Streaming Confluentes (CSUs) para esta instância do KSQL. A contagem é amostrada a cada 60 segundos. A agregação de tempo implícita para esta métrica é MAX.
      </td>
    </tr>

    <tr>
      <td>
        `query_saturation`
      </td>

      <td>
        Por cento
      </td>

      <td>
        A saturação máxima para uma determinada consulta ksqlDB em todos os nós. Retorna um valor entre 0 e 1, um valor próximo de 1 indica que o processamento da consulta do ksqlDB está com gargalo nos recursos disponíveis.
      </td>
    </tr>

    <tr>
      <td>
        `task_stored_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        O tamanho dos armazenamentos de estado de uma determinada tarefa em bytes.
      </td>
    </tr>

    <tr>
      <td>
        `storage_utilization`
      </td>

      <td>
        Por cento
      </td>

      <td>
        A utilização total de armazenamento para um determinado aplicativo ksqlDB.
      </td>
    </tr>

    <tr>
      <td>
        `consumed_total_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta de bytes consumidos do Kafka pela consulta contínua durante o período solicitado.
      </td>
    </tr>

    <tr>
      <td>
        `produced_total_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta de bytes produzidos no Kafka pela consulta contínua durante o período solicitado.
      </td>
    </tr>

    <tr>
      <td>
        `offsets_processed_total`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de deslocamentos processados por uma determinada consulta, tarefa ou tópico, ou deslocamento.
      </td>
    </tr>

    <tr>
      <td>
        `committed_offset_lag`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        O atraso atual entre o deslocamento confirmado e o deslocamento final para uma determinada consulta, tarefa ou tópico, ou deslocamento.
      </td>
    </tr>

    <tr>
      <td>
        `processing_errors_total`
      </td>

      <td>
        Contar
      </td>

      <td>
        Contagem delta do número de erros de processamento de registros de uma consulta durante o período solicitado.
      </td>
    </tr>

    <tr>
      <td>
        `query_restarts`
      </td>

      <td>
        Contar
      </td>

      <td>
        Contagem delta do número de falhas que fazem com que uma consulta seja reiniciada durante o período solicitado.
      </td>
    </tr>
  </tbody>
</table>

## Qual é o próximo

<DocTiles>
  <DocTile title="Dados e interface" path="/docs/message-queues-streaming/ui-data/understand-ui">
    Aprenda a usar New Relic para monitorar seu cluster Kafka
  </DocTile>
</DocTiles>