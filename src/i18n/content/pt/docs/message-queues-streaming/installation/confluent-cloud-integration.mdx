---
title: Integração a Confluent cloud
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

O New Relic oferece uma integração para coletar seus dados [de streaming gerenciados pelo Confluent Cloud para Apache Kafka](https://www.confluent.io/confluent-cloud/) . Este documento explica como ativar essa integração e descreve os dados que podem ser relatados.

## Pré-requisitos

* Uma conta New Relic
* Uma conta ativa do Confluent Cloud
* Uma chave de API e segredo da Confluent Cloud
* `MetricsViewer` acesso na conta Confluent Cloud

## Ativar integração [#activate]

Para habilitar esta integração, vá para <DNT>**Integrations &amp; Agents**</DNT>, selecione <DNT>**Confluent Cloud -&gt; API Polling**</DNT> e siga as instruções.

<Callout variant="important">
  Se você tiver a filtragem de IP configurada, adicione os seguintes endereços IP ao seu filtro.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  Para obter mais informações sobre as faixas IP New Relic para integração na nuvem, consulte [este documento](/docs/new-relic-solutions/get-started/networks/#webhooks). Para obter instruções sobre como executar esta tarefa, consulte [este documento](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html).
</Callout>

## Configuração e polling [#polling]

Informações de pesquisa padrão para a integração do Confluent Cloud Kafka:

* Intervalo de sondagem New Relic : 5 minutos
* Intervalo de dados da Confluent Cloud: 1 minuto

Você pode alterar a frequência de pesquisa somente durante a configuração inicial.

## Visualizar e usar dados [#find-data]

Você pode [consultar e explorar seus dados](/docs/using-new-relic/data/understand-data/query-new-relic-data) usando o seguinte [tipo de evento](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels):

<table>
  <thead>
    <tr>
      <th>
        Entidade
      </th>

      <th>
        Tipo de dados
      </th>

      <th>
        Fornecedor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Cluster
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

Para saber mais sobre como usar seus dados, consulte [Compreender e usar dados de integração](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Dados métricos [#metrics]

Esta integração registra dados do Amazon Managed Kafka para cluster, partição e entidade de tópico.

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Uma medida da utilização do cluster. O valor está entre 0,0 e 1,0. Apenas o cluster de nível dedicado possui esses dados métricos.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Um indicador da presença de uma partição quente causada por taxas de transferência de ingresso. O valor é 1,0 quando uma partição ativa é detectada e vazio quando nenhuma partição ativa é detectada.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Um indicador da presença de uma partição quente causada por taxas de transferência de egresso. O valor é 1,0 quando uma partição ativa é detectada e vazio quando nenhuma partição ativa é detectada.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta do total de bytes de solicitação dos tipos de solicitação especificados enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta do total de bytes de resposta dos tipos de resposta especificados enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta de bytes dos dados dos clientes recebidos da rede. Cada amostra é o número de bytes recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        A contagem delta de bytes dos dados dos clientes enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de registros recebidos. Cada amostra é o número de registros recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de registros enviados. Cada amostra é o número de registros enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        O número de partições.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        O atraso entre o deslocamento confirmado de um membro do grupo e o limite máximo da partição.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem delta de autenticações bem-sucedidas. Cada amostra é o número de autenticações bem-sucedidas desde o ponto de dados anterior. A contagem amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        A contagem de conexões autenticadas ativas.
      </td>
    </tr>
  </tbody>
</table>

## Qual é o próximo

<DocTiles>
  <DocTile title="Data and UI" path="/docs/message-queues-streaming/ui-data/understand-ui">Aprenda a usar New Relic para monitorar seu cluster Kafka</DocTile>
</DocTiles>