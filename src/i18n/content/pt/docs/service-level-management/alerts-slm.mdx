---
title: Alerta sobre nível de serviço
tags:
  - Service Level Management
  - SLI/SLO
metaDescription: 'With New Relic, you can alert on SLI/SLOs.'
freshnessValidatedDate: never
translationType: machine
---

Um dos resultados prometidos da implementação do nível de serviço é que você será capaz de ajustar sua política de alertas e reduzir as notificações aos problemas que realmente estão prejudicando a experiência do cliente e representam um risco para o seu negócio.

Ao definir objetivos de nível de serviço, você pode configurar <InlinePopover type="alerts"/>que irá informá-lo em caso de esgotamento do seu orçamento de erro antes do final do período de conformidade. Esses alertas mostrarão quando ocorrer um incidente de alto impacto nos negócios. Quando acionados, eles devem ter prioridade e você deve envolver as equipes relevantes para começar a diagnosticar a origem do problema.

## Alerta sobre erro na taxa de consumo de orçamento [#alert-error-budget]

A ideia por trás do alerta de taxa de consumo é que o orçamento de erros represente quantos eventos ruins você pode suportar durante o período do SLO; por definição, se você gastar todo o seu orçamento de erros a uma taxa constante, sua taxa de consumo = 1. Então, qualquer taxa de consumo acima da taxa de consumo tolerável não seria sustentável porque você teria queimado completamente o orçamento de erros antes do final do período do SLO; portanto, você pode querer receber um alerta se esse for o caso por um longo período de tempo.

### Criar alerta sobre erro na taxa de consumo do orçamento [#create-alert-error-budget]

Você encontrará a opção de criar alertas nas páginas de resumo do nível de serviço e condição do alerta.

<img
  title="Alerts CTA"
  alt="Create Alerts"
  src="/images/slm_screenshot-full_alerts-cta.webp"
/>

<figcaption>
  Vá para <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Service Levels > Choose a service level**</DNT> e clique em <DNT>**Alert conditions**</DNT> na opção <DNT>**Settings**</DNT> .
</figcaption>

Ao clicar nele, um painel lateral será aberto e você verá a opção de alertar sobre a taxa de gravação rápida no topo da lista e a gravação lenta abaixo dela.

<img
  title="Alerts Recommended Options Fast Burn"
  alt="Alerts Recommended Options Fast Burn"
  src="/images/slm_screenshot-crop_fast-burn.webp"
/>

<figcaption>
  Vá para <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Service Levels > Choose a service level**</DNT> e clique em <DNT>**Alert conditions**</DNT> na opção <DNT>**Settings**</DNT> . Clique no botão <DNT>**Alert**</DNT> para abrir o painel lateral.
</figcaption>

O alerta de consumo rápido segue a recomendação do Google para porcentagens de consumo de orçamento de SLO, especificamente para alertas de consumo rápido. Estes alertas irão alertá-lo sobre uma mudança repentina e significativa no consumo que, se não for corrigida, esgotará muito em breve o seu orçamento de erros. Definiremos um consumo de orçamento de SLO de 2% em 1 hora, o que significa que o serviço consumiria totalmente o orçamento de erro em 50 horas se não fosse alcançado.

<img
  title="Alerts Recommended Options Slow Burn"
  alt="Alerts Recommended Options Slow Burn"
  src="/images/slm_screenshot-crop_slow-burn.webp"
/>

<figcaption>
  Vá para <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Service Levels > Choose a service level**</DNT> e clique em <DNT>**Alert conditions**</DNT> na opção <DNT>**Settings**</DNT> . Clique no botão <DNT>**Alert**</DNT> para abrir o painel lateral.
</figcaption>

O alerta de consumo lento segue a recomendação do Google para porcentagens de consumo de orçamento do SLO, especificamente para alertas de consumo lento. Estes alertas irão avisá-lo de uma alteração no consumo que, se não for alterada, esgotará o seu orçamento de erro antes do final do período de cumprimento. Definiremos um consumo de orçamento de SLO de 5% em 6 horas, o que significa que o serviço consumiria totalmente o orçamento de erro em 5 dias se não fosse alcançado.

Você precisará selecionar uma política de alertas existente ou criar uma nova para continuar.

Alternativamente, você pode clicar em 'Personalizar' e definir seu próprio limite.

## Alerta sobre erro de consumo de orçamento [#alert-consumption]

Este alerta irá avisá-lo quando você consumir 80% do seu orçamento de erros do período.

Para configurá-lo, clique em <DNT>**Alert**</DNT> nas páginas de resumo do nível de serviço ou condição do alerta e selecione a opção <DNT>**Error budget consumption**</DNT> .

<img
  title="Alerts error budget.png"
  alt="Alerts Error Budget"
  src="/images/slm_screenshot-crop_alerts-error-budget.webp"
/>

<figcaption>
  Vá para <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Service Levels > Choose a service level**</DNT> e clique em <DNT>**Alert conditions**</DNT> na opção <DNT>**Settings**</DNT> . Clique no botão <DNT>**Alert**</DNT> para abrir o painel lateral.
</figcaption>

Você precisará selecionar uma política de alertas existente ou criar uma nova para continuar.

Se quiser definir um limite diferente, clique em <DNT>**Customize**</DNT> e siga as etapas no cartão de configuração de alerta.

## Alertas sobre conformidade com SLO

Se desejar configurar um alerta para quando seu SLO ficar abaixo do destino por um longo período, selecione a opção <DNT>**SLO compliance**</DNT> .

Se o seu SLI for volátil, esse tipo de alerta poderá ter baixa precisão. Portanto, você deve usar um alerta de taxa de queima para mitigá-lo.

## Configurando seu próprio limite de taxa de consumo de orçamento de erros

Se não quiser seguir a recomendação do Google para alerta rápido, você pode configurar seu próprio limite.

### Defina seu limite de condição [#condition-thresholds]

A taxa de consumo do orçamento de erros indica a rapidez com que o serviço consome o orçamento de erros, levando em consideração todo o período do SLO. Aqui está uma fórmula para calculá-lo:

```sql
critical burn rate = (tolerated budget consumption * SLO period [h]) / (evaluation period [h])
```

* Consumo de orçamento tolerado: quanto orçamento você tolera consumir no período de avaliação.
* Período do SLO: janela de tempo do seu SLO (geralmente, em horas).
* Período de avaliação: janela de agregação que estamos levando em consideração (você pode usar 1 hora na janela de agregação da condição do alerta para simplificar).

Porém, considerando que a taxa de erros máxima que pode ocorrer é de 100%, significa que também existe uma taxa de queima máxima e, portanto, a taxa de queima crítica deve estar na faixa de:

```sql
0 < critical burn rate < maximum burn rate
```

Onde o valor máximo da taxa de queima é calculado da seguinte forma:

```sql
maximum burn rate = 1 / (1 - SLO target)
```

Finalmente, para definir seu limite de alerta, você multiplicará a taxa de queima crítica por hora pelo orçamento de erros:

```sql
threshold = error budget * critical burn rate
```

#### Exemplo [#condition-thresholds-example]

Vamos ver como isso funciona com um exemplo de um SLO <DNT>**28 day**</DNT> com um destino <DNT>**99.9%**</DNT> .

Para um SLO de 28 dias, o Google recomenda alertas sobre um <DNT>**2%**</DNT> consumo de orçamento do SLO <DNT>**in the last hour**</DNT>. Isso significa que se você continuar gastando o orçamento na mesma proporção, violará seu SLO em 50 horas (resultante de `100% / 2%`).

Então temos as seguintes variáveis:

* Destino do SLO: `99.9%`
* Período do SLO: `28 days (28 * 24 hours)`
* Consumo orçamentário tolerado: `2% (0.02)`
* Periodo de avaliação: `1 hour`

Portanto:

```sql
critical burn rate per hour = (0.02 * 28 * 24) / 1 = 13.44
```

Onde o valor máximo possível da taxa de queima para o SLO é:

```sql
maximum burn rate = 1 / (1 - 0.999) = 1000
```

E finalmente:

```sql
threshold = 0.1 * 13.44 = 1.344
```

Este seria um valor que você usaria como limite de condição do alerta: Abra um incidente quando a consulta retornar um valor acima do limite (neste exemplo, 1,344), pelo menos uma vez no período de avaliação (neste exemplo, 60 minutos). ).

<img
  title="Alerts threshold.png"
  alt="Alerts threshold configuration"
  src="/images/alerts_screenshot-full_condition-thresholds-slm.webp"
/>

<Callout variant="important">
  Se você editar o destino do SLO no lado do nível de serviço, lembre-se de editar também o destino na condição do alerta.
</Callout>

### Configurações [#extra-settings]

É importante ajustar o parâmetro adicional desta condição do alerta.

Defina a duração da janela para o período de avaliação. Seguindo o exemplo anterior, você definiria <DNT>**60 minutes**</DNT>, o que significa que o sistema de alerta agregaria 60 minutos de dados.

<Callout variant="important">
  O período de avaliação suporta a agregação de até 2 horas de dados.
</Callout>

Você pode usar um slide <DNT>**60 seconds**</DNT> por intervalo, para que a cada minuto o New Relic avalie os 60 minutos anteriores de dados.

<img
  title="Alerts evaluation period"
  alt="Alerts evaluation period"
  src="/images/alerts_screenshot-crop_advanced-signal-settings-slm.webp"
/>

A seguir, conecte a condição à política que determina como as notificações são gerenciadas.

Por último, você pode escolher quando fechar automaticamente qualquer incidente aberto.

## Entenda o nível de serviço padrão política de alertas [#alert-policy]

O nível de serviço default política de alertas foi introduzido, ao nível da conta, para que o nível de serviço status de saúde se baseie no seu orçamento de erro restante. Isso melhora sua experiência ao usar outros produtos New Relic, como New Relic Navigator e Workload.

<img
  title="SLM Alert policy"
  alt="SLM Alert policy"
  src="/images/slm-alert-policy.webp"
/>

Esta política de alertas não irá acionar nenhuma notificação, e caso você prefira não ter a saúde da entidade com base no seu consumo de orçamento de erros, você pode facilmente excluir esta política. Embora a exclusão da política seja permanente e afetará o nível de serviço existente e novo para essa conta.

<img
  title="SLs without health"
  alt="SLs without health"
  src="/images/slm-missinghealth.webp"
/>
