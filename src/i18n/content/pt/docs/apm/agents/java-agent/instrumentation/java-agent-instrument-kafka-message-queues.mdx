---
title: 'Agente Java: instrumento Kafka fila de mensagens'
tags:
  - Agents
  - Java agent
  - Instrumentation
metaDescription: 'New Relic for Java includes built-in Kafka monitoring, as well as advanced event and distributed tracing data collection.'
freshnessValidatedDate: never
translationType: machine
---

O agente Java da New Relic coleta automaticamente dados da biblioteca de clientes Java do [Kafka](https://kafka.apache.org/documentation/). Como o Kafka é um sistema de mensagens de alto desempenho que gera muitos dados, você pode personalizar o agente para as taxas de transferência e casos de uso específicos do seu aplicativo.

Este documento explica como coletar e visualizar esses tipos de dados do Kafka:

* [Métrica Kafka](#view-kafka-metrics)
* [Evento Kafka](#collect-kafka-events)
* [Transações do Kafka Streams](#collect-kafka-streams-transactions)
* [Rastreamento distribuído Kafka](#collect-kafka-distributed-traces)

<Callout variant="tip">
  Também temos uma integração Kafka. Para obter detalhes sobre isso, consulte [integração de monitoramento Kafka](/docs/integrations/host-integrations/host-integrations-list/kafka-monitoring-integration).
</Callout>

## Requisitos [#requirements]

A instrumentação de clientes Kafka está disponível nas versões 4.12.0 ou superior do agente Java. A instrumentação de fluxos Kafka está disponível no agente Java versões 8.1.0 ou mais alto. Para ver todas as bibliotecas Kafka suportadas, verifique a [página de compatibilidade e requisitos do Java](/docs/agents/java-agent/getting-started/compatibility-requirements-java-agent). Observe que o Kafka Streams é executado em clientes Kafka, portanto, toda a instrumentação que se aplica aos clientes Kafka também se aplica ao Streams.

## Ver métrica Kafka

Após [a instalação](/docs/agents/java-agent/installation/install-java-agent), o agente Java reporta automaticamente a métrica Kafka rica com informações sobre taxas de mensagens, latência, lag e muito mais. O agente coleta todas [as métricas de consumidor e produtor do Kafka](https://kafka.apache.org/documentation/#monitoring) (mas não as métricas de conexão ou fluxo).

Para visualizar essas métricas, crie um dashboard personalizado:

1. Vá para o [explorador métrico New Relic](/docs/insights/use-insights-ui/explore-data/metric-explorer-search-chart-metrics-sent-new-relic-agents).

2. Use o explorador métrico para localizar sua métrica. Aqui estão algumas pastas onde você pode encontrar métricas:

   * Métrica Kafka:

     ```
     MessageBroker/Kafka/Internal/KafkaMetricName
     ```

     Por exemplo, métrica `request-rate` :

     ```
     MessageBroker/Kafka/Internal/consumer-metrics/request-rate
     ```

   * Fluxos Kafka:

     ```
     Kafka/Streams/KafkaStreamsMetricName
     ```

     Por exemplo, métrica `poll-latency-avg` :

     ```
     Kafka/Streams/stream-thread-metrics/poll-latency-avg
     ```

   * Conexão Kafka:

     ```
     Kafka/Connect/KafkaConnectMetricName
     ```

     Por exemplo, métrica `connector-count` :

     ```
     Kafka/Connect/connect-worker-metrics/connector-count
     ```

3. Adicione a métrica que deseja monitor a um dashboard clicando em <DNT>**Add to dashboard**</DNT>.

<Callout variant="tip">
  Para obter uma lista completa das métricas de consumo, produtor e fluxos do Kafka, consulte a [documentação do Kafka](https://kafka.apache.org/documentation/#remote_jmx). As métricas nesses documentos podem ser pesquisadas via JMX. Lembre-se de que nem todas as métricas mencionadas na documentação serão exportadas para o New Relic. Isso pode ser devido a um destes motivos:

  * Na verdade, a métrica não é gerada por clientes Kafka ou Kafka Streams. Isso pode ser devido ao uso de uma versão mais antiga de clientes ou Streams ou com base em como você configurou e usa sua biblioteca Kafka.
  * A métrica não é numérica ou seu valor é `NaN`. New Relic só aceita métricas com valor numérico.
</Callout>

## Ver coleção de eventos Kafka [#collect-kafka-events]

Você pode configurar o agente para coletar dados de evento em vez de dados de métrica de fração de tempo (para saber a diferença entre métrica de fração de tempo e dados de evento, consulte [coleta de dados](/docs/using-new-relic/metrics/analyze-your-metrics/data-collection-metric-timeslice-event-data#overview)). Isso permite que você use [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) para filtrar e facetar a métrica Kafka padrão. Quando ativado, o agente coleta um evento Kafka a cada 30 segundos. Este evento contém todos os dados do [consumidor Kafka e métricas de produção](https://kafka.apache.org/documentation/#monitoring) capturadas desde o evento anterior.

Se você estiver usando Kafka Streams, o agente gera um evento separado que contém todos os dados [da métrica do fluxo Kafka](https://kafka.apache.org/documentation/#remote_jmx) capturados desde o evento anterior. O evento também é coletado a cada 30 segundos.

<Callout variant="important">
  O agente registra até 2.000 eventos por [ciclo de colheita](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#harvest-cycle), embora você possa alterar esse valor com [`max_samples_stored`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored). Os dados do evento Kafka estão incluídos neste pool. Se você usar a chamada de API `recordCustomEvent()` para enviar [evento personalizado](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents) para New Relic e enviar mais de 2.000 eventos, o agente descartará algum Kafka ou evento personalizado.
</Callout>

Para ativar a coleta de eventos Kafka:

1. Adicione o elemento `kafka.metrics.as_events.enabled` ao arquivo de configuração `newrelic.yml` :

   ```yml
   kafka.metrics.as_events.enabled: true
   ```

2. Reinicie sua JVM.

3. Use o [explorador de eventos](/docs/insights/use-insights-ui/explore-data/event-explorer-query-chart-your-event-data) para visualizar seus eventos Kafka, localizados no tipo de evento `KafkaMetrics` . Ou use [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) para consultar seu evento diretamente. Por exemplo:

   ```sql
   SELECT average('producer-metrics.record-send-rate') FROM KafkaMetrics SINCE 30 minutes ago TIMESERIES
   ```

   Se você estiver consultando a métrica do Kafka Streams, use o tipo de evento `KafkaStreamsMetrics` para acessar a métrica específica do stream.

<Callout variant="important">
  Lembre-se de que as limitações sobre o tipo de métrica Kafka que você pode enviar para o New Relic como métrica de intervalo de tempo também se aplicam a evento. Ou seja, métricas não numéricas e NaN não são incluídas como atributo do evento.
</Callout>

## Habilitar métrica do nó Kafka [#kafka-node-metrics]

<Callout variant="important">
  A instrumentação métrica do Node Clientes Kafka pode não carregar para o usuário da biblioteca `kafka-clients` versões 3.7.0-3.8.x e agente Java versões 8.15.0-8.17.0.

  Para habilitar o Kafka Clients Node métrica para `kafka-clients` 3.7.0-3.8.x, atualize seu agente Java para a versão 8.18.0 ou superior.
</Callout>

Existe um módulo de instrumentação alternativo para clientes Kafka que fornecerá mais granularidade para a métrica Kafka. Este módulo de instrumentação está disponível desde o agente 8.6.0 e está desabilitado por padrão.

Para ativar este módulo de instrumentação, você deve desativar o módulo de instrumentação existente e ativar o novo adicionando o seguinte ao seu arquivo de configuração `newrelic.yml` :

```yml
class_transformer:
  kafka-clients-metrics:
    enabled: false
  kafka-clients-node-metrics:
    enabled: true
```

## Evento de configuração do Kafka [#kafka-config]

O módulo de instrumentação `kafka-clients-config` enviará periodicamente eventos com o conteúdo da configuração do cliente Kafka. Este módulo está disponível desde o agente 8.6.0 e está desabilitado por padrão.

Para ativar `kafka-clients-config` adicione o seguinte ao arquivo de configuração `newrelic.yml` :

```yml
class_transformer:
  kafka-clients-config:
    enabled: true
```

## Transações do Kafka Streams [#collect-kafka-streams-transactions]

Se você estiver usando Kafka Streams, por padrão não habilitamos a transação. Isso evita despesas desnecessárias porque os aplicativos Kafka tendem a ter altas taxas de transferência.

Ao contrário do JMS transação, os Kafka Streams transação não são processados por registro. Em vez disso, uma transação começa quando um consumidor Kafka pesquisa os registros e então os dados resultantes são processados.

Se você deseja criar transações, você precisa ativar um módulo `kafka-streams-spans` :

```yml
class_transformer:
  kafka-streams-spans:
    enabled: true
```

## Habilitar transação Kafka Connect [#collect-kafka-connect-transactions]

Se você estiver usando o Kafka Connect, por padrão não habilitamos a transação. Isso evita despesas desnecessárias porque os aplicativos Kafka tendem a ter altas taxas de transferência.

As transações do Kafka Connect são registradas para cada iteração da tarefa sink/source. Para uma tarefa de coletor, uma transação consiste em sondar um consumidor Kafka, converter cada mensagem e enviar dados ao destino. Para uma tarefa de origem, uma transação consiste na leitura do destino, convertendo os dados em mensagens e enviando cada mensagem a um produtor Kafka.

Se você deseja coletar essas transações, você precisa ativar um módulo `kafka-connect-spans` :

```yml
class_transformer:
  kafka-connect-spans:
    enabled: true
```

## Rastreamento distribuído Kafka [#collect-kafka-distributed-traces]

O agente Java também pode coletar [rastreamento distribuído](/docs/apm/distributed-tracing/getting-started/introduction-distributed-tracing) de clientes Kafka. Como o Kafka Streams é executado em clientes Kafka, as etapas para gerenciar distributed tracing também se aplicam. A ativação do rastreamento não afeta as operações normais do agente; ele ainda reportará dados métricos ou de eventos do Kafka.

Impactos e requisitos a considerar antes de permitir:

* <DNT>**The instrumentation adds a 150 to 200 byte payload to message headers.**</DNT> Se suas mensagens Kafka forem muito pequenas, o rastreamento poderá adicionar sobrecarga significativa de processamento e armazenamento. Esse tamanho de carga útil adicional pode fazer com que o Kafka descarte mensagens se elas excederem o limite de tamanho de mensagens do Kafka. Por esse motivo, recomendamos testar o rastreamento distribuído do Kafka em um ambiente de desenvolvimento antes de habilitá-lo na produção.
* Distributed tracing está disponível apenas para o cliente Kafka versões 0.11.0.0 ou superior.
* Se você ainda **não** habilitou distributed tracing para seu aplicativo, leia o [guia de transição](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing) antes de habilitá-lo.
* Para propagar W3C Trace Context por meio de cabeçalhos de mensagens Kafka, consulte o [distributed tracing API guia de uso](/docs/agents/java-agent/api-guides/guide-using-java-agent-api#trace-calls) para obter detalhes sobre APIs que foram lançadas no agente Java 6.4.0. Observe que adicionar cabeçalhos adicionais às mensagens Kafka aumentará ainda mais o tamanho da carga útil. Para ver essas API em ação,[consulte Usando do agente Java trace API com Kafka](https://github.com/newrelic/newrelic-java-examples/tree/main/newrelic-java-agent/distributed-tracing/kafka-examples).
* Se estiver usando o Kafka Streams, você precisará habilitar um módulo de instrumentação de span (consulte a [seção de transação do Kafka Streams](#collect-kafka-streams-transactions)). Como uma transação não é registrada por registro, a aceitação de cabeçalhos distributed trace funcionará apenas para um registro.

O processo completo para habilitar isso é descrito abaixo, mas em alto nível envolve estas etapas básicas: 1) habilitar o rastreamento por meio da configuração do agente e 2) chamar a [API do agente Java](/docs/agents/java-agent/api-guides/guide-using-java-agent-api) para o instrumento de transação tanto do lado do produtor quanto do consumidor.

Para coletar rastreamento distribuído do Kafka:

<CollapserGroup>
  <Collapser id="enable-dt-kafka" title="1. Habilite distributed tracing no arquivo de configuração">
    Se você ainda não habilitou distributed tracing para seu aplicativo, leia o [guia de transição distributed tracing ](/docs/apm/distributed-tracing/getting-started/transition-guide-distributed-tracing)antes de habilitá-lo.

    Para ativar o rastreamento distribuído do Kafka, essas duas configurações devem ser ativadas no [arquivo de configuração`newrelic.yml` ](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Structure):

    * Certifique-se de que o elemento [`distributed_tracing`](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#distributed-tracing) esteja ativado:

      ```yml
      distributed_tracing:
        enabled: true
      ```

    * Habilite o recurso distributed tracing específico do Kafka adicionando o seguinte ao seu arquivo de configuração:

      ```yml
      class_transformer:
        com.newrelic.instrumentation.kafka-clients-spans-0.11.0.0:
          enabled: true
      ```

    * Habilitar instrumentação spring-kafka para versões de agente `8.21` e superiores.

      <Callout variant="important">
        Isso pode causar um pico na ingestão e no uso de memória, por isso é desabilitado
      </Callout>

      ```yml
      class_transformer:
        com.newrelic.instrumentation.spring-kafka-2.2.0:
          enabled: true
      ```

    * Habilitar distributed tracing para chamadas em lote do Kafka para versões do agente `8.21` e superiores. (O rastreamento distribuído de chamadas em lote é desabilitado por padrão, pois as transações só podem aceitar 1 trace pai de uma mensagem):

      ```yml
      kafka:
        spans:
          distributed_trace: 
            consume_many:
              enabled: true
      ```
  </Collapser>

  <Collapser id="instrument-kafka-producer" title="2. instrumento do produtor Kafka">
    Para instrumentar seu produtor Kafka, você precisará iniciar uma transação antes de qualquer chamada para `Producer.send(ProducerRecord<K, V> record)`. Para fazer isso, adicione a anotação do agente Java `@Trace(dispatcher = true)` ao método.

    Por exemplo:

    ```java
    @Trace(dispatcher = true)
    public static void createAndSend(KafkaProducer<String, String> producer){
      ProducerRecord<String, String> data = new ProducerRecord<String, String>("topic", "key", "value");
      producer.send(data);
    }
    ```

    <Callout variant="important">
      Se estiver usando Kafka Streams, você não precisa iniciar uma transação diretamente ou enviar dados a um produtor.
    </Callout>
  </Collapser>

  <Collapser id="instrument-kafka-consumer" title="3. Instrumento do consumidor Kafka">
    ### Cenário 1: Usando instrumentação manual com o Kafka Client

    Para instrumentar seu consumidor Kafka por meio de instalação manual, você precisará iniciar uma transação quando a mensagem estiver sendo processada. O agente armazena o cabeçalho de carga distributed tracing na chave `newrelic` ou nas chaves `traceparent` e `tracestate` do W3C. Recupere o cabeçalho e chame New Relic API a de transação para aceitar a carga.

    Por exemplo:

    ```java
    @Trace(dispatcher = true)
    private static void processMessage(ConsumerRecord<String, String> rec) {
      // create a distributed trace headers map
      Headers dtHeaders = ConcurrentHashMapHeaders.build(HeaderType.MESSAGE);

      // Iterate through each record header and insert the trace headers into the dtHeaders map
      for (Header header : rec.headers()) {
        String headerValue = new String(header.value(), StandardCharsets.UTF_8);

        // using the newrelic key
        if (header.key().equals("newrelic")) {
          dtHeaders.addHeader("newrelic", headerValue);
        }

        // or using the W3C keys
        if (header.key().equals("traceparent")) {
          dtHeaders.addHeader("traceparent", headerValue);
        }

        if (header.key().equals("tracestate")) {
          dtHeaders.addHeader("tracestate", headerValue);
        }
      }

      // Accept distributed tracing headers to link this request to the originating request
      NewRelic.getAgent().getTransaction().acceptDistributedTraceHeaders(TransportType.Kafka, dtHeaders);
    }
    ```

    ### Cenário 2: Usando instrumentação automática para clientes Kafka

    Isso só se aplicará às versões do agente `8.21` e superiores. Você também pode aproveitar a instrumentação automática para ler distributed tracing para o consumidor kafka. Isso é feito iniciando uma transação e chamando o método `poll(...)` de um consumidor quando a transação está acontecendo.

    Isso é desabilitado por padrão porque a pesquisa do consumidor aceita, por padrão, várias mensagens e as transações podem ter apenas um trace pai, então apenas uma mensagem será lida.

    Para habilitar a aceitação automática de rastreamento distribuído para pesquisas de consumidores do Kafka, você precisa habilitar distributed tracing para chamadas em lote, conforme mostrado na etapa 1.

    Exemplo de pesquisas de consumidores instrumentado kafka:

    ```java
    @Trace(dispatcher = true)
    private void consumeMessage(KafkaConsumer<String, String> consumer) {
      final ConsumerRecords<String, String> records = consumer.poll(1000);
      // Process your records ....
    }
    ```

    ### Cenário 3: Usando Spring Kafka

    Se estiver usando o Spring Kafka, você pode habilitar a instrumentação automática para métodos instrumentados com `@KafkaListener` se estiver usando o agente nas versões `8.21.0` e superiores. Isso cria transações e aceita automaticamente o rastreamento distribuído para o consumidor. Como o Kafka é uma plataforma com altas taxas de download, ele é desabilitado para evitar muita ingestão e sobrecarga de memória. Você pode habilitar a instrumentação do spring-kafka com a configuração mostrada na etapa 1.

    Exemplo:

    ```java
    @KafkaListener(id = "foo", topics = "myTopic", clientIdPrefix = "myClientId")
    public void listen(String data) {
      ...
    }
    ```

    <Callout variant="important">
      Se você habilitou transações com Kafka Streams (consulte a [seção transação do Kafka Streams](#collect-kafka-streams-transactions)), mesmo que uma transação se aplique a muitos registros, a aceitação de cabeçalhos distributed trace se aplicará apenas a um registro.
    </Callout>
  </Collapser>
</CollapserGroup>