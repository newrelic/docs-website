---
title: Configuração do gerenciador de tarefas Sintético
tags:
  - synthetics
  - Synthetic monitoring
  - Private locations
metaDescription: Customize your New Relic synthetics job manager.
freshnessValidatedDate: '2024-07-29T00:00:00.000Z'
translationType: machine
---

Este documento irá guiá-lo na configuração do seu [gerenciador de tarefas Sintético](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager) , mostrando como:

* Use [variáveis de ambiente](#environment-variables) para configurar seu gerenciador de tarefas Sintético.
* Configure [módulos personalizados](#custom-modules) para [API com script](/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/) ou monitor [de navegador com script](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) .
* Forneça [variáveis definidas pelo usuário](#user-defined-vars) em sua configuração.

## Configuração usando variáveis de ambiente [#environment-variables]

As variáveis ambientais permitem ajustar a configuração do gerenciador de tarefas Sintético para atender às suas necessidades ambientais e funcionais específicas.

<CollapserGroup>
  <Collapser id="docker-env-config" title="Configuração do ambiente Docker">
    As variáveis são fornecidas na inicialização usando o argumento `-e, --env` .

    A tabela a seguir mostra todas as variáveis de ambiente suportadas pelo gerenciador de tarefas Sintético. `PRIVATE_LOCATION_KEY` é obrigatório e todas as outras variáveis são opcionais.

    <table>
      <thead>
        <tr>
          <th>
            Nome
          </th>

          <th>
            Descrição
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DNT>**Required.**</DNT> chave de localização privada, conforme encontrada na lista entidade privada de localização.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_API_VERSION`
          </td>

          <td>
            Formato: `"vX.Y"` versão da API a ser usada com o serviço Docker fornecido.

            Padrão: `v1.35.`
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_HOST`
          </td>

          <td>
            Aponta o gerenciador de tarefas Sintético para um determinado `DOCKER_HOST`. Se ausente, o valor padrão é `/var/run/docker.sock.`
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            Para contas baseadas nos EUA, o endpoint é: `https://synthetics-horde.nr-data.net.`

            Para contas [baseadas na UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , o endpoint é: `https://synthetics-horde.eu01.nr-data.net/`

            Certifique-se de que seu gerenciador de tarefas Sintético possa se conectar ao endpoint apropriado para atender seu monitor.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            O domínio Docker Registry onde as imagens de tempo de execução estão hospedadas. Use isto para substituir `docker.io` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            O docker repositório ou organização onde as imagens de tempo de execução estão hospedadas. Use isto para substituir `newrelic` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Host do servidor proxy usado para comunicação da Horda. Formato: `"localhost"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Porta do servidor proxy usada para comunicação da Horda. Formato: `8888`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Nome de usuário do servidor proxy usado para comunicação da Horda. Formato: `"username"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Senha do servidor proxy usada para comunicação da Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            Aceita certificados proxy autoassinados para a conexão do servidor proxy usada para comunicação do Horde? Valores aceitáveis: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            A quantidade máxima de segundos que as verificações do seu monitor podem ser executadas. Este valor deve ser um número inteiro entre 0 segundos (excluído) e 900 segundos (incluído) (por exemplo, de 1 segundo a 15 minutos).

            Padrão: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            Padrão: `INFO.`

            Opções adicionais: `WARN`, `ERROR`, `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            O número de trabalhos pesados simultâneos (navegador/navegador com script e API com script) que podem ser executados ao mesmo tempo.

            Padrão: CPUs disponíveis - 1.
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            Uma matriz que pode ser usada para executar imagens de tempo de execução específicas. Formato: \[&apos;newrelic/Sintético-ping-runtime:latest&apos;,&apos;newrelic/Sintético-node-API-runtime:latest&apos;,&apos;newrelic/Sintético-node-navegador-runtime:latest&apos;]

            Padrão: todos os tempos de execução mais recentes.
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            Se definido, ativa <DNT>**verified script execution**</DNT> e usa esse valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            Um conjunto hospedado localmente de pares de valores principais definidos pelo usuário.
          </td>
        </tr>

        <tr>
          <td>
            `ENABLE_WASM`
          </td>

          <td>
            Se definido, habilita o webassembly para o tempo de execução do navegador do nó. Para usar o webassembly, a versão mínima do seu gerenciador de tarefas Sintético deve ser release-367 ou superior e a versão do tempo de execução do navegador do nó deve ser 2.3.21 ou superior.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="podman-env-config" title="Configuração do ambiente Podman">
    As variáveis são fornecidas na inicialização usando o argumento `-e, --env` .

    A tabela a seguir exibe todas as variáveis de ambiente que o gerenciador de tarefas Sintéticos suporta. `PRIVATE_LOCATION_KEY` é obrigatório e todas as outras variáveis são opcionais. Para executar o gerenciador de tarefas Sintéticos em um ambiente Podman, a versão mínima deve ser release-418 ou superior.

    <table>
      <thead>
        <tr>
          <th>
            Nome
          </th>

          <th>
            Descrição
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DNT>**Required.**</DNT> chave de localização privada, conforme encontrada na lista entidade privada de localização.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            Para contas baseadas nos EUA, o endpoint é: `https://synthetics-horde.nr-data.net.`

            Para contas [baseadas na UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , o endpoint é: `https://synthetics-horde.eu01.nr-data.net/`

            Certifique-se de que seu gerenciador de tarefas Sintético possa se conectar ao endpoint apropriado para atender seu monitor.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_SERVICE_HOST`
          </td>

          <td>
            A entrada do host adicionada ao pod criado onde o SJM será executado. Use isto para substituir `podman.service` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_SERVICE_PORT`
          </td>

          <td>
            A porta na qual o serviço Podman LibPod RESTful API está sendo executado na instância. Use isto para substituir `8000` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_VERSION`
          </td>

          <td>
            A versão específica da API RESTful do Podman LibPod que está sendo usada. Use isto para substituir `v5.0.0` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_POD_NAME`
          </td>

          <td>
            O nome do pod no qual o contêiner SJM é executado. Use isto para substituir `SYNTHETICS` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            O domínio Docker Registry onde as imagens de tempo de execução estão hospedadas. Use isto para substituir `docker.io` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            O docker repositório ou organização onde as imagens de tempo de execução estão hospedadas. Use isto para substituir `newrelic` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Host do servidor proxy usado para comunicação da Horda. Formato: `"localhost"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Porta do servidor proxy usada para comunicação da Horda. Formato: `8888`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Nome de usuário do servidor proxy usado para comunicação da Horda. Formato: `"username"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Senha do servidor proxy usada para comunicação da Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            Aceita certificados proxy autoassinados para a conexão do servidor proxy usada para comunicação do Horde? Valores aceitáveis: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            A quantidade máxima de segundos que as verificações do seu monitor podem ser executadas. Este valor deve ser um número inteiro entre 0 segundos (excluído) e 900 segundos (incluído) (por exemplo, de 1 segundo a 15 minutos).

            Padrão: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            Padrão: `INFO.`

            Opções adicionais: `WARN`, `ERROR`, `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            O número de trabalhos pesados simultâneos (navegador/navegador com script e API com script) que podem ser executados ao mesmo tempo.

            Padrão: CPUs disponíveis - 1.
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            Uma matriz que pode ser usada para executar imagens de tempo de execução específicas. Formato: \[&apos;newrelic/Sintético-ping-runtime:latest&apos;,&apos;newrelic/Sintético-node-API-runtime:latest&apos;,&apos;newrelic/Sintético-node-navegador-runtime:latest&apos;]

            Padrão: todos os tempos de execução mais recentes.
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            Se definido, ativa <DNT>**verified script execution**</DNT> e usa esse valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            Um conjunto hospedado localmente de pares de valores principais definidos pelo usuário.
          </td>
        </tr>

        <tr>
          <td>
            `ENABLE_WASM`
          </td>

          <td>
            Se definido, habilita o webassembly para o tempo de execução do navegador do nó. Para usar o webassembly, a versão mínima do seu gerenciador de tarefas Sintético deve ser release-367 ou superior e a versão do tempo de execução do navegador do nó deve ser 2.3.21 ou superior.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="kubernetes-env-config" title="Configuração do ambiente Kubernetes">
    As variáveis são fornecidas na inicialização usando o argumento `--set` .

    A lista a seguir mostra todas as variáveis de ambiente suportadas pelo gerenciador de tarefas Sintético. `synthetics.privateLocationKey` é obrigatório e todas as outras variáveis são opcionais.

    Uma série de configurações avançadas adicionais estão disponíveis e totalmente documentadas em [nosso README do gráfico do Helm](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)

    <table>
      <thead>
        <tr>
          <th>
            Nome
          </th>

          <th>
            Descrição
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DNT>**Required if `synthetics.privateLocationKeySecretName` is not set**</DNT>. [localização privada chave](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key) da localização privada, conforme encontrado na página localização privada.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.privateLocationKeySecretName`
          </td>

          <td>
            <DNT>**Required if `synthetics.privateLocationKey` is not set**</DNT>. Nome do segredo do Kubernetes que contém a chave `privateLocationKey`, que contém a chave de autenticação associada ao seu Sintético localização privada.
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            O nome do objeto secreto usado para extrair uma imagem de um registro de contêiner especificado.
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            Substituição de nome usada para sua implantação, substituindo o padrão.
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            Versão de lançamento do Sintético-job-manager para usar em vez da versão especificada em [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml).
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            Padrão: `INFO.`

            Opções adicionais: `WARN`, `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            Para contas baseadas nos EUA, o endpoint é: `https://synthetics-horde.nr-data.net.`

            Para contas [baseadas na UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , o endpoint é: `https://synthetics-horde.eu01.nr-data.net/`

            Certifique-se de que seu gerenciador de tarefas Sintético possa se conectar ao endpoint apropriado para atender seu monitor.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.minionDockerRunnerRegistryEndpoint`
          </td>

          <td>
            O registro e organização Docker onde a imagem do minion Runner está hospedada. Use isto para substituir `quay.io/newrelic` como padrão (por exemplo, `docker.io/newrelic`)
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            Se definido, ele ativa <DNT>**verified script execution**</DNT> e usa esse valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            Se definido, permite a execução verificada do script e usa esse valor para recuperar a senha de um segredo do Kubernetes com uma chave chamada `vsePassphrase`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.enableWasm`
          </td>

          <td>
            Se definido, habilita o webassembly para o tempo de execução do navegador do nó. Para usar o webassembly, a versão mínima do seu gerenciador de tarefas Sintético deve ser release-367 ou superior e a versão do tempo de execução do navegador do nó deve ser 2.3.21 ou superior.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Servidor proxy usado para comunicação da Horda. Formato: `"host"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Porta do servidor proxy usada para comunicação da Horda. Formato: `port`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Aceite certificados autoassinados ao usar um servidor proxy para comunicação do Horde. Valores aceitáveis: `true`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Nome de usuário do servidor proxy para comunicação da Horda. Formatar: `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Senha do servidor proxy para comunicação da Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            Uma string JSON de variáveis definidas pelo usuário. O usuário pode acessar essas variáveis em seu script. Formato: `'{"key":"value","key2":"value2"}'`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            Um caminho local para o usuário para um arquivo JSON contendo variáveis definidas pelo usuário. Isso é transmitido por meio de `--set-file` e não pode ser definido no arquivo Valores.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            Um caminho no PersistentVolume fornecido pelo usuário para o arquivo user\_defined\_variables.json. O usuário deverá fornecer um PersistentVolume ou PersistentVolumeClaim se esta variável for preenchida.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingClaimName`
          </td>

          <td>
            Se estiver montando um volume, o usuário poderá fornecer um nome para um PersistentVolumeClaim que já existe no cluster. Pressupõe a existência de um PersistentVolume correspondente.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingVolumeName`
          </td>

          <td>
            Se estiver montando um volume e não fornecer um PersistentVolumeClaim, o usuário deverá fornecer, no mínimo, um nome PersistentVolume. Helm irá gerar um PersistentVolumeClaim.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.storageClass`
          </td>

          <td>
            O nome do StorageClass para o PersistentVolumeClaim gerado. Isso deve corresponder ao StorageClassName no PV existente. Caso contrário, o Kubernetes usará a classe de armazenamento padrão, se presente.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.size`
          </td>

          <td>
            O tamanho do volume do PersistentVolumeClaim gerado. Formato: `10Gi`. 2Gi padrão.
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            A quantidade máxima de segundos que as verificações do seu monitor podem ser executadas. Este valor deve ser um número inteiro entre 0 segundos (excluído) e 900 segundos (incluído) (por exemplo, de 1 segundo a 15 minutos).

            Padrão: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            O contêiner a ser puxado.

            Padrão: `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            A política de puxar.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            Configure um contexto de segurança customizado para o pod Sintético-job-manager.
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução do ping persistente deve ou não ser implantado. Isso pode ser desativado se você não usar o monitor de ping.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            O número de contêineres de tempo de execução de ping a serem implantados. Aumente o replicaCount para dimensionar a implantação com base nas suas necessidades de monitoramento de ping.

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o tempo de execução do ping.

            Padrão: `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução de ping.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução da API Node.js deve ou não ser implantado. Isso pode ser desativado se você não usar o monitor de API com script.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            O número de ambientes de execução da API Node.js `CronJobs` a serem implantados. O número máximo de trabalhos simultâneos da API Node.js que serão executados a qualquer momento. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            O número de ambientes de execução da API Node.js `CronJobs` a serem concluídos por minuto. Aumentar esta configuração juntamente com o paralelismo para melhorar as taxas de transferência. Isto deve ser aumentado sempre que o paralelismo for aumentado e as conclusões devem sempre ser pelo menos maiores ou iguais ao paralelismo. . Aumente essa configuração se você observar períodos sem trabalhos de tempo de execução de API em execução. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o ambiente de execução da API Node.js.

            Padrão: `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução da API Node.js.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução do navegador Node.js deve ou não ser implantado. Isso pode ser desativado se você não usar o script com simples ou monitor do navegador.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            O número de tempos de execução do navegador Chrome `CronJobs` a serem implantados. O número máximo de jobs simultâneos do navegador Chrome que serão executados a qualquer momento. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            O número de tempos de execução do navegador Chrome `CronJobs` a serem concluídos por minuto. Aumentar esta configuração juntamente com o paralelismo para melhorar as taxas de transferência. Isto deve ser aumentado sempre que o paralelismo for aumentado e as conclusões devem sempre ser pelo menos maiores ou iguais ao paralelismo. Aumente essa configuração se você notar períodos de tempo sem tarefas de tempo de execução do navegador em execução. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o tempo de execução do navegador Node.js.

            Padrão: `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução do navegador Node.js.

            Padrão: `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="openshift-environment-config" title="Configuração do ambiente OpenShift">
    As variáveis são fornecidas na inicialização usando o argumento `--set` .

    A lista a seguir mostra todas as variáveis de ambiente suportadas pelo gerenciador de tarefas Sintético. `synthetics.privateLocationKey` é obrigatório e todas as outras variáveis são opcionais.

    Uma série de configurações avançadas adicionais estão disponíveis e totalmente documentadas em [nosso README do gráfico do Helm](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)

    <table>
      <thead>
        <tr>
          <th>
            Nome
          </th>

          <th>
            Descrição
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DNT>**Required**</DNT>. [localização privada key](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key), conforme encontrado na lista localização privada entidade.
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            O nome do objeto secreto usado para extrair uma imagem de um registro de contêiner especificado.
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            Substituição de nome usada para sua implantação, substituindo o padrão.
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            Versão de lançamento do Sintético-job-manager para usar em vez da versão especificada em [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml).
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            Padrão: `INFO.`

            Opções adicionais: `WARN`, `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            Para contas baseadas nos EUA, o endpoint é: `https://synthetics-horde.nr-data.net.`

            Para contas [baseadas na UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , o endpoint é: `https://synthetics-horde.eu01.nr-data.net/`

            Certifique-se de que seu gerenciador de tarefas Sintético possa se conectar ao endpoint apropriado para atender seu monitor.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            Se definido, ele ativa <DNT>**verified script execution**</DNT> e usa esse valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            Se definido, permite a execução verificada do script e usa esse valor para recuperar a senha de um segredo do Kubernetes com uma chave chamada `vsePassphrase`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.enableWasm`
          </td>

          <td>
            Se definido, habilita o webassembly para o tempo de execução do navegador do nó. Para usar o webassembly, a versão mínima do seu gerenciador de tarefas Sintético deve ser release-367 ou superior e a versão do tempo de execução do navegador do nó deve ser 2.3.21 ou superior.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Servidor proxy usado para comunicação da Horda. Formato: `"host"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Porta do servidor proxy usada para comunicação da Horda. Formato: `port`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Aceite certificados autoassinados ao usar um servidor proxy para comunicação do Horde. Valores aceitáveis: `true`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Nome de usuário do servidor proxy para comunicação da Horda. Formatar: `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Senha do servidor proxy para comunicação da Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            Uma string JSON de variáveis definidas pelo usuário. O usuário pode acessar essas variáveis em seu script. Formato: `'{"key":"value","key2":"value2"}'`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            Um caminho local para o usuário para um arquivo JSON contendo variáveis definidas pelo usuário. Isso é transmitido por meio de `--set-file` e não pode ser definido no arquivo Valores.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            Um caminho fornecido pelo usuário `PersistentVolume` para o arquivo` user_defined_variables.json` . O usuário deve fornecer `PersistentVolume` ou `PersistentVolumeClaim` se esta variável for preenchida.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.existingClaimName`
          </td>

          <td>
            Ao montar um volume, o usuário pode fornecer um nome para um `PersistentVolumeClaim` que já existe no cluster. Presume a existência de um `PersistentVolume` correspondente.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.existingVolumeName`
          </td>

          <td>
            Se estiver montando um volume e não fornecer um `PersistentVolumeClaim`, o usuário deverá fornecer no mínimo um nome `PersistentVolume` . O Helm irá gerar um `PersistentVolumeClaim`.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.storageClass`
          </td>

          <td>
            O nome do `StorageClass` para o `PersistentVolumeClaim` gerado. Isso deve corresponder ao `StorageClassName` no PV existente. Caso não haja provedores, **o Kubernetes** usará a classe de armazenamento padrão, se presente.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.size`
          </td>

          <td>
            O tamanho do volume para o `PersistentVolumeClaim` gerado. Formato: `10Gi`. Padrão `2Gi`.
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            A quantidade máxima de segundos que as verificações do seu monitor podem ser executadas. Este valor deve ser um número inteiro entre 0 segundos (excluído) e 900 segundos (incluído) (por exemplo, de 1 segundo a 15 minutos).

            Padrão: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            O contêiner a ser puxado.

            Padrão: `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            A política de puxar.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            Defina um contexto de segurança personalizado para o pod `synthetics-job-manager` .
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução do ping persistente deve ou não ser implantado. Isso pode ser desativado se você não usar o monitor de ping.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            O número de contêineres de tempo de execução de ping a serem implantados. Aumente o `replicaCount` para dimensionar a implantação com base nas suas necessidades de monitoramento de ping.

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o tempo de execução do ping.

            Padrão: `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução de ping.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução da API Node.js deve ou não ser implantado. Isso pode ser desativado se você não usar o monitor de API com script.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            O número de ambientes de execução da API Node.js `CronJobs` a serem implantados. O número máximo de trabalhos simultâneos da API Node.js que serão executados a qualquer momento. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            O número de ambientes de execução da API Node.js `CronJobs` a serem concluídos por minuto. Aumentar esta configuração juntamente com o paralelismo para melhorar as taxas de transferência. Isto deve ser aumentado sempre que o paralelismo for aumentado e as conclusões devem sempre ser pelo menos maiores ou iguais ao paralelismo. . Aumente essa configuração se você observar períodos sem trabalhos de tempo de execução de API em execução. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o ambiente de execução da API Node.js.

            Padrão: `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução da API Node.js.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução do navegador Node.js deve ou não ser implantado. Isso pode ser desativado se você não usar o script com simples ou monitor do navegador.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            O número de tempos de execução do navegador Chrome `CronJobs` a serem implantados. O número máximo de jobs simultâneos do navegador Chrome que serão executados a qualquer momento. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            O número de tempos de execução do navegador Chrome `CronJobs` a serem concluídos por minuto. Aumentar esta configuração juntamente com o paralelismo para melhorar as taxas de transferência. Isto deve ser aumentado sempre que o paralelismo for aumentado e as conclusões devem sempre ser pelo menos maiores ou iguais ao paralelismo. Aumente essa configuração se você notar períodos de tempo sem tarefas de tempo de execução do navegador em execução. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o tempo de execução do navegador Node.js.

            Padrão: `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução do navegador Node.js.

            Padrão: `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Variáveis definidas pelo usuário para monitor com script [#user-defined-vars]

Os gerenciadores de tarefas Private Sintético permitem configurar variáveis de ambiente para monitor com script. Essas variáveis são gerenciadas localmente no SJM e podem ser acessadas via `$env.USER_DEFINED_VARIABLES`. Você pode definir variáveis definidas pelo usuário de duas maneiras. Você pode montar um arquivo JSON ou fornecer uma variável de ambiente ao SJM no lançamento. Se ambos forem fornecidos, o SJM utilizará apenas valores fornecidos pelo ambiente.

<CollapserGroup>
  <Collapser id="user-file-example" title="Montando arquivo JSON">
    O usuário pode criar um arquivo no formato JSON e montar o volume onde o arquivo está localizado em um caminho de destino especificado no contêiner SJM.

    O arquivo deve ter permissões de leitura e conter um mapa formatado em JSON. Exemplo de arquivo de variáveis definidas pelo usuário:

    ```json
    {
      "KEY": "VALUE",
      "user_name": "MINION",
      "my_password": "PASSW0RD123",
      "my_URL": "https://newrelic.com/",
      "ETC": "ETC"
    }
    ```

    Coloque o arquivo no diretório de origem do host. O SJM espera que o nome do arquivo seja user\_defined\_variables.json

    Exemplo de Docker :

    O diretório de destino esperado é: `/var/lib/newrelic/synthetics/variables/`

    ```sh
    docker run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw ...
    ```

    Exemplo de Podman:

    No caso do SELinux, monte o volume adicionalmente com `:z` ou `:Z`. Para mais informações, consulte [a documentação do Podman.](https://docs.podman.io/en/latest/markdown/podman-run.1.html#volume-v-source-volume-host-dir-container-dir-options) O diretório de destino esperado é: `/var/lib/newrelic/synthetics/variables/`

    ```sh
    podman run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw,z ...
    ```

    Exemplo de Kubernetes:

    O usuário tem duas opções ao fornecer um arquivo ao pod SJM no Kubernetes. Eles podem:

    * Passe um arquivo local.
    * Forneça um PersistentVolume que inclua o `user_defined_variables.json`.

    ### Passe um arquivo local

    Esta opção cria um recurso ConfigMap Kubernetes e o monta no pod SJM.

    ```sh
    helm install newrelic/synthetics-job-manager ... --set-file "synthetics.userDefinedVariables.userDefinedFile=[local-path]/user_defined_variables.json" ...
    ```

    ### Monte um `PersistentVolume`

    Esta opção exige que o usuário forneça um `PersistentVolume` que inclua o arquivo `user_defined_variables.json` ou um `PersistentVolumeClaim` para o mesmo. Para obter mais detalhes sobre a instalação do helm chart usando um `PersistentVolume`, siga as instruções em [armazenamento permanente de dados](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#permanent-data-storage).

    Depois que o usuário tiver preparado um `PersistentVolume` conforme descrito abaixo, inicie o SJM, definindo o caminho onde o arquivo `user_defined_variables.json` está localizado e defina quaisquer outras variáveis `synthetics.persistence` conforme necessário.

    ```sh
    helm install newrelic/synthetics-job-manger ... --set synthetics.userDefinedVariables.userDefinedPath="variables"
    ```
  </Collapser>

  <Collapser id="passing-env-var" title="Passando como uma variável de ambiente">
    As variáveis poderão ser passadas para seu respectivo sistema contêiner via variável de ambiente.

    Exemplo de Docker :

    Use a sinalização `-e` para configurar uma variável de ambiente chamada `USER_DEFINED_VARIABLES` e atribua a ela o valor de uma string de mapa formatada em JSON.

    ```sh
    docker run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Exemplo de Podman:

    Use a sinalização `-e` para configurar uma variável de ambiente chamada `USER_DEFINED_VARIABLES` e atribua a ela o valor de uma string de mapa formatada em JSON.

    ```sh
    podman run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Exemplo de Kubernetes:

    Use a sinalização `--set-literal` para transmitir a string formatada em JSON.

    ```sh
    helm install newrelic/synthetics-job-manager ... --set-literal synthetics.userDefinedVariables.userDefinedJson='{"key":"value","name":"sjm"}' ...
    ```
  </Collapser>
</CollapserGroup>

### Acessando variáveis de ambiente definidas pelo usuário a partir do script [#env-vars-scripts]

Para fazer referência a uma variável de ambiente definida pelo usuário configurada, use o `$env.USER_DEFINED_VARIABLES` reservado seguido do nome de uma determinada variável com notação de ponto (por exemplo, `$env.USER_DEFINED_VARIABLES.MY_VARIABLE`).

<Callout variant="caution">
  Variáveis de ambiente definidas pelo usuário não são limpas do log. Considere usar o recurso [de credenciais seguras](/docs/synthetics/new-relic-synthetics/using-monitors/secure-credentials-store-credentials-information-scripted-browsers) para informações confidenciais.
</Callout>

## Módulos de nós personalizados [#custom-modules]

Módulos de nós personalizados são fornecidos em chamadas por minuto e SJM. Eles permitem criar um conjunto customizado de [módulos de nós](https://docs.npmjs.com/about-packages-and-modules) e utilizá-los em monitoramento scriptado ( API script e browser script) para monitoramento sintético.

### Configure seu diretório de módulos personalizados

Crie um diretório com um arquivo `package.json` seguindo [as diretrizes oficiais do npm](https://docs.npmjs.com/files/package.json) na pasta raiz. O SJM instalará qualquer dependência listada no arquivo package.json campo `dependencies` . Essas dependências estarão disponíveis ao executar o monitor no gerenciador de tarefas Sintético privado. Veja um exemplo disso abaixo.

#### Exemplo

Neste exemplo, um diretório de módulo customizado é usado com a seguinte estrutura:

```
/example-custom-modules-dir/
    ├── counter
    │   ├── index.js
    │   └── package.json
    └── package.json            ⇦ the only mandatory file
```

O `package.json` define `dependencies` como um módulo local (por exemplo, `counter`) e qualquer módulo hospedado (por exemplo, `smallest` versão `1.0.1`):

```json
{
    "name": "custom-modules",
    "version": "1.0.0",                                ⇦ optional
    "description": "example custom modules directory", ⇦ optional
    "dependencies": {
    "smallest": "1.0.1",                               ⇦ hosted module
    "counter": "file:./counter"                        ⇦ local module
    }
}
```

### Adicione seu diretório de módulos personalizados ao SJM para Docker, Podman ou Kubernetes

<CollapserGroup>
  <Collapser id="docker" title="Docker">
    Para docker, lance o SJM montando o diretório em `/var/lib/newrelic/synthetics/modules`. Por exemplo:

    ```sh
    docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ...
    ```
  </Collapser>

  <Collapser id="podman" title="Homem-Pod">
    Para podman, inicie o SJM montando o diretório em `/var/lib/newrelic/synthetics/modules`. No caso do SELinux, monte o volume adicionalmente com `:z` ou `:Z`. Para mais informações, consulte [a documentação do Podman](https://docs.podman.io/en/latest/markdown/podman-run.1.html#volume-v-source-volume-host-dir-container-dir-options). Por exemplo:

    ```sh
    podman run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw,z ...
    ```
  </Collapser>

  <Collapser id="kubernetes" title="Kubernetes">
    Para Kubernetes, o diretório em `/var/lib/newrelic/synthetics/modules` precisa existir em um PV antes de iniciar o SJM com módulos customizados habilitados.

    <Callout variant="tip">
      O modo de acesso PV deverá ser ReadWriteMany se você precisar compartilhar o armazenamento entre vários pods.
    </Callout>

    Um método é criar um pod que monte o PV apenas com a finalidade de copiar o diretório de módulos personalizados para o PV. O exemplo a seguir usa Amazon EFS com Amazon EKS:

    #### Criar o namespace, o volume persistente e a declaração de volume persistente

    1. Certifique-se de já ter configurado seu sistema de arquivos EFS e instalado o [driver EFS CSI](https://github.com/kubernetes-sigs/aws-efs-csi-driver) em seu cluster. Você também precisará do ID do sistema de arquivos EFS para os PVs `spec.csi.volumeHandle`.

       ```sh
       kubectl apply -f - <<EOF
       apiVersion: v1
       kind: Namespace
       metadata:
         name: newrelic

       ---
       kind: StorageClass
       apiVersion: storage.k8s.io/v1
       metadata:
         name: efs-sc
       provisioner: efs.csi.aws.com

       ---
       apiVersion: v1
       kind: PersistentVolume
       metadata:
         name: custom-modules-pvc
       spec:
         capacity:
           storage: 5Gi
         volumeMode: Filesystem
         accessModes:
           - ReadWriteMany
         persistentVolumeReclaimPolicy: Retain
         storageClassName: efs-sc
         csi:
           driver: efs.csi.aws.com
           volumeHandle: <your-efs-filesystem-id>

       ---
       apiVersion: v1
       kind: PersistentVolumeClaim
       metadata:
         name: custom-modules-pvc
         namespace: newrelic
       spec:
         accessModes:
           - ReadWriteMany
         storageClassName: efs-sc
         resources:
           requests:
             storage: 5Gi
       EOF
       ```

    2. Mude para o namespace `newrelic` em seu `~/.kube/config`.

       ```sh
       kubectl config get-contexts
       kubectl config set-context YOUR_CONTEXT --namespace=newrelic
       kubectl config view --minify | grep namespace:
       ```

    3. Neste ponto, o PVC deve estar vinculado ao PV com modo de acesso RWX.

       ```sh
       kubectl get pv,pvc
       [output] NAME                                  CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                         STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
       [output] persistentvolume/custom-modules-pvc   5Gi        RWX            Retain           Bound    newrelic/custom-modules-pvc   efs-sc         <unset>                          4m46s
       [output]
       [output] NAME                                       STATUS   VOLUME               CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
       [output] persistentvolumeclaim/custom-modules-pvc   Bound    custom-modules-pvc   5Gi        RWX            efs-sc         <unset>                 4m10s
       ```

       #### Crie `mount-custom-mods-pod` para copiar seu diretório de módulos personalizados

       ```sh
       kubectl apply -f - <<EOF
       apiVersion: v1
       kind: Pod
       metadata:
         name: mount-custom-mods-pod
       spec:
         containers:
         - name: mount-custom-mods-pod
           image: nginx
           resources:
             requests:
               memory: "64Mi"
               cpu: "250m"
             limits:
               memory: "128Mi"
               cpu: "500m"
           volumeMounts:
             - mountPath: "/var/lib/newrelic/synthetics/modules"
               name: custom-modules-storage
         volumes:
         - name: custom-modules-storage
           persistentVolumeClaim:
             claimName: custom-modules-pvc
       EOF
       ```

       Neste ponto, o `mount-custom-mods-pod` deve ser criado e configurado para usar o volume.

       ```sh
       kubectl describe po mount-custom-mods-pod | grep -A4 Volumes:
       [output] Volumes:
       [output]   custom-modules-storage:
       [output]     Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
       [output]     ClaimName:  custom-modules-pvc
       [output]     ReadOnly:   false
       ```

       Verifique se há algum aviso relacionado ao PV, PVC ou `mount-custom-mods-pod`.

       ```sh
       kubectl get events --field-selector type=Warning --sort-by='.lastTimestamp'
       ```

       #### Copie seu diretório de módulos personalizados para o PV

       Não é necessário copiar `node_modules` pois ele será gerado pelo SJM em `npm install`.

       ```sh
       cd custom-modules
       rm -rf node_modules && cd ..
       ```

    4. Verifique se o `mount-custom-mods-pod` está em execução.

       ```sh
       kubectl get po
       [output] NAME                    READY   STATUS    RESTARTS   AGE
       [output] mount-custom-mods-pod   1/1     Running   0          5m43s
       ```

    5. Copie para o PV.

       ```sh
       kubectl cp custom-modules newrelic/mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules
       ```

    6. Verifique se `/var/lib/newrelic/synthetics/modules/custom-modules/package.json` existe no PV.

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l
       [output] total 4
       [output] drwxr-xr-x 2 root root 6144 Jun 29 03:49 custom-modules
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l custom-modules/
       [output] total 4
       [output] -rw-r--r-- 1 501 staff 299 Jun 29 03:49 package.json
       ```

       #### lançar o SJM com recurso de módulos customizados habilitado

       Configure valores para `persistence.existingClaimName` e `customNodeModules.customNodeModulesPath` na linha de comando ou em um arquivo YAML durante a instalação. O valor `customNodeModules.customNodeModulesPath` deve especificar o subcaminho no Volume Persistente onde existem seus arquivos de módulos personalizados. Por exemplo:

       ```sh
       helm upgrade --install synthetics-job-manager newrelic/synthetics-job-manager -n newrelic --set global.persistence.existingClaimName=custom-modules-pvc --set global.customNodeModules.customNodeModulesPath=custom-modules --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY
       [output] Release "synthetics-job-manager" does not exist. Installing it now.
       [output] NAME: synthetics-job-manager
       [output] LAST DEPLOYED: Fri Jun 28 16:53:28 2024
       [output] NAMESPACE: newrelic
       [output] STATUS: deployed
       [output] REVISION: 1
       [output] TEST SUITE: None
       ```

       O diretório `custom-modules` agora deve conter os pacotes instalados em `node_modules`.

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l custom-modules/
       [output] total 16
       [output] -rw-r--r--  1 root root   836 Jun 29 03:51 README
       [output] drwxr-xr-x 18 root root  6144 Jun 29 03:51 node_modules
       [output] -rw-r--r--  1  501 staff  299 Jun 29 03:49 package.json
       [output] -rw-r--r--  1 root root   190 Jun 29 03:51 package.json.shasum
       ```

       Se os módulos de nós customizados não forem detectados, ajuste as permissões no diretório `custom-modules` e no arquivo `package.json` .

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# chmod -R 777 custom-modules
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# chown -R 2000:2000 custom-modules
       ```
  </Collapser>
</CollapserGroup>

Para verificar se os módulos foram instalados corretamente ou se ocorreu algum erro, procure as seguintes linhas no `synthetics-job-manager` [contêiner](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs) ou log [pod](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring/#review-kubernetes-logs) :

```log
2024-06-29 03:51:28,407{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Detected mounted path for custom node modules
2024-06-29 03:51:28,408{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Validating permission for custom node modules package.json file
2024-06-29 03:51:28,409{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Installing custom node modules...
2024-06-29 03:51:44,670{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Custom node modules installed successfully.
```

Agora você pode adicionar `"require('smallest');"` ao [script](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) de monitor que você envia para esta localização privada.

### Mudar `package.json` [#change-package-json]

Além dos módulos locais e hospedados, você também pode utilizar [módulos Node.js.](/docs/synthetics/new-relic-synthetics/scripting-monitors/import-nodejs-modules) Para atualizar os módulos customizados usados pelo seu SJM, faça alterações no arquivo `package.json` e reinicie o SJM. Durante o processo de reinicialização, o SJM reconhecerá a alteração na configuração e executará automaticamente as operações de limpeza e reinstalação para garantir que os módulos atualizados sejam aplicados.

<Callout variant="caution">
  Módulos locais: embora seu `package.json` possa incluir qualquer módulo local, esses módulos devem residir na árvore no diretório do módulo personalizado. Se armazenado fora da árvore, o processo de inicialização falhará e você verá uma mensagem de erro no [log docker ](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs)após iniciar o SJM.
</Callout>

## Armazenamento permanente de dados [#permanent-data-storage]

O usuário pode querer usar o armazenamento permanente de dados para fornecer o arquivo `user_defined_variables.json` ou oferecer suporte a módulos de nós personalizados.

### Docker

Para definir o armazenamento permanente de dados no Docker:

1. Crie um diretório no host onde você está iniciando o Job Manager. Este é o seu diretório de origem.

2. inicie o Job Manager, montando o diretório de origem no diretório de destino `/var/lib/newrelic/synthetics`.

   Exemplo:

   ```sh
   docker run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw ...
   ```

### Homem-Pod

Para definir o armazenamento permanente de dados no Podman:

1. Crie um diretório no host onde você está iniciando o Job Manager. Este é o seu diretório de origem.
2. inicie o Job Manager, montando o diretório de origem no diretório de destino `/var/lib/newrelic/synthetics`.

Exemplo:

```sh
podman run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw,z ...
```

### Kubernetes

Para definir o armazenamento permanente de dados no Kubernetes, o usuário tem duas opções:

1. Forneça um PersistentVolumeClaim (PVC) existente para um PersistentVolume (PV) existente, definindo o valor de configuração `synthetics.persistence.existingClaimName` . Exemplo:

   ```sh
   helm install ... --set synthetics.persistence.existingClaimName=sjm-claim ...
   ```

2. Forneça um nome PersistentVolume (PV) existente, definindo o valor de configuração `synthetics.persistence.existingVolumeName` . Helm irá gerar um PVC para o usuário. O usuário também pode definir opcionalmente os seguintes valores:

* `synthetics.persistence.storageClass`: A classe de armazenamento do PV existente. Se não for fornecido, o Kubernetes usará a classe de armazenamento padrão.

* `synthetics.persistence.size`: O tamanho da reivindicação. Se não for definido, o padrão atualmente é 2Gi.

  ```sh
  helm install ... --set synthetics.persistence.existingVolumeName=sjm-volume --set synthetics.persistence.storageClass=standard ...
  ```

## Considerações de dimensionamento para Docker, Podman, Kubernetes e OpenShift [#kubernetes-sizing]

### Docker e Podman [#docker]

Para garantir que sua localização privada seja executada com eficiência, você deve provisionar recursos de CPU suficientes em seu host para lidar com sua workload de monitoramento. Muitos fatores influenciam o dimensionamento, mas você pode estimar rapidamente suas necessidades. Você precisará **de 1 núcleo de CPU para cada monitor pesado** (por exemplo, navegador simples, navegador com script ou monitor de API com script). Abaixo estão duas fórmulas para ajudar você a calcular o número de núcleos necessários, seja para diagnosticar uma configuração atual ou planejar uma futura.

#### Fórmula 1: Diagnosticando um Local Existente

Se sua localização privada atual estiver com dificuldades para acompanhar e você suspeitar que há trabalhos na fila, use esta fórmula para descobrir quantos núcleos você realmente precisa. Baseia-se no desempenho observável do seu sistema.

**A equação:**

$$C\_req = (R\_proc + R\_crescimento) \vezes D\_méd,m$$

* $C\_req$ = **Núcleos de CPU necessários**.
* $R\_proc$ = A **taxa** de trabalhos pesados sendo **processados** por minuto.
* $R\_growth$ = A **taxa** **de crescimento** da sua fila `jobManagerHeavyweightJobs` por minuto.
* $D\_avg,m$ = A **duração média** de trabalhos pesados em **minutos**.

**Veja como funciona:** esta fórmula calcula sua taxa real de chegada de trabalhos adicionando os trabalhos que seu sistema *está processando* aos trabalhos que estão *se acumulando* na fila. Multiplicar essa carga total pela duração média do trabalho informa exatamente quantos núcleos você precisa para concluir todo o trabalho sem filas.

#### Fórmula 2: Previsão de um local novo ou futuro

Se você estiver configurando uma nova localização privada ou planejando adicionar mais monitores, use esta fórmula para prever suas necessidades com antecedência.

**A equação:**

$$C\_req = N\_mon \vezes D\_méd,m \vezes \frac1P\_méd,m$$

* $C\_req$ = **Núcleos de CPU necessários**.
* $N\_mon$ = O **número** total de **monitores** pesados que você planeja executar.
* $D\_avg,m$ = A **duração média** de um trabalho pesado em **minutos**.
* $P\_avg,m$ = O **período médio** para monitores pesados em **minutos** (por exemplo, um monitor que é executado a cada 5 minutos tem $P\_avg,m = 5$).

**Veja como funciona:** isso calcula sua workload esperada a partir de princípios básicos: quantos monitores você tem, com que frequência eles são executados e quanto tempo eles levam.

#### Fatores importantes de dimensionamento

Ao usar essas fórmulas, lembre-se de levar em conta estes fatores:

* **Duração do trabalho ($D\_avg,m$):** Sua média deve incluir trabalhos que **expiram** (geralmente \~3 minutos), pois eles mantêm um núcleo durante toda a sua duração.
* **Falhas e novas tentativas de trabalho:** quando um monitor falha, ele é automaticamente repetido. Essas tentativas são trabalhos adicionais que aumentam a carga total. Um monitor que falha consistentemente e tenta novamente **multiplica efetivamente seu período**, impactando significativamente as taxas de transferência.
* **Escalonamento:** além de adicionar mais núcleos a um host (escalonamento vertical), você pode implantar gerenciadores de tarefas adicionais da Sintéticos com a mesma chave de localização privada para balancear a carga de tarefas em vários ambientes (escalonamento horizontal).

É importante observar que um único Sintéticos Job Manager (SJM) tem um limite de taxas de transferência de **aproximadamente 15 trabalhos pesados por minuto**. Isso se deve a uma estratégia de segmentação interna que favorece a competição eficiente de trabalhos entre vários SJMs em relação ao número bruto de trabalhos processados por SJM. Se seus cálculos indicarem a necessidade de taxas de transferência mais altas, você deverá **expandir** implantando SJMs adicionais. Você pode [verificar se sua fila de tarefas está crescendo](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring/) para determinar se mais SJMs são necessários.

Adicionar mais SJMs com a mesma chave de localização privada oferece diversas vantagens:

* **Balanceamento de carga**: Os trabalhos para localização privada são distribuídos em todos os SJMs disponíveis.
* **Proteção contra failover**: se uma instância do SJM ficar inativa, outras poderão continuar processando trabalhos.
* **Taxas de transferência totais mais altas**: As taxas de transferência totais para sua localização privada tornam-se a soma das taxas de transferência de cada SJM (por exemplo, dois SJMs fornecem até \~30 trabalhos/minuto).

#### Consulta NRQL para diagnóstico

Você pode executar essas consultas no [criador de consultas](/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data/) para obter as entradas para a fórmula de diagnóstico. Certifique-se de definir o intervalo de tempo para um período longo o suficiente para obter uma média estável.

**1. Encontre a taxa de trabalhos processados por minuto ($R\_proc$):** esta consulta conta o número de trabalhos não ping (pesados) concluídos no último dia e mostra a taxa média por minuto.

```nrql
FROM SyntheticCheck SELECT rate(uniqueCount(id), 1 minute) AS 'job rate per minute' WHERE location = 'YOUR_PRIVATE_LOCATION' AND type != 'SIMPLE' SINCE 1 day ago
```

**2. Encontre a taxa de crescimento da fila por minuto ($R\_growth$):** esta consulta calcula o crescimento médio por minuto da fila `jobManagerHeavyweightJobs` em um gráfico de série temporal. Uma linha acima de zero indica que a fila está crescendo, enquanto uma linha abaixo de zero significa que ela está diminuindo.

```nrql
FROM SyntheticsPrivateLocationStatus SELECT derivative(jobManagerHeavyweightJobs, 1 minute) AS 'queue growth rate per minute' WHERE name = 'YOUR_PRIVATE_LOCATION' TIMESERIES SINCE 1 day ago
```

<Callout variant="tip">
  Certifique-se de selecionar a conta onde existe a localização privada. É melhor visualizar essa consulta como uma série temporal porque a função derivada pode variar muito. O objetivo é obter uma estimativa da taxa de crescimento da fila por minuto. Play diferentes intervalos de tempo para ver o que funciona melhor.
</Callout>

**3. Encontre o número total de monitores pesados ($N\_mon$):** Esta consulta encontra a contagem exclusiva de monitores pesados.

```nrql

  FROM SyntheticCheck SELECT uniqueCount(monitorId) AS 'monitor count' WHERE location = 'YOUR_PRIVATE_LOCATION' AND type != 'SIMPLE' SINCE 1 day ago

```

**4. Encontre a duração média da tarefa em minutos ($D\_avg,m$):** esta consulta encontra a duração média de execução de tarefas não ping concluídas e converte o resultado de milissegundos para minutos. `executionDuration` representa o tempo que o trabalho levou para ser executado no host.

```nrql
FROM SyntheticCheck SELECT average(executionDuration)/60e3 AS 'avg job duration (m)' WHERE location = 'YOUR_PRIVATE_LOCATION' AND type != 'SIMPLE' SINCE 1 day ago
```

**5. Encontre o período médio do monitor de peso pesado ($P\_avg,m$):** Se a fila `jobManagerHeavyweightJobs` da localização privada estiver crescendo, não será preciso calcular o período médio do monitor a partir dos resultados existentes. Isso precisará ser estimado a partir da lista de monitores na página [Monitores Sintético](https://one.newrelic.com/synthetics). Certifique-se de selecionar a conta New Relic correta e talvez seja necessário filtrar por `privateLocation`.

<Callout variant="tip">
  Monitores Sintéticos podem existir em múltiplas subcontas. Se você tiver mais subcontas do que as que podem ser selecionadas no criador de consulta, escolha as contas com mais monitores.
</Callout>

#### Nota sobre monitores de ping e a fila `pingJobs`

**Os monitores de ping são diferentes.** São trabalhos leves que não consomem um núcleo de CPU completo cada. Em vez disso, eles usam uma fila separada (`pingJobs`) e são executados em um pool de threads de trabalho.

Embora consumam menos recursos, um alto volume de tarefas de ping, especialmente aquelas com falhas, ainda pode causar problemas de desempenho. Tenha estes pontos em mente:

* **Modelo de recursos:** os trabalhos de ping utilizam threads de trabalho, não núcleos de CPU dedicados. O cálculo de núcleo por trabalho não se aplica a eles.
* **Tempo limite e nova tentativa:** uma tarefa de ping com falha pode ocupar um thread de trabalho por até **60 segundos**. Primeiro, ele tenta uma solicitação HTTP HEAD (tempo limite de 30 segundos). Se isso falhar, ele tenta imediatamente com uma solicitação HTTP GET (outro tempo limite de 30 segundos).
* **Dimensionamento:** embora a fórmula de dimensionamento seja diferente, os mesmos princípios se aplicam. Para lidar com um grande volume de trabalhos de ping e evitar que a fila `pingJobs` cresça, talvez seja necessário aumentar e/ou diminuir a escala. Aumentar a escala significa aumentar os recursos de CPU e memória por host ou namespace. Escalar significa adicionar mais instâncias do tempo de execução do ping. Isso pode ser feito implantando mais gerenciadores de tarefas em mais hosts, em mais namespaces ou até mesmo [dentro do mesmo namespace](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#scaling-out-with-multiple-sjm-instances). Como alternativa, o `ping-runtime` no Kubernetes permite que você defina [um número maior de réplicas](https://github.com/newrelic/helm-charts/blob/41c03e287dafd41b9c914e5a6c720d5aa5c01ace/charts/synthetics-job-manager/values.yaml#L173) por implantação.

### Kubernetes e OpenShift [#k8s]

Cada tempo de execução usado pelo gerenciador de tarefas Kubernetes e do OpenShift Sintético pode ser dimensionado independentemente definindo valores no [gráfico do helm](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager). O [node-api-runtime](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager/charts/node-api-runtime) e o [node-browser-runtime](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager/charts/node-browser-runtime) são dimensionados independentemente usando uma combinação das configurações `parallelism` e `completions`.

Uma consideração importante ao dimensionar seus tempos de execução é que uma única instância SJM tem uma taxa máxima de download de **aproximadamente 15 trabalhos pesados por minuto** ( API com script e monitores de navegador). Isso se deve a uma estratégia de segmentação interna que favorece a competição eficiente de trabalhos entre vários SJMs em relação ao número bruto de trabalhos processados por SJM.

Você pode usar a duração média do seu trabalho para calcular o `parallelism` efetivo máximo para um único SJM antes de atingir este teto de taxas de transferência:

$$Paralelismo*máximo \aprox. 15 \vezes D*avg,m$$

Onde $D\_avg,m$ é a **duração média do trabalho pesado** em **minutos**.

Se suas necessidades de monitoramento excederem esse limite de \~15 trabalhos/minuto, você deverá **expandir** implantando múltiplas instâncias de SJM. Você pode [verificar se sua fila de tarefas está crescendo](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring/) para ver se mais instâncias são necessárias.

A configuração `parallelism` controla quantos pods de um tempo de execução específico são executados simultaneamente e é o equivalente à variável de ambiente `HEAVYWEIGHT_WORKERS` no Docker e no Podman SJM. A configuração `completions` controla quantos pods de um tempo de execução específico devem ser concluídos antes que o `CronJob` possa iniciar outro trabalho Kubernetes para esse tempo de execução. Para maior eficiência, `completions` deve ser definido como 6-10x o valor `parallelism`.

As equações a seguir podem ser usadas como ponto de partida para `completions` e `parallelism` para cada tempo de execução.

$$Conclusões = \frac300D\_avg,s$$

Onde $D\_avg,s$ é a **duração média do trabalho** em **segundos**.

$$Paralelismo = \fracN\_mCompletions$$

Onde $N\_m$ é o **número** de tarefas do Sintético que você precisa executar a cada **5 minutos.**

A consulta a seguir pode ser usada para obter duração média e tarifa para uma localização privada.

```sql
-- non-ping average job duration by runtime type
FROM SyntheticCheck SELECT average(duration) AS 'avg job duration'
WHERE type != 'SIMPLE' AND location = 'YOUR_PRIVATE_LOCATION' FACET typeLabel SINCE 1 hour ago

-- non-ping jobs per minute by runtime type
FROM SyntheticCheck SELECT rate(uniqueCount(id), 5 minutes) AS 'jobs per 5 minutes'
WHERE type != 'SIMPLE' AND location = 'YOUR_PRIVATE_LOCATION' FACET typeLabel SINCE 1 hour ago
```

<Callout variant="tip">
  As consultas acima são baseadas em resultados atuais. Se sua localização privada não tiver nenhum resultado ou o gerente de trabalho não estiver apresentando o melhor desempenho, os resultados da consulta poderão não ser precisos. Nesse caso, tente alguns valores diferentes para `completions` e `parallelism` até ver uma duração de `kubectl get jobs -n YOUR_NAMESPACE` de pelo menos 5 minutos (conclusões suficientes) e a fila não estiver crescendo (paralelismo suficiente).
</Callout>

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        Exemplo
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `parallelism=1`

        `completions=1`
      </td>

      <td>
        O runtime executará 1 job Sintético por minuto. Após a conclusão de 1 trabalho, a configuração `CronJob` iniciará um novo trabalho no minuto seguinte. <DNT>**Throughput will be extremely limited with this configuration.**</DNT>
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=1`

        `completions=6`
      </td>

      <td>
        O runtime executará 1 job Sintético por vez. Após a conclusão do trabalho, um novo trabalho será iniciado imediatamente. Depois que a configuração do número de jobs `completions` for concluída, a configuração `CronJob` iniciará um novo job do Kubernetes e redefinirá o contador de conclusões. <DNT>**Throughput will be limited, but slightly better.**</DNT> Um único trabalho Sintético de longa duração bloqueará o processamento de quaisquer outros trabalhos Sintético deste tipo.
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=3`

        `completions=24`
      </td>

      <td>
        O runtime executará 3 jobs Sintético de uma só vez. Após a conclusão de qualquer um desses trabalhos, um novo trabalho será iniciado imediatamente. Depois que a configuração do número de jobs `completions` for concluída, a configuração `CronJob` iniciará um novo job do Kubernetes e redefinirá o contador de conclusões. <DNT>**Throughput is much better with this or similar configurations.**</DNT> Um único trabalho Sintético de longa duração terá impacto limitado no processamento de outros trabalhos Sintético deste tipo.
      </td>
    </tr>
  </tbody>
</table>

Se os trabalhos Sintético demorarem mais para serem concluídos, serão necessárias menos conclusões para preencher 5 minutos com trabalhos, mas serão necessários mais pods paralelos. Da mesma forma, se mais trabalhos Sintético precisarem ser processados por minuto, mais pods paralelos serão necessários. A configuração `parallelism` afeta diretamente quantos jobs Sintético por minuto podem ser executados. Um valor muito pequeno e a fila poderá crescer. Um valor muito grande e os nós podem ficar com recursos limitados.

Se suas configurações `parallelism` estiverem funcionando bem para manter a fila em zero, definir um valor mais alto para `completions` do que o calculado em `300 / avg job duration` pode ajudar a melhorar a eficiência de duas maneiras:

* Acomode a variabilidade nas durações dos trabalhos de forma que pelo menos 1 minuto seja preenchido com trabalhos Sintético, que é a duração mínima do CronJob.
* Reduza o número de ciclos de conclusões para minimizar a ineficiência de &quot;próximo ao fim das conclusões&quot;, onde o próximo conjunto de conclusões não pode começar até que o trabalho final seja concluído.

É importante observar que o valor `completions` não deve ser muito grande ou o CronJob receberá um aviso como este:

```sql
8m40s       Warning   TooManyMissedTimes     cronjob/synthetics-node-browser-runtime                  too many missed start times: 101. Set or decrease .spec.startingDeadlineSeconds or check clock skew
```

<Callout variant="tip">
  New Relic não se responsabiliza por quaisquer modificações que você fizer nos arquivos do gerenciador de tarefas do Sintéticos.
</Callout>

#### Expandindo com múltiplas instâncias SJM

Para atingir taxas totais de transferência maiores, você pode instalar várias versões do SJM Helm no mesmo namespace Kubernetes. Cada SJM competirá por trabalhos da mesma localização privada, fornecendo balanceamento de carga, proteção contra failover e um aumento nas taxas totais de transferência de trabalho.

Ao instalar várias versões do SJM, você deve fornecer um nome exclusivo para cada versão. Todas as instâncias devem ser configuradas com a **mesma chave de localização privada** em seu arquivo `values.yaml`. Embora não seja obrigatório, é recomendável definir `fullnameOverride` para criar nomes de recursos mais curtos e gerenciáveis.

Por exemplo, para instalar dois SJMs chamados `sjm-alpha` e `sjm-beta` no namespace `newrelic` :

```sh
helm upgrade --install sjm-alpha -n newrelic newrelic/synthetics-job-manager -f values.yaml --set fullnameOverride=sjm-alpha --create-namespace
```

```sh
helm upgrade --install sjm-beta -n newrelic newrelic/synthetics-job-manager -f values.yaml --set fullnameOverride=sjm-beta
```

Você pode continuar esse padrão para quantos SJMs forem necessários para evitar que a fila de trabalhos cresça. Para cada SJM, defina `parallelism` e `completions` como um valor razoável com base na duração média do seu trabalho e no limite de \~15 trabalhos por minuto por instância.