---
title: Configuração do gerenciador de tarefas Sintético
tags:
  - synthetics
  - Synthetic monitoring
  - Private locations
metaDescription: Customize your New Relic synthetics job manager.
freshnessValidatedDate: never
translationType: machine
---

Este documento irá guiá-lo na configuração do seu [gerenciador de tarefas Sintético](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager) , mostrando como:

* Configure [módulos personalizados](#custom-modules) para [API com script](/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/) ou monitor [de navegador com script](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) .
* Forneça [variáveis definidas pelo usuário](#user-defined-vars) em sua configuração.
* Atualize outras [variáveis de ambiente](#environment-variables) ao iniciar seu gerenciador de tarefas Sintético.

## Variáveis definidas pelo usuário para monitor com script [#user-defined-vars]

Os gerenciadores de tarefas Private Sintético permitem configurar variáveis de ambiente para monitor com script. Essas variáveis são gerenciadas localmente no SJM e podem ser acessadas via `$env.USER_DEFINED_VARIABLES`. Você pode definir variáveis definidas pelo usuário de duas maneiras. Você pode montar um arquivo JSON ou fornecer uma variável de ambiente ao SJM no lançamento. Se ambos forem fornecidos, o SJM utilizará apenas valores fornecidos pelo ambiente.

<CollapserGroup>
  <Collapser
    id="user-file-example"
    title="Montando arquivo JSON"
  >
    O usuário pode criar um arquivo no formato JSON e montar o volume onde o arquivo está localizado em um caminho de destino especificado no contêiner SJM.

    O arquivo deve ter permissões de leitura e conter um mapa formatado em JSON. Exemplo de arquivo de variáveis definidas pelo usuário:

    ```
    {
    		      "KEY": "VALUE",
    		      "user_name": "MINION",
    		      "my_password": "PASSW0RD123",
    		      "my_URL": "https://newrelic.com/",
    		      "ETC": "ETC"
    		    }
    ```

    Coloque o arquivo no diretório de origem do host. O SJM espera que o nome do arquivo seja user_defined_variables.json

    Exemplo de Docker :

    O diretório de destino esperado é: `/var/lib/newrelic/synthetics/variables/`

    ```
    docker run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw ...
    ```

    Exemplo de Kubernetes:

    O usuário tem duas opções ao fornecer um arquivo ao pod SJM no Kubernetes. Eles podem:

    1. passe um arquivo local.
    2. forneça um PersistentVolume que inclua o user_defined_variables.json.

    ### Passe um arquivo local

    Esta opção cria um recurso ConfigMap Kubernetes e o monta no pod SJM.

    helm install newrelic/synthetics-job-manager ... --set-file "synthetics.userDefinedVariables.userDefinedFile=\[local-path]/user_defined_variables.json" ...

    ```

     ### Mount a PersistentVolume
    This option requires the user to provide a PersistentVolume that includes the user_defined_variables.json file or a PersistentVolumeClaim to the same. For more details on helm chart installation using a PersistentVolume, follow the instructions at [permanent data storage](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#permanent-data-storage).
	
    Once the user has prepared a PersistentVolume as described below, launch the SJM, setting the path where the user_defined_variables.json file is located and setting any other `synthetics.persistence` variables as necessary.

    ```

    helm install newrelic/synthetics-job-manger ... --set synthetics.userDefinedVariables.userDefinedPath="variables"

    ```

    ```
  </Collapser>

  <Collapser
    id="passing-env-var"
    title="Passando como uma variável de ambiente"
  >
    As variáveis poderão ser passadas para seu respectivo sistema de contêiner via variável de ambiente. exemplo de docker :

    Use a sinalização `-e` para configurar uma variável de ambiente chamada `USER_DEFINED_VARIABLES` e atribua a ela o valor de uma string de mapa formatada em JSON.

    ```
    docker run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Exemplo do Kubernetes: use a sinalização `--set-literal` para transmitir a string formatada em JSON.

    ```
    helm install newrelic/synthetics-job-manager ... --set-literal synthetics.userDefinedVariables.userDefinedJson='{"key":"value","name":"sjm"}' ...
    ```
  </Collapser>
</CollapserGroup>

### Acessando variáveis de ambiente definidas pelo usuário a partir do script [#env-vars-scripts]

Para fazer referência a uma variável de ambiente definida pelo usuário configurada, use o `$env.USER_DEFINED_VARIABLES` reservado seguido do nome de uma determinada variável com notação de ponto.

Por exemplo, `$env.USER_DEFINED_VARIABLES.MY_VARIABLE`

<Callout variant="caution">
  Variáveis de ambiente definidas pelo usuário não são limpas do log. Considere usar o recurso [de credenciais seguras](/docs/synthetics/new-relic-synthetics/using-monitors/secure-credentials-store-credentials-information-scripted-browsers) para informações confidenciais.
</Callout>

## Módulos de nós personalizados [#custom-modules]

Módulos de nós personalizados são fornecidos em chamadas por minuto e SJM. Eles permitem criar um conjunto customizado de [módulos de nós](https://docs.npmjs.com/about-packages-and-modules) e utilizá-los em monitoramento scriptado ( API script e browser script) para monitoramento sintético.

Para configurar os módulos:

1. Crie um diretório com um arquivo `package.json` seguindo [as diretrizes oficiais do npm](https://docs.npmjs.com/files/package.json) na pasta raiz. O SJM instalará qualquer dependência listada no arquivo package.json campo `dependencies` . Essas dependências estarão disponíveis ao executar o monitor no gerenciador de tarefas Sintético privado. Veja um exemplo disso abaixo.

<CollapserGroup>
  <Collapser
    id="example-module-directory"
    title="Diretório de módulo personalizado"
  >
    Neste exemplo, um diretório de módulo customizado é usado com a seguinte estrutura:

    ```
    /example-custom-modules-dir/
          ├── counter
          │   ├── index.js
          │   └── package.json
          └── package.json            ⇦ the only mandatory file
    ```

    O `package.json` define `dependencies` como um módulo local (por exemplo, `counter`) e qualquer módulo hospedado (por exemplo, `smallest` versão `1.0.1`):

    ```
    {
          "name": "custom-modules",
          "version": "1.0.0",           ⇦ optional
          "description": "example custom modules directory", ⇦ optional
          "dependencies": {
            "smallest": "1.0.1",          ⇦ hosted module
            "counter": "file:./counter" ⇦ local module
          }
        }
    ```
  </Collapser>
</CollapserGroup>

2. Depois de criar o diretório de módulos personalizados e o `package.json`, aplique-os ao seu SJM para docker e Kubernetes.

   <CollapserGroup>
     <Collapser
       id="docker"
       title="Docker"
     >
       Para docker, lance o SJM montando o diretório em `/var/lib/newrelic/synthetics/modules`. Por exemplo:

       ```
       docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ...
       ```
     </Collapser>

     <Collapser
       id="kubernetes"
       title="Kubernetes"
     >
       Complete o seguinte:

       1. inicie o SJM, definindo um valor para o valor de configuração `persistence.customModules` na linha de comando ou em um arquivo YAML durante a instalação. O valor deve especificar o subcaminho no Volume Persistente do gerenciador de tarefas Sintético onde existem seus arquivos de módulos customizados. Por exemplo:

          ```
          helm install ... --set persistence.customModules=<custom-modules-subpath> ...
          ```

       2. Certifique-se de que seu diretório de módulos personalizados esteja disponível no minion pod. Você pode usar `kubectl cp` como um método para copiar o diretório do seu host para o minion. Por exemplo:

          ```
          kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules
          ```
     </Collapser>
   </CollapserGroup>

3. Para verificar se os módulos foram instalados corretamente ou se ocorreu algum erro, revise o [log SJM](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs) da seção intitulada `"... Initialization of Custom Modules ..."`. Esse log incluirá o log de instalação do npm, fornecendo informações sobre o processo de instalação e quaisquer erros potenciais encontrados.

Agora você pode adicionar `"require('smallest');"` ao [script](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) de monitor que você envia para esta localização privada.

### Altere `package.json` para módulos personalizados [#change-package-json]

Além dos módulos locais e hospedados, você também pode utilizar [módulos Node.js.](/docs/synthetics/new-relic-synthetics/scripting-monitors/import-nodejs-modules) Para atualizar os módulos customizados usados pelo seu SJM, faça alterações no arquivo `package.json` e reinicie o SJM. Durante o processo de reinicialização, o SJM reconhecerá a alteração na configuração e executará automaticamente as operações de limpeza e reinstalação para garantir que os módulos atualizados sejam aplicados.

<Callout variant="caution">
  Módulos locais: embora seu `package.json` possa incluir qualquer módulo local, esses módulos devem residir na árvore no diretório do módulo personalizado. Se armazenado fora da árvore, o processo de inicialização falhará e você verá uma mensagem de erro no [log docker ](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs)após iniciar o SJM.
</Callout>

## Armazenamento permanente de dados [#permanent-data-storage]

O usuário pode querer usar o armazenamento permanente de dados para fornecer o arquivo `user_defined_variables.json` ou oferecer suporte a módulos de nós personalizados (ainda não disponíveis para gerentes de tarefas Sintético privados).

### Docker

Para definir o armazenamento permanente de dados no Docker:

1. Crie um diretório no host onde você está iniciando o Job Manager. Este é o seu diretório de origem.
2. inicie o Job Manager, montando o diretório de origem no diretório de destino `/var/lib/newrelic/synthetics`.

Exemplo:

```
		docker run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw ...
```

### Kubernetes

Para definir o armazenamento permanente de dados no Kubernetes, o usuário tem duas opções:

1. Forneça um PersistentVolumeClaim (PVC) existente para um PersistentVolume (PV) existente, definindo o valor de configuração `synthetics.persistence.existingClaimName` .

Exemplo:

```
		helm install ... --set synthetics.persistence.existingClaimName=sjm-claim ...
```

2. Forneça um nome PersistentVolume (PV) existente, definindo o valor de configuração `synthetics.persistence.existingVolumeName` . Helm irá gerar um PVC para o usuário.

O usuário também pode definir opcionalmente os seguintes valores:

* `synthetics.persistence.storageClass`: a classe de armazenamento do PV existente. Se não for fornecido, o Kubernetes usará a classe de armazenamento padrão.
* `synthetics.persistence.size`: o tamanho da reivindicação. Se não for definido, o padrão atualmente é 2Gi.

```
		helm install ... --set synthetics.persistence.existingVolumeName=sjm-volume --set synthetics.persistence.storageClass=standard ...
```

## Variáveis ambientais [#environment-variables]

As variáveis ambientais permitem ajustar a configuração do gerenciador de tarefas Sintético para atender às suas necessidades ambientais e funcionais específicas.

<CollapserGroup>
  <Collapser
    id="docker-env-config"
    title="Configuração do ambiente Docker"
  >
    As variáveis são fornecidas na inicialização usando o argumento `-e, --env` .

    A tabela a seguir mostra todas as variáveis de ambiente suportadas pelo gerenciador de tarefas Sintético. `PRIVATE_LOCATION_KEY` é obrigatório e todas as outras variáveis são opcionais.

    <table>
      <thead>
        <tr>
          <th>
            Nome
          </th>

          <th>
            Descrição
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DoNotTranslate>**REQUIRED.**</DoNotTranslate> chave de localização privada, conforme encontrada na lista entidade privada de localização.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_API_VERSION`
          </td>

          <td>
            Formato: `"vX.Y"` versão da API a ser usada com o serviço Docker fornecido.

            Padrão: `v1.35.`
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_HOST`
          </td>

          <td>
            Aponta o gerenciador de tarefas Sintético para um determinado `DOCKER_HOST`. Se ausente, o valor padrão é `/var/run/docker.sock.`
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            Para contas baseadas nos EUA, o endpoint é: `https://synthetics-horde.nr-data.net.`

            Para contas [baseadas na UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , o endpoint é: `https://synthetics-horde.eu01.nr-data.net/`

            Certifique-se de que seu gerenciador de tarefas Sintético possa se conectar ao endpoint apropriado para atender seu monitor.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            O domínio Docker Registry onde as imagens de tempo de execução estão hospedadas. Use isto para substituir `docker.io` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            O repositório/organização Docker onde as imagens de tempo de execução estão hospedadas. Use isto para substituir `newrelic` como padrão.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Host do servidor proxy usado para comunicação da Horda. Formato: `"localhost"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Porta do servidor proxy usada para comunicação da Horda. Formato: `8888`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Nome de usuário do servidor proxy usado para comunicação da Horda. Formato: `"username"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Senha do servidor proxy usada para comunicação da Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            Aceita certificados proxy autoassinados para a conexão do servidor proxy usada para comunicação do Horde? Valores aceitáveis: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            A quantidade máxima de segundos que as verificações do seu monitor podem ser executadas. Este valor deve ser um número inteiro entre 0 segundos (excluído) e 900 segundos (incluído) (por exemplo, de 1 segundo a 15 minutos).

            Padrão: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            Padrão: `INFO.`

            Opções adicionais: `WARN`, `ERROR`, `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            O número de trabalhos pesados simultâneos (navegador/navegador com script e API com script) que podem ser executados ao mesmo tempo.

            Padrão: CPUs disponíveis - 1.
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            Uma matriz que pode ser usada para executar imagens de tempo de execução específicas. Formato: \['newrelic/Sintético-ping-runtime:latest','newrelic/Sintético-node-API-runtime:latest','newrelic/Sintético-node-navegador-runtime:latest']

            Padrão: todos os tempos de execução mais recentes.
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            Se definido, ativa <DoNotTranslate>**verified script execution**</DoNotTranslate> e usa esse valor como <DoNotTranslate>**passphrase**</DoNotTranslate>.
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            Um conjunto hospedado localmente de pares de valores principais definidos pelo usuário.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="kubernetes-env-config"
    title="Configuração do ambiente Kubernetes"
  >
    As variáveis são fornecidas na inicialização usando o argumento `--set` .

    A lista a seguir mostra todas as variáveis de ambiente suportadas pelo gerenciador de tarefas Sintético. `synthetics.privateLocationKey` é obrigatório e todas as outras variáveis são opcionais.

    Uma série de configurações avançadas adicionais estão disponíveis e totalmente documentadas em [nosso README do gráfico do Helm](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)

    <table>
      <thead>
        <tr>
          <th>
            Nome
          </th>

          <th>
            Descrição
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DoNotTranslate>**REQUIRED if `synthetics.privateLocationKeySecretName` is not set**</DoNotTranslate>. [localização privada chave](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key) da localização privada, conforme encontrado na página localização privada.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.privateLocationKeySecretName`
          </td>

          <td>
            <DoNotTranslate>**REQUIRED if `synthetics.privateLocationKey` is not set**</DoNotTranslate>. Nome do segredo do Kubernetes que contém a chave `privateLocationKey`, que contém a chave de autenticação associada ao seu Sintético localização privada.
          </td>
        </tr>

        <tr>
          <td>
            `replicaCount`
          </td>

          <td>
            Número de réplicas a serem mantidas com sua instalação

            Padrão: `1.`
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            O nome do objeto secreto usado para extrair uma imagem de um registro de contêiner especificado.
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            Substituição de nome usada para sua implantação, substituindo o padrão.
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            Versão de lançamento do Sintético-job-manager para usar em vez da versão especificada em [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml).
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            Padrão: `INFO.`

            Opções adicionais: `WARN`, `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            Para contas baseadas nos EUA, o endpoint é: `https://synthetics-horde.nr-data.net.`

            Para contas [baseadas na UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , o endpoint é: `https://synthetics-horde.eu01.nr-data.net/`

            Certifique-se de que seu gerenciador de tarefas Sintético possa se conectar ao endpoint apropriado para atender seu monitor.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.minionDockerRunnerRegistryEndpoint`
          </td>

          <td>
            O registro e organização Docker onde a imagem do minion Runner está hospedada. Use isto para substituir `quay.io/newrelic` como padrão (por exemplo, `docker.io/newrelic`)
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            Se definido, ele ativa <DoNotTranslate>**verified script execution**</DoNotTranslate> e usa esse valor como <DoNotTranslate>**passphrase**</DoNotTranslate>.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            Se definido, permite a execução verificada do script e usa esse valor para recuperar a senha de um segredo do Kubernetes com uma chave chamada `vsePassphrase`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Servidor proxy usado para comunicação da Horda. Formato: `"host"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Porta do servidor proxy usada para comunicação da Horda. Formato: `port`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Aceite certificados autoassinados ao usar um servidor proxy para comunicação do Horde. Valores aceitáveis: `true`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Nome de usuário do servidor proxy para comunicação da Horda. Formatar: `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Senha do servidor proxy para comunicação da Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            Uma string JSON de variáveis definidas pelo usuário. O usuário pode acessar essas variáveis em seu script. Formato: `'{"key":"value","key2":"value2"}'`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            Um caminho local para o usuário para um arquivo JSON contendo variáveis definidas pelo usuário. Isso é transmitido por meio de `--set-file` e não pode ser definido no arquivo Valores.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            Um caminho no PersistentVolume fornecido pelo usuário para o arquivo user_defined_variables.json. O usuário deverá fornecer um PersistentVolume ou PersistentVolumeClaim se esta variável for preenchida.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingClaimName`
          </td>

          <td>
            Se estiver montando um volume, o usuário poderá fornecer um nome para um PersistentVolumeClaim que já existe no cluster. Pressupõe a existência de um PersistentVolume correspondente.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingVolumeName`
          </td>

          <td>
            Se estiver montando um volume e não fornecer um PersistentVolumeClaim, o usuário deverá fornecer, no mínimo, um nome PersistentVolume. Helm irá gerar um PersistentVolumeClaim.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.storageClass`
          </td>

          <td>
            O nome do StorageClass para o PersistentVolumeClaim gerado. Isso deve corresponder ao StorageClassName no PV existente. Caso contrário, o Kubernetes usará a classe de armazenamento padrão, se presente.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.size`
          </td>

          <td>
            O tamanho do volume do PersistentVolumeClaim gerado. Formato: `10Gi`. 2Gi padrão.
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            A quantidade máxima de segundos que as verificações do seu monitor podem ser executadas. Este valor deve ser um número inteiro entre 0 segundos (excluído) e 900 segundos (incluído) (por exemplo, de 1 segundo a 15 minutos).

            Padrão: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            O contêiner a ser puxado.

            Padrão: `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            A política de puxar.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            Configure um contexto de segurança customizado para o pod Sintético-job-manager.
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução do ping persistente deve ou não ser implantado. Isso pode ser desativado se você não usar o monitor de ping.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            O número de contêineres de tempo de execução de ping a serem implantados. Aumente o replicaCount para dimensionar a implantação com base nas suas necessidades de monitoramento de ping.

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o tempo de execução do ping.

            Padrão: `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução de ping.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução da API Node.js deve ou não ser implantado. Isso pode ser desativado se você não usar o monitor de API com script.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            O número de ambientes de execução da API Node.js `CronJobs` a serem implantados. O número máximo de trabalhos simultâneos da API Node.js que serão executados a qualquer momento. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            O número de ambientes de execução da API Node.js `CronJobs` a serem concluídos por minuto. Aumentar esta configuração juntamente com o paralelismo para melhorar as taxas de transferência. Isto deve ser aumentado sempre que o paralelismo for aumentado e as conclusões devem sempre ser pelo menos maiores ou iguais ao paralelismo. . Aumente essa configuração se você observar períodos sem trabalhos de tempo de execução de API em execução. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o ambiente de execução da API Node.js.

            Padrão: `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução da API Node.js.

            Padrão: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Se o tempo de execução do navegador Node.js deve ou não ser implantado. Isso pode ser desativado se você não usar o script com simples ou monitor do navegador.

            Padrão: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            O número de tempos de execução do navegador Chrome `CronJobs` a serem implantados. O número máximo de jobs simultâneos do navegador Chrome que serão executados a qualquer momento. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            O número de tempos de execução do navegador Chrome `CronJobs` a serem concluídos por minuto. Aumentar esta configuração juntamente com o paralelismo para melhorar as taxas de transferência. Isto deve ser aumentado sempre que o paralelismo for aumentado e as conclusões devem sempre ser pelo menos maiores ou iguais ao paralelismo. Aumente essa configuração se você notar períodos de tempo sem tarefas de tempo de execução do navegador em execução. [Detalhes adicionais](#kubernetes-sizing).

            Padrão: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            A imagem do contêiner a ser extraída para o tempo de execução do navegador Node.js.

            Padrão: `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            A política pull para o contêiner de tempo de execução do navegador Node.js.

            Padrão: `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Considerações de dimensionamento para Kubernetes e Docker [#kubernetes-sizing]

<Callout variant="tip">
  considerações de dimensionamento específicas Docker estarão disponíveis em breve.
</Callout>

Se você estiver trabalhando em ambientes maiores, pode ser necessário customizar a configuração do gerenciador de tarefas para atender aos requisitos mínimos para executar o monitor Sintético com eficiência. Muitos fatores podem impactar os requisitos de dimensionamento para uma implantação do gerenciador de tarefas Sintético, incluindo:

* Se todos os tempos de execução forem necessários com base no uso esperado
* O número de trabalhos por minuto por tipo de monitor (ping, navegador simples ou com script e API com script)
* Duração do trabalho, incluindo trabalhos que expiram em cerca de 3 minutos
* O número de falhas de trabalho. Para falhas de trabalho, novas tentativas automáticas são agendadas quando um monitor começa a falhar ao fornecer lógica de repetição 3/3 integrada. Estes empregos adicionais somam-se aos requisitos de taxas de transferência do gestor de empregos Sintético.

Além das definições de configuração de dimensionamento listadas abaixo, gerenciadores de tarefas adicionais do Sintético podem ser implantados com a mesma chave de localização privada para balancear a carga de tarefas em vários ambientes.

## Kubernetes [#k8s]

Cada tempo de execução usado pelo gerenciador de tarefas Kubernetes Sintético pode ser dimensionado de forma independente, definindo valores no [gráfico do leme](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager).

Tempos de execução de ping adicionais podem ser iniciados para ajudar a executar a carga do monitor de ping aumentando a configuração `ping-runtime.replicaCount` do valor padrão de `1`.

Os tempos de execução da API Node.js e do navegador Node.js são dimensionados de forma independente usando uma combinação das configurações `parallelism` e `completions` . A configuração ideal para essas configurações irá variar de acordo com os requisitos do cliente.

A configuração `parallelism` controla quantos pods de um ambiente de execução específico são executados simultaneamente. A configuração `parallelism` é equivalente à configuração `synthetics.heavyWorkers` no minion privado conteinerizado (chamadas por minuto). Certifique-se de que seu cluster do Kubernetes tenha recursos suficientes disponíveis para executar esse número de pods com base em suas [solicitações de recursos e valores limite](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#kubernetes-requirements).

A configuração `completions` controla quantos pods de um determinado ambiente de execução devem ser concluídos antes que o `CronJob` possa iniciar outro trabalho do Kubernetes para esse ambiente de execução. Observe a diferença entre um trabalho do Kubernetes (J maiúsculo) e um trabalho de monitor Sintético. Para maior eficiência, `completions` deve ser definido como 6 a 10x o valor de `parallelism` . Isso pode ajudar a minimizar a ineficiência de "próximo ao fim das conclusões", em que menos do que o pod de número `parallelism` pode acabar sendo executado enquanto o trabalho do Kubernetes aguarda a conclusão de todos os `completions` .

Quando `completions` for maior que 1, o pod com status "Concluído" permanecerá visível na saída de `kubectl get pods -n YOUR_NAMESPACE` até que todas as conclusões definidas no trabalho do Kubernetes tenham sido atendidas, por exemplo, 6/6 conclusões. Os recursos são liberados do nó quando um pod tem o status Concluído ou Com falha.

Um trabalho do Kubernetes com duração de 5 minutos (`kubectl get jobs -n YOUR_NAMESPACE`) é um destino conservador para levar em conta a variabilidade em quanto tempo leva para o pod ser concluído e quantos trabalhos Sintético precisam ser executados por minuto (taxa de trabalhos). As equações a seguir podem ser usadas como ponto de partida para `completions` e `parallelism` para cada tempo de execução. Talvez seja necessário fazer ajustes com base nas observações do crescimento da fila de localização privada.

```m
completions = 300 / avg job duration (s)
parallelism = synthetics jobs per 5 minutes / completions
```

Tempos de execução diferentes provavelmente terão durações e taxas de trabalho Sintético diferentes. A consulta a seguir pode ser usada para obter duração média e taxa para uma localização privada.

```sql
# non-ping average job duration by runtime type
FROM SyntheticCheck SELECT average(duration) AS 'avg job duration' WHERE type != 'SIMPLE' AND location = 'YOUR_PRIVATE_LOCATION' FACET type SINCE 1 hour ago

# non-ping jobs per minute by runtime type
FROM SyntheticCheck SELECT rate(uniqueCount(id), 5 minutes) AS 'jobs per 5 minutes' WHERE type != 'SIMPLE' AND location = 'YOUR_PRIVATE_LOCATION' FACET type SINCE 1 hour ago
```

<Callout variant="tip">
  As consultas acima são baseadas em resultados atuais. Se sua localização privada não tiver nenhum resultado ou o gerente de trabalho não estiver apresentando o melhor desempenho, os resultados da consulta poderão não ser precisos. Nesse caso, tente alguns valores diferentes para `completions` e `parallelism` até ver uma duração de `kubectl get jobs -n YOUR_NAMESPACE` de pelo menos 5 minutos (conclusões suficientes) e a fila não estiver crescendo (paralelismo suficiente).
</Callout>

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        Exemplo
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `parallelism=1`

        `completions=1`
      </td>

      <td>
        O runtime executará 1 job Sintético por minuto. Após a conclusão de 1 trabalho, a configuração `CronJob` iniciará um novo trabalho no minuto seguinte. <DoNotTranslate>**Throughput will be extremely limited with this configuration.**</DoNotTranslate>
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=1`

        `completions=6`
      </td>

      <td>
        O runtime executará 1 job Sintético por vez. Após a conclusão do trabalho, um novo trabalho será iniciado imediatamente. Depois que a configuração do número de jobs `completions` for concluída, a configuração `CronJob` iniciará um novo job do Kubernetes e redefinirá o contador de conclusões. <DoNotTranslate>**Throughput will be limited, but slightly better.**</DoNotTranslate> Um único trabalho Sintético de longa duração bloqueará o processamento de quaisquer outros trabalhos Sintético deste tipo.
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=3`

        `completions=24`
      </td>

      <td>
        O runtime executará 3 jobs Sintético de uma só vez. Após a conclusão de qualquer um desses trabalhos, um novo trabalho será iniciado imediatamente. Depois que a configuração do número de jobs `completions` for concluída, a configuração `CronJob` iniciará um novo job do Kubernetes e redefinirá o contador de conclusões. <DoNotTranslate>**Throughput is much better with this or similar configurations.**</DoNotTranslate> Um único trabalho Sintético de longa duração terá impacto limitado no processamento de outros trabalhos Sintético deste tipo.
      </td>
    </tr>
  </tbody>
</table>

Se os trabalhos Sintético demorarem mais para serem concluídos, serão necessárias menos conclusões para preencher 5 minutos com trabalhos, mas serão necessários mais pods paralelos. Da mesma forma, se mais trabalhos Sintético precisarem ser processados por minuto, mais pods paralelos serão necessários. A configuração `parallelism` afeta diretamente quantos jobs Sintético por minuto podem ser executados. Um valor muito pequeno e a fila poderá crescer. Um valor muito grande e os nós podem ficar com recursos limitados.

Se suas configurações `parallelism` estiverem funcionando bem para manter a fila em zero, definir um valor mais alto para `completions` do que o calculado em `300 / avg job duration` pode ajudar a melhorar a eficiência de duas maneiras:

* Acomode a variabilidade nas durações dos trabalhos de forma que pelo menos 1 minuto seja preenchido com trabalhos Sintético, que é a duração mínima do CronJob.
* Reduza o número de ciclos de conclusões para minimizar a ineficiência de "próximo ao fim das conclusões", onde o próximo conjunto de conclusões não pode começar até que o trabalho final seja concluído.

É importante observar que o valor `completions` não deve ser muito grande ou o CronJob receberá um aviso como este:

```
8m40s       Warning   TooManyMissedTimes     cronjob/synthetics-node-browser-runtime                  too many missed start times: 101. Set or decrease .spec.startingDeadlineSeconds or check clock skew
```

<Callout variant="tip">
  Por favor, lembre-se de que New Relic não se responsabiliza por quaisquer modificações que você fizer nos arquivos do gerenciador de tarefas Sintético.
</Callout>