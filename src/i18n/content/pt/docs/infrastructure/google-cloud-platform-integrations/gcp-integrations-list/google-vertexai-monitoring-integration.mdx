---
title: Integração de monitoramento de Google VertexAI
tags:
  - Integrations
  - Google Cloud Platform integrations
  - GCP integrations list
metaDescription: 'New Relic Google VertexAI integration: the data it reports and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

[A integração da New Relic](/docs/infrastructure/introduction-infra-monitoring) inclui uma integração para relatar seus dados do GCP Run para nossos produtos. Aqui, explicamos como ativar a integração e quais dados ela coleta.

## Ativar integração [#activate]

Para ativar a integração, siga os procedimentos padrão para [conectar seu serviço GCP ao New Relic](/docs/connect-google-cloud-platform-services-infrastructure).

## Configuração e polling [#polling]

Você pode alterar a frequência de pesquisa e filtrar dados usando [opções de configuração](/docs/integrations/new-relic-integrations/getting-started/configure-polling-frequency-data-collection-cloud-integrations).

Informações [de pesquisa](/docs/integrations/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations) padrão para a integração do GCP Run:

* Intervalo de sondagem New Relic : 5 minutos

## Encontre e use dados [#find-data]

Para encontrar seus dados de integração, acesse <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Infrastructure &amp;gt; GCP**</DNT> e selecione uma integração.

Os dados são anexados aos seguintes [tipos de eventos](/docs/data-apis/understand-data/new-relic-data-types/#event-data):

<table>
  <thead>
    <tr>
      <th>
        Entidade
      </th>

      <th>
        Tipo de evento
      </th>

      <th>
        Fornecedor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Endpoint
      </td>

      <td>
        `GcpVertexAiEndpointSample`
      </td>

      <td>
        `GcpVertexAiEndpoint`
      </td>
    </tr>

    <tr>
      <td>
        Loja de recursos
      </td>

      <td>
        `GcpVertexAiFeaturestoreSample`
      </td>

      <td>
        `GcpVertexAiFeaturestore`
      </td>
    </tr>

    <tr>
      <td>
        Loja de recurso online
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStoreSample`
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStore`
      </td>
    </tr>

    <tr>
      <td>
        Localização
      </td>

      <td>
        `GcpVertexAiLocationSample`
      </td>

      <td>
        `GcpVertexAiLocation`
      </td>
    </tr>

    <tr>
      <td>
        Índice
      </td>

      <td>
        `GcpVertexAiIndexSample`
      </td>

      <td>
        `GcpVertexAiIndex`
      </td>
    </tr>

    <tr>
      <td>
        PipelineJob
      </td>

      <td>
        `GcpVertexAiPipelineJobSample`
      </td>

      <td>
        `GcpVertexAiPipelineJob`
      </td>
    </tr>
  </tbody>
</table>

Para saber mais sobre como usar seus dados, consulte [Compreender e usar dados de integração](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Dados métricos [#metrics]

Esta integração coleta dados do GCP para VertexAI.

### Dados do endpoint VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `prediction.online.accelerator.duty_cycle`
      </td>

      <td>
        Por cento
      </td>

      <td>
        Fração média de tempo durante o período de amostragem anterior durante o qual o(s) acelerador(es) estavam processando ativamente.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.accelerator.memory.bytes_used`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Quantidade de memória aceleradora alocada pela réplica do modelo implantar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.error_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de erros de previsão online.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.memory.bytes_used`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Quantidade de memória alocada pela réplica do modelo implantar e atualmente em uso.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.received_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Número de bytes recebidos na rede pela réplica do modelo implantado.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.sent_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Número de bytes enviados pela rede pela réplica do modelo implantado.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de previsões online.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_latencies`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        Latência de predição online do modelo implantar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.private.prediction_latencies`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        Latência de predição online do modelo implantar privado.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.replicas`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de réplicas ativas utilizadas pelo modelo implantar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.response_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de diferentes códigos de resposta de previsão online.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.target_replicas`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número destino de réplicas ativas necessárias para o modelo implantar.
      </td>
    </tr>
  </tbody>
</table>

### Dados do VertexAI Featurestore

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featurestore.cpu_load`
      </td>

      <td>
        Por cento
      </td>

      <td>
        A carga média da CPU para um nó no armazenamento online do Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.cpu_load_hottest_node`
      </td>

      <td>
        Por cento
      </td>

      <td>
        A carga da CPU para o nó mais quente no armazenamento online do Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.node_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        O número de nós para o armazenamento online do Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_entities_updated`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de entidade atualizado no armazenamento online da Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.latencies`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        Latência de serviço on-line por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Tamanho da solicitação por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Contagem de serviços on-line do Featurestore por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.response_size`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Tamanho da resposta por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.billable_processed_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Número de bytes cobrados por dados offline processados.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.stored_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Bytes armazenados no Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_processed_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de solicitações de gravação de streaming processadas para armazenamento offline.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_write_delays`
      </td>

      <td>
        Segundos
      </td>

      <td>
        Tempo (em segundos) desde que a API de gravação é chamada até ser gravada no armazenamento offline.
      </td>
    </tr>
  </tbody>
</table>

### Dados VertexAI FeatureOnlineStore

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featureonlinestore.online_serving.request_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de contagem de veiculações por FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Servindo tamanho de resposta por FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_latencies`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        Latência de atendimento on-line pelo FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.running_sync`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        Número de sincronizações em execução em determinado momento.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_ages`
      </td>

      <td>
        Segundos
      </td>

      <td>
        Medida da idade dos dados de serviço em segundos.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_by_sync_time`
      </td>

      <td>
        Contar
      </td>

      <td>
        Detalhamento dos dados do Feature Online Store por timestamp sincronizado.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load`
      </td>

      <td>
        Por cento
      </td>

      <td>
        A carga média de CPU dos nós do Feature Online Store.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load_hottest_node`
      </td>

      <td>
        Por cento
      </td>

      <td>
        A carga de CPU do nó mais quente no Feature Online Store.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_nodes`
      </td>

      <td>
        Contar
      </td>

      <td>
        A quantidade de nós do Feature Online Store(Bigtable).
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.stored_bytes`
      </td>

      <td>
        Contar
      </td>

      <td>
        Bytes armazenados no Feature Online Store.
      </td>
    </tr>
  </tbody>
</table>

### Dados de localização da VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `online_prediction_requests_per_base_model`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de solicitações por modelo base.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.exceeded`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de tentativas de exceder o limite da métrica de cota.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.limit`
      </td>

      <td>
        Contar
      </td>

      <td>
        Limite atual na métrica de cota.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.usage`
      </td>

      <td>
        Contar
      </td>

      <td>
        Uso atual na métrica de cota.
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_jobs`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de trabalhos de pipeline sendo executados.
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_tasks`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de tarefas de pipeline sendo executadas.
      </td>
    </tr>
  </tbody>
</table>

### Dados do índice VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `matching_engine.stream_update.datapoint_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de pontos de dados inseridos ou removidos com êxito.
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.latencies`
      </td>

      <td>
        Milissegundos
      </td>

      <td>
        A latência entre o usuário recebe um UpsertDatapointsResponse ou RemoveDatapointsResponse e essa atualização entra em vigor.
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.request_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de solicitações de atualização de stream.
      </td>
    </tr>
  </tbody>
</table>

### Dados do trabalho do pipeline VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidade
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `pipelinejob.duration`
      </td>

      <td>
        Segundos
      </td>

      <td>
        Segundos de tempo de execução do trabalho do pipeline sendo executado (da criação ao fim).
      </td>
    </tr>

    <tr>
      <td>
        `pipelinejob/task_completed_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número total de tarefas de pipeline concluídas.
      </td>
    </tr>
  </tbody>
</table>