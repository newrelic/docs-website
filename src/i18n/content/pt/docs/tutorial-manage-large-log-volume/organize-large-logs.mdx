---
title: Organize sua grande ingestão log
metaDescription: Organize your logs into managable partitions and tag their attributes with logs parsing
freshnessValidatedDate: never
translationType: machine
---

Depois de decidir qual log ingerir e armazenar, é hora de organizar seu log. Provavelmente você ainda está ingerindo centenas de gigabytes ou dezenas de terabytes de log. Embora seja muito menos do que você tinha originalmente, você ainda terá muito trabalho ao tentar usá-los com eficácia.

Para resolver isso, agruparemos esses logs restantes em partições temáticas e analisaremos o log para extrair e tag atributos valiosos. Ao organizar seu log dessa maneira, você pode:

* Consulte para qualquer atributo dentro do seu log
* Gerencie partições específicas de cada vez, como log de front-end versus log de back-end
* Reduza o tempo de carregamento das consultas

## Por que particionar seu log

Você pode obter melhorias significativas de desempenho com o uso adequado de partições de dados. Organizar seus dados em partições discretas permite que você consulte apenas os dados necessários. Você pode consultar uma única partição ou uma lista de partições separadas por vírgulas. Os objetivos do particionamento de seus dados devem ser:

* Crie partições de dados que se alinhem às categorias em seu ambiente ou organização que são estáticas ou mudam com pouca frequência (por exemplo, por unidade de negócios, equipe, ambiente, serviço, etc.).
* Crie partições para otimizar o número de eventos que devem ser escaneados para sua consulta mais comum. Não há uma regra estabelecida, mas geralmente, quando o evento de log escaneado ultrapassa 500 milhões (especialmente mais de 1 bilhão) para sua `common` consulta, você pode considerar ajustar seu particionamento.

O namespace de uma partição determina seu período de retenção. Oferecemos duas opções de retenção:

* <DNT>**Standard:**</DNT> A retenção padrão da conta determinada pela sua assinatura do New Relic. Este é o período máximo de retenção disponível na sua conta e é o namespace que você selecionará para a maioria das suas partições.
* <DNT>**Secondary:**</DNT> Retenção de 30 dias. Todos os logs enviados para uma partição que seja membro do namespace secundário serão expurgados continuamente 30 dias após terem sido ingeridos.

## Por que analisar o log

Analisar seus logs na ingestão é a melhor maneira de tornar seus dados log mais utilizáveis por você e por outros usuários em sua organização. Por exemplo, compare essas duas pré-análise e pós-análise de log usando uma regra de análise Grok:

<SideBySide>
  <Side>
    Pré-análise:

    ```json
    {
      "message": "32 4329 store_Portland"
    }


    ```
  </Side>

  <Side>
    Pós-análise:

    ```json
    {
      "transaction_total": "32",
      "purchase_number": "4329",
      "store_location": "store_Portland",
    }
    ```
  </Side>
</SideBySide>

Isso permite que você consulte facilmente atributos recém-definidos, como `transaction_total` no painel e alerta.

## Organize seu registro

Digamos que a ACME Corp saiba que ingerirá cerca de 2 TB de log nos próximos meses. Eles desejam criar partições para log proveniente de seu aplicativo Java e de seu agente de infraestrutura. Eles acham que talvez precisem consultar seu log Java no futuro, então decidem usar uma retenção padrão. Enquanto isso, eles só precisam de logs de infraestrutura recentes, portanto usarão retenção secundária para eles.

Para fazer isso:

<Steps>
  <Step>
    ## Navegue até a interface

    Vá para <DNT>**[one.newrelic.com &gt; Logs](https://one.newrelic.com/launcher/logger.log-launcher)**</DNT>
  </Step>

  <Step>
    ## Particione seu log

    <SideBySide>
      <Side>
        1. Em <DNT>**Manage data**</DNT> no painel de navegação esquerdo, clique em <DNT>**Data partitions**</DNT> e, em seguida, clique em <DNT>**Create partition rule**</DNT>.
        2. Defina um nome de partição como uma sequência alfanumérica que começa com `Log_`. Neste caso `Log_java`.
        3. Adicione uma descrição opcional.
        4. Selecione a retenção de namespace padrão para a partição.
        5. Defina os critérios de correspondência da sua regra: insira uma cláusula NRQL `WHERE` válida para corresponder ao log a ser armazenado nesta partição. Neste caso `logtype=java`.
        6. Clique em <DNT>**Create**</DNT> para salvar sua nova partição.
      </Side>

      <Side>
        <img title="log-partition" alt="An image displaying New Relic's log partion UI" src="/images/logs_screenshot_full-partition.webp" />
      </Side>
    </SideBySide>

    Isso cria uma partição de dados com retenção de dados padrão para todos os logs Java. Para organizar seu log de infraestrutura, você seguiria as mesmas etapas acima, alterando apenas a retenção para secundária e a consulta para `logtype=infrastructure`.
  </Step>

  <Step>
    ## Analise seu registro

    Agora que seu log está particionado, é hora de analisá-los. Analisá-los permite que você extraia dados relevantes de seu log para facilitar a consulta e a acessibilidade.

    Para analisar seu log:

    <SideBySide>
      <Side>
        1. Em <DNT>**Manage Data**</DNT> no painel de navegação esquerdo da interface de registro, clique em <DNT>**Parsing**</DNT> e, em seguida, clique em <DNT>**Create parsing rule**</DNT>.
        2. Insira um nome para a nova regra de análise.
        3. Selecione um campo existente para analisar (o padrão é `message`) ou insira um novo nome de campo.
        4. Insira uma cláusula NRQL `WHERE` válida para corresponder ao log que você deseja analisar.
        5. Selecione um log correspondente, se existir, ou clique na guia colar log para colar um log de amostra.
        6. Insira a regra de análise e confirme se ela está funcionando visualizando os resultados na seção <DNT>**Output**</DNT> . (Veja exemplo abaixo)
        7. Ative e salve a regra de análise personalizada.
      </Side>

      <Side>
        <img title="log-parsing" alt="An image displaying New Relic's log parsing UI" src="/images/logs_screenshot_full-parsing.webp" />
      </Side>
    </SideBySide>

    O exemplo a seguir orienta você em um exemplo específico de criação de uma regra de análise:

    <CollapserGroup>
      <Collapser id="example" title="Exemplo de análise de log">
        Vamos trabalhar com o exemplo que usamos anteriormente neste documento. Você tem log que segue este padrão:

        ```json
        {
          "message": "32 4329 store_Portland"
        }
        ```

        Você deseja retirar o valor da transação, o número do pedido e o local da loja. As regras de análise são criadas usando Grok, que usa o seguinte padrão: `%{SYNTAX:SEMANTIC}`. `SYNTAX` é o padrão usado para localizar o texto e `SEMANTIC` é o identificador ou atributo fornecido ao resultado correspondente.

        Nesse caso, nossa regra de análise seria semelhante a:

        ```
        %{INT:transaction_total} %{INT:purchase_number} store%{DATA:store_location}
        ```

        Depois que a regra de análise for criada com o padrão acima, ela retornará log da seguinte maneira:

        ```json
        {
          "transaction_total": "32",
          "purchase_number": "4329",
          "store_location": "store_Portland",
        }
        ```
      </Collapser>
    </CollapserGroup>

    Para uma visão mais aprofundada sobre a criação de padrões Grok para analisar logs, [leia nossa postagem no blog](https://newrelic.com/blog/how-to-relic/how-to-use-grok-log-parsing).
  </Step>
</Steps>

## Qual é o próximo

Parabéns por descobrir o verdadeiro valor do seu log e poupar horas de frustração à sua equipe com ele! À medida que o seu sistema cresce e você ingere, você precisará garantir a manutenção das regras e partições de análise. Se você estiver interessado em se aprofundar no que a New Relic <InlinePopover type="logs" />pode fazer por você, confira estes documentos:

* [Análise de dados log ](/docs/logs/ui-data/parsing): uma análise mais aprofundada da análise de logs com Grok e aprenda como criar, consultar e gerenciar suas regras de análise de log usando NerdGraph, nossa API GraphQL.
* [Padrões de log](/docs/logs/ui-data/find-unusual-logs-log-patterns/): Padrões de log são a maneira mais rápida de descobrir valor nos dados de log sem pesquisar.
* [ofuscação de logs](/docs/logs/ui-data/obfuscation-ui/): Com o log regra de ofuscação, você pode evitar que certos tipos de informações sejam salvas no New Relic.
* [Localizar dados em logs longos (blobs)](/docs/logs/ui-data/long-logs-blobs/): dados log extensos podem ajudá-lo a solucionar problemas. Mas e se um atributo no seu log contiver milhares de caracteres? Quanto desses dados a New Relic pode armazenar? E como você pode encontrar informações úteis em todos esses dados?

<DocTiles numbered>
  <DocTile title="Get started" path="/docs/tutorial-large-logs/get-started-managing-large-logs" />

  <DocTile title="Filter and reduce your log ingest" path="/docs/tutorial-large-logs/filter-large-logs" />

  <DocTile title="Organize your logs" label={{text: 'You are here', color: '#FCD672'}} path="/docs/tutorial-large-logs/organize-large-logs" />
</DocTiles>