---
title: Organize sua grande ingestão log
metaDescription: Organize your logs into managable partitions and tag their attributes with logs parsing
freshnessValidatedDate: never
translationType: machine
---

Depois de decidir qual log ingerir e armazenar, é hora de organizar seu log. Provavelmente você ainda está ingerindo centenas de gigabytes ou dezenas de terabytes de log. Embora seja muito menos do que você tinha originalmente, você ainda terá muito trabalho ao tentar usá-los com eficácia.

Para resolver isso, agruparemos esses logs restantes em partições temáticas e analisaremos o log para extrair e tag atributos valiosos. Ao organizar seu log dessa maneira, você pode:

* Consulte para qualquer atributo dentro do seu log
* Gerencie partições específicas de cada vez, como log de front-end versus log de back-end
* Reduza o tempo de carregamento das consultas

## Por que particionar seu log

Separar seu log em partições discretas pode melhorar o desempenho e facilitar o gerenciamento do seu log. Por exemplo, imagine que você deseja consultar um atributo encontrado apenas no log do frontend. Consultar 5 TB de log levará muito mais tempo do que consultar uma partição específica de 1 TB apenas de log de front-end.

Os objetivos de particionar seus dados:

* Crie partições de dados que se alinhem com conceitos estáticos ou que mudam com pouca frequência em seu ambiente ou organização (por exemplo, por unidade de negócios, equipe, ambiente, serviço, etc.).
* Certifique-se de que cada partição permaneça abaixo de 1 TB de ingestão diária para obter o desempenho ideal.

Existem dois tipos de retenção para partições. Escolha <DNT>**Standard**</DNT> para retenção máxima; use isso para dados valiosos que você pode querer consultar no futuro. Escolha <DNT>**Secondary**</DNT> para retenção de 30 dias; use isso para dados menos valiosos ou para dados que você precisará apenas em um futuro próximo.

## Por que analisar o log

Analisar seus logs na ingestão é a melhor maneira de tornar seus dados log mais utilizáveis por você e por outros usuários em sua organização. Por exemplo, compare essas duas pré-análise e pós-análise de log usando uma regra de análise Grok:

<SideBySide>
  <Side>
    Pré-análise:

    ```
    {
        "message": "32 4329 store_Portland"
    }
    ```
  </Side>

  <Side>
    Pós-análise:

    ```
    {
        "transaction_total": "32",
        "purchase_number": "4329",
        "store_location": "store_Portland",
    }
    ```
  </Side>
</SideBySide>

Isso permite que você consulte facilmente atributos recém-definidos, como `transaction_total` no painel e alerta.

## Organize seu registro

Digamos que a ACME Corp saiba que ingerirá cerca de 2 TB de log nos próximos meses. Eles desejam criar partições para log proveniente de seu aplicativo Java e de seu agente de infraestrutura. Eles acham que talvez precisem consultar seu log Java no futuro, então decidem usar uma retenção padrão. Enquanto isso, eles só precisam de logs de infraestrutura recentes, portanto usarão retenção secundária para eles.

Para fazer isso:

<Steps>
  <Step>
    ## Navegue até a interface

    Vá para <DNT>**[one.newrelic.com > Logs](https://one.newrelic.com/launcher/logger.log-launcher)**</DNT>
  </Step>

  <Step>
    ## Particione seu log

    <SideBySide>
      <Side>
        1. Em

           <DNT>
             **Manage data**
           </DNT>

           no painel de navegação esquerdo, clique em

           <DNT>
             **Data partitions**
           </DNT>

           e, em seguida, clique em

           <DNT>
             **Create partition rule**
           </DNT>

           .

        2. Defina um nome de partição como uma sequência alfanumérica que começa com `Log_`. Neste caso `Log_java`.

        3. Adicione uma descrição opcional.

        4. Selecione a retenção de namespace padrão para a partição.

        5. Defina os critérios de correspondência da sua regra: insira uma cláusula NRQL `WHERE` válida para corresponder ao log a ser armazenado nesta partição. Neste caso `logtype=java`.

        6. Clique em

           <DNT>
             **Create**
           </DNT>

           para salvar sua nova partição.
      </Side>

      <Side>
        <img
          title="log-partition"
          alt="An image displaying New Relic's log partion UI"
          src="/images/logs_screenshot_full-partition.webp"
        />
      </Side>
    </SideBySide>

    Isso cria uma partição de dados com retenção de dados padrão para todos os logs Java. Para organizar seu log de infraestrutura, você seguiria as mesmas etapas acima, alterando apenas a retenção para secundária e a consulta para `logtype=infrastructure`.
  </Step>

  <Step>
    ## Analise seu registro

    Agora que seu log está particionado, é hora de analisá-los. Analisá-los permite que você extraia dados relevantes de seu log para facilitar a consulta e a acessibilidade.

    Para analisar seu log:

    <SideBySide>
      <Side>
        1. Em

           <DNT>
             **Manage Data**
           </DNT>

           no painel de navegação esquerdo da interface de registro, clique em

           <DNT>
             **Parsing**
           </DNT>

           e, em seguida, clique em

           <DNT>
             **Create parsing rule**
           </DNT>

           .

        2. Insira um nome para a nova regra de análise.

        3. Selecione um campo existente para analisar (o padrão é `message`) ou insira um novo nome de campo.

        4. Insira uma cláusula NRQL `WHERE` válida para corresponder ao log que você deseja analisar.

        5. Selecione um log correspondente, se existir, ou clique na guia colar log para colar um log de amostra.

        6. Insira a regra de análise e confirme se ela está funcionando visualizando os resultados na seção

           <DNT>
             **Output**
           </DNT>

           . (Veja exemplo abaixo)

        7. Ative e salve a regra de análise personalizada.
      </Side>

      <Side>
        <img
          title="log-parsing"
          alt="An image displaying New Relic's log parsing UI"
          src="/images/logs_screenshot_full-parsing.webp"
        />
      </Side>
    </SideBySide>

    O exemplo a seguir orienta você em um exemplo específico de criação de uma regra de análise:

    <CollapserGroup>
      <Collapser
        id="example"
        title="Exemplo de análise de log"
      >
        Vamos trabalhar com o exemplo que usamos anteriormente neste documento. Você tem log que segue este padrão:

        ```
        {
            "message": "32 4329 store_Portland"
        }
        ```

        Você deseja retirar o valor da transação, o número do pedido e o local da loja. As regras de análise são criadas usando Grok, que usa o seguinte padrão: `%{SYNTAX:SEMANTIC}`. `SYNTAX` é o padrão usado para localizar o texto e `SEMANTIC` é o identificador ou atributo fornecido ao resultado correspondente.

        Nesse caso, nossa regra de análise seria semelhante a:

        ```
        %{INT:transaction_total} %{INT:purchase_number} store%{DATA:store_location}
        ```

        Depois que a regra de análise for criada com o padrão acima, ela retornará log da seguinte maneira:

        ```
        {
            "transaction_total": "32",
            "purchase_number": "4329",
            "store_location": "store_Portland",
        }
        ```
      </Collapser>
    </CollapserGroup>

    Para uma visão mais aprofundada sobre a criação de padrões Grok para analisar logs, [leia nossa postagem no blog](https://newrelic.com/blog/how-to-relic/how-to-use-grok-log-parsing).
  </Step>
</Steps>

## Qual é o próximo

Parabéns por descobrir o verdadeiro valor do seu log e poupar horas de frustração à sua equipe com ele! À medida que o seu sistema cresce e você ingere, você precisará garantir a manutenção das regras e partições de análise. Se você estiver interessado em se aprofundar no que a New Relic <InlinePopover type="logs"/>pode fazer por você, confira estes documentos:

* [Análise de dados log ](/docs/logs/ui-data/parsing): uma análise mais aprofundada da análise de logs com Grok e aprenda como criar, consultar e gerenciar suas regras de análise de log usando NerdGraph, nossa API GraphQL.
* [Padrões de log](/docs/logs/ui-data/find-unusual-logs-log-patterns/): Padrões de log são a maneira mais rápida de descobrir valor nos dados de log sem pesquisar.
* [ofuscação de logs](/docs/logs/ui-data/obfuscation-ui/): Com o log regra de ofuscação, você pode evitar que certos tipos de informações sejam salvas no New Relic.
* [Localizar dados em logs longos (blobs)](/docs/logs/ui-data/long-logs-blobs/): dados log extensos podem ajudá-lo a solucionar problemas. Mas e se um atributo no seu log contiver milhares de caracteres? Quanto desses dados a New Relic pode armazenar? E como você pode encontrar informações úteis em todos esses dados?

<DocTiles numbered>
  <DocTile
    title="Get started"
    path="/docs/tutorial-large-logs/get-started-managing-large-logs"
  />

  <DocTile
    title="Filter and reduce your log ingest"
    path="/docs/tutorial-large-logs/filter-large-logs"
  />

  <DocTile
    title="Organize your logs"
    label={{text: 'You are here', color: '#FCD672'}}
    path="/docs/tutorial-large-logs/organize-large-logs"
  />
</DocTiles>
