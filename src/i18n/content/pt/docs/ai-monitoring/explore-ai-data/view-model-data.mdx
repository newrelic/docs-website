---
title: Analisar dados do modelo
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: '2024-06-12T00:00:00.000Z'
translationType: machine
---

AI Monitoring apresenta dados sobre seu modelo de IA para que você possa analisar o desempenho do modelo de IA junto com o desempenho do aplicativo de IA. Você pode encontrar dados sobre o seu modelo de IA em duas áreas:

* <DNT>
    **Model inventory**
  </DNT>

  : Uma visão centralizada que mostra dados de desempenho e conclusão de todos os modelos de IA da sua conta. Isole o uso token , acompanhe o desempenho geral ou analise as conclusões individuais feitas por seus modelos.

* <DNT>
    **Compare models**
  </DNT>

  : Conduza análises comparativas de desempenho entre dois modelos ao longo do tempo. Esta página exibe dados para análise agregada do desempenho do seu modelo ao longo do tempo.

<img
  title="Model data overview"
  alt="A screenshot of the model inventory page"
  src="/images/ai_screenshot-crop_intro-to-model-data.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring</DNT>**: no AI Monitoring, você pode escolher entre inventário de modelo ou comparação de modelo.
</figcaption>

## Página de inventário de modelo [#model-inventory]

<img
  title="Model inventory overview"
  alt="A screenshot of the overview page when you go to Model inventory"
  src="/images/ai_screenshot-full_model-inventory-overview-page.webp"
/>

<figcaption>
  Acesse **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory</DNT>**: Visualize dados sobre interação com seu modelo de IA.
</figcaption>

A página <DNT>model inventory</DNT> fornece insights sobre o desempenho geral e o uso do seu modelo de IA. Você pode analisar dados de chamadas feitas ao seu modelo para entender como o modelo de IA afeta seu aplicativo de IA.

Na guia de visão geral, explore o número de solicitações feitas a um modelo em relação ao seu ritmo de resposta ou analise gráficos de séries temporais para ver quando o comportamento do modelo mudou. A partir daí, investigue as guias de erros, desempenho ou custo.

### Guia Erros [#errors-inventory]

<img
  title="Model inventory: Errors"
  alt="A screenshot of the Errors time series and chart"
  src="/images/ai_screenshot-crop_model-inventory-errors.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Errors</DNT>**: visualizar dados sobre erros do modelo de IA.
</figcaption>

A guia de erros usa gráficos e tabelas de séries temporais para organizar os erros do modelo.

* <DNT>
    **Response errors**
  </DNT>

  : Acompanhe o número de erros agregados provenientes do seu modelo de IA.

* <DNT>
    **Response errors by model**
  </DNT>

  : Determine se um modelo específico produz mais erros em média ou se um erro específico está ocorrendo em seus modelos.

* <DNT>
    **Response errors by type**
  </DNT>

  : Veja com que frequência determinados erros aparecem.

* <DNT>
    **Errors table**
  </DNT>

  : Visualize o tipo de erro e a mensagem no contexto da solicitação e da resposta.

### Guia desempenho [#performance-inventory]

<img
  title="Model inventory: Performance"
  alt="A screenshot of the Errors time series and chart"
  src="/images/ai_screenshot-crop_model-inventory-performance-page.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Performance</DNT>**: visualize dados sobre o desempenho do seu modelo de IA.
</figcaption>

A guia desempenho agrega métricas de resposta e solicitação em todos os seus modelos. Visão geral dos modelos que levam mais tempo para processar uma solicitação ou criar uma resposta com os gráficos de pizza, ou consulte os gráficos de série temporal para rastrear aumentos na solicitação ou no tempo de resposta. Você pode usar gráficos de desempenho para localizar valores discrepantes em seus modelos.

### Guia Custo [#cost-inventory]

<img
  title="Model inventory: Performance"
  alt="A screenshot of the Errors time series and chart"
  src="/images/ai_screenshot-crop_model-inventory-cost.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Cost</DNT>**: visualize dados sobre o custo do seu modelo de IA.
</figcaption>

A guia de custo usa uma combinação de gráficos de série temporal e gráficos de pizza para identificar fatores de custo entre seus modelos. Determine o número de tokens provenientes de prompts ou conclusões ou se determinados modelos custam mais, em média, do que outros.

* <DNT>
    **Tokens used and token limit**
  </DNT>

  : Avalie com que frequência seus modelos se aproximam de um determinado limite de token.

* <DNT>
    **Total tokens by models**
  </DNT>

  : Determine quais dos seus modelos usam mais token em média.

* <DNT>
    **Total usage by prompt and completion tokens**
  </DNT>

  : Entenda qual proporção de token vem do prompt que seu modelo aceita em relação ao token usado por conclusão.

Compreender o custo permite que você melhore a forma como seu aplicativo de IA usa um ou mais de seus modelos para que seu conjunto de ferramentas de IA seja mais econômico.

## Página de comparação de modelos [#model-comparison]

<img
  title="Model inventory overview"
  alt="A screenshot of the overview page when you go to Model inventory"
  src="/images/ai_screenshot-full_ai-model-comparison-page.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DNT>**: compare dados sobre os diferentes modelos de IA em sua stack.
</figcaption>

A página de comparação de modelos organiza seus dados AI Monitoring para ajudá-lo a realizar análises comparativas. Esta página define o escopo dos dados de comparação de modelos para uma única conta, fornecendo dados agregados sobre custo e desempenho do modelo em um ou mais aplicativos. Para gerar dados:

1. Escolha seus modelos no menu suspenso.
2. Defina o escopo de um serviço para ver o desempenho no contexto de um aplicativo específico ou mantenha a consulta em `Service = All` para ver como um modelo se comporta em média.
3. Escolha o parâmetro de tempo. Essa ferramenta é flexível: você pode fazer comparações entre diferentes períodos, o que permite ver como o desempenho ou o custo mudaram antes e depois de uma implantação.

### Compare o desempenho do modelo [#compare-performance]

<img
  title="Model comparison page: Performance"
  alt="A screenshot of model comparison"
  src="/images/ai_screenshot-crop_model-comparison-performance.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DNT>**: Compare o desempenho entre diferentes modelos de IA em sua stack.
</figcaption>

Para começar a realizar análises comparativas, escolha um serviço, modelo e intervalo de tempo específicos. Ao comparar modelos, você pode avaliar diferentes métricas agregadas ao longo do tempo, dependendo de suas próprias configurações. Aqui estão alguns exemplos de casos de uso para análise comparativa:

* **Compare dois modelos no mesmo serviço**: O serviço X usa o modelo A durante a primeira semana, mas depois usa o modelo B na segunda semana. Você pode comparar o desempenho escolhendo o serviço X, selecionando o modelo A e definindo as datas para a primeira semana. No segundo lado, escolha o serviço X, selecione o modelo B e defina as datas para a segunda semana.
* **Compare o desempenho de um modelo ao longo do tempo**: selecione o serviço X, selecione o modelo A e defina as datas para a primeira semana. No segundo lado, escolha o serviço X, selecione o modelo A e defina as datas para a segunda semana.
* **Avalie o desempenho do modelo em dois serviços diferentes**: Você tem dois aplicativos diferentes que usam dois modelos diferentes. Para comparar o total de tokens do último mês, escolha o parâmetro relevante para o serviço específico e modelos específicos e, a seguir, defina as datas para o mesmo período de tempo.
* **Compare dois modelos**: você tem um aplicativo que usa o modelo A e deseja medir o modelo A em relação ao modelo B. Para cada prompt do usuário, você chama o modelo B como um processo em segundo plano. Compare o desempenho do modelo A em relação ao modelo B no mesmo serviço durante o mesmo período.

### Compare o custo do modelo [#compare-cost]

<img
  title="Model comparison page: Cost"
  alt="A screenshot of model comparison"
  src="/images/ai_screenshot-crop_model-comparison-cost.webp"
/>

<figcaption>
  Vá para **<DNT>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DNT>**: compare o custo entre os diferentes modelos de IA em sua stack.
</figcaption>

A coluna de custo do modelo divide o evento de conclusão em duas partes: o prompt dado ao modelo e a resposta final que o modelo entrega ao usuário final.

* <DNT>
    **Tokens per completion**
  </DNT>

  : A média token para todos os eventos de conclusão.

* <DNT>
    **Prompt tokens**
  </DNT>

  : A média token para prompt. Essa média token inclui o prompt criado pelo prompt engenheiro e pelo usuário final.

* <DNT>
    **Completion tokens**
  </DNT>

  : Quantidade de token consumido pelo modelo quando ele gera a resposta entregue ao usuário final.

Ao analisar esta coluna, o valor do token de conclusão e do token de prompt deve ser igual ao valor do token por conclusão.

## Qual é o próximo? [#whats-next]

Agora que você sabe como encontrar seus dados, pode explorar outros recursos que AI Monitoring tem a oferecer.

* Quer analisar o desempenho do seu aplicativo de IA? Confira nosso documento sobre [as páginas de resposta do aplicativo AI](/docs/ai-monitoring/explore-ai-data/view-ai-responses).
* Preocupado com informações confidenciais? [Aprenda a configurar filtros de queda](/docs/ai-monitoring/drop-sensitive-data).
* Se você quiser encaminhar informações de feedback do usuário sobre as respostas de IA do seu aplicativo para New Relic, siga nossos procedimentos para [atualizar o código do seu aplicativo para obter feedback do usuário na interface](/docs/ai-monitoring/customize-agent-ai-monitoring).
