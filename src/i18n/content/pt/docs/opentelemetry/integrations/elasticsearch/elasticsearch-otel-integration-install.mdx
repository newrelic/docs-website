---
title: Instale a integração Elasticsearch OpenTelemetry
tags:
  - OpenTelemetry
  - Elasticsearch
  - Integrations
metaDescription: Install and configure the OpenTelemetry Collector to monitor Elasticsearch clusters and send data to New Relic.
freshnessValidatedDate: never
translationType: machine
---

Instale a integração New Relic Elasticsearch OpenTelemetry para monitorar seus clusters Elasticsearch com protocolos padrão da indústria. Este guia orienta você na configuração do OpenTelemetry Collector para coletar métricas e logs de sua infraestrutura Elasticsearch e enviá-los para a New Relic.

Para instalar a integração, complete as seguintes etapas:

1. [Antes de começar](#prerequisites) - Verifique os requisitos e pré-requisitos
2. [Configure o OpenTelemetry Collector](#config) - Configure a coleta de dados
3. [Definir variáveis de ambiente](#start) - Configurar autenticação
4. [Encontre e use dados](#find-and-use) - Visualize seus dados do Elasticsearch no New Relic
5. [Configurar alertas](#alerts) - Configure o monitoramento proativo

## Passo 1: Antes de começar [#prerequisites]

Certifique-se de ter:

* **Privilégios de acesso necessários** - privilégios de administrador do cluster Elasticsearch e conta New Relic com acesso<InlinePopover type="licenseKey" />

* **Elasticsearch versão 7.16 ou superior** - Esta integração requer um cluster Elasticsearch moderno

* **Monitorar ou gerenciar privilégios do cluster** - Se a segurança estiver ativada, você precisará do privilégio de monitorar ou gerenciar o cluster. Consulte a documentação [Elasticsearch security privileges](https://www.elastic.co/docs/reference/elasticsearch/security-privileges) para obter mais detalhes

* **Conectividade de rede** - Conectividade HTTPS de saída (porta 443) para o [endpoint de ingestão OTLP da New Relic](/docs/opentelemetry/best-practices/opentelemetry-otlp)

* **OpenTelemetry Collector** - Você deve ter um OpenTelemetry Collector instalado e em execução no seu host para monitorar o Elasticsearch. Existem duas distribuições suportadas:

  * **NRDOT (Recomendado):** Siga o [guia oficial de instalação do NRDOT](/docs/opentelemetry/nrdot/nrdot-collector/) para configurar o coletor no seu host.
  * **OTel Contrib:** [OpenTelemetry Collector Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/latest) instalado e em execução no seu host. Instale via um pacote oficial (.deb ou .rpm) para garantir que a unidade de serviço do systemd seja criada corretamente.

* **Valores de configuração prontos** - Você precisará de dois valores-chave para a configuração:

  * **Endpoint do Elasticsearch** - Seu URL real do Elasticsearch (substitua `https://localhost:9200`)
  * **Nome do cluster** - Um nome exclusivo para identificar seu cluster no New Relic

<Callout variant="tip">
  Recomendamos fortemente o uso da **NRDOT (New Relic Distribution of OpenTelemetry)** em vez da versão padrão da comunidade. Como um componente de propriedade da New Relic, é:

  * **Otimizado:** Pré-configurado para o máximo desempenho com o backend da New Relic.
  * **Confiável:** Extensivamente testado para estabilidade e segurança corporativas.
  * **Suportado:** Totalmente apoiado pelas equipes de suporte da New Relic para uma solução de problemas mais rápida.
</Callout>

## Etapa 2: Configurar o OpenTelemetry Collector [#config]

Para configurar a coleta de métricas e logs do seu cluster Elasticsearch, crie ou atualize o arquivo de configuração em /etc/nrdot-collector/config.yaml para o NRDOT ou /etc/otelcol-contrib/config.yaml para o Collector Contrib.

A configuração varia com base na sua configuração do Elasticsearch e nos requisitos de monitoramento. Escolha a configuração apropriada abaixo:

<CollapserGroup>
  <Collapser id="basic-config" title="Configuração básica de métricas">
    **Comece aqui se você tiver:** Um cluster Elasticsearch não seguro sem autenticação ou SSL.

    Esta configuração coleta métricas abrangentes do Elasticsearch e do sistema host sem autenticação:

    <Callout variant="important">
      Substitua o valor `endpoint` pelo endpoint do seu cluster Elasticsearch e atualize `elasticsearch.cluster.name` no bloco do processador com um nome exclusivo para identificar seu cluster na New Relic.
    </Callout>

    ```yaml
    # =================================================================================================
    # OpenTelemetry Collector Configuration for Elasticsearch and Host
    # This configuration collects metrics and logs for a complete observability solution.
    # =================================================================================================
    # -------------------------------------------------------------------------------------------------
    # Receivers
    # Receivers define how data gets into the Collector. This config uses four receivers:
    # - elasticsearch: to scrape metrics from the Elasticsearch API
    # - hostmetrics: to collect system-level metrics from the host itself
    # - filelog: to tail Elasticsearch log files
    # -------------------------------------------------------------------------------------------------
    receivers:
      elasticsearch:
        endpoint: "http://localhost:9200"
        collection_interval: 15s
        metrics:
          elasticsearch.os.cpu.usage:
            enabled: true
          elasticsearch.cluster.data_nodes:
            enabled: true
          elasticsearch.cluster.health:
            enabled: true
          elasticsearch.cluster.in_flight_fetch:
            enabled: true
          elasticsearch.cluster.nodes:
            enabled: true
          elasticsearch.cluster.pending_tasks:
            enabled: true
          elasticsearch.cluster.shards:
            enabled: true
          elasticsearch.cluster.state_update.time:
            enabled: true
          elasticsearch.index.documents:
            enabled: true
          elasticsearch.index.operations.merge.current:
            enabled: true
          elasticsearch.index.operations.time:
            enabled: true
          elasticsearch.node.cache.count:
            enabled: true
          elasticsearch.node.cache.evictions:
            enabled: true
          elasticsearch.node.cache.memory.usage:
            enabled: true
          elasticsearch.node.shards.size:
            enabled: true
          elasticsearch.node.cluster.io:
            enabled: true
          elasticsearch.node.documents:
            enabled: true
          elasticsearch.node.disk.io.read:
            enabled: true
          elasticsearch.node.disk.io.write:
            enabled: true
          elasticsearch.node.fs.disk.available:
            enabled: true
          elasticsearch.node.fs.disk.total:
            enabled: true
          elasticsearch.node.http.connections:
            enabled: true
          elasticsearch.node.ingest.documents.current:
            enabled: true
          elasticsearch.node.ingest.operations.failed:
            enabled: true
          elasticsearch.node.open_files:
            enabled: true
          elasticsearch.node.operations.completed:
            enabled: true
          elasticsearch.node.operations.current:
            enabled: true
          elasticsearch.node.operations.get.completed:
            enabled: true
          elasticsearch.node.operations.time:
            enabled: true
          elasticsearch.node.shards.reserved.size:
            enabled: true
          elasticsearch.index.shards.size:
            enabled: true
          elasticsearch.os.cpu.load_avg.1m:
            enabled: true
          elasticsearch.os.cpu.load_avg.5m:
            enabled: true
          elasticsearch.os.cpu.load_avg.15m:
            enabled: true
          elasticsearch.os.memory:
            enabled: true
          jvm.gc.collections.count:
            enabled: true
          jvm.gc.collections.elapsed:
            enabled: true
          jvm.memory.heap.max:
            enabled: true
          jvm.memory.heap.used:
            enabled: true
          jvm.memory.heap.utilization:
            enabled: true
          jvm.threads.count:
            enabled: true
          elasticsearch.index.segments.count:
            enabled: true
          elasticsearch.index.operations.completed:
            enabled: true
          elasticsearch.node.script.cache_evictions:
            enabled: false
          elasticsearch.node.cluster.connections:
            enabled: false
          elasticsearch.node.pipeline.ingest.documents.preprocessed:
            enabled: false
          elasticsearch.node.thread_pool.tasks.queued:
            enabled: false
          elasticsearch.cluster.published_states.full:
            enabled: false
          jvm.memory.pool.max:
            enabled: false
          elasticsearch.node.script.compilation_limit_triggered:
            enabled: false
          elasticsearch.node.shards.data_set.size:
            enabled: false
          elasticsearch.node.pipeline.ingest.documents.current:
            enabled: false
          elasticsearch.cluster.state_update.count:
            enabled: false
          elasticsearch.node.fs.disk.free:
            enabled: false
          jvm.memory.nonheap.used:
            enabled: false
          jvm.memory.pool.used:
            enabled: false
          elasticsearch.node.translog.size:
            enabled: false
          elasticsearch.node.thread_pool.threads:
            enabled: false
          elasticsearch.cluster.state_queue:
            enabled: false
          elasticsearch.node.translog.operations:
            enabled: false
          elasticsearch.memory.indexing_pressure:
            enabled: false
          elasticsearch.node.ingest.documents:
            enabled: false
          jvm.classes.loaded:
            enabled: false
          jvm.memory.heap.committed:
            enabled: false
          elasticsearch.breaker.memory.limit:
            enabled: false
          elasticsearch.indexing_pressure.memory.total.replica_rejections:
            enabled: false
          elasticsearch.breaker.memory.estimated:
            enabled: false
          elasticsearch.cluster.published_states.differences:
            enabled: false
          jvm.memory.nonheap.committed:
            enabled: false
          elasticsearch.node.translog.uncommitted.size:
            enabled: false
          elasticsearch.node.script.compilations:
            enabled: false
          elasticsearch.node.pipeline.ingest.operations.failed:
            enabled: false
          elasticsearch.indexing_pressure.memory.limit:
            enabled: false
          elasticsearch.breaker.tripped:
            enabled: false
          elasticsearch.indexing_pressure.memory.total.primary_rejections:
            enabled: false
          elasticsearch.node.thread_pool.tasks.finished:
            enabled: false
      hostmetrics:
        collection_interval: 60s # Recommended for cost savings and stability
        scrapers:
          cpu:
            metrics:
              # CPU Utilization and Time are the core metrics
              system.cpu.utilization: {enabled: true}
              system.cpu.time: {enabled: true}
          load:
            metrics:
              # Load Averages (used for system health dashboards)
              system.cpu.load_average.1m: {enabled: true}
              system.cpu.load_average.5m: {enabled: true}
              system.cpu.load_average.15m: {enabled: true}
          memory:
            metrics:
              # Memory Usage and Utilization
              system.memory.usage: {enabled: true}
              system.memory.utilization: {enabled: true}
          disk:
            metrics:
              # Disk I/O operations (throughput)
              system.disk.io: {enabled: true}
              system.disk.operations: {enabled: true}
          filesystem:
            metrics:
              # Filesystem usage (disk space capacity)
              system.filesystem.usage: {enabled: true}
              system.filesystem.utilization: {enabled: true} 
          network:
            # Since this was already working, keeping it simple is best.
            # But for completeness:
            metrics:
              system.network.io: {enabled: true}
              system.network.packets: {enabled: true}
          process:
               metrics:
                 process.cpu.utilization:
                   enabled: true
    # -------------------------------------------------------------------------------------------------
    # Processors
    # -------------------------------------------------------------------------------------------------
    processors:
      # used to prevent out of memory situations on the collector
      memory_limiter:
        check_interval: 60s
        limit_mib: ${env:NEW_RELIC_MEMORY_LIMIT_MIB:-100}
      cumulativetodelta: {}
      resource/cluster_name_override:
        attributes:
          # Use the actual cluster name defined in your Elasticsearch config
          - key: elasticsearch.cluster.name
            value: "<elasticsearch-cluster-name>" # <-- REPLACE THIS WITH A UNIQUE CLUSTER NAME TO UNIQUELY IDENTIFY YOUR CLUSTER IN NEW RELIC 
            action: upsert
      # This processor adds resource attributes to all telemetry data.
      # 'service.name' is crucial for creating an entity in New Relic.
      resourcedetection:
        detectors: [ system ]
        system:
          resource_attributes:
            host.name:
              enabled: true
            host.id:
              enabled: true
            os.type:
              enabled: true 
      # This processor batches data for more efficient sending.
      batch:
        timeout: 10s
        send_batch_size: 1024
      # 1. CARDINALITY REDUCTION: Drops volatile or redundant attributes
      attributes/cardinality_reduction:
        actions:
          # Filter out VOLATILE PROCESS IDS (High churn)
          - key: process.pid
            action: delete
          - key: process.parent_pid
            action: delete
      transform/metadata_nullify:
        # We use 'metric_statements' to run OTTL logic on the metric signal
        metric_statements:
          - context: metric  # <-- Targets the high-level Metric structure itself
            statements:
              # Sets the 'description' field to an empty string ("")
              - set(description, "")
              # Sets the 'unit' field to an empty string ("")
              - set(unit, "")      
    exporters:
      # This exporter sends all data to New Relic via OTLP/HTTP.
      otlphttp:
        endpoint: ${env:NEWRELIC_OTLP_ENDPOINT}
        headers:
          api-key: ${env:NEWRELIC_LICENSE_KEY}
    # -------------------------------------------------------------------------------------------------
    # Service
    # The service block defines the pipelines.
    # -------------------------------------------------------------------------------------------------
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [memory_limiter, resourcedetection, resource/cluster_name_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [memory_limiter, resourcedetection,batch]
          exporters: [otlphttp]
    ```
  </Collapser>

  <Collapser id="secure-config" title="Configuração de autenticação e SSL">
    **Use isto se você tiver:** Um cluster Elasticsearch seguro com autenticação e/ou certificados SSL.

    Adicione as credenciais de autenticação e a configuração SSL à configuração básica acima:

    ```yaml
    receivers:
      elasticsearch:
        endpoint: "https://localhost:9200"
        username: "elastic"
        password: "your_password"
        tls:
          ca_file: "/etc/elasticsearch/certs/http_ca.crt"
          insecure_skip_verify: false
        collection_interval: 15s
    ```
  </Collapser>

  <Collapser id="logging-config" title="Habilitar logs (receptor filelog)">
    **Opcional:** Inclua isso se você quiser enviar arquivos de log do Elasticsearch para a New Relic, além das métricas.

    Adicione a configuração do receptor `filelog` para coletar e encaminhar logs do Elasticsearch. Certifique-se de que o usuário que executa o serviço do coletor (por exemplo, nrdot-collector ou otelcol-contrib) tenha acesso de leitura aos seus arquivos de log do Elasticsearch.

    ###### Se estiver executando o Elasticsearch no Linux (Host):

    ```yaml
    receivers:
      filelog:
        include:
          - /var/log/elasticsearch/elasticsearch.log #Replace with path of the elasticsearch log file.
          - /var/log/elasticsearch/*.log             #We can send multiple log files using regex.
    ```

    ###### Se estiver executando o Elasticsearch no Docker:

    ```yaml
    receivers:
      filelog:
        include:
          - /var/lib/docker/containers/*/*.log       # Replace with the container log file path. 
        operators:
          - type: move
            from: attributes.log
            to: body
    ```

    ###### Adicione o receptor filelog no pipeline de serviço:

    ```yaml
    service:
      pipelines:
        logs:
          receivers: [filelog]
          processors: [resource/cluster_name_override]
          exporters: [otlphttp]
    ```
  </Collapser>

  <Collapser id="custom-attributes" title="Adicionar metadados personalizados">
    **Opcional:** Inclua isso se quiser marcar seus dados com atributos personalizados como ambiente, equipe ou região.

    Use o processador `resource/static_override` para adicionar tags de metadados personalizados a todas as suas métricas:

    ```yaml
    processors:
      resource/static_override:
        attributes:
          - key: env
            value: "production"
            action: upsert
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [resourcedetection, resource/cluster_name_override, resource/static_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [resourcedetection, resource/static_override, batch]
          exporters: [otlphttp]        

    ```
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  **Correlacione APM com Elasticsearch**: Para conectar seu aplicativo APM e o cluster Elasticsearch, inclua o atributo de recurso `es.cluster.name="your-cluster-name"` em suas métricas APM. Isso permite a visibilidade entre serviços e uma solução de problemas mais rápida no New Relic.
</Callout>

## Passo 3: Definir variáveis de ambiente [#start]

<Tabs>
  <TabsBar>
    <TabsBarItem id="nrot-collector">
      Coletor NRDOT (Recomendado)
    </TabsBarItem>

    <TabsBarItem id="otel-collector">
      Coletor OTel Contrib
    </TabsBarItem>
  </TabsBar>

  <TabsPages>
    <TabsPageItem id="nrot-collector">
      Adicione a seguinte configuração ao /etc/systemd/system/nrdot-collector.service.d arquivo, garantindo que as variáveis de ambiente sejam colocadas na seção \[Service]:

      ```bash
      [Service]
      Environment="NEW_RELIC_LICENSE_KEY=YOUR_LICENSE_KEY_HERE"
      Environment="OTEL_EXPORTER_OTLP_ENDPOINT=YOUR_OTLP_ENDPOINT"
      Environment="NEW_RELIC_MEMORY_LIMIT_MIB=COLLECTOR_MEMORY_LIMIT"
      ```

      Para aplicar essas alterações, recarregue o gerenciador do systemd e reinicie o coletor:

      ```bash
      sudo systemctl daemon-reload
      sudo systemctl restart nrdot-collector.service
      ```
    </TabsPageItem>

    <TabsPageItem id="otel-collector">
      Adicione a seguinte configuração ao /etc/systemd/system/otelcol-contrib.service.d arquivo, garantindo que as variáveis de ambiente sejam colocadas na seção \[Service]:

      ```bash
      [Service]
      Environment="NEW_RELIC_LICENSE_KEY=YOUR_LICENSE_KEY_HERE"
      Environment="OTEL_EXPORTER_OTLP_ENDPOINT=YOUR_OTLP_ENDPOINT"
      Environment="NEW_RELIC_MEMORY_LIMIT_MIB=COLLECTOR_MEMORY_LIMIT"
      ```

      Para aplicar essas alterações, recarregue o gerenciador do systemd e reinicie o coletor:

      ```bash
      sudo systemctl daemon-reload
      sudo systemctl restart otelcol-contrib.service
      ```
    </TabsPageItem>
  </TabsPages>
</Tabs>

## Etapa 4: Visualize seus dados do Elasticsearch [#find-and-use]

Depois que o coletor estiver em execução e enviando dados, você poderá visualizar suas métricas do Elasticsearch no New Relic:

1. Vá para **[one.newrelic.com](https://one.newrelic.com)** &gt; **Integrations &amp; Agents**
2. Pesquise por **Elasticsearch (OpenTelemetry)**
3. Em **Dashboards**, clique em **Elasticsearch OpenTelemetry Dashboard**
4. Selecione sua conta e clique em **View dashboard**

Você deve ver dashboards mostrando a integridade do cluster, métricas de desempenho e uso de recursos.

<Callout variant="tip">
  **Não está vendo dados?** Pode levar alguns minutos para os dados aparecerem. Se você não vir métricas após 10 minutos, consulte nosso [guia de solução de problemas](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-otel/troubleshooting).
</Callout>

**Próximos passos com seus dados:**

* **Explorar métricas**: Todas as métricas do Elasticsearch são armazenadas como `Metric` [tipos de evento](/docs/data-apis/understand-data/new-relic-data-types)
* **Criar consultas personalizadas**: Use [NRQL](/docs/nrql/get-started/introduction-nrql-new-relics-query-language) para construir gráficos e dashboards personalizados
* **Configure alertas**: Continue para a Etapa 5 para configurar o monitoramento proativo

## Etapa 5: Configure alertas [#alerts]

O monitoramento proativo com alertas ajuda você a detectar problemas antes que eles afetem seus usuários. Para criar condições de alerta na New Relic:

1. Vá para **[one.newrelic.com](https://one.newrelic.com)** &gt; **Alerts** &gt; **Alert Conditions**.
2. Clique em **Create condition**.
3. Configure o alerta usando o **Guided mode** ou o construtor de consultas **NRQL**.

As configurações de alerta abaixo são recomendadas para um monitoramento robusto do Elasticsearch:

### Alertas Essenciais (Alta Prioridade)

Esses alertas monitoram problemas críticos de integridade do cluster que podem causar perda de dados ou interrupções do serviço:

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        Nome do Alerta
      </th>

      <th>
        Justificativa do Limite (Exemplo de Condição)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **Alerta de Shards Não Atribuídos**
      </td>

      <td>
        A métrica 

        `elasticsearch.cluster.shards`

         (onde 

        `state = 'unassigned'`

        ) está acima de 0 por pelo menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Alerta de nós de dados saudáveis**
      </td>

      <td>
        A métrica 

        `elasticsearch.cluster.data_nodes`

         está abaixo da contagem mínima de nós necessária por pelo menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Alerta de uso de heap muito alto**
      </td>

      <td>
        A porcentagem de uso de heap (Usado/Máx) está acima de 90% por pelo menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Alerta de tarefas pendentes**
      </td>

      <td>
        A métrica 

        `elasticsearch.cluster.pending_tasks`

         está acima de 5 por pelo menos 5 minutos.
      </td>
    </tr>
  </tbody>
</table>

### Alertas de monitoramento adicionais

Esses alertas ajudam a monitorar problemas de desempenho e operacionais:

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        Nome do Alerta
      </th>

      <th>
        Justificativa do Limite (Exemplo de Condição)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **Alerta de Lentidão no Tempo de Consulta**
      </td>

      <td>
        O percentil 95 de 

        `elasticsearch.node.operations.time`

         está acima de 5ms por pelo menos 2 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Inicialização de shards muito longa**
      </td>

      <td>
        A métrica 

        `elasticsearch.cluster.shards`

         (onde 

        `state = 'initializing'`

        ) está acima de 0 por pelo menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Realocação de shards muito longa**
      </td>

      <td>
        A métrica 

        `elasticsearch.cluster.shards`

         (onde 

        `state = 'relocating'`

        ) está acima de 0 por pelo menos 5 minutos.
      </td>
    </tr>
  </tbody>
</table>

## Resolução de problemas

Se você encontrar problemas durante a instalação ou não vir dados na New Relic, consulte nosso [guia de solução de problemas](/docs/opentelemetry/integrations/elasticsearch/troubleshooting) abrangente para obter soluções passo a passo para problemas comuns.