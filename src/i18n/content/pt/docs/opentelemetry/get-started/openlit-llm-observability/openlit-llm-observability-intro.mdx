---
title: Observabilidade LLM com OpenLIT
tags:
  - Integrations
  - LLM observability with OpenTelemetry
  - GenAI Observability with OpenTelemetry
  - OpenTelemetry
  - OpenLIT
metaDescription: Set up OpenTelemetry-based LLM observability with New Relic and OpenLIT.
freshnessValidatedDate: '2024-10-08T00:00:00.000Z'
translationType: machine
---

Embora OpenTelemetry ofereça um padrão poderoso para coletar dados gerais de aplicativos (trace, métrica, log), ele não possui a capacidade de capturar os principais indicadores de desempenho (KPIs) específicos do modelo de IA. Métricas essenciais como rastreamento de desempenho, uso token , custos e dados de interação do usuário na forma de prompts e respostas do LLM são cruciais para um aplicativo LLM eficaz, monitoramento e resolução de problemas.

Para preencher essa lacuna na observabilidade do LLM, o OpenLIT surgiu como uma solução personalizada. Construído na OpenTelemetry framework, o OpenLIT é uma ferramenta de código aberto que se integra suavemente e amplia suas capacidades. Ele suporta estruturas de IA amplamente utilizadas, como OpenAI, Anthropic, Pinecone, LangChain, entre outras. Além disso, ele fornece recursos de monitoramento de GPU baseados em OpenTelemetry prontos para uso.

Principais benefícios do OpenLIT:

* **Monitoramento avançado do desempenho do LLM e do VectorDB**: o OpenLIT gera automaticamente rastreamento e métrica para análise aprofundada de desempenho e custo do uso do LLM e do VectorDB, ajudando você a otimizar o uso de recursos e dimensionar com eficiência em vários ambientes, como produção.

* **Rastreamento de custos para modelos personalizados e ajustados**: permite o rastreamento preciso de custos por meio de um arquivo JSON personalizado, possibilitando orçamento preciso e alinhamento com as necessidades específicas do projeto.

* **OpenTelemetry- SDKs nativos e independentes de fornecedores**: O OpenLIT é desenvolvido com suporte nativo para OpenTelemetry, o que o torna perfeitamente compatível com seus projetos. Essa abordagem de independência de fornecedores reduz as barreiras à integração, tornando o OpenLIT uma parte intuitiva do seu stack de software em vez de uma complexidade adicional.

O OpenLIT capacita os desenvolvedores a aproveitar os pontos fortes do OpenTelemetry enquanto obtém as funcionalidades adicionais necessárias para monitoramento eficaz do LLM e otimização de desempenho.

## Antes que você comece [#prereqs]

* [Cadastre-se](https://newrelic.com/signup) para uma conta New Relic.
* Obtenha a [chave de licença](https://one.newrelic.com/launcher/api-keys-ui.launcher) da conta New Relic para a qual deseja relatar dados.

## instrumento seu modelo LLM com OpenLIT [#instrument]

Siga estas etapas comuns de configuração para monitoramento de APM baseado em OpenTelemetry com o New Relic.

<Steps>
  <Step>
    ### Rotear o traço e métrica [#route-traces]

    Como New Relic oferece suporte nativo OpenTelemetry, você só precisa rotear o rastreamento e a métrica New Relic para endpoint o do e definir a chave de API.

    Execute os seguintes comandos para que o exportador do [OpenTelemetry Protocol (OTLP, para abreviar)](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md) [New Relic envie dados para o OTLP endpoint](/docs/opentelemetry/best-practices/opentelemetry-otlp).

    ```env
    OTEL_EXPORTER_OTLP_ENDPOINT = https://otlp.nr-data.net:443
    OTEL_EXPORTER_OTLP_HEADERS = "api-key=YOUR_NEWRELIC_LICENSE_KEY"
    ```

    Veja este exemplo sobre o modelo OpenAI LLM com LangChain:

    ```python
    import openlit
    import os
    from langchain_openai import ChatOpenAI

    os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'
    os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = 'https://otlp.nr-data.net:443'
    os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = 'api-key=YOUR_NEWRELIC_LICENSE_KEY'

    openlit.init()

    def add_prompt_context():
      llm = ChatOpenAI(
          model="gpt-3.5-turbo",
          temperature=0)
      chain = llm
      return chain

    def prep_prompt_chain():
      return add_prompt_context()

    def prompt_question():
      chain = prep_prompt_chain()
      return chain.invoke("explain the business of company Newrelic and it's advantages in a max of 50 words")

    if  __name__ == "__main__":
      print(prompt_question())
    ```
  </Step>

  <Step>
    ## Visualize seus dados na interface do New Relic [#view-data]

    Depois que seu aplicativo estiver instrumentado e configurado para exportar dados para o New Relic, você poderá encontrar seus dados na interface New Relic . Você pode importar o dashboard pré-criado de observabilidade do LLM seguindo estas etapas:

    1. Vá para <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; Dashboards**</DNT>.

    2. No canto superior direito, clique em <DNT>**Import dashboard**</DNT>.

    3. Copie o JSON do painel fornecido [aqui](https://docs.openlit.io/latest/connections/new-relic#dashboard) e cole-o.

    4. Escolha as configurações de conta e permissão para o dashboard. Você não pode alterar a conta depois de defini-la, mas pode alterar as permissões a qualquer momento.

    5. Clique em <DNT>**Import dashboard**</DNT>.

    Se você não consegue encontrar sua entidade e não vê seus dados com NRQL, veja [OTLP resolução de problemas](/docs/opentelemetry/best-practices/opentelemetry-otlp-troubleshooting).

    <InstallFeedback />
  </Step>
</Steps>