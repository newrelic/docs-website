---
title: Coletor para Confluent Cloud e monitoramento Kafka
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
  - kubernetes
  - helm
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector on Kubernetes.
freshnessValidatedDate: '2024-05-28T00:00:00.000Z'
translationType: machine
---

Você pode coletar métricas sobre sua implantação Kafka gerenciada pelo Confluent Cloud com o coletor OpenTelemetry. O coletor é um componente do OpenTelemetry que coleta, processa e exporta dados de telemetria para o New Relic (ou qualquer backend de observabilidade).

Essa integração funciona executando uma configuração do receptor Prometheus dentro do coletor OpenTelemetry , que extrai [API métrica do Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w) e exporta esses dados para New Relic.

## Configurar monitoramento [#set-up-monitoring]

Conclua as etapas abaixo para coletar métricas Kafka do Confluent e exportá-las para o New Relic.

<Steps>
  <Step>
    ### Certifique-se de que você está pronto para começar [#get-started]

    Antes de começar, você precisa ter o <InlinePopover type="licenseKey"/>da conta para a qual deseja relatar dados. Você também deve verificar se:

    * Você tem um cluster do Kubernetes rodando
    * (Para usuário Helm) Certifique-se de ter [o Helm](https://helm.sh/docs/intro/quickstart/) instalado
    * Você tem uma [conta Confluent Cloud](https://www.confluent.io/get-started/) com um cluster em execução
    * Você tem sua [chave de API e segredo do Confluent Cloud](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html) disponível
  </Step>

  <Step>
    ### Baixe ou clone o repositório de exemplos de parceiros de tecnologia OpenTelemetry [#download-repo]

    Baixe [o repositório de exemplos de parceria de tecnologia OpenTelemetry da New Relic,](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations) pois esta configuração usa seu exemplo de configuração de coletor. Depois de instalado, abra o diretório [de exemplo do Confluent Cloud](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations/confluent-cloud). Para obter mais informações, você também pode verificar `README` lá.
  </Step>

  <Step>
    ### Execute o exemplo [#run-the-example]

    Conclua as instruções do Helm ou do Kubernetes abaixo, dependendo do seu ambiente.

    #### Exemplo de Helm [#run-helm-example]

    1. No diretório `./confluent-cloud/helm` , atualize as variáveis no arquivo `values.yaml`. Para obter mais informações sobre as variáveis individuais, consulte a tabela [de variáveis locais](#local-variables) abaixo.

    2. Execute o coletor usando o seguinte comando:

       ```bash
       # Open the confluent cloud helm example directory
       cd ./confluent-cloud/helm

       # Make sure to set environment variables.

       # Install and run helm
       helm install ./helm
       ```

    #### Exemplo de Kubernetes [#run-kubernetes-example]

    1. No diretório `./confluent-cloud/k8s` , atualize as variáveis no arquivo `./k8s/deployment.yaml`. Para obter mais informações sobre as variáveis individuais, consulte a tabela [de variáveis locais](#local-variables) abaixo.

    2. Depois de definidas as variáveis, execute o seguinte comando para aplicar o coletor ao seu cluster do Kubernetes.

       ```bash
       # Open the Confluent Cloud k8s example directory
       cd ./confluent-cloud/k8s

       # Make sure to set environment variables

       # Apply the collector to the cluster
       kubectl apply -f ./k8s
       ```

    #### Variáveis locais para Helm e Kubernetes [#local-variables]

    <table>
      <thead>
        <tr>
          <th style={{ width: "275px"}}>
            Variável
          </th>

          <th>
            Descrição
          </th>

          <th>
            Documentos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic
          </td>

          <td>
            [Documentos de chave de API](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            O endpoint OTLP New Relic padrão dos EUA é [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)
          </td>

          <td>
            [Documentos de configuração do endpoint OTLP](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            ID do cluster do Confluent Cloud
          </td>

          <td>
            [Documentos para o comando list cluster ID](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            Chave de API da nuvem
          </td>

          <td>
            [Documentos da chave da API do Cloud](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            Segredo da API da nuvem
          </td>

          <td>
            [Documentos da chave da API do Cloud](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (OPCIONAL) Você pode monitor seus conectores Confluent especificando o ID aqui
          </td>

          <td>
            [Documentos para o comando de ID do conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (OPCIONAL) Você pode monitor seu registro de esquema confluente especificando o ID aqui
          </td>

          <td>
            [Documentos para o comando de ID do conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ### Visualize seus dados no New Relic [#view-your-data]

    Você pode visualizar seus dados do Confluent Cloud de algumas maneiras diferentes.

    * Navegue até o [mercado New Relic](https://one.newrelic.com/marketplace) e pesquise `Confluent`. Você pode instalar os dashboards disponíveis diretamente em sua conta!
    * Navegue até o explorador métrico e filtre por `confluent_kafka`. Esses dados podem ser adicionados a qualquer alerta ou dashboard personalizado.
  </Step>
</Steps>

## Métrica de nuvem confluente [#confluent-metrics]

Esta integração cobre todas as métricas _exportáveis_ dentro da [API métrica do Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud). Temos abaixo uma lista parcial das métricas _exportáveis_ :

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Nome
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        A contagem delta de bytes dos seus dados recebidos da rede. Cada amostra é o número de bytes recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        A contagem delta de bytes dos seus dados enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        A contagem delta de registros recebidos. Cada amostra é o número de registros recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        A contagem delta de registros enviados. Cada amostra é o número de registros enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        A contagem atual de bytes retidos pelo cluster. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        A contagem de conexões autenticadas ativas.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        A contagem delta de solicitações recebidas pela rede. Cada amostra é o número de solicitações recebidas desde o ponto de dados anterior. A contagem amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        O número de partições
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        A contagem delta de autenticações bem-sucedidas. Cada amostra é o número de autenticações bem-sucedidas desde o ponto de dados anterior. A contagem amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        O atraso entre o deslocamento confirmado de um membro do grupo e o limite máximo da partição.
      </td>
    </tr>
  </tbody>
</table>