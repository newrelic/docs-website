---
title: Coletor para monitoramento Confluent Cloud e Kafka
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector.
freshnessValidatedDate: never
translationType: machine
---

Você pode coletar métricas sobre sua implantação Kafka gerenciada pelo Confluent Cloud com o coletor OpenTelemetry. O coletor é um componente do OpenTelemetry que coleta, processa e exporta dados de telemetria para o New Relic (ou qualquer backend de observabilidade).

Essa integração funciona executando uma configuração de receptor prometheus dentro do coletor OpenTelemetry, que extrai [a API métrica do Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w) e exporta esses dados para o New Relic.

Conclua as etapas abaixo para coletar métricas Kafka do Confluent e exportá-las para o New Relic.

<Steps>
  <Step>
    ## Verifique se você está configurado

    Antes de começar, você precisa ter o <InlinePopover type="licenseKey"/>da conta para a qual deseja relatar dados. Você também deve verificar se:

    * Você tem um daemon docker em execução
    * Você tem [docker Compose](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) instalado
    * Você tem uma [conta Confluent Cloud](https://www.confluent.io/get-started/)
    * Você tem sua [chave de API e segredo do Confluent Cloud](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html) disponível
  </Step>

  <Step>
    ## Baixe ou clone o repositório de exemplo

    Baixe o [repositório de exemplos OpenTelemetry da New Relic,](https://github.com/newrelic/newrelic-opentelemetry-examples) pois esta configuração usa seu exemplo de configuração do coletor. Depois de instalado, abra o diretório [de exemplo do Confluent Cloud](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) . Para obter mais informações, você também pode verificar `README` lá.
  </Step>

  <Step>
    ## Defina variáveis de ambiente e execute o coletor

    * Defina a chave de API e as variáveis secretas para Confluent Cloud e New Relic no arquivo `.env`
    * Defina a variável `Cluster_ID` com o ID do cluster kafka de destino
    * (Opcional) Para monitor conectores ou registros de esquema gerenciados pelo Confluent Cloud, você pode remover o comentário da configuração no arquivo `collector.yaml` e definir o ID correspondente no arquivo `.env`

    ```bash
    # Open the confluent cloud example directory
    cd newrelic-opentelemetry-examples/other-examples/collector/confluentcloud

    # Set environment variables.

    # run the collector in docker
    docker compose up
    ```

    ### Informações de variáveis locais

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px"}}>
            Variável
          </th>

          <th>
            Descrição
          </th>

          <th>
            Documentos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic
          </td>

          <td>
            [Documentos de chave de API](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            O endpoint OTLP New Relic padrão dos EUA é [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)
          </td>

          <td>
            [Documentos de configuração do endpoint OTLP](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/get-started/opentelemetry-set-up-your-app/#review-settings)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            ID do cluster do Confluent Cloud
          </td>

          <td>
            [Documentos para o comando list cluster ID](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            Chave de API da nuvem
          </td>

          <td>
            [Documentos da chave da API do Cloud](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            Segredo da API da nuvem
          </td>

          <td>
            [Documentos da chave da API do Cloud](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (OPCIONAL) Você pode monitor seus conectores Confluent especificando o ID aqui
          </td>

          <td>
            [Documentos para o comando de ID do conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (OPCIONAL) Você pode monitor seu registro de esquema confluente especificando o ID aqui
          </td>

          <td>
            [Documentos para o comando de ID do conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ## Visualize seus dados no New Relic

    Você pode visualizar seus dados do Confluent Cloud de algumas maneiras diferentes.

    * Navegue até o [mercado New Relic](https://one.newrelic.com/marketplace) e pesquise `Confluent`. O painel disponível pode ser instalado diretamente na sua conta!
    * Navegue até o explorador métrico e filtre por `confluent_kafka`. Esses dados podem ser adicionados a qualquer alerta ou dashboard personalizado.
  </Step>
</Steps>

### Métrica de nuvem confluente [#confluent-metrics]

Esta integração cobre todas as métricas _exportáveis_ dentro da [API métrica do Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud). Temos abaixo uma lista parcial das métricas _exportáveis_ :

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Nome
      </th>

      <th>
        Descrição
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        A contagem delta de bytes dos dados dos clientes recebidos da rede. Cada amostra é o número de bytes recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        A contagem delta de bytes dos dados dos clientes enviados pela rede. Cada amostra é o número de bytes enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        A contagem delta de registros recebidos. Cada amostra é o número de registros recebidos desde a amostra de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        A contagem delta de registros enviados. Cada amostra é o número de registros enviados desde o ponto de dados anterior. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        A contagem atual de bytes retidos pelo cluster. A contagem é amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        A contagem de conexões autenticadas ativas.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        A contagem delta de solicitações recebidas pela rede. Cada amostra é o número de solicitações recebidas desde o ponto de dados anterior. A contagem amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        O número de partições
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        A contagem delta de autenticações bem-sucedidas. Cada amostra é o número de autenticações bem-sucedidas desde o ponto de dados anterior. A contagem amostrada a cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        O atraso entre o deslocamento confirmado de um membro do grupo e o limite máximo da partição.
      </td>
    </tr>
  </tbody>
</table>