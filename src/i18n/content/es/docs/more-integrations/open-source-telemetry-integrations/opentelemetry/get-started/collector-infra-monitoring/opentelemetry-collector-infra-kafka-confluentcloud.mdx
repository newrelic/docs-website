---
title: Recolector para monitoreo de Confluent Cloud y Kafka
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector.
freshnessValidatedDate: never
translationType: machine
---

Puede recopilar métricas sobre su Kafka administrado por Confluent Cloud desplegado con el recolector OpenTelemetry. El recolector es un componente de OpenTelemetry que recopila, procesa y exporta telemetry data a New Relic (o cualquier backend de observabilidad).

Esta integración funciona ejecutando una configuración de receptor prometheus dentro del recolector OpenTelemetry, que extrae [la API métrica de Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w) y exporta esos datos a New Relic.

Complete los pasos a continuación para recopilar Kafka métrica de Confluent y exportarlos a New Relic.

<Steps>
  <Step>
    ## Asegúrate de estar configurado

    Antes de comenzar, debe tener el <InlinePopover type="licenseKey"/>de la cuenta a la que desea informar datos. También debes verificar que:

    * Tienes un docker daemon ejecutándose
    * Tienes [docker Compose](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) instalado
    * Tienes una [cuenta de Confluent Cloud](https://www.confluent.io/get-started/)
    * Tienes disponible tu [clave de API y secreto de Confluent Cloud](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html)
  </Step>

  <Step>
    ## Descargue o clone el repositorio de ejemplo

    Descargue [el repositorio de ejemplos de OpenTelemetry de New Relic](https://github.com/newrelic/newrelic-opentelemetry-examples) , ya que esta configuración utiliza su configuración de recolector de ejemplo. Una vez instalado, abra el directorio [de ejemplo de Confluent Cloud](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/collector/confluentcloud) . Para obtener más información, también puede consultar el `README` allí.
  </Step>

  <Step>
    ## Establezca variables de entorno y ejecute el recolector

    * Establezca la clave de API y las variables secretas para Confluent Cloud y New Relic en el archivo `.env`
    * Establezca la variable `Cluster_ID` con el ID del clúster objetivo Kafka
    * (Opcional) Para monitor conectores o registros de esquemas administrados por Confluent Cloud, puede quitar el comentario de la configuración en el archivo `collector.yaml` y establecer el ID correspondiente en el archivo `.env`.

    ```bash
    # Open the confluent cloud example directory
    cd newrelic-opentelemetry-examples/other-examples/collector/confluentcloud

    # Set environment variables.

    # run the collector in docker
    docker compose up
    ```

    ### Información de variables locales

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px"}}>
            Variable
          </th>

          <th>
            Descripción
          </th>

          <th>
            Documentos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic Ingest clave de API
          </td>

          <td>
            [Clave de documentos API](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            El extremo predeterminado de OTLP New Relic de EE. UU. es [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)
          </td>

          <td>
            [Documentos de configuración de OTLP extremo](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            ID del clúster de Confluent Cloud
          </td>

          <td>
            [Documentos para el comando de lista de ID de clúster](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            Clave de API en la nube
          </td>

          <td>
            [Documentos API de clave de nube](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            Secreto de la API de la nube
          </td>

          <td>
            [Documentos API de clave de nube](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (OPCIONAL) Puede monitor sus conectores Confluent especificando el ID aquí
          </td>

          <td>
            [Documentos para el comando de ID del conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (OPCIONAL) Puede monitor su Registro de esquemas de Confluent especificando el ID aquí
          </td>

          <td>
            [Documentos para el comando de ID del conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ## Ver tus datos en New Relic

    Puede ver sus datos de Confluent Cloud de diferentes maneras.

    * Navegue hasta el [mercado de New Relic](https://one.newrelic.com/marketplace) y busque `Confluent`. ¡El panel disponible se puede instalar directamente en su cuenta!
    * Navegue hasta el explorador métrica y filtre por `confluent_kafka`. Estos datos se pueden agregar a cualquier alerta o dashboard personalizado.
  </Step>
</Steps>

### Nube Confluente métrica [#confluent-metrics]

Esta integración cubre todas las métricas _Exportables_ dentro de la [API métrica de Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud). Tenemos una lista parcial de las métricas _Exportables_ a continuación:

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Nombre
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        El recuento delta de bytes de los datos de los clientes recibidos de la red. Cada muestra es el número de bytes recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        El recuento delta de bytes de los datos de los clientes enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        El recuento delta de registros recibidos. Cada muestra es el número de registros recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        El recuento delta de registros enviados. Cada muestra es el número de registros enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        El recuento actual de bytes retenidos por el clúster. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        El recuento de conexiones autenticadas activas.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        El recuento delta de solicitudes recibidas a través de la red. Cada muestra es el número de solicitudes recibidas desde el punto de datos anterior. El recuento se realizó cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        El número de particiones
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        El recuento delta de autenticaciones exitosas. Cada muestra es el número de autenticaciones exitosas desde el punto de datos anterior. El recuento se realizó cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        El retraso entre el desplazamiento comprometido de un miembro del grupo y la marca de límite superior de la partición.
      </td>
    </tr>
  </tbody>
</table>