---
title: Recolector de monitoreo de Confluent Cloud y Kafka
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Kafka
  - Confluent Cloud
  - kubernetes
  - helm
metaDescription: You can collect Kafka metrics from Confluent using the OpenTelemetry Collector on Kubernetes.
freshnessValidatedDate: '2024-05-28T00:00:00.000Z'
translationType: machine
---

Puede recopilar métricas sobre su Kafka administrado por Confluent Cloud desplegado con el recolector OpenTelemetry. El recolector es un componente de OpenTelemetry que recopila, procesa y exporta telemetry data a New Relic (o cualquier backend de observabilidad).

Esta integración funciona ejecutando una configuración de receptor Prometheus dentro del recolector OpenTelemetry , que extrae [APImétrica de Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud?_ga=2.183807142.1264186867.1705940186-6520871.1686857317&_gl=1*1te8jue*_ga*NjUyMDg3MS4xNjg2ODU3MzE3*_ga_D2D3EGKSGD*MTcwNjAzNzYwOS41Ni4wLjE3MDYwMzc2MDkuNjAuMC4w) y exporta esos datos a New Relic.

## Configurar el monitoreo [#set-up-monitoring]

Complete los pasos a continuación para recopilar Kafka métrica de Confluent y exportarlos a New Relic.

<Steps>
  <Step>
    ### Cerciórate de estar listo para comenzar [#get-started]

    Antes de comenzar, debe tener el <InlinePopover type="licenseKey"/>de la cuenta a la que desea informar datos. También debes verificar que:

    * Tienes un clúster de Kubernetes en ejecución
    * (Para usuarios de Helm) Cerciorar de tener [Helm](https://helm.sh/docs/intro/quickstart/) instalado
    * Tienes una [cuenta de Confluent Cloud](https://www.confluent.io/get-started/) con un clúster en ejecución
    * Tienes disponible tu [clave de API y secreto de Confluent Cloud](https://docs.confluent.io/confluent-cli/current/command-reference/api-key/confluent_api-key_create.html)
  </Step>

  <Step>
    ### Descargue o clone el repositorio de ejemplos de socios tecnológicos OpenTelemetry [#download-repo]

    Descargue [New Relic OpenTelemetry el repositorio de ejemplos de asociación](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations) tecnológica de ya que esta configuración emplea su configuración de recolector de ejemplo. Una vez instalado, abra el directorio [de ejemplo de Confluent Cloud](https://github.com/newrelic-experimental/tech-partner-opentelemetry-integrations/confluent-cloud). Para obtener más información, también puede consultar el `README` allí.
  </Step>

  <Step>
    ### Ejecute el ejemplo [#run-the-example]

    Complete las instrucciones de Helm o Kubernetes a continuación, según su entorno.

    #### Ejemplo de Helm [#run-helm-example]

    1. Desde el directorio `./confluent-cloud/helm` , actualice las variables en el archivo `values.yaml`. Para obtener más información sobre las variables individuales, consulte la tabla [de variables locales](#local-variables) a continuación.

    2. Ejecute el recolector usando el siguiente comando:

       ```bash
       # Open the confluent cloud helm example directory
       cd ./confluent-cloud/helm

       # Make sure to set environment variables.

       # Install and run helm
       helm install ./helm
       ```

    #### Ejemplo de Kubernetes [#run-kubernetes-example]

    1. Desde el directorio `./confluent-cloud/k8s` , actualice las variables en el archivo `./k8s/deployment.yaml`. Para obtener más información sobre las variables individuales, consulte la tabla [de variables locales](#local-variables) a continuación.

    2. Una vez configuradas las variables, ejecute el siguiente comando para aplicar el recolector a su clúster de Kubernetes.

       ```bash
       # Open the Confluent Cloud k8s example directory
       cd ./confluent-cloud/k8s

       # Make sure to set environment variables

       # Apply the collector to the cluster
       kubectl apply -f ./k8s
       ```

    #### Variables locales para Helm y Kubernetes [#local-variables]

    <table>
      <thead>
        <tr>
          <th style={{ width: "275px"}}>
            Variable
          </th>

          <th>
            Descripción
          </th>

          <th>
            Documentos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `NEW_RELIC_API_KEY`
          </td>

          <td>
            New Relic Ingest clave de API
          </td>

          <td>
            [Clave de documentos API](/docs/apis/intro-apis/new-relic-api-keys/)
          </td>
        </tr>

        <tr>
          <td>
            `NEW_RELIC_OTLP_ENDPOINT`
          </td>

          <td>
            El extremo predeterminado de OTLP New Relic de EE. UU. es [https://otlp.nr-data.net:4318](https://otlp.nr-data.net:4318)
          </td>

          <td>
            [Documentos de configuración de OTLP extremo](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp)
          </td>
        </tr>

        <tr>
          <td>
            `CLUSTER_ID`
          </td>

          <td>
            ID del clúster de Confluent Cloud
          </td>

          <td>
            [Documentos para el comando de lista de ID de clúster](https://docs.confluent.io/confluent-cli/current/command-reference/kafka/cluster/confluent_kafka_cluster_list.html#description)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_KEY`
          </td>

          <td>
            Clave de API en la nube
          </td>

          <td>
            [Documentos API de clave de nube](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONFLUENT_API_SECRET`
          </td>

          <td>
            Secreto de la API de la nube
          </td>

          <td>
            [Documentos API de clave de nube](https://docs.confluent.io/cloud/current/monitoring/metrics-api.html#metrics-quick-start)
          </td>
        </tr>

        <tr>
          <td>
            `CONNECTOR_ID`
          </td>

          <td>
            (OPCIONAL) Puede monitor sus conectores Confluent especificando el ID aquí
          </td>

          <td>
            [Documentos para el comando de ID del conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/connect/cluster/confluent_connect_cluster_list.html)
          </td>
        </tr>

        <tr>
          <td>
            `SCHEMA_REGISTRY_ID`
          </td>

          <td>
            (OPCIONAL) Puede monitor su Registro de esquemas de Confluent especificando el ID aquí
          </td>

          <td>
            [Documentos para el comando de ID del conector de lista](https://docs.confluent.io/confluent-cli/current/command-reference/schema-registry/schema/confluent_schema-registry_schema_list.html)
          </td>
        </tr>
      </tbody>
    </table>
  </Step>

  <Step>
    ### Ver tus datos en New Relic [#view-your-data]

    Puede ver sus datos de Confluent Cloud de diferentes maneras.

    * Navegue hasta el [mercado de New Relic](https://one.newrelic.com/marketplace) y busque `Confluent`. ¡Puedes instalar los dashboards disponibles directamente en tu cuenta!
    * Navegue hasta el explorador métrica y filtre por `confluent_kafka`. Estos datos se pueden agregar a cualquier alerta o dashboard personalizado.
  </Step>
</Steps>

## Nube Confluente métrica [#confluent-metrics]

Esta integración cubre todas las métricas _Exportables_ dentro de la [API métrica de Confluent Cloud](https://api.telemetry.confluent.cloud/docs/descriptors/datasets/cloud). Tenemos una lista parcial de las métricas _Exportables_ a continuación:

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Nombre
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        confluent_kafka_server_received_bytes
      </td>

      <td>
        El recuento delta de bytes de sus datos recibidos de la red. Cada muestra es el número de bytes recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_bytes
      </td>

      <td>
        El recuento delta de bytes de sus datos enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_received_records
      </td>

      <td>
        El recuento delta de registros recibidos. Cada muestra es el número de registros recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_sent_records
      </td>

      <td>
        El recuento delta de registros enviados. Cada muestra es el número de registros enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_retained_bytes
      </td>

      <td>
        El recuento actual de bytes retenidos por el clúster. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_active_connection_count
      </td>

      <td>
        El recuento de conexiones autenticadas activas.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_request_count
      </td>

      <td>
        El recuento delta de solicitudes recibidas a través de la red. Cada muestra es el número de solicitudes recibidas desde el punto de datos anterior. El recuento se realizó cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_partition_count
      </td>

      <td>
        El número de particiones
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_successful_authentication_count
      </td>

      <td>
        El recuento delta de autenticaciones exitosas. Cada muestra es el número de autenticaciones exitosas desde el punto de datos anterior. El recuento se realizó cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        confluent_kafka_server_consumer_lag_offsets
      </td>

      <td>
        El retraso entre el desplazamiento comprometido de un miembro del grupo y la marca de límite superior de la partición.
      </td>
    </tr>
  </tbody>
</table>