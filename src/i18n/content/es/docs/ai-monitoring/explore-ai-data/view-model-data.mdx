---
title: Analizar datos del modelo
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: '2024-06-12T00:00:00.000Z'
translationType: machine
---

import aiIntrotoModelData from 'images/ai_screenshot-crop_intro-to-model-data.webp'

import aiModelInventoryOverviewPage from 'images/ai_screenshot-full_model-inventory-overview-page.webp'

import aiModelInventoryErrors from 'images/ai_screenshot-crop_model-inventory-errors.webp'

import aiModelInventoryPerformancePage from 'images/ai_screenshot-crop_model-inventory-performance-page.webp'

import aiModelInventoryCostPage from 'images/ai_screenshot-crop_model-inventory-cost.webp'

import aiModelComparisonPage from 'images/ai_screenshot-full_ai-model-comparison-page.webp'

import aiModelComparisonCost from 'images/ai_screenshot-crop_model-comparison-cost.webp'

import aiModelComparisonPerformance from 'images/ai_screenshot-crop_model-comparison-performance.webp'

El monitoreo de IA muestra datos sobre su modelo de IA para que pueda analizar el rendimiento del modelo de IA junto con el rendimiento de la aplicación AI. Podrás encontrar datos sobre tu modelo de IA en dos áreas:

* <DoNotTranslate>**Model inventory**</DoNotTranslate>

  : Una vista centralizada que muestra datos de rendimiento y finalización de todos los modelos de IA en su cuenta. Aísle el uso token , realice un seguimiento del rendimiento general o profundice en las terminaciones individuales que realizan sus modelos.

* <DoNotTranslate>**Compare models**</DoNotTranslate>

  : Realizar análisis comparativos de rendimiento entre dos modelos a lo largo del tiempo. Esta página muestra datos para un análisis agregado del rendimiento de su modelo a lo largo del tiempo.

<img
  title="Model data overview"
  alt="A screenshot of the model inventory page"
  src={aiIntrotoModelData}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring</DoNotTranslate>**: desde el monitoreo de IA, puede elegir entre inventario de modelos o comparación de modelos.
</figcaption>

## Página de inventario de modelos [#model-inventory]

<img
  title="Model inventory overview"
  alt="A screenshot of the overview page when you go to Model inventory"
  src={aiModelInventoryOverviewPage}
/>

<figcaption>
  Ir a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory</DoNotTranslate>**: Ver datos sobre la interacción con su modelo de IA.
</figcaption>

La página <DoNotTranslate>model inventory</DoNotTranslate> proporciona información valiosa sobre el rendimiento general y el uso de su modelo de IA. Puede analizar los datos de las llamadas realizadas a su modelo, para poder comprender cómo el modelo de IA afecta su aplicación de IA.

Desde la pestaña de descripción general, explore la cantidad de solicitudes realizadas a un modelo en comparación con su tiempo de respuesta o analice gráficos de seriales de tiempo para ver cuándo cambió el comportamiento del modelo. A partir de ahí, investigue las pestañas de errores, rendimiento o costos.

### Pestaña de errores [#errors-inventory]

<img
  title="Model inventory: Errors"
  alt="A screenshot of the Errors time series and chart"
  src={aiModelInventoryErrors}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Errors</DoNotTranslate>**: vea datos sobre errores del modelo de IA.
</figcaption>

La pestaña de errores emplea tablas y gráficos de seriales temporales para organizar los errores del modelo.

* <DoNotTranslate>**Response errors**</DoNotTranslate>

  : Realice un seguimiento de la cantidad de errores totales que provienen de su modelo de IA.

* <DoNotTranslate>**Response errors by model**</DoNotTranslate>

  : Determine si un modelo específico produce más errores en promedio o si se produce un error específico en todos sus modelos.

* <DoNotTranslate>**Response errors by type**</DoNotTranslate>

  : Vea con qué frecuencia aparecen ciertos errores.

* <DoNotTranslate>**Errors table**</DoNotTranslate>

  : Vea el tipo de error y el mensaje en el contexto de la solicitud y la respuesta.

### Pestaña de rendimiento [#performance-inventory]

<img
  title="Model inventory: Performance"
  alt="A screenshot of the Errors time series and chart"
  src={aiModelInventoryPerformancePage}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Performance</DoNotTranslate>**: vea datos sobre el rendimiento de su modelo de IA.
</figcaption>

La pestaña de rendimiento agrega respuestas y solicitudes métricas en todos sus modelos. Obtenga una descripción general de los modelos que toman más tiempo para procesar una solicitud o crear una respuesta con los gráficos circulares, o consulte los gráficos de seriales de tiempo para realizar un seguimiento de los aumentos en la solicitud o el tiempo de respuesta. Puede emplear gráficos de rendimiento para localizar el valor atípico en sus modelos.

### Pestaña de costos [#cost-inventory]

<img
  title="Model inventory: Performance"
  alt="A screenshot of the Errors time series and chart"
  src={aiModelInventoryCostPage}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model inventory > Cost</DoNotTranslate>**: vea datos sobre el costo de su modelo de IA.
</figcaption>

La pestaña de costos emplea una combinación de gráficos de seriales temporales y gráficos circulares para identificar los factores de costos entre sus modelos. Determine la cantidad de tokens que provienen del símbolo o de las terminaciones, o si ciertos modelos cuestan más en promedio que otros.

* <DoNotTranslate>**Tokens used and token limit**</DoNotTranslate>

  : Evalúe la frecuencia con la que sus modelos se acercan a un límite de token determinado.

* <DoNotTranslate>**Total tokens by models**</DoNotTranslate>

  : Determine cuál de sus modelos emplea más tokens en promedio.

* <DoNotTranslate>**Total usage by prompt and completion tokens**</DoNotTranslate>

  : Comprenda qué proporción de token proviene del símbolo que acepta su modelo frente al token empleado por finalización.

Comprender el costo le permite mejorar la forma en que su aplicación de IA emplea uno o más de sus modelos para que su cadena de herramientas de IA sea más rentable.

## Página de comparación de modelos [#model-comparison]

<img
  title="Model inventory overview"
  alt="A screenshot of the overview page when you go to Model inventory"
  src={aiModelComparisonPage}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DoNotTranslate>**: compare datos sobre los diferentes modelos de IA en su stack.
</figcaption>

La página de comparación de modelos organiza sus datos de monitoreo de IA para ayudarlo a realizar análisis comparativos. Esta página limita los datos de comparación de sus modelos a una sola cuenta, brindándole datos agregados sobre el costo y el rendimiento del modelo en una o más aplicaciones. Para generar datos:

1. Elija sus modelos en el menú desplegable.
2. Emplee un servicio para ver el rendimiento en el contexto de una aplicación en individua o mantenga la consulta en `Service = All` para ver cómo se comporta un modelo en promedio.
3. Elija el parámetro de tiempo. Esta herramienta es flexible: puedes hacer comparaciones entre diferentes periodos de tiempo, lo que te permite ver cómo cambió el rendimiento o el costo antes y luego de un despliegue.

### Comparar el rendimiento del modelo [#compare-performance]

<img
  title="Model comparison page: Performance"
  alt="A screenshot of model comparison"
  src={aiModelComparisonPerformance}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DoNotTranslate>**: Compare el rendimiento entre diferentes modelos de IA en su stack.
</figcaption>

Para comenzar a realizar un análisis comparativo, elija un servicio, modelo y rango de tiempo específicos. Cuando comparas modelos, puedes evaluar diferentes métricas agregadas a lo largo del tiempo, dependiendo de tu propia configuración. A continuación se muestran algunos ejemplos de casos de uso para el análisis comparativo:

* **Compare dos modelos en el mismo servicio**: el servicio X usa el modelo A durante la primera semana, pero luego usa el modelo B en la segunda semana. Puede comparar el rendimiento eligiendo el servicio X, seleccionando el modelo A y estableciendo las fechas para la primera semana. En el segundo lado, elige el servicio X, selecciona el modelo B y establece las fechas para la segunda semana.
* **Compare el rendimiento de un modelo a lo largo del tiempo**: seleccione el servicio X, seleccione el modelo A y establezca las fechas para la primera semana. En el segundo lado, elige el servicio X, selecciona el modelo A y establece las fechas para la segunda semana.
* **Evalúe el rendimiento del modelo en dos servicios diferentes**: Tiene dos aplicaciones diferentes que emplean dos modelos diferentes. Para comparar el token total durante el último mes, elija el parámetro relevante para el servicio específico y los modelos específicos, luego establezca las fechas para el mismo periodo de tiempo.
* **Compare dos modelos**: tiene una aplicación que usa el modelo A y desea medir el modelo A con el modelo B. Para cada símbolo de usuario, llama al modelo B como proceso en segundo plano. Compare el rendimiento del modelo A en relación con el modelo B en el mismo servicio durante el mismo periodo de tiempo.

### Comparar el costo del modelo [#compare-cost]

<img
  title="Model comparison page: Cost"
  alt="A screenshot of model comparison"
  src={aiModelComparisonCost}
/>

<figcaption>
  Vaya a **<DoNotTranslate>[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI monitoring > Model comparison</DoNotTranslate>**: compare el costo entre diferentes modelos de IA en su stack.
</figcaption>

La columna de costo del modelo divide el evento de finalización en dos partes: el símbolo dado al modelo y la respuesta final que el modelo entrega al usuario final.

* <DoNotTranslate>**Tokens per completion**</DoNotTranslate>

  : El promedio token para todos los eventos de finalización.

* <DoNotTranslate>**Prompt tokens**</DoNotTranslate>

  : El promedio token para el símbolo. Este token promedio incluye el símbolo creado por el símbolo ingeniero y el usuario final.

* <DoNotTranslate>**Completion tokens**</DoNotTranslate>

  : La cantidad de token consumida por el modelo cuando genera la respuesta entregada al usuario final.

Al analizar esta columna, el valor del token de finalización y del símbolo token debe ser igual al valor en token por finalización.

## ¿Que sigue? [#whats-next]

Ahora que sabe cómo encontrar sus datos, puede explorar otras características que el monitoreo de IA tiene para ofrecer.

* ¿Quiere analizar el rendimiento de su aplicación de IA? Consulte nuestro documento sobre [las páginas de respuesta de la aplicación AI](/docs/ai-monitoring/explore-ai-data/view-ai-responses).
* ¿Preocupado por la información confidencial? [Aprenda a configurar filtros de caída](/docs/ai-monitoring/drop-sensitive-data).
* Si desea reenviar información de comentarios de los usuarios sobre las respuestas de IA de su aplicación a New Relic, siga nuestros procedimientos para [actualizar el código de su aplicación y obtener comentarios de los usuarios en la UI](/docs/ai-monitoring/customize-agent-ai-monitoring).