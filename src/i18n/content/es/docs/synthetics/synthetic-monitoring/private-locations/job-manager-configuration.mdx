---
title: Configuración del gestor de trabajos sintético
tags:
  - synthetics
  - Synthetic monitoring
  - Private locations
metaDescription: Customize your New Relic synthetics job manager.
freshnessValidatedDate: '2024-07-29T00:00:00.000Z'
translationType: machine
---

Este documento lo guiará a través de la configuración de su [administrador de trabajos Sintético](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager) mostrándole cómo:

* Emplee [variables de entorno](#environment-variables) para configurar su administrador de trabajos Sintéticos.
* Configure [módulos personalizados](#custom-modules) para [API con script](/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/) o monitor [browser con script](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) .
* Proporcione [variables definidas por el usuario](#user-defined-vars) en su configuración.

## configuración usando variables de entorno [#environment-variables]

Las variables ambientales le permiten ajustar la configuración del administrador de trabajos de Sintético para satisfacer sus necesidades ambientales y funcionales específicas.

<CollapserGroup>
  <Collapser id="docker-env-config" title="Configuración del entorno Docker">
    Las variables se proporcionan al inicio utilizando el argumento `-e, --env` .

    La siguiente tabla muestra todas las variables de entorno que soporta Sintético job manager. `PRIVATE_LOCATION_KEY` es obligatorio y todas las demás variables son opcionales.

    <table>
      <thead>
        <tr>
          <th>
            Nombre
          </th>

          <th>
            Descripción
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DNT>**Required.**</DNT> Clave de ubicación privada, como se encuentra en la lista de entidades de Ubicación Privada.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_API_VERSION`
          </td>

          <td>
            Formato: `"vX.Y"` versión de API que se utilizará con el servicio Docker determinado.

            Por defecto: `v1.35.`
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_HOST`
          </td>

          <td>
            Apunta al administrador de trabajos de Sintético a un `DOCKER_HOST` determinado. Si está ausente, el valor predeterminado es `/var/run/docker.sock.`
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            Para cuentas con sede en EE. UU., el extremo es: `https://synthetics-horde.nr-data.net.`

            Para cuentas [basadas en la UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , el extremo es: `https://synthetics-horde.eu01.nr-data.net/`

            Asegúrese de que su administrador de trabajo de Sintético pueda conectarse al extremo apropiado para atender su monitor.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            El dominio del Registro Docker donde se alojan las imágenes en tiempo de ejecución. Utilice esto para anular `docker.io` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            El repositorio u organización Docker donde se alojan las imágenes en tiempo de ejecución. Emplee esto para anular `newrelic` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Host de servidor proxy utilizado para la comunicación de la Horda. Formato: `"localhost"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Puerto del servidor proxy utilizado para la comunicación de la Horda. Formato: `8888`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Nombre de usuario del servidor proxy utilizado para la comunicación de la Horda. Formato: `"username"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Contraseña del servidor proxy utilizada para la comunicación de la Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            ¿Aceptar certificados de proxy autofirmados para la conexión del servidor proxy utilizado para la comunicación de la Horda? Valores aceptables: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            La cantidad máxima de segundos que se permite que se ejecuten las comprobaciones de su monitor. Este valor debe ser un número entero entre 0 segundos (excluido) y 900 segundos (incluido) (por ejemplo, de 1 segundo a 15 minutos).

            Predeterminado: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            Por defecto: `INFO.`

            Opciones adicionales: `WARN`, `ERROR`, `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            El número de trabajos pesados simultáneos (browser/ browser con secuencias de comandos y API con secuencias de comandos) que se pueden ejecutar al mismo tiempo.

            Valor predeterminado: CPU disponibles - 1.
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            Una matriz que se puede utilizar para ejecutar imágenes en tiempo de ejecución específicas. Formato: \[&apos;newrelic/Sintético-ping-runtime:latest&apos;,&apos;newrelic/Sintético-node-API-runtime:latest&apos;,&apos;newrelic/Sintético-node-browser-runtime:latest&apos;]

            Valor predeterminado: todos los tiempos de ejecución más recientes.
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            Si se establece, habilita <DNT>**verified script execution**</DNT> y utiliza este valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            Un conjunto alojado localmente de pares de valores principales definidos por el usuario.
          </td>
        </tr>

        <tr>
          <td>
            `ENABLE_WASM`
          </td>

          <td>
            Si se configura, habilita webassembly para el tiempo de ejecución del navegador de nodos. Para emplear webassembly, la versión mínima de su administrador de trabajos Sintéticos debe ser release-367 o superior y la versión de ejecución del navegador de nodo debe ser 2.3.21 o superior.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="podman-env-config" title="Configuración del entorno Podman">
    Las variables se proporcionan al inicio utilizando el argumento `-e, --env` .

    La siguiente tabla muestra todas las variables de entorno que admite el administrador de trabajos de Sintéticos. Se requiere `PRIVATE_LOCATION_KEY` y todas las demás variables son opcionales. Para ejecutar el administrador de trabajos Sintéticos en un entorno Podman, la versión mínima debe ser release-418 o superior.

    <table>
      <thead>
        <tr>
          <th>
            Nombre
          </th>

          <th>
            Descripción
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `PRIVATE_LOCATION_KEY`
          </td>

          <td>
            <DNT>**Required.**</DNT> Clave de ubicación privada, como se encuentra en la lista de entidades de Ubicación Privada.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_ENDPOINT`
          </td>

          <td>
            Para cuentas con sede en EE. UU., el extremo es: `https://synthetics-horde.nr-data.net.`

            Para cuentas [basadas en la UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , el extremo es: `https://synthetics-horde.eu01.nr-data.net/`

            Asegúrese de que su administrador de trabajo de Sintético pueda conectarse al extremo apropiado para atender su monitor.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_SERVICE_HOST`
          </td>

          <td>
            La entrada de host agregada al pod creado donde se ejecutará el SJM. Emplee esto para anular `podman.service` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_SERVICE_PORT`
          </td>

          <td>
            El puerto en el que se ejecuta el servicio API RESTful de Podman LibPod en la instancia. Emplee esto para anular `8000` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_API_VERSION`
          </td>

          <td>
            La versión específica de la API RESTful de Podman LibPod que se está empleando. Emplee esto para anular `v5.0.0` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `PODMAN_POD_NAME`
          </td>

          <td>
            El nombre del pod en el que se ejecuta el contenedor SJM. Emplee esto para anular `SYNTHETICS` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REGISTRY`
          </td>

          <td>
            El dominio del Registro Docker donde se alojan las imágenes en tiempo de ejecución. Utilice esto para anular `docker.io` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `DOCKER_REPOSITORY`
          </td>

          <td>
            El repositorio u organización Docker donde se alojan las imágenes en tiempo de ejecución. Emplee esto para anular `newrelic` como valor predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_HOST`
          </td>

          <td>
            Host de servidor proxy utilizado para la comunicación de la Horda. Formato: `"localhost"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PORT`
          </td>

          <td>
            Puerto del servidor proxy utilizado para la comunicación de la Horda. Formato: `8888`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_USERNAME`
          </td>

          <td>
            Nombre de usuario del servidor proxy utilizado para la comunicación de la Horda. Formato: `"username"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_PW`
          </td>

          <td>
            Contraseña del servidor proxy utilizada para la comunicación de la Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `HORDE_API_PROXY_ACCEPT_SELF_SIGNED_CERT`
          </td>

          <td>
            ¿Aceptar certificados de proxy autofirmados para la conexión del servidor proxy utilizado para la comunicación de la Horda? Valores aceptables: `true`
          </td>
        </tr>

        <tr>
          <td>
            `CHECK_TIMEOUT`
          </td>

          <td>
            La cantidad máxima de segundos que se permite que se ejecuten las comprobaciones de su monitor. Este valor debe ser un número entero entre 0 segundos (excluido) y 900 segundos (incluido) (por ejemplo, de 1 segundo a 15 minutos).

            Predeterminado: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `LOG_LEVEL`
          </td>

          <td>
            Por defecto: `INFO.`

            Opciones adicionales: `WARN`, `ERROR`, `DEBUG`
          </td>
        </tr>

        <tr>
          <td>
            `HEAVYWEIGHT_WORKERS`
          </td>

          <td>
            El número de trabajos pesados simultáneos (browser/ browser con secuencias de comandos y API con secuencias de comandos) que se pueden ejecutar al mismo tiempo.

            Valor predeterminado: CPU disponibles - 1.
          </td>
        </tr>

        <tr>
          <td>
            `DESIRED_RUNTIMES`
          </td>

          <td>
            Una matriz que se puede utilizar para ejecutar imágenes en tiempo de ejecución específicas. Formato: \[&apos;newrelic/Sintético-ping-runtime:latest&apos;,&apos;newrelic/Sintético-node-API-runtime:latest&apos;,&apos;newrelic/Sintético-node-browser-runtime:latest&apos;]

            Valor predeterminado: todos los tiempos de ejecución más recientes.
          </td>
        </tr>

        <tr>
          <td>
            `VSE_PASSPHRASE`
          </td>

          <td>
            Si se establece, habilita <DNT>**verified script execution**</DNT> y utiliza este valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `USER_DEFINED_VARIABLES`
          </td>

          <td>
            Un conjunto alojado localmente de pares de valores principales definidos por el usuario.
          </td>
        </tr>

        <tr>
          <td>
            `ENABLE_WASM`
          </td>

          <td>
            Si se configura, habilita webassembly para el tiempo de ejecución del navegador de nodos. Para emplear webassembly, la versión mínima de su administrador de trabajos Sintéticos debe ser release-367 o superior y la versión de ejecución del navegador de nodo debe ser 2.3.21 o superior.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="kubernetes-env-config" title="Configuración del entorno de Kubernetes">
    Las variables se proporcionan al inicio utilizando el argumento `--set` .

    La siguiente lista muestra todas las variables de entorno que admite Sintético job manager. `synthetics.privateLocationKey` es obligatorio y todas las demás variables son opcionales.

    Una serie de configuraciones avanzadas adicionales están disponibles y completamente documentadas en [nuestro archivo README del gráfico Helm.](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)

    <table>
      <thead>
        <tr>
          <th>
            Nombre
          </th>

          <th>
            Descripción
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DNT>**Required if `synthetics.privateLocationKeySecretName` is not set**</DNT>. [ubicación privada clave](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key) de la ubicación privada, tal como se encuentra en la página web de la ubicación privada.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.privateLocationKeySecretName`
          </td>

          <td>
            <DNT>**Required if `synthetics.privateLocationKey` is not set**</DNT>. Nombre del secreto de Kubernetes que contiene la clave `privateLocationKey`, que contiene la clave de autenticación asociada a tu ubicación privada de Sintético.
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            El nombre del objeto secreto utilizado para extraer una imagen de un registro de contenedor específico.
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            Anulación del nombre utilizado para su implementación, reemplazando el predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            Versión de lanzamiento de Sintético-job-manager para usar en lugar de la versión especificada en [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml).
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            Por defecto: `INFO.`

            Opciones adicionales: `WARN`, `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            Para cuentas con sede en EE. UU., el extremo es: `https://synthetics-horde.nr-data.net.`

            Para cuentas [basadas en la UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , el extremo es: `https://synthetics-horde.eu01.nr-data.net/`

            Asegúrese de que su administrador de trabajo de Sintético pueda conectarse al extremo apropiado para atender su monitor.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.minionDockerRunnerRegistryEndpoint`
          </td>

          <td>
            El registro y la organización Docker donde se aloja la imagen minion Runner. Utilice esto para anular `quay.io/newrelic` como valor predeterminado (por ejemplo, `docker.io/newrelic`).
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            Si se establece, habilita <DNT>**verified script execution**</DNT> y utiliza este valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            Si se establece, habilita la ejecución de script verificada y utiliza este valor para recuperar la frase de contraseña de un secreto de Kubernetes con una clave llamada `vsePassphrase`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.enableWasm`
          </td>

          <td>
            Si se configura, habilita webassembly para el tiempo de ejecución del navegador de nodos. Para emplear webassembly, la versión mínima de su administrador de trabajos Sintéticos debe ser release-367 o superior y la versión de ejecución del navegador de nodo debe ser 2.3.21 o superior.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Servidor proxy utilizado para la comunicación de la Horda. Formato: `"host"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Puerto del servidor proxy utilizado para la comunicación de la Horda. Formato: `port`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Acepte certificados autofirmados cuando utilice un servidor proxy para la comunicación de la Horda. Valores aceptables: `true`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Nombre de usuario del servidor proxy para la comunicación de la Horda. Formato: `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Contraseña del servidor proxy para la comunicación de la Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            Una cadena JSON de variables definidas por el usuario. El usuario puede acceder a estas variables en su script. Formato: `'{"key":"value","key2":"value2"}'`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            Una ruta local para el usuario a un archivo JSON que contiene variables definidas por el usuario. Esto se pasa a través de `--set-file` y no se puede configurar en el archivo de valores.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            Una ruta en el PersistentVolume proporcionado por el usuario al archivo user\_defined\_variables.json. El usuario debe proporcionar un PersistentVolume o PersistentVolumeClaim si esta variable está completa.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingClaimName`
          </td>

          <td>
            Si monta un volumen, el usuario puede proporcionar un nombre para un PersistentVolumeClaim que ya existe en el clúster. Presume la existencia de un PersistentVolume correspondiente.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.existingVolumeName`
          </td>

          <td>
            Si monta un volumen y no proporciona un PersistentVolumeClaim, el usuario debe, como mínimo, proporcionar un nombre de PersistentVolume. Helm generará un PersistentVolumeClaim.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.storageClass`
          </td>

          <td>
            El nombre de StorageClass para el PersistentVolumeClaim generado. Esto debe coincidir con StorageClassName en el PV existente. Si no son proveedores, Kubernetes utilizará la clase de almacenamiento predeterminada, si está presente.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.persistence.size`
          </td>

          <td>
            El tamaño del volumen para el PersistentVolumeClaim generado. Formato: `10Gi`. 2Gi predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            La cantidad máxima de segundos que se permite que se ejecuten las comprobaciones de su monitor. Este valor debe ser un número entero entre 0 segundos (excluido) y 900 segundos (incluido) (por ejemplo, de 1 segundo a 15 minutos).

            Predeterminado: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            El contenedor para tirar.

            Por defecto: `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            La política de atracción.

            Por defecto: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            Establezca un contexto de seguridad personalizado para el pod Sintético-job-manager.
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            Si se debe implementar o no el tiempo de ejecución del ping persistente. Esto se puede desactivar si no utiliza el monitor de ping.

            Por defecto: `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            El número de contenedores de tiempo de ejecución de ping a desplegar. Aumente el replicaCount para escalar el despliegue según sus necesidades de monitoreo de ping.

            Por defecto: `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            La imagen del contenedor que se extraerá para el tiempo de ejecución de ping.

            Por defecto: `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            La política de extracción para el contenedor de tiempo de ejecución de ping.

            Por defecto: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Si se debe implementar o no el tiempo de ejecución de la API de Node.js. Esto se puede desactivar si no utiliza el monitor API con script.

            Por defecto: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            La cantidad de tiempo de ejecución de API de Node.js `CronJobs` para implementar. La cantidad máxima de trabajos simultáneos de la API de Node.js que se ejecutarán en cualquier momento. [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            La cantidad de tiempos de ejecución de API de Node.js `CronJobs` que se deben completar por minuto. Aumente esta configuración junto con el paralelismo para mejorar el rendimiento. Esto debe aumentarse cada vez que se aumenta el paralelismo y las terminaciones siempre deben ser al menos mayores o iguales que el paralelismo. . Aumente esta configuración si observa períodos de tiempo sin trabajos de ejecución de API en ejecución. [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            La imagen del contenedor que se extraerá para el tiempo de ejecución de la API de Node.js.

            Por defecto: `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            La política de extracción para el contenedor de tiempo de ejecución de la API de Node.js.

            Por defecto: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Si se debe desplegar o no el tiempo de ejecución browser Node.js. Esto se puede desactivar si no utiliza el script simple o monitor del browser.

            Por defecto: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            El número de tiempo de ejecución browser Chrome `CronJobs` para desplegar. La cantidad máxima de trabajos simultáneos browser Chrome que se ejecutarán en cualquier momento. [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            El número de tiempos de ejecución browser Chrome `CronJobs` que se deben completar por minuto. Aumente esta configuración junto con el paralelismo para mejorar el rendimiento. Esto debe aumentarse cada vez que se aumenta el paralelismo y las terminaciones siempre deben ser al menos mayores o iguales que el paralelismo. Aumente esta configuración si observa períodos de tiempo sin que se ejecuten trabajos de tiempo de ejecución browser . [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            La imagen del contenedor que se extraerá para el tiempo de ejecución browser Node.js.

            Por defecto: `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            La política de extracción para el contenedor de tiempo de ejecución browser Node.js.

            Por defecto: `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="openshift-environment-config" title="Configuración del entorno OpenShift">
    Las variables se proporcionan al inicio utilizando el argumento `--set` .

    La siguiente lista muestra todas las variables de entorno que admite Sintético job manager. `synthetics.privateLocationKey` es obligatorio y todas las demás variables son opcionales.

    Una serie de configuraciones avanzadas adicionales están disponibles y completamente documentadas en [nuestro archivo README del gráfico Helm.](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/README.md)

    <table>
      <thead>
        <tr>
          <th>
            Nombre
          </th>

          <th>
            Descripción
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `synthetics.privateLocationKey`
          </td>

          <td>
            <DNT>**Required**</DNT>. [Clave de ubicación privada](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#private-location-key), como se encuentra en la lista de entidades de ubicación privada.
          </td>
        </tr>

        <tr>
          <td>
            `imagePullSecrets`
          </td>

          <td>
            El nombre del objeto secreto utilizado para extraer una imagen de un registro de contenedor específico.
          </td>
        </tr>

        <tr>
          <td>
            `fullnameOverride`
          </td>

          <td>
            Anulación del nombre utilizado para su implementación, reemplazando el predeterminado.
          </td>
        </tr>

        <tr>
          <td>
            `appVersionOverride`
          </td>

          <td>
            Versión de lanzamiento de Sintético-job-manager para usar en lugar de la versión especificada en [chart.yml](https://github.com/newrelic/helm-charts/blob/master/charts/synthetics-job-manager/Chart.yaml).
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.logLevel`
          </td>

          <td>
            Por defecto: `INFO.`

            Opciones adicionales: `WARN`, `ERROR`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiEndpoint`
          </td>

          <td>
            Para cuentas con sede en EE. UU., el extremo es: `https://synthetics-horde.nr-data.net.`

            Para cuentas [basadas en la UE](/docs/using-new-relic/welcome-new-relic/get-started/introduction-eu-region-data-center#partner-hierarchy) , el extremo es: `https://synthetics-horde.eu01.nr-data.net/`

            Asegúrese de que su administrador de trabajo de Sintético pueda conectarse al extremo apropiado para atender su monitor.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphrase`
          </td>

          <td>
            Si se establece, habilita <DNT>**verified script execution**</DNT> y utiliza este valor como <DNT>**passphrase**</DNT>.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.vsePassphraseSecretName`
          </td>

          <td>
            Si se establece, habilita la ejecución de script verificada y utiliza este valor para recuperar la frase de contraseña de un secreto de Kubernetes con una clave llamada `vsePassphrase`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.enableWasm`
          </td>

          <td>
            Si se configura, habilita webassembly para el tiempo de ejecución del navegador de nodos. Para emplear webassembly, la versión mínima de su administrador de trabajos Sintéticos debe ser release-367 o superior y la versión de ejecución del navegador de nodo debe ser 2.3.21 o superior.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyHost`
          </td>

          <td>
            Servidor proxy utilizado para la comunicación de la Horda. Formato: `"host"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.apiProxyPort`
          </td>

          <td>
            Puerto del servidor proxy utilizado para la comunicación de la Horda. Formato: `port`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxySelfSignedCert`
          </td>

          <td>
            Acepte certificados autofirmados cuando utilice un servidor proxy para la comunicación de la Horda. Valores aceptables: `true`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyUsername`
          </td>

          <td>
            Nombre de usuario del servidor proxy para la comunicación de la Horda. Formato: `"username"`
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.hordeApiProxyPw`
          </td>

          <td>
            Contraseña del servidor proxy para la comunicación de la Horda. Formato: `"password"`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedJson`
          </td>

          <td>
            Una cadena JSON de variables definidas por el usuario. El usuario puede acceder a estas variables en su script. Formato: `'{"key":"value","key2":"value2"}'`.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedFile`
          </td>

          <td>
            Una ruta local para el usuario a un archivo JSON que contiene variables definidas por el usuario. Esto se pasa a través de `--set-file` y no se puede configurar en el archivo de valores.
          </td>
        </tr>

        <tr>
          <td>
            `synthetics.userDefinedVariables.userDefinedPath`
          </td>

          <td>
            Una ruta en el `PersistentVolume` proporcionado por el usuario al archivo` user_defined_variables.json` . El usuario debe proporcionar `PersistentVolume` o `PersistentVolumeClaim` si esta variable está completa.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.existingClaimName`
          </td>

          <td>
            Si se monta un volumen, el usuario puede proporcionar un nombre para un `PersistentVolumeClaim` que ya existe en el clúster. Supone la existencia de un `PersistentVolume` correspondiente.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.existingVolumeName`
          </td>

          <td>
            Si se monta un volumen y no se proporciona un `PersistentVolumeClaim`, el usuario debe proporcionar como mínimo un nombre `PersistentVolume` . Helm generará un `PersistentVolumeClaim`.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.storageClass`
          </td>

          <td>
            El nombre del `StorageClass` para el `PersistentVolumeClaim` generado. Esto debe coincidir con el `StorageClassName` en el PV existente. Si no hay proveedores, **Kubernetes** empleará la clase de almacenamiento predeterminada si está presente.
          </td>
        </tr>

        <tr>
          <td>
            `global.persistence.size`
          </td>

          <td>
            El tamaño del volumen para el `PersistentVolumeClaim` generado. Formato: `10Gi`. Valor predeterminado `2Gi`.
          </td>
        </tr>

        <tr>
          <td>
            `global.checkTimeout`
          </td>

          <td>
            La cantidad máxima de segundos que se permite que se ejecuten las comprobaciones de su monitor. Este valor debe ser un número entero entre 0 segundos (excluido) y 900 segundos (incluido) (por ejemplo, de 1 segundo a 15 minutos).

            Predeterminado: 180 segundos
          </td>
        </tr>

        <tr>
          <td>
            `image.repository`
          </td>

          <td>
            El contenedor para tirar.

            Por defecto: `docker.io/newrelic/synthetics-job-runner`
          </td>
        </tr>

        <tr>
          <td>
            `image.pullPolicy`
          </td>

          <td>
            La política de atracción.

            Por defecto: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `podSecurityContext`
          </td>

          <td>
            Establezca un contexto de seguridad personalizado para el pod `synthetics-job-manager` .
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.enabled`
          </td>

          <td>
            Si se debe implementar o no el tiempo de ejecución del ping persistente. Esto se puede desactivar si no utiliza el monitor de ping.

            Por defecto: `true`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.replicaCount`
          </td>

          <td>
            El número de ping que el contenedor va a desplegar. Aumente `replicaCount` para escalar la implementación según sus necesidades de monitoreo de ping.

            Por defecto: `1`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.repository`
          </td>

          <td>
            La imagen del contenedor que se extraerá para el tiempo de ejecución de ping.

            Por defecto: `docker.io/newrelic/synthetics-ping-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `ping-runtime.image.pullPolicy`
          </td>

          <td>
            La política de extracción para el contenedor de tiempo de ejecución de ping.

            Por defecto: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.enabled`
          </td>

          <td>
            Si se debe implementar o no el tiempo de ejecución de la API de Node.js. Esto se puede desactivar si no utiliza el monitor API con script.

            Por defecto: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.parallelism`
          </td>

          <td>
            La cantidad de tiempo de ejecución de API de Node.js `CronJobs` para implementar. La cantidad máxima de trabajos simultáneos de la API de Node.js que se ejecutarán en cualquier momento. [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.completions`
          </td>

          <td>
            La cantidad de tiempos de ejecución de API de Node.js `CronJobs` que se deben completar por minuto. Aumente esta configuración junto con el paralelismo para mejorar el rendimiento. Esto debe aumentarse cada vez que se aumenta el paralelismo y las terminaciones siempre deben ser al menos mayores o iguales que el paralelismo. . Aumente esta configuración si observa períodos de tiempo sin trabajos de ejecución de API en ejecución. [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.repository`
          </td>

          <td>
            La imagen del contenedor que se extraerá para el tiempo de ejecución de la API de Node.js.

            Por defecto: `docker.io/newrelic/synthetics-node-api-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-api-runtime.image.pullPolicy`
          </td>

          <td>
            La política de extracción para el contenedor de tiempo de ejecución de la API de Node.js.

            Por defecto: `IfNotPresent`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.enabled`
          </td>

          <td>
            Si se debe desplegar o no el tiempo de ejecución browser Node.js. Esto se puede desactivar si no utiliza el script simple o monitor del browser.

            Por defecto: `true`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.parallelism`
          </td>

          <td>
            El número de tiempo de ejecución browser Chrome `CronJobs` para desplegar. La cantidad máxima de trabajos simultáneos browser Chrome que se ejecutarán en cualquier momento. [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `1`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.completions`
          </td>

          <td>
            El número de tiempos de ejecución browser Chrome `CronJobs` que se deben completar por minuto. Aumente esta configuración junto con el paralelismo para mejorar el rendimiento. Esto debe aumentarse cada vez que se aumenta el paralelismo y las terminaciones siempre deben ser al menos mayores o iguales que el paralelismo. Aumente esta configuración si observa períodos de tiempo sin que se ejecuten trabajos de tiempo de ejecución browser . [Detalles adicionales](#kubernetes-sizing).

            Por defecto: `6`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.repository`
          </td>

          <td>
            La imagen del contenedor que se extraerá para el tiempo de ejecución browser Node.js.

            Por defecto: `docker.io/newrelic/synthetics-node-browser-runtime`
          </td>
        </tr>

        <tr>
          <td>
            `node-browser-runtime.image.pullPolicy`
          </td>

          <td>
            La política de extracción para el contenedor de tiempo de ejecución browser Node.js.

            Por defecto: `IfNotPresent`
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Variables definidas por el usuario para monitor con script [#user-defined-vars]

Los administradores de trabajos de Private Sintético le permiten configurar variables de entorno para el monitor con script. Estas variables se administran localmente en SJM y se puede acceder a ellas a través de `$env.USER_DEFINED_VARIABLES`. Puede configurar variables definidas por el usuario de dos maneras. Puede montar un archivo JSON o puede proporcionar una variable de entorno al SJM en el lanzamiento. Si se proporcionan ambos, el SJM solo utilizará valores proporcionados por el entorno.

<CollapserGroup>
  <Collapser id="user-file-example" title="Montaje del archivo JSON">
    El usuario puede crear un archivo con formato JSON y montar el volumen donde se encuentra el archivo en una ruta de destino especificada en el contenedor SJM.

    El archivo debe tener permisos de lectura y contener un mapa con formato JSON. Ejemplo de archivo de variables definidas por el usuario:

    ```json
    {
      "KEY": "VALUE",
      "user_name": "MINION",
      "my_password": "PASSW0RD123",
      "my_URL": "https://newrelic.com/",
      "ETC": "ETC"
    }
    ```

    Coloque el archivo en el directorio de origen del host. El SJM espera que el nombre del archivo sea user\_defined\_variables.json

    Ejemplo Docker:

    El directorio objetivo esperado es: `/var/lib/newrelic/synthetics/variables/`

    ```sh
    docker run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw ...
    ```

    Ejemplo de Podman:

    En el caso de SELinux, monte el volumen adicionalmente con `:z` o `:Z`. Para obtener más información, consulte [la documentación de Podman.](https://docs.podman.io/en/latest/markdown/podman-run.1.html#volume-v-source-volume-host-dir-container-dir-options) El directorio objetivo esperado es: `/var/lib/newrelic/synthetics/variables/`

    ```sh
    podman run ... -v /variables:/var/lib/newrelic/synthetics/variables:rw,z ...
    ```

    Ejemplo de Kubernetes:

    El usuario tiene dos opciones al proporcionar un archivo al pod SJM en Kubernetes. Que puede:

    * Pasar un archivo local.
    * Proporcione un PersistentVolume que incluya `user_defined_variables.json`.

    ### Pasar en un archivo local

    Esta opción crea un recurso ConfigMap Kubernetes y lo monta en el pod SJM.

    ```sh
    helm install newrelic/synthetics-job-manager ... --set-file "synthetics.userDefinedVariables.userDefinedFile=[local-path]/user_defined_variables.json" ...
    ```

    ### Montar una `PersistentVolume`

    Esta opción requiere que el usuario proporcione un `PersistentVolume` que incluya el archivo `user_defined_variables.json` o un `PersistentVolumeClaim` al mismo. Para obtener más detalles sobre la instalación del gráfico de Helm usando un `PersistentVolume`, siga las instrucciones en [almacenamiento de datos permanente](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#permanent-data-storage).

    Una vez que el usuario preparó un `PersistentVolume` como se describe a continuación, inicie el SJM, configure la ruta donde se encuentra el archivo `user_defined_variables.json` y configure cualquier otra variable `synthetics.persistence` según sea necesario.

    ```sh
    helm install newrelic/synthetics-job-manger ... --set synthetics.userDefinedVariables.userDefinedPath="variables"
    ```
  </Collapser>

  <Collapser id="passing-env-var" title="Pasando como una variable de entorno">
    Las variables pueden pasar a su respectivo sistema contenedor a través de la variable de entorno.

    Ejemplo Docker:

    Utilice la bandera `-e` para configurar una variable de entorno denominada `USER_DEFINED_VARIABLES` y asígnele el valor de una cadena de mapa con formato JSON.

    ```sh
    docker run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Ejemplo de Podman:

    Utilice la bandera `-e` para configurar una variable de entorno denominada `USER_DEFINED_VARIABLES` y asígnele el valor de una cadena de mapa con formato JSON.

    ```sh
    podman run ... -e USER_DEFINED_VARIABLES='{"key":"value","name":"sjm"}' ...
    ```

    Ejemplo de Kubernetes:

    Emplee la bandera `--set-literal` para pasar la cadena con formato JSON.

    ```sh
    helm install newrelic/synthetics-job-manager ... --set-literal synthetics.userDefinedVariables.userDefinedJson='{"key":"value","name":"sjm"}' ...
    ```
  </Collapser>
</CollapserGroup>

### Acceder a variables de entorno definidas por el usuario desde un script [#env-vars-scripts]

Para hacer referencia a una variable de entorno definida por el usuario configurada, emplee el `$env.USER_DEFINED_VARIABLES` reservado seguido del nombre de una variable dada con notación de punto (por ejemplo, `$env.USER_DEFINED_VARIABLES.MY_VARIABLE`).

<Callout variant="caution">
  Las variables de entorno definidas por el usuario no se desinfectan del log. Considere utilizar la característica [de credenciales seguras](/docs/synthetics/new-relic-synthetics/using-monitors/secure-credentials-store-credentials-information-scripted-browsers) para información confidencial.
</Callout>

## Módulos de nodo personalizados [#custom-modules]

Se proporcionan módulos de nodo personalizados tanto en llamadas por minuto como en SJM. Le permiten crear un conjunto personalizado de [módulos de nodo](https://docs.npmjs.com/about-packages-and-modules) y usarlos en un monitor con script ( API con script y browser con script) para monitoreo sintético.

### Configurar su directorio de módulos personalizados

Cree un directorio con un archivo `package.json` siguiendo [las pautas oficiales de npm](https://docs.npmjs.com/files/package.json) en la carpeta raíz. El SJM instalará cualquier dependencia enumerada en el paquete.json. campo `dependencies` . Estas dependencias estarán disponibles cuando se ejecute el monitor en el administrador de trabajos privado de Sintético. Vea un ejemplo de esto a continuación.

#### Ejemplo

En este ejemplo, se utiliza un directorio de módulo personalizado con la siguiente estructura:

```
/example-custom-modules-dir/
    ├── counter
    │   ├── index.js
    │   └── package.json
    └── package.json            ⇦ the only mandatory file
```

`package.json` define `dependencies` como un módulo local (por ejemplo, `counter`) y cualquier módulo alojado (por ejemplo, `smallest` versión `1.0.1`):

```json
{
    "name": "custom-modules",
    "version": "1.0.0",                                ⇦ optional
    "description": "example custom modules directory", ⇦ optional
    "dependencies": {
    "smallest": "1.0.1",                               ⇦ hosted module
    "counter": "file:./counter"                        ⇦ local module
    }
}
```

### Agregue su directorio de módulos personalizados al SJM para Docker, Podman o Kubernetes

<CollapserGroup>
  <Collapser id="docker" title="Docker">
    Para docker, lanza SJM montando el directorio en `/var/lib/newrelic/synthetics/modules`. Por ejemplo:

    ```sh
    docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ...
    ```
  </Collapser>

  <Collapser id="podman" title="Podman">
    Para podman, inicie SJM montando el directorio en `/var/lib/newrelic/synthetics/modules`. En el caso de SELinux, monte el volumen adicionalmente con `:z` o `:Z`. Para obtener más información, consulte [la documentación de Podman](https://docs.podman.io/en/latest/markdown/podman-run.1.html#volume-v-source-volume-host-dir-container-dir-options). Por ejemplo:

    ```sh
    podman run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw,z ...
    ```
  </Collapser>

  <Collapser id="kubernetes" title="Kubernetes">
    Para Kubernetes, el directorio en `/var/lib/newrelic/synthetics/modules` debe existir en un PV antes de iniciar SJM con módulos personalizados habilitados.

    <Callout variant="tip">
      El modo de acceso a PV debe ser ReadWriteMany si necesita compartir almacenamiento entre varios pods.
    </Callout>

    Un método es crear un pod que monte el PV solo con el propósito de copiar el directorio de módulos personalizados al PV. El siguiente ejemplo emplea Amazon EFS con Amazon EKS:

    #### Cree el namespace, el volumen persistente y la reclamación del volumen persistente

    1. Cerciorar de que ya configuró su sistema de archivos EFS e instaló el [controlador CSI de EFS](https://github.com/kubernetes-sigs/aws-efs-csi-driver) en su clúster. También necesitará su ID de sistema de archivos EFS para los PV `spec.csi.volumeHandle`.

       ```sh
       kubectl apply -f - <<EOF
       apiVersion: v1
       kind: Namespace
       metadata:
         name: newrelic

       ---
       kind: StorageClass
       apiVersion: storage.k8s.io/v1
       metadata:
         name: efs-sc
       provisioner: efs.csi.aws.com

       ---
       apiVersion: v1
       kind: PersistentVolume
       metadata:
         name: custom-modules-pvc
       spec:
         capacity:
           storage: 5Gi
         volumeMode: Filesystem
         accessModes:
           - ReadWriteMany
         persistentVolumeReclaimPolicy: Retain
         storageClassName: efs-sc
         csi:
           driver: efs.csi.aws.com
           volumeHandle: <your-efs-filesystem-id>

       ---
       apiVersion: v1
       kind: PersistentVolumeClaim
       metadata:
         name: custom-modules-pvc
         namespace: newrelic
       spec:
         accessModes:
           - ReadWriteMany
         storageClassName: efs-sc
         resources:
           requests:
             storage: 5Gi
       EOF
       ```

    2. Cambie al namespace `newrelic` en su `~/.kube/config`.

       ```sh
       kubectl config get-contexts
       kubectl config set-context YOUR_CONTEXT --namespace=newrelic
       kubectl config view --minify | grep namespace:
       ```

    3. En este punto, el PVC debe estar vinculado al PV con el modo de acceso RWX.

       ```sh
       kubectl get pv,pvc
       [output] NAME                                  CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                         STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
       [output] persistentvolume/custom-modules-pvc   5Gi        RWX            Retain           Bound    newrelic/custom-modules-pvc   efs-sc         <unset>                          4m46s
       [output]
       [output] NAME                                       STATUS   VOLUME               CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
       [output] persistentvolumeclaim/custom-modules-pvc   Bound    custom-modules-pvc   5Gi        RWX            efs-sc         <unset>                 4m10s
       ```

       #### Crea `mount-custom-mods-pod` para copiar tu directorio de módulos personalizados

       ```sh
       kubectl apply -f - <<EOF
       apiVersion: v1
       kind: Pod
       metadata:
         name: mount-custom-mods-pod
       spec:
         containers:
         - name: mount-custom-mods-pod
           image: nginx
           resources:
             requests:
               memory: "64Mi"
               cpu: "250m"
             limits:
               memory: "128Mi"
               cpu: "500m"
           volumeMounts:
             - mountPath: "/var/lib/newrelic/synthetics/modules"
               name: custom-modules-storage
         volumes:
         - name: custom-modules-storage
           persistentVolumeClaim:
             claimName: custom-modules-pvc
       EOF
       ```

       En este punto, se debe crear y configurar el `mount-custom-mods-pod` para usar el volumen.

       ```sh
       kubectl describe po mount-custom-mods-pod | grep -A4 Volumes:
       [output] Volumes:
       [output]   custom-modules-storage:
       [output]     Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
       [output]     ClaimName:  custom-modules-pvc
       [output]     ReadOnly:   false
       ```

       Consulte el evento para ver si hay advertencias relacionadas con PV, PVC o `mount-custom-mods-pod`.

       ```sh
       kubectl get events --field-selector type=Warning --sort-by='.lastTimestamp'
       ```

       #### Copie su directorio de módulos personalizados al PV

       No es necesario copiar `node_modules` ya que lo generará el SJM en `npm install`.

       ```sh
       cd custom-modules
       rm -rf node_modules && cd ..
       ```

    4. Compruebe que `mount-custom-mods-pod` se esté ejecutando.

       ```sh
       kubectl get po
       [output] NAME                    READY   STATUS    RESTARTS   AGE
       [output] mount-custom-mods-pod   1/1     Running   0          5m43s
       ```

    5. Copiar al PV.

       ```sh
       kubectl cp custom-modules newrelic/mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules
       ```

    6. Compruebe que `/var/lib/newrelic/synthetics/modules/custom-modules/package.json` exista en el PV.

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l
       [output] total 4
       [output] drwxr-xr-x 2 root root 6144 Jun 29 03:49 custom-modules
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l custom-modules/
       [output] total 4
       [output] -rw-r--r-- 1 501 staff 299 Jun 29 03:49 package.json
       ```

       #### lanzar el SJM con la característica de módulos personalizados habilitada

       Establezca valores para `persistence.existingClaimName` y `customNodeModules.customNodeModulesPath` en la línea de comando o en un archivo YAML durante la instalación. El valor `customNodeModules.customNodeModulesPath` debe especificar la subruta en el volumen persistente donde existen sus archivos de módulos personalizados. Por ejemplo:

       ```sh
       helm upgrade --install synthetics-job-manager newrelic/synthetics-job-manager -n newrelic --set global.persistence.existingClaimName=custom-modules-pvc --set global.customNodeModules.customNodeModulesPath=custom-modules --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY
       [output] Release "synthetics-job-manager" does not exist. Installing it now.
       [output] NAME: synthetics-job-manager
       [output] LAST DEPLOYED: Fri Jun 28 16:53:28 2024
       [output] NAMESPACE: newrelic
       [output] STATUS: deployed
       [output] REVISION: 1
       [output] TEST SUITE: None
       ```

       El directorio `custom-modules` ahora debería contener los paquetes instalados en `node_modules`.

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# ls -l custom-modules/
       [output] total 16
       [output] -rw-r--r--  1 root root   836 Jun 29 03:51 README
       [output] drwxr-xr-x 18 root root  6144 Jun 29 03:51 node_modules
       [output] -rw-r--r--  1  501 staff  299 Jun 29 03:49 package.json
       [output] -rw-r--r--  1 root root   190 Jun 29 03:51 package.json.shasum
       ```

       Si no se detectan módulos de nodo personalizados, ajuste las licencias en el directorio `custom-modules` y el archivo `package.json` .

       ```sh
       kubectl exec -it mount-custom-mods-pod -- bash
       [output] root@mount-custom-mods-pod:/# cd /var/lib/newrelic/synthetics/modules/
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# chmod -R 777 custom-modules
       [output] root@mount-custom-mods-pod:/var/lib/newrelic/synthetics/modules# chown -R 2000:2000 custom-modules
       ```
  </Collapser>
</CollapserGroup>

Para comprobar si los módulos se instalaron correctamente o si se produjo algún error, busque las siguientes líneas en los registros [del contenedor](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs) o [pod](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring/#review-kubernetes-logs) `synthetics-job-manager` :

```log
2024-06-29 03:51:28,407{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Detected mounted path for custom node modules
2024-06-29 03:51:28,408{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Validating permission for custom node modules package.json file
2024-06-29 03:51:28,409{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Installing custom node modules...
2024-06-29 03:51:44,670{UTC} [main] INFO  c.n.s.j.p.options.CustomModules - Custom node modules installed successfully.
```

Ahora puede agregar `"require('smallest');"` al [script](/docs/synthetics/new-relic-synthetics/scripting-monitors/write-scripted-browsers) del monitor que envía a esta ubicación privada.

### Cambiar `package.json` [#change-package-json]

Además de los módulos locales y alojados, también puede utilizar [módulos de Node.js.](/docs/synthetics/new-relic-synthetics/scripting-monitors/import-nodejs-modules) Para actualizar los módulos personalizados utilizados por su SJM, realice cambios en el archivo `package.json` y reinicie SJM. Durante el proceso de reinicio, el SJM reconocerá el cambio de configuración y realizará automáticamente operaciones de limpieza y reinstalación para garantizar que se apliquen los módulos actualizados.

<Callout variant="caution">
  Módulos locales: si bien su `package.json` puede incluir cualquier módulo local, estos módulos deben residir dentro del árbol debajo de su directorio de módulos personalizados. Si se almacena fuera del árbol, el proceso de inicialización fallará y verá un mensaje de error en el [log docker ](/docs/synthetics/new-relic-synthetics/private-locations/job-manager-maintenance-monitoring#monitor-docker-logs)después de iniciar SJM.
</Callout>

## Almacenamiento permanente de datos [#permanent-data-storage]

Es posible que el usuario desee emplear almacenamiento de datos permanente para proporcionar el archivo `user_defined_variables.json` o admitir módulos de nodo personalizados.

### Docker

Para configurar el almacenamiento permanente de datos en Docker:

1. Cree un directorio en el host donde está iniciando Job Manager. Este es su directorio de origen.

2. Inicie el Administrador de trabajos, montando el directorio de origen en el directorio de destino `/var/lib/newrelic/synthetics`.

   Ejemplo:

   ```sh
   docker run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw ...
   ```

### Podman

Para configurar el almacenamiento de datos permanente en Podman:

1. Cree un directorio en el host donde está iniciando Job Manager. Este es su directorio de origen.
2. Inicie el Administrador de trabajos, montando el directorio de origen en el directorio de destino `/var/lib/newrelic/synthetics`.

Ejemplo:

```sh
podman run ... -v /sjm-volume:/var/lib/newrelic/synthetics:rw,z ...
```

### Kubernetes

Para configurar el almacenamiento permanente de datos en Kubernetes, el usuario tiene dos opciones:

1. Proporcione un PersistentVolumeClaim (PVC) existente para un PersistentVolume (PV) existente y establezca el valor de configuración `synthetics.persistence.existingClaimName` . Ejemplo:

   ```sh
   helm install ... --set synthetics.persistence.existingClaimName=sjm-claim ...
   ```

2. Proporcione un nombre de PersistentVolume (PV) existente y establezca el valor de configuración `synthetics.persistence.existingVolumeName` . Helm generará una PVC para el usuario. El usuario también puede configurar opcionalmente los siguientes valores:

* `synthetics.persistence.storageClass`:La clase de almacenamiento del PV existente. Si no se proporciona, Kubernetes empleará la clase de almacenamiento predeterminada.

* `synthetics.persistence.size`:El tamaño de la reclamación. Si no se configura, el valor predeterminado actualmente es 2Gi.

  ```sh
  helm install ... --set synthetics.persistence.existingVolumeName=sjm-volume --set synthetics.persistence.storageClass=standard ...
  ```

## Consideraciones de tamaño para OpenShift, Kubernetes y Docker [#kubernetes-sizing]

<Callout variant="tip">
  Las consideraciones de tamaño específicas Docker estarán disponibles pronto.
</Callout>

Si está trabajando en entornos más grandes, es posible que necesite personalizar la configuración del administrador de trabajos para cumplir con los requisitos mínimos para ejecutar el monitor Sintético de manera eficiente. Muchos factores pueden afectar los requisitos de tamaño para el despliegue de un administrador de trabajos de Sintético, entre ellos:

* Si se requieren todos los tiempos de ejecución según el uso esperado
* El número de trabajos por minuto por tipo de monitor (ping, browser simple o con secuencias de comandos y API con secuencias de comandos)
* Duración del trabajo, incluidos los trabajos cuyo tiempo de espera es de aproximadamente 3 minutos
* El número de fracasos laborales. En el caso de errores de trabajo, se programan reintentos automáticos cuando un monitor comienza a fallar para proporcionar una lógica de reintento 3/3 incorporada. Estos trabajos adicionales se suman a los requisitos de rendimiento del administrador de trabajos de Sintético.

Además de los ajustes de configuración de tamaño que se enumeran a continuación, se pueden implementar administradores de trabajos de Sintético adicionales con la misma clave de ubicación privada para equilibrar la carga de trabajos en múltiples entornos.

## Kubernetes y OpenShift [#k8s]

Cada entorno de ejecución empleado por el administrador de trabajos Kubernetes y OpenShift Sintético se puede dimensionar de forma independiente configurando valores en el [gráfico de Helm](https://github.com/newrelic/helm-charts/tree/master/charts/synthetics-job-manager).

Se pueden iniciar tiempos de ejecución de ping adicionales para ayudar a ejecutar la carga del monitor de ping aumentando la configuración `ping-runtime.replicaCount` del valor predeterminado de `1`.

La API de Node.js y los tiempos de ejecución browser Node.js se dimensionan de forma independiente mediante una combinación de las configuraciones `parallelism` y `completions`. La configuración ideal para estas configuraciones variará según los requisitos del cliente.

La configuración `parallelism` controla cuántos pods de un tiempo de ejecución particular se ejecutan simultáneamente. La configuración `parallelism` es el equivalente a la configuración `synthetics.heavyWorkers` en el minion privado en contenedor (llamadas por minuto). Asegúrese de que su clúster de Kubernetes tenga suficientes recursos disponibles para ejecutar esta cantidad de pods según su [solicitud de recursos y sus valores límite](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#kubernetes-requirements).

La configuración `completions` controla cuántos pods de un tiempo de ejecución particular deben completarse antes de que `CronJob` pueda iniciar otro trabajo de Kubernetes para ese tiempo de ejecución. Tenga en cuenta la diferencia entre un trabajo de Kubernetes (J mayúscula) y un trabajo de monitor Sintético. Para mejorar la eficiencia, `completions` debe establecerse entre 6 y 10 veces el valor `parallelism` . Esto puede ayudar a minimizar la ineficiencia de &quot;cerca del final de las finalizaciones&quot;, donde menos del grupo de `parallelism` podrían terminar ejecutándose mientras el trabajo de Kubernetes espera a que finalicen los `completions` .

Cuando `completions` es mayor que 1, el pod con estado &quot;Completado&quot; permanecerá visible en la salida de `kubectl get pods -n YOUR_NAMESPACE` hasta que se hayan cumplido todas las finalizaciones definidas en el trabajo de Kubernetes, por ejemplo, 6/6 finalizaciones. Los recursos se liberan del nodo cuando un pod tiene el estado Completado o Fallido.

Una duración del trabajo de Kubernetes de 5 minutos (`kubectl get jobs -n YOUR_NAMESPACE`) es un objetivo conservador para tener en cuenta la variabilidad en el tiempo que tarda el pod en completarse y cuántos trabajos de Sintético deben ejecutarse por minuto (tasa de trabajos). Las siguientes ecuaciones se pueden utilizar como punto de partida para `completions` y `parallelism` para cada tiempo de ejecución. Es posible que sea necesario realizar ajustes en función de las observaciones del crecimiento de la cola de ubicación privada.

```m
completions = 300 / avg job duration (s)
parallelism = synthetics jobs per 5 minutes / completions
```

Es probable que diferentes tiempos de ejecución tengan diferentes duraciones y tarifas de trabajo de Sintético. La siguiente consulta se puede utilizar para obtener la duración y la tarifa promedio para una ubicación privada.

```sql
-- non-ping average job duration by runtime type
FROM SyntheticCheck SELECT average(duration) AS 'avg job duration'
WHERE type != 'SIMPLE' AND location = 'YOUR_PRIVATE_LOCATION' FACET type SINCE 1 hour ago

-- non-ping jobs per minute by runtime type
FROM SyntheticCheck SELECT rate(uniqueCount(id), 5 minutes) AS 'jobs per 5 minutes'
WHERE type != 'SIMPLE' AND location = 'YOUR_PRIVATE_LOCATION' FACET type SINCE 1 hour ago
```

<Callout variant="tip">
  Las consultas anteriores se basan en resultados actuales. Si su ubicación privada no tiene ningún resultado o el administrador de trabajos no está funcionando al máximo, es posible que los resultados de la consulta no sean precisos. En ese caso, pruebe con algunos valores diferentes para `completions` y `parallelism` hasta que vea una duración de `kubectl get jobs -n YOUR_NAMESPACE` de al menos 5 minutos (suficientes finalizaciones) y la cola no crezca (suficiente paralelismo).
</Callout>

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        Ejemplo
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `parallelism=1`

        `completions=1`
      </td>

      <td>
        El tiempo de ejecución ejecutará 1 trabajo Sintético por minuto. Después de que se complete 1 trabajo, la configuración `CronJob` comenzará un nuevo trabajo en el siguiente minuto. <DNT>**Throughput will be extremely limited with this configuration.**</DNT>
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=1`

        `completions=6`
      </td>

      <td>
        El tiempo de ejecución ejecutará 1 trabajo de Sintético a la vez. Una vez finalizado el trabajo, se iniciará un nuevo trabajo inmediatamente. Una vez que se complete el número de trabajos de configuración `completions` , la configuración `CronJob` iniciará un nuevo trabajo de Kubernetes y restablecerá el contador de finalización. <DNT>**Throughput will be limited, but slightly better.**</DNT> Un único trabajo de Sintético de larga duración bloqueará el procesamiento de cualquier otro trabajo de Sintético de este tipo.
      </td>
    </tr>

    <tr>
      <td>
        `parallelism=3`

        `completions=24`
      </td>

      <td>
        El tiempo de ejecución ejecutará 3 trabajos de Sintético a la vez. Una vez completado cualquiera de estos trabajos, se iniciará un nuevo trabajo inmediatamente. Una vez que se complete el número de trabajos de configuración `completions` , la configuración `CronJob` iniciará un nuevo trabajo de Kubernetes y restablecerá el contador de finalización. <DNT>**Throughput is much better with this or similar configurations.**</DNT> Un único trabajo de Sintético de larga duración tendrá un impacto limitado en el procesamiento de otros trabajos de Sintético de este tipo.
      </td>
    </tr>
  </tbody>
</table>

Si los trabajos de Sintético tardan más en completarse, se necesitarán menos terminaciones para llenar 5 minutos con trabajos, pero se necesitarán más módulos paralelos. De manera similar, si es necesario procesar más trabajos de Sintético por minuto, se necesitarán más pods paralelos. La configuración `parallelism` afecta directamente la cantidad de trabajos de Sintético por minuto que se pueden ejecutar. Un valor demasiado pequeño y la cola puede crecer. Un valor demasiado grande y los nodos pueden verse limitados en recursos.

Si su configuración `parallelism` funciona bien para mantener la cola en cero, establecer un valor más alto para `completions` que el calculado a partir de `300 / avg job duration` puede ayudar a mejorar la eficiencia de dos maneras:

* Adáptese a la variabilidad en la duración de los trabajos de modo que al menos 1 minuto esté ocupado con trabajos de Sintético, que es la duración mínima de CronJob.
* Reduzca el número de ciclos de terminación para minimizar la ineficiencia de &quot;acercarse al final de las terminaciones&quot;, donde el siguiente conjunto de terminaciones no puede comenzar hasta que se complete el trabajo final.

Es importante tener en cuenta que el valor `completions` no debe ser demasiado grande o CronJob experimentará un evento de advertencia como el siguiente:

```
8m40s       Warning   TooManyMissedTimes     cronjob/synthetics-node-browser-runtime                  too many missed start times: 101. Set or decrease .spec.startingDeadlineSeconds or check clock skew
```

<Callout variant="tip">
  Tenga en cuenta que New Relic no es responsable de ninguna modificación que realice en los archivos del administrador de trabajos de Sintéticos.
</Callout>