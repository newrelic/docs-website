---
title: Instalar el administrador de trabajos Sintético
tags:
  - Synthetics
  - Synthetic monitoring
  - Private locations
metaDescription: Install New Relic's container based job manager that accepts and runs jobs assigned to your private locations
freshnessValidatedDate: never
translationType: machine
---

Nuestros administradores de trabajos de monitoreo de Sintético son recursos basados en [contenedoresDocker ](https://www.docker.com/resources/what-container)que aceptan y ejecutan [monitores de Sintético](/docs/synthetics/synthetic-monitoring/using-monitors/intro-synthetic-monitoring/#types-of-synthetic-monitors) asignados a [la ubicación privada](/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations).

El administrador de trabajos puede operar en un entorno de sistema Docker , un entorno de sistema Podman, un entorno de sistema de orquestación Kubernetes o un entorno de sistema OpenShift. El administrador de trabajos detecta automáticamente su entorno para seleccionar el modo operativo apropiado.

## Característica del gestor de trabajo sintético [#enhancements]

Debido a que el administrador de trabajos de Sintético opera como un contenedor en lugar de una máquina virtual, hemos simplificado [la instalación](#install), [la introducción ](#start)y [la actualización](#install) de la administración y orquestación de trabajos. También viene con algunas funciones adicionales:

* Compatible con Linux, [macOS](https://docs.docker.com/docker-for-mac/) y [Windows](https://docs.docker.com/docker-for-windows/).
* [Seguridad](#security) mejorada y soporte para la ejecución de usuarios [no root](#run-as-non-root) .
* Capacidad de aprovechar un contenedor Docker como entorno [sandbox](#docker-dependencies) .

## Característica específica de Kubernetes [#kubernetes-enhancements]

El administrador de trabajos introduce algunas funciones adicionales específicas de Kubernetes:

* Utiliza recursos de Kubernetes CronJob para ejecutar un monitor sin ping
* No requiere acceso privilegiado al socket de la docker
* Soporta clúster de Kubernetes alojado y on-premise
* Admite varios motores de contenedores como Docker y Containerd
* Implementable a través de gráficos Helm y YAML de configuración
* Permite la asignación de recursos basada en el tiempo de ejecución del trabajo configurable (ping, API y browser) para una gestión óptima de los recursos.
* Observabilidad ofrecida a través del explorador New Relic clúster de Kubernetes

## requisito del sistema y compatibilidad [#system-requirements]

Para alojar administradores de trabajos de Sintético, su sistema debe cumplir con los requisitos mínimos para el entorno del sistema elegido.

<Callout variant="caution">
  No modifique ningún archivo del administrador de trabajos de Sintético. New Relic no es responsable de las modificaciones que realice. Para obtener más información, comuníquese con su representante de cuenta o con un [representante técnico de ventas](https://newrelic.com/contact-sales) de New Relic.
</Callout>

<CollapserGroup>
  <Collapser
    id="docker-requirements"
    title={<><img src="/images/synthetic_logo_docker.webp" title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }} />Requisitos del entorno del sistema Docker Contenedor</>
    }
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "265px" }}>
            Compatibilidad para
          </th>

          <th>
            Requisitos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            Sistema operativo
          </td>

          <td>
            <DNT>**Linux kernel:**</DNT> 4.18 o superior (Recomendado para v447+)<br /> <DNT>**macOS:**</DNT> 10.11 o superior<br /> <DNT>**Windows:**</DNT> Windows 10 de 64 bits o superior

            También debe configurar docker para ejecutar el contenedor de Linux para que los administradores de trabajos de Sintético funcionen en sistemas Windows.
          </td>
        </tr>

        <tr>
          <td>
            Procesador
          </td>

          <td>
            Una CPU AMD64 o x86\_64 moderna y multinúcleo
          </td>
        </tr>

        <tr>
          <td>
            Memoria
          </td>

          <td>
            3.256 GiB de RAM por núcleo de CPU (dedicado)
          </td>
        </tr>

        <tr>
          <td>
            Tamaño del disco
          </td>

          <td>
            Un mínimo de 50 GiB por host
          </td>
        </tr>

        <tr>
          <td>
            sistema de archivos de disco
          </td>

          <td>
            NFSv4.1 o superior (si usa NFS)
          </td>
        </tr>

        <tr>
          <td>
            [Versión Docker](https://docs.docker.com/engine/release-notes/)
          </td>

          <td>
            Docker [17.12.1-ce](https://docs.docker.com/engine/release-notes/17.12/) o mas alto
          </td>
        </tr>

        <tr>
          <td>
            Clave de ubicación privada
          </td>

          <td>
            Debes tener una [clave de ubicación privada](#private-location-key)
          </td>
        </tr>
      </tbody>
    </table>

    <Callout variant="caution">
      El administrador de trabajos Docker Sintéticos no está diseñado para usar con orquestadores de contenedores como AWS ECS, Docker Swarm, Apache Mesos, Azure contenedor instancia, etc. Ejecutar el administrador de trabajos Docker Sintéticos en un orquestador de contenedores genera problemas inesperados, ya que funciona como un orquestador en sí mismo. Si está empleando la orquestación de contenedor, consulte nuestros [requisitos del administrador de trabajosKubernetes Sintéticos](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#kubernetes-requirements).
    </Callout>

    <Callout variant="caution">
      A partir de Synthetics Job Manager v447 (que utiliza Ubuntu 24.04 como su imagen base), RHEL 7 y otras distribuciones que utilizan versiones del kernel de Linux anteriores a 4.18 ya no son compatibles debido a los requisitos modernos de glibc y seccomp. Para una experiencia estable, use RHEL 8/9 o una distribución de Linux moderna equivalente.
    </Callout>
  </Collapser>

  <Collapser
    id="podman-requirements"
    title={<><img src="/images/synthetic_logo_podman.webp" title="Podman icon" alt="Podman icon" style={{ height: '35px', width: '40px' }} /></>
    }
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "265px" }}>
            Compatibilidad para
          </th>

          <th>
            Requisitos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            Sistema operativo
          </td>

          <td>
            <DNT>**Linux kernel:**</DNT> 4.18 o superior (Recomendado para v447+)<br />
          </td>
        </tr>

        <tr>
          <td>
            Procesador
          </td>

          <td>
            Una CPU AMD64 o x86\_64 moderna y multinúcleo
          </td>
        </tr>

        <tr>
          <td>
            Memoria
          </td>

          <td>
            3.256 GiB de RAM por núcleo de CPU (dedicado)
          </td>
        </tr>

        <tr>
          <td>
            Tamaño del disco
          </td>

          <td>
            Un mínimo de 50 GiB por host
          </td>
        </tr>

        <tr>
          <td>
            sistema de archivos de disco
          </td>

          <td>
            NFSv4.1 o superior (si usa NFS)
          </td>
        </tr>

        <tr>
          <td>
            [Versión de Podman](https://github.com/containers/podman/releases)
          </td>

          <td>
            Podman [5.0.0-ce](https://github.com/containers/podman/releases/tag/v5.0.0) o superior
          </td>
        </tr>

        <tr>
          <td>
            Clave de ubicación privada
          </td>

          <td>
            Debes tener una [clave de ubicación privada](#private-location-key)
          </td>
        </tr>
      </tbody>
    </table>

    <Callout variant="caution">
      El administrador de trabajos Podman Sintéticos no está diseñado para usar con orquestadores de contenedores como AWS ECS, Docker Swarm, Apache Mesos, Azure contenedor instancia, etc. Ejecutar el administrador de trabajos Docker Sintéticos en un orquestador de contenedores genera problemas inesperados, ya que funciona como un orquestador en sí mismo. Si está empleando la orquestación de contenedor, consulte nuestros [requisitos del administrador de trabajosKubernetes Sintéticos](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager/#kubernetes-requirements).
    </Callout>
  </Collapser>

  <Collapser
    id="kubernetes-requirements"
    title={<><img src="/images/synthetic_logo_k8logo.webp" title="Kubernetes icon" alt="Kubernetes icon" style={{ height: '35px', width: '40px' }} />Requisitos del entorno del sistema de orquestación de contenedores Kubernetes</>
    }
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "265px" }}>
            Compatibilidad para
          </th>

          <th>
            Requisitos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            Sistema operativo
          </td>

          <td>
            <DNT>**Linux kernel:**</DNT> 4.18 o superior (Recomendado para v447+) <br /><DNT>**macOS:**</DNT> 10.11 o superior<br />

            El contenedor de Linux, incluido el administrador de trabajos, solo se ejecuta en nodos Linux K8.
          </td>
        </tr>

        <tr>
          <td>
            Procesador
          </td>

          <td>
            Una CPU moderna y multinúcleo
          </td>
        </tr>

        <tr>
          <td>
            Podde gestión de trabajos Sintético
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 0,5 hasta 0,75<br /> <DNT>**Memory:**</DNT> 800Mi hasta 1600Mi

            Los recursos asignados a un pod de administrador de trabajos de Sintético son configurables por el usuario.
          </td>
        </tr>

        <tr>
          <td>
            Podde tiempo de ejecución de ping
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 0,5 hasta 0,75<br /> <DNT>**Memory:**</DNT> 500Mi hasta 1Gi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución de ping son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Podde tiempo de ejecución de API de Node.js
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 0,5 hasta 0,75<br /> <DNT>**Memory:**</DNT> 1250Mi hasta 2500Mi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución de API de Node.js son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Runtime de ejecución Node.js browser pod
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 1,0 hasta 1,5<br /> <DNT>**Memory:**</DNT> 2000Mi hasta 3000Mi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución browser Node.js son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Tamaño del disco
          </td>

          <td>
            <DNT>**Root volume:**</DNT> Un mínimo de 50 GiB<br />
          </td>
        </tr>

        <tr>
          <td>
            sistema de archivos de disco
          </td>

          <td>
            NFSv4.1 o superior (si usa NFS)
          </td>
        </tr>

        <tr>
          <td>
            Versión Kubernetes
          </td>

          <td>
            Se requiere [Kubernetes v1.21](https://kubernetes.io/blog/2021/04/08/kubernetes-1-21-release-announcement/) o posterior.
          </td>
        </tr>

        <tr>
          <td>
            Clave de ubicación privada
          </td>

          <td>
            Debes tener una [clave de ubicación privada](#private-location-key)
          </td>
        </tr>

        <tr>
          <td>
            Timón
          </td>

          <td>
            Siga [las instrucciones de instalación de Helm v3](https://helm.sh/docs/intro/install/) para su sistema operativo.
          </td>
        </tr>

        <tr>
          <td>
            Kubectl
          </td>

          <td>
            Siga [las instrucciones de instalación de Kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) para su sistema operativo.
          </td>
        </tr>
      </tbody>
    </table>

    Para ver las versiones, dependencias, valores predeterminados de cuántos pods de tiempo de ejecución se inician con cada administrador de trabajos de Sintético y más, consulte [Mostrar ayuda y ejemplos](#help) a continuación.
  </Collapser>

  <Collapser id="Openshift-requirements" title="Requisitos del entorno del sistema contenedor OpenShift">
    <table>
      <thead>
        <tr>
          <th style={{ width: "265px" }}>
            Compatibilidad para
          </th>

          <th>
            Requisitos
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            Sistema operativo
          </td>

          <td>
            <DNT>**Linux kernel:**</DNT> [4.18 o superior (Recomendado para v447+)](https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html/deploying_installer-provisioned_clusters_on_bare_metal/ipi-install-prerequisites#minimum-resource-requirements)<br /> <DNT>**macOS:**</DNT> 10.11 o superior<br />

            El contenedor de Linux, incluido el administrador de trabajos, solo se ejecuta en nodos Linux K8.
          </td>
        </tr>

        <tr>
          <td>
            Procesador
          </td>

          <td>
            Un moderno procesador multinúcleo `AMD64` o `x86_64 CPU`
          </td>
        </tr>

        <tr>
          <td>
            Podde tiempo de ejecución de ping
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 0,5 hasta 0,75<br /> <DNT>**Memory:**</DNT> 500Mi hasta 1Gi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución de ping son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Podde tiempo de ejecución de API de Node.js
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 0,5 hasta 0,75<br /> <DNT>**Memory:**</DNT> 500Mi hasta 1Gi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución de ping son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Podde tiempo de ejecución de API de Node.js
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 0,5 hasta 0,75<br /> <DNT>**Memory:**</DNT> 1250Mi hasta 2500Mi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución de API de Node.js son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Runtime de ejecución Node.js browser pod
          </td>

          <td>
            <DNT>**CPU (vCPU/Core):**</DNT> 1,0 hasta 1,5<br /> <DNT>**Memory:**</DNT> 2000Mi hasta 3000Mi

            Consideraciones adicionales:

            * Los recursos asignados a un pod de tiempo de ejecución browser Node.js son configurables por el usuario.
            * La relación máxima de recursos de solicitud de límite tanto para la CPU como para la memoria es 2.
          </td>
        </tr>

        <tr>
          <td>
            Tamaño del disco
          </td>

          <td>
            <DNT>**Root volume:**</DNT> Un mínimo de 50 GiB<br />
          </td>
        </tr>

        <tr>
          <td>
            sistema de archivos de disco
          </td>

          <td>
            NFSv4.1 o superior (si usa NFS)
          </td>
        </tr>

        <tr>
          <td>
            Versión
          </td>

          <td>
            Versión 4.11 y posteriores.
          </td>
        </tr>

        <tr>
          <td>
            Clave de ubicación privada
          </td>

          <td>
            Debes tener una [clave de ubicación privada](#private-location-key)
          </td>
        </tr>

        <tr>
          <td>
            Timón
          </td>

          <td>
            Siga [las instrucciones de instalación de Helm v3](https://helm.sh/docs/intro/install/) para su sistema operativo.
          </td>
        </tr>
      </tbody>
    </table>

    Para ver las versiones, dependencias, valores predeterminados de cuántos pods de tiempo de ejecución se inician con cada administrador de trabajos de Sintético y más, consulte [Mostrar ayuda y ejemplos](#help) a continuación.
  </Collapser>
</CollapserGroup>

## Clave de ubicación privada

Antes de lanzar los gestores de trabajos de Sintético, debes tener una [clave de ubicación privada](/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations#create-location). Su administrador de trabajos de Sintético usa la clave para autenticarse en New Relic y ejecutar el monitor asociado con esa ubicación privada.

Para encontrar la clave de una ubicación privada existente:

1. Vaya a <DNT>**[one.newrelic.com &gt; Synthetic monitoring &gt; Private locations](https://one.newrelic.com/synthetics-nerdlets/private-location-list)**</DNT>.
2. En el índice <DNT>**Private locations**</DNT> , localice la ubicación privada a la que desea que se asigne su administrador de trabajos de Sintético.
3. Tenga en cuenta la clave asociada a la ubicación privada con la clave <Icon name="fe-key" /> icono.

## Instalar, actualizar y configurar el administrador de trabajos Sintético [#install]

Si está ejecutando más de un contenedor de ubicación privada Docker o Podman en el mismo host, tendrá conflictos de puertos. Para evitar esta contención de puertos, cerciorar de hacer lo siguiente cuando comience a configurar administradores de trabajos:

* Ejecute administradores de trabajos y llamadas por minuto en diferentes hosts.
* Ejecute cada administrador de trabajos en un host independiente.
* Ejecute cada llamada por minuto en un host diferente.

Las imágenes del administrador de trabajos de Sintético están alojadas en [Docker Hub](https://hub.docker.com/). Vaya a [hub.docker.com/r/newrelic/synthetics-job-manager/tags](https://hub.docker.com/r/newrelic/synthetics-job-manager/tags) para obtener una lista de todos los lanzamientos.

A menos que esté alojando las imágenes en un repositorio de imágenes local, debe permitir conexiones a `docker.io` a través de su firewall para que Docker o Podman puedan extraer el trabajo del administrador de imágenes sintéticas y el tiempo de ejecución de las imágenes sintéticas. Cuando se inicia el administrador de trabajos de Sintéticos, las imágenes en tiempo de ejecución se extraen automáticamente. Consulte [Configuración del entornoDocker ](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration/#docker-env-config), [Configuración del entorno Podman](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration/#podman-env-config) y [Configuración del entornoKubernetes ](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration/#kubernetes-env-config)para obtener detalles sobre cómo configurar un repositorio local y el extremo del registro del corredor.

Para obtener más detalles sobre la configuración avanzada, consulte [Configuración del administrador de trabajos de Sintético](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration).

## Iniciar gestor de trabajos Sintético [#start]

A continuación se muestran las instrucciones aplicables de Docker, Podman o Kubernetes para iniciar el administrador de trabajos.

<CollapserGroup>
  <Collapser
    id="docker-update"
    title={<><img src="/images/synthetic_logo_docker.webp" title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }} />Procedimiento de inicio de docker</>
    }
  >
    1. Localice su [clave de ubicación privada](#private-location-key).

    2. Cerciorar de habilitar [la dependenciaDocker ](#docker-dependencies)para el sandbox y [de instalar](#install-update) el administrador de trabajos Sintéticos en su sistema.

    3. Ejecute el script apropiado para su sistema. Adapte el valor predeterminado común `/var/run/docker.sock` en los siguientes ejemplos para que coincida con su sistema.

       * Linux/macOS:

         ```shell
         docker run \
             --name YOUR_CONTAINER_NAME \
             -e "PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY" \
             -v /var/run/docker.sock:/var/run/docker.sock:rw \
             -d \
             --restart unless-stopped \
             newrelic/synthetics-job-manager:latest
         ```

       * Ventanas:

         ```shell
         docker run ^
             --name YOUR_CONTAINER_NAME ^
             -e "PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY" ^
             -v /var/run/docker.sock:/var/run/docker.sock:rw ^
             -d ^
             --restart unless-stopped ^
             newrelic/synthetics-job-manager:latest
         ```

       Vea el registro de su contenedor minion:

       ```shell
       docker logs --follow YOUR_CONTAINER_NAME
       ```
  </Collapser>

  <Collapser
    id="podman-update"
    title={<><img src="/images/synthetic_logo_podman.webp" title="Podman icon" alt="Podman icon" style={{ height: '35px', width: '40px' }} /></>
    }
  >
    1. Localice su [clave de ubicación privada](#private-location-key).
    2. Cerciorar de habilitar [la dependencia de Podman](#podman-dependencies) para el sandbox y [de instalar](#install-update) el administrador de trabajos Sintéticos en su sistema.
    3. Ejecute el siguiente script para su sistema.

    Para crear un pod en Linux y agregar la dirección IP de la máquina host:

    ```
    podman pod create --network slirp4netns --name YOUR_POD_NAME --add-host=podman.service:HOST_IP_ADDRESS
    ```

    Para iniciar el Administrador de trabajos:

    ```
    podman run \
    --name YOUR_CONTAINER_NAME \
    --pod YOUR_POD_NAME \
    -e "PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY" \
    -e "CONTAINER_ENGINE=PODMAN" \
    -e "PODMAN_API_SERVICE_PORT=YOUR_PODMAN_API_SERVICE_PORT" \
    -e "PODMAN_POD_NAME=YOUR_POD_NAME" \
    -d \
    --restart unless-stopped \
    newrelic/synthetics-job-manager:latest
    ```

    Para ver los logs de su minion contenedor:

    ```
    podman logs --follow YOUR_CONTAINER_NAME
    ```
  </Collapser>

  <Collapser
    id="kubernetes-install"
    title={<><img src="/images/synthetic_logo_k8logo.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ height: '35px', width: '40px' }} />Procedimiento de inicio de Kubernetes</>
    }
  >
    1. Localice su [clave de ubicación privada](#private-location-key).

    2. Configure un namespace para el administrador de trabajos de Sintético en su clúster de Kubernetes:

       ```shell
       kubectl create namespace YOUR_NAMESPACE
       ```

    3. Copie los gráficos de Helm del repositorio de New Relic Helm.

       * Si está copiando los gráficos por primera vez:

         ```shell
         helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com
         ```

       * Si anteriormente copió los gráficos de Helm del repositorio de New Relic Helm, obtenga lo último:

         ```shell
         helm repo update
         ```

    4. Instale el administrador de trabajos Sintético con el siguiente comando de Helm:

       * Para una nueva instalación del administrador de trabajos Sintético:

         ```
         helm install YOUR_JOB_MANAGER_NAME YOUR_REPO_NAME/synthetics-job-manager -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY
         ```

       * Para actualizar una instalación existente del administrador de trabajos de Sintético:

         ```shell
         helm upgrade YOUR_JOB_MANAGER_NAME YOUR_REPO_NAME/synthetics-job-manager -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY
         ```

    5. Compruebe si el pod del administrador de trabajos de Sintético está en funcionamiento:

       ```shell
       kubectl get -n YOUR_NAMESPACE pods
       ```

       Una vez que el atributo `status` de cada pod se muestra como `running`, su administrador de trabajos de Sintético estará activo y listo para ejecutar el monitor asignado a su ubicación privada.
  </Collapser>

  <Collapser id="-install" title="Procedimiento de inicio de OpenShift">
    Cerciorar de tener la [CLI de OpenShift (oc)](https://docs.redhat.com/en/documentation/openshift_container_platform/4.8/html/cli_tools/openshift-cli-oc) instalada para ejecutar comandos a través de la CLI de OpenShift.

    1. Localice su [clave de ubicación privada](#private-location-key).

    2. Inicie sesión en su proyecto OpenShift:

       ```shell
       oc project your_namespace
       ```

    3. Crear etiqueta de imagen usando el comando:

       ```shell
       oc create imagestream image_streame_name -n your_namespace
       ```

    4. Crear `buildConfig.yaml`

       ```dockerfile
       apiVersion: build.openshift.io/v1
       kind: BuildConfig
       metadata:
         name: synthetics-node-api-runtime-build
         namespace: <your_namespace> 
       spec:
         output:
           to:
             kind: ImageStreamTag
             name: <your_output_image_name>:<output_tag> 
         source:
           type: Dockerfile
           dockerfile: |-
             FROM newrelic/synthetics-node-api-runtime:latest 
             USER root
             RUN setcap -r /usr/bin/node
             USER 2000
         strategy:
           type: Docker
           dockerStrategy:
             platform:
               architecture: amd64 
         postCommit: {}
         triggers:
           - type: ConfigChange
           - type: ImageChange
             imageChange:
               from:
                 kind: ImageStreamTag
                 name: <image_stream_name>:latest
       ```

    5. Aplicar el `BuildConfig`:

       ```shell
       oc create -f buildConfig.yaml
       ```

    6. (Opcional) Iniciar la compilación (si la compilación no se inicia automáticamente, ejecute este comando):

       ```shell
       oc start-build synthetics-node-api-runtime-build -n your-namespace
       ```

       <Callout variant="important">
         Monitorear el progreso de la construcción empleando:

         ```shell
         oc logs -f bc/synthetics-node-api-runtime-build -n synthetics
         ```
       </Callout>

    7. desplegar con Helm:

       * Ejecute este comando para agregar el repositorio de gráficos New Relic Helm a su configuración local Helm, lo que le permitirá instalar fácilmente la integración de Kubernetess.

         ```shell
         helm repo add newrelic https://helm-charts.newrelic.com
         ```

       * Ejecute el siguiente comando para ejecutar SJM en su ubicación privada en OpenShift:

         ```shell
         helm install release_name newrelic/synthetics-job-manager -n your_namespace --set synthetics.privateLocationKey=private_location_key --set image_stream_name.image.repository=image_repo --set image_stream_name.appVersionOverride=tag
         ```

         * **release\_name**: cualquier nombre que quieras darle a tu imagen.

         * **your\_namespace**: como archivo mentionml.

         * **private\_location\_key**: clave única correspondiente a su ubicación privada.

         * **image\_stream\_name**: como se menciona en el archivo yaml buildConfig yaConfig.

         * **etiqueta**: como se menciona en el archivo yaml buildConfig.

         * **repositorio\_de\_imagen**:

           * Ejecute oc registry info en la terminal para obtener la URL del registro.
           * image\_repo es una combinación de URL de registro, `your_namespace`, `your_output_image_name` como se menciona en el archivo yaml buildConfig, separados por una barra diagonal. registery\_url/su\_espacio\_de\_nombres/su\_nombre\_de\_imagen\_de\_salida

         Consideremos el siguiente ejemplo:

         ```shell
         helm install synthetics-kevin newrelic/synthetics-job-manager -n synthetics --set synthetics.privateLocationKey=<PRIVATE_LOC_KEY>   --set node-api-runtime.image.repository=default-route-openshift-image-registry.apps-crc.testing/synthetics/synthetics-node-api-runtime --set node-api-runtime.appVersionOverride=custom
         ```

    8. Compruebe que el pod del administrador de trabajos de Sintéticos esté en funcionamiento:

       ```shell
       oc get pods -n your-namespace
       ```
  </Collapser>
</CollapserGroup>

## Detener o eliminar el administrador de trabajos de Sintético [#stop]

En un entorno de sistema contenedor Docker o Podman, emplee el procedimiento `stop` respectivo para detener el administrador de trabajos Sintéticos. En un entorno de sistema de orquestación de contenedores Kubernetes , emplee el procedimiento Kubernetes `delete` para detener la ejecución del administrador de trabajos sintéticos.

<CollapserGroup>
  <Collapser
    id="docker-stop"
    title={<><img src="/images/synthetic_logo_docker.webp" title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }} />Procedimiento de detención de docker</>
    }
  >
    Puede [detener un contenedor Docker](https://docs.docker.com/engine/reference/commandline/stop/) por el nombre del contenedor o por el ID del contenedor.

    * Detención del nombre del contenedor para Linux, macOS y Windows:

      ```shell
      docker stop YOUR_CONTAINER_NAME
      docker rm YOUR_CONTAINER_NAME
      ```

    * Detención de ID de contenedor para Linux/macOS:

      En los ejemplos, el contenedor se detiene y se retira. Para detener únicamente el contenedor, omita `docker rm $CONTAINER_ID`.

      ```shell
      CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME)
      docker stop $CONTAINER_ID
      docker rm $CONTAINER_ID
      ```

    * Detención de ID de contenedor para Windows:

      En los ejemplos, el contenedor se detiene y se retira. Para detener únicamente el contenedor, omita `docker rm $CONTAINER_ID`.

      ```shell
      FOR /F "tokens=*" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID)
      docker stop %CONTAINER_ID%
      docker rm %CONTAINER_ID%
      ```
  </Collapser>

  <Collapser
    id="podman-stop"
    title={<><img src="/images/synthetic_logo_podman.webp" title="Docker icon" alt="Podman icon" style={{ height: '35px', width: '40px' }} /></>
    }
  >
    Puede [detener un contenedor Podman](https://docs.podman.io/en/stable/markdown/podman-stop.1.html) por el nombre del contenedor o por el ID del contenedor.

    * Nombre del contenedor stop para Linux:

    ```
    podman stop YOUR_CONTAINER_NAME
    podman rm YOUR_CONTAINER_NAME
    ```

    * Detención del ID del contenedor para Linux:

    En los ejemplos, el contenedor se detiene y se retira. Para detener únicamente el contenedor, omita `podman rm $CONTAINER_ID`.

    ```
    CONTAINER_ID=$(podman ps -aqf name=YOUR_CONTAINER_NAME)
    podman stop $CONTAINER_ID
    podman rm $CONTAINER_ID
    ```
  </Collapser>

  <Collapser
    id="kubernetes-delete"
    title={<><img src="/images/synthetic_logo_k8logo.webp" title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ height: '35px', width: '40px' }} />Procedimiento de eliminación de Kubernetes</>
    }
  >
    1. Obtenga el `JOB_MANAGER_POD_INSTALLATION_NAME` del pod del administrador de trabajos de Sintético que desea eliminar:

       ```shell
       helm list -n YOUR_NAMESPACE
       ```

    2. Eliminar el minion pod:

       ```shell
       helm uninstall -n YOUR_NAMESPACE JOB_MANAGER_POD_INSTALLATION_NAME
       ```

    3. Elimina el namespace configurado para el administrador de trabajos de Sintético en tu clúster de Kubernetes:

       ```shell
       kubectl delete namespace YOUR_NAMESPACE
       ```
  </Collapser>

  <Collapser id="openshift-delete" title="Procedimiento de eliminación de OpenShift">
    ```shell
    helm uninstall release_name -n your_namespace
    ```
  </Collapser>
</CollapserGroup>

## Sandboxing y dependencia [#sandboxing-and-deps]

El sandboxing y la dependencia son aplicables al gestor de trabajos Sintéticos en un entorno de sistema contenedor Docker o Podman.

<CollapserGroup>
  <Collapser
    id="docker-dependencies"
    title={<><img src="/images/synthetic_logo_docker.webp" title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }} />Dependencia de Docker</>
    }
  >
    El administrador de trabajos de Sintético se ejecuta en docker y puede aprovechar docker como tecnología de espacio aislado. Esto garantiza un aislamiento completo de la ejecución del monitor, lo que mejora la seguridad, la confiabilidad y la repetibilidad. Cada vez que se ejecuta un monitor browser o script, el administrador de trabajos de Sintético crea un nuevo contenedor docker para ejecutarlo utilizando el tiempo de ejecución correspondiente.

    El contenedor del administrador de trabajos Sintético debe configurarse para comunicarse con el motor docker a fin de generar contenedores de tiempo de ejecución adicionales. Luego, cada contenedor generado se dedica a ejecutar una verificación asociada con el [monitor Sintético](/docs/synthetics/new-relic-synthetics/using-monitors/add-edit-monitors) que se ejecuta en la ubicación privada a la que está asociado el contenedor del administrador de trabajos Sintético.

    Existe una dependencia crucial en el lanzamiento. Para habilitar el espacio aislado, asegúrese de que:

    * Su socket UNIX docker grabable está montado en [la variable de entorno](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration/#environment-variables) `/var/run/docker.sock` o `DOCKER_HOST`. Para obtener más información, consulte [Opción de socket Daemon](https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-socket-option) de Docker.

      <Callout variant="caution">
        El recuento de núcleos en el host determina cuántos contenedores de tiempo de ejecución puede ejecutar el administrador de trabajos Sintético simultáneamente en el host. Dado que los requisitos de memoria se ajustan al recuento esperado del contenedor de tiempo de ejecución, recomendamos <DNT>**not running multiple synthetics job managers on the same host**</DNT> para evitar la contención de recursos.
      </Callout>

      Para obtener información adicional sobre el sandboxing y la ejecución como usuario raíz o no root, consulte [Seguridad, sandboxing y ejecución como no root](#run-non-root).
  </Collapser>
</CollapserGroup>

<CollapserGroup>
  <Collapser
    id="podman-dependencies"
    title={<><img src="/images/synthetic_logo_podman.webp" title="Podman icon" alt="Podman icon" style={{ height: '35px', width: '40px' }} /></>
    }
  >
    El administrador de trabajos Sintéticos se ejecuta en Podman y puede aprovechar Podman como una tecnología de sandbox. Esto garantiza un aislamiento completo de la ejecución del monitor, lo que mejora la seguridad, la confiabilidad y la repetibilidad. Cada vez que se ejecuta un monitor browser o script, el administrador de trabajos de Sintéticos crea un nuevo contenedor Podman para ejecutarlo empleando el entorno de ejecución correspondiente.

    El administrador de trabajos Sintéticos contenedor debe configurar para comunicar con el motor Podman a fin de generar tiempo de ejecución adicional contenedor. Luego, cada contenedor generado se dedica a ejecutar una verificación asociada con el [monitor Sintético](/docs/synthetics/new-relic-synthetics/using-monitors/add-edit-monitors) que se ejecuta en la ubicación privada con la que está asociado el contenedor del administrador de trabajos Sintéticos.

    Existe una dependencia crucial en el lanzamiento. Para habilitar el sandboxing, cerciorar de tener:

    1. Instaló Podman [5.0.0-ce](https://github.com/containers/podman/releases/tag/v5.0.0) o superior.

    2. Habilitada la ejecución sin raíz:

       * Configure Podman para ejecutar contenedor sin requerir privilegios de root.
         ```
         mkdir -p ~/.config/containers
         touch ~/.config/containers/containers.conf
         vi ~/.config/containers/containers.conf
         ```
       * Edite el archivo `containers.conf` para configurar Podman para que use `crun` y `systemd`:
         ```
         [engine]
         runtime = "crun"
         cgroup_manager = "systemd"
         ```

    3. Se habilitaron los cgroups v2 (solo RHEL):
       * Edite GRUB para habilitar cgroups v2, esto garantiza la compatibilidad con los tiempos de ejecución de contenedor modernos en RHEL.
         ```
         sudo sed -i 's/GRUB_CMDLINE_LINUX="/&systemd.unified_cgroup_hierarchy=1 /' /etc/default/grub
         sudo grub2-mkconfig -o /boot/grub2/grub.cfg
         sudo reboot
         ```

    4. Se habilitó la delegación en todo el sistema para permitir la delegación `cgroups` para los servicios de Podman.
       ```
       sudo mkdir -p /etc/systemd/system/user@.service.d/
       echo -e "[Service]\nDelegate=yes" | sudo tee /etc/systemd/system/user@.service.d/delegate.conf > /dev/null
       ```

    5. Configurar el servicio de nivel de usuario `systemd` :

       * Crear directorios para los servicios de nivel de usuario `systemd` .
         ```
         mkdir -p ~/.config/systemd/user/podman.service.d
         ```
       * Agregue la configuración de delegado al servicio de nivel de usuario `systemd` .
         ```
         echo -e "[Service]\nDelegate=yes" > ~/.config/systemd/user/podman.service.d/override.conf
         ```

    6. Habilitado e iniciado el socket Podman.
       ```
       systemctl --user enable podman.socket
       systemctl --user start podman.socket
       systemctl --user status podman.socket
       ```

    7. Creó y configuró el servicio API de Podman:

       * Crea un servicio API de Podman y configura Podman para proporcionar acceso a la API HTTP.
         ```
         mkdir -p ~/.config/systemd/user
         touch ~/.config/systemd/user/podman-api.service
         vi ~/.config/systemd/user/podman-api.service
         ```
       * Define el servicio para exponer la API de Podman en el puerto 8000.
         ```
         [Unit]
         Description=Podman API Service
         After=default.target

         [Service]
         Type=simple
         ExecStart=/usr/bin/podman system service -t 0 tcp:0.0.0.0:8000
         Restart=on-failure

         [Install]
         WantedBy=default.target
         ```

    8. Habilitado e iniciado el servicio API de Podman.
       ```
       systemctl --user daemon-reload
       systemctl --user enable podman-api.service
       systemctl --user start podman-api.service
       systemctl --user status podman-api.service
       ```

    <Callout variant="caution">
      El recuento de núcleos en el host determina cuántos contenedores de tiempo de ejecución puede ejecutar el administrador de trabajos Sintético simultáneamente en el host. Dado que los requisitos de memoria se ajustan al recuento esperado del contenedor de tiempo de ejecución, recomendamos <DNT>**not running multiple synthetics job managers on the same host**</DNT> para evitar la contención de recursos.
    </Callout>
  </Collapser>
</CollapserGroup>

## Seguridad, espacio aislado y ejecución como no root [#security]

De forma predeterminada, el software que se ejecuta dentro de un administrador de trabajos de Sintético se ejecuta con `root` privilegios de usuario. Esto es adecuado para la mayoría de los escenarios, ya que la ejecución está protegida.

Para ejecutar el administrador de trabajos de Sintético como usuario no root, se requieren pasos adicionales:

<CollapserGroup>
  <Collapser
    id="run-non-root"
    title={<><img src="/images/synthetic_logo_docker.webp" title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }} />Ejecutar como usuario no root para Docker</>
    }
  >
    Para obtener más información, consulte la documentación oficial de Docker sobre [seguridad](https://docs.docker.com/engine/security/security/) y [perfiles de seguridad de AppArmor](https://docs.docker.com/engine/security/apparmor/).

    Si su entorno requiere que ejecute el administrador de trabajos de Sintético como usuario no root, siga este procedimiento. En el siguiente ejemplo, el usuario no root es `my_user`.

    1. Asegúrese de que `my_user` pueda utilizar el motor Docker en el host:

       Verifique que `my_user` [pertenezca al grupo de sistemas `"docker"` ](https://docs.docker.com/engine/install/linux-postinstall/). Aún se necesita acceso raíz con alcance a `docker.sock` para crear redes puente.

       O

       Habilite la [opción de socket TCP de Docker](https://docs.docker.com/engine/reference/commandline/dockerd/#examples) y pase la [variable de entorno](#environemnt-variables) `DOCKER_HOST` al administrador de trabajos de Sintético.

    2. Verifique que `my_user` tenga permisos de lectura/escritura en todos los directorios y volúmenes pasados al administrador de trabajos de Sintético. Para establecer estos permisos, utilice el comando `chmod` .

    3. Obtenga el `uid` de `my_user` para usarlo en el comando de ejecución: `id -u my_user`.

       Una vez que se cumplan estas condiciones, utilice la opción `"-u <uid>:<gid>"` al iniciar el administrador de trabajos de Sintético:

       ```shell
       docker run ... -u 1002 ...
       ```

       O

       ```shell
       docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ...
       ```
  </Collapser>
</CollapserGroup>

## Comprenda sus entornos Docker, Podman, Kubernetes u OpenShift [#understand]

A continuación se muestra información adicional sobre cómo mantener y comprender el entorno de contenedor del administrador de trabajos. Vea información de licencia, comprenda la configuración de red del administrador de trabajos y consulte el repositorio de imágenes docker .

<CollapserGroup>
  <Collapser id="help" title="Mantener el administrador de trabajos.">
    Utilice estas opciones según corresponda:

    * Para realizar un seguimiento de los logs Docker o Podman y verificar el estado de sus monitores, consulte [Mantenimiento y monitoreo del administrador de trabajos sintéticos](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-maintenance-monitoring).

    * Para un administrador de trabajos sintéticos en el entorno del sistema de orquestación de contenedores **OpenShift** y **Kubernetes** , se pueden usar los siguientes comandos Helm `show` para ver `chart.yaml` y `values.yaml`, respectivamente:

      ```shell
      helm show chart YOUR_REPO_NAME/synthetics-job-manager
      ```

      ```shell
      helm show values YOUR_REPO_NAME/synthetics-job-manager
      ```
  </Collapser>

  <Collapser id="license" title="Mostrar información de licencia">
    Parte de nuestro software de código abierto aparece bajo varias licencias de software y, en ese caso, hemos enumerado la licencia que hemos elegido utilizar. La información de nuestra licencia también está disponible en la [documentación de nuestras licencias](/docs/licenses/new-relic-products/new-relic-synthetics/new-relic-synthetics-licenses).
  </Collapser>

  <Collapser id="network" title="Configuración de la red">
    Tanto para docker como para Kubernetes, el administrador de trabajos de Sintético y su contenedor de tiempo de ejecución heredarán la configuración de red del host. Para ver un ejemplo de esto en un entorno de sistema de contenedor docker , consulte el [sitiodocker ](https://docs.docker.com/config/containers/container-networking/).

    Se crea una red puente para la comunicación entre el administrador de trabajos de Sintético y el contenedor de tiempo de ejecución. Esto significa que las opciones de comando de red como `--network` y `--dns` que se pasan al contenedor del administrador de trabajos de Sintético en el momento del lanzamiento (como a través de comandos de ejecución docker en un entorno de sistema de contenedor docker ) no son heredadas ni utilizadas por los contenedores de tiempo de ejecución.

    Cuando se crean estas redes, se extraen del grupo de direcciones IP predeterminado configurado para daemon. Para ver un ejemplo de esto en un entorno de sistema de contenedor Docker, consulte el [sitio Docker ](https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file).

    En el caso de Podman, no empleamos una red de puente para la comunicación entre el administrador de trabajos Sintéticos y el contenedor en tiempo de ejecución, en su lugar usamos un pod Podman. Todos los contenedores en un pod Podman comparten el mismo namespace de red. Esto significa que comparten la misma dirección IP dentro de ese pod. En este caso aunque los contenedores comparten la misma IP, sus servicios están expuestos en puertos diferentes.
  </Collapser>

  <Collapser id="image" title="Repositorio de imágenes Docker">
    Una única imagen Docker del administrador de trabajos Sintéticos sirve al entorno del sistema de orquestación de contenedores **Docker**, **Podman**, **OpenShift** y **Kubernetes** . La imagen de Docker está alojada en Docker Hub. Para cerciorar de que su imagen Docker esté actualizada, consulte el [repositorio newrelic/synthetics-job-managerDocker Hub](https://hub.docker.com/r/newrelic/synthetics-job-manager/tags).
  </Collapser>
</CollapserGroup>

## Consideraciones adicionales para la conexión del administrador de trabajos de Sintético [#FAQ]

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Conexión
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Gestores de empleo Sintético sin acceso a Internet
      </td>

      <td>
        Un gestor de trabajos de Sintético puede operar sin acceso a Internet, pero con algunas excepciones. El gestor de trabajos de Sintético debe poder contactar con el dominio `"synthetics-horde.nr-data.net"` . Esto es necesario para que informe datos a New Relic y reciba un monitor para ejecutar. Pregunte a su administrador de red si esto representa un problema y cómo configurar excepciones.
      </td>
    </tr>

    <tr>
      <td>
        Comunicarse con Sintético a través de un proxy
      </td>

      <td>
        Para configurar la comunicación con New Relic mediante proxy, utilice las [variables de entorno](/docs/synthetics/synthetic-monitoring/private-locations/job-manager-configuration#environment-variables) denominadas `HORDE_API_PROXY*.`
      </td>
    </tr>

    <tr>
      <td>
        Argumentos aprobados en el lanzamiento
      </td>

      <td>
        Esto se aplica únicamente al entorno contenedor Docker y Podman. Los argumentos que se pasan al administrador de trabajos Sintéticos contenedor en el lanzamiento no se pasan al contenedor en tiempo de ejecución generado por el administrador de trabajos Sintéticos. Docker y Podman no tienen el concepto de &quot;herencia&quot; o &quot;jerarquía&quot; de contenedor, y no copiamos la configuración que se pasa del administrador de trabajos sintéticos al contenedor en tiempo de ejecución. Sin embargo, en el caso de Podman, los argumentos que se pasan a nivel pod se comparten entre el administrador de trabajos de Sintéticos y el contenedor en tiempo de ejecución dentro del pod. La única configuración compartida entre ellos es la establecido en el nivel [del demonio Docker](https://docs.docker.com/config/daemon/) .
      </td>
    </tr>
  </tbody>
</table>