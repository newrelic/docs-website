---
title: Integración con Confluent cloud
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

New Relic ofrece una integración para recopilar sus datos [de transmisión gestionados por Confluent Cloud para Apache Kafka](https://www.confluent.io/confluent-cloud/) . Este documento explica cómo activar esta integración y describe los datos que se pueden informar.

## Requisitos previos

* Una cuenta de New Relic
* Una cuenta activa de Confluent Cloud
* Una clave de API y un secreto de Confluent Cloud
* `MetricsViewer` acceso a la cuenta de Confluent Cloud

## Activar la integración [#activate]

Para habilitar esta integración, vaya a <DNT>**Integrations &amp; Agents**</DNT>, seleccione <DNT>**Confluent Cloud -&gt; API Polling**</DNT> y siga las instrucciones.

<Callout variant="important">
  Si tiene configurado el filtrado de IP, agregue las siguientes direcciones IP a su filtro.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  Para obtener más información sobre los rangos de IP de New Relic para la integración en la nube, consulte [este documento](/docs/new-relic-solutions/get-started/networks/#webhooks). Para obtener instrucciones sobre cómo realizar esta tarea, consulte [este documento](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html).
</Callout>

## Configuración y sondeo [#polling]

Información de sondeo predeterminada para la integración de Confluent Cloud Kafka:

* New Relic intervalo de sondeo: 5 minutos
* Intervalo de datos de Confluent Cloud: 1 minuto

Puede cambiar la frecuencia de sondeo solo durante la configuración inicial.

## Ver y usar datos [#find-data]

Puede [consultar y explorar sus datos](/docs/using-new-relic/data/understand-data/query-new-relic-data) empleando el siguiente [tipo de evento](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels):

<table>
  <thead>
    <tr>
      <th>
        Entidad
      </th>

      <th>
        Tipo de datos
      </th>

      <th>
        Proveedor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Grupo
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        Conector
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>

    <tr>
      <td>
        ksql
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

Para obtener más información sobre cómo utilizar sus datos, consulte [Comprender y utilizar los datos de integración](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Datos métricos [#metrics]

Esta integración registra datos de Kafka cloud de Confluent para clúster, conector y ksql.

### Datos del clúster

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Una medida de la utilización del clúster. El valor está entre 0,0 y 1,0. Sólo el nivel clúster dedicado tiene estos datos métricos.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Un indicador de la presencia de una partición caliente causada por el rendimiento de entrada. El valor es 1.0 cuando se detecta una partición activa y está vacío cuando no se detecta ninguna partición activa.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Un indicador de la presencia de una partición caliente causada por el rendimiento de salida. El valor es 1.0 cuando se detecta una partición activa y está vacío cuando no se detecta ninguna partición activa.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta del total de bytes de solicitud de los tipos de solicitud especificados enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta del total de bytes de respuesta de los tipos de respuesta especificados enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta de bytes de los datos de los clientes recibidos de la red. Cada muestra es el número de bytes recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta de bytes de los datos de los clientes enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de registros recibidos. Cada muestra es el número de registros recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de registros enviados. Cada muestra es el número de registros enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El número de particiones.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        El retraso entre el desplazamiento comprometido de un miembro del grupo y la marca de límite superior de la partición.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de autenticaciones exitosas. Cada muestra es el número de autenticaciones exitosas desde el punto de datos anterior. El recuento se realizó cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento de conexiones autenticadas activas.
      </td>
    </tr>
  </tbody>
</table>

### Datos del conector

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta del número total de registros enviados desde las transformaciones y escritos en Kafka para el conector de origen. Cada muestra es el número de registros enviados desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `connector_status`
      </td>

      <td>
        Bit
      </td>

      <td>
        El estado de un conector dentro del sistema. Su valor siempre se establece en 1, lo que significa la presencia del conector. El estado operativo actual del conector se identifica a través de la etiqueta métrica.status.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_status`
      </td>

      <td>
        Bit
      </td>

      <td>
        El estado de la tarea de un conector dentro del sistema. Su valor siempre se establece en 1, lo que significa la presencia de la tarea del conector. El estado operativo actual del conector se identifica a través de la etiqueta métrica.status.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_avg`
      </td>

      <td>
        Contar
      </td>

      <td>
        El tamaño promedio de lote (medido por el recuento de registros) por minuto. Para un conector de origen, indica el tamaño de lote promedio enviado a Kafka. Para un conector de sumidero, indica el tamaño de lote promedio leído por la tarea de sumidero.
      </td>
    </tr>

    <tr>
      <td>
        `connector_task_batch_size_max`
      </td>

      <td>
        Contar
      </td>

      <td>
        El tamaño máximo de lote (medido por el recuento de registros) por minuto. Para un conector de origen, indica el tamaño máximo de lote enviado a Kafka. Para un conector de sumidero, indica el tamaño máximo de lote leído por la tarea de sumidero.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta del número total de registros recibidos por el conector del receptor. Cada muestra es el número de registros recibidos desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta del número total de registros recibidos por el conector del receptor. Cada muestra es el número de registros recibidos desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta del total de bytes recibidos por el conector del receptor. Cada muestra es el número de bytes recibidos desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `dead_letter_queue_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de registros de la cola de mensajes inactivos escritos en Kafka para el conector del receptor. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>
  </tbody>
</table>

### datos ksql

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `streaming_unit_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento de unidades de transmisión confluente (CSU) para esta instancia de KSQL. El recuento se muestrea cada 60 segundos. La agregación de tiempo implícita para esta métrica es MAX.
      </td>
    </tr>

    <tr>
      <td>
        `query_saturation`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        La saturación máxima para una consulta ksqlDB determinada en todos los nodos. Devuelve un valor entre 0 y 1, un valor cercano a 1 indica que el procesamiento de ksqlDB consulta está basado en los recursos disponibles.
      </td>
    </tr>

    <tr>
      <td>
        `task_stored_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El tamaño del estado de una tarea determinada se almacena en bytes.
      </td>
    </tr>

    <tr>
      <td>
        `storage_utilization`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        La utilización total de almacenamiento para una aplicación ksqlDB determinada.
      </td>
    </tr>

    <tr>
      <td>
        `consumed_total_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta de bytes consumidos de Kafka por consulta continua durante el periodo aplicar.
      </td>
    </tr>

    <tr>
      <td>
        `produced_total_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta de bytes producidos en Kafka por consulta continua durante el periodo aplicar.
      </td>
    </tr>

    <tr>
      <td>
        `offsets_processed_total`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de compensaciones procesadas por una consulta, tarea, tema o compensación determinada.
      </td>
    </tr>

    <tr>
      <td>
        `committed_offset_lag`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        El retraso actual entre el desplazamiento confirmado y el desplazamiento final para una consulta, tarea o tema determinado, o desplazamiento.
      </td>
    </tr>

    <tr>
      <td>
        `processing_errors_total`
      </td>

      <td>
        Contar
      </td>

      <td>
        Recuento delta del número de errores de procesamiento de registros de una consulta durante el periodo aplicar.
      </td>
    </tr>

    <tr>
      <td>
        `query_restarts`
      </td>

      <td>
        Contar
      </td>

      <td>
        Recuento delta de la cantidad de fallas que hacen que una consulta se resetear durante el periodo aplicar.
      </td>
    </tr>
  </tbody>
</table>

## Que sigue

<DocTiles>
  <DocTile title="Datos e UI" path="/docs/message-queues-streaming/ui-data/understand-ui">
    Aprenda a usar New Relic para monitorear su clúster de Kafka
  </DocTile>
</DocTiles>