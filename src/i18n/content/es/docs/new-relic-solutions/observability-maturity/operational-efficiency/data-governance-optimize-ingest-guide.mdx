---
title: Optimice su ingesta de datos
tags:
  - Observability maturity
  - Operational efficiency
  - Data ingest cost
  - Sampling rate
  - Drop rules
  - Observability as code
  - Value drivers
  - Bill and Usage Data
  - Data ingest cost
metaDescription: 'The third part of New Relic''s data ingest governance series on optimizing how you ingest and use your telemetry data: this focuses on optimizing data ingest.'
freshnessValidatedDate: never
translationType: machine
---

<img src="/images/oma-oe-dg_icon_optimizing.webp" alt="Optimize" style={{ height: '96px', width: '120px', verticalAlign: 'middle', horizontalAlign: 'right'}} />

**La gobernanza de la ingesta de datos** es una práctica para obtener un valor óptimo de los telemetry data recopilados por una organización. Esto es especialmente importante para una organización compleja que tiene numerosas unidades de negocio y grupos de trabajo. Esta es la tercera parte de una guía de cuatro partes para optimizar la ingesta de datos de New Relic y es parte de [nuestro serial sobre madurez de observabilidad](/docs/new-relic-solutions/observability-maturity/introduction).

## Antes de que empieces [#before-start]

Esta guía contiene recomendaciones detalladas para optimizar la ingesta de datos. Antes de utilizar esta guía, le recomendamos revisar [nuestros documentos generales de gestión de datos](/docs/data-apis/manage-data/manage-your-data).

## Resultado deseado [#desired-outcome]

Maximice el valor de observabilidad de sus datos optimizando la ingesta de datos. Reduzca los datos de ingesta no esenciales para que pueda mantenerse dentro de su presupuesto.

## Proceso [#process]

El proceso incluirá estos pasos:

* [Priorice sus objetivos de observabilidad](#prioritize-objectives)
* [Desarrollar un plan de optimización.](#develop-plan)
* [Utilice técnicas de reducción de datos para ejecutar su plan](#use-reduction-techniques)

Explicaremos estos pasos con más detalle.

## Priorice sus objetivos de observabilidad [#prioritize-objectives]

Una de las partes más importantes del framework de gobernanza de la ingesta de datos es alinear la telemetría recopilada con **los impulsores de valor de la observabilidad**. Debe cerciorar de comprender que el objetivo principal de observabilidad es cuando configura la nueva telemetría.

Cuando introduce una nueva telemetría, desea comprender qué aporta a su solución de observabilidad general. Es posible que sus nuevos datos se superpongan con otros datos. Si considera introducir telemetría que no puede alinear con ninguno de los objetivos clave, puede reconsiderar la introducción de esos datos.

Los objetivos incluyen:

* Cumplir con un SLA interno
* Cumplir con un SLA externo
* Apoyar la innovación característica (pruebas de adopción y rendimiento A/B)
* Monitor la experiencia de los clientes
* Mantener a los proveedores y proveedores de servicios internos cumpliendo su SLA
* Proceso empresarial monitoreo de salud
* Otros requisitos de cumplimiento

La alineación con estos objetivos es lo que le permite tomar decisiones flexibles e intuitivas sobre cómo priorizar un conjunto de datos sobre otro y ayudar a guiar a los equipos a saber por dónde empezar cuando instrumentan una nueva plataforma y servicios.

## Desarrollar un plan de optimización. [#develop-plan]

Para esta sección, haremos dos suposiciones principales:

* Tienes las herramientas y técnicas de la [línea de base de tu sección de ingesta de datos](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining) para tener una contabilidad adecuada de dónde provienen tus datos.
* Tiene un buen conocimiento de los [factores que impulsan el valor de la madurez de la observabilidad](/docs/new-relic-solutions/observability-maturity/introduction). Esto será crucial a la hora de aplicar un valor y una prioridad a los grupos de telemetría.

Utilice los siguientes ejemplos para visualizar cómo evaluaría su propia ingesta de telemetría y tomar las decisiones, a veces difíciles, necesarias para ajustarse al presupuesto. Aunque cada uno de estos ejemplos intenta centrarse en un impulsor de valor, la mayoría de la instrumentación sirve a más de un impulsor de valor. Esta es la parte más difícil de la gestión de la ingesta de datos.

<CollapserGroup>
  <Collapser id="case-study-1" title="Ejemplo 1: centrarse en el tiempo de actividad y la confiabilidad">
    Una cuenta está ingiriendo aproximadamente un 20% más de lo que tenía presupuestado. Un gerente les pidió que encuentren alguna forma de reducir el consumo. Su factor de valor más importante es **el tiempo de actividad, el rendimiento y la confiabilidad**.

    <img src="/images/oma-oe-dg_diagram_value-driver-uptime.webp" alt="Observability value drivers with a focus on uptime and reliability" title="Observability value drivers with a focus on uptime and reliability" style={{width: "400px"}} />

    <figcaption>
      Impulsores de valor de observabilidad con un enfoque en el tiempo de actividad y la confiabilidad.
    </figcaption>

    Su patrimonio incluye:

    * <InlinePopover type="apm" />(dev, de prueba, prod)
    * rastreo distribuido
    * Browser
    * Monitoreo de infraestructura de 100 hosts
    * Monitoreo K8s (dev, de prueba, prod)
    * Log (dev, de prueba, prod - incluyendo depuración)

    <Callout variant="IMPORTANT" title="Plan de optimización">
      * Omitir el log de depuración (sabiendo que se pueden activar si hay un problema) (ahorra un 5%)
      * Omitir varios K8 de estado métrico que no son necesarios para mostrar el explorador del clúster de Kubernetes (ahorra un 10%)
      * Suelte algún evento browser personalizado que estaban recopilando cuando hacían muchas pruebas A/B de una nueva característica (ahorra 10%)
    </Callout>

    Después de ejecutar esos cambios, el equipo está un 5 % por debajo de su presupuesto y ha liberado algo de espacio para realizar un piloto de NPM. Su gerente está satisfecho de que no están perdiendo ningún tiempo de actividad significativo ni observabilidad de confiabilidad.

    <Callout variant="IMPORTANT" title="Resultado final">
      * 5% por debajo de su presupuesto original
      * Espacio libre creado para un piloto de NPM que cumple objetivos de tiempo de actividad, rendimiento y confiabilidad
      * Pérdida mínima de tiempo de actividad y observabilidad de confiabilidad
    </Callout>
  </Collapser>

  <Collapser id="case-study-2" title="Ejemplo 2: centrarse en la experiencia del cliente">
    Un equipo responsable de una nueva plataforma orientada al usuario con énfasis en monitoreo de celulares y monitoreo de browser está funcionando con un 50% por encima de la cotización. Tendrán que ajustar el tamaño de su ingesta, pero están decididos a no sacrificar la observabilidad **de la experiencia del cliente** .

    <img src="/images/oma-oe-dg_diagram_value-driver-customer.webp" alt="Observability value drivers with a focus on customer experience" title="Observability value drivers with a focus on customer experience" style={{width: "400px"}} />

    <figcaption>
      Observabilidad: impulsores de valor con foco en **la experiencia del cliente**
    </figcaption>

    Su patrimonio incluye:

    * Móvil
    * Browser
    * APM
    * rastreo distribuido
    * Infraestructura en 30 hosts, incluyendo muestras de procesos
    * Monitoreo sin servidor para algunos procesos asincrónicos backend
    * Logs desde su función serverless
    * Varias integraciones en la nube.

    <Callout variant="IMPORTANT" title="Plan de optimización">
      * Omita el log sin servidor (básicamente son redundantes con respecto a lo que obtienen de su integración Lambda)
      * Reducir la frecuencia de muestreo del proceso en sus hosts a cada minuto.
      * Eliminar datos de muestra de procesos en entornos DEV
      * Desactive la integración de EC2, que es altamente redundante con otros monitoreos de infraestructura proporcionados por el agente de infraestructura New Relic.
    </Callout>

    <Callout variant="IMPORTANT" title="Resultado final">
      * 5% sobre su presupuesto original
      * Suficiente para pasar la temporada alta.
      * Observabilidad de la experiencia sin pérdida de clientes
    </Callout>

    Después de ejecutar los cambios, ahora están solo un 5% por encima de su presupuesto original, pero concluyen que esto será suficiente para aguantar la temporada alta.
  </Collapser>

  <Collapser id="case-study-3" title="Ejemplo 3: centrarse en la innovación">
    Un equipo está en el proceso de refactorizar un gran monolito de Python en cuatro microservicios. El monolito comparte gran parte de la infraestructura con la nueva arquitectura, incluida una base de datos de clientes y una capa de caché. Están un 70% por encima del presupuesto y les quedan dos meses antes de poder desmantelar oficialmente el monolito.

    <img src="/images/oma-oe-dg_diagram_value-driver-innovation.webp" alt="Observability value drivers with a focus on Innovation and Growth" title="Observability value drivers with a focus on Innovation and Growth" style={{width: "400px"}} />

    <figcaption>
      Impulsores de valor de observabilidad con foco en **innovación y crecimiento**.
    </figcaption>

    Su patrimonio incluye:

    * Monitoreo K8s (microservicios)
    * Monitoreo del host New Relic (monolito)
    * APM (microservicios y monitoreo de host)
    * Rastreo distribuido (microservicios y monitorización de host)
    * Postgresql (compartido)
    * Redis (compartido)
    * MSSQL (futura base de datos para la arquitectura de microservicios)
    * Logging del balanceador de carga (microservicios y monitoreo de host)

    <Callout variant="IMPORTANT" title="Plan de optimización">
      * Configure el logging del balanceador de carga para monitor solo los códigos de respuesta 5xx (monolito)
      * Frecuencia de muestreo personalizada en `ProcessSample`, `StorageSample` y `NetworkSample` a 60 s para los hosts que ejecutan el monolito
      * Deshabilite el monitoreo de MSSQL ya que actualmente la nueva arquitectura no lo utiliza.
      * Deshabilite rastreo distribuido para el monolito ya que es mucho menos útil que para la arquitectura de microservicios.
    </Callout>

    <Callout variant="IMPORTANT" title="Resultado final">
      * 1% por debajo de su presupuesto original
      * Sin pérdida de **innovación y observabilidad del crecimiento**
    </Callout>
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  Le recomendamos realizar un seguimiento del plan en una herramienta de gestión de tareas con la que esté familiarizado. Esto ayuda a gestionar el plan de optimización y también a comprender el efecto que tiene cada tarea de optimización. Puede utilizar esta [plantilla de plan de optimización de datos](https://docs.google.com/spreadsheets/d/1CimLpALwl1Z9f41vzbNWx00bGcED9XPV3s4ROqVEnr0/copy).
</Callout>

## Utilice técnicas de reducción de datos para ejecutar su plan [#use-reduction-techniques]

En esta etapa, ha pensado en todos los tipos de telemetría en su(s) cuenta(s) y cómo se relaciona con sus impulsores de valor. Esta sección proporcionará instrucciones técnicas detalladas y ejemplos sobre cómo reducir una variedad de tipos de telemetría.

Hay dos formas principales de abordar la reducción de datos:

* A través de la configuración
* Mediante el uso de reglas de caída

### Optimización a través de la configuración. [#optimization-through-configuration]

Esta sección incluye varias formas de configurar la característica New Relic para optimizar los informes de datos y la ingesta:

<CollapserGroup>
  <Collapser id="apm-agent" title="Agente APM">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Monitorear transacciones
      * Actividad de error
      * Evento personalizado
    </Callout>

    El volumen de datos generado por el agente APM vendrá determinado por varios factores:

    * La cantidad de tráfico orgánico generado por la aplicación (por ejemplo, en igualdad de condiciones, una aplicación que se llama un millón de veces al día generará más datos que una que se llama mil veces al día)
    * Algunas de las características de los datos de la transacción subyacentes (longitud y complejidad de las URL)
    * Si la solicitud informa consulta de la base de datos
    * Si la aplicación tiene transacción con muchos (o cualquier) atributo personalizado
    * El volumen de errores de la aplicación.
    * Si el agente de aplicación está configurado para rastreo distribuido

    ### Gestionar el volumen

    Si bien puede suponer que todas las llamadas a una aplicación son necesarias para respaldar el negocio, es posible que pueda ser más ahorrativo en su arquitectura general. En un caso extremo puede tener un perfil de usuario de microservicios al que llaman cada 10 segundos sus clientes. Esto ayuda a reducir la latencia si otros clientes actualizan alguna información del usuario. Sin embargo, una palanca que tenemos es reducir la frecuencia de las llamadas a este servicio a, por ejemplo, cada minuto.

    ### Atributo personalizado

    Cualquier [atributo personalizado](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/) agregado mediante una llamada a una API de APM [`addCustomParameter`](https://developer.newrelic.com/collect-data/custom-attributes/) agregará un atributo adicional a la carga útil de la transacción. Suelen ser útiles, pero a medida que la lógica de la aplicación y las prioridades cambian, los datos pueden volverse menos valiosos o incluso obsoletos.

    El agente de Java captura el siguiente `request.headers` de forma predeterminada:

    * `request.headers.referer`
    * `request.headers.accept`
    * `request.headers.contentLength`
    * `request.headers.host`
    * `request.headers.userAgent`

    Los desarrolladores también pueden utilizar `addCustomParameter` para capturar información adicional (encabezados potencialmente más detallados).

    Para ver un ejemplo de la configuración enriquecida que está disponible en relación con APM, consulte nuestra [documentación de agente de Java.](/docs/apm/agents/java-agent/attributes/java-agent-attributes/#requestparams)

    ### Evento de error

    Es posible determinar cómo APM manejará los errores. Esto puede reducir el volumen de datos en algunos casos. Por ejemplo, puede haber un error de gran volumen pero inofensivo que no se puede eliminar en este momento.

    Tenemos la capacidad de `collect`, `ignore` o `mark as expected`. Para obtener más información, consulte [Administrar errores de APM](/docs/apm/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected).

    ### Consulta de la base de datos

    Un aspecto muy variable de la instancia de APM es la cantidad de llamadas a la base de datos y la configuración que hemos establecido. Tenemos bastante control sobre cuán detallada es la monitorización de la consulta de la base de datos. Estas consultas aparecerán en la página de traza de la transacción.

    Los cambios comunes en la configuración de la consulta de la base de datos incluyen:

    * [Recopilar datos de consultas sin procesar en lugar de ofuscarlos o desactivar la recopilación de consultas](/docs/apm/transactions/transaction-traces/configure-transaction-traces#record-sql)
    * Cambiando el umbral del rastreo del stack
    * Activar consulta para explicar la recopilación del plan

    Para obtener más detalles, consulte [la página de traza de la transacción consulta de la base de datos](/docs/apm/transactions/transaction-traces/transaction-traces-database-queries-page/#settings).

    ### Establecer límites de eventos

    Nuestro APM y nuestro agente móvil tienen límites sobre cuántos eventos se pueden informar por ciclo de recolección. Si no hubiera límite, una gran cantidad de eventos enviados podrían afectar el rendimiento de su aplicación o de New Relic. Cuando se alcanza el límite, el agente comienza a muestrear el evento para dar una muestra representativa de evento a lo largo del ciclo de recolección. Diferentes agentes tienen diferentes límites.

    Los eventos que están limitados y sujetos a muestreo incluyen:

    * Evento personalizado reportado a través de la API del agente (por ejemplo, el `RecordCustomEvent` del agente .NET)
    * `Mobile`
    * `MobileCrash`
    * `MobileHandledException`
    * `MobileRequest`
    * `Span` (ver muestreo rastreo distribuido)
    * `Transaction`
    * `TransactionError`

    La mayoría de los agentes tienen opciones de configuración para cambiar el límite de eventos en la transacción muestreada. Por ejemplo, el agente de Java usa [`max_samples_stored`](/docs/apm/agents/java-agent/configuration/java-agent-configuration-config-file/#ae-max_samples_stored). El valor predeterminado para `max_samples_stored` es `2000` y el máximo es `10000`. Este valor rige cuántos eventos muestreados se pueden informar cada 60 segundos desde una instancia de agente.

    Para obtener una explicación completa de los límites de muestreo de eventos, consulte [límites de eventos](/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling).

    Puede compensar el evento muestreado mediante el [operador NRQL`EXTRAPOLATE` ](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#extrapolate).

    Antes de intentar cambiar la forma en que se realiza el muestreo, lea estas advertencias y recomendaciones:

    * Cuanto más eventos reportes, más memoria utilizará tu agente.
    * Por lo general, puede obtener los datos que necesita sin aumentar el límite de informes de eventos de un agente.
    * El límite de tamaño de carga útil es 1 MB (10^6 bytes) (comprimido), por lo que el número de eventos aún puede verse afectado por ese límite. Para determinar si el evento se está eliminando, consulte el log del agente para ver un mensaje de estado `413 HTTP`.

    ### Tasa de muestreo log

    Las versiones más recientes del agente de lenguaje New Relic APM pueden reenviar el log directamente a New Relic. En algunos casos, es posible que desee controlar algunos límites de cuán grandes pueden ser los picos de logging de cada instancia del agente APM.

    Para obtener detalles sobre el muestreo de logs del agente APM, consulte [reenviador de logs](#log-forwarders).

    ### Traza de la transaccion

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de servicios conectados
      * Número de llamadas al método de monitoreo por servicios conectados
    </Callout>

    En APM, [la traza de la transacción](/docs/apm/transactions/transaction-traces/transaction-traces) registra detalles detallados sobre la transacción de su aplicación y las llamadas a la base de datos. Puede editar la configuración predeterminada para la traza de la transacción.

    Esto también es altamente configurable a través de [transacción trade configuración](/docs/apm/transactions/transaction-traces/configure-transaction-traces). El nivel y el modo de configurabilidad serán específicos del idioma en muchos casos.

    Las configuraciones de traza de la transacción disponibles usando la configuración del lado del servidor diferirán según el agente de New Relic que utilice. La UI incluye descripciones de cada uno. Las configuraciones en la UI pueden incluir:

    * Seguimiento y umbral de transacciones.
    * Grabar SQL, incluido el nivel de grabación y los campos de entrada
    * Log SQL y rastreo del umbral de pila
    * Planes de consulta SQL y umbral
    * Colección de errores, incluido el código HTTP y la clase de error
    * Consulta lenta rastreo
    * Hilo generador de perfiles

    ### rastreo distribuido

    La configuración de rastreo distribuido tiene algunas diferencias específicas del idioma.

    Rastreo distribuido se puede desactivar según sea necesario. Este es un ejemplo para el agente de Java `newrelic.yml`:

    ```yml
    distributed_tracing:
        enabled: false
    ```

    Este es un ejemplo de node.js para `newrelic.js`

    ```js
    distributed_tracing: {
      enabled: false
    }
    ```

    El volumen de datos también variará según si está utilizando [Infinite Tracing](/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing).

    El rastreo distribuido estándar para el agente APM (arriba) captura hasta el 10% de su traza, pero si desea que analicemos todos sus datos y encontremos la traza más relevante, puede configurar Infinite Tracing. Esta alternativa al rastreo distribuido estándar está disponible para todos los agentes de lenguaje APM.

    Los principales parámetros que podrían impulsar un pequeño aumento en la ingesta mensual son:

    * Configurar monitoreo de observador de trazas
    * Configurar filtro de traza de atributo span
    * Configurar filtro de traza aleatorio
  </Collapser>

  <Collapser id="browser-agent" title="Agente del navegador">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Cargas de página
      * Llamadas Ajax
      * Actividad de error
    </Callout>

    Para [la versión 1211 o superior del agente del navegador](/docs/release-notes/new-relic-browser-release-notes/browser-agent-release-notes) , todas las solicitudes de red realizadas por una página se registran como `AjaxRequest` evento. Puede utilizar las opciones de configuración de la lista de denegación en la página de configuración UI de la aplicación para filtrar qué eventos de registro de solicitudes. Independientemente de este filtro, todas las solicitudes de red se capturan como métricas y están disponibles en la página AJAX.

    ### Usando la lista de denegación

    Las solicitudes se pueden bloquear de tres formas:

    * Para bloquear la grabación de todos los eventos `AjaxRequest` , agregue un asterisco `*` como comodín.
    * Para bloquear la grabación del evento `AjaxRequest` en un dominio, ingrese solo el nombre del dominio. Ejemplo: `example.com`
    * Para bloquear la grabación del evento `AjaxRequest` en un dominio y ruta específicos, ingrese el dominio y la ruta. Ejemplo: `example.com/path`
    * La lista de denegación ignora el protocolo, el puerto, la búsqueda y el hash de una URL.

    Para validar si los filtros que ha agregado funcionan como se esperaba, ejecute una consulta NRQL para `AjaxRequest` evento que coincida con su filtro.

    ### Accediendo a la lista de denegados

    Para actualizar la lista de URL denegadas que su aplicación filtrará para la creación de eventos, vaya a la página de configuración UI de la aplicación:

    1. Vaya a **[one.newrelic.com](https://one.newrelic.com/all-capabilities)**, y haga clic en Browser.
    2. Seleccione una aplicación.
    3. En la navegación izquierda, haga clic en **App settings** \[Configuración de la aplicación].
    4. En **Ajax request deny list** \[la lista de solicitudes rechazadas de Ajax], agregue los filtros que desea aplicar.
    5. Seleccione **Save application settings** \[Almacenar configuración de la aplicación] para actualizar la configuración del agente.
    6. Vuelva a implementar el agente del navegador (ya sea reiniciando el agente APM asociado o actualizando la instalación de copiar y pegar browser ).

    ### Validando

    ```sql
    FROM AjaxRequest SELECT * WHERE requestUrl LIKE `%example.com%`
    ```
  </Collapser>

  <Collapser id="mobile-agent" title="Agente móvil">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Usuarios activos mensuales
      * Evento de accidente
      * Número de eventos por usuario
    </Callout>

    ### Android

    Todas las configuraciones, incluida la llamada para invocar al agente, se llaman en el método `onCreate` de la clase `MainActivity` . Para cambiar la configuración, llame a la configuración de una de dos maneras (si la configuración lo admite):

    ```java
    NewRelic.disableFeature(FeatureFlag.DefaultInteractions);
    NewRelic.enableFeature(FeatureFlag.CrashReporting);
    NewRelic.withApplicationToken(NEW_RELIC_TOKEN).start(this.getApplication());
    ```

    [La configuración de análisis](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#analytics-settings) habilita o deshabilita la recopilación de datos de eventos. Estos eventos se informan a New Relic y se emplean en la página de **Crash analysis** .

    También es posible configurar [el logging del agente](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#logging-settings-logging) para que sea más o menos detallado.

    ### iOS

    Al igual que ocurre con Android, la configuración de iOS de New Relic permite habilitar y deshabilitar [banderas de características](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags).

    Se pueden configurar los siguientes indicadores de características:

    #### Informes de fallos y errores

    * `NRFeatureFlag_CrashReporting`
    * `NRFeatureFlag_HandleExceptionEvents`
    * `NRFeatureFlag_CrashReporting`

    #### rastreo distribuido

    * `NRFeatureFlag_DistributedTracing`

    #### Interacción

    * `NRFeatureFlag_DefaultInteractions`
    * `NRFeatureFlag_InteractionTracing`
    * `NRFeatureFlag_SwiftInteractionTracing`

    #### Banderas características de red

    * `NRFeatureFlag_ExperimentalNetworkInstrumentation`
    * `NRFeatureFlag_NSURLSessionInstrumentation`
    * `NRFeatureFlag_NetworkRequestEvents`
    * `NRFeatureFlag_RequestErrorEvents`
    * `NRFeatureFlag_HttpResponseBodyCapture`

    Para obtener más detalles, consulte [banderas de características](/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/ios-agent-configuration-feature-flags).
  </Collapser>

  <Collapser id="infrastructure-agent" title="Agente de infraestructura">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Monitor de hosts y contenedores
      * Tasas de muestreo para eventos principales
      * Configuración de muestra de proceso
      * Atributo personalizado
      * Número y tipo de integración en el host instalado
      * Configuración de reenvío de logs
    </Callout>

    [El archivo de configuración del agente de infraestructura](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings) de New Relic contiene un par de formas poderosas de controlar el volumen de ingesta. El control de ingesta más importante es la configuración de las tasas de muestreo. Hay varias configuraciones de frecuencia de muestreo distintas que se pueden ajustar. Además, es posible crear expresiones regulares para controlar lo que se recopila de determinados recopiladores, como `ProcessSample` y `NetworkSample`.

    ### Tasas de muestreo configurables

    Hay varias frecuencias de muestreo que se pueden configurar en la infraestructura, pero estas son las más utilizadas.

    | Parámetro                     | Por defecto | Desactivar |
    | ----------------------------- | ----------- | ---------- |
    | `metrics_storage_sample_rate` | 5           | -1         |
    | `metrics_process_sample_rate` | 20          | -1         |
    | `metrics_network_sample_rate` | 10          | -1         |
    | `metrics_system_sample_rate`  | 5           | -1         |
    | `metrics_nfs_sample_rate`     | 5           | -1         |

    ### Muestras de proceso

    Las muestras de procesos pueden ser la fuente de datos de mayor volumen del agente de infraestructura. Esto se debe a que enviará información sobre cualquier proceso en ejecución en un host. Están deshabilitados de forma predeterminada, pero se pueden habilitar de la siguiente manera:

    ```yaml
    enable_process_metrics: true
    ```

    Esto tiene el mismo efecto que configurar `metrics_process_sample_rate` en `-1`.

    De forma predeterminada, los procesos que utilizan poca memoria están excluidos del muestreo. Para obtener más información, consulte `disable-zero-mem-process-filter`.

    Puedes controlar la cantidad de datos que se envían a New Relic configurando `include_matching_metrics`, lo que te permite restringir la transmisión de datos métricos en función de los valores del [atributo](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql#naming-conventions) métrico.

    Puedes incluir datos métricos definiendo valores literales o parciales para cualquiera de los atributos de la métrica. Por ejemplo, puede optar por enviar el `host.process.cpuPercent` de todos los procesos cuyo `process.name` coincida con la expresión regular `^java` .

    En este ejemplo, incluimos el proceso métrica usando archivos ejecutables y nombres:

    ```yaml
      include_matching_metrics:             # You can combine attributes from different metrics
        process.name:
          - regex "^java"                   # Include all processes starting with "java"
        process.executable:
          - "/usr/bin/python2"              # Include the Python 2.x executable
          - regex "\\System32\\svchost"     # Include all svchost executables
    ```

    También puedes utilizar este filtro para la integración de Kubernetes:

    ```yaml
    env:
      - name: NRIA_INCLUDE_MATCHING_METRICS
        value: |
          process.name:
            - regex "^java"
          process.executable:
            - "/usr/bin/python2"
            - regex "\\System32\\svchost"
    ```

    Hay un `exclude_matching_metrics` disponible que funciona de manera similar para excluir datos métricos.

    ### Filtro de interfaz de red

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Monitor de número de interfaces de red
    </Callout>

    La configuración utiliza un mecanismo simple de coincidencia de patrones que puede buscar interfaces que comiencen con una secuencia específica de letras o números siguiendo cualquiera de los patrones:

    * `{name}[other characters]`
    * `[number]{name}[other characters]`, donde especificas el nombre usando la opción `index-1`

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    Filtros de interfaz de red predeterminados para Linux:

    * Interfaces de red que comienzan con `dummy`, `lo`, `vmnet`, `sit`, `tun`, `tap` o `veth`
    * Interfaces de red que contienen `tun` o `tap`

    Filtros de interfaz de red predeterminados para Windows:

    * Interfaces de red que comienzan con `Loop`, `isatap` o `Local`

    Para anular los valores predeterminados, incluya su propio filtro en el archivo de configuración:

    ```yaml
    network_interface_filters:
      prefix:
        - dummy
        - lo
      index-1:
        - tun
    ```

    ### Atributo personalizado

    [Los atributos personalizados](/docs/data-apis/custom-data/custom-events/collect-custom-attributes) son pares de valores principales (similares a la etiqueta en otras herramientas) empleados para anotar los datos del agente de infraestructura. Puede emplear estos metadatos para crear conjuntos de filtros, agrupar sus resultados y anotar sus datos. Por ejemplo, puede indicar el entorno de una máquina (de prueba o de producción), el servicio que aloja una máquina (servicio de inicio de sesión, por ejemplo) o el equipo responsable de esa máquina.

    Ejemplo de atributo personalizado de `newrelic.yml`

    ```yaml
    custom_attributes:
      environment: production
      service: billing
      team: alpha-team
    ```

    Son potentes y útiles, pero si los datos no están bien organizados o se han vuelto obsoletos de alguna manera, debería considerar optimizarlos.
  </Collapser>

  <Collapser id="k8s-integration" title="Integración de Kubernetes">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de monitores `pods` y `containers`
      * Frecuencia y número de estados métricos de kube recopilados
      * Log generado por cluster
    </Callout>

    No sorprende que un sistema complejo y descentralizado como Kubernetes tenga el potencial de generar mucha telemetría rápidamente. Existen algunos buenos enfoques para gestionar la ingesta de datos en Kubernetes. Estos serán muy sencillos si utilizas la observabilidad como código en el despliegue de tu K8. Le recomendamos encarecidamente que instale este dashboard de análisis de ingesta de datos de Kubernetes antes de tomar cualquier decisión sobre la reducción de la ingesta de K8. Para obtener este dashboard, consulte el [inicio rápido de integración de infraestructura](https://newrelic.com/instant-observability/infrastructure-integrations-data-analysis/8e31a0ae-81c0-4df0-a119-a0ada9ec16fa).

    ### Intervalo de raspado

    Dependiendo de sus objetivos de observabilidad, puede considerar ajustar el intervalo de raspado. El valor predeterminado es 15 segundos. Ahora el explorador del clúster de Kubernetes solo se actualiza cada 45 segundos. Si su uso principal de los datos de K8 es respaldar las visualizaciones de KCE, puede considerar cambiar su intervalo de raspado a 20 segundos. Ese cambio de 15 a 20 años puede tener un impacto sustancial. Para obtener más detalles sobre cómo administrar esto, consulte nuestros [documentos sobre el intervalo de raspado de integración de Helm](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#scrape-interval).

    ### Filtrado de espacio de nombres

    La integración de Kubernetes v3 y superior permite filtrar qué espacios de nombres se eliminan etiquetándolos. De forma predeterminada, se eliminan todos los espacios de nombres.

    Usamos `namespaceSelector` de la misma manera que lo hace Kubernetes. Para incluir solo el espacio de nombres que coincida con una etiqueta, cambie el `namespaceSelector` agregando lo siguiente a su `values-newrelic.yaml`, en la sección `newrelic-infrastructure` :

    ```yaml
    common:
      config:
        namespaceSelector:
          matchLabels:
            key1 : "value1"
    ```

    En este ejemplo, solo se eliminará el espacio de nombres con la etiqueta `newrelic.com/scrape` establecida en `true` :

    ```yaml
    global:
      licenseKey: YOUR_NEW_RELIC_LICENSE_KEY
      cluster: K8S_CLUSTER_NAME

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchLabels:
              newrelic.com/scrape: "true"
    ```

    También puede utilizar expresiones de coincidencia de Kubernetes para incluir o excluir espacios de nombres. Los operadores válidos son:

    * En
    * No en
    * Existe
    * No existe

    La estructura general de la sección `matchExpressions` es una o más de las siguientes líneas:

    ```yaml
    {key: VALUE, operator: OPERATOR, values: LIST_OF_VALUES}
    ```

    Aquí tienes un ejemplo completo:

    ```yaml
    common:
      config:
        namespaceSelector:
          matchExpressions:
          - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    <Callout variant="tip">
      Se puede incluir más de una línea en la sección `matchExpresions` y las expresiones se concatenan. Todo debe ser cierto para que se aplique el filtro. Las etiquetas y las expresiones de coincidencia se explican con más detalle [aquí](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/).
    </Callout>

    En este ejemplo, se excluirá el espacio de nombres con la etiqueta `newrelic.com/scrape` establecida en `false` :

    ```yaml
    global:
      licenseKey: YOUR_NEW_RELIC_LICENSE_KEY
      cluster: K8S_CLUSTER_NAME

    # ... Other settings as shown above

    # Configuration for newrelic-infrastructure
    newrelic-infrastructure:
      # ... Other settings as shown above
      common:
        config:
          namespaceSelector:
            matchExpressions:
            - {key: newrelic.com/scrape, operator: NotIn, values: ["false"]}
    ```

    Vea una lista completa de las configuraciones que se pueden modificar en el [archivo README del gráfico](https://github.com/newrelic/nri-kubernetes/tree/main/charts/newrelic-infrastructure).

    #### ¿Cómo puedo saber qué espacios de nombres están excluidos? [#excluded-namespaces]

    Todo el espacio de nombres dentro del clúster se enumera gracias al ejemplo `K8sNamespace` . El atributo `nrFiltered` determina si los datos relacionados con el namespace se eliminarán.

    Utilice esta consulta para saber qué espacio de nombres se está supervisando:

    ```sql
    FROM K8sNamespaceSample SELECT displayName, nrFiltered
    WHERE clusterName = INSERT_NAME_OF_CLUSTER 
    SINCE 2 MINUTES AGO
    ```

    #### ¿Qué datos se descartan del espacio de nombres excluido? [#namespaces-discarded-data]

    Los siguientes ejemplos no estarán disponibles para el espacio de nombres excluido:

    * `K8sContainerSample`
    * `K8sDaemonsetSample`
    * `K8sDeploymentSample`
    * `K8sEndpointSample`
    * `K8sHpaSample`
    * `K8sPodSample`
    * `K8sReplicasetSample`
    * `K8sServiceSample`
    * `K8sStatefulsetSample`
    * `K8sVolumeSample`

    ### Estado de Kube métrica

    El explorador del clúster de Kubernetes requiere únicamente el siguiente estado métrico de kube (KSM):

    * Datos del contenedor
    * Datos del clúster
    * Datos de nodo
    * Datos del pod
    * Datos de volumen
    * Datos del servidor API<sup>1</sup>
    * Datos del administrador del controlador<sup>1</sup>
    * Datos ETCD<sup>1</sup>
    * Datos del programador<sup>1</sup>

    <sup>1</sup> No recopilado en un entorno de Kubernetes administrado (EKS, GKE, AKS, etc.)

    Puede considerar desactivar algunos de los siguientes:

    * Datos del DaemonSet
    * Desplegar datos
    * Datos extremos
    * Datos namespace
    * Datos del conjunto de réplicas<sup>2</sup>
    * Datos de servicio
    * Datos de StatefulSet

    <sup>2</sup> Usado en la alerta predeterminada: &quot;ReplicaSet no tiene la cantidad deseada de pod&quot;

    #### Ejemplo de actualización de estado métrica en manifiesto (despliegue)

    ```shell
    [spec]
      [template]
        [spec]
          [containers]
            [name=kube-state-metrics]
            [args]
            #- --collectors=daemonsets
            #- --collectors=deployments
            #- --collectors=endpoints
            #- --collectors=namespaces
            #- --collectors=replicasets
            #- --collectors=services
            #- --collectors=statefulsets
    ```

    *Ejemplo de actualización de estado métrica en manifiesto (ClusterRole)*

    ```shell
    [rules]
    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - daemonsets
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - deployments
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - endpoints
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - namespaces
    #   verbs: ["list", "watch"]

    # - apiGroups: ["extensions", "apps"]
    #   resources:
    #   - replicasets
    #   verbs: ["list", "watch"]

    # - apiGroups: [""]
    #   resources:
    #   - services
    #   verbs: ["list", "watch"]

    # - apiGroups: ["apps"]
    #   resources:
    #   - statefulsets
    #   verbs: ["list", "watch"]
    ```

    ### Configurar `lowDataMode` en `nri-bundle` gráfico

    Nuestros gráficos Helm admiten la configuración de una opción para reducir la cantidad de datos ingeridos a costa de eliminar información detallada. Para habilitarlo, establezca `global.lowDataMode` en `true` en el gráfico `nri-bundle` .

    `lowDataMode` afecta a tres componentes específicos del gráfico `nri-bundle` :

    1. Aumente el intervalo del agente de infraestructura de `15` a `30` segundos.
    2. La integración de Prometheus OpenMetrics excluirá algunas métricas como se indica en el documento Helm a continuación.
    3. Los detalles de las etiquetas y anotaciones se eliminarán del log.

    Puede encontrar más detalles sobre esta configuración en nuestro [documento Helm](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#reducedataingest).
  </Collapser>

  <Collapser id="on-host-integrations" title="Integracion on-host">
    La integración de New Relic en el host representa un conjunto diverso de integración para servicios de terceros como Postgresql, MySQL, Kafka, RabbitMQ, etc. No es posible proporcionar todas las técnicas de optimización en el alcance de este documento, pero podemos proporcionar estas técnicas de aplicación general. :

    * Administrar la frecuencia de muestreo
    * Administre aquellas partes de la configuración que pueden aumentar o disminuir la amplitud de la colección.
    * Administre aquellas partes de la configuración que permiten consultas personalizadas.
    * Administre el atributo personalizado del agente de infraestructura porque se aplicarán a todos los datos de integración en el host.

    Usaremos algunos ejemplos para demostrarlo.

    ### [Integración PostgreSQL](/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration/#example-postgresSQL-collection-config)

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Monitor de número de mesas
      * Monitor de número de índices
    </Callout>

    La configuración de integración en el host de PostgreSQL proporciona estas configuraciones ajustables que pueden ayudar a administrar el volumen de datos:

    * `interval`: El valor predeterminado es 15s
    * `COLLECTION_LIST`: lista de tablas para monitor (use TODOS para monitor TODOS)
    * `COLLECT_DB_LOCK_METRICS`: Recoge `dblock` métrica
    * `PGBOUNCER`: Recoge `pgbouncer` métrica
    * `COLLECT_BLOAT_METRICS`: Recoger hinchazón métrica
    * `METRICS`: Establezca en `true` para recopilar solo métrica
    * `INVENTORY`: Establezca en `true` para habilitar solo la recopilación de inventario
    * `CUSTOM_METRICS_CONFIG`: Archivo de configuración que contiene consulta de colección personalizada

    **Configuración de muestra:**

    ```yaml
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres
          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

    ### [Integración de kafka](/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration/)

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de corredores en el clúster
      * Número de temas en clúster
    </Callout>

    La configuración de integración en el host de Kafka proporciona estas configuraciones ajustables que pueden ayudar a administrar el volumen de datos:

    * `interval`: El valor predeterminado es 15s
    * `TOPIC_MODE`: Determina cuántos temas recopilamos. Las opciones son `all`, `none`, `list` o `regex`.
    * `METRICS`: Establezca en `true` para recopilar solo métrica
    * `INVENTORY`: Establezca en `true` para habilitar solo la recopilación de inventario
    * `TOPIC_LIST`: Matriz JSON de nombres de temas a monitor. Solo tiene efecto si topic\_mode está configurado en lista.
    * `COLLECT_TOPIC_SIZE`: recopile la métrica Tamaño del tema. Las opciones son `true` o `false`, el valor predeterminado es `false`.
    * `COLLECT_TOPIC_OFFSET`:Recopila la métrica de desplazamiento del tema. Las opciones son `true` o `false`, el valor predeterminado es `false`.

    Cabe señalar que la recopilación de métricas a nivel de tema, especialmente las compensaciones, puede requerir muchos recursos y puede tener un impacto en el volumen de datos. Es muy posible que la ingesta de un clúster pueda aumentar en un orden de magnitud simplemente agregando nuevos temas de Kafka al clúster.

    ### [Integración de MongoDB](/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration)

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de monitor de base de datos
    </Callout>

    La integración de MongoDB proporciona estas configuraciones ajustables que pueden ayudar a administrar el volumen de datos:

    * `interval`: El valor predeterminado es 15s
    * `METRICS`: Establezca en `true` para recopilar solo métrica
    * `INVENTORY`: Establezca en `true` para habilitar solo la recopilación de inventario
    * `FILTERS`: un mapa JSON de nombres de bases de datos a una matriz de nombres de colecciones. Si está vacío, el valor predeterminado es toda la base de datos y colecciones.

    Para cualquier integración en el host que utilice, es importante tener en cuenta parámetros como `FILTERS` donde el valor predeterminado es recopilar métricas de toda la base de datos. Esta es un área donde puede utilizar sus prioridades de monitoreo para optimizar los datos recopilados.

    **Ejemplo de configuración con diferentes intervalos para métrica e INVENTARIO:**

    ```yaml
    integrations:
      - name: nri-mongodb
        env:
          METRICS: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 15s
        labels:
          environment: production

      - name: nri-mongodb
        env:
          INVENTORY: true
          CLUSTER_NAME: my_cluster
          HOST: localhost
          PORT: 27017
          USERNAME: mongodb_user
          PASSWORD: mongodb_password
        interval: 60s
        labels:
          environment: production
        inventory_source: config/mongodb
    ```

    ### [Integración de búsqueda elástica](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration)

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de nodos en el clúster
      * Número de índices en clúster
    </Callout>

    La integración de Elasticsearch proporciona estas configuraciones ajustables que pueden ayudar a administrar el volumen de datos:

    * `interval`: El valor predeterminado es 15s
    * `METRICS`: Establezca en `true` para recopilar solo métrica
    * `INVENTORY`: Establezca en `true` para habilitar solo la recopilación de inventario
    * `COLLECT_INDICES`: Señala si se deben recoger índices métricos o no.
    * `COLLECT_PRIMARIES`: Señala si se debe recoger métrica primaria o no.
    * `INDICES_REGEX`: filtra qué índices se recopilan.
    * `MASTER_ONLY`: Recoge el grupo métrico únicamente en el maestro elegido.

    **Ejemplo de configuración con diferentes intervalos para `METRICS` y `INVENTORY`:**

    ```yaml
    integrations:
      - name: nri-elasticsearch
        env:
          METRICS: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          REMOTE_MONITORING: true
        interval: 15s
        labels:
          environment: production

      - name: nri-elasticsearch
        env:
          INVENTORY: true
          HOSTNAME: localhost
          PORT: 9200
          USERNAME: elasticsearch_user
          PASSWORD: elasticsearch_password
          CONFIG_PATH: /etc/elasticsearch/elasticsearch.yml
        interval: 60s
        labels:
          environment: production
        inventory_source: config/elasticsearch
    ```

    ### [Integración JMX](/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration)

    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Métrica listada en `COLLECTION_CONFIG`
    </Callout>

    La integración JMX es inherentemente genérica. Nos permite extraer métrica de cualquier instancia de JMX. Tenemos un buen control sobre lo que se recopila mediante esta integración. En algunos entornos empresariales de New Relic, JMX métrica representa una proporción relativamente alta de todos los datos recopilados.

    La integración JMX proporciona estas configuraciones ajustables que pueden ayudar a administrar el volumen de datos:

    * `interval`: El valor predeterminado es 15s
    * `METRICS`: Establezca en `true` para recopilar solo métrica
    * `INVENTORY`: Establezca en `true` para habilitar solo la recopilación de inventario
    * `METRIC_LIMIT`: Número de métricas que se pueden recolectar por entidad. Si se excede este límite la entidad no será reportada. Un límite de 0 implica que no hay límite.
    * `LOCAL_ENTITY`: Recoge todas las métricas de la entidad local. Sólo se utiliza cuando se monitorea localhost.
    * `COLLECTION_FILES`: una lista separada por comas de rutas de archivo completas a los archivos de definición de la colección métrica. Para la instalación en el host, el archivo de colección métrica JVM predeterminado está en `/etc/newrelic-infra/integrations.d/jvm-metrics.yml`.
    * `COLLECTION_CONFIG`: configuración de la colección métrica como JSON.

    Son las `COLLECTION_CONFIG` entradas las que más controlan la cantidad de datos ingeridos. Comprender el modelo JMX que está extrayendo le ayudará a optimizar.

    *`COLLECTION_CONFIG` ejemplo para JVM métrica*

    ```java
    COLLECTION_CONFIG='{"collect":[{"domain":"java.lang","event_type":"JVMSample","beans":[{"query":"type=GarbageCollector,name=*","attributes":["CollectionCount","CollectionTime"]},{"query":"type=Memory","attributes":["HeapMemoryUsage.Committed","HeapMemoryUsage.Init","HeapMemoryUsage.Max","HeapMemoryUsage.Used","NonHeapMemoryUsage.Committed","NonHeapMemoryUsage.Init","NonHeapMemoryUsage.Max","NonHeapMemoryUsage.Used"]},{"query":"type=Threading","attributes":["ThreadCount","TotalStartedThreadCount"]},{"query":"type=ClassLoading","attributes":["LoadedClassCount"]},{"query":"type=Compilation","attributes":["TotalCompilationTime"]}]}]}'
    ```

    Omitir cualquier entrada de esa configuración, como `NonHeapMemoryUsage.Init` , tendrá un impacto tangible en el volumen general de datos recopilados.

    *`COLLECTION_CONFIG` ejemplo para Tomcat métrica*

    ```java
    COLLECTION_CONFIG={"collect":[{"domain":"Catalina","event_type":"TomcatSample","beans":[{"query":"type=UtilityExecutor","attributes":["completedTaskCount"]}]}]}
    ```

    ### Otra integración en el host

    Hay muchas otras integraciones en el host con opciones de configuración que te ayudarán a optimizar la recopilación. Algunos de uso común son:

    * [NGINX](/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-integration/)
    * [MySQL](/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration)
    * [Redis](/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration)
    * [Apache](/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration)
    * [RabbitMQ](/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration)

    Este es un buen [punto de partida](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations#on-host) para aprender más.
  </Collapser>

  <Collapser id="network-performance-monitoring" title="Monitoreo del desempeño de la red (NPM)">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      Monitorear dispositivos impulsados por:

      * dispositivos configurados duro
      * Alcance de CIDR en la sección de descubrimiento
      * trampas configuradas
    </Callout>

    Esta sección se centra en el monitoreo del rendimiento de la red de New Relic que depende del agente `ktranslate` de Kentik. Este agente es bastante sofisticado y es importante comprender completamente los [documentos de configuración avanzada](/docs/network-performance-monitoring/advanced/advanced-config) antes de realizar esfuerzos importantes de optimización. Las opciones de configuración incluyen:

    * `mibs_enabled`: matriz de todas las MIB activas que sondeará la imagen docker de KTranslate. Esta lista se genera automáticamente durante el descubrimiento si el atributo `discovery_add_mibs` es `true`. Las MIB que no figuran aquí no serán sondeadas en ningún dispositivo en el archivo de configuración. Puede especificar una tabla SNMP directamente en un archivo MIB usando la sintaxis `MIB-NAME.tableName` . Ej: `HOST-RESOURCES-MIB.hrProcessorTable`.

    * `user_tags`: valor principal atributo del par para darle más contexto al dispositivo. La etiqueta en este nivel se aplicará a todos los dispositivos en el archivo de configuración.

    * `devices`: Sección que enumera los dispositivos que se monitorearán para determinar el flujo

    * `traps`: configura IP y puertos para ser monitoreados con capturas SNMP (el valor predeterminado es `127.0.0.1:1162`)

    * `discovery`: configura cómo se puede descubrir el extremo. En esta sección, el siguiente parámetro hará más para aumentar o disminuir el alcance:

      * `cidrs`: matriz de rangos de IP objetivo en [notación CIDR](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation).
      * `ports`: matriz de puertos de destino para escanear durante el sondeo SNMP.
      * `debug`: Indica si se debe habilitar el logging de nivel de depuración durante el descubrimiento. De forma predeterminada, está configurado en `false`
      * `default_communities`: matriz de cadenas de comunidad SNMPv1/v2c para escanear durante el sondeo SNMP. Esta matriz se evalúa en orden y el descubrimiento acepta la primera comunidad que pasa.

    Para admitir el filtrado de datos que no crean valor para sus necesidades de observabilidad, puede configurar el mapa de atributos `global.match_attributes.{}` y/o `devices.<deviceName>.match_attributes.{}` .

    Esto proporcionará filtrado a nivel de KTranslate, antes de enviar datos a New Relic, brindándole un control granular sobre el monitoreo de cosas como interfaces.

    Para obtener más detalles, consulte [Configuración de monitoreo del rendimiento de la red](/docs/network-performance-monitoring/advanced/advanced-config/#match_attributes-attribute).
  </Collapser>

  <Collapser id="log-forwarders" title="Reenviador de log">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Log reenviado
      * Tamaño promedio de los log de avance
    </Callout>

    Log representa una de las fuentes de telemetría más flexibles, ya que normalmente enrutamos el log a través de una capa de reenvío dedicada con sus propias reglas de enrutamiento y transformación. Debido a que existe una variedad de reenviadores, nos centraremos en los más utilizados:

    * APM language agente (versiones recientes)
    * Fluentd
    * Fluentbit
    * Agente New Relic Infrastructure (Fluentbit integrado)
    * Logstash

    ### Muestreo log del agente APM

    Las versiones recientes del agente de lenguaje de New Relic pueden reenviar logs directamente a New Relic. En algunos casos, es posible que desee controlar algunos límites de cuán grandes pueden ser los picos de logging de cada instancia del agente APM.

    Podemos habilitar el muestreo con la variable de entorno. `NEW_RELIC_APPLICATION_LOGGING_FORWARDING_MAX_SAMPLES_STORED`

    Se configura simplemente proporcionando la cantidad máxima de logs que se almacenarán en la cola de logging del agente APM. Opera en base a una cola de prioridad personalizada. Todos los mensajes de log tienen prioridad. Los logs que ocurren dentro de una transacción obtienen la prioridad de la transacción.

    La cola de logs se ordena según la prioridad y cuándo llega el log . La prioridad más alta gana y, si es necesario, ganará el log más nuevo (mantenemos un recuento de cada entrada en la cola). Los logs se agregan individualmente a la cola (los pares en una transacción) y cuando se alcanza el límite, el log al final de la cola se elimina a favor del log más nuevo. En la sección de recursos a continuación hay un [dashboard inicio rápido](https://onenr.io/0Bj3BlEZkRX) que le ayuda a realizar un seguimiento del volumen log de una manera sencilla. El seguimiento del volumen log le permitirá ajustar o desactivar la frecuencia de muestreo para satisfacer sus necesidades de observabilidad.

    ### Configurando filtros en Fluentd o Fluentbit

    La mayoría de los reenviadores generales proporcionan un [flujo de trabajo de enrutamiento](https://docs.fluentd.org/configuration/routing-examples) bastante completo que incluye filtrado y transformación. El agente de infraestructura de New Relic proporciona algunos patrones muy simples para filtrar logs no deseados. Expresión regular para filtrar registros. Solo se admite para las fuentes `tail`, `systemd`, `syslog` y `tcp` (solo con formato ninguno). Este campo funciona de forma similar a `grep -E` en sistemas Unix. Por ejemplo, para un archivo determinado que se está capturando, puede filtrar los registros que contengan `WARN` o `ERROR` usando:

    ```yaml
    - name: only-records-with-warn-and-error
      file: /var/log/logFile.log
      pattern: WARN|ERROR
    ```

    Si tiene configuraciones de Fluentd preescritas para Fluentbit que realizan filtrado o análisis valiosos, puede importarlas a nuestra configuración de logging de New Relic. Para hacer esto, use el parámetro `config_file` y `parsers` en cualquier archivo `.yaml` en su carpeta `logging.d` :

    * `config_file`: ruta a un archivo de configuración de Fluent Bit existente. Cualquier fuente superpuesta da como resultado mensajes duplicados en New Relic la administración de de log .
    * `parsers_file`: ruta a un archivo de analizadores Fluent Bit existente.

    Los siguientes nombres de analizadores están reservados: `rfc3164`, `rfc3164-local` y `rfc5424`.

    Aprender cómo inyectar un atributo (o etiqueta) en su log en su canal de datos y realizar transformaciones puede ayudar con la eliminación de características posteriores utilizando las reglas de eliminación de New Relic. Al aumentar su log con metadatos sobre la fuente, podemos tomar decisiones centralizadas y fácilmente reversibles sobre qué colocar en el backend. Como mínimo, asegúrese de que el siguiente atributo esté presente en su log de alguna forma:

    * Equipo
    * Entorno (desarrollo/etapa/producción)
    * Aplicación
    * Centro de datos
    * Nivel de Log

    A continuación se muestran algunos recursos detallados de enrutamiento y filtrado:

    * [Patrones comunes de filtrado y enrutamiento en Fluentd](https://docs.fluentd.org/configuration/routing-examples)
    * [Tubería de datos de Fluentbit](https://docs.fluentbit.io/manual/concepts/data-pipeline)
    * [Reenvío de logs con el agente New Relic Infrastructure](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/)

    ### Ajustar el conjunto de atributos predeterminado del agente de infraestructura

    El agente de infraestructura agrega algún atributo de forma predeterminada, incluida cualquier etiqueta personalizada agregada al host. Es posible que su configuración incluya muchas más que eso, incluida una gran cantidad de etiquetas de AWS, que aparecen en New Relic con el formulario `aws.[attributename]`. Estos atributos son importantes para una observabilidad óptima, por lo que se recomienda encarecidamente que evalúe sus necesidades de visualización, análisis y alertas a la luz de cualquier cambio de configuración planificado. Por ejemplo, el log de un clúster de Kubernetes probablemente no será útil sin metadatos como:

    * `cluster_name`
    * `pod_name`
    * `container_name`
    * `node_name`
  </Collapser>

  <Collapser id="prometheus-metrics-sources" title="Fuentes métricas de Prometheus">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de métricas exportadas desde aplicaciones
      * Número de métricas transferidas vía escritura remota o POMI
    </Callout>

    New Relic ofrece dos opciones principales para enviar Prometheus métrica a New Relic. Las mejores prácticas para gestionar la ingesta métrica en este documento se centrarán principalmente en la opción 2, la integración de Prometheus OpenMetrics (POMI), porque este componente fue creado por New Relic.

    ### Opción 1: [integración de escritura remota de Prometheus](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)

    Para conocer las opciones de configuración de extracción del servidor Prometheus, consulte [los documentos de configuración de Prometheus](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config). Estas configuraciones de raspado determinan qué métricas recopila el servidor Prometheus. Al configurar el parámetro [`remote_write`](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration) , la métrica recopilada se puede escribir en la base de datos de New Relic (NRDB) a través de la API de métrica de New Relic.

    ### Opción 2: [integración de Prometheus OpenMetrics (POMI)](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration)

    POMI es una integración independiente que extrae métrica del extremo Prometheus tanto dinámico como estático. Luego, POMI envía estos datos a NRDB a través de la API métrica de New Relic. Esta integración es ideal para clientes que actualmente no ejecutan Prometheus Server.

    #### POMI: etiqueta raspada

    POMI descubrirá cualquier extremo de Prometheus que contenga la etiqueta o anotación `prometheus.io/scrape=true` de forma predeterminada. Dependiendo de lo que se despliegue en el grupo, esto puede ser una gran cantidad de extremos y, por lo tanto, una gran cantidad de métricas ingeridas.

    Se sugiere modificar el parámetro `scrape_enabled_label` a algo personalizado (p. ej. `newrelic/scrape`) y que el extremo de Prometheus se etiquete o anote selectivamente cuando la ingesta de datos sea de suma preocupación.

    Para obtener la configuración de referencia más reciente, consulte [nri-prometheus-latest.yaml](https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml).

    **Parámetros de configuración de POMI:**

    ```yaml
    # Label used to identify scrapable targets. 
    # Defaults to "prometheus.io/scrape"
    scrape_enabled_label: "prometheus.io/scrape"
    ```

    POMI descubrirá cualquier extremo de Prometheus expuesto a nivel de nodo de forma predeterminada. Esto generalmente incluye métricas provenientes de Kubelet y cAdvisor.

    Si está ejecutando New Relic Kubernetes Daemonset, es importante que configure `require_scrape_enabled_label_for_nodes: true` para que POMI no recopile métricas duplicadas.

    Para conocer el objetivo final de New Relic Kubernetes Daemonset, consulte [nuestro README de Kubernetes en GitHub](https://github.com/newrelic/nri-kubernetes/blob/main/README.md).

    #### POMI: etiqueta raspada para nodos

    POMI descubrirá cualquier extremo de Prometheus expuesto a nivel de nodo de forma predeterminada. Esto generalmente incluye métricas provenientes de Kubelet y cAdvisor.

    Si está ejecutando New Relic Kubernetes Daemonset, es importante que configure `require_scrape_enabled_label_for_nodes: true` para que POMI no recopile métricas duplicadas.

    Para conocer el objetivo final de New Relic Kubernetes Daemonset, consulte [nuestro README de Kubernetes en GitHub](https://github.com/newrelic/nri-kubernetes/blob/main/README.md).

    *Parámetro de configuración POMI*

    ```yaml
    # Whether k8s nodes need to be labeled to be scraped or not. 
    # Defaults to false.
    require_scrape_enabled_label_for_nodes: false
    ```

    #### POMI: coexistiendo con `nri-kubernetes`

    [La integración de Kubernetes](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration) de New Relic recopila una [cantidad de métricas](/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data#metrics) listas para usar. Sin embargo, no recopila todas las métricas posibles disponibles de un clúster de Kubernetes.

    En la configuración de POMI, verá una sección similar a esta que deshabilitará la recopilación de métrica para un subconjunto de métrica que ****la New Relic Kubernetes integración ya está recopilando de **Kube State Metrics**.

    También es muy importante configurar `require_scrape_enabled_label_for_node: true` para que Kubelet y cAdvisor métrica no se dupliquen.

    **Parámetros de configuración de POMI:**

    ```yaml
    transformations:
      - description: "Uncomment if running New Relic Kubernetes integration"
        ignore_metrics:
          - prefixes:
            - kube_daemonset_
            - kube_deployment_
            - kube_endpoint_
            - kube_namespace_
            - kube_node_
            - kube_persistentvolume_
            - kube_persistentvolumeclaim_
            - kube_pod_
            - kube_replicaset_
            - kube_service_
            - kube_statefulset_
    ```

    #### POMI: configuración de solicitud/límite

    Al ejecutar POMI, se recomienda aplicar los siguientes [límites de recursos](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/) para el clúster que genera aproximadamente 500k DPM:

    * Límite de CPU: 1 núcleo (1000 m)
    * Límite de memoria: 1Gb 1024 (1G)

    La solicitud de recursos para CPU y memoria debe establecerse en un valor razonable para que POMI reciba suficientes recursos del clúster. Establecer esto en algo extremadamente bajo (p. ej. CPU: 50 m) puede provocar que los &quot;vecinos ruidosos&quot; consuman los recursos del clúster.

    **Parámetros de configuración de POMI:**

    ```yaml
    spec:
      serviceAccountName: nri-prometheus
      containers:
      - name: nri-prometheus
        image: newrelic/nri-prometheus:2.2.0
        resources:
          requests:
            memory: 512Mi
            cpu: 500m
          limits:
            memory: 1G
            cpu: 1000m
    ```

    ### POMI: estimación de DPM y cardinalidad

    Aunque la cardinalidad no está asociada directamente con la facturación por ingesta de GB, New Relic mantiene ciertos límites de velocidad en cardinalidad y puntos de datos por minuto. Poder visualizar la cardinalidad y el DPM de un clúster de Prometheus puede ser muy importante.

    <Callout variant="tip">
      Las cuentas New Relic tienen un límite de 1 millón de DPM y 1 millón de cardinalidad, pero puedes solicitar hasta 15 millones de DPM y 15 millones de cardinalidad. Para solicitar cambios, comuníquese con su representante de cuenta de New Relic. Para obtener más información, consulte [Límites API métricos](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes).
    </Callout>

    Si ya está ejecutando Prometheus Server, puede ejecutar estimaciones de cardinalidad y DPM allí antes de habilitar POMI o `remote_write`.

    **Puntos de datos por minuto (DPM):**

    ```promql
    rate(prometheus_tsdb_head_samples_appended_total[10m]) * 60
    ```

    **Top 20 métricas (alta cardinalidad):**

    ```promql
    topk(20, count by (**name**, job)({__name__=~".+"}))
    ```
  </Collapser>

  <Collapser id="cloud-integration" title="Integracion en la nube">
    <Callout variant="IMPORTANT" title="Controladores de crecimiento">
      * Número de métricas exportadas por integración
      * Frecuencia de sondeo (para integración basada en sondeo)
    </Callout>

    Algunas integraciones de New Relic en la nube obtienen datos de las API de los proveedores de la nube. Con esta implementación, los datos generalmente se recopilan de API de monitoreo como AWS CloudWatch, monitoreo de Azure y GCP Stackdriver, y los metadatos de inventario se recopilan de las API de servicios específicos.

    Otras integraciones en la nube obtienen sus datos de streaming métrico (o métrico &quot;empujado&quot;) que se envían a través de un servicio de streaming como AWS Kinesis.

    ### Integración basada en API de sondeo

    Si desea reportar más o menos datos de su integración en la nube, o si necesita controlar el uso de las API de los proveedores de la nube para evitar alcanzar límites de velocidad y aceleración en su cuenta de la nube, puede cambiar los ajustes de configuración para modificar la cantidad de datos que reportan. Los dos controles principales son:

    * [Cambiar la frecuencia de las encuestas](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#polling)
    * [Cambiar los datos que se informan](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#filter-data)

    Ejemplos de razones comerciales para querer cambiar la frecuencia de las encuestas incluyen:

    * **Facturación**: si necesita gestionar su factura de AWS CloudWatch, es posible que desee disminuir la frecuencia de sondeo. Antes de hacer esto, cerciorar de que cualquier condición de alerta establecida para su integración en la nube no se vea afectada por esta reducción.
    * **Nuevos servicios**: si está implementando un nuevo servicio o configuración y desea recopilar datos con más frecuencia, es posible que desee aumentar la frecuencia de sondeo temporalmente.

    <Callout variant="caution">
      Cambiar los ajustes de configuración de su integración puede afectar la condición de alerta y las tendencias de los gráficos.
    </Callout>

    Para obtener más detalles, consulte [Configurar el sondeo](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations).

    ### &quot;Streaming&quot; o &quot;empujado&quot; métrica

    Cada vez más integración en la nube ofrecen la opción de enviar los datos a través de un [servicio de transmisión](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream) en lugar de utilizar el sondeo API. Se ha demostrado que esto reduce drásticamente la latencia. Un problema que algunos usuarios han observado es que no es tan fácil controlar el volumen porque no se puede configurar la frecuencia de muestreo.

    New Relic para eliminar datos se tratarán detalladamente en la siguiente sección. Son la forma principal de filtrar transmisiones métricas que tienen un volumen demasiado alto. Sin embargo, hay algunas cosas que se pueden hacer por parte del proveedor de la nube para limitar un poco el volumen de transmisión.

    Por ejemplo, en AWS es posible utilizar claves de condición para [limitar el acceso a los espacios de nombres de CloudWatch\*](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/iam-cw-condition-keys-namespace.html).

    La siguiente política limita al usuario a publicar métricas únicamente en el namespace denominado `MyCustomNamespace`:

    ```json
    {
        "Version": "2012-10-17",
        "Statement": {
            "Effect": "Allow",
            "Resource": "*",
            "Action": "cloudwatch:PutMetricData",
            "Condition": {
                "StringEquals": {
                    "cloudwatch:namespace": "MyCustomNamespace"
                }
            }
        }
    }
    ```

    La siguiente política permite al usuario publicar métricas en cualquier namespace excepto `CustomNamespace2`:

    ```json
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData"
            },
            {
                "Effect": "Deny",
                "Resource": "*",
                "Action": "cloudwatch:PutMetricData",
                "Condition": {
                    "StringEquals": {
                        "cloudwatch:namespace": "CustomNamespace2"
                    }
                }
            }
        ]
    }
    ```
  </Collapser>
</CollapserGroup>

#### Optimización con reglas de caída [#optimization-with-drop-rules]

Una regla simple para entender lo que puedes hacer con las reglas de eliminación es: **si puedes consultarla, puedes eliminarla.**

Las reglas de filtrado de caídas le ayudan a lograr varios objetivos importantes:

* Reduzca los costos almacenando solo el log relevante para su cuenta.
* Proteja la privacidad y la seguridad eliminando la información de identificación personal (PII).
* Reduzca el ruido eliminando eventos y atributos irrelevantes.

**Nota de precaución**: al crear reglas de eliminación, usted es responsable de garantizar que las reglas identifiquen y descarten con precisión los datos que cumplan las condiciones que estableció. También eres responsable de monitorear la regla, así como los datos que divulgas a New Relic. Pruebe siempre y vuelva a probar su consulta y, luego de instalar la regla de eliminación, cerciorar de que funcione según lo previsto. Será de ayuda crear un dashboard para monitor sus datos antes y luego del lanzamiento.

A continuación se ofrecen algunas pautas para utilizar reglas de eliminación para optimizar la ingesta de datos para herramientas específicas:

<CollapserGroup>
  <Collapser id="logs" title="Logs">
    Todas las reglas de caída de New Relic se implementan mediante el mismo modelo de datos de backend y API. Sin embargo, la administración de logs de New Relic proporciona una potente UI que hace que sea muy fácil crear y monitor reglas de eliminación.

    En nuestra sección anterior sobre priorización de la telemetría, realizamos algunos ejercicios para mostrar formas en las que podríamos desaprobar ciertos datos. Revisemos este ejemplo:

    ```
    Omit debug logs (knowing they can be turned on if there is an issue) (saves 5%)
    ```

    #### Método 1: [log UI](/docs/logs/ui-data/drop-data-drop-filter-rules)

    * Identifique el log que nos interesa mediante un filtro en la log UI: `level: DEBUG`.
    * Asegúrese de que encuentre el log que queremos eliminar.
    * Verifique alguna sintaxis alternativa como `level:debug` y `log_level:Debug`. Estas variaciones son comunes.
    * En **Manage data**, haga clic en **Drop filters** y cree y habilite un filtro llamado &apos;Eliminar registro de depuración&apos;.
    * Verifique que la regla funcione.

    #### Método 2: [nuestra API NerdGraph](/docs/data-apis/manage-data/drop-data-using-nerdgraph/)

    * Cree la consulta NRQL relevante:
      ```sql
      SELECT count(*) FROM Log WHERE `level` = 'DEBUG'
      ```
    * Asegúrese de que encuentre el log que queremos eliminar.
    * Verifique las variaciones en el nombre y el valor del atributo (`Debug` vs `DEBUG`).
    * Ejecute la siguiente declaración NerdGraph y asegúrese de que funcione:

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_DATA
                nrql: "SELECT * FROM Log WHERE `level` = 'DEBUG'"
                description: "Drops DEBUG logs.  Disable if needed for troubleshooting."
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser id="process-samples" title="Muestras de proceso">
    Implementemos la recomendación: `Drop process sample data in DEV environments`.

    * Cree la consulta relevante:

      ```sql
      SELECT * FROM ProcessSample WHERE `env` = 'DEV'
      ```

    * Asegúrese de que encuentre las muestras de proceso que queremos eliminar.

    * Compruebe si hay otras variaciones en `env` como `ENV` y `Environment`

    * Compruebe si hay varios de `DEV` como `Dev` y `Development`

    * Utilice nuestra API NerdGraph para ejecutar la siguiente declaración y asegúrese de que funcione:

      ```graphql
      mutation {
          nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
              {
                  action: DROP_DATA
                  nrql: "SELECT * FROM ProcessSample WHERE `env` = 'DEV'"
                  description: "Drops ProcessSample from development environments"
              }
          ])
          {
              successes { id }
              failures {
                  submitted { nrql }
                  error { reason description }
              }
          }
      }
      ```
  </Collapser>

  <Collapser id="cloud-metrics" title="Nube métrica">
    En algunos casos podemos economizar datos cuando tenemos cobertura redundante. Por ejemplo: en un entorno donde tiene la integración de AWS RDS ejecutándose, así como una de las integraciones de New Relic en el host que monitor la base de datos SQL como `nri-mysql` o `nri-postgresql`, es posible que pueda descartar algunas métricas superpuestas. .

    Para una exploración rápida podemos ejecutar una consulta como esta:

    ```sql
    FROM Metric SELECT count(*) WHERE metricName LIKE 'aws.rds%' 
    FACET metricName LIMIT MAX
    ```

    Eso nos mostrará todos los `metricName` valores que coinciden con el patrón.

    Vemos en los resultados que hay un gran volumen de métrica del patrón `aws.rds.cpu%`. Dejémoslos porque tenemos otra instrumentación para ellos:

    * Cree la consulta relevante:
      ```sql
      FROM Metric SELECT * WHERE metricName LIKE 'aws.rds.cpu%' 
      FACET metricName LIMIT MAX SINCE 1 day ago
      ```
    * Asegúrese de que encuentre las muestras de proceso que queremos eliminar.
    * Utilice la API NerdGraph para ejecutar la siguiente declaración y asegúrese de que funcione:

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_DATA
                nrql: "FROM Metric SELECT * WHERE metricName LIKE 'aws.rds.cpu%' FACET metricName LIMIT MAX SINCE 1 day ago"
                description: "Drops rds cpu related metrics"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser id="drop-specific-attributes" title="Soltar atributo específico">
    Una ventaja de las reglas de eliminación es que podemos configurar una regla que elimine un atributo específico pero mantenga el resto de los datos intactos. Úselo para eliminar datos privados de NRDB o para eliminar un atributo excesivamente grande. Por ejemplo, el rastreo del stack o grandes fragmentos de JSON en log a veces pueden ser muy grandes.

    Para establecer estas reglas de eliminación, cambie el campo `action` a `DROP_ATTRIBUTES` en lugar de `DROP_DATA`.

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_ATTRIBUTES
                nrql: "SELECT stack_trace, json_data FROM Log WHERE appName='myApp'"
                description: "Drops large fields from logs for myApp"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser id="drop-random-sample-of-events" title="Soltar muestra aleatoria de evento">
    <Callout variant="caution">
      Utilice este enfoque con cuidado y sólo en situaciones en las que no haya otras alternativas, porque puede alterar las inferencias estadísticas realizadas a partir de sus datos. Sin embargo, para eventos con un tamaño de muestra enorme, puede utilizar solo una parte de sus datos siempre que comprenda las consecuencias.
    </Callout>

    En este ejemplo aprovecharemos la distribución relativa de ciertos ID de traza para aproximar el muestreo aleatorio. Podemos utilizar el operador `RLIKE` para comprobar los valores principales del atributo `trace.id` de un intervalo.

    El siguiente ejemplo podría reducir aproximadamente el 25 % de los intervalos:

    ```sql
    SELECT * FROM Span 
    WHERE trace.id RLIKE r'.*[0-3]' AND appName = 'myApp'
    ```

    Las expresiones útiles incluyen:

    * `r'.*0'` se aproxima al 6,25%
    * `r'.*[0-1]'` se aproxima al 12,5%
    * `r'.*[0-2]'` se aproxima al 18,75%
    * `r'.*[0-3]'` se aproxima al 25,0%

    Aquí hay un ejemplo de una mutación completa:

    ```graphql
    mutation {
        nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
            {
                action: DROP_ATTRIBUTES
                nrql: "SELECT * FROM Span WHERE trace.id RLIKE r'.*[0-3]' AND appName = 'myApp'"
                description: "Drops approximately 25% of spans for myApp"
            }
        ])
        {
            successes { id }
            failures {
                submitted { nrql }
                error { reason description }
            }
        }
    }
    ```
  </Collapser>

  <Collapser id="other-events-and-metrics" title="Otros eventos y métricas">
    Los ejemplos anteriores deberían mostrarle todo lo que necesita saber para utilizar estas técnicas en cualquier otro evento o métrica en NRDB. Si puedes consultarlo puedes dejarlo. Comuníquese con New Relic si tiene preguntas sobre la forma precisa de estructurar una consulta para una regla de eliminación.
  </Collapser>
</CollapserGroup>

## Ejercicio [#exercise]

Responder las siguientes preguntas le ayudará a desarrollar confianza en su capacidad para desarrollar y ejecutar planes de optimización. Es posible que desee utilizar los dashboards de desglose de entidades de [ingesta de datos de la línea de base](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-dashboard) y [de ingesta de datos](http://localhost:8000/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-entity-breakdown-dashboard) de la sección `Baselining` . Instale esos dashboards como se describe y vea cuántas de estas preguntas puede responder.

| Preguntas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ¿Muestre tres reglas de eliminación en las que podría reducir la ingesta de esta organización en al menos un 5 % por mes? Incluya la sintaxis NerdGraph para su regla de eliminación en su respuesta.                                                                                                                                                                                                                                                                                                                                                             |
| ¿Sugiera tres cambios de configuración de instrumentación que podría implementar para reducir la ingesta de esta organización en al menos un 5 % por mes? Incluya el fragmento de configuraciones en su respuesta.                                                                                                                                                                                                                                                                                                                                                |
| ¿Cuáles son las tres cosas que podría hacer para reducir el volumen de datos del monitoreo de K8? ¿Cuánta reducción de datos podría lograr? ¿Cuáles son las posibles ventajas y desventajas de esta reducción? (por ejemplo, ¿perderían alguna observabilidad sustancial?)                                                                                                                                                                                                                                                                                        |
| 1. Emplee el dashboard línea de base de gobernanza de ingesta de datos para identificar una cuenta que envía una gran cantidad de datos de log a New Relic.<br />2. Busque y seleccione esa cuenta desde el selector de cuentas.<br />3. Navegue a la página de** logs** de la cuenta y seleccione **patterns** en el menú del lado izquierdo.<br />4. Revise los patrones de troncos que se muestran y dé algunos ejemplos de patrones de troncos de bajo valor. ¿Qué hace que tengan bajo valor? ¿Cuánta reducción total podrías lograr si eliminas estos logs? |
| Según su análisis general de esta organización, ¿qué telemetría está infrautilizada?                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

## Conclusión [#conclusion]

La sección de proceso nos mostró cómo asociar nuestra telemetría con impulsores u objetivos de valor de observabilidad específicos. Esto puede facilitar un poco la difícil decisión de optimizar la ingesta de nuestra cuenta. Aprendimos a describir un [plan de optimización](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#develop-plan) de alto nivel que optimiza la ingesta y al mismo tiempo protege nuestros objetivos. Finalmente, se nos presentó un [rico conjunto de recetas](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#use-reduction-techniques) para la configuración y optimizaciones de ingesta basadas en reglas de eliminación.