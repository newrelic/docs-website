---
title: 'Gestión de calidad de alerta: Optimice su alerta y reduzca el exceso de alertas.'
tags:
  - Observability maturity
  - 'Uptime, performance, and reliability'
  - Alert quality management
  - Implementation guide
metaDescription: 'New Relic observability maturity series: the alert quality management guide helps reduce alert fatigue by ensuring that fewer and more valuable incidents are created in New Relic.'
freshnessValidatedDate: never
translationType: machine
---

Esta guía le guiará para mejorar y optimizar la calidad de sus alertas. Es parte de nuestra [serie sobre madurez de observabilidad](/docs/new-relic-solutions/observability-maturity/introduction).

## Descripción general [#overview]

Los equipos sufren de exceso de alertas cuando experimentan altos volúmenes de alertas y alertas que no están alineadas con el impacto empresarial. Los altos volúmenes de alertas capacitan a los respondedores de incidentes para que asuman que las alertas son falsas y no tienen ningún impacto comercial. A su vez, pueden comenzar a priorizar alertas fáciles de resolver sobre otras y pueden cerrar incidentes no resueltos para poder mantenerse dentro de su objetivo de SLA. Esto da como resultado una respuesta a incidentes más lenta y un mayor alcance y gravedad cuando ocurren verdaderos problemas que afectan el negocio.

<DoNotTranslate>**Alert quality management**</DoNotTranslate> (AQM) se centra en reducir el número de incidentes molestos para que usted se centre únicamente en las alertas con un verdadero impacto empresarial. Esto reduce el exceso de alertas y garantiza que usted y su equipo concentren su atención en los lugares correctos en los momentos correctos.

Eres un buen candidato para AQM si:

* Tienes demasiadas alertas.
* Tienes alerta que permanece abierta por largos periodos de tiempo.
* Tus alertas no son relevantes.
* Sus clientes descubren sus problemas antes que sus herramientas de monitoreo.
* No puede ver el valor de sus herramientas de observabilidad.

## Resultado deseado [#desired-outcome]

Al utilizar una estrategia de alerta basada en la medición del impacto empresarial, disminuirá el tiempo de respuesta y aumentará el conocimiento de eventos críticos. A medida que mejore su relación señal-ruido de alerta, reducirá la confusión y podrá identificar y aislar rápidamente la causa raíz de sus problemas.

El objetivo general de <DoNotTranslate>**alert quality management**</DoNotTranslate> es garantizar que se creen menos incidentes y más valiosos. Esto resultará en:

* Mayor tiempo de actividad y disponibilidad
* Tiempo medio de resolución reducido (MTTR)
* Volumen de alerta reducido
* La capacidad de identificar fácilmente alertas que no son valiosas, para que puedas convertirlas en valiosas o eliminarlas.

Esta guía lo guía a través del proceso de generación de la clave de indicadores de rendimiento que utilizará para medir el progreso hacia estas metas. Los KPI se miden en tiempo real, se publican en un dashboard y se utilizan para impulsar un proceso de mejora continua que utilizará para identificar y reducir las alertas molestas y aumentar la participación en la investigación de incidentes.

La práctica <DoNotTranslate>**alert quality management**</DoNotTranslate> no abarca la detección de anomalías ni AIOps, que están diseñados para detectar modos de falla desconocidos o inesperados. Las dos prácticas (AQM y ML/AI) funcionan de la mano, no son mutuamente excluyentes.

## Indicadores de rendimiento clave [#key-perf-indicators]

_Nota: Las versiones anteriores de esta guía de implementación se basaban en un evento personalizado (`NrAQMIncident`) generado por un webhook para recopilar los KPI necesarios. Esa dependencia ha cambiado. AQM ahora utiliza los tipos de eventos predeterminados `NrAiIncident` y `NrAiIssue` . Consulte la sección [de la guía de migración de AQM](#aqm-migration-guide) para obtener más detalles._

Utilizará el proceso AQM para recopilar y medir el volumen de incidentes y los KPI de participación.

[<DoNotTranslate>**Incident volume**</DoNotTranslate>](#kpi-incident-volume), que incluye:

* Recuento de incidentes
* Tiempo de incidente acumulado
* Hora media de cierre (MTTC)
* Porcentaje menos de 5 minutos

[<DoNotTranslate>**Incident engagement**</DoNotTranslate>](#kpi-incident-engagement), que incluye:

* Tiempo medio para investigar (MTTI)
* % de incidente investigado

Estos KPI te ayudarán a encontrar las alertas más ruidosas y menos valiosas para que puedas mejorar su valor o eliminarlas. Luego utilizará las tendencias métricas a largo plazo para mostrar el impacto real del negocio a la gerencia y a las partes interesadas.

A continuación se incluye información detallada sobre estas métricas.

### Volumen incidente [#kpi-incident-volume]

Debes tratar el incidente (con o sin alerta) como una cola de tareas. Al igual que una cola, el número de alertas debería pasar un tiempo cercano a cero. Cada incidente debe ser un desencadenante de una acción de investigación o correctiva para resolver la condición. Si una alerta no resulta en algún tipo de acción, entonces usted debe cuestionar el valor de la condición de alerta.

En particular, si ve incidentes específicos que están "siempre activos", entonces debería preguntarse por qué. ¿Se encuentra en un estado constante de impacto comercial o simplemente tiene un gran volumen de ruido? Los KPI de volumen de alerta le ayudan a responder esas preguntas y a medir el progreso hacia un estado saludable de alertas de alta calidad.

<CollapserGroup>
  <Collapser
    id="kpi-incident-count"
    title="KPI de recuento de incidentes"
  >
    El recuento de incidentes es el número de incidentes generados durante un período de tiempo. Normalmente deberías comparar la semana actual y la anterior.

    <DoNotTranslate>**Goal:**</DoNotTranslate> Reducir el número de incidentes molestos o de bajo valor.

    <DoNotTranslate>
      **Best practices:**
    </DoNotTranslate>

    * Asegúrese de que la configuración de las condiciones esté destinada a detectar el impacto real en el negocio.
    * Asegúrese de que la configuración de condiciones detecte un comportamiento anormal.
    * Comunique que la característica "Reconocer" de los detalles del incidente ayuda a medir alertas significativas y procesables. Ver [KPI de reconocimiento de incidentes porcentuales](#kpi-user-engagement).
    * Informar los KPI de AQM a todas las partes interesadas.
  </Collapser>

  <Collapser
    id="kpi-incident-duration"
    title="KPI de duración acumulada del incidente"
  >
    La duración acumulada del incidente es la suma total de minutos que todos los incidentes han acumulado durante un período de tiempo. Normalmente deberías comparar la semana actual y la anterior.

    <DoNotTranslate>**Goal:**</DoNotTranslate> Reducir el total de minutos acumulados de incidente.

    <DoNotTranslate>
      **Best practices:**
    </DoNotTranslate>

    * No cerrar manualmente incidentes que no motiven algún tipo de acción investigativa. El cierre manual distorsionará la duración real del incidente.
    * Eliminar alertas que no resulten en acciones correctivas por parte de los destinatarios.
    * Mejore los KPI del porcentaje investigado y del tiempo medio de investigación comunicando su importancia para mejorar la detección y el tiempo de respuesta.
    * Informar los KPI de AQM a todas las partes interesadas.
  </Collapser>

  <Collapser
    id="kpi-mttc"
    title="KPI de tiempo medio de cierre (MTTC)"
  >
    Duración media del incidente dentro del periodo de tiempo medido.

    <DoNotTranslate>**Goal:**</DoNotTranslate> Reducir el MTTC

    <DoNotTranslate>
      **Best practices:**
    </DoNotTranslate>

    * No cierre el incidente manualmente. El cierre manual distorsionará la duración real del incidente.
    * Mejorar las habilidades de ingeniería de confiabilidad.
    * Informar los KPI de AQM a todas las partes interesadas.
  </Collapser>

  <Collapser
    id="kpi-pct-under-five"
    title="Porcentaje de KPI de menos de 5 minutos"
  >
    Porcentaje de incidentes cuya duración es inferior a cinco minutos. Esto puede ser un indicador de oscilaciones incidentes.

    <DoNotTranslate>**Goal:**</DoNotTranslate> Minimizar porcentaje de incidencia con duraciones cortas.

    <DoNotTranslate>
      **Best practices:**
    </DoNotTranslate>

    * Asegúrese de que las condiciones detecten una desviación legítima del comportamiento esperado.
    * Comprender la administración a nivel de servicio.
    * Asegúrese de que las condiciones detecten desviación legítima que se correlacione con el impacto comercial o el impacto comercial inminente.
  </Collapser>
</CollapserGroup>

### Participación del usuario [#kpi-user-engagement]

Debes medir el valor de un incidente por la cantidad de atención que recibe. Aquí, medimos el compromiso en función de si se ha reconocido o no un incidente.

La cantidad de participación que recibe una alerta individual es una medida directa de su valor. Una mayor participación implica una alerta valiosa. Una participación menor (o nula) implica una alerta molesta que debe modificarse o desactivarse.

Existe una diferencia significativa entre medir el momento en que se toma conciencia del incidente y reconocer el momento en que comienza la actividad de resolución. Si está utilizando una integración con New Relic alerta, asegúrese de que el evento de "reconocimiento" que se envía a New Relic se active cuando comience la actividad de resolución, no cuando el incidente se envíe a la herramienta externa de gestión de incidentes.

Para obtener más información sobre los procesos estándar de gestión de incidentes, consulte "[Proceso de gestión de incidentes: 5 pasos para una resolución efectiva, publicado el 31 de agosto de 2020 por OnPage Corporation](https://www.onpage.com/incident-management-process-5-steps-to-effective-resolution) en referencia a [ITIL4](https://itsm.tools/its-here-itil-4-explained)".

<CollapserGroup>
  <Collapser
    id="kpi-pct-ack"
    title="KPI porcentual reconocido"
  >
    El incidente reconocido identifica el porcentaje de incidentes con los que se ha interactuado al tener su indicador de reconocimiento establecido en verdadero. Normalmente deberías comparar la semana actual y la anterior.

    <DoNotTranslate>**Goal:**</DoNotTranslate> Incrementar el porcentaje de participación en incidentes.

    <DoNotTranslate>
      **Best practices:**
    </DoNotTranslate>

    * Eduque al equipo de DevOps sobre cuándo es apropiado reconocer una alerta de incidente.
    * Reconocimiento de alerta de Gamify para impulsar el uso.
    * Desalentar los ejercicios de reconocimiento masivo.
  </Collapser>

  <Collapser
    id="kpi-mtti"
    title="Tiempo medio para investigar (MTTI) KPI"
  >
    El tiempo medio para investigar identifica el tiempo promedio que lleva reconocer un incidente. Normalmente deberías comparar la semana actual y la anterior.

    <DoNotTranslate>**Goal:**</DoNotTranslate> Reducir el tiempo medio de investigación.

    <DoNotTranslate>
      **Best practices:**
    </DoNotTranslate>

    * Trabaje para desarrollar la confianza del personal de respuesta a incidentes en Alerta.
    * Asegúrese de que se reconozcan las alertas valiosas.
    * Incentivar a los equipos de respuesta para que respondan rápidamente a la alerta.
  </Collapser>
</CollapserGroup>

## Requisitos previos [#prerequisites]

Antes de comenzar, si no tiene experiencia equivalente, complete el [curso general de New Relic University (NRU)](https://learn.newrelic.com/overview-course).

Además, debes tener al menos un conocimiento básico de:

* New Relic política de alertas y configuración de condiciones

* NRQL (nuestro lenguaje de consulta)

* Nuestras mejores prácticas de alertas

* New Relic

  <InlinePopover type="apm"/>

  y monitoreo de infraestructura

* Cómo línea de base de datos para determinar anomalía versus comportamiento normal

## Establecer el estado actual [#current-state]

Como ocurre con cualquier proceso de mejora continua, el primer paso de AQM es establecer el estado actual de sus KPI. Para ello, realice las siguientes tareas:

* [Instalar el dashboardde AQM](#install-dashboard)
* [Analizar KPI de volumen de eventos](#analyze-event-volume)
* [Realizar orientación y habilitación inicial de AQM.](#perform-enablement-one)
* [Acumular datos de participación](#accumulate-data)
* [Realizar segunda sesión de habilitación.](#perform-enablement-two)

_Nota: Las versiones anteriores de esta guía de implementación se basaban en un evento personalizado (`nrAQMIncident`) generado por un webhook para recopilar los KPI necesarios. Esa dependencia ha cambiado. AQM ahora utiliza los tipos de eventos predeterminados `NrAiIncident` y `NrAiIssue` . Consulte la sección [de la guía de migración de AQM](#aqm-migration-guide) para obtener más detalles._

### Instalar el dashboardde AQM [#install-dashboard]

El dashboard de AQM es el activo principal que impulsa el proceso de AQM. Debe instalar el dashboard de AQM desde nuestra biblioteca de inicio rápido haciendo lo siguiente:

1. [Vaya a la página de observabilidad instantánea ](https://newrelic.com/instant-observability/alert-quality-management)

   <DoNotTranslate>[**Alert Quality Management**](https://newrelic.com/instant-observability/alert-quality-management)</DoNotTranslate>

   [ .](https://newrelic.com/instant-observability/alert-quality-management)

2. Haga clic en el botón

   <DoNotTranslate>**Install now**</DoNotTranslate>

   .

3. Siga el símbolo para elegir la cuenta en la que desea instalar el dashboard .

4. Vea su dashboard.

La definición dashboard JSON también está disponible en el [centro de recursos de madurez de observabilidad en GitHub.](https://github.com/newrelic/oma-resource-center/tree/main/src/content/docs/oma/value-drivers/uptime-performance-and-reliability/use-cases/alert-quality-management). Esta versión es idéntica a la que se encuentra en los inicios rápidos. Si va a utilizar la versión de GitHub, haga lo siguiente:

1. Actualice la propiedad

   <DoNotTranslate>**accountId**</DoNotTranslate>

   para reflejar el ID de la cuenta a la que está importando el dashboard . Hay 13 instancias de esa propiedad que deben actualizarse desde 0000000 al ID de cuenta correcto.

2. Importe la definición a su cuenta.

Para obtener más detalles sobre la importación del panel, consulte [Introducción al panel](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/#dashboards-import).

### Analizar KPI de volumen de eventos [#analyze-event-volume]

Una vez instalado el dashboard , puede usarlo inmediatamente para analizar los cuatro KPI del volumen de eventos.

Utilice el panel <DoNotTranslate>**Alerting Count by Policy**</DoNotTranslate> en el dashboard para buscar políticas que generen un alto número de incidentes, duraciones acumuladas altas de incidentes, cierres largos de MTT o un alto porcentaje de incidentes abiertos durante menos de 5 minutos. En particular, debe identificar políticas:

* Que generan incidentes "siempre activos" (es decir, incidente con miles de minutos o más de duración acumulada).
* Cuando el 30% o más de las incidencias estén abiertas por menos de 5 minutos.
* Cuyo cierre del MTT sea superior a 30 minutos.
* Eso genera más de 350 incidentes por semana.

Debe identificar las cuatro políticas principales que se ajustan a uno o más de esos criterios, revisar las condiciones de la política y observar los detalles del incidente resultante para determinar patrones. Luego debe asegurarse de que los equipos que crearon esas políticas y los equipos que responden al incidente de esas políticas participen en el proceso de habilitación de AQM.

### Realizar orientación y habilitación inicial de AQM. [#perform-enablement-one]

Durante esta fase, su(s) equipo(s) de gestión de incidentes y otras partes interesadas aprenderán los objetivos del proceso AQM, el alcance de su participación en él y participarán en una revisión inicial de las políticas que identificó en el paso [de análisis del volumen de eventos](#analyze-event-volume) .

Puede utilizar la [plantilla de presentación de la primera sesión](https://docs.google.com/presentation/d/1TBK_4AJ_YdDNddjy5R82soyOnK81JsLmmg3qTeFHGW8/edit?usp=sharing) para comunicar este material a sus partes interesadas.

El dashboard de AQM le proporcionará una línea de base inicial de sus KPI de volumen de incidentes que debe utilizar como punto de partida para el proceso de mejora continua. Además, debe hablar con los equipos adecuados sobre las formas de cambiar las cuatro políticas de incidentes más ruidosas para que sean más valiosas. Al revisar las políticas ruidosas, debe hacer las siguientes preguntas sobre cada política en el siguiente orden:

1. ¿La alerta nos dice algo sobre un recurso que necesita ser reparado? Si es así, solucione el problema y vea si el volumen de alerta disminuye.
2. ¿La alerta nos está informando sobre algo que realmente requiere una respuesta inmediata? De lo contrario, ajuste o desactive la política.
3. ¿Se han establecido correctamente los umbrales de política? De lo contrario, considere ajustar el umbral.

Una de las partes más importantes de esta tarea es educar a su equipo sobre la importancia de reconocer las alertas de incidentes, porque así es como se determina el valor de una alerta. En general, indíqueles que sigan estas pautas:

* Si observa una alerta y decide tomar algún tipo de acción de investigación adicional, reconozca la alerta.
* Si normalmente cierra una alerta sin hacer nada más, no reconozca la alerta.
* Si la alerta de incidente está siempre activa, no la cierre ni la reconozca. Para obtener más detalles, consulte [Segunda sesión de habilitación](#perform-enablement-two).

### Acumular datos de participación [#accumulate-data]

El proceso de medir la participación de alerta requiere al menos dos semanas de datos antes de poder continuar. Durante este tiempo, debe verificar periódicamente si el personal de respuesta a incidentes sigue las pautas de reconocimiento de alerta descritas en la [primera sesión de habilitación](#perform-enablement-one).

### Realizar segunda sesión de habilitación. [#perform-enablement-two]

Debes realizar la segunda sesión de habilitación dos semanas después de la primera. Durante esta fase, presentará a los equipos de gestión de incidentes y a otras partes interesadas los datos de tendencias de AQM y el proceso de mejora continua que seguirá.

El proceso consta de cuatro actividades:

1. Revise dashboard de AQM y las tendencias de KPI: aquí usted y las partes interesadas observarán los KPI de AQM e identificarán sus tendencias semanales. El equipo debe identificar áreas donde los KPI no mejoran y desarrollar estrategias para impulsar la mejora.
2. Identifique logros, desafíos y oportunidades: aquí usted y las partes interesadas mapearán el estado actual de la calidad de Alerta con el impacto comercial, identificando áreas donde la mejora ha resultado en mejores resultados comerciales y áreas donde los problemas están impactando los resultados comerciales.
3. Revisión de políticas de incidentes: utilizando el dashboard de AQM, usted y las partes interesadas identificarán las políticas de incidentes más ruidosas. Una vez identificadas, esas políticas deben evaluarse como se detalla en el paso 4 a continuación.
4. Recomendaciones de política de alertas: En este paso, usted y las partes interesadas revisarán las políticas más ruidosas utilizando los siguientes criterios:

* ¿La alerta tiene algún impacto empresarial?

* ¿Están las políticas configuradas correctamente?

  * ¿Nos están diciendo algo sobre el recurso que necesita ser arreglado?
  * ¿Son necesarias las políticas? ¿Tienen impacto empresarial?
  * ¿Están configurados correctamente los umbrales?

5. Recomendaciones técnicas: aquí, usted y las partes interesadas revisarán cualquier recomendación técnica, que incluye:

   * ¿Hay problemas de aplicación/sistema que los ingenieros deben revisar?
   * ¿Hay políticas mal diseñadas que deben corregirse?
   * ¿Existen lagunas de instrumentación?

Puede utilizar la [plantilla de presentación de la segunda sesión](https://docs.google.com/presentation/d/1d8QN2rELwFDNieYPJrD2axhLvAs_wKb6xMI1UtoTvmo/edit?usp=sharing) para mantener organizada esta parte del proceso de AQM.

Durante esta fase, también debe aprovechar la oportunidad para mostrar el valor de AQM revisando las cuatro políticas más ruidosas que identificó en la [primera sesión de habilitación](#perform-enablement-one) y destacando cómo han mejorado sus KPI.

## Proceso de mejora [#improvement-process]

Esta es la fase continua del proceso de mejora continua en la que revisa periódicamente sus datos AQM acumulados y realiza los ajustes necesarios a la política de alertas. Debe realizar este paso semanalmente o quincenalmente hasta que el volumen de alerta sea aceptable. Luego podrá realizarlo con menos frecuencia.

Durante esta fase debes:

* Informe sus KPI cada semana a la alta dirección para garantizar que los equipos de partes interesadas prioricen adecuadamente el trabajo y muestren el progreso hacia los resultados comerciales prometidos.
* Registre y conserve sus KPI semanales durante períodos de meses a años para establecer una línea de base y mostrar la tasa de mejora.

Debes tener en cuenta que este es un proceso de mejora continua. Continuará recopilando y evaluando los KPI durante largos períodos de tiempo para asegurarse de cumplir con sus objetivos de AQM.

## Realización de valor [#value-realization]

Una vez que se establezca el proceso AQM, verá reducciones significativas en el volumen de alertas mientras que la confiabilidad y la estabilidad seguirán siendo las mismas o mejorarán. Además, debes asegurarte de que tu alerta tenga un impacto empresarial claro e inequívoco. Sus KPI de AQM proporcionarán pruebas cuantificables de estas mejoras.

Este proceso también debería ayudar a los creadores de alertas a comprender mejor el impacto que la nueva política de alertas tiene en los socorristas y ayudar a los creadores de alertas a crear una política de alertas más significativa.

Una vez que esté firmemente encaminado hacia el cumplimiento de los objetivos de AQM, considere pasar a otros casos de uso dentro del flujo de valor <DoNotTranslate>**Uptime, performance, and reliability**</DoNotTranslate> , como [administración a nivel de servicio](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide) o ingeniería de confiabilidad. También puede pasar a otros flujos de valor de madurez de observabilidad, como [la experiencia de los clientes](/docs/new-relic-solutions/observability-maturity/customer-experience/quality-foundation-implementation-guide).

## Referencia de KPI [#kpi-reference]

A continuación se muestran las descripciones de cada KPI, así como un ejemplo de consulta NRQL que los extraerá de la plataforma New Relic. Estos KPI también se incluyen en el dashboard de AQM que se puede descargar desde nuestro [centro de recursos de madurez de observabilidad en GitHub.](https://github.com/newrelic/oma-resource-center/tree/main/src/content/docs/oma/value-drivers/uptime-performance-and-reliability/use-cases/alert-quality-management)

### Volumen incidente

<CollapserGroup>
  <Collapser
    id="kpi-incident-count-query"
    title="KPI de recuento de incidentes"
  >
    El recuento de incidentes es el número de incidentes generados durante un período de tiempo. Normalmente deberías comparar la semana actual y la anterior.

    ```sql
    FROM NrAiIncident SELECT count(*) AS 'Incident Count' WHERE event = 'open' AND priority = 'critical' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO
    ```
  </Collapser>

  <Collapser
    id="kpi-incident-duration-query"
    title="KPI de duración acumulada del incidente"
  >
    La duración acumulada del incidente es la suma total de minutos que acumularon todos los incidentes durante un período de tiempo. Normalmente deberías comparar la semana actual y la anterior.

    ```sql
    FROM NrAiIncident SELECT sum(durationSeconds)/60 AS 'Incident Minutes' WHERE event = 'close' AND priority = 'critical' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO
    ```
  </Collapser>

  <Collapser
    id="kpi-mttc-query"
    title="KPI de tiempo medio de cierre (MTTC)"
  >
    Duración media del incidente dentro del periodo de tiempo medido.

    ```sql
    FROM NrAiIncident SELECT average(durationSeconds/60) AS 'Incident MTTC (minutes)' WHERE event = 'close' AND priority = 'critical' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO
    ```
  </Collapser>

  <Collapser
    id="kpi-pct-under-five-query"
    title="Porcentaje de KPI de menos de 5 minutos"
  >
    Porcentaje de incidentes cuya duración es inferior a cinco minutos. Esto puede ser un indicador de oscilaciones incidentes.

    ```sql
    FROM NrAiIncident SELECT percentage(count(*), WHERE durationSeconds <= 5*60) AS '% Under 5min' WHERE event = 'close' AND priority = 'critical' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO 
    ```
  </Collapser>
</CollapserGroup>

### Compromiso de incidente

<Callout
  variant="IMPORTANT"
  title="Reconociendo alerta"
>
  Para que los KPI de participación sean significativos, es necesario [reconocer el incidente](/docs/alerts-applied-intelligence/new-relic-alerts/alert-incidents/acknowledge-alert-incidents/) ya sea en la UI o mediante una API. A menudo, en un entorno de prueba esto no se hace. Eso puede provocar que no se devuelvan datos válidos. Si las alertas críticas no se reconocen o rara vez se reconocen en un entorno de producción, esto puede ser una señal de alerta de bajo valor, alerta de "oscilaciones" o alerta que no están bien dirigidas al ingeniero correcto.
</Callout>

<CollapserGroup>
  <Collapser
    id="kpi-pct-ack-query"
    title="KPI porcentual reconocido"
  >
    Incidente reconocido identifica el porcentaje de incidentes con los que se ha interactuado y cuya propiedad reconocida se ha establecido en verdadera. Normalmente deberías comparar la semana actual y la anterior.

    ```sql
    FROM NrAiIssue SELECT filter(count(*), WHERE event='acknowledge')/filter(count(*), WHERE event='create')*100 AS '% Investigated' WHERE priority='CRITICAL' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO
    ```
  </Collapser>

  <Collapser
    id="kpi-mtti-query"
    title="Tiempo medio para investigar (MTTI) KPI"
  >
    El tiempo medio para investigar identifica el tiempo promedio que lleva clasificar un incidente. Normalmente deberías comparar la semana actual y la anterior.

    ```sql
    FROM NrAiIssue SELECT average(acknowledgeTime - activateTime) / 60000 AS 'Incident MTTI (minutes)' WHERE event = 'acknowledge' SINCE 1 WEEK AGO COMPARE WITH 1 WEEK AGO
    ```
  </Collapser>
</CollapserGroup>

## Recursos adicionales

¿Quiere ensuciarse las manos antes de empezar a implementar esto en su cuenta? Consulte el [laboratorio de gestión de calidad de alerta](https://learn.newrelic.com/hands-on-lab-alert-quality-management)

## Guía de migración de AQM [#aqm-migration-guide]

La versión original de AQM aprovechó un evento personalizado llamado nrAQMIncident para impulsar el proceso. El evento nrAQMIncident fue generado por un webhook asociado con cada política de alertas en la cuenta y generó KPI de volumen de incidentes y participación.

La versión actual de AQM utiliza dos eventos predeterminados, `NrAiIncident` y `NrAiIssue`, que se generan automáticamente.

El método de webhook legacy utilizado en la versión original de AQM quedará obsoleto en enero de 2023. Debe realizar la transición a la nueva metodología antes de ese momento. Si su organización está adoptando AQM por primera vez, debe utilizar la nueva metodología basada en `NrAiIncident`.

Al realizar la transición, debe tener en cuenta lo siguiente:

* Su dashboard de AQM existente deberá reemplazarse por el nuevo dashboard de AQM que utiliza el evento `NrAiIncident` / `NrAiIssue`.
* Estos eventos son necesarios para generar los KPI del volumen de incidentes y los KPI de participación en incidentes.
* A medida que realiza la transición de `nrAQMIncident` a `NrAiIncident`, sus números de KPI cambiarán sustancialmente. Esto se debe a que el evento `NrAiIncident` rastrea el número de veces que se ha producido un incidente de umbral, mientras que el evento `nrAQMIncident` rastrea la notificación de alerta. Si bien las cifras han cambiado, las relaciones subyacentes con los KPI y los valores relativos entre ellos no. Deberá educar a los participantes de AQM sobre esto para reducir los riesgos de confusión.

Una vez que se complete la transición, puede desactivar o eliminar el webhook de AQM y el dashboard anterior.