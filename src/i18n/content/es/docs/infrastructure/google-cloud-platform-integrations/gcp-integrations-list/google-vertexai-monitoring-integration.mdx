---
title: Integración de monitoreo de Google VertexAI
tags:
  - Integrations
  - Google Cloud Platform integrations
  - GCP integrations list
metaDescription: 'New Relic Google VertexAI integration: the data it reports and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

[La integración de New Relic](/docs/infrastructure/introduction-infra-monitoring) incluye una integración para informar sus datos de ejecución de GCP a nuestros productos. Aquí explicamos cómo activar la integración y qué datos recopila.

## Activar la integración [#activate]

Para habilitar la integración, siga los procedimientos estándar para [conectar su servicio GCP a New Relic](/docs/connect-google-cloud-platform-services-infrastructure).

## Configuración y sondeo [#polling]

Puede cambiar la frecuencia de sondeo y filtrar datos usando [las opciones de configuración](/docs/integrations/new-relic-integrations/getting-started/configure-polling-frequency-data-collection-cloud-integrations).

Información [de sondeo](/docs/integrations/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations) predeterminada para la integración de GCP Run:

* New Relic intervalo de sondeo: 5 minutos

## Buscar y utilizar datos [#find-data]

Para encontrar sus datos de integración, vaya a <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Infrastructure &amp;gt; GCP**</DNT> y seleccione una integración.

Los datos se adjuntan a los siguientes [tipos de eventos](/docs/data-apis/understand-data/new-relic-data-types/#event-data):

<table>
  <thead>
    <tr>
      <th>
        Entidad
      </th>

      <th>
        Tipo de evento
      </th>

      <th>
        Proveedor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Extremo
      </td>

      <td>
        `GcpVertexAiEndpointSample`
      </td>

      <td>
        `GcpVertexAiEndpoint`
      </td>
    </tr>

    <tr>
      <td>
        Tienda caracteristica
      </td>

      <td>
        `GcpVertexAiFeaturestoreSample`
      </td>

      <td>
        `GcpVertexAiFeaturestore`
      </td>
    </tr>

    <tr>
      <td>
        Tienda característica online
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStoreSample`
      </td>

      <td>
        `GcpVertexAiFeatureOnlineStore`
      </td>
    </tr>

    <tr>
      <td>
        Ubicación
      </td>

      <td>
        `GcpVertexAiLocationSample`
      </td>

      <td>
        `GcpVertexAiLocation`
      </td>
    </tr>

    <tr>
      <td>
        Índice
      </td>

      <td>
        `GcpVertexAiIndexSample`
      </td>

      <td>
        `GcpVertexAiIndex`
      </td>
    </tr>

    <tr>
      <td>
        PipelineJob
      </td>

      <td>
        `GcpVertexAiPipelineJobSample`
      </td>

      <td>
        `GcpVertexAiPipelineJob`
      </td>
    </tr>
  </tbody>
</table>

Para obtener más información sobre cómo utilizar sus datos, consulte [Comprender y utilizar los datos de integración](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Datos métricos [#metrics]

Esta integración recopila datos de GCP para VertexAI.

### Datos extremos de VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `prediction.online.accelerator.duty_cycle`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Fracción de tiempo promedio durante el último periodo de muestra durante el cual los aceleradores estuvieron procesando activamente.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.accelerator.memory.bytes_used`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Cantidad de memoria aceleradora asignada por la réplica del modelo de despliegue.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.error_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de errores de predicción en línea.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.memory.bytes_used`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Cantidad de memoria asignada por la réplica del modelo de despliegue y actualmente en uso.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.received_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Número de bytes recibidos a través de la red por la réplica del modelo de desplegar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.network.sent_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Número de bytes enviados a través de la red por la réplica del modelo de desplegar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de predicciones en línea.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.prediction_latencies`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        Latencia de predicción online del modelo desplegar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.private.prediction_latencies`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        Latencia de predicción online del modelo privado desplegar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.replicas`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de réplicas activas empleadas por el modelo desplegar.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.response_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de códigos de respuesta de predicción en línea diferentes.
      </td>
    </tr>

    <tr>
      <td>
        `prediction.online.target_replicas`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número objetivo de réplicas activas necesarias para el modelo de despliegue.
      </td>
    </tr>
  </tbody>
</table>

### Datos de VertexAI Featurestore

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featurestore.cpu_load`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        La carga promedio de CPU para un nodo en el almacenamiento en línea de Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.cpu_load_hottest_node`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        La carga de CPU para el nodo más activo en el almacenamiento en línea de Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.node_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        La cantidad de nodos para el almacenamiento en línea de Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_entities_updated`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de entidad actualizada en el almacenamiento en línea de Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.latencies`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        Latencia de servicio online por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Tamaño de la solicitud por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.request_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Recuento de servicios en línea de Featurestore por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.online_serving.response_size`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Tamaño de respuesta por EntityType.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.billable_processed_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Número de bytes facturados por datos fuera de línea procesados.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.storage.stored_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Bytes almacenados en Featurestore.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_processed_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de solicitudes de escritura en streaming procesadas para almacenamiento sin conexión.
      </td>
    </tr>

    <tr>
      <td>
        `featurestore.streaming_write.offline_write_delays`
      </td>

      <td>
        Segundos
      </td>

      <td>
        Tiempo (en segundos) desde que se llama a la API de escritura hasta que se escribe en el almacenamiento fuera de línea.
      </td>
    </tr>
  </tbody>
</table>

### Datos de VertexAI FeatureOnlineStore

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `featureonlinestore.online_serving.request_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de recuento de porciones por FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_bytes_count`
      </td>

      <td>
        Bytes
      </td>

      <td>
        Tamaño de respuesta de publicación por FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.online_serving.serving_latencies`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        Latencia de servicio en línea mediante FeatureView.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.running_sync`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        Número de sincronizaciones en ejecución en un momento determinado.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_ages`
      </td>

      <td>
        Segundos
      </td>

      <td>
        Medida de la antigüedad de los datos de servicio en segundos.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.serving_data_by_sync_time`
      </td>

      <td>
        Contar
      </td>

      <td>
        Desglose de datos en Feature Online Store por timestamp sincronizada.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        La carga promedio de CPU de los nodos en Feature Online Store.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_cpu_load_hottest_node`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        La carga de CPU del nodo más caliente en Feature Online Store.
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.bigtable_nodes`
      </td>

      <td>
        Contar
      </td>

      <td>
        El número de nodos de Feature Online Store(Bigtable).
      </td>
    </tr>

    <tr>
      <td>
        `featureonlinestore.storage.stored_bytes`
      </td>

      <td>
        Contar
      </td>

      <td>
        Bytes almacenados en Feature Online Store.
      </td>
    </tr>
  </tbody>
</table>

### Datos de ubicación de VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `online_prediction_requests_per_base_model`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de solicitudes por modelo base.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.exceeded`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de intentos de superar el límite de la métrica de cuota.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.limit`
      </td>

      <td>
        Contar
      </td>

      <td>
        Límite actual de la métrica de cuota.
      </td>
    </tr>

    <tr>
      <td>
        `quota.online_prediction_requests_per_base_model.usage`
      </td>

      <td>
        Contar
      </td>

      <td>
        Uso actual en la métrica de cuota.
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_jobs`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de trabajos de canalización que se ejecutan.
      </td>
    </tr>

    <tr>
      <td>
        `executing_vertexai_pipeline_tasks`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de tareas de canalización que se ejecutan.
      </td>
    </tr>
  </tbody>
</table>

### Datos del índice VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `matching_engine.stream_update.datapoint_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de puntos de datos insertados o eliminados correctamente.
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.latencies`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        La latencia entre el usuario recibe una UpsertDatapointsResponse o RemoveDatapointsResponse y esa actualización surte efecto.
      </td>
    </tr>

    <tr>
      <td>
        `matching_engine.stream_update.request_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número de solicitudes de actualización de flujo.
      </td>
    </tr>
  </tbody>
</table>

### Datos del trabajo de pipeline de VertexAI

<table>
  <thead>
    <tr>
      <th>
        Métrica
      </th>

      <th>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `pipelinejob.duration`
      </td>

      <td>
        Segundos
      </td>

      <td>
        Segundos de tiempo de ejecución del trabajo de canalización que se ejecuta (desde la creación hasta el final).
      </td>
    </tr>

    <tr>
      <td>
        `pipelinejob/task_completed_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        Número total de tareas de canalización completadas.
      </td>
    </tr>
  </tbody>
</table>