---
title: Integración con Confluent cloud
tags:
  - Integrations
  - Confluent cloud integrations
  - Apache Kafka
metaDescription: ' New Relic''s Confluent cloud integration for Kafka: what data it reports, and how to enable it.'
freshnessValidatedDate: never
translationType: machine
---

New Relic ofrece una integración para recopilar sus datos [de transmisión gestionados por Confluent Cloud para Apache Kafka](https://www.confluent.io/confluent-cloud/) . Este documento explica cómo activar esta integración y describe los datos que se pueden informar.

## Requisitos previos

* Una cuenta de New Relic
* Una cuenta activa de Confluent Cloud
* Una clave de API y un secreto de Confluent Cloud
* `MetricsViewer` acceso a la cuenta de Confluent Cloud

## Activar la integración [#activate]

Para habilitar esta integración, vaya a <DNT>**Integrations &amp; Agents**</DNT>, seleccione <DNT>**Confluent Cloud -&gt; API Polling**</DNT> y siga las instrucciones.

<Callout variant="important">
  Si tiene configurado el filtrado de IP, agregue las siguientes direcciones IP a su filtro.

  * `162.247.240.0/22`
  * `152.38.128.0/19`

  Para obtener más información sobre los rangos de IP de New Relic para la integración en la nube, consulte [este documento](/docs/new-relic-solutions/get-started/networks/#webhooks). Para obtener instrucciones sobre cómo realizar esta tarea, consulte [este documento](https://docs.confluent.io/cloud/current/security/access-control/ip-filtering/manage-ip-filters.html).
</Callout>

## Configuración y sondeo [#polling]

Información de sondeo predeterminada para la integración de Confluent Cloud Kafka:

* New Relic intervalo de sondeo: 5 minutos
* Intervalo de datos de Confluent Cloud: 1 minuto

Puede cambiar la frecuencia de sondeo solo durante la configuración inicial.

## Ver y usar datos [#find-data]

Para ver sus datos de integración, vaya a <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &amp;gt; Infrastructure &amp;gt; AWS**</DNT> y seleccione una integración.

Puede [consultar y explorar sus datos](/docs/using-new-relic/data/understand-data/query-new-relic-data) empleando el siguiente [tipo de evento](/docs/data-apis/understand-data/new-relic-data-types/#metrics-in-service-levels):

<table>
  <thead>
    <tr>
      <th>
        Entidad
      </th>

      <th>
        Tipo de datos
      </th>

      <th>
        Proveedor
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Grupo
      </td>

      <td>
        `Metric`
      </td>

      <td>
        `Confluent`
      </td>
    </tr>
  </tbody>
</table>

Para obtener más información sobre cómo utilizar sus datos, consulte [Comprender y utilizar los datos de integración](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Datos métricos [#metrics]

Esta integración registra datos de Amazon Managed Kafka para clúster, partición y entidad temática.

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Métrica
      </th>

      <th style={{ width: "150px" }}>
        Unidad
      </th>

      <th>
        Descripción
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `cluster_load_percent`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Una medida de la utilización del clúster. El valor está entre 0,0 y 1,0. Sólo el nivel clúster dedicado tiene estos datos métricos.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_ingress`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Un indicador de la presencia de una partición caliente causada por el rendimiento de entrada. El valor es 1.0 cuando se detecta una partición activa y está vacío cuando no se detecta ninguna partición activa.
      </td>
    </tr>

    <tr>
      <td>
        `hot_partition_egress`
      </td>

      <td>
        Por ciento
      </td>

      <td>
        Un indicador de la presencia de una partición caliente causada por el rendimiento de salida. El valor es 1.0 cuando se detecta una partición activa y está vacío cuando no se detecta ninguna partición activa.
      </td>
    </tr>

    <tr>
      <td>
        `request_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta del total de bytes de solicitud de los tipos de solicitud especificados enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `response_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta del total de bytes de respuesta de los tipos de respuesta especificados enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se muestrea cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta de bytes de los datos de los clientes recibidos de la red. Cada muestra es el número de bytes recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_bytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        El recuento delta de bytes de los datos de los clientes enviados a través de la red. Cada muestra es el número de bytes enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `received_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de registros recibidos. Cada muestra es el número de registros recibidos desde la muestra de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `sent_records`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de registros enviados. Cada muestra es el número de registros enviados desde el punto de datos anterior. El recuento se realiza cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `partition_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El número de particiones.
      </td>
    </tr>

    <tr>
      <td>
        `consumer_lag_offsets`
      </td>

      <td>
        Milisegundos
      </td>

      <td>
        El retraso entre el desplazamiento comprometido de un miembro del grupo y la marca de límite superior de la partición.
      </td>
    </tr>

    <tr>
      <td>
        `successful_authentication_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento delta de autenticaciones exitosas. Cada muestra es el número de autenticaciones exitosas desde el punto de datos anterior. El recuento se realizó cada 60 segundos.
      </td>
    </tr>

    <tr>
      <td>
        `active_connection_count`
      </td>

      <td>
        Contar
      </td>

      <td>
        El recuento de conexiones autenticadas activas.
      </td>
    </tr>
  </tbody>
</table>