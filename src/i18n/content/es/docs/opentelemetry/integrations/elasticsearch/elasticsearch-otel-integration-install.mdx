---
title: Instale la integración de OpenTelemetry de Elasticsearch
tags:
  - OpenTelemetry
  - Elasticsearch
  - Integrations
metaDescription: Install and configure the OpenTelemetry Collector to monitor Elasticsearch clusters and send data to New Relic.
freshnessValidatedDate: never
translationType: machine
---

Instale la integración de New Relic Elasticsearch OpenTelemetry para monitorear sus clústeres de Elasticsearch con protocolos estándar de la industria. Esta guía lo guiará a través de la configuración del OpenTelemetry Collector para recopilar métricas y logs de su infraestructura de Elasticsearch y enviarlos a New Relic.

Para instalar la integración, complete los siguientes pasos:

1. [Antes de comenzar](#prerequisites) - Verifique los requisitos y prerrequisitos
2. [Configurar el OpenTelemetry Collector](#config) - Configurar la recopilación de datos
3. [Establecer variables de entorno](#start) - Configurar la autenticación
4. [Encontrar y usar datos](#find-and-use) - Vea sus datos de Elasticsearch en New Relic
5. [Configurar alertas](#alerts) - Configurar la supervisión proactiva

## Paso 1: Antes de comenzar [#prerequisites]

Asegúrese de tener:

* **Privilegios de acceso requeridos** - Privilegios de administrador del clúster de Elasticsearch y cuenta de New Relic con acceso<InlinePopover type="licenseKey" />

* **Versión 7.16 o superior de Elasticsearch** - Esta integración requiere un clúster moderno de Elasticsearch

* **Supervisar o administrar los privilegios del clúster** - Si la seguridad está habilitada, necesita el privilegio de supervisar o administrar el clúster. Consulte la documentación de [privilegios de seguridad de Elasticsearch](https://www.elastic.co/docs/reference/elasticsearch/security-privileges) para obtener más detalles

* **Conectividad de red** - Conectividad HTTPS saliente (puerto 443) al [punto de ingestión OTLP de New Relic](/docs/opentelemetry/best-practices/opentelemetry-otlp)

* **OpenTelemetry Collector** - [OpenTelemetry Collector Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/latest) instalado y en ejecución en su host. Instale a través de un paquete oficial (.deb o .rpm) para asegurar que la unidad de servicio systemd se cree correctamente

* **Valores de configuración listos** - Necesitará dos valores clave para la configuración:

  * **Endpoint de Elasticsearch** - Su URL real de Elasticsearch (reemplace `https://localhost:9200`)
  * **Nombre del clúster** - Un nombre único para identificar su clúster en New Relic

## Paso 2: Configura el OpenTelemetry Collector [#config]

Configure el OpenTelemetry Collector para recopilar métricas y logs de su clúster de Elasticsearch. Cree o actualice su archivo de configuración en `/etc/otelcol-contrib/config.yaml`.

La configuración varía según su configuración de Elasticsearch y los requisitos de monitoreo. Elija la configuración adecuada a continuación:

<CollapserGroup>
  <Collapser id="basic-config" title="Configuración básica de métricas">
    **Comience aquí si tiene:** Un clúster de Elasticsearch no seguro sin autenticación ni SSL.

    Esta configuración recopila métricas completas de Elasticsearch y el sistema host sin autenticación:

    <Callout variant="important">
      Reemplace el valor `endpoint` con el endpoint de su clúster de Elasticsearch y actualice `elasticsearch.cluster.name` en el bloque del procesador con un nombre único para identificar de forma única su clúster en New Relic.
    </Callout>

    ```yaml
    # =================================================================================================
    # OpenTelemetry Collector Configuration for Elasticsearch and Host
    # This configuration collects metrics and logs for a complete observability solution.
    # =================================================================================================
    # -------------------------------------------------------------------------------------------------
    # Receivers
    # Receivers define how data gets into the Collector. This config uses four receivers:
    # - elasticsearch: to scrape metrics from the Elasticsearch API
    # - hostmetrics: to collect system-level metrics from the host itself
    # - filelog: to tail Elasticsearch log files
    # - otlp: to accept data from other OpenTelemetry-instrumented services
    # -------------------------------------------------------------------------------------------------
    receivers:
      elasticsearch:
        endpoint: "http://localhost:9200"
        collection_interval: 15s
        metrics:
          elasticsearch.breaker.tripped:
            enabled: true
          elasticsearch.cluster.data_nodes:
            enabled: true
          elasticsearch.cluster.health:
            enabled: true
          elasticsearch.cluster.in_flight_fetch:
            enabled: true
          elasticsearch.cluster.nodes:
            enabled: true
          elasticsearch.cluster.pending_tasks:
            enabled: true
          elasticsearch.cluster.shards:
            enabled: true
          elasticsearch.cluster.state_update.time:
            enabled: true
          elasticsearch.index.documents:
            enabled: true
          elasticsearch.index.operations.merge.current:
            enabled: true
          elasticsearch.index.operations.time:
            enabled: true
          elasticsearch.indexing_pressure.memory.total.primary_rejections:
            enabled: true
          elasticsearch.node.cache.count:
            enabled: true
          elasticsearch.node.cache.evictions:
            enabled: true
          elasticsearch.node.cache.memory.usage:
            enabled: true
          elasticsearch.node.cluster.io:
            enabled: true
          elasticsearch.node.documents:
            enabled: true
          elasticsearch.node.disk.io.read:
            enabled: true
          elasticsearch.node.disk.io.write:
            enabled: true
          elasticsearch.node.fs.disk.available:
            enabled: true
          elasticsearch.node.fs.disk.total:
            enabled: true
          elasticsearch.node.http.connections:
            enabled: true
          elasticsearch.node.ingest.documents.current:
            enabled: true
          elasticsearch.node.ingest.operations.failed:
            enabled: true
          elasticsearch.node.open_files:
            enabled: true
          elasticsearch.node.operations.completed:
            enabled: true
          elasticsearch.node.operations.current:
            enabled: true
          elasticsearch.node.operations.get.completed:
            enabled: true
          elasticsearch.node.operations.get.time:
            enabled: true
          elasticsearch.node.operations.time:
            enabled: true
          elasticsearch.node.shards.reserved.size:
            enabled: true
          elasticsearch.node.thread_pool.tasks.finished:
            enabled: true
          elasticsearch.os.cpu.load_avg.1m:
            enabled: true
          elasticsearch.os.cpu.load_avg.5m:
            enabled: true
          elasticsearch.os.cpu.load_avg.15m:
            enabled: true
          elasticsearch.os.memory:
            enabled: true
          jvm.gc.collections.count:
            enabled: true
          jvm.gc.collections.elapsed:
            enabled: true
          jvm.memory.heap.max:
            enabled: true
          jvm.memory.heap.used:
            enabled: true
          jvm.memory.heap.utilization:
            enabled: true
          jvm.threads.count:
            enabled: true
      hostmetrics:
        collection_interval: 60s # Recommended for cost savings and stability
        scrapers:
          cpu:
            metrics:
              # CPU Utilization and Time are the core metrics
              system.cpu.utilization: {enabled: true}
              system.cpu.time: {enabled: true}
          load:
            metrics:
              # Load Averages (used for system health dashboards)
              system.cpu.load_average.1m: {enabled: true}
              system.cpu.load_average.5m: {enabled: true}
              system.cpu.load_average.15m: {enabled: true}
          memory:
            metrics:
              # Memory Usage and Utilization
              system.memory.usage: {enabled: true}
              system.memory.utilization: {enabled: true}
          disk:
            metrics:
              # Disk I/O operations (throughput)
              system.disk.io: {enabled: true}
              system.disk.operations: {enabled: true}
          filesystem:
            metrics:
              # Filesystem usage (disk space capacity)
              system.filesystem.usage: {enabled: true}
              system.filesystem.utilization: {enabled: true} 
          network:
            # Since this was already working, keeping it simple is best.
            # But for completeness:
            metrics:
              system.network.io: {enabled: true}
              system.network.packets: {enabled: true}
          process:
               metrics:
                 process.cpu.utilization:
                   enabled: true
    # -------------------------------------------------------------------------------------------------
    # Processors
    # -------------------------------------------------------------------------------------------------
    processors:
      cumulativetodelta: {}
      resource/cluster_name_override:
        attributes:
          # Use the actual cluster name defined in your Elasticsearch config
          - key: elasticsearch.cluster.name
            value: "<elasticsearch-cluster-name>" # <-- REPLACE THIS WITH A UNIQUE CLUSTER NAME TO UNIQUELY IDENTIFY YOUR CLUSTER IN NEW RELIC 
            action: upsert
      # This processor adds resource attributes to all telemetry data.
      # 'service.name' is crucial for creating an entity in New Relic.
      resourcedetection:
        detectors: [ system ]
        system:
          resource_attributes:
            host.name:
              enabled: true
            host.id:
              enabled: true
            os.type:
              enabled: true 
      # This processor batches data for more efficient sending.
      batch:
        timeout: 10s
        send_batch_size: 1024
      # 1. CARDINALITY REDUCTION: Drops volatile or redundant attributes
      attributes/cardinality_reduction:
        actions:
          # Filter out VOLATILE PROCESS IDS (High churn)
          - key: process.pid
            action: delete
          - key: process.parent_pid
            action: delete
          # Filter out REDUNDANT/STATIC METADATA (Already known at the Resource level)
          - key: elasticsearch.node.version
            action: delete
          - key: os.type
            action: delete
      transform/metadata_nullify:
        # We use 'metric_statements' to run OTTL logic on the metric signal
        metric_statements:
          - context: metric  # <-- Targets the high-level Metric structure itself
            statements:
              # Sets the 'description' field to an empty string ("")
              - set(description, "")
              # Sets the 'unit' field to an empty string ("")
              - set(unit, "")      
    exporters:
      # This exporter sends all data to New Relic via OTLP/HTTP.
      otlphttp:
        endpoint: ${env:NEWRELIC_OTLP_ENDPOINT}
        headers:
          api-key: ${env:NEWRELIC_LICENSE_KEY}
    # -------------------------------------------------------------------------------------------------
    # Service
    # The service block defines the pipelines.
    # -------------------------------------------------------------------------------------------------
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [resourcedetection, resource/cluster_name_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [resourcedetection,batch]
          exporters: [otlphttp]
    ```
  </Collapser>

  <Collapser id="secure-config" title="Configuración de autenticación y SSL">
    **Use esto si tiene:** Un clúster de Elasticsearch seguro con autenticación y/o certificados SSL.

    Agregue las credenciales de autenticación y la configuración SSL a la configuración básica anterior:

    ```yaml
    receivers:
      elasticsearch:
        endpoint: "https://localhost:9200"
        username: "elastic"
        password: "your_password"
        tls:
          ca_file: "/etc/elasticsearch/certs/http_ca.crt"
          insecure_skip_verify: false
        collection_interval: 15s
    ```
  </Collapser>

  <Collapser id="logging-config" title="Habilitar logs (receptor filelog)">
    **Opcional:** Incluya esto si desea enviar archivos de log de Elasticsearch a New Relic además de las métricas.

    Agregue la configuración del receptor `filelog` para recopilar y reenviar los logs de Elasticsearch. Asegúrese de que el usuario `otelcol-contrib` tenga acceso `read` a los archivos de log.

    ###### Si ejecuta Elasticsearch en Linux (Host):

    ```yaml
    receivers:
      filelog:
        include:
          - /var/log/elasticsearch/elasticsearch.log #Replace with path of the elasticsearch log file.
          - /var/log/elasticsearch/*.log             #We can send multiple log files using regex.
    ```

    ###### Si ejecuta Elasticsearch en Docker:

    ```yaml
    receivers:
      filelog:
        include:
          - /var/lib/docker/containers/*/*.log       # Replace with the container log file path. 
        operators:
          - type: move
            from: attributes.log
            to: body
    ```

    ###### Agregar el receptor filelog en el pipeline de servicio:

    ```yaml
    service:
      pipelines:
        logs:
          receivers: [filelog]
          processors: [resource/cluster_name_override]
          exporters: [otlphttp]
    ```

    Otorgue permiso agregando el usuario al grupo:

    ```bash
    sudo usermod -a -G elasticsearch otelcol-contrib
    ```
  </Collapser>

  <Collapser id="custom-attributes" title="Agregar metadatos personalizados">
    **Opcional:** Incluya esto si desea etiquetar sus datos con atributos personalizados como entorno, equipo o región.

    Use el procesador `resource/static_override` para agregar etiquetas de metadatos personalizadas a todas sus métricas:

    ```yaml
    processors:
      resource/static_override:
        attributes:
          - key: env
            value: "production"
            action: upsert
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [resourcedetection, resource/cluster_name_override, resource/static_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [resourcedetection, resource/static_override, batch]
          exporters: [otlphttp]        

    ```
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  **Correlacione APM con Elasticsearch**: Para conectar su aplicación APM y el clúster de Elasticsearch, incluya el atributo de recurso `es.cluster.name="your-cluster-name"` en sus métricas de APM. Esto permite la visibilidad entre servicios y una solución de problemas más rápida dentro de New Relic.
</Callout>

## Paso 3: Establecer variables de entorno [#start]

Configure la autenticación agregando su punto final de New Relic <InlinePopover type="licenseKey" />y OTLP al servicio del recopilador.

1. Crea un directorio de anulación de systemd:

   ```bash
   sudo mkdir -p /etc/systemd/system/otelcol-contrib.service.d
   ```

2. Escribe `environment.conf` con tu punto final OTLP. Reemplaza `YOUR_LICENSE_KEY` con la clave de licencia de New Relic y `YOUR_OTLP_ENDPOINT` con el punto final apropiado para tu región. Consulta la [documentación](https://docs.newrelic.com/docs/opentelemetry/best-practices/opentelemetry-otlp/#configure-endpoint-port-protocol) de configuración del punto final OTLP para seleccionar el punto final correcto.

   ```bash
   cat <<EOF | sudo tee /etc/systemd/system/otelcol-contrib.service.d/environment.conf
   [Service]
   Environment="NEWRELIC_OTLP_ENDPOINT=YOUR_OTLP_ENDPOINT"
   Environment="NEWRELIC_LICENSE_KEY=YOUR_LICENSE_KEY"
   EOF
   ```

3. Recargue systemd y reinicie el recopilador:

   ```bash
   sudo systemctl daemon-reload
   sudo systemctl restart otelcol-contrib.service
   ```

## Paso 4: Vea sus datos de Elasticsearch [#find-and-use]

Una vez que el recopilador esté en ejecución y enviando datos, puede ver sus métricas de Elasticsearch en New Relic:

1. Vaya a **[one.newrelic.com](https://one.newrelic.com)** &gt; **Integrations &amp; Agents**
2. Buscar **Elasticsearch (OpenTelemetry)**
3. En **Dashboards**, haga clic en **Elasticsearch OpenTelemetry Dashboard**
4. Seleccione su cuenta y haga clic en **View dashboard**

Debería ver dashboards que muestren el estado del clúster, las métricas de rendimiento y el uso de recursos.

<Callout variant="tip">
  **¿No ve datos?** Puede tardar unos minutos en aparecer los datos. Si no ve métricas después de 10 minutos, consulte nuestra [guía de solución de problemas](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-otel/troubleshooting).
</Callout>

**Próximos pasos con sus datos:**

* **Explorar métricas**: Todas las métricas de Elasticsearch se almacenan como `Metric` [tipos de eventos](/docs/data-apis/understand-data/new-relic-data-types)
* **Crear consultas personalizadas**: Use [NRQL](/docs/nrql/get-started/introduction-nrql-new-relics-query-language) para construir gráficos y dashboards personalizados
* **Configure alertas**: Continúe con el Paso 5 para configurar el monitoreo proactivo

## Paso 5: Configurar alertas [#alerts]

La monitorización proactiva con alertas le ayuda a detectar problemas antes de que afecten a sus usuarios. Para crear condiciones de alerta en New Relic:

1. Vaya a **[one.newrelic.com](https://one.newrelic.com)** &gt; **Alerts** &gt; **Alert Conditions**.
2. Haga clic en **Create condition**.
3. Configure la alerta utilizando el **Guided mode** o el generador de consultas **NRQL**.

Las configuraciones de alerta a continuación se recomiendan para una supervisión robusta de Elasticsearch:

### Alertas esenciales (Alta prioridad)

Estas alertas monitorean problemas críticos de salud del clúster que pueden causar pérdida de datos o interrupciones del servicio:

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        Nombre de la alerta
      </th>

      <th>
        Fundamento del umbral (Condición de ejemplo)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **Alerta de fragmentos no asignados**
      </td>

      <td>
        La métrica 

        `elasticsearch.cluster.shards`

         (donde 

        `state = 'unassigned'`

        ) está por encima de 0 durante al menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Alerta de nodos de datos en buen estado**
      </td>

      <td>
        La métrica 

        `elasticsearch.cluster.data_nodes`

         está por debajo del recuento mínimo de nodos requeridos durante al menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Alerta de uso de memoria dinámica excesivo**
      </td>

      <td>
        El porcentaje de uso del montón (Usado/Máx.) es superior al 90% durante al menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Alerta de tareas pendientes**
      </td>

      <td>
        La métrica 

        `elasticsearch.cluster.pending_tasks`

         está por encima de 5 durante al menos 5 minutos.
      </td>
    </tr>
  </tbody>
</table>

### Alertas de supervisión adicionales

Estas alertas ayudan a monitorear el rendimiento y los problemas operativos:

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        Nombre de la alerta
      </th>

      <th>
        Fundamento del umbral (Condición de ejemplo)
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        **Alerta de tiempo de consulta lento**
      </td>

      <td>
        El percentil 95 de 

        `elasticsearch.node.operations.time`

         es superior a 5 ms durante al menos 2 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Inicializando fragmentos durante demasiado tiempo**
      </td>

      <td>
        La métrica 

        `elasticsearch.cluster.shards`

         (donde 

        `state = 'initializing'`

        ) está por encima de 0 durante al menos 5 minutos.
      </td>
    </tr>

    <tr>
      <td>
        **Reubicando fragmentos durante demasiado tiempo**
      </td>

      <td>
        La métrica 

        `elasticsearch.cluster.shards`

         (donde 

        `state = 'relocating'`

        ) está por encima de 0 durante al menos 5 minutos.
      </td>
    </tr>
  </tbody>
</table>

## Resolución de problemas

Si encuentra problemas durante la instalación o no ve datos en New Relic, consulte nuestra completa [guía de solución de problemas](/docs/opentelemetry/integrations/elasticsearch/troubleshooting) para obtener soluciones paso a paso a los problemas comunes.