---
title: Observabilidad de LLM con OpenLIT
tags:
  - Integrations
  - LLM observability with OpenTelemetry
  - GenAI Observability with OpenTelemetry
  - OpenTelemetry
  - OpenLIT
metaDescription: Set up OpenTelemetry-based LLM observability with New Relic and OpenLIT.
freshnessValidatedDate: '2024-10-08T00:00:00.000Z'
translationType: machine
---

Si bien OpenTelemetry ofrece un estándar poderoso para recopilar datos de aplicaciones generales (traza, métrica, log), carece de la capacidad de capturar indicadores de clave de rendimiento (KPI) específicos del modelo de IA. Métricas esenciales como el seguimiento del rendimiento, el uso token , los costos y los datos de interacción del usuario en forma de símbolo y respuestas de LLM son cruciales para un monitoreo y resolución de problemas efectivos de la aplicación de LLM.

Para cerrar esta brecha en la observabilidad del LLM, OpenLIT surgió como una solución personalizada. Construido sobre el OpenTelemetry framework, OpenLIT es una herramienta de código abierto que se integra sin problemas y amplía sus capacidades. Es compatible con marcos de inteligencia artificial ampliamente empleados, como OpenAI, Anthropic, Pinecone, LangChain, entre otros. Además, proporciona capacidades de monitoreo de GPU basadas en OpenTelemetry listas para usar.

Principales beneficios de OpenLIT:

* **Monitoreo avanzado del rendimiento de LLM y VectorDB**: OpenLIT genera automáticamente gráficos y métricas para un análisis profundo del rendimiento y los costos del uso de LLM y VectorDB, lo que lo ayuda a optimizar el uso de los recursos y a escalar de manera eficiente en diversos entornos, como la producción.

* **Seguimiento de costos para modelos personalizados y ajustados**: permite un seguimiento preciso de los costos a través de un archivo JSON personalizado, lo que posibilita una presupuestación precisa y la alineación con las necesidades específicas del proyecto.

* **OpenTelemetry- SDK nativo e independiente del proveedor**: OpenLIT está construido con soporte nativo para OpenTelemetry, lo que hace que se integre perfectamente con sus proyectos. Este enfoque independiente del proveedor reduce las barreras a la integración, haciendo de OpenLIT una parte intuitiva de su stack de software en lugar de una complejidad adicional.

OpenLIT permite a los desarrolladores aprovechar las fortalezas de OpenTelemetry y al mismo tiempo obtener las funcionalidades adicionales necesarias para un monitoreo LLM efectivo y la optimización del rendimiento.

## Antes de que empieces [#prereqs]

* [Regístrese](https://newrelic.com/signup) para obtener una cuenta New Relic.
* Obtenga la [clave de licencia](https://one.newrelic.com/launcher/api-keys-ui.launcher) para la cuenta New Relic a la que desea reportar datos.

## Instrumente su modelo LLM con OpenLIT [#instrument]

Siga estos pasos de configuración comunes para OpenTelemetryel APM monitoreo basado en con New Relic.

<Steps>
  <Step>
    ### Ruta la traza y métrica [#route-traces]

    Dado que New Relic admite de forma nativa OpenTelemetry, solo necesita enrutar la traza y la métrica al extremo de New Relic y configurar la clave API.

    Ejecute los siguientes comandos para que el exportador del [ProtocoloOpenTelemetry ](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md)(OTLP para abreviar) envíe datos al [extremo OTLPNew Relic ](/docs/opentelemetry/best-practices/opentelemetry-otlp).

    ```env
    OTEL_EXPORTER_OTLP_ENDPOINT = https://otlp.nr-data.net:443
    OTEL_EXPORTER_OTLP_HEADERS = "api-key=YOUR_NEWRELIC_LICENSE_KEY"
    ```

    Vea este ejemplo sobre el modelo LLM de OpenAI con LangChain:

    ```python
    import openlit
    import os
    from langchain_openai import ChatOpenAI

    os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'
    os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = 'https://otlp.nr-data.net:443'
    os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = 'api-key=YOUR_NEWRELIC_LICENSE_KEY'

    openlit.init()

    def add_prompt_context():
      llm = ChatOpenAI(
          model="gpt-3.5-turbo",
          temperature=0)
      chain = llm
      return chain

    def prep_prompt_chain():
      return add_prompt_context()

    def prompt_question():
      chain = prep_prompt_chain()
      return chain.invoke("explain the business of company Newrelic and it's advantages in a max of 50 words")

    if  __name__ == "__main__":
      print(prompt_question())
    ```
  </Step>

  <Step>
    ## Vea sus datos en la UI de New Relic [#view-data]

    Una vez que su aplicación esté instrumentada y configurada para exportar datos a New Relic, debería poder encontrar sus datos en la New Relic UI; puede importar el observación prediseñado de LLM dashboard siguiendo estos pasos:

    1. Vaya a <DNT>**[one.newrelic.com &gt; All capabilities](https://one.newrelic.com/all-capabilities) &gt; Dashboards**</DNT>.

    2. En la esquina superior derecha, haga clic en <DNT>**Import dashboard**</DNT>.

    3. Copie el JSON del panel proporcionado [aquí](https://docs.openlit.io/latest/connections/new-relic#dashboard) y péguelo.

    4. Elija la configuración de cuenta y licencias para el dashboard. No puedes cambiar la cuenta una vez que la configuraste, pero puedes cambiar las licencias en cualquier momento.

    5. Haga clic en <DNT>**Import dashboard**</DNT>.

    Si no puede encontrar su entidad y no ve sus datos con NRQL, consulte [Resolución de problemas de OTLP](/docs/opentelemetry/best-practices/opentelemetry-otlp-troubleshooting).

    <InstallFeedback />
  </Step>
</Steps>