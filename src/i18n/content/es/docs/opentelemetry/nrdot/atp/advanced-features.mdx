---
title: Funciones avanzadas y capas de inteligencia de ATP
metaDescription: 'Learn about ATP intelligent features including dynamic thresholds, multi-metric composite scoring, and anomaly detection.'
tags:
  - Open source telemetry integrations
  - OpenTelemetry
  - NRDOT
  - Adaptive Telemetry Processor
  - ATP
  - Dynamic thresholds
  - Anomaly detection
  - Multi-metric scoring
  - Intelligence
freshnessValidatedDate: never
translationType: machine
---

<Callout title="Avance">
  Todavía estamos trabajando en esta característica, ¡pero nos encantaría que la probaras!

  Esta función se proporciona actualmente como parte de una vista previa de conformidad con nuestras [políticas de prelanzamiento](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy/).
</Callout>

ATP incluye capas de inteligencia avanzada que le proporcionan un procesamiento de telemetría sofisticado y adaptativo más allá del simple filtrado basado en umbrales.

## Opciones de configuración avanzada [#advanced-config]

Puede agregar estos **parámetros opcionales** a la configuración de su procesador ATP para habilitar funciones avanzadas.

<CollapserGroup>
  <Collapser id="dynamic" title="Umbrales dinámicos">
    ### Umbrales dinámicos [#dynamic-thresholds]

    Esta función ajusta automáticamente los umbrales basándose en el comportamiento histórico de su sistema, ayudándole a detectar anomalías mientras reduce los falsos positivos.

    ```yaml
    processors:
      adaptivetelemetry:
        # ... existing config ...
        # Dynamic threshold configuration
        enable_dynamic_thresholds: true
        dynamic_smoothing_factor: 0.2
        min_thresholds:
          process.cpu.utilization: 0.04  # Can't go below 4%
          process.memory.utilization: 0.04  # Can't go below 4%
        max_thresholds:
          process.cpu.utilization: 0.30  # Can't exceed 30%
          process.memory.utilization: 0.30  # Can't exceed 30%
    ```
  </Collapser>

  <Collapser id="multi-metric" title="Puntuación compuesta multimétrica">
    ### Puntuación compuesta multimétrica [#multi-metric-scoring]

    Esto evalúa múltiples métricas en conjunto para brindarle una visión holística de la salud del proceso, detectando los procesos que son problemáticos en múltiples dimensiones.

    ```yaml
    processors:
      adaptivetelemetry:
        # ... existing config ...
        # Multi-metric configuration
        enable_multi_metric: true
        composite_threshold: 1.2
        weights:
          process.cpu.utilization: 0.5
          process.memory.utilization: 0.5
    ```
  </Collapser>

  <Collapser id="anomaly-detection" title="Detección de anomalías">
    ### Detección de anomalías [#anomaly-detection]

    Esto detecta picos repentinos en las métricas por encima de los promedios históricos, lo que le ayuda a detectar procesos que se han salido de control o han experimentado cambios de comportamiento inesperados.

    ```yaml
    processors:
      adaptivetelemetry:
        # ... existing config ...
        # Anomaly detection configuration
        enable_anomaly_detection: true
        anomaly_history_size: 15
        anomaly_change_threshold: 50.0  # 50% spike triggers anomaly
        anomaly_min_data_points: 3
    ```
  </Collapser>
</CollapserGroup>

## Ejemplo completo de configuración avanzada [#complete-example]

Aquí hay un ejemplo completo con todas las funciones avanzadas habilitadas:

```yaml
processors:
  adaptivetelemetry:
    enable_storage: true
    retention_minutes: 30
    include_process_list:
      - "/usr/bin/postgres"
      - "/usr/sbin/nginx"
    metric_thresholds:
      process.cpu.utilization: 0.05
      process.memory.utilization: 0.05
    
    # All advanced features enabled
    enable_dynamic_thresholds: true
    dynamic_smoothing_factor: 0.2
    min_thresholds:
      process.cpu.utilization: 0.04
      process.memory.utilization: 0.04
    max_thresholds:
      process.cpu.utilization: 0.30
      process.memory.utilization: 0.30
    
    enable_multi_metric: true
    composite_threshold: 1.5
    weights:
      process.cpu.utilization: 0.5
      process.memory.utilization: 0.5
    
    enable_anomaly_detection: true
    anomaly_history_size: 15
    anomaly_change_threshold: 50.0
    anomaly_min_data_points: 3
```

## Guía de ajuste de configuración [#tuning-guide]

Las siguientes secciones explican en detalle cada opción de configuración avanzada, junto con orientación sobre cómo ajustarlas para su entorno.

<CollapserGroup>
  <Collapser id="basic" title="Configuración básica">
    ### Configuración básica

    * `enable_storage`: Habilite el almacenamiento persistente para datos históricos de métricas. Esto es necesario para la persistencia entre reinicios.

      * Por defecto: `true`

      * Las rutas de almacenamiento son determinadas automáticamente por la plataforma:

        * **Linux**: `/var/lib/nrdot-collector/adaptiveprocess.db`
        * **Windows**: `%LOCALAPPDATA%\nrdot-collector\adaptiveprocess.db`

    * `retention_minutes`: Cuánto tiempo (en minutos) seguir rastreando un proceso después de que excedió un umbral por última vez.

      * Predeterminado: 30 (máx.: 30)
      * Ajuste: Use valores más bajos (5-10) para procesos de corta duración; manténgalo en 30 para cargas de trabajo estables
  </Collapser>

  <Collapser id="thresholds" title="Configuración de umbrales">
    ### Incluir lista de procesos

    La `include_process_list` es una lista de procesos que siempre omiten todos los filtros y se reportan independientemente de los umbrales.

    * Caso de uso: Procesos críticos que siempre desea monitorear (por ejemplo, base de datos, servidor web)
    * Seguridad: Use rutas completas (`/usr/bin/postgres`) con separadores como `/usr/bin/postgres`. Las entradas sin separadores de ruta como `"postgres"` no coincidirán con ningún proceso.

    **Ejemplo:**

    ```yaml
    include_process_list:
      - "/usr/bin/postgres"  # Always include PostgreSQL
      - "/usr/sbin/nginx"    # Always include Nginx
    ```
  </Collapser>

  <Collapser id="metric-thresholds" title="Umbrales de métrica">
    ### Umbrales de métrica

    Los `metric_thresholds` son valores de umbral estáticos para cada métrica. Un proceso se marca cuando **excede** este valor.

    **Cómo optimizar:**

    * Comience con valores de referencia de su carga de trabajo promedio
    * Aumente los umbrales para reducir el ruido y obtener menos alertas
    * Reduzca los umbrales para detectar anomalías más pequeñas
    * Para métricas de utilización (CPU/memoria): Use porcentajes (0.0-1.0 = 0%-100%)
    * Para métricas de conteo (hilos, descriptores de archivos): Use números absolutos

    **Valores de ejemplo explicados:**

    ```yaml
    metric_thresholds:
      process.cpu.utilization: 0.0005      # 0.05% CPU - very sensitive
      process.memory.utilization: 0.0005   # 0.05% memory - very sensitive
      process.memory.virtual: 20971520     # 20 MB virtual memory
      process.threads: 16                  # 16 threads
      process.open_file_descriptors: 30    # 30 open files
      process.disk.io: 204800              # 200 KB disk I/O
      process.cpu.time: 0.01               # 0.01 seconds CPU time
    ```
  </Collapser>

  <Collapser id="dynamic-thresholds" title="Umbrales dinámicos">
    ### Umbrales dinámicos

    Ajusta automáticamente los umbrales basándose en el comportamiento histórico. Útil para procesos con patrones de carga de trabajo variables.

    * `enable_dynamic_thresholds`: Activa el ajuste de umbral adaptativo.

      * Cuándo habilitar: Procesos con comportamiento fluctuante, como trabajos por lotes, servidores de API
      * Cuándo deshabilitar: Procesos con comportamiento estable y predecible

    * `dynamic_smoothing_factor`: Qué tan rápido se adaptan los umbrales (0.0-1.0).

      * Más bajo (0.1): Adaptación lenta, más estable (adecuado para cambios graduales)
      * Más alto (0.5): Adaptación rápida, mayor capacidad de respuesta (bueno para cargas de trabajo volátiles)
      * Predeterminado: 0.2 (equilibrado)

    * `min_thresholds`: Valores piso - los umbrales no caerán por debajo de estos. Esto se utiliza para evitar que los umbrales se vuelvan demasiado sensibles.

    * `max_thresholds`: Valores máximos - los umbrales no superarán estos valores. Esto se utiliza para evitar que los umbrales se vuelvan demasiado laxos.
  </Collapser>

  <Collapser id="multi-metric-scoring" title="Puntuación multimétrica">
    ### Puntuación multimétrica (puntuación compuesta)

    Evalúa múltiples métricas en conjunto en lugar de individualmente. Útil para detectar procesos que son &quot;actores maliciosos&quot; en múltiples dimensiones.

    * `enable_multi_metric`: Habilita la puntuación compuesta.

      * Cuándo habilitar: Desea detectar procesos que son problemáticos de múltiples formas (alto consumo de CPU + alto consumo de memoria)
      * Cuándo deshabilitar: Desea alertar sobre violaciones de métricas individuales

    * `composite_threshold`: El umbral de puntuación combinada. Se marca un proceso cuando: (suma ponderada de métricas) &gt; composite\_threshold.

      * Inferior (0.5): Más sensible, detecta casos marginales
      * Más alto (2.0): Menos sensible, solo detecta problemas significativos
      * Predeterminado: 1.5

    * `weights`: Importancia de cada métrica en la puntuación compuesta. Cuanto mayor sea el peso, más influencia tendrá la métrica.
  </Collapser>

  <Collapser id="anomaly-detection" title="Detección de anomalías">
    ### Detección de anomalías

    Esto detecta picos repentinos o comportamientos inusuales al comparar los valores actuales con patrones históricos.

    * `enable_anomaly_detection`: Activa la detección de picos.

      * Cuándo habilitar: Para detectar cambios repentinos (proceso fuera de control)
      * Cuándo deshabilitar: Para umbrales absolutos

    * `anomaly_history_size`: Número de puntos de datos recientes para calcular el promedio de la línea base.

      * Más grande (50-100): Línea base más suave, detecta anomalías más grandes
      * Más pequeño (5-15): Más reactivo, detecta picos más pequeños
      * Predeterminado: 10 (máx.: 100)

    * `anomaly_change_threshold`: Pico de porcentaje por encima del promedio histórico para activar una alerta.

      * Ejemplo: 50.0 = marcar si el valor actual es un 50% mayor que el promedio
      * Más bajo (20-50): Más sensible a los cambios
      * Más alto (100-200): Solo capturar picos drásticos
      * Predeterminado: 200.0

    * `anomaly_min_data_points`: Puntos de datos históricos mínimos antes de que se active la detección de anomalías.

      * Esto evita falsos positivos durante el inicio
      * Recomendado: Mantener en 3 (predeterminado)
      * Debe ser ≤ `anomaly_history_size`
  </Collapser>
</CollapserGroup>

## Estrategia de optimización [#tuning-strategy]

**Primeros pasos:**

1. Comenzar solo con `metric_thresholds` (deshabilitar dinámico/multimétrica/anomalía)
2. Observe durante 1-2 días, luego ajuste los umbrales para reducir los falsos positivos
3. Habilitar `enable_dynamic_thresholds` para cargas de trabajo variables
4. Agregar `enable_anomaly_detection` para detectar picos repentinos
5. Utilice `enable_multi_metric` si los procesos muestran problemas de recursos correlacionados

**Patrones comunes:**

* **Servicios de producción estables**: utilice únicamente umbrales estáticos
* **Trabajos por lotes**: use umbrales dinámicos + detección de anomalías
* **Aplicaciones de uso intensivo de recursos**: use la puntuación multimétrica
* **Procesos críticos**: agregar a `include_process_list`

## Recursos relacionados [#related-resources]

<DocTiles>
  <DocTile title="Resolución de problemas" path="/docs/opentelemetry/nrdot/atp/troubleshooting">
    Aprenda a solucionar problemas de ATP para su entorno.
  </DocTile>

  <DocTile title="Consulta tus datos" path="/docs/opentelemetry/nrdot/atp/query">
    Aprenda a consultar datos de ATP en New Relic usando NRQL.
  </DocTile>

  <DocTile title="Ver tus datos" path="/docs/opentelemetry/nrdot/atp/view-data">
    Aprenda a ver los datos recopilados por ATP en New Relic.
  </DocTile>
</DocTiles>