---
title: Introducción al monitoreo del rendimiento de los modelos (MLOps)
metaDescription: Use New Relic ML model performance monitoring to monitor and observe the performance of your machine learning models.
freshnessValidatedDate: never
translationType: machine
---

Las operaciones de aprendizaje automático son un conjunto de prácticas diseñadas para aumentar la calidad, simplificar el proceso de gestión y automatizar el despliegue de modelos de aprendizaje automático en entornos de producción a gran escala.

A medida que más empresas invierten en inteligencia artificial y aprendizaje automático, existe una brecha en la comprensión entre los equipos de ciencia de datos que desarrollan modelos de aprendizaje automático y los equipos de DevOps que operan la aplicación que impulsa esos modelos. A día de hoy, sólo el 15% de las empresas utilizan la IA para abarcar todas sus actividades. No ayuda que el 75% de los modelos de aprendizaje automático en producción nunca se utilicen debido a problemas de implementación, monitoreo, gestión y gobernanza. En última instancia, esto genera una enorme pérdida de tiempo para el ingeniero y los científicos de datos que trabajan en los modelos, una gran pérdida neta de dinero invertido por la empresa y una falta general de confianza cuando los modelos de aprendizaje automático permiten un crecimiento cuantificable.

Nuestro monitoreo del rendimiento de los modelos brinda a los científicos de datos y especialistas de MLOps visibilidad sobre el rendimiento de su aplicación de aprendizaje automático al monitorear el comportamiento y la efectividad de los modelos en producción. Permite a los equipos de datos la capacidad de colaborar directamente con los equipos de DevOps, lo que crea un proceso continuo de desarrollo, pruebas y monitoreo operativo.

## Cómo monitor sus modelos de aprendizaje automático [#use-mlops]

Para emplear el monitoreo del rendimiento de los modelos dentro de [las alertas New Relic](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/introduction-applied-intelligence/), tienes algunas opciones diferentes:

1. <DNT>**Bring your own data (BYOD):**</DNT> Este es el enfoque recomendado por New Relic. Nuestro monitoreo del rendimiento de los modelos ML brinda observabilidad en profundidad de cómo operan sus modelos ML en producción. BYOD se puede utilizar desde cualquier entorno (script de Python, contenedor, función Lambda, SageMaker, etc.) y se puede integrar fácilmente con cualquier framework de aprendizaje automático (Scikit-learn, Keras, Pytorch, Tensorflow, Jax, etc.). Con BYOD, puede incorporar su propia telemetría de modelo de ML a New Relic y comenzar a obtener valor de los datos de su modelo de ML. En solo unos minutos, puede obtener distribución de características, datos estadísticos y distribución de predicción junto con cualquier otra métrica personalizada que desee monitor. Lea más sobre BYOD en [nuestros documentos](/docs/alerts-applied-intelligence/mlops/bring-your-own/mlops-byo).

2. <DNT>**Integrations:**</DNT> New Relic también se ha asociado con Amazon SageMaker, lo que le brinda una vista de la métrica de rendimiento de SageMaker en New Relic y amplía el acceso a la observabilidad para los equipos de ingeniería de ML y ciencia de datos. Lea más sobre nuestra [integración de Amazon SageMaker](/docs/mlops/integrations/aws-sagemaker-mlops-integration/).

3. <DNT>**Partnerships:**</DNT> New Relic se ha asociado con siete proveedores diferentes de MLOps que ofrecen casos de uso específicos y capacidades de monitoreo. Los socios son una excelente manera de obtener acceso a rendimiento seleccionado <InlinePopover type="dashboards"/>y otras herramientas de observabilidad, ya que brindan un panel listo para usar que le brinda visibilidad instantánea de sus modelos.

   Actualmente nos asociamos con:

   * [Datarobot (Algorithmia)](/docs/alerts-applied-intelligence/mlops/integrations/datarobot-mlops-integration/)
   * [Aporia](/docs/alerts-applied-intelligence/mlops/integrations/aporia-mlops-integration/)
   * [Comet](/docs/alerts-applied-intelligence/mlops/integrations/comet-mlops-integration/)
   * [DagsHub](/docs/alerts-applied-intelligence/mlops/integrations/dagshub-mlops-integration/)
   * [Mona](/docs/alerts-applied-intelligence/mlops/integrations/mona-mlops-integration/)
   * [Superwise](/docs/alerts-applied-intelligence/mlops/integrations/superwise-mlops-integration/)
   * [TruEra](/docs/alerts-applied-intelligence/mlops/integrations/truera-mlops-integration/)

Para comenzar a medir el rendimiento del modelo de aprendizaje automático en minutos utilizando cualquiera de estas opciones, consulte los [inicios rápidos de monitoreo del rendimiento de los modelos](https://newrelic.com/instant-observability/?category=machine-learning-ops).

## Cómo monitor aplicaciones OpenAI GPT [#monitor-openai-gtp]

Con la [integración de aplicaciones de la serie GPT](/docs/mlops/integrations/openai-integration/), tendrá la capacidad de monitor la consulta de finalización de OpenAI y log estadísticas útiles en un dashboard personalizable de New Relic sobre sus solicitudes. Al agregar solo dos líneas de código, puede obtener acceso a métricas clave de rendimiento, como el costo, el tiempo de respuesta y muestras de entradas/salidas. El dashboard totalmente personalizable también permite al usuario realizar un seguimiento de las solicitudes totales, el promedio token/solicitudes y los nombres de los modelos. Lea más o instale la integración visitando nuestro [inicio rápido de New Relic OpenAI](https://newrelic.com/instant-observability/openai).
