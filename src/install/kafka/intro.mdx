---
headingText: Before we start
componentType: default
---

The New Relic Kafka [on-host integration](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) reports metrics and configuration data from your Kafka service. Gain deep insights into Kafka performance with seamless data integration into New Relic. Monitor key metrics for clusters, brokers (both ZooKeeper and Bootstrap), producers, consumers, and topics effortlessly, all within our powerful platform. Create alerts to stay ahead of spikes, build custom dashboards for tailored views, and proactively optimize your Kafka monitoring.

<Callout variant="tip">
  Guided install is a single CLI command you can run on your system to monitor your Kafka instance. The CLI installs the infrastructure agent and Kafka integration. This is a good way to trial ingesting data on our platform.

  <ButtonGroup>
    <ButtonLink
      role="button"
      to="https://one.newrelic.com/launcher/nr1-core.explorer?pane=eyJuZXJkbGV0SWQiOiJucjEtY29yZS5saXN0aW5nIn0=&cards[0]=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsImFjdGl2ZUNvbXBvbmVudCI6IlZUU09FbnZpcm9ubWVudCIsInBhdGgiOiJndWlkZWQifQ=="
      variant="primary"
    >
      Guided install
    </ButtonLink>

    <ButtonLink
      role="button"
      to="https://one.eu.newrelic.com/launcher/nr1-core.explorer?pane=eyJuZXJkbGV0SWQiOiJucjEtY29yZS5saXN0aW5nIn0=&cards[0]=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsImFjdGl2ZUNvbXBvbmVudCI6IlZUU09FbnZpcm9ubWVudCIsInBhdGgiOiJndWlkZWQifQ=="
      variant="primary"
    >
      EU guided install
    </ButtonLink>
  </ButtonGroup>

  If you'd prefer to install manually, follow the steps below.
</Callout>

## Requirements [#compability-requirements]

### General requirements [#general-requirements]

* A New Relic account. Don't have one? [Sign up for free!](https://newrelic.com/signup) No credit card required.

* Our integration is compatible with Kafka version 3 or lower.

* Check the [Apache Kafka EOL](https://cwiki.apache.org/confluence/display/KAFKA/Time+Based+Release+Plan#TimeBasedReleasePlan-WhatIsOurEOLPolicy) policy and the [End of Life](https://docs.confluent.io/platform/current/installation/versions-interoperability.html#cp-and-apache-ak-compatibility) Kafka version to avoid unexpected results you may have.

* If Kafka is not running on Kubernetes or Amazon ECS, you can [install the infrastructure agent](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) on a Linux or Windows OS host or on a host capable of remotely accessing where Kafka is installed. Otherwise:
  * If running on <img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src="/images/os_icon_k8.webp"/>Kubernetes, see [these requirements](/docs/monitor-service-running-kubernetes#requirements).
  * If running on <img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src="/images/os_icon_ecs.webp"/>Amazon ECS, see [these requirements](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).

* Java version 8 or higher.

* JMX enabled on all brokers.

* Java-based consumers and producers only, and with JMX enabled.

* Total number of monitored topics must be fewer than 10000.

### Connectivity requirements [#connectivity-requirements]

You must configure the integration and allow it to connec to:

* Hosts listed in `zookeeper_hosts` over the Zookeeper protocol, using the Zookeeper authentication mechanism if `autodiscover_strategy` is set to `zookeeper`.

* Hosts defined in `bootstrap_broker_host` over the Kafka protocol, using the Kafka broker's authentication and transport mechanisms, if `autodiscover_strategy` is set to `bootstrap`.

* All brokers in the cluster over the Kafka protocol and port, using the Kafka brokers' authentication and transport mechanisms.

* All brokers in the cluster over the JMX protocol and port, using the authentication and transport mechanisms specified in the JMX configuration of the brokers.

* All producers and consumers specified in producers and consumers over the JMX protocol and port, if you want producer and consumer monitoring. JMX settings for the consumer must be the same as for the brokers.

<Callout variant="important">
  By default, security groups and their equivalents in other cloud providers in AWS, don't have the required ports open by default. JMX requires 2 ports in order to work: the JMX port and the RMI port. You can set them to the same value when configuring the JVM to enable JMX and must be open for the integration to be able to connect to and collect metrics from brokers.
</Callout>

## Prepare for the installation [#prepare-installation]

Kafka is a complex piece of software that is built as a distributed system. For this reason, you need to ensure that the integration can contact all the required hosts and services so the data is collected correctly.

<CollapserGroup>
  <Collapser
    id="autodiscovery"
    title="Autodiscovery"
  >
    Given the distributed nature of Kafka, the actual number and list of brokers is usually not fixed by the configuration, and it's instead quite dynamic. For this reason, the Kafka integration offers 2 mechanisms to perform automatic discovery of the list of brokers in the cluster: Bootstrap and Zookeeper. The mechanism you use depends on the setup of the Kafka cluster you'll monitor.

    ### Bootstrap

    With the bootstrap mechanism, the integration uses a bootstrap broker to perform the autodiscovery. This is a broker whose address is well known and that will be asked for any other brokers it's aware of. The integration needs to be able to contact this broker in the address provided in the `bootstrap_broker_host` parameter for bootstrap discovery to work.

    ### Zookeeper

    The Kafka integration can also talk to a Zookeeper server in order to obtain the list of brokers. To do this, you need to provide the integration with the following:

    * The list of Zookeeper hosts, `zookeeper_hosts`, to contact.
    * The proper authentication secrets to connect with the hosts.

    Together with the list of brokers it knows about, Zookeeper will also advertise which connection mechanisms are supported by each broker.

    You can configure the Kafka integration to try directly with one of these mechanisms with the `preferred_listener` parameter. If this parameter is not provided, the integration will try to contact the brokers with all the advertised configurations until one of them succeeds.

    <Callout variant="tip">
      The integration will use Zookeeper only for discovering brokers and will not retrieve metrics from it.
    </Callout>
  </Collapser>

  <Collapser
    id="topic-listing"
    title="Topic listing"
  >
    To correctly list the topics processed by the brokers, the integration needs to contact brokers over the Kafka protocol. Depending on the configuration of the brokers, this might require setting up SSL and SASL to match the broker configuration. The topics must have `DESCRIBE` access.
  </Collapser>

  <Collapser
    id="broker-monitoring"
    title="Broker monitoring (JMX)"
  >
    The Kafka integration queries JMX, a standard Java extension for exchanging metrics in Java applications. You need to enable JMX in Kafka brokers to have the metrics collecton working properly. JMX requires RMI to be enabled, and the RMI port needs to be set to the same port as JMX.

    You can configure JMX to use username and password authentication, as well as SSL. If such features have been enabled in the broker's JMX settings, you need to configure the integration accordingly.

    If autodiscovery is set to bootstrap, the JMX settings defined for the bootstrap broker will be applied for all other discovered brokers, so the port and other settings should be the same on all the brokers.

    <Callout variant="important">
      We don't recommend enabling anonymous and unencrypted JMX and RMI access on public or untrusted network segments because this poses a big security risk.
    </Callout>
  </Collapser>

  <Collapser
    id="consumer-offset"
    title="Consumer offset"
  >
    You can get the offsets of consumers and consumer groups, as well as the lag. Use a [`KafkaOffsetSample`](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection) with the `CONSUMER_OFFSET=true` flag. Note that it must be in a separate instance because when this flag is activated, the instance will not collect other samples.
  </Collapser>

  <Collapser
    id="producer"
    title="Producer and consumer monitoring (JMX)"
  >
    You can also monitor producers and consumers written in Java to get more specific metadata through the same mechanism (JMX). This will generate `KafkaConsumerSamples` and `KafkaProducerSamples`. JMX needs to be enabled and configured on those applications where it is not enabled by default.

    Non-Java producers and consumers don't support JMX and are therefore not supported by the Kafka integration.
  </Collapser>
</CollapserGroup>

<Callout variant="caution">
  On-host integrations don't update automatically. For best results, regularly update the [integration package](/docs/infrastructure/host-integrations/installation/update-infrastructure-host-integration-package/) and the [infrastructure agent](/docs/infrastructure/infrastructure-agent/update-or-uninstall/update-infrastructure-agent/kafka-config.yml).
</Callout>


## Start our interactive instructions

This page is interactive, which means you'll have to select options related to your environment so we can give you specific steps to install the Kafka integration. After you make your selections, you'll get customized steps for your environment. If you change your mind after making some selections, click <DNT>**Reset the form**</DNT> to start again:

<ButtonLink
  role="button"
  to="/install/kafka"
  variant="primary"
>
  Reset the form
</ButtonLink>


