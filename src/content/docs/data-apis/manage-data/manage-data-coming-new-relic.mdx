---
title: Understand and manage data ingest
tags:
  - Ingest and manage data
  - Manage data
  - Data Ingest Governance
metaDescription: 'How to understand and manage your New Relic data ingest.'
redirects:
  - /docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic
  - /docs/manage-data-coming-new-relic
  - /docs/telemetry-data-platform/get-started/manage-data/manage-data-coming-in
  - /docs/manage-data-coming-in
  - /docs/telemetry-data-platform/get-data-new-relic/manage-data/manage-data-coming-new-relic
  - /telemetry-data-platform/get-started/manage-data/manage-data-coming-in
---

import dataIngestSourceAccount from 'images/data-ingest-source-account.gif'

import dataFacet from 'images/data-facet.png'

When you report data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our [usage-based pricing model](/docs/accounts/accounts-billing/new-relic-one-pricing-users/pricing-billing), you're charged for the number of bytes written to our database that are above and beyond the free per-month amount.

If you're trying to estimate the cost of your data ingest, see [Estimate data ingest](https://newrelic.com/blog/nerdlog/estimate-data-cost).

## Data ingestion UI [#ui]

To learn how to easily analyze the data your account is ingesting, watch this short video (3:18 minutes).

<Video
  id="3mDiExsIjhE"
  type="youtube"
/>

The **Data ingestion** tab is located in the [Data management UI](/docs/data-apis/manage-data/manage-your-data). The **Data ingestion** UI shows your ingest rates for the time period specified by the time picker in the upper right.

The page shows your daily average GBs, and the total GBs for that time range. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively [manage your data ingest in various ways](#adjust-ingest).

To see the underlying NRQL query that is used to generate the chart, click **View query**.

<img
  title="data-ingest-source-account.gif"
  alt="Gif shows data ingestion with source and account views"
  src={dataIngestSourceAccount}
/>

<figcaption>
  From the [account dropdown](/docs/glossary/glossary/#account-dropdown), select **Manage your data**, and then select **Data ingestion**.
</figcaption>

<Callout variant="tip">
  For a deep dive into managing data ingest for a complex organization, see [Data ingest governance](/docs/new-relic-solutions/observability-maturity/operational-efficiency/intro-data-governance).
</Callout>

For how to get more details about ingested data, see [Get ingest details](#get-ingest-detail).

## Data ingestion sources [#sources-list]

The [data ingestion UI](#data-ingest-ui) chart shows you a high level breakdown of your billable data usage. The table below explains those sources. In this table, "usage metric group" refers to the value of that source's `usageMetric` attribute value on the `NrConsumption` event.

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Data sources
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Metrics
      </td>

      <td>
        In the data ingestion chart, **Metrics** is a combination of two types of metrics: [metric timeslice data](/docs/data-apis/understand-data/new-relic-data-types/#timeslice-data) and [dimensional metrics](/docs/data-apis/understand-data/new-relic-data-types/#dimensional-metrics).

        Usage metric group: `MetricsBytes`.

        Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days.

        You are only billed for the initial ingest volume. You are not billed for subsequent rollups.
      </td>
    </tr>

    <tr>
      <td>
        APM
      </td>

      <td>
        This includes [APM events](/docs/insights/insights-data-sources/default-data/apm-default-events-insights), like `Transaction` and `TransactionError`.

        Usage metric group: `ApmEventsBytes`.
      </td>
    </tr>

    <tr>
      <td>
        Infrastructure
      </td>

      <td>
        Includes several categories of [infrastructure monitoring events](/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-events), described below.
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure host data.

        Usage metric group:`InfraHostBytes`.

        Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data.
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure process data stored in `ProcessSample`.

        Usage metric group: `InfraProcessBytes`.

        Data related to each process running on the hosts running the infrastructure agent. This feature is turned off by default. For more information, see [Process metrics](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#enable-process-metrics).
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure integrations.

        Usage metric group: `InfraIntegrationBytes`.

        Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP.
      </td>
    </tr>

    <tr>
      <td>
        Logging
      </td>

      <td>
        Includes logs and any `Log_<value>` custom data partition created.

        Usage metric group: `LoggingBytes`.

        Log records are stored on the `Log` data type by default. Additional custom data partitions will create new data types, which are always prefixed with `Log_` and are counted as part of the overall set of log data stored.

        With `LogExtendedRecord`, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data.

        As of September 2021, log storage as blobs replaces `LogExtendedRecord`. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our [log blobs docs](/docs/logs/log-management/ui-data/long-logs-blobs).
      </td>
    </tr>

    <tr>
      <td>
        Default
      </td>

      <td>
        [Custom events](/docs/insights/insights-data-sources/custom-data/report-custom-event-data).

        Usage metric group: `CustomEventsBytes`
      </td>
    </tr>

    <tr>
      <td>
        Mobile events
      </td>

      <td>
        [Mobile events](/docs/insights/insights-data-sources/default-data/mobile-default-events-insights), including the general `Mobile` event, `MobileRequestError`, `MobileBreadcrumb`, `MobileSession`, `MobileHandledException`, `MobileCrash`, `MobileRequest`, and `MobileJavaScriptError`.

        Usage metric group: `MobileEventsBytes`.
      </td>
    </tr>
    <tr>
      <td>
        Tracing
      </td>

      <td>
        Usage metric group: `TracingBytes`. This includes the `Span` data type and OpenTelemetry's `SpanEvent`. You are not charged for `DistributedTraceSummary` events.
      </td>
    </tr>

    <tr>
      <td>
        Browser events
      </td>

      <td>
        [Browser events](/docs/insights/insights-data-sources/default-data/browser-default-events-insights), including the namespaces of `Browser`, `Browser:EventLog`, `Browser:JSErrors`, and `PcvPerf` (PageView timing).

        Usage metric group: `BrowserEventsBytes`.
      </td>
    </tr>

    <tr>
      <td>
        Lambda
      </td>

      <td>
        [AWS Lambda events](/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure).

        Usage metric group: `ServerlessBytes`.
      </td>
    </tr>
  </tbody>
</table>

## Understand where data is coming from [#get-ingest-detail]

You can inspect your data ingest to gain more information about your ingest health.

From the data ingestion UI page, you can analyze your usage in more detail. Spending some time understanding your ingested data and where it comes from and how it changes over time can be valuable. You'll know your ingest anomalies, and you'll be able to more easily spot anomalies, like ingest spikes, and understand their source.

On the data ingestion chart, time is on the X axis and the bands representing data sources are located along the Y axis. Click on a data source band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate.

<img
  title="data-facet.png"
  alt="screenshot of data facet selection"
  src={dataFacet}
/>

<figcaption>
  This image shows the data source band for June 15 right before it's clicked.
</figcaption>

A modal opens with the account, data source, and facet selected. You can do a handful of things on this page:

* Change the account, data source, or facet you want to drill down into.
* Change the time range.
* Review the results of the query in chart form. The chart displays the top 15 results for the facet query.
* Open the NRQL query in the **Query builder** where you'll find additional facets that you can use.

For more about creating more detailed queries:

* Learn some [NRQL basics](/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/).
* See some [example usage-related queries](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/#data-queries).

### How ingested data is broken down

Some of the usage data in this UI can vary depending on your account. This information is intended to help you understand how we're working with your ingest data:

* The chart on the **Data ingestion** page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem.
* If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a one hour period.
* The ingest value provided on the main **Data ingestion** chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate.

## Set alerts for data use [#set-alerts]

For how to set alerts that will notify you when you're reaching data ingest levels you don't want to cross, see [Query and alert on usage data](/docs/accounts/accounts-billing/new-relic-one-pricing-users/usage-queries-alerts). For example, you might set an alert on logs, which can accumulate quickly in an active system.

## Reduce your data ingest [#adjust-ingest]

All of the tools you use to report data to New Relic have various configuration options for adjusting the data reported. We'll give some of the more common methods for reducing data ingest here, but we recommend looking at the docs for the specific tools you're using to learn other options. 

### Drop unwanted data [#drop-data]

On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional [data dropping rules](/docs/accounts/accounts/data-management/drop-data-using-nerdgraph) yourself. For how to drop log data, see [Drop log data](/docs/logs/new-relic-logs/ui-data/drop-data-drop-filter-rules).

### Disable agents and integrations [#disable]

If you have agents or integrations that you don't need at all, you can uninstall/delete those tools. For instructions, see the specific docs for that tool.

### Adjust APM data ingest [#adjust-apm-ingest]

Options for adjusting APM data include:

* Configure the sampling rate for transaction events. See agent configurations for [Java](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Transaction_Events), [.Net](/docs/apm/agents/net-agent/configuration/net-agent-configuration), [Go](/docs/apm/agents/go-agent/configuration/go-agent-configuration#transaction-events-settings), [NodeJS](/docs/apm/agents/nodejs-agent/installation-configuration/nodejs-agent-configuration), [PHP](https://docs.newrelic.com/docs/apm/agents/php-agent/configuration/php-agent-configuration), [Python](/docs/apm/agents/python-agent/configuration/python-agent-configuration), and [Ruby](/docs/apm/agents/ruby-agent/configuration/ruby-agent-configuration).  
* [Set appropriate Apdex scores](/docs/apm/new-relic-apm/apdex/change-your-apdex-settings/), for example, for frequency of traces.
* Optimize [custom instrumentation](/docs/apm/agents/manage-apm-agents/agent-data/custom-instrumentation/) and/or [custom metrics](/docs/apm/agents/manage-apm-agents/agent-data/collect-custom-metrics/).

### Adjust infrastructure data ingest [#adjust-infra-ingest]

Options for adjusting infrastructure data include:

* Adjust [sampling rate](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings#samples-variables) for network, storage, and system events.
* [Disable process metrics](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#enable-process-metrics).
* Adjust polling intervals:
  * [Polling for cloud integrations](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations).
  * For on-host integrations: edit the configuration file for a specific integration.
* [Control the reporting of specific attributes](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#include-matching-metrics).
* Manage [Kubernetes events integration](/docs/kubernetes-pixie/kubernetes-integration/kubernetes-events/install-kubernetes-events-integration/#install).

### Adjust log data ingest [#adjust-log-ingest]

Options for adjusting log data ingest include:

* [Automatic logs in context](/docs/logs/logs-context/disable-automatic-logging): Disable or enable via the UI or API, or adjust client-side configuration settings.
* [Manual logs in context](/docs/logs/forward-logs/enable-log-management-new-relic): Adjust the log forwarder configuration to filter log events on the sending side.
* [Drop log data](/docs/logs/ui-data/drop-data-drop-filter-rules): Manage data ingest via the UI or API.

## Optimize your data ingest [#optimize-ingest]

We also have an [in-depth tutorial on how to optimize data ingest](/docs/new-relic-solutions/observability-maturity/operational-efficiency/intro-data-governance).  