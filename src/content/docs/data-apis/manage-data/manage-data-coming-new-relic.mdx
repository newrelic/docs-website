---
title: Manage data coming into New Relic
tags:
  - Ingest and manage data
  - Manage data
metaDescription: 'For accounts on the New Relic One pricing model: how we ingest and store and calculate ingested data.'
redirects:
  - /docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic
  - /docs/manage-data-coming-new-relic
  - /docs/telemetry-data-platform/get-started/manage-data/manage-data-coming-in
  - /docs/manage-data-coming-in
  - /docs/telemetry-data-platform/get-data-new-relic/manage-data/manage-data-coming-new-relic
  - /telemetry-data-platform/get-started/manage-data/manage-data-coming-in
---

When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our [New Relic One pricing model](/docs/accounts/accounts-billing/new-relic-one-pricing-users/pricing-billing), you're charged by the number of bytes written to our database, above and beyond the standard amount thatâ€™s free.

<Callout variant="important">
  This doc is for accounts on our [New Relic One pricing model](/docs/accounts/accounts-billing/new-relic-one-pricing-users/pricing-billing). If you're on our original product-based pricing model, see [Original pricing model](/docs/accounts/original-accounts-billing/product-pricing/product-based-pricing/). Not sure which you're on? See [Overview of pricing models](/docs/transition-guide-our-new-pricing-plan-user-model).
</Callout>

## Data ingestion page in UI [#ui]

To learn how to easily analyze the data your account is ingesting, watch this short video (3:18 minutes).

<Video id="3mDiExsIjhE" type="youtube" />

The **Data ingestion** tab is located in the [Data management UI](/docs/data-apis/manage-data/manage-your-data). The **Data ingestion** UI shows your ingest rates for the time period specified by the time picker in the upper right.

The page shows your daily average GBs, and the total GBs for that time range. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively [manage your data ingest in various ways](#adjust-ingest). 

To see the underlying NRQL query that is used to generate the chart, click **View query**. 

![Gif shows data ingestion with source and account views](./images/data-ingest-source-account.gif "data-ingest-source-account.gif")

<figcaption>
  From the [account dropdown](/docs/glossary/glossary/#account-dropdown), select **Manage your data**, and then select **Data ingestion**. 
</figcaption>

For how to get more detail about data ingest, see [Get ingest details](#get-ingest-detail).

## Data ingestion sources [#sources-list]

The [data ingestion UI](#data-ingest-ui) chart shows you a high level breakdown of your billable data usage. The table below explains those sources. The "usage metric group" refers to the value of that source's `usageMetric` attribute value on the `NrConsumption` event. 

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Data sources
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Metrics
      </td>

      <td>
        In the data ingestion chart, **Metrics** is a combination of two types of metrics: [metric timeslice data](/docs/data-apis/understand-data/new-relic-data-types/#timeslice-data) and [dimensional metrics](/docs/data-apis/understand-data/new-relic-data-types/#dimensional-metrics). 

        Usage metric group: `MetricsBytes`.

        Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days.

        You are only billed for the initial ingest volume. You are not billed for subsequent rollups.
      </td>
    </tr>

    <tr>
      <td>
        APM
      </td>

      <td>
        This includes [APM events](/docs/insights/insights-data-sources/default-data/apm-default-events-insights), like APM `Transaction` and `TransactionError`. 

        Usage metric group: `ApmEventsBytes`
      </td>
    </tr>

    <tr>
      <td>
        Infrastructure
      </td>

      <td>
        Includes several categories of [infrastructure monitoring events](/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-events), described below. 
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure host data.

        Usage metric group:`InfraHostBytes`.

        Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data.
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure process data stored in `ProcessSample`.

        Usage metric group: `InfraProcessBytes`.

        Data related to each process running on the hosts running the infrastructure agent. This feature is turned off by default. For more information, see [Process metrics](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#enable-process-metrics).
      </td>
    </tr>

    <tr>
      <td/>

      <td>
        Infrastructure integrations. 

        Usage metric group: `InfraIntegrationBytes`.

        Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP.
      </td>
    </tr>

    <tr>
      <td>
        Logging
      </td>

      <td>
        Includes logs and any `Log_<value>` custom data partition created.

        Usage metric group: `LoggingBytes`.

        Log records are stored on the `Log` data type by default. Additional custom data partitions will create new data types, which are always prefixed with `Log_` and are counted as part of the overall set of log data stored.

        With `LogExtendedRecord`, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data.

        As of September 2021, log storage as blobs replaces `LogExtendedRecord`. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our [log blobs docs](/docs/logs/log-management/ui-data/long-logs-blobs).
      </td>
    </tr>

    <tr>
      <td>
        Default
      </td>

      <td>
        [Custom events](/docs/insights/insights-data-sources/custom-data/report-custom-event-data).

        Usage metric group: `CustomEventsBytes`
      </td>
    </tr>

    <tr>
      <td>
 Mobile events
      </td>

      <td>
        [Mobile events](/docs/insights/insights-data-sources/default-data/mobile-default-events-insights), including the general `Mobile` event, `MobileRequestError`, `MobileBreadcrumb`, `MobileSession`, `MobileHandledException`, `MobileCrash`. 

        Usage metric group: `MobileEventsBytes`.
      </td>
    </tr>

    <tr>
      <td>
        Tracing
      </td>

      <td>
        Usage metric group: `TracingBytes`. This includes the `Span` data type and OpenTelemetry's `SpanEvent`. You are not charged for `DistributedTraceSummary` events.
      </td>
    </tr>

    <tr>
      <td>
Browser events
      </td>

      <td>
        [Browser events](/docs/insights/insights-data-sources/default-data/browser-default-events-insights), including Browser, Browser:EventLog, Browser:JSErrors, and PcvPerf (PageView timing). 
        
        Usage metric group: `BrowserEventsBytes`.
      </td>
    </tr>

    <tr>
      <td>
        Lambda
      </td>

      <td>
        [AWS Lambda events](/docs/serverless-function-monitoring/aws-lambda-monitoring/ui-data/understand-lambda-data-structure).

        Usage metric group: `ServerlessBytes`.
      </td>
    </tr>
  </tbody>
</table>

## Understand where data is coming from [#get-ingest-detail]

You can inspect your data ingest to gain more information about your ingest health. 

From the data ingestion UI page, you can analyze your usage in more detail. Spending some time understanding your ingested data and where it comes from and how it changes over time can be valuable. You'll know your ingest baselines, and you'll be able to more easily spot anomalies, like ingest spikes, and understand their source. 

On the data ingestion chart, time is on the X axis and the bands representing data sources are located along the Y axis. Click on a data source band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. 

![screenshot of data facet selection](./images/data-facet.png "data-facet.png")

<figcaption>
   This image shows the data source band for June 15 right before it's clicked. 
</figcaption>

A modal opens with the account, data source, and facet selected. You can do a handful of things on this page:

* Change the account, data source, or facet you want to drill down into.
* Change the time range.
* Review the results of the query in chart form. The chart displays the top 15 results for the facet query. 
* Open the NRQL query in the **Query builder** where you'll find additional facets that you can use.  

For more about queries: 
* Learn some [NRQL basics](/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/). 
* See some [example usage-related queries](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/#data-queries). 

### How we break your ingest data down

Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data.

* The chart on the **Data ingestion** page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem.
*  If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period.
* The ingest value provided on the main **Data ingestion** chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate.

## Set alerts for data use [#set-alerts]

[Query and alert on usage data](/docs/accounts/accounts-billing/new-relic-one-pricing-users/usage-queries-alerts) describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system.

## Adjust your data ingest [#adjust-ingest]

Here are some ideas for managing your data: 

### Drop unwanted data [#drop-data]

On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional [data dropping rules](/docs/accounts/accounts/data-management/drop-data-using-nerdgraph) yourself. For how to drop log data, see [Drop log data](/docs/logs/new-relic-logs/ui-data/drop-data-drop-filter-rules).

### Disable agents and integrations [#disable]

If you have agents or integrations that you don't need at all, you can uninstall/delete those tools. For instructions, see the specific docs for that tool.

### Adjust APM data ingest [#adjust-apm-ingest]

Options for adjusting APM data include:
* Configure the [sampling rate](/docs/agents/java-agent/configuration/java-agent-configuration-config-file#Transaction_Events) for transaction events.
* [Set appropriate Apdex scores](/docs/apm/new-relic-apm/apdex/change-your-apdex-settings/), for example, for frequency of traces.
* Optimize [custom instrumentation](/docs/apm/agents/manage-apm-agents/agent-data/custom-instrumentation/) and/or [custom metrics](/docs/apm/agents/manage-apm-agents/agent-data/collect-custom-metrics/).

### Adjust infrastructure data ingest [#adjust-infra-ingest]

Options for adjusting infrastructure data include: 
* Adjust [sampling rate](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings#samples-variables) for network, storage, and system events.
* [Disable process metrics](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#enable-process-metrics).
* Adjust [polling intervals](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations) for on-host and cloud integrations. 
* [Control the reporting of specific attributes.](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#include-matching-metrics)
* Manage [Kubernetes events integration](/docs/kubernetes-pixie/kubernetes-integration/kubernetes-events/install-kubernetes-events-integration/#install).

/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/#include-matching-metrics

### Adjust log data ingest [#adjust-log-ingest]

Options for adjusting log data ingest include: 
* Use the log forwarder to filter log events on the sending side.
* Drop log data, either [via the UI](/docs/logs/ui-data/drop-data-drop-filter-rules) or [with NerdGraph](/docs/data-apis/manage-data/drop-data-using-nerdgraph).
