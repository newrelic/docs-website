---
title: Create NRQL alert conditions
tags:
  - Alerts and applied intelligence 
  - Alerts
  - Alert conditions
translate:
  - jp
  - kr
metaDescription: How to define thresholds that trigger alert notifications based on your NRQL queries.
redirects:
  - /docs/new-relic-alerts-nrql-alerts
  - /docs/new-relic-alerts-alert-nrql-queries
  - /docs/alerts/new-relic-alerts/configuring-alert-policies/alert-conditions-nrql-queries
  - /docs/alerts/new-relic-alerts/configuring-alert-policies/create-alert-conditions-nrql-queries
  - /docs/alerts/new-relic-alerts/defining-conditions/create-alert-conditions-nrql-queries
---

import nr1NrqlAlertConditions from 'images/nr1_nrql_alert_conditions.webp'

import inContextDemo from 'images/in-context-demo.gif'

import signalLossUi0 from 'images/signal-loss-ui_0.webp'

import fineTuneSignals from 'images/fine-tune-signals.webp'

You can use [NRQL queries](/docs/insights/new-relic-insights/using-new-relic-query-language/using-nrql) to create alert conditions. Once you've defined your signal, you can further define your warning and critical threshold levels. This determines when an alerts incident is created.

Read on to learn more about how to do this.

<img
  title="An example NRQL condition and generated results."
  alt="A screenshot of an example NRQL condition and generated results."
  src={nr1NrqlAlertConditions}
/>

<figcaption>
  **[one.newrelic.com](https://one.newrelic.com/all-capabilities) > Alerts & AI > Alert conditions (Policies) > (select a policy) > Add a condition**. Click **NRQL**, and then **Next, define thresholds**.
</figcaption>

<Callout variant="tip">
  For more information on key concepts relating to NRQL alert conditions and streaming alerts, see [Streaming alerts: key terms and concepts](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts).
</Callout>

Ready to get started? If you haven't already, be sure to [sign up for a New Relic account](https://newrelic.com/signup). It's free, forever.

## Create a NRQL alert condition [#create]

To create a NRQL alert condition for a policy:

1. Go to **[one.newrelic.com](https://one.newrelic.com/all-capabilities) > Alerts & AI > Alert conditions (policies)**.
2. Select an existing policy or click **New alert policy** to [create a new policy](/docs/alerts-applied-intelligence/new-relic-alerts/alert-policies/create-edit-or-find-alert-policy).
3. Click **Add a condition**.
4. Under **Select a product** click **NRQL**, and then click **Next, define thresholds**.

Note that editing an existing condition can result in [resetting its evaluation](#evaluation-resets).

## Create a condition from a chart [#create-chart]

You can use a chart to create a NRQL alert condition.

<img
  title="Create a NRQL alerts condition from a chart."
  alt="Animated GIF showing how to create a NRQL alerts condition from a chart."
  src={inContextDemo}
/>

<figcaption>
  To create a NRQL alerts condition from a chart, click the chart menu <Icon name="fe-more-horizontal"/>, then click **Create alert condition**.
</figcaption>

Once you've named and customized your condition, you can add it to an existing policy or create a new one.

<Callout variant="caution">
  A small number of our older charts don't include the option to create an alert condition.
</Callout>

## NRQL alert syntax [#syntax]

Here's the basic syntax for creating all NRQL alert conditions.

```
SELECT function(attribute)
	FROM Event
	WHERE attribute [comparison] [AND|OR ...]
```

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        **Clause**
      </th>

      <th>
        **Notes**
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `SELECT function(attribute)`

        **Required**
      </td>

      <td>
        Supported functions that return numbers include:

        * `apdex`
        * `average`
        * `count`
        * `latest`
        * `max`
        * `min`
        * `percentage`
        * `percentile`
        * `sum`
        * `uniqueCount`

          <Callout variant="tip">
            If you use the `percentile` aggregator in a faceted alert condition with many facets, this may cause the following error to appear:

            `An error occurred while fetching chart data.`

            If you see this error, use `average` instead.
          </Callout>
      </td>
    </tr>

    <tr>
      <td>
        `FROM data type`

        **Required**
      </td>

      <td>
        Only one data type can be targeted.

        Supported data types:

        * `Event`
        * `Metric` (RAW data points will be returned)
      </td>
    </tr>

    <tr>
      <td>
        `WHERE attribute [comparison] [AND|OR ...]`
      </td>

      <td>
        Use the `WHERE` clause to specify a series of one or more conditions. All the [operators](/docs/insights/new-relic-insights/using-new-relic-query-language/nrql-reference#where-operators) are supported.
      </td>
    </tr>

    <tr>
      <td id="facet">
        `FACET` attribute
      </td>

      <td>
        Include an optional `FACET` clause in your NRQL syntax depending on the [threshold type](#threshold-types) (static or anomaly).

        Use the [`FACET`](/docs/insights/nrql-new-relic-query-language/nrql-resources/nrql-syntax-components-functions) clause to separate your results by attribute and alert on each attribute independently. No `LIMIT` clause is allowed, but all queries will receive the maximum number of facets possible.

        Faceted queries can return a maximum of 5000 values for [static and anomaly](/docs/alerts/new-relic-alerts/defining-conditions/create-alert-conditions-nrql-queries#threshold-types) conditions.

        <Callout variant="important">
          If the query returns more than the maximum number of values, the alert condition can't be created. If you create the condition and the query returns more than this number later, the alert will fail. Modify your query so that it returns a fewer number of values.
        </Callout>
      </td>
    </tr>
  </tbody>
</table>

## Reformatting incompatible NRQL [#reformatting]

Some elements of NRQL used in charts don’t make sense in the streaming context of alerts. Here’s a list of the most common incompatible elements and suggestions for reformatting a NRQL alert query to achieve the same effect.

<table>
  <thead>
    <tr>
      <th style={{ width: "300px" }}>
        **Element**
      </th>

      <th>
        **Notes**
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `SINCE` and `UNTIL`
      </td>

      <td>
        Example:

        ```
        SELECT percentile(largestContentfulPaint, 75) FROM PageViewTiming WHERE (appId = 837807) SINCE yesterday
        ```

        NRQL conditions produce a never-ending stream of windowed query results, so the `SINCE` and `UNTIL` keywords to scope the query to a point in time are not compatible. As a convenience, we automatically strip `SINCE` and `UNTIL` from a query when creating a condition from the context of a chart.
      </td>
    </tr>

    <tr>
      <td>
        `TIMESERIES`
      </td>

      <td>
        In NRQL queries, the `TIMESERIES` clause is used to return data as a time series broken out by a specified period of time.

        For NRQL conditions, the equivalent property of a signal is the aggregation duration window.
      </td>
    </tr>

    <tr>
      <td>
        `histogram()`
      </td>

      <td>
        The `histogram()` aggregation function is used to generate histograms.

        `histogram()` is not compatible with NRQL alerting: histogram aggregations can not be formatted as a time series. To create an alert from a portion of a histogram (for example, 95th percentile), use the [`percentile()`](/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#functions) aggregation function.
      </td>
    </tr>

    <tr>
      <td>
        `bytecountestimate()`, `cardinality()`
      </td>

      <td>
        These functions are not yet supported for NRQL alerting.
      </td>
    </tr>

    <tr>
      <td>
        Multiple aggregation functions
      </td>

      <td>
        Each condition can only target a single aggregated value. To alert on multiple values simultaneously, you’ll need to decompose them into individual conditions within the same policy.

        Original Query:

        ```
        SELECT count(foo), average(bar), max(baz) from Transaction
        ```

        Decomposed:

        ```
        SELECT count(foo) from Transaction

        SELECT average(bar) from Transaction

        SELECT max(baz) from Transaction
        ```
      </td>
    </tr>

    <tr>
      <td>
        `COMPARE WITH`
      </td>

      <td>
        The `COMPARE WITH` clause is used to compare the values for two different time ranges. This type of query is incompatible with NRQL alerting. We recommend using a [Anomaly Alert Condition](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-anomaly-alert-conditions) to dynamically detect deviations for a particular signal.
      </td>
    </tr>

    <tr>
      <td>
        `SLIDE BY`
      </td>

      <td>
        The `SLIDE BY` clause supports a feature known as [sliding windows](#sliding-window-aggregation). With sliding windows, `SLIDE BY` data is gathered into "windows" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time.

        You can enable sliding windows in the UI. When creating or editing a condition, go to **Fine-tune advanced signal settings > Data aggregation settings > Use sliding window aggregation**.
      </td>
    </tr>

    <tr>
      <td>
        `LIMIT`
      </td>

      <td>
        In NRQL queries, the LIMIT clause is used to control the amount of data a query returns, either the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT \* queries.

        LIMIT is not compatible with NRQL alerting: evaluation is always performed on the full result set.
      </td>
    </tr>

    <tr>
      <td>
        Subqueries
      </td>

      <td>
        [Subqueries](/docs/query-your-data/nrql-new-relic-query-language/get-started/subqueries-in-nrql) are not compatible with streaming alerts because subquery execution requires multiple passes through data.
      </td>
    </tr>
  </tbody>
</table>

## NRQL alert threshold examples [#examples]

Here are some common use cases for NRQL conditions. These queries will work for static and anomaly [condition types](#threshold-types).

<CollapserGroup>
  <Collapser
    id="constrained-alerts"
    title="Alert on specific segments of your data"
  >
    Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the `WHERE` clause to define those conditions.

    ```
    SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230)
    ```

    ```
    SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%'
    ```
  </Collapser>

  <Collapser
    id="nth-percentile"
    title="Alert on Nth percentile of your data"
  >
    Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately.

    ```
    SELECT percentile(duration, 95) FROM Transaction
    ```

    ```
    SELECT percentile(databaseDuration, 75) FROM Transaction
    ```
  </Collapser>

  <Collapser
    id="max-min-avg"
    title="Alert on max, min, avg of your data"
  >
    Create alerts when your data hits a certain maximum, minimum, or average; for example, ensuring that a duration or response time does not pass a certain threshold.

    ```
    SELECT max(duration) FROM Transaction
    ```

    ```
    SELECT average(duration) FROM Transaction
    ```
  </Collapser>

  <Collapser
    id="percentage"
    title="Alert on a percentage of your data"
  >
    Create alerts when a proportion of your data goes above or below a certain threshold.

    ```
    SELECT percentage(count(*), WHERE duration > 2) FROM Transaction
    ```

    ```
    SELECT percentage(count(*), WHERE http.statusCode = '500') FROM Transaction
    ```
  </Collapser>

  <Collapser
    id="apdex"
    title="Alert on Apdex with any T-value"
  >
    Create alerts on [Apdex](/docs/apm/new-relic-apm/apdex/apdex-measuring-user-satisfaction), applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8.

    ```
    SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%'
    ```
  </Collapser>
</CollapserGroup>

## NRQL conditions and query order of operations [#query-order]

By default, the aggregation window duration is 1 minute, but you can change the window to suit your needs. Whatever the aggregation window, New Relic will collect data for that window using the function in the NRQL condition’s query. The query is parsed and executed by our systems in the following order:

1. `FROM` clause – which event type needs to be grabbed?
2. `WHERE` clause – what can be filtered out?
3. `SELECT` clause – what information needs to be returned from the now-filtered data set?

### Example: null value returned [#example-null]

Let's say this is your alert condition query:

```
SELECT count(*) FROM SyntheticCheck WHERE monitorName = 'My Cool Monitor' AND result = 'FAILURE'
```

If there are no failures for the aggregation window:

1. The system will execute the `FROM` clause by grabbing all `SyntheticCheck` events on your account.
2. Then it will execute the `WHERE` clause to filter through those events by looking only for the ones that match the monitor name and result specified.
3. If there are still events left to scan through after completing the `FROM` and `WHERE` operations, the `SELECT` clause will be executed. If there are no remaining events, the `SELECT` clause will not be executed.

This means that aggregators like `count()` and `uniqueCount()` will never return a zero value. When there is a count of 0, the `SELECT` clause is ignored and no data is returned, resulting in a value of `NULL`.

### Example: zero value returned [#example-zero]

If you have a data source delivering legitimate numeric zeroes, the query will return zero values and not null values.

Let's say this is your alert condition query, and that `MyCoolEvent` is an attribute that can sometimes return a zero value.

```
SELECT average(MyCoolAttribute) FROM MyCoolEvent
```

If, in the aggregation window being evaluated, there's at least one instance of `MyCoolEvent` and if the average value of all `MyCoolAttribute` attributes from that window is equal to zero, then a `0` value will be returned. If there are no `MyCoolEvent` events during that minute, then a `NULL` will be returned due to the order of operations.

### Example: null vs. zero value returned [#example-null-zero]

To determine how null values will be handled, adjust the loss of signal and gap filling settings in the [Alert conditions UI](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/#signal-loss).

You can avoid `NULL` values entirely with a query order of operations shortcut. To do this, use a `filter` sub-clause, then include all filter elements within that sub-clause. The main body of the query will run and return data, at which point the `SELECT` clause will then run and apply the filter elements. The query will return a value of `0` if the filter elements result in no matching data. Here's an example:

```
SELECT filter(count(*), WHERE result = 'SUCCESS' AND monitorName = 'My Favorite Monitor') FROM SyntheticCheck
```

For more information, check out our [blog post](https://discuss.newrelic.com/t/relic-solution-how-can-i-figure-out-when-to-use-gap-filling-and-loss-of-signal/120401) on troubleshooting for zero versus null values.

## Nested aggregation NRQL alerts [#h2-nested-aggregation-nrql-alerts]

[Nested aggregation queries](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nested-aggregation-make-ordered-computations-single-query) are a powerful way to query your data. However, they have a few restrictions that are important to note.

<CollapserGroup>
  <Collapser
    id="non-faceted_innermost_query"
    title="Nested queries with a non-faceted innermost query are not currently supported"
  >
    Without a `FACET`, the inner query produces a single result, giving the outer query nothing to aggregate. If you're using a nested query, make sure your inner query is faceted.

    ```
    SELECT max(cpu) FROM (FROM SystemSample SELECT min(cpuPercent) as 'cpu' FACET hostname) ​​​​​
    ```
  </Collapser>

  <Collapser
    id="aggregation_window_size"
    title="Queries at all levels must have the same aggregation window size"
  >
    With an alert aggregation window of 1 minute, the inner query would produce two smaller windows of 30 seconds. In theory, these two windows could be aggregated by the outer query. However, this is not currently supported.

    ```
    SELECT max(cpu) FROM (FROM Event SELECT min(cpuTime) as cpu TIMESERIES 30 seconds)​​
    ```
  </Collapser>

  <Collapser
    id="signal_loss"
    title="Signal loss is not yet supported for nested queries"
  >
    For more information on signal loss, see [NerdGraph API: Loss of signal and gap filling](/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling).
  </Collapser>

  <Collapser
    id="with_metric_format"
    title="Nested queries on metric timeslice data are not currently supported"
  >
    Nested queries for [metric timeslice](/docs/data-apis/understand-data/new-relic-data-types/#timeslice-data) isn't supported. More specifically, these terms are not allowed in the inner query of NRQL alert conditions:
    * `WITH METRIC_FORMAT`
    * `metricTimesliceName`
    * `keyset`, `uniques`, `nativesizeestimate`, or `bytecountestimate` called on the `Metric` type
    * `newrelic.timeslice.value`
    * `apm.service.*`, `apm.browser.*` , `apm.mobile.*`, `apm.key.transaction.*`
  </Collapser>
</CollapserGroup>

## NRQL condition creation tips [#condition-tips]

Here are some tips for creating and using a NRQL condition:

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Topic
      </th>

      <th>
        Tips
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Condition types
      </td>

      <td>
        NRQL condition types include [static and anomaly](#threshold-types).
      </td>
    </tr>

    <tr>
      <td>
        Create a description
      </td>

      <td>
        For NRQL conditions, you can create a custom [description](/docs/alerts/new-relic-alerts/defining-conditions/alert-condition-descriptions) to add to each violation. Descriptions can be enhanced with variable substitution based on metadata in the specific violation.

        For details, see [Description](/docs/alerts/new-relic-alerts/defining-conditions/alert-condition-descriptions)
      </td>
    </tr>

    <tr>
      <td>
        Query results
      </td>

      <td>
        Queries must return a number. The condition evaluates the returned number against the thresholds you've set.
      </td>
    </tr>

    <tr>
      <td>
        Time period
      </td>

      <td>
        NRQL conditions evaluate data based on how it's aggregated, using aggregation windows from 30 seconds to 120 minutes, in increments of 15 seconds. For best results, we recommend using the event flow or event timer aggregation methods.

        For the cadence aggregation method, the implicit `SINCE ... UNTIL` clause specifying which minute to evaluate is controlled by your [**delay/timer**](#time) setting. Since very recent data may be incomplete, you may want to query data from 3 minutes ago or longer, especially for:

        * Applications that run on multiple hosts.
        * `SyntheticCheck` data: Timeouts can take 3 minutes, so 5 minutes or more is recommended.

          Also, if a query will generate intermittent data, consider using the advanced signal [`slide by`](#sliding-window-aggregation) option.
      </td>
    </tr>

    <tr>
      <td>
        Lost signal threshold
        (loss of signal detection)
      </td>

      <td>
        You can use loss of signal detection to alert on when your data (a telemetry signal) should be considered lost. A signal loss can indicate that a service or entity is no longer online or that a periodic job failed to run. You can also use this to make sure that violations for sporadic data, such as error counts, are closed when no signal is coming in.
      </td>
    </tr>

    <tr>
      <td>
        Advanced signal settings
      </td>

      <td>
        These settings give you options for better handling continuous, streaming data signals that may sometimes be missing. These settings include the aggregation window duration, the delay/timer, and an option for filling data gaps. For more on using these, see [Advanced signal settings](#advanced-signal).
      </td>
    </tr>

    <tr>
      <td>
        Condition settings
      </td>

      <td>
        Use the **Condition settings** to:

        * Create a concise, descriptive [condition name](/docs/alerts/new-relic-alerts/configuring-alert-policies/define-alert-conditions#rename-condition).
        * Provide a [custom violation description for the condition](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/alert-custom-violation-descriptions) that will be included in violations and notifications.
        * Add the runbook URL to include your organization's procedures for handling incidents. You may also add this information to the [custom violation description](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/alert-custom-violation-descriptions).
      </td>
    </tr>

    <tr>
      <td>
        Limits on conditions
      </td>

      <td>
        See the [maximum values](/docs/alerts/new-relic-alerts/getting-started/minimum-maximum-values).
      </td>
    </tr>

    <tr>
      <td>
        Health status
      </td>

      <td>
        In order for a NRQL alert condition [health status display](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/view-entity-health-status-find-entities-without-alert-conditions) to function properly, the query must be scoped to a single entity. To do this, either use a WHERE clause (for example, `WHERE appName = 'MyFavoriteApp'`) or use a FACET clause to scope each signal to a single entity (for example, `FACET hostname` or `FACET appName`).
      </td>
    </tr>

    <tr>
      <td>
        Examples
      </td>

      <td>
        For more information, see:

        * [Expected NRQL syntax](#syntax)
        * [Examples of NRQL condition queries](#examples)
      </td>
    </tr>
  </tbody>
</table>

## Managing tags on conditions [#condition-edit]

When you edit an existing NRQL condition, you have the option to add or remove tags associated with the condition entity. To do this, click the **Manage tags** button below the condition name. In the menu that pops up, add or delete a tag.

## Condition edits can reset condition evaluation [#evaluation-resets]

When you edit NRQL alert conditions in some specific ways (detailed below), their evaluations are reset, meaning that any evaluation up until that point is lost, and the evaluation starts over from that point. The two ways this will affect you are:

* For "for at least x minutes" thresholds: because the evaluation window has been reset, there will be a delay of at least x minutes before any violations can be reported.
* For [anomaly conditions](#threshold-types): the condition starts over again and all anomaly learning is lost.

The following actions cause an evaluation reset for NRQL conditions:

* Changing the query
* Changing the aggregation window, aggregation method, or aggregation delay/timer setting
* Changing the "close violations on signal loss" setting
* Changing any gap fill settings
* Changing the anomaly direction (if applicable) – higher, lower, or higher/lower
* Change the threshold value, threshold window, or threshold operator
* Change the slide-by interval (on [sliding windows aggregation](https://docs.newrelic.com/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/#sliding-window-aggregation) conditions only)

The following actions (along with any other actions not covered in the above list) will **not** reset the evaluation:

* Changing the loss of signal time window (expiration duration)
* Changing the time function (switching "for at least" to "at least once in," or vice-versa)
* Toggling the "open violation on signal loss" setting

## Alert condition types [#threshold-types]

When you create a NRQL alert, you can choose from different types of conditions:

<table>
  <thead>
    <tr>
      <th style={{ width: "150px" }}>
        NRQL alert condition types
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Static
      </td>

      <td>
        This is the simplest type of NRQL condition. It allows you to create a condition based on a NRQL query that returns a numeric value.

        Optional: Include a `FACET` clause.
      </td>
    </tr>

    <tr>
      <td>
        [Anomaly](/docs/alerts/new-relic-alerts/defining-conditions/create-anomaly-alert-conditions)
        (Dynamic anomaly)
      </td>

      <td>
        Uses a self-adjusting condition based on the past behavior of the monitored values. Uses the same NRQL query form as the static type,
        including the optional `FACET` clause.
      </td>
    </tr>
  </tbody>
</table>

## Set the loss of signal threshold [#signal-loss]

<Callout variant="important">
  The loss of signal feature requires a signal to be present before it can detect that the signal is lost. If you enable a condition while a signal is not present, no loss of signal will be detected and the loss of signal feature will not activate.
</Callout>

Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed.

<img
  title="signal-loss-ui.png"
  alt="signal-loss-ui.png"
  src={signalLossUi0}
/>

<figcaption>
  Go to **[one.newrelic.com](https://one.newrelic.com/all-capabilities) > Alerts & AI > Alert conditions (Policies) > (select a policy)**, then **Add a condition**. Loss of signal is only available for NRQL conditions.
</figcaption>

You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific [GraphQL API examples](/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling).

**Loss of signal settings:**

Loss of signal settings include a time duration and two possible actions.

* **Signal loss expiration time**
  * UI label: **Signal is lost after:**
  * GraphQL Node: [expiration.expirationDuration](/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling)
  * Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the `WHERE` clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal.
  * The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires.
  * The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes.
* **Loss of signal actions**
  Once a signal is considered lost, you can close open violations, open new violations, or both.
  * Close all current open violations: This closes all open violations that are related to a specific signal. It won't necessarily close all violations for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that violations are closed properly. The GraphQL node name for this is ["closeViolationsOnExpiration](/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling)"
  * Open new violations: This will open a new violation when the signal is considered lost. These violations will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this [is "openViolationOnExpiration](/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling)"
  * When you enable both actions, we'll close all open violations first, and then open a new violation for loss of signal.

To create a NRQL alert configured with loss of signal detection in the UI:

1. For a policy, when you create a condition, under **Select a product**, click **NRQL**, then click **Next, define thresholds**.
2. Write a [NRQL query](/docs/alerts/new-relic-alerts/defining-conditions/create-alert-conditions-nrql-queries#syntax) that returns the values you want to alert on.
3. For **Threshold type**, select **Static** or **Anomaly**.
4. Click **+ Add lost signal threshold**, then set the signal expiration duration time in minutes or seconds in the **Signal is lost after** field.
5. Choose what you want to happen when the signal is lost. You can check one or both of **Close all current open violations** and **Open new "lost signal" violation**. These control how loss of signal violations will be handled for the condition.
6. Make sure you name your condition before you save it.

Violations open due to loss of signal close when

* the signal comes back. Newly opened lost signal violations will close immediately when new data is evaluated.
* the condition they belong to expires. By default, conditions expire after 3 days.
* you manually close the violation with the **Close all current open violations** option.

<Callout variant="tip">
  Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries.
</Callout>

## Advanced signal settings [#advanced-signal]

<img
  title="Screenshot showing advanced signal settings"
  alt="Screenshot showing advanced signal settings"
  src={fineTuneSignals}
/>

<figcaption>
  When creating a NRQL alert condition, use the advanced signal settings to control [streaming alert data](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts) and  avoid false alarms.
</figcaption>

When creating a NRQL condition, there are several advanced signal settings:

* Aggregation window duration
* Sliding window aggregation
* Streaming method
* Delay/timer
* Fill data gaps

To read an explanation of what these settings are and how they relate to each other, see [Streaming alerts concepts](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts). Below are instructions and tips on how to configure them.

### Aggregation window duration [#window-duration]

You can set the [aggregation window duration](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts#aggregation-window) to choose how long data is accumulated in a streaming time window before it's aggregated. You can set it to anything between 30 seconds and 120 minutes. The default is one minute.

### Sliding window aggregation [#sliding-window-aggregation]

You can use [sliding windows](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows) to create smoother charts. This is done by creating overlapping windows of data.

Learn how to set sliding windows in this short video (2:30 minutes):

<Video
  id="-5--8DZynFE"
  type="youtube"
/>

Once enabled, set the "slide by interval" to control how much overlap time your aggregated windows have. The interval must be shorter than the aggregation window while also dividing evenly into it.

<Callout variant="important">
  Immediately after you create a new sliding windows alert condition or perform any action that can cause an [evaluation reset](#evaluation-resets), your condition will need time build up an "aggregated buffer" for the duration of the first aggregation window. During that time, no violations will trigger. Once that single aggregation window has passed, a complete "buffer" will have been built and the condition will function normally.
</Callout>

### Streaming method [#streaming]

Choose between [three streaming aggregation methods](/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/#aggregation-methods) to get the best evaluation results for your conditions.

### Delay/timer [#delay-timer]

You can adjust the [delay/timer](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts#delay-timer) to coordinate [our streaming alerting algorithm](/docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts) with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method.

For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay.

If the data type comes from an [APM language agent](/docs/apm/new-relic-apm/getting-started/introduction-apm) and is aggregated from many app instances (for example, `Transactions`, `TransactionErrors`, etc.), we recommend using the event flow method with the default settings.

<Callout variant="important">
  When creating NRQL conditions for data collected from [Infrastructure Cloud Integrations](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations) such as AWS CloudWatch or Azure, we recommend that you use the event timer method.
</Callout>

### Fill data gaps [#data-gaps]

Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings:

* **None**: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be in violation.
* **Custom static value**: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of `fillValue` (as named in the API) that specifies what static value should be used. This defaults to `0`.
* **Last known value**: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for 2 hours.

<Callout variant="tip">
  The alerts system fills gaps in actively reported signals. This signal history is dropped after 2 hours of inactivity. For gap filling, data points received after this period of inactivity are treated as new signals.

  To learn more about signal loss, gap filling, and how to request access to these features, see [this Support Forum post](https://discuss.newrelic.com/t/announcing-new-relic-one-streaming-alerts-for-nrql-conditions/115361).
</Callout>

Options for editing data gap settings:

* In the NRQL conditions UI, go to **Condition settings > Advanced signal settings > fill data gaps with** and choose an option.
* If using our [Nerdgraph API](/docs/alerts-applied-intelligence/new-relic-alerts/alerts-nerdgraph/nerdgraph-api-loss-signal-gap-filling) (preferred), this node is located at:
  `actor : account : alerts : nrqlCondition : signal : fillOption | fillValue`
* NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the **"signal"** section of [the Alert NRQL conditions API](https://rpm.newrelic.com/api/explore/alerts_nrql_conditions/list).
