---
title: ktranslate Docker container health monitoring
tags:
  - Integrations
  - Network Performance Monitoring
metaDescription: Monitoring and troubleshooting the health of your ktranslate container.
---

While running the **ktranslate** Docker container for New Relic network performance monitoring, you can monitor the health of the container to proactively detect potential issues.

The **ktranslate** container image has the `-tee_logs=true` and `-metrics=jchf` settings available during runtime, which allow it to send health metrics into New Relic One directly. These are enabled by default when installing network performance monitoring via the New Relic One guided install. We recommend you to set them up when installing network performance monitoring manually.

### Logs from ktranslate [#logs] 

<Callout variant="tip">
  If you want to check the logs locally from the Docker host, run `docker logs $CONTAINER_NAME`. For example, `docker logs ktranslate-snmp`.
</Callout>

The `-tee_logs=true` option sends logs to New Relic One when polling devices. To see them, do the following:

1. Go to [one.newrelic.com](https://one.newrelic.com/) > **Logs**.
2. In **Find logs where**, enter `collector.name:"ktranslate"` and click **Query logs**.

#### Optional log parsing rule [#log-parsing]

We recommend you to add a [parsing rule](/docs/logs/log-management/ui-data/parsing) to New Relic One logs to break the logs from **ktranslate** into fields that are easily searchable. This is especially helpful when you are running more than one container as it allows you to then search by the value of `--service_name` from the Docker container.

Using the [New Relic One logs UI](/docs/logs/log-management/ui-data/parsing), use the following patterns: 

```
Rule Name: ktranslate-health logs
Query Attribute: "plugin.type"
Query Value: "ktranslate-health"
Parsing logic: %{NOTSPACE:time} ktranslate/%{NOTSPACE:container_service} \[%{NOTSPACE:severity}\] %{GREEDYDATA:message}
```

Alternatively, you can use [New Relic's Nerdgraph API to manage your parsing rules](/docs/apis/nerdgraph/examples/nerdgraph-log-parsing-rules-tutorial/). A sample of the `logConfigurationsCreateParsingRule` is below, you will need to replace `$ACCOUNT_ID` with the ID of your target account.

```sql
mutation {
  logConfigurationsCreateParsingRule(
    accountId: $ACCOUNT_ID, 
    rule: {
      description: "ktranslate-health logs", 
      enabled: true, 
      grok: "%{NOTSPACE:time} ktranslate/%{NOTSPACE:container_service} \\[%{NOTSPACE:severity}\\] %{GREEDYDATA:message}", 
      lucene: "\"plugin.type\":\"ktranslate-health\"", 
      nrql: "SELECT * FROM Log WHERE `plugin.type` = 'ktranslate-health'"
    }
  ) 
  {
    errors {
      message
      type
    }
    rule {
      accountId
      id
      enabled
      description
      grok
      lucene
      nrql
    }
  }
}
```

The result of this parsing rule is splitting a raw message from this:

```json
{
  "collector.name": "ktranslate",
  "instrumentation.provider": "kentik",
  "message": "2021-12-08T14:59:56.007 ktranslate/snmp [Info] nrmFormat New Metadata for cisco-7513",
  "newrelic.source": "api.logs",
  "plugin.type": "ktranslate-health",
  "timestamp": 1638975596000
}
```

To this, creating the searchable fields of `container_service`, `severity`, and `time`; as well as trimming the `message` field to more actionable data:

```json
{
  "collector.name": "ktranslate",
  "container_service": "snmp",
  "instrumentation.provider": "kentik",
  "message": "nrmFormat New Metadata for cisco-7513",
  "newrelic.source": "api.logs",
  "plugin.type": "ktranslate-health",
  "severity": "Info",
  "time": "2021-12-08T15:29:56.026",
  "timestamp": 1638977396000
}
```

#### Common log searches [#common-log-searches]

Below are some common searches that can be used during troubleshooting to gather data for support:

<CollapserGroup>
  <Collapser
    id="container-version"
    title="What version of ktranslate am I running?"
  >

    Logs UI:

    ```shell
    collector.name:"ktranslate" message:"*KTranslate Running -- Version*"
    ```

    NRQL:

    ```sql
    FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` LIKE '%KTranslate Running -- Version%'
    ```

    Expected Results:

    ```shell
    KTranslate Running -- Version kt-2021-12-06-1546870234; Build Mon Dec  6 22:22:56 UTC 2021
    ```

  </Collapser>
  <Collapser
    id="docker-arguments"
    title="What arguments were passed to Docker at runtime?"
  >

    Logs UI:

    ```shell
    collector.name:"ktranslate" message:"*KTranslate CLI:*"
    ```

    NRQL:

    ```sql
    FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` LIKE '%KTranslate CLI:%'
    ```

    Expected Results:

    ```shell
    KTranslate CLI: [ktranslate -listen off -mapping /etc/ktranslate/config.json -geo /etc/ktranslate/GeoLite2-Country.mmdb -udrs /etc/ktranslate/udr.csv -api_devices /etc/ktranslate/devices.json -asn /etc/ktranslate/GeoLite2-ASN.mmdb -log_level info -snmp /snmp-base.yaml -nr_account_id=2583772 -log_level=info -metrics=jchf -tee_logs=true -service_name=snmp nr1.snmp]
    ```

  </Collapser>
  <Collapser
    id="container-errors"
    title="What errors am I experiencing?"
  >
    - Without a parsing rule applied to your logs

    Logs UI:

    ```shell
    collector.name:"ktranslate" message:-*\[Info\]*
    ```

    NRQL:

    ```sql
    FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` NOT LIKE '%[Info]%'
    ```

    - With a parsing rule applied to your logs

    Logs UI:

    ```shell
    collector.name:"ktranslate" severity:-"Info"
    ```

    NRQL:

    ```sql
    FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `severity` != 'Info'
    ```

    Expected Results:

    ```shell
    KTranslate>cisco-7513 There was an SNMP polling error with the CustomDeviceMetrics walking OID .1.3.6.1.2.1.4.31.1.1.21 after 0 retries: request timeout (after 0 retries).
    ``` 

  </Collapser>
  <Collapser
    id="match_attributes"
    title="Is my match_attributes filter working on my device?"
  >

    Logs UI:

    ```shell
    collector.name:"ktranslate" message:"*Match Attribute*"
    ```

    NRQL:

    ```sql
    FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` LIKE '%Match Attribute%'
    ```

    Expected Results:

    ```shell
    KTranslate>cisco-7513 Added 1 Match Attribute(s)
    ```

    All devices are expected to have at least 1 Match Attribute inherited from the default `monitor_admin_shut: true` configuration. You should expect a value of `2` to be shown for a device that you have added a single match attribute to.

    <Callout variant="tip">
      You can further filter these results by adding the device name to your query: `collector.name:"ktranslate" message:"*$DEVICE_NAME*Match Attribute*"`.
    </Callout>
  </Collapser>
</CollapserGroup>

### Metrics from ktranslate [#metrics]

The `-metrics` option captures the following performance metrics when polling devices:

<table>
  <thead>
    <tr>
      <th style={{ width: "400px" }}>
        Metric
      </th>
      <th>
        Granularity
      </th>
      <th>
        Description
      </th>
    </tr>
  </thead>
    <tbody>
    <tr>
      <td>
        `baseserver_healthcheck_execution_total`
      </td>
      <td>
        Top Level
      </td>
      <td>
        Rate of internal health checks. Shows mostly that things are not deadlocked and should always be less than 0.
      </td>
    </tr>
    <tr>
      <td>
        `inputq`
      </td>
      <td>
        Top Level
      </td>
      <td>
        Messages per second (msg/sec) received over the last 60 seconds from all SNMP, Flow, and VPC inputs combined.
      </td>
    </tr>
    <tr>
      <td>
        `jchfq`
      </td>
      <td>
        Top Level
      </td>
      <td>
        Gauge rate with number of available pre-allocated buffers. It should be about 8,000.
      </td>
    </tr>
    <tr>
      <td>
        `delivery_metrics_nr`
      </td>
      <td>
        Delivery to New Relic One
      </td>
      <td>
        Batches per second (batches/sec) sent over the last 60 seconds for all metrics to New Relic One.
      </td>
    </tr>
    <tr>
      <td>
        `delivery_logs_nr`
      </td>
      <td>
        Delivery to New Relic One
      </td>
      <td>
        Logs per second (logs/sec) sent over the last 60 seconds for all logs to New Relic One.
      </td>
    </tr>
    <tr>
      <td>
        `delivery_wins_nr`
      </td>
      <td>
        Delivery to New Relic One
      </td>
      <td>
        Wins per second (wins/sec) of 200 HTTP codes received over the last 60 seconds from sending metrics and events to New Relic One.
      </td>
    </tr>
    <tr>
      <td>
        `device_metrics`
      </td>
      <td>
        SNMP
      </td>
      <td>
        Polls per second (polls/sec) of SNMP polling over the last 60 seconds for device level metrics.
      </td>
    </tr>
    <tr>
      <td>
        `interface_metrics`
      </td>
      <td>
        SNMP
      </td>
      <td>
        Polls per second (polls/sec) of SNMP polling over the last 60 seconds for interface level metrics.
      </td>
    </tr>
    <tr>
      <td>
        `snmp_fail`
      </td>
      <td>
        SNMP
      </td>
      <td>
        Gauge to monitor if SNMP polling is working faceted by `device_name`. Where 1 means good and 2 means fail.
      </td>
    </tr>
    <tr>
      <td>
        `netflow.flows`
      </td>
      <td>
        Netflow
      </td>
      <td>
        Flows per second (fps) received over the last 60 seconds for all device flow data: IPFIX, NetFlow, or sFlow.
      </td>
    </tr>
    <tr>
      <td>
        `syslog_queue`
      </td>
      <td>
        Syslog
      </td>
      <td>
        Gauge of syslog messages waiting to be processed.
      </td>
    </tr>
    <tr>
      <td>
        `syslog_errors`
      </td>
      <td>
        Syslog
      </td>
      <td>
        Errors per second (errors/sec) over the last 60 seconds while processing syslog messages.
      </td>
    </tr>
    <tr>
      <td>
        `syslog_messages`
      </td>
      <td>
        Syslog
      </td>
      <td>
        Messages per second (msg/sec) received over the last 60 seconds for all syslog data.
      </td>
    </tr>
    </tbody>
</table>

#### Common metrics searches [#common-metric-searches]

To see these metrics in New Relic One:

1. Go to [one.newrelic.com](https://one.newrelic.com/) and click **Query your data**.
2. Enter one of the following NRQL queries:

<CollapserGroup>
  <Collapser
    id="ktranslate-versions"
    title="What are the current versions of my ktranslate applications?"
  >

    ```sql
    FROM Metric
    SELECT
    latest(ver) AS 'image_version'
    FACET host AS 'docker_host', svc AS 'container_service'
    WHERE provider = 'kentik-agent'
    AND instrumentation.name = 'heartbeat'
    ```

  </Collapser>
  <Collapser
    id="top-level-health"
    title="What is the health of my ktranslate application?"
  >

    ```sql
    FROM Metric
    SELECT
    latest(kentik.ktranslate.chf.kkc.baseserver_healthcheck_execution_total) AS 'healthcheck_total',
    latest(kentik.ktranslate.chf.kkc.inputq) AS 'input_per_second',
    latest(kentik.ktranslate.chf.kkc.jchfq) AS 'buffer'
    FACET host AS 'docker_host', svc AS 'container_service'
    WHERE provider = 'kentik-agent'
    AND instrumentation.name = 'heartbeat'
    ```

  </Collapser>
  <Collapser
    id="delivery-health"
    title="What is the health of my deliveries to New Relic One?"
  >

    ```sql
    FROM Metric
    SELECT
    latest(kentik.ktranslate.chf.kkc.delivery_metrics_nr) AS 'delivery_metric_batches_per_second',
    latest(kentik.ktranslate.chf.kkc.delivery_logs_nr) AS 'delivery_logs_per_second',
    latest(kentik.ktranslate.chf.kkc.delivery_wins_nr) AS 'delivery_wins_per_second'
    FACET host AS 'docker_host', svc AS 'container_service'
    WHERE provider = 'kentik-agent'
    AND instrumentation.name = 'heartbeat'
    ```

  </Collapser>
  <Collapser
    id="snmp-health"
    title="What is the health of my SNMP collection overall?"
  >

    ```sql
    FROM Metric
    SELECT
    latest(kentik.ktranslate.chf.kkc.device_metrics) AS 'device_polls_per_second',
    latest(kentik.ktranslate.chf.kkc.interface_metrics) AS 'interface_polls_per_second'
    FACET host AS 'docker_host', svc AS 'container_service'
    WHERE provider = 'kentik-agent'
    AND instrumentation.name = 'heartbeat'
    ```

  </Collapser>
  <Collapser
    id="snmp-failing-devices"
    title="What devices are failing SNMP collection?"
  >

    ```sql
    SELECT
    max(snmp_fail)
    FROM (
      FROM Metric
      SELECT
      latest(kentik.ktranslate.chf.kkc.snmp_fail) AS 'snmp_fail'
      FACET host AS 'docker_host', svc AS 'container_service', device_name AS 'snmp_device'
      WHERE provider = 'kentik-agent'
      AND instrumentation.name = 'heartbeat'
    )
    FACET docker_host, container_service, snmp_device
    WHERE snmp_fail = 2
    ```

  </Collapser>
  <Collapser
    id="netflow-health"
    title="What is the health of my flow data collection?"
  >

    ```sql
    FROM Metric
    SELECT
    max(kentik.ktranslate.chf.kkc.netflow) AS 'flows_per_second'
    FACET host AS 'docker_host', svc AS 'container_service', device_name AS 'flow_device'
    WHERE provider = 'kentik-agent'
    AND instrumentation.name = 'heartbeat'
    ```

  </Collapser>
  <Collapser
    id="syslog-health"
    title="What is the health of my syslog collection?"
  >

    ```sql
    FROM Metric
    SELECT
    latest(kentik.ktranslate.chf.kkc.syslog_queue) AS 'syslog_queue_total',
    latest(kentik.ktranslate.chf.kkc.syslog_errors) AS 'syslog_errors_per_second',
    latest(kentik.ktranslate.chf.kkc.syslog_messages) AS 'syslog_messages_per_second'
    FACET host AS 'docker_host', svc AS 'container_service'
    WHERE provider = 'kentik-agent'
    AND instrumentation.name = 'heartbeat'
    ```

  </Collapser>
</CollapserGroup>
