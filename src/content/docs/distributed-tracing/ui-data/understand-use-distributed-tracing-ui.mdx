---
title: Understand and use the distributed tracing UI
tags:
  - Understand dependencies
  - Distributed tracing
  - UI and data
metaDescription: "For New Relic's distributed tracing feature: learn how to use the UI and understand the data displayed."
redirects:
  - /docs/guide-using-distributed-tracing
  - /docs/use-distributed-tracing-data
  - /docs/understand-use-distributed-tracing-data
  - /docs/apm/distributed-tracing/ui-data/understand-use-distributed-tracing-data
  - /docs/understand-dependencies/distributed-tracing/ui-data/additional-distributed-tracing-features-new-relic-one
  - /docs/distributed-tracing-new-relic-one
  - /docs/filter-distributed-traces-new-relic-one
  - /docs/apm/distributed-tracing/ui-data/additional-distributed-tracing-features-new-relic-one
  - /docs/understand-dependencies/distributed-tracing/ui-data/understand-use-distributed-trace-ui
  - /docs/understand-dependencies/distributed-tracing/ui-data/scatter-plot-overview
  - /docs/understand-dependencies/distributed-tracing/ui-data/understand-use-distributed-tracing-ui
freshnessValidatedDate: never
---

[Distributed tracing](/docs/apm/distributed-tracing/getting-started/introduction-distributed-tracing) helps you monitor and analyze the behavior of your distributed system. After you enable distributed tracing, you can use our UI tools to search for traces and analyze them.

If you're looking to troubleshoot errors in a transaction that spans many services:

1. [Open](#open-dt-ui) the distributed tracing UI page.
2. [Sort through your traces](#search-for-spans) using a filter to find that specific request and show only traces containing errors.
3. On the [trace details page](/docs/distributed-tracing/ui-data/trace-details/), review the span along the request route that originated the error.
4. Noting the error class and message, navigate to the service from its span in the trace so you can see that the error is occurring at a high rate.

Read on to explore the options in the distributed tracing UI.

## Open the distributed tracing UI [#open-dt-ui]

To view traces for a specific service:

1. Go to [one.newrelic.com > All entities](https://one.newrelic.com/).
2. Under <DNT>**Your system**</DNT> in the left panel, select the entity that contains the trace you want to inspect.
3. Click <DNT>**Distributed tracing**</DNT> in the left pane.

Or, to view traces across all your accounts:

1. Go to <DNT>**[one.newrelic.com > All Capabilities](https://one.newrelic.com/all-capabilities)**</DNT>.
2. Click the <DNT>**Traces**</DNT> tile.

<Callout variant="tip">
  If you don't have access to accounts for some services in a trace, we'll [obfuscate some details for those services](/docs/understand-dependencies/distributed-tracing/troubleshooting/missing-trace-data/#account-access).
</Callout>

## Filter your span data [#search-for-spans]

We have a variety of tools to help you find traces and spans so you can resolve issues. The opening distributed tracing page is populated with a default list of traces. You can quickly refine this list using these tools:

<CollapserGroup>
  <Collapser
    id="1"
    title="Filter using the query bar"
  >
    The <DNT>**Find traces**</DNT> query bar is a quick way to narrow your search for traces. You can either start typing in the query bar or use the dropdown to create a compound query.

    Query returns are based on [span](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#span) attributes, not on trace attributes. You define spans that have certain criteria, and the search displays traces that contain those spans.

    If you use a multi-attribute filter, it is affected by first attribute selected. Distributed tracing reports on two types of data: transaction events and spans. When you select an attribute in the filter, the data type that attribute is attached to dictates the available attributes. For example, if you filter on an attribute that is attached to a transaction event, only transaction event attributes are available when you attempt to add filter on additional attribute values.

    Queries for traces are similar to [NRQL](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) (our query language), with a few main exceptions:

    * String values don't require quote marks (for example, you can use either `appName = MyApp` or `appName = 'MyApp'`)
    * The `like` operator doesnâ€™t require `%` (for example, you can use either `appName like product` or `appName like %product%`).

      These are two examples of how to use the query bar:

      <Tabs>
        <TabsBar>
          <TabsBarItem id="query-example-1">
            Find traces that touch two services
          </TabsBarItem>

          <TabsBarItem id="query-example-2">
            {
              <>Find error spans using the <InlineCode>like</InlineCode> operator</>
            }
          </TabsBarItem>
        </TabsBar>

        <TabsPages>
          <TabsPageItem id="query-example-1">
            The query in the image below finds traces that:

            1. Pass through both WebPortal and Inventory Service applications
            2. Have an Inventory Service datastore call that takes longer than 500 ms
            3. Contains an error in any [span](/docs/using-new-relic/welcome-new-relic/getting-started/glossary#span).

               <img
                 title="Distributed tracing example query 1"
                 alt="new-relic-one-distributed-tracing-query-example-1.png"
                 src="/images/new-relic-one-distributed-tracing-query-example-1.webp"
               />

               <figcaption>
                 Go to <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Apps > Distributed tracing**</DNT>
               </figcaption>
          </TabsPageItem>

          <TabsPageItem id="query-example-2">
            The query in the image below finds traces that:

            1. Contain spans that pass through the WebPortal application and where an error occurred on any span in the WebPortal application
            2. Contain spans where the `customer_user_email` attribute contains a value ending with `hotmail.com` anywhere in the trace.

               <img
                 title="new-relic-one-distributed-tracing-query-example-2.png"
                 alt="Distributed tracing - query example 2"
                 src="/images/new-relic-one-distributed-tracing-query-example-2.webp"
               />

               <figcaption>
                 Go to <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Apps > Distributed tracing**</DNT>
               </figcaption>
          </TabsPageItem>
        </TabsPages>
      </Tabs>
  </Collapser>

  <Collapser
    id="2"
    title="Select left-pane filters"
  >
    Besides the query bar at the top of the page, you can use a variety of filters in the left pane to find traces you're interested in.

    <img
      title="Screenshot showing left-pane filters"
      alt="Screenshot showing left-pane filters"
      src="/images/distributed-tracing_screenshot-crop_left-pane-filters.webp"
    />

    * <DNT>**Infinite tracing data**</DNT>: Select this only to show traces related to the Infinite Tracing feature.
    * <DNT>**Multi span traces only**</DNT>: Use this to hide single-span traces.
    * <DNT>**Error filters**</DNT>: Under <DNT>**Errors**</DNT> select the errors to filter by.
    * <DNT>**Histogram filters**</DNT>: Below <DNT>**Errors**</DNT> at the bottom of the left pane, you can click <DNT>**More filters**</DNT> to show histogram filters. Drag the sliders to change the values, such as <DNT>**Trace duration**</DNT>:

      * Drag the left end of the slider for greater-than comparisons.
      * Drag the right end of the slider for less-than comparisons.
      * Drag each end of the slider toward the center to filter by a range.

      <img
        title="new-relic-one-distributed-tracing-histogram-selection.png"
        alt="Distributed tracing - histogram"
        src="/images/new-relic-one-distributed-tracing-histogram-selection.webp"
      />

      <figcaption>
        When you drag the slider, it changes both the list of traces and what's shown in the trace charts.
      </figcaption>
  </Collapser>
</CollapserGroup>

## Organize your span data

<CollapserGroup>
  <Collapser
    id="3"
    title="Group similar traces"
  >
    The default view of distributed tracing shows traces grouped by the same root entry span. In other words, traces are grouped by the span where New Relic began recording the request. You can slide the toggle <DNT>**Group similar traces**</DNT> to turn this on and off.

    With trace groups you get a high-level view of traces so you can understand request behavior for groups of similar traces. This helps you understand dips or spikes in trace count, duration, and errors. When you click on one of the trace groups, you get all the standard details in context of the specific trace group you selected.

    If <DNT>**Group similar traces**</DNT> is turned on, you'll see three charts at the top of the page in distributed tracing. These charts show you the trace-count, 95th percentile duration, and error-count for each of the trace groups listed in the table below the charts. To change the filters on these charts, see left-pane filters.
  </Collapser>

  <Collapser
    id="4"
    title="View outlying traces in a scatter plot"
  >
    The trace scatter plot is a quick way to search for outlying traces. This is available on the opening page of distributed tracing if you turn off the <DNT>**Group similar traces**</DNT> toggle at the top of the page.

    In the scatter plot, you can move the cursor across the chart to view trace details and you can click individual points to get details:

    <img
      title="new-relic-one-distributed-tracing-histogram-selection.webp"
      alt="Screenshot showing the distributed tracing scatter plot chart."
      src="/images/new-relic-one-distributed-tracing-scatterplot.webp"
    />

    Control what's displayed in the scatter plot:

    1. Select the duration type in the <DNT>**View by**</DNT> dropdown:

    * <DNT>
        **Backend duration**
      </DNT>
    * <DNT>
        **Root span duration**
      </DNT>
    * <DNT>
        **Trace duration**
      </DNT>

    2. In <DNT>**Facet traces by**</DNT>, select one of these options:

    * <DNT>**Root entry span**</DNT>: Group by the root transaction, which is the root service's endpoint. In a trace where Service A calls Service B and Service B calls Service C, the root entry span is Service A's endpoint. For example: "Service A - GET /user/%".
    * <DNT>**Root entity**</DNT>: Group by the name of the first entity in traces. In a trace where Service A calls Service B and Service B calls Service C, the root entity would be Service A.
    * <DNT>**Errors**</DNT>: Group by whether or not traces contain errors.

    3. For tips about how to change the filters on the scatter plot, check out left-pane filters.
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  Some queries that produce many results may result in false positives in charts. This could manifest as charts showing trace results that are not in the trace list.
</Callout>

## Additional UI details [#rules-limits]

Here are some additional distributed tracing UI details, rules, and limits:

<CollapserGroup>
  <Collapser
    id="error-tips"
    title="How to understand span errors"
  >
    Span-level errors show you where errors originated in a process, how they bubbled up, and where they were handled. Every span that ends with an error is shown with an error in the UI and contributes to the total error count for that trace.

    Here are some general tips about understanding span errors:

    * Spans with errors are highlighted red in the distributed tracing UI. You can see more information on the <DNT>**Error Details**</DNT> pane for each span.
    * All spans that exit with errors are counted in the span error count.
    * When multiple errors occur on the same span, only one is written to the span in this order of precedence:

      * A `noticeError`
      * The most recent span error within the scope of that span

      This table describes how different span errors are handled:

      <table>
        <thead>
          <tr>
            <th style={{ width: "200px" }}>
              Error type
            </th>

            <th>
              Description
            </th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td>
              Spans ending in errors
            </td>

            <td>
              An error that leaves the boundary of a span results in an error on that span and on any ancestor spans that also exit with an error, until the error is caught or exits the transaction. You can see if an error is caught in an ancestor span.
            </td>
          </tr>

          <tr>
            <td>
              Notice errors
            </td>

            <td>
              Errors noticed by calls to the agent `noticeError` API or by the automatic agent instrumentation are attached to the currently executing span.
            </td>
          </tr>

          <tr>
            <td>
              Response code errors
            </td>

            <td>
              Response code errors are attached to the associated span, such as:

              * Client span: External transactions prefixed with `http` or `db`.
              * Entry span: In the case of a transaction ending in a response code error.

                The response code for these spans is captured as an attribute `http.statusCode` and attached to that span.
            </td>
          </tr>

          <tr>
            <td>
              OpenTelemetry Errors
            </td>

            <td>
              The <DNT>**Error Details**</DNT> box of the right pane is populated by spans containing `otel.status_code = ERROR` and displays the content of `otel.status_description`.

              <Callout variant="tip">
                OpenTelemetry span events handled by the app/service are displayed independently of span error status and are not necessarily associated with a span error status. You can view span event exceptions and non-exceptions by clicking <DNT>**View span events**</DNT> in the right pane.
              </Callout>
            </td>
          </tr>
        </tbody>
      </table>
  </Collapser>

  <Collapser
    id="anomalous-spans"
    title="Anomalous spans"
  >
    If a span is displayed as anomalous in the UI, it means that the following are both true:

    * The span is more than two standard deviations slower than the average of all spans with the same name from the same service over the last six hours.
    * The span's duration is more than 10% of the trace's duration.
  </Collapser>

  <Collapser
    id="client-server-time"
    title="Client span duration: time differences between client and server spans"
  >
    When a process calls another process, and both processes are instrumented by New Relic, the trace contains both a client-side representation of the call and a server-side representation. The [client span](/docs/understand-dependencies/distributed-tracing/get-started/how-new-relic-distributed-tracing-works#trace-structure) (calling process) can have time-related differences when compared to the server span (called process). These differences could be due to:

    * Clock skew, due to system clock time differences
    * Differences in duration, due to things like network latency or DNS resolution delay

      The UI shows these time-related differences by displaying an outline of the client span in the same space as the server span. This span represents the duration of the client span.

      It isn't possible to determine every factor contributing to these time-related discrepancies, but here are some common span patterns and tips for understanding them:

      <img
        title="new-relic-distributed-tracing-client-span-time.jpg"
        alt="New Relic distributed tracing client vs server time discrepancy diagram"
        src="/images/new-relic-distributed-tracing-client-span-time.webp"
      />

      A. When a client span is longer than the server span, this could be due to latency in a number of areas, such as: network time, queue time, DNS resolution time, or from a load balancer that we cannot see.
      B. When a client span starts and ends before a server span begins, this could be due to clock skew, or due to the server doing asynchronous work that continues after sending the response.
      C. When a client span starts after a server span, this is most likely clock skew.
  </Collapser>

  <Collapser
    id="fragmented-traces"
    title="Fragmented traces"
  >
    Fragmented traces are traces with missing spans. When a span is missing or has invalid parent span IDs, its children spans become separated from the rest of the trace, which we refer to as "orphaned." Orphaned spans appear at the bottom of the trace, and they will lack connecting lines to the rest of the trace. If you have fragmented spans, you'll see the word <DNT>**Fragmented**</DNT> at the top of the details page:

    <img
      style={{ width: "70%",align: "left" }}
      title="Screenshot showing how to locate a fragmented trace"
      alt="Screenshot showing how to locate a fragmented trace"
      src="/images/distributed-tracing_screenshot-crop_fragmented-trace.webp"
    />

    Types of orphaned span properties indicated in the UI:

    * <DNT>**No root span.**</DNT> Missing the root span, which is the first operation in the request. When this happens, the span with the earliest timestamp is displayed as the root.

    * <DNT>**Orphaned span.**</DNT> A single span with a missing parent span. This could be due to the parent span having an ID that doesn't match its child span.

    * <DNT>**Orphaned trace fragment.**</DNT> A group of connected spans where the first span in the group is an orphan span.

    This can happen for a number of reasons, including:

    * <DNT>**Collection limits.**</DNT> Some high-throughput applications may exceed collection limits (for example, [APM agent collection limits](#1k-limit), or API limits). When this happens, it may result in traces having missing spans. One way to remedy this is to turn off some reporting, so that the limit is not reached.

    * <DNT>**Incorrect instrumentation.**</DNT> If an application is instrumented incorrectly, it won't pass trace context correctly and this will result in fragmented traces. To remedy this, examine the data source that is generating orphan spans to ensure instrumentation is done correctly. To discover a span's data source, select it and examine its span details.

    * <DNT>**Spans still arriving**</DNT>. If some parent spans haven't been collected yet, this can result in temporary gaps until the entire trace has reported.

    * <DNT>**UI display limits.**</DNT> Orphaned spans may result if a trace exceeds the 10K span display limit.
  </Collapser>

  <Collapser
    id="preserved-traces"
    title="Preserved traces"
  >
    Preserved traces are similar to snapshots of original traces. They archive a full trace that has been previously viewed and has surpassed the retention period. Full traces are only available for 7 days, unless you've purchased extended retention (which would reflect automatically in the UI). However, preserved traces can exist for up to 1 year, and generally function like the original trace.

    Note that preserved traces won't display span performance data or span anomaly data. Preserved traces may not be accessible if an entity in a preserved trace is deleted, expires, or stops reporting data.

    <img
      style={{ width: "70%",align: "left" }}
      title="Screenshot showing how to locate a preserved trace"
      alt="Screenshot showing how to locate a preserved trace"
      src="/images/distributed-tracing_screenshot-crop_preserved-trace.webp"
    />
  </Collapser>

  <Collapser
    id="account-access"
    title="Trace details obfuscated based on account access"
  >
    If you donâ€™t have access to the New Relic accounts that monitor other services, some of the span and service details will be obfuscated in the UI. Obfuscation can include:

    * Span name concealed by asterisks
    * Service name replaced with New Relic account ID and app ID

      For more information on the factors affecting your access to accounts, see [Account access](/docs/accounts/accounts-billing/account-structure/factors-affecting-access-features-data/#account-access).
  </Collapser>

  <Collapser
    id="1k-limit"
    title="Span limits and sampling"
  >
    See [Language agents: adaptive sampling](/docs/apm/distributed-tracing/getting-started/how-new-relic-distributed-tracing-works#trace-origin-sampling).
  </Collapser>

  <Collapser
    id="prettified-span-names"
    title="Incomplete span names in waterfall view"
  >
    When viewing the span waterfall, span names may be displayed in an incomplete form that is more human-readable than the complete span name. To find the complete name, select that span and look for the <DNT>**Full span name**</DNT>. Knowing the complete name can be valuable for querying that data with NRQL.
  </Collapser>

  <Collapser
    id="span-counts"
    title="Missing spans and span/service count discrepancies"
  >
    A trace may sometimes have (or seem to have) missing spans or services. This can manifest as a discrepancy between the count of a trace's spans or services displayed in the [trace list](#trace-list) and the count displayed on the [trace details](#trace-details) page.

    Reasons for missing spans and count discrepancies include:

    * An <InlinePopover type="apm"/> agent may have hit its [span collection limit](/docs/distributed-tracing/concepts/how-new-relic-distributed-tracing-works/#trace-origin-sampling).
    * A span may be initially counted but not make it into a trace display, for reasons such as network latency or a query issue.
    * The UI may have hit its 10K span display limit.

      All spans collected, including those not displayed, can be [queried with NRQL](/docs/apm/distributed-tracing/ui-data/example-insights-queries-distributed-trace-data).
  </Collapser>
</CollapserGroup>

In addition to these UI tools, you can also check out the example NRQL queries in [Query distributed trace data](/docs/distributed-tracing/ui-data/query-distributed-trace-data/#example-nrql-queries).

<UserJourneyControls nextStep={{path: "/docs/distributed-tracing/ui-data/trace-details/", title: "Next step:", body: "Understand the trace details UI"}}/>
