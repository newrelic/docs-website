---
title: Navigate from APM Summary to relevant traces
tags:
  - Understand dependencies
  - Distributed tracing
  - Intelligent Exemplar
  - APM Summary
  - Error investigation
  - Latency investigation
metaDescription: Use Intelligent Exemplar to investigate errors and latency spikes directly from your APM Summary page with preserved context.
freshnessValidatedDate: never
---

{/* TODO: Add screenshot of APM Summary page with error and latency charts highlighted */}

When you notice an error spike or latency anomaly in your APM Summary page, Intelligent Exemplar automatically presents the most relevant traces without losing the context of what you're investigating. This guide shows you how to navigate from your service overview to actionable traces.

## Before you begin [#before-you-begin]

Ensure you have:

* **Distributed tracing enabled** on your services
* **Intelligent Exemplar access** (Limited Preview - contact your account team if needed)
* **Recent trace data** in the time period you want to investigate
* **APM Summary page access** for your service

<Callout variant="tip">
  If you're new to APM Summary pages, see [Introduction to APM](/docs/apm/new-relic-apm/getting-started/introduction-apm) to familiarize yourself with the layout.
</Callout>

## Investigate errors from APM Summary [#investigate-errors]

The APM Summary page displays an **Error rate** chart showing errors per minute. When you see a spike or anomaly, Intelligent Exemplar helps you quickly find the traces causing it.

### Navigate to error traces [#navigate-error-traces]

1. **Go to your APM Summary page:**
   * Navigate to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > APM & services**
   * Select your service

2. **Identify the error spike:**
   * Look at the **Error rate** or **Errors** chart
   * Notice any spikes, increases, or anomalies

   {/* TODO: Add screenshot of error chart with spike highlighted */}

3. **Click on the spike:**
   * Click directly on the spike in the chart
   * Or select a time range that includes the error spike

4. **View intelligent trace selection:**
   * You'll be taken to a traces page with **context preserved**
   * Traces are automatically filtered to the time window you selected
   * Only traces containing errors are shown
   * Traces are ranked by relevance to the error pattern

{/* TODO: Add screenshot showing filtered trace list with Intelligent Exemplar indicators */}

### Understanding the error trace list [#understand-error-list]

When Intelligent Exemplar presents error traces, you'll see:

**Relevance indicators:**
* **Most relevant traces first:** Those that best exemplify the error pattern
* **Error type highlighted:** The specific error(s) that occurred in each trace
* **Timestamp correlation:** Traces from the exact time window of the spike
* **Service path:** Which services are involved in each error trace

{/* TODO: Add annotated screenshot explaining the trace list components */}

**Trace metadata shown:**
* Error message and type
* Trace duration
* Number of spans
* Services involved
* Root entry point

**Example scenario:**

```
You click on an error spike at 2:30 PM in your checkout service.

Intelligent Exemplar shows you:
✓ 15 traces from 2:29-2:32 PM (the spike window)
✓ All containing "PaymentProcessingException"
✓ Ranked by how representative they are of the pattern
✓ Preferring complete (non-fragmented) traces
✓ Showing which payment provider was involved
```

### Filter and refine error traces [#filter-error-traces]

After seeing the initial intelligent selection, you can refine further:

1. **Apply additional filters:**
   ```
   Filter by:
   - Specific error types
   - Error messages
   - Services involved
   - User attributes (customer segment, region, etc.)
   - Duration ranges
   ```

2. **Adjust time window:**
   * Expand or narrow the time range
   * Intelligent Exemplar maintains relevance ranking as you adjust

3. **Sort traces:**
   * By relevance (default)
   * By duration
   * By timestamp
   * By span count

{/* TODO: Add screenshot of filter panel with options */}

### Analyze error patterns [#analyze-error-patterns]

Intelligent Exemplar provides pattern insights for your error investigation:

**Error propagation visualization:**
* See how errors flow through services
* Identify the source service where errors originate
* Understand downstream impact

{/* TODO: Add screenshot of error propagation diagram */}

**Contribution percentages:**
* Which services or paths account for most errors
* Example: "70% of errors come from traces involving the payment-gateway service"

**Affected transaction analysis:**
* What types of transactions are impacted
* How many traces of each type contain the error
* Duration patterns for erroring vs non-erroring traces

**Example analysis output:**

```
Error spike analysis for "DatabaseConnectionTimeout":

Source: payment-db service
Affected paths:
  → checkout-api → payment-service → payment-db (70% of errors)
  → admin-api → payment-service → payment-db (30% of errors)

Affected transactions:
  → POST /checkout/complete (85 traces)
  → GET /orders/status (22 traces)

Pattern: All errors occurred when payment-db connection pool exhausted
```

{/* TODO: Add real screenshot of pattern analysis */}

## Investigate latency spikes from APM Summary [#investigate-latency]

The APM Summary page shows **Response time** or **Web transaction time** charts. Intelligent Exemplar helps you quickly find traces responsible for latency increases.

### Navigate to slow traces [#navigate-slow-traces]

1. **Identify the latency spike:**
   * Look at the **Response time** chart on your APM Summary page
   * Notice increases, spikes, or gradual degradation

   {/* TODO: Add screenshot of latency chart with spike */}

2. **Click on the spike:**
   * Click directly on elevated portion of the chart
   * Or drag to select a time range

3. **View intelligent latency trace selection:**
   * Redirected to traces page with context
   * Traces filtered to your selected time window
   * Only traces exceeding normal latency thresholds shown
   * Ranked by how well they exemplify the latency pattern

{/* TODO: Add screenshot of latency-filtered trace list */}

### Understanding the latency trace list [#understand-latency-list]

For latency investigations, you'll see:

**Latency-specific information:**
* **Duration highlighted:** Clear indication of how slow each trace is
* **Baseline comparison:** How much slower than your service's normal performance
* **Bottleneck indicators:** Which spans contribute most to overall duration
* **Service breakdown:** Time spent in each service

**Sorting options optimized for latency:**
* By slowest first (default for latency investigations)
* By contribution to total latency
* By number of slow spans
* By recency

**Example scenario:**

```
You click on a 5-minute latency spike at 3:15 PM.

Intelligent Exemplar shows:
✓ 23 traces from 3:14-3:19 PM
✓ All with response times >2s (vs 200ms baseline)
✓ Slowest traces first
✓ Highlighting that 80% spent time in "inventory-check" service
```

### Analyze latency patterns [#analyze-latency-patterns]

Intelligent Exemplar provides latency-specific insights:

**Bottleneck identification:**
* Which services or operations contribute most to latency
* Span-level breakdown of time spent
* Comparison with normal traces

{/* TODO: Add screenshot of bottleneck analysis */}

**Latency propagation:**
* Visualize how delays cascade through services
* Identify the source of slowdown
* See which services are affected vs. causing the issue

**Duration distribution:**
* Histogram showing trace duration spread
* Comparison with baseline
* Outlier identification

**Common attributes among slow traces:**
* What do slow traces have in common?
* Examples:
  - Same database instance
  - Same customer region
  - Same feature flag value
  - Same time of day pattern

**Example analysis:**

```
Latency spike analysis:

Baseline response time: 180ms
Spike response time: 2,400ms (13x increase)

Bottleneck: inventory-service/checkStock operation
  → Normal: 50ms
  → During spike: 2,200ms

Pattern: All slow traces querying "west-region" database
Affected: 340 traces over 5-minute period
Suggestion: Investigate west-region database performance
```

{/* TODO: Add real screenshot of latency analysis */}

## What information is preserved [#information-preserved]

When you click from APM Summary to traces, Intelligent Exemplar preserves:

<table>
  <thead>
    <tr>
      <th width={200}>Context element</th>
      <th>How it's preserved</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Time window**</td>
      <td>Exact time range of your click or selection is applied as a filter</td>
    </tr>
    <tr>
      <td>**Service context**</td>
      <td>Traces are scoped to the service you were viewing</td>
    </tr>
    <tr>
      <td>**Issue type**</td>
      <td>Error vs latency investigation mode determines ranking criteria</td>
    </tr>
    <tr>
      <td>**Severity**</td>
      <td>The magnitude of the spike influences relevance scoring</td>
    </tr>
    <tr>
      <td>**Entry point**</td>
      <td>System remembers you came from APM Summary for navigation breadcrumbs</td>
    </tr>
  </tbody>
</table>

## Refine your results [#refine-results]

After viewing the initial intelligent selection, you can:

### Adjust filters [#adjust-filters]

* **Add attribute filters:** Narrow by customer ID, region, endpoint, etc.
* **Change time window:** Expand to see broader patterns or narrow for precision
* **Toggle error/latency criteria:** Switch between error-focused and latency-focused views

### Compare with baseline [#compare-baseline]

* **View normal traces:** Toggle to see traces outside the issue period
* **Side-by-side comparison:** Understand what's different about problematic traces
* **Attribute comparison:** See which attributes differ between normal and abnormal

### Export or share findings [#export-share]

* **Permalink:** Share the filtered view with your team
* **Create alert:** Set up alerts based on the pattern you found
* **Add to dashboard:** Pin relevant trace queries to a dashboard

{/* TODO: Add screenshot showing share/export options */}

## Common workflows [#common-workflows]

### Investigate new error type [#new-error-workflow]

1. Notice new error type in error chart
2. Click on first occurrence
3. Review exemplar traces
4. Identify common attributes
5. Determine root cause
6. Create fix or mitigation

### Diagnose latency regression [#latency-regression-workflow]

1. Notice response time increase in latency chart
2. Click on degraded time period
3. View slow traces
4. Identify bottleneck service/operation
5. Compare with historical baseline
6. Implement optimization

### Compare before/after deployment [#deployment-comparison-workflow]

1. Note deployment time on APM Summary
2. Click on post-deployment time range
3. View traces after deployment
4. Compare with pre-deployment period
5. Identify any regressions
6. Rollback if needed or create hotfix

## Troubleshooting [#troubleshooting]

### No traces shown after clicking chart [#no-traces-shown]

**Possible causes:**
* Trace data not yet available (wait 1-2 minutes)
* Time window too narrow (expand selection)
* Distributed tracing not enabled on this service

**Solutions:**
* Expand time window to 5+ minutes
* Verify distributed tracing is enabled
* Check for [missing trace data](/docs/distributed-tracing/troubleshooting/missing-trace-data)

### Traces don't match the issue I clicked on [#traces-mismatch]

**Possible causes:**
* Sampling may have missed some traces
* Issue affected only specific requests not captured
* Time synchronization issues between services

**Solutions:**
* Adjust time window slightly earlier/later
* Add specific attribute filters to narrow down
* Check service clocks are synchronized

### Too many traces to review [#too-many-traces]

**Solutions:**
* Use the relevance ranking—start with top 5 traces
* Apply additional filters (error type, service, attribute)
* Focus on pattern analysis instead of individual traces
* Use [Attribute Correlation Analysis](/docs/distributed-tracing/attribute-correlation-analysis/introduction-aca) for automated analysis

## What's next? [#whats-next]

* [Navigate from Error Inbox to relevant traces](/docs/distributed-tracing/intelligent-exemplar/navigate-from-error-inbox)
* [Understand trace relevance and pattern analysis](/docs/distributed-tracing/intelligent-exemplar/understand-trace-relevance)
* [Troubleshooting Intelligent Exemplar](/docs/distributed-tracing/intelligent-exemplar/troubleshooting)

{/*
WRITING NOTES FOR COMPLETION:
- Add all TODO screenshots with actual UI
- Get product team input on relevance algorithm details
- Add video walkthrough for common workflows
- Update with any UI changes
- Add more real-world examples
- Include customer quotes/testimonials if available
- Verify all troubleshooting scenarios
- Update filter options when finalized
*/}
