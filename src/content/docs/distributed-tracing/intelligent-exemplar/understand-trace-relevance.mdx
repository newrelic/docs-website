---
title: Understand trace relevance and pattern analysis
tags:
  - Understand dependencies
  - Distributed tracing
  - Intelligent Exemplar
  - Trace ranking
  - Pattern analysis
metaDescription: Learn how Intelligent Exemplar ranks traces by relevance and provides automated pattern analysis to accelerate root cause identification.
freshnessValidatedDate: never
---

{/* TODO: Add diagram showing relevance scoring factors */}

Intelligent Exemplar doesn't just filter traces—it intelligently ranks them by relevance to help you focus on the most informative examples. This guide explains how relevance is determined and how to interpret the pattern analysis insights.

## How trace relevance is determined [#relevance-determination]

When you investigate an issue (error spike, latency anomaly), Intelligent Exemplar scores each trace based on multiple factors to present the most exemplary traces first.

### Relevance scoring factors [#scoring-factors]

<table>
  <thead>
    <tr>
      <th width={200}>Factor</th>
      <th>Weight</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Issue match**</td>
      <td>Critical</td>
      <td>Contains the error type, exceeds latency threshold, or matches the issue characteristic</td>
    </tr>
    <tr>
      <td>**Time correlation**</td>
      <td>High</td>
      <td>Occurred during or very close to the selected time window</td>
    </tr>
    <tr>
      <td>**Completeness**</td>
      <td>High</td>
      <td>All expected services present, no missing spans, complete trace context</td>
    </tr>
    <tr>
      <td>**Representativeness**</td>
      <td>Medium</td>
      <td>Has typical attributes shared by other traces with the same issue</td>
    </tr>
    <tr>
      <td>**Statistical significance**</td>
      <td>Medium</td>
      <td>Attributes that differentiate this issue from normal traces</td>
    </tr>
    <tr>
      <td>**Recency**</td>
      <td>Low</td>
      <td>More recent traces may better reflect current system state</td>
    </tr>
  </tbody>
</table>

### How scoring works [#how-scoring-works]

**Step 1: Issue matching**
* Traces must match the issue type (error, latency, etc.)
* Non-matching traces are excluded entirely
* Matching traces proceed to further evaluation

**Step 2: Time correlation**
* Traces within the selected time window score highest
* Traces near the window edges score progressively lower
* Example: Clicking a 5-minute spike favors traces from those exact 5 minutes

**Step 3: Completeness evaluation**
* Complete traces (all services, no gaps) score higher
* Fragmented traces are penalized but not excluded
* Missing critical services significantly lowers score

**Step 4: Pattern analysis**
* System identifies common attributes among issue traces
* Traces with these attributes score higher
* Example: If 80% of error traces have `region=us-west`, traces with this attribute rank higher

**Step 5: Final ranking**
* All factors combined into a relevance score (0-100)
* Traces sorted by score, highest first
* Top 10-20 traces typically account for 90%+ of the pattern

{/* TODO: Add diagram showing scoring algorithm flow */}

## Understanding relevance indicators [#relevance-indicators]

When viewing traces, you'll see several indicators of relevance:

### Visual relevance markers [#visual-markers]

**Relevance score badge:**
* Displayed on each trace (e.g., "95% relevant")
* Higher = more exemplary of the issue
* Focus on traces above 80% for investigation

{/* TODO: Add screenshot showing relevance badges on trace list */}

**Highlighted attributes:**
* Attributes that contribute to high relevance are highlighted
* Shows why this trace is considered exemplary
* Example: `experimentId: A123` might be highlighted if this value appears in most error traces

**Completeness indicator:**
* Green check = complete trace
* Yellow warning = minor gaps
* Red warning = significant fragmentation

### Sorting by relevance [#sorting-relevance]

**Default sort:** By relevance score (highest first)

**Alternative sorts:**
* By duration (for latency investigations)
* By timestamp (for chronological analysis)
* By span count (for complexity analysis)

**When to use relevance sort:**
* Starting investigation (see most exemplary first)
* Limited time to review traces
* Need representative examples for documentation

**When to use other sorts:**
* Duration: Finding slowest or fastest traces
* Timestamp: Understanding event sequence
* Span count: Identifying unusually complex or simple traces

## View error and latency propagation paths [#propagation-paths]

Intelligent Exemplar visualizes how issues propagate through your distributed system.

### Propagation path visualization [#propagation-visualization]

The propagation diagram shows:

1. **Source node:** Where the issue originates
2. **Propagation edges:** How it spreads to other services
3. **Affected nodes:** Services experiencing the issue
4. **Path thickness:** Indicates volume (thicker = more traces)
5. **Path percentages:** Contribution of each path to total issue

{/* TODO: Add annotated screenshot of propagation visualization */}

**Example for an error:**

```
Error: DatabaseTimeout in orders-db

Propagation visualization:

orders-db (source)
    ↓ 70% (520 traces)
    orders-service
        ↓ 65% (480 traces)
        api-gateway
            ↓ 50% (370 traces)
            web-frontend
            ↓ 15% (110 traces)
            mobile-api
    ↓ 25% (180 traces)
    reporting-service
        ↓ 20% (150 traces)
        analytics-pipeline
    ↓ 5% (40 traces)
    admin-api
```

### Interpret propagation patterns [#interpret-propagation]

**Single-source patterns:**
* One service originates the issue
* Multiple downstream paths affected
* **Action:** Fix the source service

**Multi-source patterns:**
* Issue originates from multiple services
* May indicate systemic problem
* **Action:** Investigate common dependency or configuration

**Cascading patterns:**
* Issue triggers secondary issues in downstream services
* Chain reaction of failures
* **Action:** Fix root cause; secondary issues may resolve automatically

**Branch patterns:**
* Some paths affected, others not
* Indicates conditional or intermittent issue
* **Action:** Identify what differentiates affected vs unaffected paths

### Source path visualization [#source-path]

For each issue, Intelligent Exemplar identifies:

**Primary source:**
* The service/operation where issue first appears
* Marked with "source" badge
* Usually the best place to focus remediation

**Contributing sources:**
* Secondary origins that also produce the issue
* May indicate multiple root causes
* Each should be investigated

**False sources:**
* Services that appear to originate issue but actually propagate it
* System helps identify true vs apparent source
* Look for "propagates from" indicators

{/* TODO: Add screenshot showing source identification */}

## Understanding contribution percentages [#contribution-percentages]

Contribution percentages show which paths, services, or attributes account for the most issue occurrences.

### Service contribution [#service-contribution]

**What it shows:**
* Percentage of issue traces that involve each service
* Helps prioritize which services to investigate

**Example:**

```
Error traces by service involvement:

payment-service: 95% (710 of 750 traces)
  → Primary contributor, investigate first

auth-service: 60% (450 of 750 traces)
  → Secondary, often downstream from payment-service

inventory-service: 30% (225 of 750 traces)
  → Minor contributor, may be affected not causing

notification-service: 5% (38 of 750 traces)
  → Minimal involvement, likely not the issue
```

### Path contribution [#path-contribution]

**What it shows:**
* Which service paths account for most issues
* Identifies critical paths to focus on

**Example:**

```
Error paths ranked by contribution:

Path A: payment-api → payment-service → payment-db
  → 70% of errors
  → Highest priority

Path B: checkout-api → payment-service → payment-db
  → 25% of errors
  → Secondary priority

Path C: admin-api → payment-service → payment-db
  → 5% of errors
  → Lower priority
```

### Attribute contribution [#attribute-contribution]

**What it shows:**
* Which attribute values appear most frequently in issue traces
* Helps identify patterns and root causes

**Example:**

```
Attribute analysis for latency spikes:

region=us-west: 82% of slow traces
  → Strong correlation, investigate us-west infrastructure

customer_tier=enterprise: 75% of slow traces
  → Enterprise queries may be more complex

database_shard=shard-07: 68% of slow traces
  → Specific shard performance issue likely
```

## Analyze trace patterns [#analyze-patterns]

Intelligent Exemplar automatically identifies patterns across traces.

### Transaction type patterns [#transaction-patterns]

**Analysis provided:**
* Which API endpoints are affected
* Which operations fail or slow down
* Which user actions are impacted

**Example output:**

```
Pattern analysis for PaymentTimeoutError:

Affected transactions:
1. POST /checkout/complete - 520 traces (69%)
   - 95% error rate (normal: 0.1%)
   - Average duration: 8.2s (normal: 0.9s)

2. POST /payment/process - 180 traces (24%)
   - 85% error rate (normal: 0.2%)
   - Average duration: 7.8s (normal: 1.1s)

3. GET /order/status - 50 traces (7%)
   - 12% error rate (normal: 0%)
   - Average duration: 2.1s (normal: 0.4s)

Insight: Checkout operations most severely affected
```

### Temporal patterns [#temporal-patterns]

**Analysis provided:**
* Time-of-day correlations
* Duration patterns
* Frequency patterns

**Example:**

```
Temporal analysis:

Peak error period: 2:15 PM - 2:45 PM (540 errors)
Secondary peak: 3:30 PM - 3:50 PM (180 errors)
Baseline: <10 errors/hour

Pattern: Correlates with batch processing schedule
Insight: Batch jobs may be overloading payment-db
```

### Attribute correlation patterns [#attribute-patterns]

**Analysis provided:**
* Which attributes differ between issue traces and normal traces
* Statistical significance of each attribute
* Recommended attributes to investigate

**Example:**

```
Attribute correlation for latency spike:

High correlation attributes:
- database_instance: "db-replica-3" (appears in 88% of slow traces vs 15% of normal)
- query_type: "complex_join" (82% vs 20%)
- cache_hit: false (79% vs 30%)

Moderate correlation:
- customer_region: "APAC" (65% vs 40%)

Low correlation:
- user_agent (no significant difference)

Recommendation: Investigate db-replica-3 performance and query optimization
```

{/* TODO: Add screenshot of attribute correlation panel */}

## Identify trigger points [#trigger-points]

Intelligent Exemplar helps identify what triggered the issue.

### Causal path analysis [#causal-analysis]

**What it identifies:**
* The operation or span where issue begins
* Preceding operations that may have contributed
* Downstream effects

**Visualization:**

```
Causal path for DatabaseTimeout:

Normal flow:
checkout-api → validate-cart (50ms)
  → calculate-tax (30ms)
  → payment-service → process-payment (200ms)
    → payment-db → insert-transaction (80ms) ✓

Problem flow:
checkout-api → validate-cart (50ms)
  → calculate-tax (30ms)
  → payment-service → process-payment (8,200ms) ⚠️
    → payment-db → insert-transaction (timeout after 8s) ✗

Trigger point: payment-db connection pool exhausted
Contributing factor: payment-service retry logic amplifying load
```

{/* TODO: Add diagram showing causal path with trigger point marked */}

### Deployment correlation [#deployment-correlation]

**What it checks:**
* Recent deployments to involved services
* Configuration changes
* Dependency updates

**Example output:**

```
Deployment correlation:

payment-service v2.5.1 deployed at 2:10 PM
Issue started at 2:15 PM (5 minutes later)

Correlation confidence: High

Suggested action: Review payment-service v2.5.1 changes
  - Check database query modifications
  - Review timeout configuration changes
  - Examine connection pool settings
```

### External dependency correlation [#external-dependency-correlation]

**What it analyzes:**
* Calls to external services during issue period
* Third-party API performance
* Network or infrastructure issues

**Example:**

```
External dependency analysis:

payment-gateway-api.example.com:
  - Response time: 6.2s (normal: 0.4s)
  - Error rate: 35% (normal: 0.1%)
  - Status codes: 504 Gateway Timeout

Correlation: Strong (appears in 92% of issue traces)

Insight: Payment gateway experiencing outage
Action: Switch to backup payment processor or queue payments
```

## Examples and use cases [#examples]

### Use case 1: Investigating a sudden error spike [#example-error-spike]

**Scenario:** Your checkout service shows a sudden spike in `PaymentProcessingException` at 3:15 PM.

**Using Intelligent Exemplar:**

1. **Click on error spike** in APM Summary
2. **Review top 3 exemplar traces** (95%, 93%, 92% relevant)
3. **Check propagation path:**
   ```
   payment-db (source) → payment-service (85%) → checkout-api (80%)
   ```
4. **Review contribution analysis:**
   ```
   database_instance=db-primary: 98% of errors
   payment_method=credit_card: 100% of errors
   customer_region: no correlation
   ```
5. **Check trigger point:**
   ```
   payment-db connection pool exhausted at 3:14 PM
   Caused by: database maintenance window started early
   ```
6. **Action taken:** Extended connection pool size, coordinated maintenance windows

**Result:** Issue identified and resolved in 8 minutes vs. typical 45+ minutes

### Use case 2: Diagnosing intermittent latency [#example-intermittent-latency]

**Scenario:** Users report occasional slow checkout, but issue is hard to reproduce.

**Using Intelligent Exemplar:**

1. **Select 24-hour period** from latency chart
2. **View pattern analysis:**
   ```
   Slow periods: Every 2 hours, lasting 5-10 minutes
   Pattern: Correlates with batch report generation
   ```
3. **Check attribute correlation:**
   ```
   cache_hit=false: 95% of slow traces
   query_complexity=high: 88% of slow traces
   ```
4. **Review causal analysis:**
   ```
   Trigger: Batch jobs invalidate payment history cache
   Effect: Next user requests trigger complex queries
   Duration: Until cache repopulates (~10 minutes)
   ```
5. **Action taken:** Pre-warm cache after batch jobs, optimize queries

**Result:** Intermittent latency eliminated

### Use case 3: Understanding error impact [#example-error-impact]

**Scenario:** New error appears after deployment, need to understand scope.

**Using Intelligent Exemplar:**

1. **Navigate from Error Inbox**
2. **Review propagation visualization:**
   ```
   auth-service (source)
     → api-gateway (60% of requests affected)
       → web-frontend (user-facing impact)
       → mobile-api (mobile users impacted)
     → admin-service (40% of requests)
       → admin-dashboard (internal tools impacted)
   ```
3. **Check transaction analysis:**
   ```
   POST /api/login: 2,500 errors (critical - user login broken)
   GET /api/validate: 800 errors (high - session validation broken)
   POST /admin/users: 150 errors (medium - admin operations impacted)
   ```
4. **Review contribution percentages:**
   ```
   Customer-facing: 75% of errors
   Internal tools: 25% of errors
   ```
5. **Action taken:** Emergency rollback of auth-service, high priority given user-facing impact

**Result:** Understood full impact scope, prioritized remediation correctly

## What's next? [#whats-next]

* [Navigate from APM Summary to relevant traces](/docs/distributed-tracing/intelligent-exemplar/navigate-from-apm-summary)
* [Navigate from Error Inbox to relevant traces](/docs/distributed-tracing/intelligent-exemplar/navigate-from-error-inbox)
* [Use Attribute Correlation Analysis for automated root cause detection](/docs/distributed-tracing/attribute-correlation-analysis/introduction-aca)

{/*
WRITING NOTES FOR COMPLETION:
- Add all TODO diagrams and screenshots
- Get product team confirmation on scoring algorithm details
- Add more real-world examples from customer use cases
- Include video walkthrough of pattern analysis
- Verify all technical details with engineering
- Add more visual examples of propagation patterns
- Update with any UI changes
- Add customer testimonials if available
*/}
