---
title: Introduction to Attribute Correlation Analysis
tags:
  - Understand dependencies
  - Distributed tracing
  - Attribute Correlation Analysis
  - Root cause analysis
  - MTTR reduction
metaDescription: Automatically identify root causes of anomalies by comparing anomalous traces against baseline traces with statistical attribute analysis.
freshnessValidatedDate: never
---

{/* TODO: Add hero screenshot showing ACA interface */}

Attribute Correlation Analysis (ACA) dramatically reduces Mean Time to Resolution (MTTR) by automatically identifying which attributes differentiate anomalous traces from normal traces. Instead of manually comparing hundreds of attributes across traces, ACA surfaces the specific characteristics that explain why some requests fail or slow down.

<Callout variant="important">
  **Limited Preview:** Attribute Correlation Analysis is currently in Limited Preview. Contact your New Relic Account Team or [New Relic Support](https://support.newrelic.com) to request access.
</Callout>

## What is Attribute Correlation Analysis? [#what-is-aca]

ACA is an automated analytical tool within Distributed Tracing that compares a selected group of anomalous traces (e.g., slow or failing requests) against a baseline of normal traces. Using statistical analysis, it identifies and ranks the attributes that best explain the anomalous behavior.

**Key capabilities:**
* Automated comparison of trace attributes between anomalous and baseline groups
* Statistical significance testing to identify differentiating characteristics
* Visual comparative charts showing distribution differences
* Intelligent summary identifying probable root causes
* Support for both high and low cardinality attributes

{/* TODO: Add architecture diagram showing ACA analysis flow */}

##The "why" gap in distributed tracing [#the-why-gap]

Distributed tracing excels at showing **what** happened and **where** in your system. You can visualize request flows, identify slow spans, and understand service dependencies. However, answering **why** a particular set of traces is anomalous often remains manual and time-consuming.

### Current limitations [#current-limitations]

**Cardinal blind spots:**
* Span attributes can have hundreds or thousands of unique values (high cardinality)
* Manually comparing attribute distributions is overwhelming
* Key differentiating attributes often hidden in the noise

**Manual comparison overhead:**
* Engineers hypothesize which attributes matter
* Iteratively compare subsets of traces
* Prone to oversight and confirmation bias
* Time-consuming, especially under incident pressure

**Information overload:**
* Distributed systems generate massive attribute variety
* Services, hosts, containers, versions, flags, regions, customers, etc.
* Difficult to know where to start investigation

{/* TODO: Add "before ACA" screenshot showing manual attribute comparison difficulty */}

## How ACA automates root cause detection [#how-aca-works]

ACA transforms root cause analysis from manual to automated:

### 1. Select anomalous traces [#select-anomalous]
Choose traces exhibiting the problem behavior:
* Latency above threshold
* Containing specific errors
* From a time period with issues
* Selected from scatter plots or filters

### 2. Define baseline traces [#define-baseline]
System automatically selects normal traces for comparison, or you can manually specify baseline criteria.

### 3. Automated statistical analysis [#statistical-analysis]
ACA analyzes all attributes across both groups:
* Compares distribution of each attribute value
* Calculates statistical significance
* Ranks attributes by correlation strength
* Identifies high-impact differentiators

### 4. Visual presentation [#visual-presentation]
Results shown through intuitive comparative visualizations:
* Side-by-side histograms
* Bar charts showing percentage differences
* Distribution overlays
* Ranked attribute list by impact

### 5. Intelligent summary [#intelligent-summary]
ACA provides automated insights:
* Probable root cause identification
* Confidence indicators
* Explanation of behavioral differences
* Recommended investigation path

{/* TODO: Add screenshot of complete ACA results */}

## Key benefits [#benefits]

<table>
  <thead>
    <tr>
      <th width={200}>Benefit</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Faster root cause identification**</td>
      <td>Minutes instead of hours to find differentiating attributes</td>
    </tr>
    <tr>
      <td>**Reduced MTTR**</td>
      <td>Quickly understand why issues occur, accelerate remediation</td>
    </tr>
    <tr>
      <td>**Lower expertise barrier**</td>
      <td>Automated analysis helps less experienced engineers</td>
    </tr>
    <tr>
      <td>**Handles high cardinality**</td>
      <td>Analyzes attributes with thousands of unique values automatically</td>
    </tr>
    <tr>
      <td>**Unbiased analysis**</td>
      <td>Statistical approach avoids confirmation bias</td>
    </tr>
    <tr>
      <td>**Comprehensive coverage**</td>
      <td>Analyzes all attributes, not just suspected ones</td>
    </tr>
  </tbody>
</table>

## Requirements and prerequisites [#requirements]

To use Attribute Correlation Analysis:

* **Distributed tracing enabled** on relevant services
* **Sufficient trace data** (recommended: 100+ traces in each group)
* **Attributes populated** on spans (more attributes = better analysis)
* **ACA access** (Limited Preview - contact your account team)

**Optimal conditions:**
* 500+ traces in anomalous group for robust statistics
* Clear baseline period without the issue
* Rich attribute instrumentation (custom attributes especially valuable)
* Time windows large enough to capture representative samples

## Common use cases [#use-cases]

### Latency investigation [#latency-investigation]
**Scenario:** Response times suddenly increased for a subset of requests.

**Using ACA:**
* Select slow traces (> 2 seconds)
* Compare against fast traces (< 500ms)
* ACA reveals: `database_shard: "shard-07"` appears in 85% of slow traces vs 12% of fast
* **Root cause found:** shard-07 experiencing performance degradation

### Error root cause [#error-root-cause]
**Scenario:** New error type appearing intermittently.

**Using ACA:**
* Select traces containing the error
* Compare against successful traces
* ACA reveals: `feature_flag_new_checkout: true` in 98% of error traces vs 50% of successful
* **Root cause found:** New checkout feature has a bug

### Performance regression [#performance-regression]
**Scenario:** After deployment, some requests slow down significantly.

**Using ACA:**
* Select post-deployment slow traces
* Compare against pre-deployment traces
* ACA reveals: `app_version: "v2.5.1"` and `cache_tier: "distributed"` correlation
* **Root cause found:** v2.5.1 distributed cache implementation has issue

### Intermittent issues [#intermittent-issues]
**Scenario:** Problem occurs occasionally, hard to reproduce.

**Using ACA:**
* Collect traces over extended period (24+ hours)
* Select problematic traces
* Compare against normal traces
* ACA reveals temporal or conditional patterns
* **Root cause found:** Issue correlates with specific time-of-day, customer segment, or configuration

{/* WRITING NOTES: Add 4,000+ more words with sections on:
- Detailed architecture
- Step-by-step workflow example
- Comparison with manual analysis
- Statistical methods explained
- Getting started guide
- Integration with other features
- Best practices
- Limitations and when not to use
- FAQ section
*/}

