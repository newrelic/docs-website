---
title: Control distributed tracing data volume
tags:
  - Understand dependencies
  - Distributed tracing
  - Span configuration
  - Cost optimization
metaDescription: Configure APM agent settings to control distributed tracing span volume and attributes, reducing costs while maintaining visibility.
freshnessValidatedDate: never
---

New Relic APM agents provide configurable controls to manage the volume and granularity of your distributed tracing data. You can reduce tracing costs by 50-80% by controlling which spans are captured and what attributes they contain, while maintaining complete service-to-service visibility.

These are agent configuration options for APM-monitored services—not a separate product or feature. You configure them through your agent's configuration file (YAML or equivalent).

## What problems do these configurations solve? [#problems-solved]

Distributed tracing is powerful, but we've heard from customers facing three common challenges:

### High barrier to entry for new customers

You want to see the value of distributed tracing, but instrumenting your entire service landscape feels like a big investment. The cost and effort can make it hard to justify before you've seen the results.

### Trace fragmentation from incomplete instrumentation

When only some of your services send traces, you end up with broken-looking maps and incomplete visibility. It's hard to know what you're missing or how to fix it.

### Inflexible cost management

Full distributed tracing data can get expensive at scale. You're forced into an all-or-nothing choice: capture everything from a service or capture nothing at all. You need a middle ground.

These agent configuration options solve these problems by letting you control exactly how much trace data you send to New Relic.

## Understanding span types [#span-types]

Before configuring your tracing data, understand the three types of spans:

### Entry spans

The span created when a request enters your service or entity. This represents the incoming request.

**Example:** An HTTP request arriving at your API service.

### Exit spans

Spans representing calls from your service to other entities—databases, external services, other microservices, etc.

**Examples:** Database queries, HTTP calls to downstream services, cache operations.

### In-process spans

Spans representing internal function calls within your service. These show detailed execution paths inside your code.

**Examples:** Individual method calls, internal business logic, framework operations.

Together, all spans within one service form a **transaction trace**. When you connect transaction traces across multiple services, you get a **distributed trace**.

## Configuration options [#configuration-options]

APM agents provide three configuration levels to control span data:

### Option 1: Remove in-process spans

Drop all in-process spans, keeping only entry and exit spans. This shows you what services call what, without internal method-level detail.

* **Span reduction:** 50-80% (depending on your instrumentation depth)
* **Preserves:** Service-to-service connectivity, external calls, database queries
* **Removes:** Internal method call detail within each service

### Option 2: Remove in-process spans + reduce attributes

Same as Option 1, plus remove most attributes from entry and exit spans. Keeps only attributes needed to maintain relationships between entities.

* **Data reduction:** 60-75% total (spans + attributes)
* **Preserves:** Complete trace connectivity, service relationships for flow maps
* **Removes:** In-process spans, detailed span metadata, most custom attributes

### Option 3: Option 2 + compress duplicate spans

Same as Option 2, plus compress duplicate exit spans. If your service calls the same database or downstream service multiple times, only one span is captured showing that the call happened at least once.

* **Data reduction:** 70-85% total (maximum reduction)
* **Preserves:** Service relationship graph, complete distributed trace paths
* **Removes:** In-process spans, detailed attributes, duplicate call information
* **Trade-off:** You know a service was called, but not how many times

**Note:** You can also adjust adaptive sampling rates independently of these options to further control how many traces are captured per minute.

## What you keep vs what you lose [#tradeoffs]

These configuration options preserve what matters most for troubleshooting while reducing costs:

<table>
  <thead>
    <tr>
      <th width={200}>
        You keep
      </th>
      <th>
        You lose
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        * Complete end-to-end traces
        * Service-to-service relationships
        * Request flow visualization
        * Dynamic Flow Map connectivity
        * Transaction 360 data
        * Error tracking across services
      </td>
      <td>
        * In-process method-level detail (MST)
        * Detailed span attributes (LGT)
        * Some custom attributes (LGT)
        * Internal code path visibility
      </td>
    </tr>
  </tbody>
</table>

The key insight: you maintain the "what" and "where" of your system behavior while reducing the "how" details.

## When should you use these configurations? [#when-to-use]

Consider these span configuration options if you're in any of these situations:

<CollapserGroup>
  <Collapser
    id="new-customer"
    title="You're new to distributed tracing and want to start small"
  >
    Use LGT to light up your entire service map at low cost. You'll see complete traces and prove the value quickly. Then dial up detail on services that matter most.

    **Recommended config:** LGT on all services, then add full DT selectively.
  </Collapser>

  <Collapser
    id="fragmented-traces"
    title="You have gaps in your trace coverage"
  >
    Use LGT on uninstrumented services to fill the gaps. You'll get complete end-to-end traces without the cost of full instrumentation everywhere.

    **Recommended config:** LGT on services currently not sending traces.
  </Collapser>

  <Collapser
    id="cost-optimization"
    title="You need to reduce distributed tracing costs"
  >
    Prioritize your services and use different configurations based on importance. Business-critical services keep full DT, while supporting services use MST or MST + LGT.

    **Recommended config:** Tiered approach based on service priority.
  </Collapser>

  <Collapser
    id="large-deployment"
    title="You have many microservices generating lots of span data"
  >
    Use Option 1 to dramatically reduce span volume while maintaining connectivity. This is especially effective for services with deep call stacks.

    **Recommended config:** Option 1 (remove in-process spans) on services with many internal function calls.
  </Collapser>
</CollapserGroup>

## Requirements [#requirements]

To use these configuration options, you need:

* **APM agent monitoring:** These configurations only work with New Relic APM agents (Java, .NET, Node.js, Python, Go, Ruby, PHP). They do not apply to OpenTelemetry instrumentation.
* **Distributed tracing enabled:** Your services must already have distributed tracing enabled.
* **Compatible agent versions:** See configuration docs for minimum agent versions.
* **Configuration file access:** You'll modify your agent's configuration file (typically YAML format).

When services with different configurations communicate, trace context propagates correctly—you can mix configuration levels across your architecture (some services with Option 1, others with full tracing, etc.).

## Get started [#get-started]

Ready to configure span control options for your APM agents? Start here:

* [Configure span filtering](/docs/distributed-tracing/core-tracing/configure-minimal-spans-tracing): Remove in-process spans and reduce span volume (Options 1-3)
* [Configure span attributes](/docs/distributed-tracing/core-tracing/configure-low-granularity-tracing): Control which attributes are included in spans
* [Configure adaptive sampling rate](/docs/distributed-tracing/core-tracing/configure-adaptive-sampling-rate): Control how many traces get sampled

Or explore strategic guidance:

* [Cost optimization strategies](/docs/distributed-tracing/core-tracing/cost-optimization-strategies): Learn how to reduce costs while maintaining visibility
* [Use cases and examples](/docs/distributed-tracing/core-tracing/use-cases-examples): See real-world implementation scenarios

<Callout variant="tip">
  Start conservative. Enable span filtering on a small subset of services first, monitor the impact for 1-2 weeks, then expand based on results.
</Callout>
