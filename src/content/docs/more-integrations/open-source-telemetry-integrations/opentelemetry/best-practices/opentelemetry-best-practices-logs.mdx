---
title: OpenTelemetry logs in New Relic
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Logs
translate:
  - kr
metaDescription: Details on how New Relic works with OpenTelemetry logs
freshnessValidatedDate: never
---

There are two typical workflows for collecting logs with OpenTelemetry:

- [Direct to collector](https://opentelemetry.io/docs/specs/otel/logs/#direct-to-collector): Send logs directly from an application to an OTLP endpoint. For details, see relevant [OpenTelemetry language documentation](https://opentelemetry.io/docs/languages/).
- [Via file or stdout](https://opentelemetry.io/docs/specs/otel/logs/#via-file-or-stdout-logs): Scrape application logs from a file or stdout (typically with the OpenTelemetry Collector) and send to an OTLP endpoint. For details, see [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/) documentation, including [Filelog receiver with kubernetes](https://opentelemetry.io/docs/kubernetes/collector/components/#filelog-receiver). A working code example of this workflow is available [here](https://github.com/newrelic/newrelic-opentelemetry-examples/tree/main/other-examples/java/logs-in-context-log4j2).

In either case, integrating these workflows with New Relic requires configuring the logs to be exported to the [New Relic OTLP Endpoint](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp). Please review New Relic OTLP endpoint configuration requirements.

## OTLP Log Record Mapping [#otlp-mapping]

New Relic maps OTLP log records to the `Log` data type. The table below describes how fields from the [LogRecord proto message](https://github.com/open-telemetry/opentelemetry-proto/blob/main/opentelemetry/proto/logs/v1/logs.proto) are interpreted:

| Field                                       | New Relic `Log` field                              |
|---------------------------------------------|----------------------------------------------------|
| `ResourceLogs.Resource.attributes`          | Each key/value is an attribute on the `Log`**[1]** |
| `ScopeLogs.InstrumentationScope.name `      | `otel.library.name`                                |
| `ScopeLogs.InstrumentationScope.version`    | `otel.library.version`                             |
| `ScopeLogs.InstrumentationScope.attributes` | Each key/value is an attribute the `Log`**[1]**    |
| `LogRecord.time_unix_nanos`                 | `timestamp` **[2]**                                |
| `LogRecord.severity_number`                 | `severity.number`                                  |
| `LogRecord.severity_text`                   | `severity.text`                                    |
| `LogRecord.body`                            | `message`, and possibly parsed attributes **[3]**  |
| `LogRecord.attributes`                      | Each key/value is an attribute on the `Log`**[1]** |
| `LogRecord.dropped_attribute_count`         | `otel.dropped_attributes_count`                    |
| `LogRecord.flags`                           | `w3c.flags` (integer)                              |
| `LogRecord.trace_id`                        | `trace.id`                                         |
| `LogRecord.span_id`                         | `span.id`                                          |

**[1]**: In case of conflict in resource attributes, scope attributes, log record attributes, top level log record fields, and parsed attributes from the log record body` **[3]**, the order of precedent (highest to lowest) is: parsed attributes from log record body -> log record fields > log record attributes > scope attributes > resource attributes.

**[2]**: If `LogRecord.time_unix_nanos` is not present, `timestamp` is set to the time that the data was received by New Relic.

**[3]**: [Log parsing](/docs/logs/ui-data/parsing/) is applied to the `LogRecord.body` to attempt to extract attributes from plain log text. For example, if a JSON structured log format is used, the key / values become attributes on the resulting log. This is particularly useful when collecting logs from files or stdout. In this case, it's common to have no resource attributes associated with the log record (required for [APM service correlation](#service-correlation)) and no value for `LogRecord.trace_id` / `LogRecord.span_id` (required for [trace correlation](#trace-correlation)). Correlation will function as intended if the required fields can be successfully parsed.

## Correlation with OpenTelemetry APM service [#service-correlation]

Log are correlated with a service entity if they include the [required attributes](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-resources/#required-attributes). Typically, these come from the log's resource attributes (i.e `ResourceLogs.Resource.attributes`), but can also be parsed from the `LogRecord.body` as described in footnote 3 of [OTLP Mapping](#otlp-mapping).

To view a service's logs, navigate to the "Logs" page for that service.

## Correlation with traces [#trace-correlation]

Logs are correlated with a trace if `trace.id` and `span.id` attributes can be resolved. Typically, these come from `LogRecord.trace_id` and `LogRecord.span_id` fields, but can also be parsed from the `LogRecord.body` as described in footnote 3 of [OTLP Mapping](#otlp-mapping).

To view logs recorded in the context of a particular trace, navigate to the "Logs" tab within the [trace details page](/docs/distributed-tracing/ui-data/trace-details/).

It's also possible to go the other way, starting at logs and navigating to the associated trace: Navigate to the "Logs" page for a service and click on a log to open "Log details". If it is associated with a trace, you can navigate from "Log details" to "Trace details".
