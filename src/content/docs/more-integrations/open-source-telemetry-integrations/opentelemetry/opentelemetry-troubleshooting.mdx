---
title: Troubleshooting OpenTelemetry with New Relic
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
metaDescription: Troubleshoot tips for when you use OpenTelemetry with New Relic
freshnessValidatedDate: never
---

import moreintegrationsOtlpFacetQuery from 'images/more-integrations_screenshot-crop_otlp-facet-query.webp'

Troubleshooting OpenTelemetry with New Relic may just be a matter of making sure you are following [best practices](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-concepts), but sometimes you may need to take additional steps to diagnose your issues. Here are some examples of specific problems you might encounter, along with steps and tools to resolve them.

## OpenTelemetry data sent via OTLP is not queryable

### Problem

You sent OpenTelemetry metrics, logs, or traces using OTLP and are unable to view the data. Before digging deeper, make sure you've checked the following:

* The OTLP endpoint configured matches one of our [documented endpoints](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/get-started/opentelemetry-set-up-your-app/#review-settings), is properly formatted, and includes the [default port for OTLP/gRPC](https://github.com/open-telemetry/opentelemetry-specification/blob/v1.8.0/specification/protocol/otlp.md#otlpgrpc-default-port), 4317, or the [default port for OTLP/HTTP](https://github.com/open-telemetry/opentelemetry-specification/blob/v1.8.0/specification/protocol/otlp.md#otlphttp-default-port), 4318. Port 443 is also supported for either transport. Please note the specific endpoint for FedRAMP compliance, if applicable.
* Confirm that you are using the correct endpoint based on your region. For example, if you are based in Europe and configure your exporter to send data to our US endpoint, data will fail to be exported as the endpoints are region-specific.
* The outbound traffic is not restricted by a firewall. Our [Networks](/docs/using-new-relic/cross-product-functions/install-configure/networks/#opentelemetry) document explains domains and network blocks that you may need to explicitly allow.
* The client is configured to use TLS 1.2 or higher and the request includes the `api-key` header with a valid New Relic <InlinePopover type="licenseKey" />.
* Requests include valid protobuf payloads and use gRPC or HTTP transport, preferably with [gzip compression](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-concepts/#compression) enabled. Request payloads should be no larger than 1MB (10^6 bytes). [JSON-encoded protobuf](https://github.com/open-telemetry/opentelemetry-specification/blob/v1.8.0/specification/protocol/otlp.md#otlphttp-connection) payloads are also supported.
* Client output and logs do not indicate `4xx` or `5xx` response codes are being returned.

### Solution

There are number of tools you can use to validate the successful delivery of telemetry data to our platform. A good first step is to check the [data management hub](/docs/data-apis/manage-data/manage-your-data/) to [facet data ingest](/docs/data-apis/manage-data/manage-data-coming-new-relic/#facet-data-ingest) and determine how much data is arriving from various sources. You can also use [metrics and events](/docs/query-your-data/explore-query-data/browse-data/introduction-data-explorer/#use-case-troubleshooting) or [query builder](/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data) to look for data faceted by `instrumentation.provider` or `newrelic.source` attributes:

```sql
FROM Log, Metric, Span SELECT datapointcount() WHERE instrumentation.provider = 'opentelemetry' FACET instrumentation.provider, newrelic.source
```

<img
  title="Screenshot showing the data point count for logs, metrics, and traces faceted by instrumentation.provider and newrelic.source"
  alt="Screenshot showing the data point count for logs, metrics, and traces faceted by instrumentation.provider and newrelic.source"
  src={moreintegrationsOtlpFacetQuery}
/>

This query should tell you whether data is arriving via OTLP. If the data you expect is not present, try this alternate query:

```sql
FROM Log, Metric, Span SELECT count(*) where newrelic.source LIKE 'api.%.otlp'
```

You can also check for integration errors by querying [NrIntegrationError events](/docs/data-apis/manage-data/nrintegrationerror/). This can help you determine whether you have configuration or format issues or if you've run into our platform limits.

<Callout variant="important">
  The ingest limits for metrics, logs, and traces via OTLP are the same as our other [data ingest API limits](/docs/data-apis/manage-data/view-system-limits/#data-ingest-api-limits).
</Callout>

Various parts of the New Relic UI rely on the presence of specific attributes to function properly. You can use the [NRQL console](/docs/query-your-data/explore-query-data/query-builder/nrql-console/) feature in many places to check the `WHERE` or `FACET` clauses of the query for required attributes. You can also edit those clauses and re-run the query to determine whether there is data present with those attributes missing. Examples of required attributes include `service.name` and `service.instance.id`. For a more complete list of examples, see [resources](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-concepts/#resources).

## OpenTelemetry log correlation isn't working

### Problem

You've correlated your logs with your service using `service.name`([OpenTelemetry logs: Best practices](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-best-practices-logs)) so you can see logs associated with traces, but you don't see any logs in the New Relic UI. In this scenario, the log data has made it to New Relic, but isn't showing up in the distributed trace UI with corresponding spans.

### Solution

To correlate your logs with trace data, the logs need to include the trace context that is contained `trace_id` and `span_id`. However, to ensure your logs show up in the New Relic UI, you'll need to configure rules in your log pipeline to translate `trace_id` and `span_id` to `trace.id` and `span.id`.

## OpenTelemetry entities or relationships are missing

### Problem

You sent OpenTelemetry data from a service or infrastructure component and either the [entity](/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/) or its [relationships](/docs/new-relic-one/use-new-relic-one/core-concepts/what-entity-new-relic/#related-entities) are missing or incorrect.

### Solution

OpenTelemetry entities will be synthesized based on the [public rules](https://github.com/newrelic/entity-definitions/blob/b8e75d839eed7859044a9bb601a62e5323107350/definitions/ext-service/definition.yml) described for the `EXT-SERVICE` entity type. The standard rule to match relies on the presence of the `service.name` dimension which follows the OpenTelemetry [semantic conventions](https://github.com/open-telemetry/opentelemetry-specification/blob/527206ea49e384de957eda105d9425aa8fefca25/specification/overview.md#semantic-conventions).

To set the `service.name` with the OpenTelemetry Java SDK, include it in your [resource](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-concepts/#resources):

```java
var resource = Resource.getDefault()
    .merge(Resource.builder().put(SERVICE_NAME, serviceName).build());
```

Depending on the SDK, you may also set the `service.name` by declaring it in the `OTEL_RESOURCE_ATTRIBUTES` or `OTEL_SERVICE_NAME` [environment variables](https://github.com/open-telemetry/opentelemetry-specification/blob/20c82de552d08428e8cadaaef3e6cb46812f7c00/specification/sdk-environment-variables.md#general-sdk-configuration).

For <InlinePopover type="logs" />, you can use a structured log template to inject the `service.name`. See [Logs in context with Log4j2](https://github.com/newrelic/newrelic-opentelemetry-examples/blob/e3f5ee85b4dcd8dd29f8f69d78d122b82a9638ba/other-examples/java/logs-in-context-log4j2/Log4j2EventLayout.json#L2) for an example.

<Callout variant="tip">
  For more OpenTelemetry examples with New Relic, visit the [newrelic-opentelemetry-examples](https://github.com/newrelic/newrelic-opentelemetry-examples) repository on GitHub.
</Callout>

## Troubleshooting the OpenTelemetry Collector [#troubleshooting-collector]

The best place for collector troubleshooting tips and monitoring practices is the up-to-date guidelines in the OpenTelemetry community. See the links below for community troubleshooting documents.

### Collector logs [#collector-logs]

Set the log level in the config `service::telemetry::logs`. The default level is `INFO`. Supported levels are: `DEBUG`, `INFO`, `WARN`, `ERROR`, `DPANIC`, `PANIC`, `FATAL`.

For troubleshooting tips, see [logs troubleshooting (GitHub)](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/troubleshooting.md#logs).

### Collector metrics [#collector-metrics]

The following NRQL query shows all the available metrics from the collector itself in New Relic:

```sql
FROM Metric SELECT uniques(metricName) WHERE metricName like ‘otelcol_%’ LIMIT MAX
```

For troubleshooting tips, see:

* [Metric troubleshooting (GitHub)](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/troubleshooting.md#metrics)
* [Monitoring collector metrics (GitHub)](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/monitoring.md)

### Collector traces [#collector-traces]

For troubleshooting tips, see [zPages (Github)](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/troubleshooting.md#zpages).
