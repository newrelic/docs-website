---
title: Reduce noise with quality alerts
metaDescription: "Evaluate the quality of your alerts before a peak gameday event by installing the alert quality management dashboard."
redirects:
  - /docs/journey-demand/create-quality-alerts/
freshnessValidatedDate: never
---

Redundant alerts bury critical incidents under noise. Assessing your existing alerts is a key part of your prioritization strategy, as the quality of your alerts translates into how well your teams respond to incidents. If there's too much noise, you risk fatiguing your team with low priority incidents that have little or no business impact. Incidents that fail to alert, however, lead to outages that affect customer experience.

## Objectives [#objective]

This tutorial assumes you already have active alerts. It offers some recommendations about managing the quality of your alerts and provides some NRQL queries for creating new ones. You will:

* Install the alert quality management (AQM) dashboard
* Differentiate between a good and bad alert
* Review our recommended NRQL strings for creating alerts

## Install the AQM dashboard [#install]

AQM focuses on reducing the number of nuisance incidents so that your team focuses on <InlinePopover type="alerts"/> with true business impact. You're a good candidate for AQM if:

* You have too many alerts.
* You have alerts that stay open for long time periods.
* Your customers discover your issues before your monitoring tools do.

To begin, install the AQM dashboard via our quickstart:

1. [Go to the <DNT>**Alert Quality Management**</DNT> instant observability page.](https://newrelic.com/instant-observability/alert-quality-management)
2. Click on the <DNT>**Install now**</DNT> button.
3. Follow the prompts to choose the account you want to install the dashboard into.
4. View your dashboard.

<img
  title="AQM Dashboard"
  alt="AQM Dashboard"
  src="/images/alerts_screenshot-crop_AQM-dashboard.webp"
/>

We recommend you spend at least two weeks with the AQM dashboard. During that time, the AQM dashboard will collect data about how your teams interact with all of your alerts.

As a general rule, we recommend removing these types of alerts:

* Generate "always-on" incidents that have thousands of minutes or more of cumulative duration.
* Where 30% or more of incidents are open for less than 5 minutes.
* Whose mean-time-to-close is longer than 30 minutes.
* Create more than 350 incidents per week.

## Create new alerts for peak demand [#new-alerts]

With your existing policies under review, you may want to create new alerts that are adjusted for peak demand. Creating a good alert depends on the specificity of your settings. Two alerts can share the same alert condition query, for example:

```sql
SELECT average(`apm.service.memory.heap.used`) FROM Metric WHERE appName = 'Inventory Service'
```

While the query itself is a strong alert policy, how you configure this alert can create redundancy or noise. A bad alert may have too small a window duration, a low threshold, or no delay or baseline. Additionally, attaching an alert condition to a relatively young data source can also create problems, as there's not enough history to detect anamlous behavior.

If you're ready to create new alerts, here are some recommended queries you can use for your gameday:

<CollapserGroup>
  <Collapser
    id="constrained-alerts"
    title="Alert on specific segments of your data"
  >
    Create constrained alerts that target a specific segment of your data, such as a few key customers or a range of data. Use the `WHERE` clause to define those conditions.

    ```sql
    SELECT average(duration) FROM Transaction WHERE account_id in (91290, 102021, 20230)
    ```

    ```sql
    SELECT percentile(duration, 95) FROM Transaction WHERE name LIKE 'Controller/checkout/%'
    ```
  </Collapser>

  <Collapser
    id="nth-percentile"
    title="Alert on Nth percentile of your data"
  >
    Create alerts when an Nth percentile of your data hits a specified threshold; for example, maintaining SLA service levels. Since we evaluate the NRQL query based on the aggregation window duration, percentiles will be calculated for each duration separately.

    ```sql
    SELECT percentile(duration, 95) FROM Transaction
    ```

    ```sql
    SELECT percentile(databaseDuration, 75) FROM Transaction
    ```
  </Collapser>

  <Collapser
    id="max-min-avg"
    title="Alert when data hits a maximum, minimum, or average"
  >
    Create alerts when your data hits a certain maximum, minimum, or average. This ensures that a duration or response time does not pass a certain threshold.

    ```sql
    SELECT max(duration) FROM Transaction
    ```

    ```sql
    SELECT average(duration) FROM Transaction
    ```
  </Collapser>

  <Collapser
    id="percentage"
    title="Alert on a percentage of your data"
  >
    Create alerts when a proportion of your data goes above or below a certain threshold.

    ```sql
    SELECT percentage(count(*), WHERE duration > 2) FROM Transaction
    ```

    ```sql
    SELECT percentage(count(*), WHERE http.statusCode = '500') FROM Transaction
    ```
  </Collapser>

  <Collapser
    id="apdex"
    title="Alert on Apdex with any T-value"
  >
    Create alerts on [Apdex](/docs/apm/new-relic-apm/apdex/apdex-measuring-user-satisfaction), applying your own T-value for certain transactions. For example, get an alert notification when your Apdex for a T-value of 500ms on transactions for production apps goes below 0.8.

    ```sql
    SELECT apdex(duration, t:0.5) FROM Transaction WHERE appName like '%prod%'
    ```
  </Collapser>
</CollapserGroup>

<DocTiles numbered>
  <DocTile
    title="Get started"
    path="/docs/journey-demand/get-started"
  >
    Get data about your architecture with APM and infrastructure agents
  </DocTile>

  <DocTile
    title="Create service levels for gameday"
    path="/docs/journey-demand/find-your-baseline/"
  >
    Create service levels informed by your baseline
  </DocTile>
</DocTiles>

<DocTiles>
  <DocTile
    title="Reduce noise with quality alerts"
    number="3"
    path="/docs/journey-demand/create-quality-alerts/"
    label={{text: "You are here", color: "orange"}}
  >
    Evaluate your alerts with alert quality management
  </DocTile>

  <DocTile
    title="Align your teams with workloads"
    number="4"
    path="/docs/journey-demand/organize-data-workloads/"
  >
    Align your teams around the same data
  </DocTile>

  <DocTile
    title="Autoscale your infrastructure with Kubernetes"
    number="5"
    path="/docs/journey-demand/autoscale-your-infra/"
  >
    Scale your resources as demand peaks
  </DocTile>
</DocTiles>
