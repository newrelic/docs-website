---
title: "Advance your dashboarding with NRQL"
tags:
  - NRQL tutorial
  - 'NRQL: New Relic query language'
  - Get started
  - Tutorial
metaDescription: "Learn how to use NRQL to improve your dashboarding"
---

import queriesnrql2tutorial1 from 'images/queries-nrql_screenshot-crop-tutorial2-1.webp'

import queriesnrql2tutorial2 from 'images/queries-nrql_screenshot-crop-tutorial2-2.webp'

import queriesnrql2tutorial3 from 'images/queries-nrql_screenshot-crop-tutorial2-3.webp'

import queriesnrql2tutorial4 from 'images/queries-nrql_screenshot-crop-tutorial2-4.webp'

import queriesnrql2tutorial5 from 'images/queries-nrql_screenshot-crop-tutorial2-5.webp'

import queriesnrql2tutorial6 from 'images/queries-nrql_screenshot-crop-tutorial2-6.webp'

import queriesnrql2tutorial7 from 'images/queries-nrql_screenshot-crop-tutorial2-7.webp'

import queriesnrql2tutorial8 from 'images/queries-nrql_screenshot-crop-tutorial2-8.webp'

import queriesnrql2tutorial9 from 'images/queries-nrql_screenshot-crop-tutorial2-9.webp'

import queriesnrql2tutorial10 from 'images/queries-nrql_screenshot-crop-tutorial2-10.webp'

import queriesnrql2tutorial11 from 'images/queries-nrql_screenshot-crop-tutorial2-11.webp'

import queriesnrql2tutorial12 from 'images/queries-nrql_screenshot-crop-tutorial2-12.webp'

import queriesnrql2tutorial13 from 'images/queries-nrql_screenshot-crop-tutorial2-13.webp'

import queriesnrql2tutorial14 from 'images/queries-nrql_screenshot-crop-tutorial2-14.webp'

import queriesnrql2tutorial15 from 'images/queries-nrql_screenshot-crop-tutorial2-15.webp'

import queriesnrql2tutorial16 from 'images/queries-nrql_screenshot-crop-tutorial2-16.webp'

import queriesnrql2tutorial17 from 'images/queries-nrql_screenshot-crop-tutorial2-17.webp'

import queriesnrql2tutorial18 from 'images/queries-nrql_screenshot-crop-tutorial2-18.webp'

import queriesnrql2tutorial19 from 'images/queries-nrql_screenshot-crop-tutorial2-19.webp'

import queriesnrql2tutorial20 from 'images/queries-nrql_screenshot-crop-tutorial2-20.webp'

Welcome! We hope seeing example queries and explanations in the context of your own data helps you better understand how to transform data into powerful visuals. (Try queries from this course on different event types in your own account(s) to really understand their power!)

We are now moving on to even more advanced concepts. You may not use these functions and features on every single dashboard, but they will certainly come in handy when tackling specific problems and requirements.

In this level, we will cover faceting by case, advanced aggregation functions, the value of the EXT RAPOLATE keyword, filtering aggregation functions, and how to override values. Remember if you've chosen an account without APM data. You will see backup queries that may not match the lesson description. 

Specifically, you'll learn how to use:

* Advanced aggregation functions like `filter()`, `apdex()`, `rate()funnel()`, `histogram()`.
* The `EXTRAPOLATE` clauses.
* `FACET CASES()`, including how to use attribute and group matching values.
* `filter()` to combine Event Types.
* Overriding values, when necessary.

### Use advanced aggregators 
<Steps>
    <Step>
#### Calculating Rate
Let's start with the `rate()` function. It allows you to visualize the frequency of events over time. This is helpful when you want to understand the frequency of events in small periods of time within larger time windows.

In the example below, we display the average frequency of requests per 5 minutes for the last hour. We compare this to the previous hour's 5-minute average frequency. Notice the query uses `SINCE 1 hour ago`, this is the overall time window in which we are calculating the rate.

You can use `rate()` to calculate requests per minute or requests per second by setting the time interval to either 1 minute or 1 second.

<SideBySide>
    <Side>
```sql
SELECT rate(count(*), 5 minutes) 
FROM Public_APICall 
SINCE 1 hour ago 
COMPARE WITH 1 hour ago
```
    </Side>
    <Side>
<img
    title="Calculate range"
    alt="A screenshot of a query using Since and Compare to capture data within a time range"
    src={queriesnrql2tutorial1}
/>
    </Side>
</SideBySide>

    </Step>
    <Step>
#### Funnel Charts
Many New Relic customers use funnel charts to understand end-user behavior. Funnel charts track the occurrence of an attribute value across multiple records. They are commonly used to visualize how successfully users' progress through defined paths, and are especially powerful when using custom attributes.

Here we use the `funnel()` aggregator function to visualize how many users visit the home page, then proceed to another page. The first parameter is the identifying attribute for the unique entries we're counting. In this case, New Relic Browser assigns and retains a `session ID` attribute for each user on your site (subject to cookies being enabled). You can also set your own session ID using custom attributes.

The remaining parameters determine how each step of the funnel is calculated. They are written in the format "`, WHERE attr OP value`". In this case, we provide two: we want to know how many user sessions visited the homepage, then also how many of these also navigated to other pages. Try this query on your own data to get a reasonable result.

<SideBySide>
    <Side>
```sql
SELECT funnel(awsAPI, WHERE http.url LIKE '%.amazonaws.com', WHERE http.url LIKE '%.us-west%.amazonaws.com') 
FROM Public_APICall 
SINCE 1 week ago 
UNTIL now
```
    </Side>
    <Side>
<img
    title="Funnel Charts"
    alt="A screenshot displaying the funnel charts functionality"
    src={queriesnrql2tutorial2}
/>
    </Side>
</SideBySide>

    </Step>
    <Step>
#### Aggregator Filters
`filter()` is a powerful tool that allows you to aggregate multiple data points in a single query, offering more control over which events are included in function results. In this example, we use `filter()` to return the separate values for total transactions, total web transactions, and total non-web transactions:

```sql
SELECT count(*) AS 'All Transactions', filter(count(*), WHERE awsAPI = 'dynamodb') AS 'DynamoDB', filter(count(*), WHERE awsAPI = 'sqs') AS 'SQS' 
FROM Public_APICall SINCE 1 day ago
```
<img
    title="Aggregator filters"
    alt="A screenshot displaying the aggregator filter functionality"
    src={queriesnrql2tutorial3}
/>
Since it returns a number, you can also perform math on its results. For example, we can divide total web transactions by all transactions to determine what percent of transaction were web transactions:

<SideBySide>
    <Side>
```sql
SELECT filter(count(*), WHERE awsAPI = 'dynamodb') / count(*) AS 'Percent of APIs that are DynamoDB' 
FROM Public_APICall 
SINCE 1 day ago
```
    </Side>
    <Side>
<img
    title="Aggregator filters divided"
    alt="A screenshot showing the aggregator filters divided"
    src={queriesnrql2tutorial4}
/>
    </Side>
</SideBySide>

    </Step>
    <Step>
#### Histograms
Histograms allow you to better visualize the distribution of your data. This assists in understanding how data points are grouped by frequency, not just averages. The `histogram()` function takes three arguments:
1. the attribute you want to plot (such as duration)
2. the maximum value of the range you want to consider (such as "1" for 1 second or less)
3. the number of buckets you want data grouped in
In our example, we create a `histogram()` chart for all duration values between 0 and 1 second, grouped into 50ms buckets. We do this by specifying "20" for the number of buckets. All the durations larger than 1 second are grouped together in the last bucket.


<SideBySide>
    <Side>
```sql
SELECT histogram(duration, 1, 20) 
FROM Public_APICall 
SINCE 1 day ago
```
    </Side>
    <Side>
<img
    title="Histograms"
    alt="A screenshot showing the histogram functionality"
    src={queriesnrql2tutorial5}
/>
    </Side>
</SideBySide>
    </Step>
    <Step>
#### Apdex
The `apdex()` function calculates an Apdex score on any numerical value (such as duration). You can calculate Apdex for one or more specific transactions, account for custom attribute values, and even provide your own Apdex-T value without interfering with application settings. In this example, we have provided the function with an attribute of "duration" and an Apdex-T value of 0.08:

```sql
SELECT apdex(duration, 0.1) AS 'Apdex Of Duration' 
FROM Public_APICall 
SINCE 1 week ago
```
<img
    title="Apdex"
    alt="A screenshot showing the apdex functionality"
    src={queriesnrql2tutorial6}
/>

We can also add the `TIMESERIES` operator to chart the data over time. Notice this also plots the Apdex satisifed, tolerated, and frustrated thresholds.

<SideBySide>
    <Side>
```sql
SELECT apdex(duration, 0.1) AS 'Apdex Of Duration' 
FROM Public_APICall 
SINCE 1 week ago 
TIMESERIES
```
    </Side>
    <Side>
<img
    title="Apdex timeseries"
    alt="A screenshot showing an apdex timeseries"
    src={queriesnrql2tutorial7}
/>
    </Side>
</SideBySide>
    </Step>
</Steps>

We just explored a whole new set of visualizations with `funnel()` and `histogram()`. We also learned how `filter()` can help us get more specific in queries with WHERE clauses, and how `rate()` can display the rate of an attribute over time.

These queries further advance your NRQL ability. Apdex is an industry standard and is applicable in many scenarios. Funnels can track progress through desired paths. Histograms visualize the clear distribution of the data; and filters let you get super specific with your returned values. Next, we will learn about `EXTRAPOLATE`.

### Use extrapolate

The New Relic Database (NRDB) receives and processes enormous amounts of data, every day, at lightning speed! When APM records a large amount of event data, New Relic agents implement a sampling technique to continue collecting meaningful data while reducing potential impact to your applications. This usually only happens when a single event in an application or service handles extremely high volumes of requests. If multiple agents are spread across multiple load-balanced instances of a service, this limit might never be observed.

Let's discuss what we can do when this happens. The `EXTRAPOLATE` operator tells New Relic to mathematically compensate for the effects of sampling, thereby returning results that more closely represent activity in your system. We store an extra value to record how many similar events occured over the limit. This allows New Relic to deliver statistically accurate results. There is no fallback query for this if you have no APM data due to the fact this is specific to Transaction events.

```sql
SELECT count(*) 
FROM Transaction 
SINCE 60 minutes ago 
FACET appName 
TIMESERIES 1 minute 
EXTRAPOLATE
```
<img
    title="Extrapolate"
    alt="A screenshot showing the extrapolate functionality"
    src={queriesnrql2tutorial8}
/>

You might be thinking "are we hitting the limit?" Well, try removing `EXTRAPOLATE` from the query, and see if your count changes. If it doesn't, you most likely haven't reached the limit.

When `EXTRAPOLATE` is included in a query, the ratio between the reported events and the total events is calculated. This ratio is then used to extrapolate an approximation of unsampled data. Keep in mind that only some queries support its use. When included in a NRQL query that doesnâ€™t support it, or that doesn't use sampled data, it will have no effect.

Note that `EXTRAPOLATE` is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like `uniqueCount()` or `uniques()`). This clause works only with NRQL queries that use one of the following aggregator functions:

* apdex
* average
* count
* histogram
* sum
* percentage
* rate
* stddev

### Use facet cases

<Steps>
    <Step>
As you learned in previous lessons, `FACET` is a great way to both segment your data, and understand it from differently grouped perspectives (such as seeing average response time based on different response codes). When you use `FACET`, NRDB organizes data into groups based on the values of provided attributes. But what if you wanted to group multiple values together, such as HTTP response codes 200, 201, etc.?

`FACET CASES()` solves for this issue by allowing you to choose how facet buckets are broken out. The operator takes any number of parameters in the format "`WHERE attr OP value`". In the example below we've categorized all transactions with response code starting with "2" into a "2xx Responses" bucket. We could also do this for 3xx, 4xx, and 5xx response codes to group our data in ways that increase readability and help us understand what's happening in our application(s).

```sql
SELECT count(*) 
FROM Public_APICall 
FACET CASES(WHERE http.url LIKE '%amazon%', WHERE http.url LIKE '%google%', WHERE http.url LIKE '%microsoft%')
```
<img
    title="Facet cases"
    alt="A screenshot showing the facet cases functionality"
    src={queriesnrql2tutorial9}
/>
    </Step>
    <Step>
As you can see, these groupings are useful but difficult to read. Let's clean them up using something we learned in level 2 of this course:

```sql
SELECT count(*) 
FROM Public_APICall 
FACET CASES(WHERE http.url LIKE '%amazon%' AS 'Amazon', WHERE http.url LIKE '%google%' AS 'Google', WHERE http.url LIKE '%microsoft%' AS 'Microsoft')
```
<img
    title="Facet cases groupings"
    alt="A screenshot showing the grouping functionality of facet cases"
    src={queriesnrql2tutorial10}
/>
    </Step>
</Steps>

`FACET CASES()` allows us to match and group attributes with mulitple, interesting values we want combined. There are many useful scenarios for this functionality. It's also even more powerful when custom data is tagged onto your transaction data, allowing you more granularity and control in navigating and grouping data.

### Filter by event type

<Steps>
    <Step>
We're truly becoming NRQL wizards! Next we'll explore something few New Relic customers are even aware of: filtering to event types.

So far, we've made queries that pull data from a single source. But what if you want to plot 2 data points that are stored as two different event types? Querying NRDB data is not limited to a single event type! To query from multiple event types you can include each event type seperated by a comma.

<SideBySide>
    <Side>
```sql
SELECT count(*) AS 'Combined Events' 
FROM NrdbQuery, NrDailyUsage 
SINCE 1 day ago
```
    </Side>
    <Side>
<img
    title="Filter event type"
    alt="A screenshot showing the filter event type functionality"
    src={queriesnrql2tutorial11}
/>
    </Side>
</SideBySide>

    </Step>
    <Step>
To make this even more useful, the `eventType()` function tells us which event type a record is from. We can use this to control our data output. In this example, we see the total number of Transaction and PageView events combined, as well as the totals for only Transaction and PageView.

```sql
SELECT count(*) AS 'Combined Events', filter(count(*), WHERE eventType() = 'NrdbQuery') as 'NrdbQuery', filter(count(*), WHERE eventType()='NrDailyUsage') as 'NrDailyUsage' 
FROM NrdbQuery, NrDailyUsage 
SINCE 1 day ago
```
<img
    title="Event type with transaction and pageview"
    alt="A screenshot showing the event type functionality with transactions and pageview"
    src={queriesnrql2tutorial12}
/>
    </Step>
    <Step>
Let's look at this in more detail: `count(*)` is the total number of both Transaction and PageView events. However, we can use the aggregator function `filter()` we recently learned about to do something unique. We tell it `WHERE eventType()='PageView'`. This invokes the filter function to observe the event type as part of the total result set, then filter to display only those specific events. We can even add `TIMESERIES` to visualize 2 directly comparable data points on a line graph.

```sql
SELECT count(*) AS 'Combined Events', filter(count(*), WHERE eventType() = 'NrdbQuery') as 'NrdbQuery', filter(count(*), WHERE eventType()='NrDailyUsage') as 'NrDailyUsage' 
FROM NrdbQuery, NrDailyUsage 
SINCE 1 day ago 
TIMESERIES max
```
<img
    title="Event type with count and timeseries"
    alt="A screenshot showing the event type functionality with count and timeseries"
    src={queriesnrql2tutorial13}
/>
    </Step>
</Steps>

We have managed to locate, return, and graph data from two different event types. This is an example of how NRQL can allow you to navigate any necessary data quickly and succinctly; no complex joining or join statements required!

### Override values

<Steps>
    <Step>
#### Counting NULL Values
Sometimes data simply doesn't report in the format you need. For instance, sometimes integers are returned as strings, but you need them as integers to perform maths. Or maybe you get a NULL result, but in your case NULL actually means 0. Don't worry! We hear you, and we've added functionality to address this.

NULL values on attributes can appear on both out-of-the-box and custom data. When you use aggregators such as `count()` and `average()`, NRQL automatically removes NULL values from the calculation, only performing the function on events without NULL values. NRQL lets you account for unexpected NULL values in calculations by using the `OR value` clause. For example, if you wanted to make sure NULL values for your "cartValue" attribute are counted as 0, you could use "cartValue OR 0" in your query.

In this example, running `count()` on ApdexPerfZone only counts the number of times ApdexPerfZone has a value. But if we add `OR 'Null'` to the argument, we can count all transactions where ApdexPerfZone exists, and also those where the value is null.

```sql
SELECT count(duration) AS 'Events With Durations', count(http.url OR 'Null') AS 'Events With and Without URL' 
FROM Public_APICall 
SINCE 1 day ago
```
<img
    title="Null values"
    alt="A screenshot showing the null values functionality"
    src={queriesnrql2tutorial14}
/>
    </Step>
    <Step>
#### Coercion
NRQL does not automatically apply coercion. This means a float stored as a string is treated as a string, and cannot be used by mathematical functions like `sum()` or `average()`. To override this behavior, use `boolean()` or `numeric()` to convert arguments to a boolean or numerical values. In this example, an `average()` function on "httpResponseCode" provides no value since this attribute is a string. But if we convert the attribute to a number using `numeric`(httpResponseCode), we can use the `average()` function successfully.

```sql
SELECT average(numeric(duration)) AS 'Ensuring stored value is treated as numeric', average(duration) AS 'Non-Converted Attribute' 
FROM Public_APICall 
SINCE 1 day ago
```
<img
    title="Coercion"
    alt="A screenshot showing the coercion functionality"
    src={queriesnrql2tutorial15}
/>
    </Step>
    <Step>
Another common example is BOOLEAN (TRUE or FALSE) values. These are often incorrectly formatted as strings. When this happens, don't worry! You can change how the source sends the data to make it a proper boolean. Or, you can use the `boolean()` function. The example query below returns the same result, but that is because we're using a value sent by the agent as a BOOLEAN. If your attribute was a string "TRUE", `boolean()` would convert it into a proper boolean format, allowing the query to run as intended.

```sql
SELECT count(boolean(sampleDataSet)), count(sampleDataSet)  
FROM Public_APICall 
SINCE 24 hours ago
```
<img
    title="Coercion with boolean"
    alt="A screenshot showing the coercion functionality with the boolean function"
    src={queriesnrql2tutorial16}
/>
    </Step>
    <Step>
You can also convert boolean and numeric values to strings by using the `string()` function. Where numeric values are floating-point numbers you can use the optional `precision` argument to limit the number of decimal places for the string. This query returns the duration value as a string limited to three decimal places.

```sql
SELECT string(duration, precision: 3) 
FROM Public_APICall 
SINCE 24 hours ago
```
<img
    title="Coercion with precision"
    alt="A screenshot showing the coercion functionality with precision"
    src={queriesnrql2tutorial17}
/>
    </Step>
</Steps>

Sometimes the devil is in the details. Here we've given you the power to control your data formats, and tell NRQL how you want it to act. NRQL operates in the manner we deem most logical, but if that does not suit your unique scenario, you can use the functions explored in this lesson to override values.

### Use string concatenation

<Steps>
    <Step>
There may be some cases where you need to append and/or prepend text to the returned value of an attribute. This can be achieved using the `concat()` function.

You can provide upto 20 arguments for the `concat()` function to concatenate into a string.

```sql
SELECT concat('The duration of ', http.url, ' is ', duration, ' seconds') 
FROM Public_APICall
```
<img
    title="Concatenation"
    alt="A screenshot showing the concatenation functionality"
    src={queriesnrql2tutorial18}
/>
    </Step>
    <Step>
We can limit the number of decimal places that are used for any floating point numbers in the values of the concatenated attributes. To do this we use the optional `precision:` argument as the last value. In this example we are appending 's' to denote seconds, and limiting the value to 3 decimal places.

```sql
SELECT http.url, concat(duration, 's', precision: 3) 
FROM Public_APICall
```
<img
    title="Concatenation with precision"
    alt="A screenshot showing the concatenation functionality with precision"
    src={queriesnrql2tutorial19}
/>
    </Step>
    <Step>
Values that start with `http(s)` are automatically displayed as links which can be clicked to open a new page, which means it is possible to create integrations to solutions where a dynamic URL can be used to open a related page to the entity. The following example demonstrates an example URL where the query parameter values are set by the attribute values.

```sql
SELECT http.url, concat('https://www.example.com/?appId=', api, '&error=', error) AS 'URL' 
FROM Public_APICall
```
<img
    title="Concatenation with URLs"
    alt="A screenshot showing the concatenation functionality with a URL"
    src={queriesnrql2tutorial20}
/>
    </Step>
</Steps>

You can use the `concat()` function to combine values together (e.g. city and country for location), and prepend/append additional strings to present the data as you need.

<CollapserGroup>
    <Collapser
        id="summary"
        title="Lesson summary"
    >
In this section we explored specific, powerful NRQL functionality. These skills will undoubtedly serve you next time you're in the trenches, diving into the nitty-gritty of your data.

You're now a Level 3 NRQL expert! Believe it or not, there are even more features and functions we want to showcase in the next section.
    </Collapser>
</CollapserGroup>

### What's next?

Content forthcoming