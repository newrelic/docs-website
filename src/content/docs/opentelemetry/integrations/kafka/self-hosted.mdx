---
title: Monitor self-hosted Kafka with OpenTelemetry
tags:
  - Integrations
  - OpenTelemetry
  - Kafka
  - Self-hosted
metaDescription: "Install OpenTelemetry Collector on Linux hosts to monitor self-hosted Kafka clusters."
freshnessValidatedDate: never
---

Monitor your self-hosted Apache Kafka cluster by installing the OpenTelemetry Collector directly on Linux hosts.

## Before you begin [#prerequisites]

Ensure you have:

* A [New Relic account](https://newrelic.com/signup) with a <InlinePopover type="licenseKey"/>
* Network access from the collector to Kafka bootstrap server port (typically 9092)

### Step 1: Download the OpenTelemetry Java Agent [#download-java-agent]

The [OpenTelemetry Java Agent](https://opentelemetry.io/docs/zero-code/java/agent/) runs as a Java agent attached to your Kafka brokers, collecting Kafka and JMX metrics and sending them via OTLP to the collector:

```bash
# Create directory for OpenTelemetry components
mkdir -p ~/opentelemetry

# Download OpenTelemetry Java Agent
curl -L -o ~/opentelemetry/opentelemetry-javaagent.jar \
  https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar
```

### Step 2: Create JMX custom configuration [#jmx-config]

Create an OpenTelemetry Java Agent JMX configuration file to collect Kafka metrics from JMX MBeans.

Create the file `~/opentelemetry/jmx-custom-config.yaml` with the following configuration:

```yaml
---
rules:
  # Per-topic custom metrics using custom MBean commands
  - bean: kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=*
    metricAttribute:
      topic: param(topic)
    mapping:
      Count:
        metric: kafka.prod.msg.count
        type: counter
        desc: The number of messages per topic
        unit: "{message}"

  - bean: kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=*
    metricAttribute:
      topic: param(topic)
      direction: const(in)
    mapping:
      Count:
        metric: kafka.topic.io
        type: counter
        desc: The bytes received or sent per topic
        unit: By

  - bean: kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=*
    metricAttribute:
      topic: param(topic)
      direction: const(out)
    mapping:
      Count:
        metric: kafka.topic.io
        type: counter
        desc: The bytes received or sent per topic
        unit: By

  # Cluster-level metrics using controller-based MBeans
  - bean: kafka.controller:type=KafkaController,name=GlobalTopicCount
    mapping:
      Value:
        metric: kafka.cluster.topic.count
        type: gauge
        desc: The total number of global topics in the cluster
        unit: "{topic}"

  - bean: kafka.controller:type=KafkaController,name=GlobalPartitionCount
    mapping:
      Value:
        metric: kafka.cluster.partition.count
        type: gauge
        desc: The total number of global partitions in the cluster
        unit: "{partition}"

  - bean: kafka.controller:type=KafkaController,name=FencedBrokerCount
    mapping:
      Value:
        metric: kafka.broker.fenced.count
        type: gauge
        desc: The number of fenced brokers in the cluster
        unit: "{broker}"

  - bean: kafka.controller:type=KafkaController,name=PreferredReplicaImbalanceCount
    mapping:
      Value:
        metric: kafka.partition.non_preferred_leader
        type: gauge
        desc: The count of topic partitions for which the leader is not the preferred leader
        unit: "{partition}"

  # Broker-level metrics using ReplicaManager MBeans
  - bean: kafka.server:type=ReplicaManager,name=UnderMinIsrPartitionCount
    mapping:
      Value:
        metric: kafka.partition.under_min_isr
        type: gauge
        desc: The number of partitions where the number of in-sync replicas is less than the minimum
        unit: "{partition}"

  # Broker uptime metric using JVM Runtime
  - bean: java.lang:type=Runtime
    mapping:
      Uptime:
        metric: kafka.broker.uptime
        type: gauge
        desc: Broker uptime in milliseconds
        unit: ms

  # Leader count per broker
  - bean: kafka.server:type=ReplicaManager,name=LeaderCount
    mapping:
      Value:
        metric: kafka.broker.leader.count
        type: gauge
        desc: Number of partitions for which this broker is the leader
        unit: "{partition}"

  # JVM metrics
  - bean: java.lang:type=GarbageCollector,name=*
    mapping:
      CollectionCount:
        metric: jvm.gc.collections.count
        type: counter
        unit: "{collection}"
        desc: total number of collections that have occurred
        metricAttribute:
          name: param(name)
      CollectionTime:
        metric: jvm.gc.collections.elapsed
        type: counter
        unit: ms
        desc: the approximate accumulated collection elapsed time in milliseconds
        metricAttribute:
          name: param(name)

  - bean: java.lang:type=Memory
    unit: By
    prefix: jvm.memory.
    dropNegativeValues: true
    mapping:
      HeapMemoryUsage.committed:
        metric: heap.committed
        desc: current heap usage
        type: gauge
      HeapMemoryUsage.max:
        metric: heap.max
        desc: current heap usage
        type: gauge
      HeapMemoryUsage.used:
        metric: heap.used
        desc: current heap usage
        type: gauge

  - bean: java.lang:type=Threading
    mapping:
      ThreadCount:
        metric: jvm.thread.count
        type: gauge
        unit: "{thread}"
        desc: Total thread count (Kafka typical range 100-300 threads)

  - bean: java.lang:type=OperatingSystem
    prefix: jvm.
    dropNegativeValues: true
    mapping:
      SystemLoadAverage:
        metric: system.cpu.load_1m
        type: gauge
        unit: "{run_queue_item}"
        desc: System load average (1 minute) - alert if > CPU count
      AvailableProcessors:
        metric: cpu.count
        type: gauge
        unit: "{cpu}"
        desc: Number of processors available
      ProcessCpuLoad:
        metric: cpu.recent_utilization
        type: gauge
        unit: '1'
        desc: Recent CPU utilization for JVM process (0.0 to 1.0)
      SystemCpuLoad:
        metric: system.cpu.utilization
        type: gauge
        unit: '1'
        desc: Recent CPU utilization for whole system (0.0 to 1.0)
      OpenFileDescriptorCount:
        metric: file_descriptor.count
        type: gauge
        unit: "{file_descriptor}"
        desc: Number of open file descriptors - alert if > 80% of ulimit

  - bean: java.lang:type=ClassLoading
    mapping:
      LoadedClassCount:
        metric: jvm.class.count
        type: gauge
        unit: "{class}"
        desc: Currently loaded class count

  - bean: java.lang:type=MemoryPool,name=*
    type: gauge
    unit: By
    metricAttribute:
      name: param(name)
    mapping:
      Usage.used:
        metric: jvm.memory.pool.used
        desc: Memory pool usage by generation (G1 Old Gen, Eden, Survivor)
      Usage.max:
        metric: jvm.memory.pool.max
        desc: Maximum memory pool size
      CollectionUsage.used:
        metric: jvm.memory.pool.used_after_last_gc
        desc: Memory used after last GC (shows retained memory baseline)
  
  - bean: kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
    mapping:
      Count:
        metric: kafka.message.count
        type: counter
        desc: The number of messages received by the broker
        unit: "{message}"

  - bean: kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec
    metricAttribute:
      type: const(fetch)
    mapping:
      Count:
        metric: &metric kafka.request.count
        type: &type counter
        desc: &desc The number of requests received by the broker
        unit: &unit "{request}"

  - bean: kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec
    metricAttribute:
      type: const(produce)
    mapping:
      Count:
        metric: *metric
        type: *type
        desc: *desc
        unit: *unit

  - bean: kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec
    metricAttribute:
      type: const(fetch)
    mapping:
      Count:
        metric: &metric kafka.request.failed
        type: &type counter
        desc: &desc The number of requests to the broker resulting in a failure
        unit: &unit "{request}"

  - bean: kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec
    metricAttribute:
      type: const(produce)
    mapping:
      Count:
        metric: *metric
        type: *type
        desc: *desc
        unit: *unit

  - beans:
      - kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce
      - kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer
      - kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchFollower
    metricAttribute:
      type: param(request)
    unit: ms
    mapping:
      Count:
        metric: kafka.request.time.total
        type: counter
        desc: The total time the broker has taken to service requests
      50thPercentile:
        metric: kafka.request.time.50p
        type: gauge
        desc: The 50th percentile time the broker has taken to service requests
      99thPercentile:
        metric: kafka.request.time.99p
        type: gauge
        desc: The 99th percentile time the broker has taken to service requests
      Mean:
        metric: kafka.request.time.avg
        type: gauge
        desc: The average time the broker has taken to service requests

  - bean: kafka.network:type=RequestChannel,name=RequestQueueSize
    mapping:
      Value:
        metric: kafka.request.queue
        type: gauge
        desc: Size of the request queue
        unit: "{request}"

  - bean: kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
    metricAttribute:
      direction: const(in)
    mapping:
      Count:
        metric: &metric kafka.network.io
        type: &type counter
        desc: &desc The bytes received or sent by the broker
        unit: &unit By

  - bean: kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec
    metricAttribute:
      direction: const(out)
    mapping:
      Count:
        metric: *metric
        type: *type
        desc: *desc
        unit: *unit

  - beans:
      - kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce
      - kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Fetch
    metricAttribute:
      type: param(delayedOperation)
    mapping:
      Value:
        metric: kafka.purgatory.size
        type: gauge
        desc: The number of requests waiting in purgatory
        unit: "{request}"

  - bean: kafka.server:type=ReplicaManager,name=PartitionCount
    mapping:
      Value:
        metric: kafka.partition.count
        type: gauge
        desc: The number of partitions on the broker
        unit: "{partition}"

  - bean: kafka.controller:type=KafkaController,name=OfflinePartitionsCount
    mapping:
      Value:
        metric: kafka.partition.offline
        type: gauge
        desc: The number of partitions offline
        unit: "{partition}"

  - bean: kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions
    mapping:
      Value:
        metric: kafka.partition.under_replicated
        type: gauge
        desc: The number of under replicated partitions
        unit: "{partition}"

  - bean: kafka.server:type=ReplicaManager,name=IsrShrinksPerSec
    metricAttribute:
      operation: const(shrink)
    mapping:
      Count:
        metric: kafka.isr.operation.count
        type: counter
        desc: The number of in-sync replica shrink and expand operations
        unit: "{operation}"

  - bean: kafka.server:type=ReplicaManager,name=IsrExpandsPerSec
    metricAttribute:
      operation: const(expand)
    mapping:
      Count:
        metric: kafka.isr.operation.count
        type: counter
        desc: The number of in-sync replica shrink and expand operations
        unit: "{operation}"

  - bean: kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica
    mapping:
      Value:
        metric: kafka.max.lag
        type: gauge
        desc: The max lag in messages between follower and leader replicas
        unit: "{message}"

  - bean: kafka.controller:type=KafkaController,name=ActiveControllerCount
    mapping:
      Value:
        metric: kafka.controller.active.count
        type: gauge
        desc: For KRaft mode, the number of active controllers in the cluster. For ZooKeeper, indicates whether the broker is the controller broker.
        unit: "{controller}"

  - bean: kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs
    mapping:
      Count:
        metric: kafka.leader.election.rate
        type: counter
        desc: The leader election count
        unit: "{election}"

  - bean: kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec
    mapping:
      Count:
        metric: kafka.unclean.election.rate
        type: counter
        desc: Unclean leader election count - increasing indicates broker failures
        unit: "{election}"

  - bean: kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs
    unit: ms
    type: gauge
    prefix: kafka.logs.flush.
    mapping:
      Count:
        metric: count
        unit: '{flush}'
        type: counter
        desc: Log flush count
      50thPercentile:
        metric: time.50p
        desc: Log flush time - 50th percentile
      99thPercentile:
        metric: time.99p
        desc: Log flush time - 99th percentile
```

<Callout variant="tip">
  **Customize metrics collection**: You can add more Kafka metrics by extending the rules in `jmx-custom-config.yaml`:

  - Learn about [OpenTelemetry JMX Metrics configuration syntax](https://github.com/open-telemetry/opentelemetry-java-instrumentation/tree/main/instrumentation/jmx-metrics#jmx-metric-insight---custom-yaml-definitions)
  - Find available MBean names in the [Kafka monitoring documentation](https://kafka.apache.org/documentation/#monitoring)

  This allows you to collect any JMX metric exposed by Kafka brokers based on your specific monitoring needs.
</Callout>

### Step 3: Configure Kafka broker [#configure-broker]

Attach the OpenTelemetry Java Agent to your Kafka broker by setting the `KAFKA_OPTS` environment variable before starting Kafka.

**Single broker example**:

```bash
OTEL_AGENT="$HOME/opentelemetry/opentelemetry-javaagent.jar"
JMX_CONFIG="$HOME/opentelemetry/jmx-custom-config.yaml"

nohup env KAFKA_OPTS="-javaagent:$OTEL_AGENT \
    -Dotel.jmx.enabled=true \
    -Dotel.jmx.config=$JMX_CONFIG \
    -Dotel.resource.attributes=broker.id=1,kafka.cluster.name=my-kafka-cluster \
    -Dotel.exporter.otlp.endpoint=http://localhost:4317 \
    -Dotel.exporter.otlp.protocol=grpc \
    -Dotel.metrics.exporter=otlp \
    -Dotel.metric.export.interval=30000" \
    bin/kafka-server-start.sh config/server.properties &
```

<Callout variant="important">
  **Multi-broker clusters**: For multiple brokers, use the same configuration with unique `broker.id` values (e.g., `broker.id=1`, `broker.id=2`, `broker.id=3`) in the `-Dotel.resource.attributes` parameter for each broker.
</Callout>

<CollapserGroup>
  <Collapser
    id="configuration-parameters"
    title="Configuration parameters"
  >
    * `nohup` - Runs the Kafka broker in the background, continuing even if the shell session ends
    * `-javaagent` - Attaches the OpenTelemetry Java Agent to the Kafka broker JVM
    * `-Dotel.jmx.enabled=true` enables JMX metrics collection
    * `-Dotel.jmx.config` specifies your custom JMX metrics configuration file
    * `-Dotel.resource.attributes` adds metadata: unique `broker.id` and `kafka.cluster.name`
    * `-Dotel.exporter.otlp.endpoint` points to your OpenTelemetry Collector (default: localhost:4317)
    * `-Dotel.exporter.otlp.protocol=grpc` uses gRPC protocol for OTLP
    * `-Dotel.metrics.exporter=otlp` sends metrics via OTLP
    * `-Dotel.metric.export.interval=30000` exports metrics every 30 seconds
    * `&` - Runs the command in the background

    **For remote collectors** (different host):
    ```bash
    -Dotel.exporter.otlp.endpoint=http://collector-host:4317
    ```

    For complete configuration options, see the [Java Agent configuration guide](https://opentelemetry.io/docs/zero-code/java/agent/configuration/).
  </Collapser>
</CollapserGroup>

### Step 4: Create collector configuration [#collector-config]

Create the main OpenTelemetry Collector configuration at `~/opentelemetry/kafka-config.yaml`.

```yaml
receivers:
  # OTLP receiver for Kafka and JMX metrics from Java agents and application telemetry
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"

  # Kafka metrics receiver for cluster-level metrics
  kafkametrics:
    brokers: ${env:KAFKA_BOOTSTRAP_BROKER_ADDRESSES}
    protocol_version: 2.0.0
    scrapers:
      - brokers
      - topics
      - consumers
    collection_interval: 30s
    topic_match: ".*"
    metrics:
      kafka.topic.min_insync_replicas:
        enabled: true
      kafka.topic.replication_factor:
        enabled: true
      kafka.partition.replicas:
        enabled: false
      kafka.partition.oldest_offset:
        enabled: false
      kafka.partition.current_offset:
        enabled: false

processors:
  batch/aggregation:
    send_batch_size: 1024
    timeout: 30s

  resourcedetection:
    detectors: [env, ec2, system]
    system:
      resource_attributes:
        host.name:
          enabled: true
        host.id:
          enabled: true

  resource:
    attributes:
      - action: insert
        key: kafka.cluster.name
        value: ${env:KAFKA_CLUSTER_NAME}

  transform/remove_broker_id:
    metric_statements:
      # Remove broker.id from resource attributes for cluster-level metrics
      - context: resource
        statements:
          - delete_key(attributes, "broker.id")

  transform/remove_extra_attributes:
    metric_statements:
      - context: resource
        statements:
          # Delete all attributes starting with "process."
          - delete_matching_keys(attributes, "^process\\..*")
          # Delete all attributes starting with "telemetry."
          - delete_matching_keys(attributes, "^telemetry\\..*")
          - delete_key(attributes, "host.arch")
          - delete_key(attributes, "os.description")

  filter/include_cluster_metrics:
    metrics:
      include:
        match_type: regexp
        metric_names:
          - "kafka\\.partition\\.offline"
          - "kafka\\.(leader|unclean)\\.election\\.rate"
          - "kafka\\.partition\\.non_preferred_leader"
          - "kafka\\.broker\\.fenced\\.count"
          - "kafka\\.cluster\\.partition\\.count"
          - "kafka\\.cluster\\.topic\\.count"

  filter/exclude_cluster_metrics:
    metrics:
      exclude:
        match_type: regexp
        metric_names:
          - "kafka\\.partition\\.offline"
          - "kafka\\.(leader|unclean)\\.election\\.rate"
          - "kafka\\.partition\\.non_preferred_leader"
          - "kafka\\.broker\\.fenced\\.count"
          - "kafka\\.cluster\\.partition\\.count"
          - "kafka\\.cluster\\.topic\\.count"

  transform/des_units:
    metric_statements:
      - context: metric
        statements:
          - set(description, "") where description != ""
          - set(unit, "") where unit != ""

  cumulativetodelta:

  metricstransform/kafka_topic_sum_aggregation:
    transforms:
      - include: kafka.partition.replicas_in_sync
        action: insert
        new_name: kafka.partition.replicas_in_sync.total
        operations:
          - action: aggregate_labels
            label_set: [topic]
            aggregation_type: sum
      
      - include: kafka.partition.replicas
        action: insert
        new_name: kafka.partition.replicas.total
        operations:
          - action: aggregate_labels
            label_set: [topic]
            aggregation_type: sum

  filter/remove_partition_level_replicas:
    metrics:
      exclude:
        match_type: strict
        metric_names:
          - kafka.partition.replicas_in_sync

exporters:
  otlp/newrelic:
    endpoint: https://otlp.nr-data.net:4317
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}
    compression: gzip
    timeout: 30s

service:
  pipelines:
    # Broker metrics pipeline (excludes cluster-level metrics)
    metrics/broker:
      receivers: [otlp, kafkametrics]
      processors: [resourcedetection, resource, filter/exclude_cluster_metrics, transform/remove_extra_attributes, transform/des_units, cumulativetodelta, metricstransform/kafka_topic_sum_aggregation, filter/remove_partition_level_replicas, batch/aggregation]
      exporters: [otlp/newrelic]

    # Cluster metrics pipeline (only cluster-level metrics, no broker.id)
    metrics/cluster:
      receivers: [otlp]
      processors: [resourcedetection, resource, filter/include_cluster_metrics, transform/remove_broker_id, transform/remove_extra_attributes, transform/des_units, cumulativetodelta, batch/aggregation]
      exporters: [otlp/newrelic]
```

**Configuration requirements:**

* **Kafka brokers**: Update the `kafkametrics` receiver `brokers` list to match your broker bootstrap addresses and ports (e.g., `localhost:9092,localhost:9093,localhost:9094`)
* **OTLP endpoint**: Uses `https://otlp.nr-data.net:4317` (US region) or `https://otlp.eu01.nr-data.net:4317` (EU region). See [Configure your OTLP endpoint](/docs/opentelemetry/best-practices/opentelemetry-otlp/#configure-endpoint-port-protocol) for other regions

<CollapserGroup>
  <Collapser
    id="configuration-notes"
    title="Configuration notes"
  >
    **Architecture highlights:**

    * **OTLP receiver**: Receives Kafka and JMX metrics from OpenTelemetry Java Agent running on Kafka brokers via gRPC on port 4317
    * **Two pipelines approach**: Cluster-level metrics are sent without broker.id to map to cluster entity
    * **Metric filtering**: Separates broker-specific metrics from cluster-level metrics to avoid duplication
    * **Aggregation**: Automatically aggregates partition-level metrics by topic
  </Collapser>

  <Collapser
    id="additional-receiver-docs"
    title="Additional receiver documentation"
  >
    For advanced configuration options, refer to these receiver documentation pages:

    * [OTLP receiver documentation](https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver/otlpreceiver) - OTLP receiver configuration options
    * [Kafka metrics receiver documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/kafkametricsreceiver) - Additional Kafka metrics configuration
  </Collapser>
</CollapserGroup>

### Step 5: Set environment variables [#env-vars]

Set the required environment variables before installing the collector:

```bash
export NEW_RELIC_LICENSE_KEY="YOUR_LICENSE_KEY"
export KAFKA_CLUSTER_NAME="my-kafka-cluster"
export KAFKA_BOOTSTRAP_BROKER_ADDRESSES="localhost:9092"
```

Replace:
* `YOUR_LICENSE_KEY` with your New Relic license key
* `my-kafka-cluster` with a unique name for your Kafka cluster
* `localhost:9092` with your Kafka bootstrap broker address(es). For multiple brokers, use comma-separated list: `broker1:9092,broker2:9092,broker3:9092`

### Step 6: Install and start the collector [#install-start-collector]

Choose between NRDOT Collector (New Relic's distribution) or OpenTelemetry Collector:

<Tabs>
  <TabsBar>
    <TabsBarItem id="nrdot">NRDOT Collector</TabsBarItem>
    <TabsBarItem id="otel">OpenTelemetry Collector</TabsBarItem>
  </TabsBar>

  <TabsPages>
    <TabsPageItem id="nrdot">
      <Callout variant="tip">
        **NRDOT Collector** is New Relic's distribution of OpenTelemetry Collector with New Relic support for assistance.
      </Callout>

      **6.1 Install NRDOT Collector**

      Download and install the NRDOT Collector binary for your host operating system. The example below is for linux_amd64 architecture:

      ```bash
      # Set version and architecture
      NRDOT_VERSION="1.9.0"
      ARCH="amd64"  # or arm64
      
      # Download and extract
      curl "https://github.com/newrelic/nrdot-collector-releases/releases/download/${NRDOT_VERSION}/nrdot-collector_${NRDOT_VERSION}_linux_${ARCH}.tar.gz" \
        --location --output collector.tar.gz
      tar -xzf collector.tar.gz
      
      # Move to a location in PATH (optional)
      sudo mv nrdot-collector /usr/local/bin/
      
      # Verify installation
      nrdot-collector --version
      ```

      <Callout variant="important">
        For other operating systems and architectures, visit [NRDOT Collector releases](https://github.com/newrelic/nrdot-collector-releases/releases/latest) and download the appropriate binary for your system.
      </Callout>

      **6.2 Start NRDOT Collector**

      Run the collector with your configuration file:

      ```bash
      nrdot-collector --config ~/opentelemetry/kafka-config.yaml
      ```

      The collector will start sending Kafka metrics to New Relic within a few minutes.
    </TabsPageItem>

    <TabsPageItem id="otel">
      **6.1 Install OpenTelemetry Collector**

      Download and install the OpenTelemetry Collector Contrib binary for your host operating system. The example below is for linux_amd64 architecture:

      ```bash
      # Set version and architecture
      # Check https://github.com/open-telemetry/opentelemetry-collector-releases/releases/latest for the latest version
      OTEL_VERSION="<collector_version>"
      ARCH="amd64"
      
      # Download the collector
      curl -L -o otelcol-contrib.tar.gz \
        "https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v${OTEL_VERSION}/otelcol-contrib_${OTEL_VERSION}_linux_${ARCH}.tar.gz"
      
      # Extract the binary
      tar -xzf otelcol-contrib.tar.gz
      
      # Move to a location in PATH (optional)
      sudo mv otelcol-contrib /usr/local/bin/
      
      # Verify installation
      otelcol-contrib --version
      ```

      For other operating systems, visit the [OpenTelemetry Collector releases](https://github.com/open-telemetry/opentelemetry-collector-releases/releases/latest) page.

      **6.2 Start OpenTelemetry Collector**

      Run the collector with your configuration file:

      ```bash
      otelcol-contrib --config ~/opentelemetry/kafka-config.yaml
      ```

      The collector will start sending Kafka metrics to New Relic within a few minutes.
    </TabsPageItem>
  </TabsPages>
</Tabs>

### Step 7: (Optional) Instrument producer or consumer applications [#instrument-apps]

<Callout variant="important">
  **Language support**: Currently, only Java applications are supported for Kafka client instrumentation using the OpenTelemetry Java Agent.
</Callout>

To collect application-level telemetry from your Kafka producer and consumer applications, use the OpenTelemetry Java Agent you downloaded in [Step 1](#download-java-agent).

Start your application with the agent:

```bash
java \
  -javaagent:$HOME/opentelemetry/opentelemetry-javaagent.jar \
  -Dotel.service.name="order-process-service" \
  -Dotel.resource.attributes="kafka.cluster.name=my-kafka-cluster" \
  -Dotel.exporter.otlp.endpoint=http://localhost:4317 \
  -Dotel.exporter.otlp.protocol="grpc" \
  -Dotel.metrics.exporter="otlp" \
  -Dotel.traces.exporter="otlp" \
  -Dotel.logs.exporter="otlp" \
  -Dotel.instrumentation.kafka.experimental-span-attributes="true" \
  -Dotel.instrumentation.messaging.experimental.receive-telemetry.enabled="true" \
  -Dotel.instrumentation.kafka.producer-propagation.enabled="true" \
  -Dotel.instrumentation.kafka.enabled="true" \
  -jar your-kafka-application.jar
```

Replace:
* `order-process-service` with a unique name for your producer or consumer application
* `my-kafka-cluster` with the same cluster name used in your collector configuration

<Callout variant="tip">
  The configuration above sends telemetry to an OpenTelemetry Collector running on localhost:4317.
  
  <CollapserGroup>
    <Collapser
      id="app-collector-config"
      title="Sample collector configuration"
    >
      ```yaml
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: "0.0.0.0:4317"

      exporters:
        otlp/newrelic:
          endpoint: https://otlp.nr-data.net:4317
          headers:
            api-key: "${NEW_RELIC_LICENSE_KEY}"
          compression: gzip
          timeout: 30s

      service:
        pipelines:
          traces:
            receivers: [otlp]
            exporters: [otlp/newrelic]
          metrics:
            receivers: [otlp]
            exporters: [otlp/newrelic]
          logs:
            receivers: [otlp]
            exporters: [otlp/newrelic]
      ```
    </Collapser>
  </CollapserGroup>

  This allows you to customize processing, add filters, or route to multiple backends. For other endpoint configurations, see [Configure your OTLP endpoint](/docs/opentelemetry/best-practices/opentelemetry-otlp/#configure-endpoint-port-protocol).
</Callout>

The Java Agent provides [out-of-the-box Kafka instrumentation](https://opentelemetry.io/docs/zero-code/java/spring-boot-starter/out-of-the-box-instrumentation/) with zero code changes, capturing:
* Request latencies
* Throughput metrics
* Error rates
* Distributed traces

For advanced configuration, see the [Kafka instrumentation documentation](https://github.com/open-telemetry/opentelemetry-java-instrumentation/tree/main/instrumentation/kafka).

### Step 8: (Optional) Forward Kafka broker logs [#forward-logs]

To collect Kafka broker logs and send them to New Relic, configure the filelog receiver in your OpenTelemetry Collector.

<CollapserGroup>
  <Collapser
    id="configure-log-collection"
    title="Configure log collection"
  >
    Update your collector configuration at `~/opentelemetry/kafka-config.yaml` to add the filelog receiver.

    **Add to receivers section**:
    ```yaml
    receivers:
      # ... existing receivers (otlp, kafkametrics) ...
      
      # File log receiver for Kafka broker logs
      filelog/kafka_broker_1:
        include:
          - /path/to/kafka/logs/server.log
        start_at: end
        multiline:
          line_start_pattern: '^\['
        resource:
          broker.id: "1"
          kafka.cluster.name: ${env:KAFKA_CLUSTER_NAME}
    ```

    **Add logs pipeline to service section**:
    ```yaml
    service:
      pipelines:
        # ... existing pipelines (metrics/broker, metrics/cluster) ...
        
        # Logs pipeline for Kafka broker logs
        logs:
          receivers: [filelog/kafka_broker_1]
          processors: [batch/aggregation, resourcedetection]
          exporters: [otlp/newrelic]
    ```

    **Configuration notes:**
    * Update `/path/to/kafka/logs/server.log` to your actual Kafka log file path (e.g., `~/kafka/logs/server.log`)
    * The `broker.id` resource attribute correlates logs with specific broker metrics and entities
    * For multiple brokers, create separate `filelog` receivers (e.g., `filelog/kafka_broker_2`, `filelog/kafka_broker_3`) with their respective broker IDs
    * The `multiline` pattern assumes logs start with `[` - adjust if your log format differs
    * Consider log volume and collection costs before enabling log forwarding
    * For complete configuration options, see the [filelog receiver documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/filelogreceiver)

    After updating the configuration, restart the collector:

    ```bash
    # If running in foreground, stop with Ctrl+C and restart
    nrdot-collector --config ~/opentelemetry/kafka-config.yaml
    # Or for OpenTelemetry Collector
    otelcol-contrib --config ~/opentelemetry/kafka-config.yaml
    ```
  </Collapser>

  <Collapser
    id="find-logs-in-new-relic"
    title="Find your logs in New Relic"
  >
    Your Kafka broker logs will appear in two places:
    * **Broker entities**: Navigate to the Kafka broker entity in New Relic to see logs correlated with that specific broker
    * **Logs UI**: Query all Kafka logs using the [Logs UI](/docs/logs/ui-data/use-logs-ui/) with filters like `kafka.cluster.name = 'my-cluster'`

    You can also query your logs with NRQL:

    ```sql
    FROM Log SELECT * WHERE kafka.cluster.name = 'my-kafka-cluster'
    ```
  </Collapser>
</CollapserGroup>

## Find your data [#find-data]

After a few minutes, your Kafka metrics should appear in New Relic. See [Find your data](/docs/opentelemetry/integrations/kafka/find-and-query-data) for detailed instructions on exploring your Kafka metrics across different views in the New Relic UI.

You can also query your data with NRQL:

```sql
FROM Metric SELECT * WHERE kafka.cluster.name = 'my-kafka-cluster'
```

## Troubleshooting [#troubleshooting]

<CollapserGroup>
  <Collapser
    id="initial-checks"
    title="Initial system checks"
  >
    Run these commands first to verify your setup. Use the results to identify which specific troubleshooting section to follow.

    **Check if collector is running**:
    ```bash
    # Check if port 4317 is listening (best indicator collector is running)
    ss -tlnp | grep 4317
    
    # Search for collector process (using bracket trick to exclude grep itself)
    ps aux | grep "[k]afka-config.yaml"
    
    # Or search for common collector names
    ps aux | grep -E "[n]rdot-collector|[o]telcol"
    ```
    
    If no results appear, the collector is not running. Start it following Step 6.

    **Check if Java Agent is attached to Kafka brokers**:
    ```bash
    # Search for Kafka processes with Java agent attached
    ps aux | grep "[o]pentelemetry-javaagent"
    ```
    
    **Note**: This command shows the full Java process with classpath, which can be very long (3+ lines per broker). This is expected. Look for `-javaagent:/path/to/opentelemetry-javaagent.jar` in the output.

    **Test port connectivity**:
    ```bash
    # Test Kafka bootstrap port (9092)
    timeout 5 bash -c "</dev/tcp/localhost/9092" 2>/dev/null && echo "Port 9092 open" || echo "Port 9092 closed"

    # Test OTLP collector port (4317)
    timeout 5 bash -c "</dev/tcp/localhost/4317" 2>/dev/null && echo "Port 4317 open" || echo "Port 4317 closed"
    ```

    **Check collector logs**:
    ```bash
    # View recent collector output
    tail -n 50 ~/logs/collector.log
    ```

    **Verify environment variables**:
    ```bash
    echo $NEW_RELIC_LICENSE_KEY
    echo $KAFKA_CLUSTER_NAME
    echo $KAFKA_BOOTSTRAP_BROKER_ADDRESSES
    ```
  </Collapser>

  <Collapser
    id="enable-debug-logging"
    title="Enable debug logging"
  >
    **Enable collector debug logs**: Add detailed logging to troubleshoot configuration issues

    Add to your collector configuration:
    ```yaml
    service:
      telemetry:
        logs:
          level: "debug"  # Enable detailed collector internal logs
    ```

    **Add debug exporter**: View metrics in collector logs before sending to New Relic
    ```yaml
    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5        # Log first 5 metrics
        sampling_thereafter: 200   # Then log every 200th metric

      otlp/newrelic:
        endpoint: https://otlp.nr-data.net:4317
        headers:
          api-key: ${env:NEW_RELIC_LICENSE_KEY}
        compression: gzip
        timeout: 30s

    service:
      pipelines:
        metrics/broker:
          receivers: [otlp, kafkametrics]
          processors: [resourcedetection, resource, filter/exclude_cluster_metrics, transform/des_units, cumulativetodelta, metricstransform/kafka_topic_sum_aggregation, batch/aggregation]
          exporters: [debug, otlp/newrelic]  # Add debug exporter

        metrics/cluster:
          receivers: [otlp]
          processors: [resourcedetection, resource, filter/include_cluster_metrics, transform/remove_broker_id, transform/des_units, cumulativetodelta, batch/aggregation]
          exporters: [debug, otlp/newrelic]  # Add debug exporter
    ```

    Then restart the collector and check logs:
    ```bash
    # Check collector output log
    tail -f ~/logs/collector.log

    # Look for metric output in the logs
    ```

    **Important**: Remove the debug exporter in production to avoid log overflow.
  </Collapser>

  <Collapser
    id="no-data-appearing"
    title="No data appearing in New Relic"
  >
    **First, run the [Initial system checks](#initial-checks)** to verify collector and Java agent are running.

    **Check collector logs for errors**: Look for authentication or connection failures
    ```bash
    # Look for errors in collector output
    tail -n 100 ~/logs/collector.log | grep -i "error\|fail\|refuse"
    
    # Check for OTLP receiver activity
    tail -n 100 ~/logs/collector.log | grep -i "otlp\|metric"
    ```
  </Collapser>

  <Collapser
    id="missing-jmx-metrics"
    title="Missing JMX metrics from Kafka brokers"
  >
    **First, run the [Initial system checks](#initial-checks)** to verify the Java agent is attached to Kafka processes.

    **Check broker logs for Java agent initialization**:
    ```bash
    # Find Kafka log directory (common locations)
    find ~ -name "server.log" -path "*/kafka/logs/*" 2>/dev/null
    
    # Check the log file for OpenTelemetry messages
    # Replace with your actual Kafka log path
    tail -100 ~/kafka/logs/server.log 2>/dev/null | grep -i "otel\|jmx" || echo "Log file not found or no OTel messages"
    
    # Check directory where you started Kafka for nohup.out
    ls -lh nohup.out 2>/dev/null && tail -100 nohup.out | grep -i "otel\|jmx" || echo "No nohup.out file found"
    ```

    **Verify Java Agent configuration**: Ensure the startup command matches Step 3
    ```bash
    # Check if broker was started with correct Java agent parameters
    ps aux | grep "[o]pentelemetry-javaagent" | grep -o "Dotel\.[^ ]*"
    ```
    
    This should show all `-Dotel.*` parameters. Verify:
    - `-Dotel.jmx.enabled=true`
    - `-Dotel.jmx.config=<path>`
    - `-Dotel.exporter.otlp.endpoint=http://localhost:4317`

    **Check collector logs for incoming JMX metrics**:
    ```bash
    # Look for metrics coming from brokers
    tail -n 100 ~/logs/collector.log | grep -i "broker.id\|kafka\|jmx"
    ```
  </Collapser>

  <Collapser
    id="otlp-connection-errors"
    title="OTLP connection errors"
  >
    **First, run the [Initial system checks](#initial-checks)** to verify port 4317 is listening and accessible.

    **Check collector logs for specific OTLP errors**:
    ```bash
    # Look for connection refusals or timeouts
    tail -n 100 ~/logs/collector.log | grep -i "connection refused\|context deadline exceeded\|failed to connect"
    ```

    **Verify OTLP receiver configuration**: Ensure collector listens on `0.0.0.0:4317` (not `127.0.0.1`)
    ```yaml
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "0.0.0.0:4317"  # Accepts connections from any interface
    ```

    **Test remote connectivity** (if collector and Kafka are on different hosts):
    ```bash
    # From Kafka broker machine, test connection to collector
    timeout 5 bash -c "</dev/tcp/COLLECTOR_HOST/4317" 2>/dev/null && echo "Can reach collector" || echo "Cannot reach collector"
    ```
  </Collapser>
</CollapserGroup>

## Next steps [#next-steps]

* **[Explore Kafka metrics](/docs/opentelemetry/integrations/kafka/metrics-reference)** - View the complete metrics reference
* **[Create custom dashboards](/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards)** - Build visualizations for your Kafka data
* **[Set up alerts](/docs/opentelemetry/integrations/kafka/metrics-reference/#alerting)** - Monitor critical metrics like consumer lag and under-replicated partitions
