---
title: Docker container metrics reference
tags:
  - Integrations
  - OpenTelemetry
  - Docker
  - Metrics
metaDescription: "Complete reference of Docker container metrics collected by OpenTelemetry, including descriptions, types, and alerting recommendations."
freshnessValidatedDate: never
---

This page provides a comprehensive reference for all Docker container metrics collected by the OpenTelemetry [dockerstatsreceiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/dockerstatsreceiver). Use this reference to understand what data is available, create custom queries, and set up effective alerts for your containerized applications.

## Key metrics for monitoring [#key-metrics]

While the Docker Stats receiver collects extensive metrics, these are the most important ones for monitoring container health and performance:

### Essential CPU metrics
- **`container.cpu.utilization`** - Percentage of CPU used by the container (most important for alerting)
- **`container.cpu.usage.total`** - Total CPU time consumed (useful for trend analysis)
- **`container.cpu.throttling_data.throttled_periods`** - Container hitting CPU limits (indicates resource constraints)

### Critical memory metrics
- **`container.memory.percent`** - Percentage of memory used (key for resource monitoring)
- **`container.memory.usage.total`** - Current memory usage excluding cache
- **`container.memory.fails`** - Memory allocation failures (critical alert condition)

### Important network metrics
- **`container.network.io.usage.rx_bytes`** / **`container.network.io.usage.tx_bytes`** - Network throughput
- **`container.network.io.usage.rx_errors`** / **`container.network.io.usage.tx_errors`** - Network errors

### Essential operational metrics
- **`container.pids.count`** - Number of processes in the container
- **`container.restarts`** - Container restart count (stability indicator)
- **`container.uptime`** - Time since container started

## Alerting recommendations [#alerting]

Set up alerts for these critical thresholds:

| Metric | Alert Condition | Suggested Threshold | Severity |
|--------|----------------|-------------------|----------|
| `container.cpu.utilization` | High CPU usage | > 85% for 5 minutes | Warning |
| `container.cpu.utilization` | Critical CPU usage | > 95% for 2 minutes | Critical |
| `container.memory.percent` | High memory usage | > 90% for 5 minutes | Warning |
| `container.memory.percent` | Critical memory usage | > 95% for 2 minutes | Critical |
| `container.memory.fails` | Memory allocation failures | > 0 | Critical |
| `container.restarts` | Frequent restarts | > 5 in 1 hour | Warning |
| `container.pids.count` | Process count spike | > 1000 (adjust per app) | Warning |
| `container.network.io.usage.rx_errors` | Network errors | > 100 per minute | Warning |
| `container.cpu.throttling_data.throttled_periods` | CPU throttling | > 0 | Info |

<Callout variant="tip">
**NRQL Alert Examples:**

CPU utilization alert:
```sql
SELECT average(container.cpu.utilization) FROM Metric WHERE container.name LIKE '%your-app%' FACET container.name
```

Memory usage alert:
```sql
SELECT average(container.memory.percent) FROM Metric WHERE container.name LIKE '%your-app%' FACET container.name
```

Container restart detection:
```sql
SELECT latest(container.restarts) - earliest(container.restarts) FROM Metric WHERE container.name LIKE '%your-app%' FACET container.name SINCE 1 hour ago
```
</Callout>

## Complete metrics reference [#metrics-reference]

The OpenTelemetry Collector Contrib's [dockerstatsreceiver](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/dockerstatsreceiver) collects the following metrics from the Docker Stats API:

<CollapserGroup>
<Collapser
id="docker-metrics"
title="Container metrics"
>
<table>
<thead>
<tr>
<th style={{ width: "350px" }}>
Metric
</th>
<th>
Description
</th>
<th>
Type
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
`container.blockio.io_merged_recursive`
</td>
<td>
Number of bios/requests merged into requests belonging to this cgroup and its descendant cgroups
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.blockio.io_queued_recursive`
</td>
<td>
Number of requests queued up for this cgroup and its descendant cgroups
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.blockio.io_service_bytes_recursive`
</td>
<td>
Number of bytes transferred to/from the disk by the group and descendant groups
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.blockio.io_service_time_recursive`
</td>
<td>
Total amount of time in nanoseconds between request dispatch and request completion for the IOs done by this cgroup and descendant cgroups
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.blockio.io_serviced_recursive`
</td>
<td>
Number of IOs (bio) issued to the disk by the group and descendant groups
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.blockio.io_time_recursive`
</td>
<td>
Disk time allocated to cgroup (and descendant cgroups) per device in milliseconds
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.blockio.io_wait_time_recursive`
</td>
<td>
Total amount of time the IOs for this cgroup (and descendant cgroups) spent waiting in the scheduler queues for service
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.usage.kernelmode`
</td>
<td>
CPU kernel mode usage
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.usage.percpu`
</td>
<td>
Per-core CPU usage by the container (disabled by default)
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.usage.system`
</td>
<td>
System CPU usage
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.usage.total`
</td>
<td>
Total CPU time consumed by the container
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.usage.usermode`
</td>
<td>
CPU user mode usage
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.percent`
</td>
<td>
Percent of CPU used by the container (deprecated, use container.cpu.utilization instead)
</td>
<td>
Gauge
</td>
</tr>
<tr>
<td>
`container.cpu.utilization`
</td>
<td>
Percent of CPU used by the container
</td>
<td>
Gauge
</td>
</tr>
<tr>
<td>
`container.cpu.throttling_data.periods`
</td>
<td>
Number of periods with throttling active
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.throttling_data.throttled_periods`
</td>
<td>
Number of periods when the container hit its throttling limit
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.throttling_data.throttled_time`
</td>
<td>
Aggregate time the container was throttled
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.cpu.limit`
</td>
<td>
CPU limit set for the container
</td>
<td>
Gauge
</td>
</tr>
<tr>
<td>
`container.cpu.logical.count`
</td>
<td>
Number of cores available to the container
</td>
<td>
Gauge
</td>
</tr>
<tr>
<td>
`container.cpu.shares`
</td>
<td>
CPU shares allocated to the container
</td>
<td>
Gauge
</td>
</tr>
<tr>
<td>
`container.cpu.cores.used`
</td>
<td>
Number of CPU cores used by the container
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.usage.limit`
</td>
<td>
Memory usage limit
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.usage.max`
</td>
<td>
Maximum memory usage
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.usage.total`
</td>
<td>
Memory usage of the container. This excludes the cache
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.percent`
</td>
<td>
Percentage of memory used
</td>
<td>
Gauge
</td>
</tr>
<tr>
<td>
`container.memory.active_anon`
</td>
<td>
Amount of memory used in anonymous mappings such as brk(), sbrk(), and mmap(MAP_ANONYMOUS) that are actively used
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.active_file`
</td>
<td>
Amount of cache memory used by files that are actively used
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.anon`
</td>
<td>
Amount of memory used in anonymous mappings (pages not backed by files)
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.cache`
</td>
<td>
The amount of memory used by the processes of this control group that can be associated with a block on a block device
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.dirty`
</td>
<td>
Bytes that are waiting to get written back to the disk, from this cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.fails`
</td>
<td>
Number of times memory limit was hit
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.file`
</td>
<td>
Amount of memory used by files (file cache)
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.hierarchical_memory_limit`
</td>
<td>
The max amount of physical memory that the cgroup can use
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.hierarchical_memsw_limit`
</td>
<td>
The max amount of RAM + swap that the cgroup can use
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.inactive_anon`
</td>
<td>
Amount of memory used in anonymous mappings such as brk(), sbrk(), and mmap(MAP_ANONYMOUS) that are not actively used
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.inactive_file`
</td>
<td>
Amount of cache memory used by files that are not actively used
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.mapped_file`
</td>
<td>
Indicates the amount of memory mapped by the processes in the control group
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.pgfault`
</td>
<td>
Indicate the number of times that a process of the cgroup triggered a page fault
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.pgmajfault`
</td>
<td>
Indicate the number of times that a process of the cgroup triggered a major fault
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.pgpgin`
</td>
<td>
Number of pages read from disk by the cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.pgpgout`
</td>
<td>
Number of pages written to disk by the cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.rss`
</td>
<td>
The amount of memory that doesn't correspond to anything on disk: stacks, heaps, and anonymous memory maps
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.rss_huge`
</td>
<td>
Number of bytes of anonymous transparent hugepages in this cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.unevictable`
</td>
<td>
The amount of memory that cannot be reclaimed
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.memory.writeback`
</td>
<td>
Number of bytes of file/anon cache that are queued for syncing to disk in this cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.rx_bytes`
</td>
<td>
Bytes received by the container via its network interface
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.rx_dropped`
</td>
<td>
Number of received packets dropped by the container
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.rx_errors`
</td>
<td>
Received errors by the container
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.rx_packets`
</td>
<td>
Packets received by the container via its network interface
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.tx_bytes`
</td>
<td>
Bytes sent by the container via its network interface
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.tx_dropped`
</td>
<td>
Number of sent packets dropped by the container
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.tx_errors`
</td>
<td>
Transmission errors by the container
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.network.io.usage.tx_packets`
</td>
<td>
Packets sent by the container via its network interface
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.pids.count`
</td>
<td>
Number of PIDs in the container's cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.pids.limit`
</td>
<td>
Maximum number of PIDs in the container's cgroup
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.restarts`
</td>
<td>
Number of times the container has been restarted
</td>
<td>
Sum
</td>
</tr>
<tr>
<td>
`container.uptime`
</td>
<td>
Time elapsed since container started
</td>
<td>
Gauge
</td>
</tr>
</tbody>
</table>
</Collapser>

<Collapser
id="docker-attributes"
title="Container attributes"
>
<table>
<thead>
<tr>
<th style={{ width: "350px" }}>
Attribute
</th>
<th>
Description
</th>
<th>
Values
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
`collector.name`
</td>
<td>
Custom attribute for collector identification (if configured in your collector)
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`container.hostname`
</td>
<td>
The hostname of the container
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`container.id`
</td>
<td>
The full container ID
</td>
<td>
String (64-character hex)
</td>
</tr>
<tr>
<td>
`container.image.name`
</td>
<td>
Name of the container image
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`container.name`
</td>
<td>
Container name
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`container.runtime`
</td>
<td>
Container runtime
</td>
<td>
`docker`
</td>
</tr>
<tr>
<td>
`deployment.environment`
</td>
<td>
Deployment environment identifier (if configured in your collector)
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`description`
</td>
<td>
Description of the metric
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`device_major`
</td>
<td>
Device major number (for block I/O metrics)
</td>
<td>
Integer
</td>
</tr>
<tr>
<td>
`device_minor`
</td>
<td>
Device minor number (for block I/O metrics)
</td>
<td>
Integer
</td>
</tr>
<tr>
<td>
`entity.guid`
</td>
<td>
New Relic entity GUID for the container
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`entity.name`
</td>
<td>
New Relic entity name (typically the container name)
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`entity.type`
</td>
<td>
New Relic entity type
</td>
<td>
`CONTAINER`
</td>
</tr>
<tr>
<td>
`instrumentation.provider`
</td>
<td>
Instrumentation provider identifier
</td>
<td>
`opentelemetry`
</td>
</tr>
<tr>
<td>
`interface`
</td>
<td>
Network interface name (for network metrics)
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`newrelic.source`
</td>
<td>
Source of the metric in New Relic
</td>
<td>
`api.metrics.otlp`
</td>
</tr>
<tr>
<td>
`nr.entity_type`
</td>
<td>
New Relic entity type for entity correlation
</td>
<td>
`CONTAINER`
</td>
</tr>
<tr>
<td>
`operation`
</td>
<td>
Type of block I/O operation
</td>
<td>
`read`, `write`
</td>
</tr>
<tr>
<td>
`otel.library.name`
</td>
<td>
OpenTelemetry library/receiver name
</td>
<td>
`github.com/open-telemetry/opentelemetry-collector-contrib/receiver/dockerstatsreceiver`
</td>
</tr>
<tr>
<td>
`otel.library.version`
</td>
<td>
OpenTelemetry library version
</td>
<td>
String (e.g., `0.142.0`)
</td>
</tr>
<tr>
<td>
`service.name`
</td>
<td>
Service name configured in the collector
</td>
<td>
String
</td>
</tr>
<tr>
<td>
`telemetry.sdk.name`
</td>
<td>
Telemetry SDK identifier
</td>
<td>
`opentelemetry`
</td>
</tr>
<tr>
<td>
`unit`
</td>
<td>
Unit of measurement for the metric
</td>
<td>
String (e.g., `{cpus}`, `By`, `1`)
</td>
</tr>
</tbody>
</table>
</Collapser>

</CollapserGroup>

## Understanding metric types [#metric-types]

Docker metrics use different measurement types:

- **Sum**: Cumulative values that increase over time (e.g., total CPU time, bytes transferred)
- **Gauge**: Point-in-time values that can go up or down (e.g., current memory usage, CPU percentage)

<Callout variant="important">
**Rate calculations**: For Sum metrics, use NRQL's `rate()` function to calculate per-second rates:

```sql
SELECT rate(sum(container.network.io.usage.rx_bytes), 1 second) AS 'Bytes received/sec'
FROM Metric WHERE container.name = 'your-container'
FACET container.name TIMESERIES
```
</Callout>

## Metric collection configuration [#configuration]

Some metrics require explicit enablement in your collector configuration:

```yaml
docker_stats:
  metrics:
    # Required for New Relic UI
    container.pids.count:
      enabled: true
    # Network error metrics (useful for troubleshooting)
    container.network.io.usage.tx_errors:
      enabled: true
    container.network.io.usage.rx_errors:
      enabled: true
    # Per-CPU metrics (high cardinality - use carefully)
    container.cpu.usage.percpu:
      enabled: false  # Keep disabled unless needed
```

## Resource optimization [#optimization]

For high-container-count environments, consider these optimizations:

- **Disable high-cardinality metrics**: Turn off `container.cpu.usage.percpu` unless needed
- **Adjust collection frequency**: Increase `collection_interval` from 15s to 30s or 60s
- **Filter containers**: Use container label filtering to monitor only critical containers

For more details, see the [Docker Stats receiver documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/receiver/dockerstatsreceiver/documentation.md).

## Next steps [#next-steps]

Now that you understand Docker metrics:

- **[Find and query your data](/docs/opentelemetry/integrations/docker-monitoring/find-and-query-data)** - Learn how to explore your Docker metrics in New Relic
- **[Set up monitoring](/docs/opentelemetry/integrations/docker-monitoring/self-hosted)** - Configure Docker monitoring if you haven't already
- **Create dashboards**: Build custom visualizations using the metrics in this reference