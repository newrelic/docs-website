---
title: PostgreSQL monitoring integration
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: "New Relic's PostgreSQL integration: how to install it and configure it, and what data it reports."
redirects:
  - /https%3A/docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/postgresql-monitoring-integration
  - /docs/postgresql-integration-new-relic-infrastructure
  - /docs/postgresql-monitoring-integration
---

The New Relic PostgreSQL [on-host integration](https://docs.newrelic.com/docs/integrations/host-integrations/getting-started/introduction-host-integrations) receives and sends inventory metrics from your PostgreSQL instance to the New Relic platform, where you can aggregate and visualize key performance metrics. Data from instances, databases, and clusters helps you find the source of problems.

Read on to install the integration, and to see what data we collect.

## Compatibility and requirements [#comp-req]

Our integration is compatible with PostgreSQL 9.0 or higher.

If PostgreSQL is **not** running on Kubernetes or Amazon ECS, you must [install the infrastructure agent](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) on a host running PostgreSQL. Otherwise:

* If running on Kubernetes, see [these requirements](https://docs.newrelic.com/docs/monitor-service-running-kubernetes#requirements).
* If running on ECS, see [these requirements](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).

## Quick start [#quick]

Instrument your PostgreSQL instance quickly and send your telemetry data with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent.

![A screenshot of the guided install CLI.](./images/guided-install-cli.png "The guided install CLI.")

Ready to get started? Click one of these button to try it out.

<ButtonGroup>
<ButtonLink
  role="button"
  to="https://one.newrelic.com/launcher/nr1-core.home?pane=eyJuZXJkbGV0SWQiOiJucjEtY29yZS5ob21lLXNjcmVlbiJ9&cards%5B0%5D=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsImFjdGlvbkluZGV4IjoxfQ=="
  variant="primary"
>
  Guided install
</ButtonLink>

<ButtonLink
  role="button"
  to="https://one.eu.newrelic.com/launcher/nr1-core.home?pane=eyJuZXJkbGV0SWQiOiJucjEtY29yZS5ob21lLXNjcmVlbiJ9&cards%5B0%5D=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsImFjdGlvbkluZGV4IjoxfQ=="
  variant="primary"
>
  EU Guided install
</ButtonLink>
</ButtonGroup>

Our guided install uses the infrastructure agent to set up the PostgreSQL integration. Not only that, it discovers other applications and log sources running in your environment and then recommends which ones you should instrument.

The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your PostgreSQL instance.

## Install and activate [#install]

To install the PostgreSQL integration, follow the instructions for your environment:

<CollapserGroup>
  <Collapser
    id="ecs-install"
    title="ECS"
  >
    See [Monitor service running on ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
  </Collapser>

  <Collapser
    id="k8s-install"
    title="Kubernetes"
  >
    See [Monitor service running on Kubernetes](/docs/monitor-service-running-kubernetes).
  </Collapser>

  <Collapser
    id="linux-install"
    title="Linux"
  >
    1. Follow the procedures to [install the infrastructure integration package](https://docs.newrelic.com/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic) using the file name `nri-postgresql`.
    2. Change directory to the integrations folder:

       ```
       cd /etc/newrelic-infra/integrations.d
       ```
    3. Copy of the [sample configuration file](#example-postgresSQL-config):

       ```
       sudo cp postgresql-config.yml.sample postgresql-config.yml
       ```
    4. Edit the `postgresql-config.yml` file as described in the [configuration settings](#config).
    5. Before you restart the infrastructure agent, [create a user](#create-user) with `READ` permissions on the required functions.
    6. [Restart the infrastructure agent.](https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)
  </Collapser>

  <Collapser
    id="windows-install"
    title="Windows"
  >
    1. Download the `nri-postgresql` .MSI installer image from:

       [http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-postgresql/nri-postgresql-amd64.msi](http://download.newrelic.com/infrastructure_agent/windows/integrations/nri-postgresql/nri-postgresql-amd64.msi)
    2. To install from the Windows command prompt, run:

       ```
       msiexec.exe /qn /i <var>PATH\TO\</var>nri-postgresql-amd64.msi
       ```
    3. In the Integrations directory, `C:\Program Files\New Relic\newrelic-infra\integrations.d\`, create a copy of the sample configuration file by running:

       ```
       cp postgresql-config.yml.sample postgresql-config.yml
       ```
    4. Edit the `postgresql-config.yml` file as described in the [configuration settings](#config).
    5. [Restart the infrastructure agent](https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status).
  </Collapser>
</CollapserGroup>

Additional notes:

* **Advanced:** Integrations are also available in [tarball format](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball) to allow for install outside of a package manager.
* **On-host integrations do not automatically update.** For best results, regularly [update the integration package](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package) and [the infrastructure agent](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent).

## PostgreSQL users and permissions [#create-user]

Create a user with `SELECT` permissions on:

* `pg_stat_database`
* `pg_stat_database_conflicts`
* `pg_stat_bgwriter`

You can complete this step before or after you [configure the `postgresql-config.yml` file](#config). To create the user for the PostgreSQL integration:

```
CREATE USER new_relic WITH PASSWORD '<var>PASSWORD</var>';
GRANT SELECT ON pg_stat_database TO new_relic;
GRANT SELECT ON pg_stat_database_conflicts TO new_relic;
GRANT SELECT ON pg_stat_bgwriter TO new_relic;
```

This will allow the integration to gather global metrics related to the PostgreSQL instance.

If you also want to obtain table and index-related metrics (for example, table size and index size), the PostgreSQL role used by the integration (`new_relic`) also needs `SELECT` permissions on the tables from which it will gather metrics from. For example, to allow the integration to collect metrics from all the tables and indexes present in the database (in the public `schema`), use the following:

```
GRANT SELECT ON ALL TABLES IN SCHEMA public TO new_relic;
```

## Configure the integration [#config]

An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference.

There are several ways to configure the integration, depending on how it was installed:

* If enabled via Kubernetes: see [Monitor services running on Kubernetes](/docs/monitor-service-running-kubernetes).
* If enabled via Amazon ECS: see [Monitor services running on ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
* If installed on-host: edit the config in the integration's YAML config file, `postgresql-config.yml`.

Config options are below. For an example configuration, see the [example config file](#example-postgresSQL-config).

<Callout variant="important">
  With secrets management, you can configure on-host integrations with New Relic infrastructure's agent to use sensitive data (such as passwords) without having to write them as plain text into the integration's configuration file. For more information, see [Secrets management](https://docs.newrelic.com/docs/integrations/host-integrations/installation/secrets-management).
</Callout>

### Commands

The configuration accepts the following commands:

* `all_data`: collects both inventory and metric data for the configured PostgreSQL instance..

### Arguments

The `all_data` command accepts the following arguments:

* `username`: the user name for the PostgreSQL connection. **Required.**
* `password`: the password for the PostgreSQL connection. **Required.**
* `hostname`: the hostname for the PostgreSQL connection. Default: `localhost.`
* `port`: the port where PostgreSQL is running. Default: `5432`.
* `collection_list`: a JSON array, a JSON object, or the string literal `ALL` that specifies the entities to be collected. The PostgreSQL user can only collect table and index metrics from tables it has `SELECT` permissions for. **Required except for PgBouncer.**

  * JSON array: Interpreted as a list of database names from which to collect all relevant metrics, including any tables and indexes belonging to that database. For example:

    ```
    collection_list: '["postgres"]'
    ```
  * JSON object: only entities specified in the object will be collected, no automatic discovery will be performed. The levels of JSON are `database name -> schema name -> table name -> index name`. For example:

    ```
    collection_list: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
    ```
  * `ALL`: collect metrics for all databases, schemas, tables, and indexes discovered. For example:

    ```
    collection_list: 'ALL'
    ```
* `pgbouncer`: collect `pgbouncer` metrics. Default: `false`.
* `enable_ssl`: determines if SSL is enabled. If `true`, `ssl_cert_location` and `ssl_key_location` are required. Default: `false`.
* `trust_server_certificate`: if `true`, the server certificate is not verified for SSL. If `false`, the server certificate identified in `ssl_root_cert_location` is verified. Default: `false`.
* `ssl_root_cert_location`: absolute path to PEM-encoded root certificate file. Required if `trust_server_certificate` is `false`.
* `ssl_cert_location`: absolute path to PEM-encoded client certificate file. Required if `enable_ssl` is `true`.
* `ssl_key_location`: absolute path to PEM-encoded client key file. Required if `enable_ssl` is `true`.
* `timeout`: maximum wait for connection, in seconds. Set to `0` for no timeout. Default: `10`.
* `database`: the PostgreSQL database to connect to. Default: `postgres`.
* `custom_metrics_query`: a SQL query that required `columns metric_name`, `metric_type`, and `metric_value.metric_type` can be `gauge`, `rate`, `delta`, or `attribute`. Additional columns collected with the query are added to the metric set as attributes.
* `custom_metrics_config`: a path to a YAML file with a list of custom queries, along with their metric type, database, and sample name overrides. See example for details.
* `collect_db_lock_metrics`: Enable collecting database lock metrics, which can be performance intensive. Default: `true`.
* `collect_bloat_metrics`: Enable tablespace bloat metrics, which can be performance intensive. Default: `true`.

### Example configuration [#example-config]

Example `postgresql-config.yml` file configuration:

<CollapserGroup>
  <Collapser
    id="example-postgresSQL-config"
    title="PostgreSQL configuration file"
  >
    ```
    integration_name: com.newrelic.postgresql

    instances:
      # A name for the collection
      - name: sample_postgres
        # The only supported command is all_data.
        command: all_data
        arguments:
          # The username for the Postgres instance. Required.
          username: postgres
          # The password for the Postgres instance. Required.
          password: pass
          # The hostname for the Postgres instance. Defaults to localhost.
          hostname: psql-sample.localnet
          # The port of the Postgres instance. If PgBouncer is being used,
          # use the port it is running on. Defaults to 5432.
          port: 6432
          # The JSON object which contains the entities to monitor. The nesting
          # levels of JSON are database name -> schema name -> table name -> index name.
          collection_list: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
          # True if SSL is to be used. Defaults to false.
          enable_ssl: true
          # True if the SSL certificate should be trusted without validating.
          # Setting this to true may open up the monitoring service to MITM attacks.
          # Defaults to false.
          trust_server_certificate: false
          ssl_root_cert_location: /etc/newrelic-infra/root_cert.crt
          ssl_cert_location: /etc/newrelic-infra/postgresql.crt
          ssl_key_location: /etc/newrelic-infra/postgresql.key
          timeout:  10
          # custom_metrics_query:
            # select
              # 'rows_inserted' as "metric_name",
              # 'delta' as "metric_type",
              # sd.tup_inserted as "metric_value",
              # sd.datid as "database_id"
            # from pg_stat_database sd;
        # Used to label your data.
        labels:
          env: production
          role: postgresql
    ```
  </Collapser>

  <Collapser
    id="example-postgresSQL-config"
    title="PostgreSQL custom metrics config"
  >
    ```
    ---
    queries:

      # Metric names are set to the column names in the query results
      - query: >-
          SELECT
          BG.checkpoints_timed AS scheduled_checkpoints_performed,
          BG.checkpoints_req AS requested_checkpoints_performed,
          BG.buffers_checkpoint AS buffers_written_during_checkpoint,
          BG.buffers_clean AS buffers_written_by_background_writer,
          BG.maxwritten_clean AS background_writer_stops,
          BG.buffers_backend AS buffers_written_by_backend,
          BG.buffers_alloc AS buffers_allocated
          FROM pg_stat_bgwriter BG;

        # database defaults to the auth database in the main config
        database: new_frontier_config_dev

        # If not set explicitly here, metric type will default to
        # 'gauge' for numbers and 'attribute' for strings
        metric_types:
          buffers_allocated: rate

        # If unset, sample_name defaults to PostgresqlCustomSample
        sample_name: MyCustomSample
    ```
  </Collapser>
</CollapserGroup>

For more about the general structure of on-host integration configuration, see [Configuration](/docs/integrations/integrations-sdk/file-specifications/host-integration-configuration-overview).

## Find and use data [#find-and-use]

Data from this service is reported to an [integration dashboard](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts).

Metrics are attached to these [event types](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic):

* [`PostgresqlDatabaseSample`](#databaseSample)
* [`PostgresqlIndexSample`](#indexSample)
* [`PostgresqlInstanceSample`](#instanceSample)
* [`PostgresqlTableSample`](#tableSample)
* [`PgBouncerSample`](#pgBouncerSample)

You can [query this data](/docs/using-new-relic/data/understand-data/query-new-relic-data) for troubleshooting purposes or to create custom charts and dashboards.

For more on how to find and use your data, see [Understand integration data](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Metric data [#metrics]

The PostgreSQL integration collects the following database metric attributes. Some attributes apply to [all PostgreSQL event types](#all-metrics). Some metric names are prefixed with a category indicator and a period, such as `db.` or `index.` metric names.

### PostgresqlDatabaseSample metrics [#databaseSample]

These attributes are attached to the `PostgresqlDatabaseSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLDatabaseSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `db.connections`
      </td>

      <td>
        Number of backends currently connected to this database.
      </td>
    </tr>

    <tr>
      <td>
        `db.commitsPerSecond`
      </td>

      <td>
        Committed transactions per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rollbacksPerSecond`
      </td>

      <td>
        Transactions rolled back per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.readsPerSecond`
      </td>

      <td>
        Number of disk blocks read in this database per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.bufferHitsPerSecond`
      </td>

      <td>
        Number of times disk blocks were found already in the buffer cache, so that a read was not necessary. This only includes hits in the PostgreSQL buffer cache, not the operating system's file system cache.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsReturnedPerSecond`
      </td>

      <td>
        Rows returned by queries per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsFetchedPerSecond`
      </td>

      <td>
        Rows fetched by queries per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsInsertedPerSecond`
      </td>

      <td>
        Rows inserted per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsUpdatedPerSecond`
      </td>

      <td>
        Rows updated per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsDeletedPerSecond`
      </td>

      <td>
        Rows deleted per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.tablespacePerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to dropped tablespaces.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.locksPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to lock timeouts.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.snapshotPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to old snapshots.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.bufferpinPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to pinned buffers.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.deadlockPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to deadlocks.
      </td>
    </tr>

    <tr>
      <td>
        `db.tempFilesCreatedPerSecond`
      </td>

      <td>
        Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (for example, sorting or hashing), and regardless of the `log_temp_files` setting.
      </td>
    </tr>

    <tr>
      <td>
        `db.tempWrittenInBytesPerSecond`
      </td>

      <td>
        Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the `log_temp_files` setting.
      </td>
    </tr>

    <tr>
      <td>
        `db.deadlocksPerSecond`
      </td>

      <td>
        Number of deadlocks detected in this database.
      </td>
    </tr>

    <tr>
      <td>
        `db.readTimeInMillisecondsPerSecond`
      </td>

      <td>
        Time spent reading data file blocks by backends in this database, in milliseconds.
      </td>
    </tr>

    <tr>
      <td>
        `db.writeTimeInMillisecondsPerSecond`
      </td>

      <td>
        Time spent writing data file blocks by backends in this database, in milliseconds.
      </td>
    </tr>
  </tbody>
</table>

### PostgresqlIndexSample metrics [#indexSample]

These attributes are attached to the `PostgresqlIndexSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLIndexSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `index.sizeInBytes`
      </td>

      <td>
        The size of an index.
      </td>
    </tr>

    <tr>
      <td>
        `index.rowsReadPerSecond`
      </td>

      <td>
        The number of index entries returned by scans on this index.
      </td>
    </tr>

    <tr>
      <td>
        `index.rowsFetchedPerSecond`
      </td>

      <td>
        The number of index entries fetched by scans on this index.
      </td>
    </tr>
  </tbody>
</table>

### PostgresqlInstanceSample metrics [#instanceSample]

These attributes are attached to the `PostgresqlInstanceSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLInstanceSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `bgwriter.checkpointsScheduledPerSecond`
      </td>

      <td>
        Number of scheduled checkpoints that have been performed.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.checkpointsRequestedPerSecond`
      </td>

      <td>
        Number of requested checkpoints that have been performed.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersWrittenForCheckpointsPerSecond`
      </td>

      <td>
        Number of buffers written during checkpoints.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersWrittenByBackgroundWriterPerSecond`
      </td>

      <td>
        Number of buffers written by the background writer.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.backgroundWriterStopsPerSecond`
      </td>

      <td>
        Number of times the background writer stopped a cleaning scan because it had written too many buffers.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersWrittenByBackendPerSecond`
      </td>

      <td>
        Number of buffers written directly by a backend.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersAllocatedPerSecond`
      </td>

      <td>
        Number of buffers allocated.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.backendFsyncCallsPerSecond`
      </td>

      <td>
        Number of times a backend had to execute its own `fsync` call. Normally the background writer handles them even when the backend does its own write.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.checkpointWriteTimeInMillisecondsPerSecond`
      </td>

      <td>
        Total amount of time that has been spent in the portion of checkpoint processing where files are written to disk, in milliseconds.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.checkpointSyncTimeInMillisecondsPerSecond`
      </td>

      <td>
        Total amount of time that has been spent in the portion of checkpoint processing where files are synchronized to disk, in milliseconds.
      </td>
    </tr>
  </tbody>
</table>

### PostgresqlTableSample metrics [#tableSample]

These attributes are attached to the `PostgresqlTableSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLTableSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `table.totalSizeInBytes`
      </td>

      <td>
        The total disk space used by the table, including indexes and TOAST data.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexSizeInBytes`
      </td>

      <td>
        The total disk space used by indexes attached to the specified table.
      </td>
    </tr>

    <tr>
      <td>
        `table.liveRows`
      </td>

      <td>
        Number of live rows.
      </td>
    </tr>

    <tr>
      <td>
        `table.deadRows`
      </td>

      <td>
        Number of dead rows.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexBlocksReadPerSecond`
      </td>

      <td>
        The number of disk blocks read from all indexes on this table.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexBlocksHitPerSecond`
      </td>

      <td>
        The number of buffer hits in all indexes on this table.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexToastBlocksReadPerSecond`
      </td>

      <td>
        The number of disk blocks read from this table's TOAST table index.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexToastBlocksHitPerSecond`
      </td>

      <td>
        The number of buffer hits in this table's TOAST table index.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastVacuum`
      </td>

      <td>
        Time of last vacuum on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastAutoVacuum`
      </td>

      <td>
        Time of last automatic vacuum on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastAnalyze`
      </td>

      <td>
        Time of last analyze on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastAutoAnalyze`
      </td>

      <td>
        Time of last automatic analyze on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.sequentialScansPerSecond`
      </td>

      <td>
        Number of sequential scans initiated on this table per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.sequentialScanRowsFetchedPerSecond`
      </td>

      <td>
        Number of live rows fetched by sequential scans per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexScansPerSecond`
      </td>

      <td>
        Number of index scans initiated on this table.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexScanRowsFetchedPerSecon`
      </td>

      <td>
        Number of live rows fetched by index scans.
      </td>
    </tr>

    <tr>
      <td>
        `table.rowsInsertedPerSecond`
      </td>

      <td>
        Rows inserted per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.rowsUpdatedPerSecond`
      </td>

      <td>
        Rows updated per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.rowsDeletedPerSecond`
      </td>

      <td>
        Rows deleted per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.bloatSizeInBytes`
      </td>

      <td>
        Size of bloat in bytes.
      </td>
    </tr>

    <tr>
      <td>
        `table.dataSizeInBytes`
      </td>

      <td>
        Size of disk spaced used by the main fork of the table.
      </td>
    </tr>

    <tr>
      <td>
        `table.bloatRatio`
      </td>

      <td>
        Fraction of table data size that is bloat.
      </td>
    </tr>
  </tbody>
</table>

### PgBouncerSample metrics [#pgBouncerSample]

These attributes are attached to the `PgBouncerSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PgBouncerSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `pgbouncer.stats.transactionsPerSecond`
      </td>

      <td>
        The transaction rate.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.queriesPerSecond`
      </td>

      <td>
        The query rate.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.bytesInPerSecond`
      </td>

      <td>
        The total network traffic received.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.bytesOutPerSecond`
      </td>

      <td>
        The total network traffic sent.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.totalTransactionDurationInMillisecondsPerSecond`
      </td>

      <td>
        Time spent by `pgbouncer` in transaction.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.totalQueryDurationInMillisecondsPerSecond`
      </td>

      <td>
        Time spent by `pgbouncer` actively querying PostgreSQL.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgTransactionCount`
      </td>

      <td>
        The average number of transactions per second in last stat period.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgTransactionDurationInMilliseconds`
      </td>

      <td>
        The average transaction duration.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgQueryCount`
      </td>

      <td>
        The average number of queries per second in last stat period.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgBytesIn`
      </td>

      <td>
        The client network traffic received.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgBytesOut`
      </td>

      <td>
        The client network traffic sent.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgQueryDurationInMilliseconds`
      </td>

      <td>
        The average query duration.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.clientConnectionsActive`
      </td>

      <td>
        Client connections linked to server connection and able to process queries.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.clientConnectionsWaiting`
      </td>

      <td>
        Client connections waiting on a server connection.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsActive`
      </td>

      <td>
        Server connections linked to a client connection.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsIdle`
      </td>

      <td>
        Server connections idle and ready for a client query.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsUsed`
      </td>

      <td>
        Server connections idle more than `server_check_delay`, needing `server_check_query`.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsTested`
      </td>

      <td>
        Server connections currently running either `server_reset_query` or `server_check_query`.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsLogin`
      </td>

      <td>
        Server connections currently in the process of logging in.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.maxwaitInMilliseconds`
      </td>

      <td>
        Age of oldest unserved client connection.
      </td>
    </tr>
  </tbody>
</table>

## Inventory data [#inventory]

The PostgreSQL integration collects each setting from `pg_settings` along with its `boot_val` and `reset_val`. The [inventory data](/docs/infrastructure/integrations-getting-started/getting-started/understand-integration-data-data-types#inventory-data) appears on the [Inventory page](/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure), under the **config/postgresql** source.

## Troubleshooting

Here are some troubleshooting tips for the PostgreSQL integration:

* If you have connection problems, make sure you can connect to the cluster from the same box with `psql`.
* If you have problems collecting `PgBouncer` metrics, make sure you are connected to the instance through `PgBouncer`. Default port is `6432`.
* If you get the error message `Error creating list of entities to collect: pq: unsupported startup parameter: extra_float_digits`, set `ignore_startup_parameters = extra_float_digits` in the PgBouncer config file.

## Check the source code [#source-code]

This integration is open source software. That means you can [browse its source code](https://github.com/newrelic/nri-postgresql "Link opens in a new window.") and send improvements, or create your own fork and build it.
