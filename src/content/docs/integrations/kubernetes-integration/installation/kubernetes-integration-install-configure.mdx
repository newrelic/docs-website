---
title: 'Kubernetes integration: install and configure'
tags:
  - Integrations
  - Kubernetes integration
  - Installation
translate:
  - jp
metaDescription: 'New Relic''s Kubernetes integration: How to install and activate the integration, and what data is reported.'
redirects:
  - /docs/kubernetes-monitoring-integration-beta
  - /docs/kubernetes-integration-beta
  - /docs/kubernetes-integration
  - /docs/kubernetes-integration-new-relic-infrastructure
  - /docs/kubernetes-monitoring-integration
  - /docs/integrations/host-integrations/host-integrations-list/kubernetes-monitoring-integration
  - /docs/integrations/kubernetes-integration/installation/kubernetes-monitoring-integration
  - /docs/integrations/kubernetes-integration/installation/kubernetes-monitoring-installation
  - /docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration
---

import pivotal from './images/pivotal.png'

import aks from './images/aks.png'

import openshift from './images/openshift.png'

import cke from './images/cke.jpeg'

import eks from './images/eks.png'

The easiest way to install the Kubernetes integration is to use our automated installer to generate a manifest. It bundles not just the integration DaemonSets, but also other New Relic Kubernetes configurations, like [Kubernetes events](/docs/integrations/kubernetes-integration/kubernetes-events/install-kubernetes-events-integration), [Prometheus OpenMetrics](/docs/integrations/prometheus-integrations/get-started/new-relic-prometheus-openmetrics-integration-kubernetes), and [New Relic log monitoring](/docs/logs).

Want to try out our Kubernetes integration? [Create a New Relic account](https://newrelic.com/signup) for free! No credit card required.

## Use automated installer [#installer]

You can use the automated installer for servers, VMs, and unprivileged environments. The installer can also help you with managed services or platforms after you review a few [preliminary notes](#cloud-platforms). We also have separate instructions if you need a [custom manifest](#customized-manifest) or prefer to do a [manual unprivileged installation](#unprivileged).

<ButtonLink
  role="button"
  to="https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0="
  variant="primary"
>
  Start the installer
</ButtonLink>

If your New Relic account [is in the EU region](/docs/using-new-relic/welcome-new-relic/get-started/our-eu-us-region-data-centers), access the installer from [one.eu.newrelic.com](http://one.eu.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=).

## Installs for managed services and platforms [#cloud-platforms]

Before starting our [automated installer](https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=), check out these notes for your managed services or platforms:

<CollapserGroup>
  <Collapser
    className="freq-link"
    id="install-amazon-eks"
    title={<><img src={eks} alt="EKS" style={{ verticalAlign: 'middle' }}/> <Link to="#install-amazon-eks"> Amazon EKS</Link></>}
  >
    The Kubernetes integration monitors worker nodes. In Amazon EKS, master nodes are managed by Amazon and abstracted from the Kubernetes platforms.

    Before starting our [automated installer](https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=) to deploy the Kubernetes integration in Amazon EKS, make sure you are using the version of [`kubectl` provided by AWS](https://docs.aws.amazon.com/eks/latest/userguide/configure-kubectl.html).
  </Collapser>

  <Collapser
    className="freq-link"
    id="install-amazon-eks-fargate"
    title={<><img src={eks} alt="EKS" style={{ verticalAlign: 'middle' }}/> <Link to="#install-amazon-eks-fargate"> Amazon EKS Fargate</Link></>}
  >
    For help installing our EKS Fargate integration, see these [setup options](/docs/integrations/kubernetes-integration/installation/install-fargate-integration).

  </Collapser>

  <Collapser
    className="freq-link"
    id="install-google-kubernetes-engine"
    title={<><img src={cke} alt="CKE" style={{ verticalAlign: 'middle' }}/> <Link to="#install-google-kubernetes-engine"> Google Kubernetes Engine (GKE)</Link></>}
  >
    The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google and abstracted from the Kubernetes platforms.

    Before starting our [automated installer](https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=) to deploy the Kubernetes integration on GKE, ensure you have sufficient permissions:

    1. Go to [console.cloud.google.com/iam-admin/iam](https://console.cloud.google.com/iam-admin/iam) and find your username. Click **edit**.
    2. Ensure you have permissions to create `Roles` and `ClusterRoles`: If you are not sure, add the **Kubernetes Engine Cluster Admin** role. If you cannot edit your user role, ask the owner of the GCP project to give you the necessary permissions.
    3. Ensure you have a `RoleBinding` that grants you the same permissions to create `Roles` and `ClusterRoles`:

       ```
       kubectl create clusterrolebinding <var>YOUR_USERNAME</var>-cluster-admin-binding --clusterrole=cluster-admin --user=<var>YOUR_GCP_EMAIL</var>
       ```

    Creating a RoleBinding is necessary because of a known RBAC issue in Kubernetes and Kubernetes Engine versions 1.6 or higher. For more information, see [Google Cloud's documentation on defining permissions in a role](https://cloud.google.com/kubernetes-engine/docs/how-to/role-based-access-control#defining_permissions_in_a_role).
  </Collapser>

  <Collapser
    className="freq-link"
    id="install-openshift-container-platform"
    title={<><img src={openshift} alt="OpenShift" style={{ verticalAlign: 'middle' }}/> OpenShift container platform</>}
  >
    To deploy the Kubernetes integration with [OpenShift](https://learn.openshift.com/?extIdCarryOver=true&sc_cid=701f2000001OH7iAAG):

    1. Add the `<>{'<release_name>'}</>-newrelic-infrastructure` service account to your privileged [Security Context Constraints](https://docs.openshift.com/enterprise/3.0/admin_guide/manage_scc.html):

       ```
       oc adm policy add-scc-to-user privileged \
       system:serviceaccount:<var><namespace></var>:<var><release_name></var>-newrelic-infrastructure
       ```

       The default `<>{'<release_name>'}</>` provided by the installer is `nri-bundle`.
    2. Complete the steps in our [automated installer](https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=).
    3. If you're using signed certificates, make sure they are properly configured by using the following variables in the `DaemonSet` portion of your manifest to set the `.pem` file:

       ```
       - name: NRIA_CA_BUNDLE_DIR
         value: <var>YOUR_CA_BUNDLE_DIR</var>
       - name: NRIA_CA_BUNDLE_FILE
         value: <var>YOUR_CA_BUNDLE_NAME</var>
       ```

       YAML key path: `spec.template.spec.containers.name.env`
    4. Save your changes.
  </Collapser>

  <Collapser
    className="freq-link"
    id="install-azure-aks"
    title={<><img src={aks} alt="AKS" style={{ verticalAlign: 'middle' }}/> Azure Kubernetes Service (AKS)</>}
  >
    The Kubernetes integration monitors worker nodes. In Azure Kubernetes Service, master nodes are managed by Azure and abstracted from the Kubernetes platforms.

    To deploy in Azure Kubernetes Service (AKS), complete the steps in our [automated installer](https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=).
  </Collapser>

  <Collapser
    className="freq-link"
    id="install-pks"
    title={<><img src={pivotal} alt="PKS" style={{ verticalAlign: 'middle' }}/> Pivotal Container Service (PKS / VMware Tanzu)</>}
  >
    To deploy in PKS, we recommend that you use the [automated installer](https://one.newrelic.com/launcher/k8s-cluster-explorer-nerdlet.cluster-explorer-launcher?pane=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJndWlkZWQiLCJlbnYiOiJrdWJlcm5ldGVzIiwiaW5pdGlhbEFjdGlvbkluZGV4IjpudWxsLCJhY3Rpb25JbmRleCI6MX0=), or you can follow the manual instructions provided in [Install the Kubernetes integration using Helm](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm).
  </Collapser>
</CollapserGroup>

## Custom manifest [#customized-manifest]

If the Kubernetes automated installer doesn't provide the settings you need, you can download our manifest template and install the integration manually.

To activate the Kubernetes integration, you must deploy the `newrelic-infra` agent onto a Kubernetes cluster as a `DaemonSet`:

1. [Install kube-state-metrics](https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment) and get it running on the cluster. For example:

   ```
   curl -L -o kube-state-metrics-<mark>1.9.5</mark>.zip https://github.com/kubernetes/kube-state-metrics/archive/v<mark>1.9.5</mark>.zip && unzip kube-state-metrics-<mark>1.9.5</mark>.zip && kubectl apply -f kube-state-metrics-<mark>1.9.5</mark>/examples/standard
   ```
2. Download the manifest file:

   ```
   curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml
   ```
3. In the `DaemonSet` portion of your manifest, add your [New Relic license key](https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/#ingest-license-key) and a cluster name to identify your Kubernetes cluster. **Both values are required.**

   * **Recommendation:** Do not change the `NRIA_PASSTHROUGH_ENVIRONMENT` or `NRIA_DISPLAY_NAME` value in your manifest.
   * `YOUR_CLUSTER_NAME` is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment.
   * YAML key path: `spec.template.spec.containers.name.env`

   ```
   env:
     - name: NRIA_LICENSE_KEY
       value: <var>YOUR_LICENSE_KEY</var>
     - name: CLUSTER_NAME
       value: <var>YOUR_CLUSTER_NAME</var>
   ```
4. If you need to adapt the manifest to fit your environment, review the [configure](#configure-the-integration) section in this doc.
5. Confirm that `kube-state-metrics` is installed.

   ```
   kubectl get pods --all-namespaces | grep kube-state-metrics
   ```
6. Create the `DaemonSet`:

   ```
   kubectl create -f newrelic-infrastructure-k8s-latest.yaml
   ```
7. Confirm that the `DaemonSet` has been created successfully by looking for `newrelic-infra` in the results generated by this command:

   ```
   kubectl get daemonsets
   ```

To confirm that the integration is working: wait a few minutes, then look for data in the [New Relic Kubernetes cluster explorer](/docs/integrations/kubernetes-integration/cluster-explorer/kubernetes-cluster-explorer).

If you don't see data, review the [configuration procedures](#install) again, then follow the [troubleshooting procedures](/docs/integrations/host-integrations/troubleshooting/kubernetes-integration-troubleshooting-not-seeing-data).

<Callout variant="important">
  In the future, the number of labels collected on Kubernetes objects will be limited per object type (containers, pods, nodes, etc.). If objects have labels above the limit, you will be able to configure important labels that should always be sent to New Relic. When the limitation is in place, this documentation will be updated.
</Callout>

### Make sure New Relic pods can be scheduled [#new-relic-pods]

Some of the New Relic pods are set up as `DaemonSet` in the manifest file so that they can run on every host. These include `newrelic-infrastructure` and `newrelic-logging`. In rare circumstances, other pods may be scheduled first and starve the New Relic pods of resources. Since each of these pods have to run on a specific host, they will stay in pending status until that host has enough resources, even if there are other hosts available. This could end up occurring for long periods of time and result in reporting gaps.

To prevent this scenario, you can configure the Kubernetes scheduler to give New Relic pods a higher priority. Using the default scheduler:

1. Ensure `kube-scheduler` flag `disablePreemption` is not set to `true` (by default it is `false`).
2. Create a [PriorityClass](https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass) for the New Relic `DaemonSet` pods:

   * Set the appropriate priority value, which should generally be higher than your other pods.
   * `preemptionPolicy` is set to `PreemptLowerPriority` by default. This allows New Relic pods assigned this priority class to remove lower-priority pods that are taking up resources.
3. Edit the manifest file to add `priorityClassName` to any `DaemonSet` specs. In the example below, the highlighted line sets the priority class for `newrelic-infrastructure`:

   ```
   apiVersion: apps/v1
   kind: DaemonSet
   metadata:
     namespace: default
     labels:
       app: newrelic-infrastructure
       chart: newrelic-infrastructure-1.0.0
       release: nri-bundle
       mode: privileged
     name: nri-bundle-newrelic-infrastructure
   spec:
     <mark>priorityClassName: your-priority-class</mark>
     ...
   ```
4. If you have already deployed the New Relic pods, re-deploy them and confirm they have been created:

   ```
   kubectl delete -f newrelic-infrastructure-k8s-latest.yaml
   kubectl create -f newrelic-infrastructure-k8s-latest.yaml
   kubectl get daemonsets
   ```

## Unprivileged installs of the Kubernetes integration [#unprivileged]

For platforms that have stringent security requirements, we provide an unprivileged version of the Kubernetes integration. Changes from the standard Kubernetes integration are:

* Runs the infrastructure agent and the Kubernetes integration as a standard user instead of root
* No access to the underlying host filesystem
* No access to `/var/run/docker.sock`
* Container's root filesystem mounted as read-only
* `allowPrivilegeEscalation` is set to `false`
* `hostnetwork` is set to `false`

The tradeoff is that the solution will **only** collect metrics from Kubernetes, but it will not collect any metric from the underlying hosts directly. Kubernetes provides some [data (metrics and metadata) about its nodes (hosts)](/docs/integrations/kubernetes-integration/understand-use-data/understand-use-data#metrics).

<Callout variant="tip">
  Optional: To collect the underlying host metrics, the non-containerized [infrastructure agent can be deployed](/docs/infrastructure/new-relic-infrastructure/installation/install-infrastructure-linux) on the underlying host. The infrastructure agent already supports running as non-root. The combination of the Kubernetes integration in its unprivileged version and the agent running on the host will report all the [metrics that our standard solution for monitoring Kubernetes receives](/docs/infrastructure/new-relic-infrastructure/data-instrumentation/default-infrastructure-attributes-events).
</Callout>

<CollapserGroup>
  <Collapser
    id="unprivileged-steps"
    title="Steps to complete an unprivileged install"
  >
    1. Install `kube-state-metrics` and get it running on the cluster. For example:

       ```
       curl -L -o kube-state-metrics-<mark>1.9.5</mark>.zip https://github.com/kubernetes/kube-state-metrics/archive/v<mark>1.9.5</mark>.zip && unzip kube-state-metrics-<mark>1.9.5</mark>.zip && kubectl apply -f kube-state-metrics-<mark>1.9.5</mark>/examples/standard
       ```
    2. Download the integration manifest:

       ```
       curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-unprivileged-latest.yaml
       ```
    3. In the manifest, add your [New Relic license key](/docs/apis/intro-apis/new-relic-api-keys/#ingest-license-key) and a cluster name to identify your Kubernetes cluster. **Both values are required.**

       <Callout variant="important">
         `YOUR_CLUSTER_NAME` is your cluster’s id in New Relic Explorer. It doesn’t need to match the name of the cluster running in your environment.
       </Callout>

       ```
       env:
         - name: NRIA_LICENSE_KEY
           value: <var>YOUR_LICENSE_KEY</var>
         - name: CLUSTER_NAME
           value: <var>YOUR_CLUSTER_NAME</var>
       ```

       _YAML key path: `spec.template.spec.containers.name.env`_
    4. Confirm that `kube-state-metrics` is installed.

       ```
       kubectl get pods --all-namespaces | grep kube-state-metrics
       ```
    5. Create the `DaemonSet`:

       ```
       kubectl create -f newrelic-infrastructure-k8s-unprivileged-latest.yaml
       ```
    6. Confirm that the `DaemonSet` has been created successfully by looking for newrelic-infra in the results generated by this command:

       ```
       kubectl get daemonsets
       ```
    7. To confirm that the integration has been configured correctly, wait a few minutes, then run this [NRQL query](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql) to see if data has been reported:

       ```
       SELECT * FROM K8sPodSample since 5 minutes ago
       ```
  </Collapser>
</CollapserGroup>

## Configure the integration [#configure-integration]

The Kubernetes integration comes with a default configuration that should work in most environments. To change the configuration, modify the manifest file:

<CollapserGroup>
  <Collapser
    id="include-matching-metrics"
    title="Select which processes should send their data to New Relic"
  >
    By default, data about the processes running on your pods is not sent to New Relic. You can enable it by setting [`enable_process_metrics`](https://docs.newrelic.com/docs/infrastructure/install-configure-manage-infrastructure/configuration/infrastructure-configuration-settings#enable-process-metrics) to `true`.

    To choose what metric data you want to send to New Relic, configure the [`include_matching_metrics`](/docs/infrastructure/install-configure-manage-infrastructure/configuration/infrastructure-configuration-settings#include-matching-metrics) environment variable in your manifest.
  </Collapser>

  <Collapser
    id="custom-k8s-api-url"
    title="Specify the Kubernetes API host and port"
  >
    This is necessary when you are using SSL and not using the default FQDN. The Kubernetes API FQDN needs to match the FQDN of the SSL certificate.

    You do not need to specify both variables. For example, if you only specify the `HOST`, the default `PORT` will be used.

    ```
    - name: "KUBERNETES_SERVICE_HOST" 
      value: "<var>KUBERNETES_API_HOST</var>"
    - name: "KUBERNETES_SERVICE_PORT" 
      value: "<var>KUBERNETES_API_TCP_PORT</var>"
    ```
  </Collapser>

  <Collapser
    id="k8s-version-1.6-1.7.6"
    title="Kubernetes versions 1.6 to 1.7.5: Edit manifest file"
  >
    For Kubernetes versions 1.6 to 1.7.5, uncomment these two lines in the manifest file:

    ```
    - name: "CADVISOR_PORT" # Enable direct connection to cAdvisor by specifying the port.  Needed for Kubernetes versions prior to 1.7.6.
      value: "4194"
    ```
  </Collapser>

  <Collapser
    id="include-matching-processes"
    title="Use environment variables"
  >
    Use [environment variables](https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/configuration/configure-infrastructure-agent#Environment_Variables) that can be passed to the Kubernetes integration if you use a proxy to configure its URL.
  </Collapser>

  <Collapser
    id="disable-kube-state-metrics"
    title={<>Disable <InlineCode>kube-state-metrics</InlineCode> parsing</>}
  >
    You can disable `kube-state-metrics` parsing for the `DaemonSet` by using the following configuration:

    ```
    - name: "DISABLE_KUBE_STATE_METRICS"
       value: "true"
    ```

    <Callout variant="caution">
      Disabling `kube-state-metrics` also disables data collection for the following:

      * `ReplicaSets`
      * `DaemonSets`
      * `StatefulSets`
      * `Namespaces`
      * `Deployments`
      * `Services`
      * `Endpoints`
      * `Pods` (that are **pending**)

      Additionally, disabling this affects the Kubernetes Cluster Explorer in the following ways:

      * No pending pods are shown.
      * No filters based on services.
    </Callout>
  </Collapser>

  <Collapser
    id="kube-state-metrics-url-change"
    title={<>Specify the <InlineCode>kube-state-metrics</InlineCode> URL</>}
  >
    If several instances of `kube-state-metrics` are present in the cluster, uncomment and configure the following lines to specify which one to use:

    ```
    - name: "KUBE_STATE_METRICS_URL"
       value: "http://<var>KUBE_STATE_METRICS_IP_OR_FQDN</var>:<var>PORT</var>"
    ```

    <Callout variant="important">
      Even though a `KUBE_STATE_METRICS_URL` is defined, the KSM service should contain one of the following labels for the auto-discovery process:

      * `k8s-app=kube-state-metrics`

        OR
      * `app=kube-state-metrics`

        OR
      * `​​app.kubernetes.io/name=kube-state-metrics`
    </Callout>

    <Callout variant="important">
      This configuration option overrides `KUBE_STATE_METRICS_POD_LABEL`. If you have both defined, `KUBE_STATE_METRICS_POD_LABEL` has no effect.
    </Callout>
  </Collapser>

  <Collapser
    id="kube-state-metrics-pod-label-discovery"
    title={<>Discover <InlineCode>kube-state-metrics</InlineCode> pods using a label</>}
  >
    If several instances of `kube-state-metrics` are present in the cluster, another option to easily target one of these instances with the Kubernetes integration is to use label-based discovery.

    ```
    - name: "KUBE_STATE_METRICS_POD_LABEL"
       value: "<var>LABEL_NAME</var>"
    ```

    <Callout variant="important">
      When a `KUBE_STATE_METRICS_POD_LABEL` is defined, the label should have a value equal to `true`. For example, if the label name is `my-ksm`, ensure that `my-ksm=true`.
    </Callout>

    <Callout variant="important">
      This configuration option is incompatible with `KUBE_STATE_METRICS_URL`. If you have both defined, `KUBE_STATE_METRICS_URL` is used.
    </Callout>
  </Collapser>

  <Collapser
    id="kube-state-metrics-behind-rbac"
    title={<>Query <InlineCode>kube-state-metrics</InlineCode> behind RBAC</>}
  >
    If your instance of `kube-state-metrics` is behind [kube-rbac-proxy](https://github.com/brancz/kube-rbac-proxy), the integration can be configured in a compatible way using the combination of the label-based discovery and two other environment variables:

    ```
    - name: "KUBE_STATE_METRICS_SCHEME"
       value: "https"
     - name: "KUBE_STATE_METRICS_PORT"
       value: "<var>KSM_RBAC_PROXY_PORT</var>"
    ```

    To confirm which port should be used as the value of `KUBE_STATE_METRICS_PORT`, we recommend running a describe command on the `kube-state-metrics` pod and look for the port exposed by the container named `kube-rbac-proxy-main`.

    <Callout variant="important">
      These two configuration options only work when using the `KUBE_STATE_METRICS_POD_LABEL` configuration described above.
    </Callout>
  </Collapser>

  <Collapser
    id="kube-state-metrics-timeout-change"
    title={<><InlineCode>kube-state-metrics</InlineCode> timeout: Increase the client timeout</>}
  >
    To increase the client timeout of `kube-state-metrics`, add a new environment variable, `TIMEOUT`, to the manifest file:

    ```
    env:
      - name: TIMEOUT
        value: 5000 # The default client timeout when calling kube-state-metrics, in milliseconds
    ```

    Then, add this new environment variable to the [`NRIA_PASSTHROUGH_ENVIRONMENT`](/docs/infrastructure/install-configure-manage-infrastructure/configuration/infrastructure-configuration-settings)
  </Collapser>

  <Collapser
    id="non-default-namespace"
    title="Non-default namespace deployments: Edit config file"
  >
    If you want to deploy in a different namespace from `default`, change all values of `namespace` in the manifest.
  </Collapser>

  <Collapser
    id="ttl-for-api-responses"
    title="Set the TTL for the Kubernetes API responses cache"
  >
    By default, the integration will cache any retrieved information from the Kubernetes API for 5 minutes.

    Use the `API_SERVER_CACHE_TTL` environment variable to set a custom cache duration for responses from the API server. Valid time unit values are: `ns`, `us`, `ms`, `s`, `m`, and `h`. To disable caching, set to `0s`.

    ```
    env: 
      - name: API_SERVER_CACHE_TTL 
        value: "1m"
    ```
  </Collapser>

  <Collapser
    id="kube-state-metrics-control-plane"
    title="Specify base URLs for control plane component endpoints"
  >
    Use the following environment variables if any of the Kubernetes control plane components export metrics on base URLs that are different [from the defaults](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#discover-nodes-components). This is necessary for environments such as [OpenShift](http://learn.openshift.com/?extIdCarryOver=true&sc_cid=701f2000001OH7iAAG) when a control plane component metrics endpoint is using SSL or an alternate port.

    Values of these environment variables must be base URLs of the form `[scheme]://[host]:[port]`. URLs should not include a path component. For example:

    ```
    - name: "SCHEDULER_ENDPOINT_URL"
      value: "https://localhost:10259"
    - name: "ETCD_ENDPOINT_URL"
      value: "https://localhost:9979"
    - name: "CONTROLLER_MANAGER_ENDPOINT_URL"
      value: "https://localhost:10257"
    - name: "API_SERVER_ENDPOINT_URL"
      value: "https://localhost:6443"
    ```

    The `/metrics` path segment is added automatically. In addition, if the `https` scheme is used, authentication to the control plane component pod(s) is accomplished via service accounts.

    <Callout variant="caution">
      If a FQDN (fully qualified domain name) is used in a multi-master cluster, inconsistent results may be returned. Therefore, it is recommended to use `localhost` only.
    </Callout>

    <Callout variant="important">
      Even though a custom base URL is defined for a given control plane component, the control plane component pod(s) must contain one of [the labels supported by the auto-discovery process](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#discover-nodes-components).
    </Callout>

    <Callout variant="important">
      Even though a custom `ETCD_ENDPOINT_URL` can be defined, ETCD will always require `https` and [mTLS authentication to be configured](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#mtls-how-to).
    </Callout>
  </Collapser>
</CollapserGroup>

Here are some additional configurations to consider:

* [Do more configuration for control plane monitoring](/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring)
* [Link New Relic APM to the Kubernetes integration](/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes)
* [Monitor services that run on Kubernetes](/docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration#monitor-services)

## Configure the infrastructure agent [#configure-infrastructure-agent]

The Kubernetes integration image comes with a default configurations for the agent that can be modified if needed. When installing with the manifest, you can modify the infrastructure agent configuration by editing the manifest and adding any needed [configuration option of the agent](docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings) as environment variables of the `newrelic-infrastructure` DaemonSet.

When installing with Helm, you can specify the needed [infrastructure agent configuration options](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings) in the `values.yaml` [as shown in the example in GitHub](https://github.com/newrelic/helm-charts/blob/6a8b2e5f3a9d7b5d6527cfab306a16c9c1378542/charts/newrelic-infrastructure/values.yaml#L120).

The `config` object is used to populate the `configMap` that is mounted automatically in the location of the infrastructure agent configuration file in the pods created by the `newrelic-infrastructure` DaemonSet.

## Update to the latest version [#update]

### Using the automated installer [#update-installer]

To update a Kubernetes integration installed with the [automated installer](#installer), just run the installer again. It will always offer a manifest pointing to the last released version of the integration.

### Using helm [#update-helm]

See [Install the Kubernetes integration using Helm](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm#upgrade)

### Custom manifest [#update-custom-manifest]

If you are already running the Kubernetes integration and want to update the `newrelic-infra` agent to the [latest agent version](#logs-versions):

1. Run this [NRQL query](/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql) to check which version you are currently running (this will return the image name by cluster):

   ```
   SELECT latest(containerImage)  FROM K8sContainerSample 
   WHERE containerImage LIKE '<var>%newrelic/infrastructure%</var>' FACET clusterName SINCE 1 day ago
   ```

   If you've set a name other than `newrelic/infrastructure` for the integration's container image, the above query won't yield results: to make it work, edit the name in the query.
2. Download the integration manifest file:

   ```
   curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml
   ```
3. Copy the changes you made to the manifest. At a minimum, include `CLUSTER_NAME` and `NRIA_LICENSE_KEY`, and paste your changes in the manifest you downloaded.
4. Install the latest `DaemonSet` with the following command (Kubernetes will automatically do a rollout upgrade for the integration's pods):

   ```
   kubectl apply -f newrelic-infrastructure-k8s-latest.yaml
   ```

## Uninstall the Kubernetes integration [#uninstall]

To uninstall the Kubernetes integration:

1. Verify that `newrelic-infrastructure-k8s-latest.yaml` corresponds to the filename of the manifest as you have saved it.

   **Example:** If you are using the unprivileged version of the integration, the default filename will be `newrelic-infrastructure-k8s-unprivileged-latest.yaml`.
2. After you verify the filename, use the following command:

   ```
   kubectl delete -f newrelic-infrastructure-k8s-latest.yaml
   ```

You only need to execute this command once, regardless of the number of nodes in your cluster.
