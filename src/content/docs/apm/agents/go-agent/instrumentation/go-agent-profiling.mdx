---
title: Go agent profiling instrumentation
tags:
  - Agents
  - Go agent
  - Instrumentation
  - Profiling
metaDescription: For the New Relic Go language agent, you can get real-time application performance and resource profiling data to analyze
freshnessValidatedDate: never
---

## Estimating the cost of profiling data ingest [#profiling-ingest-cost]
Since running profiling data means sending a stream of data to New Relic during the course of your application's runtime, you may wish to consider how much data this will involve and make any necessary budgetary and network planning as a result. Since the amount of data that will actually be sent will vary based on your application, type(s) of profiles requested, and the sample frequency you selected, there is no one-size-fits-all answer we can give here, but we can offer some general advice for your consideration as you plan for your application.

Generally speaking, the profile samples will be larger for larger applications since they report the state of what's happening inside the code and include things like the program's call stack and heap memory allocation tables. If you have a particularly large program, then, each profile sample will be much larger than each sample of a small microservice component. In such a case, you might want to reduce the sample frequency to reduce data ingest amounts if too much data are being sent per minute for your needs and budget.

Each profiling type is also a different size since the data being collected are different. On one extreme end, CPU profiles have the lowest ingest impact over the full runtime of an application because they only report at the end of their total runtime instead of streaming throughout the runtime. On the other hand, heap profiles summarize memory allocations throughout the program's execution which may be substantial.

To cite a couple of examples, we ran a small sample program (our `examples/server` applcation in our Go Agent source repository), running heap memory profile samples every 500 mS for a few minutes to produce 416 samples reported to New Relic averaging 7,280.5 bytes each, or a total of 3 Mb of heap sample data for just under 3.5 minutes of runtime.

In another example, we ran the same sample program, collecting goroutine profile data while launching 10,000 goroutines with the same sample rate (500 mS). This generated 2,366 samples averaging 2,298 bytes each or a total of 5,437,248 bytes in just under 20 minutes.

While in our testing, the impact on the system resources of performing the profiling operations themselves for sample times in the typical range of 100 mS to 1 S was negligible, this is a subjective judgement which also depends greatly on the details of your application and the operational constraints of your environment. We recommend careful selection of your profiling parameters after a few trials in a test or staging environment to determine the settings that will provide reasonable sample sizes for you without causing loading issues on your system.
