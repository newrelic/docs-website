---
title: Kubernetes cross-cluster UI
tags:
  - Integrations
  - Kubernetes integration
  - Understand and use data
metaDescription: Explore and triage your entire fleet of clusters by using K8s cross-cluster UI
redirects:
  - /docs/integrations/kubernetes-integration/understand-use-data/kubernetes-cross-cluster
  - /docs/integrations/kubernetes-integration/cluster-explorer/kubernetes-cross-cluster
  - /docs/kubernetes-pixie/kubernetes-integration/understand-use-data
freshnessValidatedDate: never
---

<Callout title="preview">
  We're still working on this feature, but we'd love for you to try it out!

  This feature is currently provided as part of a preview program pursuant to our [pre-release policies](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy).
</Callout>


Modern Kubernetes environments have evolved into complex, **multi-cluster fleets**, but traditional observability tools often provide only a fractured, siloed view of individual clusters. This Kubernetes cross-cluster UI provides a unified command center that transforms this multi-cluster complexity into fleet-wide clarity.

This unified view helps Platform Engineers and SREs to:
* **Unify fleet-wide observability** on a single dashboard that's compatible with clusters monitored by New Relic agents or OpenTelemetry.
* **Accelerate root cause analysis** with a guided triage workflow.
* **Reduce costs** by identifying wasted resources across the entire fleet.
* **Empower developers** with an application-centric view for self-service.

<img
  title="K8s cross-cluster UI"
  alt="K8s cross-cluster UI"
  src="/images/k8s-cross-cluster.webp"
/>

## Access the new UI [#access]

You can access the new Kubernetes cross-cluster UI from the Kubernetes option in the left navigation in the New Relic platform.

To access the Kubernetes cross-cluster UI:

1. Go to <DNT>**[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Kubernetes**</DNT>
2. Click the **Try it out** button at the top right corner of the page.

  The Kubernetes cross-cluster UI is structured to provide both a high-level overview and deep-dive capabilities into your entire Kubernetes fleet. The main components of the UI include:

  * **Feedback button**: Lets you easily share feedback on your experience with the UI.
  * **Entity filters**: Filter and triage issues using **tags and values** at the **cluster or node level**.
      * **Cluster filter**: Filter to isolate the UI to a single or smaller set of Kubernetes clusters.
      * **Node filter**: Filter to isolate the UI to a single or smaller set of worker nodes (hosts).
  * **Colored scorecards**: Display relevant high-level metrics to surface the most important issues that need attention across the entire fleet.
      * Clicking a scorecard **orders the table** in the context of that metric, surfacing the clusters and nodes with the most critical issues at the top.
      * It also enables a **line chart** to visualize the metric's evolution over the selected time range.
  * **Line chart**: Provides the **evolution of the metric** over the selected time frame for trend analysis.
  * **Table**: Lists all entities in the fleet and provides **detailed metric data** for each cluster under the five main tabs.
      * **Health focus**: The table provides a filter to only list "unhealthy" entities to focus your attention where it is really needed.
      * **Search**: A text search bar allows you to filter table rows based on **free text** entered.
      * **Color-coding**: Like the scorecards, table cells are color-coded (Green, Yellow, Red) to quickly draw attention to entities with issues that meet a specific **severity threshold**.

## Drill-down capabilities for triage [#drill-down]

The cross-cluster UI is specifically designed to accelerate root cause analysis with a **guided triage workflow**. The primary mechanism for this deep investigation is the ability to drill down from a fleet-wide metric to a single cluster's view:

* **From scorecard to cluster ranking:** When you click a **colored scorecard** (e.g., Unhealthy Pods), the clusters table immediately re-sorts. This places the clusters with the worst performance for that specific metric at the top, enabling you to identify where the issue is most critical across your entire fleet.
* **From table metric to Kubernetes navigator:** Click a metric value within any cell of the table for a specific cluster or node to automatically launch the **Kubernetes navigator**. The navigator's view is automatically **predefined/filtered** for that specific cluster and metric of interest, allowing you to continue your investigation with a deep dive.

## Tab-specific metrics [#tab]

The UI is organized into five main tabs: 

* [Overview](#overview) 
* [Health](#health)
* [Performance](#performance)
* [Resources](#resources)
* [Workloads](#workloads)


Each tab provides specific metrics both at the aggregate (Scorecard) and cluster/node (Metric) level, along with their associated color-coded thresholds for quick triage.



<CollapserGroup>
  <Collapser
    id="overview"
    title="Overview tab"
  >


The **Overview** tab provides a general summary of the **operational health, capacity, and risk** across your entire Kubernetes fleet.



<table>
  <thead>
    <tr>
      <th>Metric name</th>
      <th>Scorecard explanation</th>
      <th>Metric explanation (cluster/node)</th>
      <th>Importance</th>
      <th>Thresholds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`Total Clusters`</td>
      <td>The total count of Kubernetes clusters currently reporting telemetry.</td>
      <td>N/A</td>
      <td>Verifies the connectivity and scope of your entire fleet monitoring estate.</td>
      <td>N/A</td>
    </tr>
    <tr>
      <td>`Unhealthy Nodes`</td>
      <td>Percentage of nodes in the fleet reporting `NotReady` or `Unknown`.</td>
      <td>Percentage of nodes in the specific cluster reporting `NotReady`.</td>
      <td>Signals widespread instability and potential zone failures across the infrastructure.</td>
      <td>`Fleet:` Green: 0%; Yellow: 1% to 5%; Red: 5%. `Cluster:` Yellow: 1% to 5%; Red: 5%.</td>
    </tr>
    <tr>
      <td>`Unhealthy Pods`</td>
      <td>Percentage of pods in the fleet in `Pending, Failed, or Unknown` states.</td>
      <td>Percentage of pods in the specific cluster in `Pending, Failed, or Unknown` states.</td>
      <td>Measures widespread application instability across all clusters.</td>
      <td>`Fleet:` Green: &lt; 1%; Yellow: 1% to 5%; Red: 5%. `Cluster:` Yellow: 1% to 5%; Red: 5%.</td>
    </tr>
    <tr>
      <td>`Unhealthy Workloads`</td>
      <td>Count of workloads (Deployments, Daemonset or Statefulsets) in the fleet with `missing replicas`.</td>
      <td>Count of workloads in the specific cluster with `missing replicas`.</td>
      <td>Indicates failure to reconcile desired states across the organization.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: 6. `Cluster:` Yellow: 1 to 3; Red: 4.</td>
    </tr>
    <tr>
      <td>`CPU Usage % (vs Total)`</td>
      <td>Percentage of total fleet CPU capacity currently consumed.</td>
      <td>Percentage of the specific cluster's CPU capacity currently consumed.</td>
      <td>Measures aggregate node saturation risk across the entire estate.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Memory Usage % (vs Total)`</td>
      <td>Percentage of total fleet memory capacity currently consumed.</td>
      <td>Percentage of the specific cluster's memory capacity currently consumed.</td>
      <td>High values indicate risk of aggregate eviction storms across clusters.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Alerts`</td>
      <td>Count of `active high-severity alerts` across the fleet.</td>
      <td>Count of `active high-severity alerts` for this specific cluster.</td>
      <td>Tracking active incidents that require operator intervention.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 10; Red: 11. `Cluster:` Yellow: 1 to 5; Red: 6.</td>
    </tr>
    <tr>
      <td>`Warning Events`</td>
      <td>Volume of `Warning type K8s cluster events` across the fleet.</td>
      <td>Volume of `Warning type K8s cluster events` in this cluster.</td>
      <td>High noise levels obscure critical alerts and indicate config debt.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 50; Red: 50. `Cluster:` Yellow: 1 to 20; Red: 21.</td>
    </tr>
  </tbody>
</table>

</Collapser>

  <Collapser
    id="health"
    title="Health tab"
  >


The **Health** tab focuses on metrics related to the **availability and current status** of your nodes and pods to detect immediate failure risks.



<table>
  <thead>
    <tr>
      <th>Metric name</th>
      <th>Scorecard explanation</th>
      <th>Metric explanation (cluster/node)</th>
      <th>Importance</th>
      <th>Thresholds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`Nodes Total`</td>
      <td>Total count of nodes detected in the fleet.</td>
      <td>Count of nodes in the specific cluster.</td>
      <td>Zero indicates fundamental control plane failure.</td>
      <td>Red: 0.</td>
    </tr>
    <tr>
      <td>`Nodes Ready`</td>
      <td>Percentage of nodes in the fleet reporting `Ready` status.</td>
      <td>Percentage of nodes in the cluster reporting `Ready` status.</td>
      <td>Availability metric; values below 95% signal severe fleet instability.</td>
      <td>`Fleet:` Green: 100%; Yellow: 95% to 99%; Red: &lt; 95%. `Cluster:` Yellow: 99%; Red: &lt; 99%.</td>
    </tr>
    <tr>
      <td>`Nodes Memory Pressure`</td>
      <td>Percentage of nodes in fleet rejecting pods due to `low memory`.</td>
      <td>Percentage of nodes in cluster rejecting pods due to `low memory` at cluster level.</td>
      <td>Predicts widespread eviction storms.</td>
      <td>`Fleet:` Green: 0%; Yellow: &gt;0% to 5%; Red: ≥ 6%. `Cluster:` Yellow: &gt;0% to &lt;1%; Red: ≥ 1%.</td>
    </tr>
    <tr>
      <td>`Nodes Disk Pressure`</td>
      <td>Percentage of nodes in fleet with `low disk availability`.</td>
      <td>Percentage of nodes in cluster with `low disk availability` at cluster level.</td>
      <td>Risk of widespread node failures due to disk exhaustion.</td>
      <td>`Fleet:` Green: 0%; Yellow: &gt;0% to 5%; Red: ≥ 6%. `Cluster:` Yellow: &gt;0% to &lt;1%; Red: ≥ 1%.</td>
    </tr>
    <tr>
      <td>`Pods Running`</td>
      <td>Percentage of fleet pods successfully in `Running` phase.</td>
      <td>Percentage of cluster pods successfully in `Running` phase.</td>
      <td>Operational success rate; &lt;90% indicates widespread failure.</td>
      <td>`Fleet:` Green: 95% to 100%; Yellow: 90% to 94%; Red: &lt; 90%. `Cluster:` Yellow: 95% to 99%; Red: &lt; 95%.</td>
    </tr>
    <tr>
      <td>`Pods Pending`</td>
      <td>Sustained count of pods `waiting to be scheduled` across fleet.</td>
      <td>Sustained count of pods `waiting to be scheduled`.</td>
      <td>Indicates scheduler failure or capacity starvation.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: ≥ 6. `Cluster:` Yellow: 1; Red: ≥ 2.</td>
    </tr>
    <tr>
      <td>`Container Restarts`</td>
      <td>Count of restarts `per period` across the fleet.</td>
      <td>Count of restarts `per period`.</td>
      <td>Symptom of CrashLoopBackOff or OOMKills.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: 6. `Cluster:` Yellow: 1; Red: 2.</td>
    </tr>
    <tr>
      <td>`Network Errors / sec`</td>
      <td>Rate of `packet drops/errors` across the fleet.</td>
      <td>Rate of `packet drops/errors`.</td>
      <td>Symptom of hardware failure or systemic CNI issues.</td>
      <td>`Fleet:` Green: &lt; 10; Yellow: 11 to 50; Red: &gt; 50. `Cluster:` Yellow: 5 to 10; Red: &gt; 11.</td>
    </tr>
  </tbody>
</table>

</Collapser>

  <Collapser
    id="performance"
    title="Performance tab"
  >


The **Performance** tab measures **utilization against total capacity and limits** to identify node saturation and risk of performance degradation.



<table>
  <thead>
    <tr>
      <th>Metric name</th>
      <th>Scorecard explanation</th>
      <th>Metric explanation (cluster/node)</th>
      <th>Importance</th>
      <th>Thresholds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`CPU Usage % vs Total`</td>
      <td>% of fleet `CPU capacity` used.</td>
      <td>% of cluster/node `CPU capacity` used.</td>
      <td>Measures saturation risk across the entire estate.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`CPU Usage % vs Limits`</td>
      <td>% of `CPU hard limits` consumed across fleet.</td>
      <td>% of `CPU hard limits` consumed in cluster.</td>
      <td>Measures proximity to throttling.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Memory Usage % vs Total`</td>
      <td>% of fleet `memory capacity` used across fleet.</td>
      <td>% of cluster/node `memory capacity` used.</td>
      <td>Proximity to eviction thresholds.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Memory Usage % vs Limits`</td>
      <td>% of `RAM hard limits` consumed across fleet.</td>
      <td>% of `RAM hard limits` consumed.</td>
      <td>Proximity to OOMKill events.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`FS Usage %`</td>
      <td>% of `disk capacity` consumed across fleet.</td>
      <td>% of `disk capacity` consumed.</td>
      <td>Critical to prevent Kubelet crashes.</td>
      <td>Yellow: 80% to 95%; Red: &gt; 95%.</td>
    </tr>
    <tr>
      <td>`Pods Capacity %`</td>
      <td>% of `max allowed pod count` scheduled across fleet.</td>
      <td>% of `max allowed pod count` scheduled.</td>
      <td>Measures resource density and slot exhaustion.</td>
      <td>`Fleet:` Green: 85%; Yellow: 85% to 100%; Red: 100%. `Cluster:` Yellow: 85% to 100%; Red: 100%.</td>
    </tr>
  </tbody>
</table>

</Collapser>

<Collapser
    id="resources"
    title="Resources tab"
  >


The **Resources** tab analyzes **Request vs. Usage and Request vs. Limits** to assess resource allocation efficiency and identify waste or sizing inaccuracies.


<table>
  <thead>
    <tr>
      <th>Metric name</th>
      <th>Scorecard explanation</th>
      <th>Metric explanation (cluster/node)</th>
      <th>Importance</th>
      <th>Thresholds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`CPU Usage % vs Request`</td>
      <td>% of `CPU usage vs requests` across fleet.</td>
      <td>% of `CPU usage vs requests`.</td>
      <td>Governance metric for sizing accuracy and waste.</td>
      <td>Yellow: &lt; 70% or &gt; 200%.</td>
    </tr>
    <tr>
      <td>`CPU Request % vs Limits`</td>
      <td>% of `CPU request vs limit` across fleet.</td>
      <td>% of `CPU request vs limit`.</td>
      <td>Measures performance headroom and burst capacity.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Memory Usage % vs Request`</td>
      <td>% of `memory usage to requests` across fleet.</td>
      <td>% of `memory usage to requests`.</td>
      <td>Governance metric for memory sizing accuracy.</td>
      <td>Yellow: &lt; 70% or &gt; 200%.</td>
    </tr>
    <tr>
      <td>`Memory Request % vs Limits`</td>
      <td>% of `limit reserved by requests` across fleet.</td>
      <td>% of `limit reserved by requests`.</td>
      <td>Helps to assess resource allocation efficiency and potential overprovisioning.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Pod Evictions`</td>
      <td>Count of `forced pod terminations by Kubelet` in fleet.</td>
      <td>Count of `forced pod terminations by Kubelet`.</td>
      <td>Symptom of node resource starvation.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: 6. `Cluster:` Yellow: 1; Red: 2.</td>
    </tr>
  </tbody>
</table>

</Collapser>

<Collapser
    id="workloads"
    title="Workloads tab"
  >


The **Workloads** tab provides an application-centric view, focusing on metrics such as **throttling, restarts, and missing replicas** to diagnose application instability and poor QoS.



<table>
  <thead>
    <tr>
      <th>Metric name</th>
      <th>Scorecard</th>
      <th>Metric (cluster/node)</th>
      <th>Importance</th>
      <th>Thresholds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`CPU Usage % vs Limits`</td>
      <td>% of `CPU hard limits` consumed by workloads.</td>
      <td>% of `CPU hard limits` consumed by specific workload.</td>
      <td>Measures performance cap proximity.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`CPU Throttling %`</td>
      <td>Ratio of `throttled time to active time` across fleet.</td>
      <td>Ratio of `throttled time to active time` for workload.</td>
      <td>Measures latency/lag caused by CFS quotas.</td>
      <td>`Fleet:` Green: &lt; 10%; Yellow: 10% to 50%; Red: 50%. `Workload:` Yellow: 10% to 50%; Red: 50%.</td>
    </tr>
    <tr>
      <td>`Memory Usage % vs Limits`</td>
      <td>% of `memory limits` consumed across workloads.</td>
      <td>% of `memory limits` consumed by specific workload.</td>
      <td>Proximity to OOMKill.</td>
      <td>Yellow: 75% to 95%; Red: 95-100%.</td>
    </tr>
    <tr>
      <td>`Network Errors / sec`</td>
      <td>Error rate on `network interfaces` across fleet.</td>
      <td>Error rate on `network interfaces` for workload.</td>
      <td>Signals application failure or connectivity loss.</td>
      <td>`Fleet:` Green: varies (near 0); Yellow: ≤ 10; Red: ≥ 51. `Workload:` Green: ≤ 2; Yellow: 3 to 15; Red: &gt; 15.</td>
    </tr>
    <tr>
      <td>`Pods Total`</td>
      <td>Total count of pods in fleet workloads.</td>
      <td>Total count of pods for specific workload.</td>
      <td>Baseline metric for capacity.</td>
      <td>Red: 0.</td>
    </tr>
    <tr>
      <td>`Pods Missing`</td>
      <td>Gap between `desired and ready replicas` in fleet.</td>
      <td>Gap between `desired and ready replicas` for workload.</td>
      <td>Indicates service degradation.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: 6. `Workload:` Yellow: 1; Red: 2.</td>
    </tr>
    <tr>
      <td>`Pod Evictions`</td>
      <td>Count of `evictions` for workloads in fleet.</td>
      <td>Count of `evictions` for specific workload.</td>
      <td>Workload is causing node pressure or misconfigured.</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: 6. `Workload:` Yellow: 1; Red: 2.</td>
    </tr>
    <tr>
      <td>`Container Restarts`</td>
      <td>Count of `restarts` for workloads in fleet.</td>
      <td>Count of `restarts` for specific workload.</td>
      <td>Persistent failure state (CrashLoopBackOff).</td>
      <td>`Fleet:` Green: 0; Yellow: 1 to 5; Red: 6. `Workload:` Yellow: 1; Red: 2.</td>
    </tr>
    <tr>
      <td>`Container Images Restarting`</td>
      <td>Restarts caused by `image/config errors` in fleet.</td>
      <td>Restarts caused by `image/config errors` for workload.</td>
      <td>Specific symptom of registry failure or bad tags.</td>
      <td>`Fleet:` Green: 0; Yellow: 1; Red: 2. `Workload:` Yellow: 1; Red: 2.</td>
    </tr>
  </tbody>
</table>

</Collapser>

</CollapserGroup>
