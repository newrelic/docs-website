---
title: Manage your Auto-telemetry with Pixie data ingest
tags:
  - Pixie Auto-telemetry
  - lowdatamode
  - low data mode
  - reduce ingest
  - Kubernetes pods
  - Kubernetes
  - manage Pixie data
metaDescription: 
redirects:
  - /docs/auto-telemetry-pixie/manage-pixie-data
---

You have options for the type and the amount of data you ingest when you install Auto-telemetry with Pixie. During install, use Helm to reduce or exclude data, either by excluding specific namespaces or pods, or by collecting data for only the nodes you want.

## Exclude namespaces and pods [#reduce-ingest-helm]

If you want to reduce the amount of Pixie data that New Relic ingests, you can exclude namespaces or pods by adding the following parameters to your Helm chart during installation. Note that the data still exists in Pixie:

  * `excludeNamespacesRegex` - use to identify the namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all namespaces is sent to New Relic. For example: 
  
  ```
  --set newrelic-pixie.excludeNamespacesRegex="examplenamespace-1|examplenamespace-2"
  ```
  * `excludePodsRegex` - use to identify pods across all namespaces that you want to exclude from sending observability data to New Relic. If empty, data for all pods (except those in excluded namespaces) is sent to New Relic. For example: 
  
  ```
  --set newrelic-pixie.excludePodsRegex="examplepod-1|examplepod-2"
  ```
  
These two configuration options provide additional control over the `Metric` and `Span` data sent to New Relic from Pixie.  
  
For example, if you wanted to configure the `newrelic-pixie` integration to exclude all namespaces except for `px-sock-shop` and `kafka-demo`, append the following config parameter to your Helm install or Helm upgrade command. 

```
  --set newrelic-pixie.excludeNamespacesRegex="default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator"
```

Or, if you wanted to exclude pods running in a non-excluded namespace, you could add another configuration parameter to your Helm install or Helm upgrade. Instead of matching exact names, you can use a simple regex to match pod names related to load testing, just as an example. 

```

--set newrelic-pixie.excludePodsRegex="load-test.*|loadgen.*"

```
  
If you're performing a brand new install, you'll need to append `excludeNamespacesRegex` and `excludePodsRegex` to the `helm upgrade --install` command provided by New Relic's guided install:

```
kubectl apply -f https://raw.githubusercontent.com/pixie-labs/pixie/main/k8s/operator/crd/base/px.dev_viziers.yaml && \
kubectl apply -f https://raw.githubusercontent.com/pixie-labs/pixie/main/k8s/operator/helm/crds/olm_crd.yaml && \
helm repo add newrelic https://helm-charts.newrelic.com && helm repo update && \
kubectl create namespace newrelic ; helm upgrade --install newrelic-bundle newrelic/nri-bundle \
 --set global.licenseKey=<NR LICENSE KEY> \
 --set global.cluster=pixie-auto-telemetry \
 --namespace=newrelic \
 --set newrelic-infrastructure.privileged=true \
 --set ksm.enabled=true \
 --set prometheus.enabled=true \
 --set kubeEvents.enabled=true \
 --set logging.enabled=true \
 --set newrelic-pixie.enabled=true \
 --set newrelic-pixie.apiKey=<PIXIE API KEY> \
 --set pixie-chart.enabled=true \
 --set pixie-chart.deployKey=<PIXIE DEPLOY KEY> \
 --set pixie-chart.clusterName=pixie-auto-telemetry \
 --set newrelic-pixie.excludeNamespacesRegex="default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator" \ 
 --set newrelic-pixie.excludePodsRegex="load-test.*|loadgen.*"
```

If you're just upgrading an existing install, then this is a much simpler approach:

```
helm upgrade newrelic-bundle newrelic/nri-bundle --reuse-values -n newrelic --set newrelic-pixie.excludeNamespacesRegex="default|kube-node-lease|kube-public|kube-system|newrelic|newrelic-custom-metrics|olm|px-operator
```

Learn more about the available parameters for the `newrelic-pixie` Helm chart [here](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-pixie#chart-details).



## Use Kubernetes features to collect selected data [#selected-data]

When you deploy Auto-telemetry with Pixie, you're actually enabling the Auto-telemetry with Pixie Helm chart, as well as other New Relic components included in the New Relic infrastructure bundle. The [Pixie Edge Module (PEM)](https://docs.pixielabs.ai/tutorials/custom-data/distributed-bpftrace-deployment#background) pods are deployed to the cluster as a Kubernetes DaemonSet. This means that by default, a pod is scheduled to every cluster node and is responsible for collecting all of the observability metrics for that node.

In Kubernetes, you can assign pods to a specific subset of cluster nodes using nodeSelectors, taints/tolerations, and node affinity/anti-affinity. That way, you'll only collect metrics for the nodes you choose, instead of every node. This is helpful if you only want to deploy Auto-telemetry with Pixie to five of your ten cluster nodes, for example. Maybe the designated five nodes are responsible for high-priority workloads, or perhaps you're running both Linux and Windows nodes in your cluster and only want to deploy on the Linux nodes, since Windows nodes are not currently supported. You can now assign pods to a subset of nodes by providing an additional option to the guided installation command. This option passes an escaped JSON string to the Auto-telemetry with Pixie chart, which enables a `nodeSelector` that only schedules the PEM DaemonSet on nodes with the label `pixie=allowed`.

```
--set pixie-chart.patches.vizier-pem='\{\"spec\"\: \{\"template\"\: \{\"spec\"\: \{ \"nodeSelector\"\: \{\"pixie\"\: \"allowed\" \}\}\}\}\}'
```

If you're using a values file, common with Helm, then this is what that would look like in the `nri-bundle values.yaml`:

```
pixie-chart:
 enabled: true
 patches:
    vizier-pem: '{"spec": {"template": {"spec": { "nodeSelector": {"pixie": "allowed" }}}}}'

```

This approach gives you a multitude of configuration options; you just need to stick with the standard Kubernetes spec.


