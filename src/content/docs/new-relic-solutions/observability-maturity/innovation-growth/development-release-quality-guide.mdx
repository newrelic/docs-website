---
title: "Release quality management: Optimize your deployment cadence and quality" 
tags:
  - Observability maturity
  - Innovation and growth
  - Release quality
  - Implementation guide
metaDescription: "Our release quality guide helps you use New Relic to improve and optimize the quality and cadence of your code deployments."
redirects: 
  - /docs/new-relic-solutions/observability-maturity/innovation-growth/release-quality-implementation-guide
---

This guide walks you through establishing KPIs and using New Relic to improve and optimize the quality and cadence of your code deployments. It's part of our [series on observability maturity](/docs/new-relic-solutions/observability-maturity/introduction). 

## Overview [#overview]

A development team is ultimately measured by the frequency and success of their releases. Teams that release too slowly won't be able to keep pace with business demands and innovation. Teams that create too many unsuccessful releases will have a negative impact on customer satisfaction, revenue, and overall system stability.

Google's [DevOps Research and Assessment](https://www.devops-research.com/research.html) (DORA) team has identified four key metrics that indicate the performance of a software development organization. Our **Innovation and Growth** value driver uses those metrics to create an overall program that drives more efficient and responsive development teams, along with more reliable and performant applications. This **Release quality** (RelQual) guide contributes to that program by driving deployment frequency, application performance, and application reliablity.

## Desired outcome [#desired-outcome]

You will use this **Release Quality** guide's processes to increase the frequency of deployments while reducing their size and scope. This will result in a faster time for an idea to be implemented in production code, while also reducing the impact (or blast radius) of software defects.

In addition, the RelQual process will be used to identify performance bottlenecks and sources of errors and feed them back into the development process so they can be resolved. This will increase reliability and customer satisfaction, while driving down infrastructure costs.

RelQual's overall goal is to create a continuous cycle of performance improvement and to drive a pattern of more releases with fewer changes. By doing this, you'll reduce the risks to business reputation and earnings and increase application performance and reliability.

## Key concepts [#key-concepts]

Kep concepts include: 

### Communicate, remediate, innovate [#communicate]

One of the central themes of New Relic's observability maturity practice is "Communicate, remediate, innovate." RelQual supports that theme by enabling you to communicate the current state of your development practices and applications to stakeholders using specific KPIs. You will then use those KPIs to adjust your development practices and to identfy slow and unreliable application components so they can be fixed in subsequent development sprints. Finally, you will use those KPIs to acclerate your development practices, thus adding additional time to innovate.

### Trunk-based development [#trunk]

Trunk-based development is a practice identified by the DevOps Research and Assessment (DORA) organization as a key capability that drives faster delivery and higher organizational performance. It's a required practice for CI/CD.

In short, trunk-based development divides development work into small batches which are performed against branches of a single trunk. As soon as the batch of work is completed, the branch is merged back into the trunk. Each branch is expected to have a short lifetime, thus making merges back into the trunk simple and ensuring every developer is working from a recent release of the code base.

RelQual drives the adoption of this DevOps best practice and ensures that you adhere to it. By doing so, you will accelerate the delivery of code into production.

### IT service boundary [#it-boundary]

The RelQual use case works at the level of the IT service boundary. By measuring the service at the boundary, we get a picture of what's happening upstream from it.

As you may have seen, the [service level management guide](/docs/new-relic-solutions/observability-maturity/uptime-performance-reliability/slm-implementation-guide) in our **Observability maturity** series uses the service boundary concept to measure the response time and error rate of the service and its dependencies. RelQual uses the same concept to measure the impact that your development practices have on the service and then to improve your development team's responsiveness, ability to innovate, and application stability as the IT service evolves.

## Key performance indicators [#key-perf-indicators]

You'll use the development quality process to collect and measure the following KPIs:
* Release rate
* Release size/scope
* App responsiveness and error rate
* Production impact
* Support ticket volume
* Infrastructure costs
* Observability coverage

Detailed information on each metric follows.

<CollapserGroup>
  <Collapser
    id="kpi-release-rate"
    title="Release rate KPI"
  >
Release rate measures the number of releases over time. Release events should include the following attributes:
* The application's name
* The release's unique identiifer (SHA signature, version number, etc.)
* The number of lines of code added
* The number of lines of code removed
* The date and time the release occurred
* The user or process that deployed the release
* The URL that points at this release in the source code repository
* An indicator that shows if this release is new or a rollback

**Goal:** Increase the rate of releases.

**Best practices:**
* Use continuous improvement processes to drive a higher release rate.
* Minimize the number of changes in each release to reduce the impact of release failures.
* Map this KPI back to business impact and report it to stakeholders.
  </Collapser>

  <Collapser
    id="kpi-release-size-scope"
    title="Release size/scope KPI"
  >
Release size/scope measures the number of lines of code added or removed. As an alternative, it can measure the percentage of the code base changed.

This KPI should be included as an attribute of a release event as defined by the Release rate KPI.

**Goal:** Reduce the size/scope of each release.

**Best practices:**
* Minimize the number of changes in each release to reduce the impact of release failures.
* Map this KPI back to business impact and report it to stakeholders.
  </Collapser>

  <Collapser
    id="kpi-app-resp-errors"
    title="App transaction responsiveness and errors KPI"
  >
The app responsiveness and errors KPI measures the release's 95th percentile response time and volume of errors.

You should use observability instrumentation to collect this KPI for every transaction at the application's service boundary. The KPI's attributes should, at minimum, include the following:
* Transaction name and/or URI
* The transaction's start wall clock time
* The transaction's duration
* The compute resource that serviced the request

**Goal:** Improve response time and reduce errors.

**Best practices:**
* Use service level management techniques to create more responsive applications with fewer user-facing errors.
* Use this KPI to prioritize engineering's performance enhancement efforts.
* Use your observability solution to feed back information on bottlenecks and blame components to your development teams so they can fix them.
  </Collapser>

  <Collapser
    id="kpi-production-impact"
    title="Production impact KPI"
  >
Production impact measures the number of failed releases (such as releases that were rolled back or failed to deploy).

This KPI should be included as an attribute of a release event as defined by the release rate KPI.

**Goal:** Reduce the number of failed releases.

**Best practices:**
* Ensure you realistically test your deployments in non-production environments prior to moving them to production.
* Perform in-depth retrospectives on failed deployments so you can discover and fix gaps in your testing and deployment processes.
  </Collapser>

  <Collapser
    id="kpi-observability-coverage"
    title="Observability coverage KPI"
  >
This KPI measures the percentage of the application that has observability instrumentation.

**Goal:** 100% coverage

**Best practices:**
* Add diagnostic instrumentation to the application's main components.
* Use SLO attainment failures to drive diagnostic processes to identify and fill observabilty gaps.
* Use incident retrospectives to identify and fill observability gaps.
  </Collapser>

  <Collapser
    id="kpi-support-ticket-volume"
    title="Support ticket volume KPI (optional)"
  >
Support ticket volume measures the number of support tickets opened against this release. This is an optional KPI.

This KPI should be collected as an hourly or daily metric which has the following attributes:
* Application name and release
* Timestamp
* Number of tickets opened by severity
* Mean time to close by severity

**Goal:** Reduce the number of tickets.

**Best practices:**
* Ensure support tickets can be correlated against specific releases.
* Analyze support tickets to understand the kinds of issues encountered, and use that info to drive continuous improvement.
  </Collapser>

  <Collapser
    id="kpi-infra-costs"
    title="Infrastructure cost KPI (optional)"
  >
This KPI measures the application's hosting costs. It is an optional KPI.

**Goal:** Create a predictable and stable cost model.

**Best practices:**
* Measure the costs of each application's hosting infrastructure.
* Periodically review the application's performance vs. cost metrics to ensure the application has resources appropriate to its function and business importance.
  </Collapser>
</CollapserGroup>

## Prerequisites [#prerequisites]

Before you begin, if you don't have equivalent experience, you should complete the [New Relic University (NRU) Overview Course](https://learn.newrelic.com/overview-course). You should also have a basic understanding of:
* [New Relic platform fundamentals](https://learn.newrelic.com/fundamentals-course)
* [Introduction to instrumentation](https://learn.newrelic.com/self-paced-intro-to-instrumentation-with-new-relic)
* [New Relic dashboards and NRQL](https://learn.newrelic.com/webinar-getting-started-with-dashboards-nrql)

## Establish current state of your KPIs [#current-state]

As with any continuous improvement process, the first step of RelQual is to establish the current state of your KPIs. To do so, you'll perform the following tasks:
* [Identify the application](#identify-application)
* [Gather the required KPIs](#gather-kpis)
* [Implement the RelQual dashboards](#implement-dashboards)
* [Establish a baseline](#establish-baseline)
* [Perform initial enablement](#perform-enablement-one)
* [Start continuous improvement process](#start-continuous-improvement)

These are explained in more detail below. 

### Identify the application [#identify-application]

The first step is for you to identify the application or applications that are in-scope for the first iterations of the RelQual process. Applications that are good candidates for inclusion in the RelQual process are ones that:
* Are under active development
* Are a key operational service
* Have slow development cycles
* Have a track record of failed deployments

### Gather the required KPIs [#gather-kpis]

The success of the release quality use case is highly dependent on its key performance indicators. We need to start by ensuring we gather the KPIs as defined from definitive sources such as your CI/CD platform, source repository, observability solution, etc. Once you identify the sources for your KPIs, you will need to identify methods for extracting them and importing them into the New Relic platform.

The KPIs and minimum required attributes required by this use case are listed in the [key performance indicators](#key-perf-indicators) section. Typically, you'll use your development toolchain's APIs to extract the KPIs and their attributes and then submit them to New Relic using the [custom events API](/docs/data-apis/ingest-apis/introduction-event-api/).

Prior to starting any custom integration work, you should determine if any out-of-box integrations exist that meet your goals.

### Implement the RelQual dashboards [#implement-dashboards]

The RelQual <InlinePopover type="dashboards" /> are the primary drivers of the quality improvement process. They'll show KPIs and trends so you can identify and prioritize your improvement efforts.

Sample RelQual dashboards can be [found in our observability maturity resource center on GitHub](https://github.com/newrelic/oma-resource-center).

Some of the information you present in the dashboards is dependent on your development toolchain, so your dashboard may need to be modified from the sample.

### Establish a baseline [#establish-baseline]

The RelQual process requires a baseline so you can [perform the initial enablement](#perform-enablement-one). Your baseline should include a representative sample of your release activity. This should include at least one complete release cycle, but may require more cycles to get a valid baseline.

Your baseline collection and evaluation cycle should be aligned with your Agile sprints, and you should periodically ensure that RelQual event data is accumulating as expected.

### Perform initial enablement [#perform-enablement-one]

In this stage, you'll introduce development teams and other stakeholders to the baseline RelQual data and the ongoing continuous improvement process you will be following.

The process consists of four activities:
1. **Introduce the concepts of trunk-based development.** You and the stakeholders will review the core concepts of truck-based development, identify where your current practices differ, and then create strategies to implement it.
2. **Review your release KPIs and trends.** You'll review the release rate and release size/scope KPIs to ensure you're making progress towards implementing trunk-based development. Your goal is to increase your release rate while reducing the size/scope of new releases.
3. **Review your application KPIs and trends.** Here, you'll review your application's performance and error KPIs to identify and prioritize your efforts towards improving application reliability and performance.
4. **Make technical recommendations.** Here, you and the relevant stakeholders will identify and review technical recommendations, such as making changes to your release workflows or observability strategies.

You can use the [session template presentation](https://docs.google.com/presentation/d/1FflqMMVejwn6HMjEni8igZh6UR0a3_JbuMcS5xlZiJU/edit?usp=sharing) to keep this part of the RelQual process organized.

## Improvement process [#improvement-process]

This is the ongoing phase of the continuous improvement process. During this phase you'll repeat [the initial enablement steps](#perform-enablement-one) to review your progress against your baseline and adjust your strategies and tactics so you deliver the required positive business outcome.

Each cycle of the improvment process should occur after several iterations of your release process. As an alternative, you can schedule evaluations at the mid-point and end of each Agile sprint.

During this phase you should:
* Report your KPIs to upper management to ensure that the stakeholder teams are appropriately prioritizing the work, and to show that progress towards the promised business outcomes are being reached.
* Record and retain your weekly KPIs over periods of months to years to establish a baseline and to show the rate of improvement.

You should keep in mind that this is a continuous improvment process. You'll continue to collect and evaluate the KPIs over the long-term to ensure you're meeting your RelQual goals.

## Value realization [#value-realization]

Once your implementation of the RelQual process becomes mature, you'll see a reduction in the business and technical risks associated with application deployments and improved application performance. This will result in improvements to customer satisfaction, reduced overhead costs, and an improvement in earnings potential.

If you haven't already done it, we also recommend reviewing and using the [Development quality guide](/docs/new-relic-solutions/observability-maturity/innovation-growth/development-quality-implementation-guide).  
