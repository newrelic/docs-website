---
title: Observability as Code implementation guide
tags:
  - Observability as Code
  - Automation
  - Workflow
  - Implementation guide
---

import img_oac_env_maturity from 'images/oac-env-maturity.png';
import img_oac_team_based_access from 'images/oac-team-based-access.png';
import img_oac_tf_workflow from 'images/oac-tf-workflow.png';
import img_oac_config_drift from 'images/oac-config-drift.png';

## Overview [#overview]
Observability as Code is a term best used to describe methods of automating the configuration of New Relic's Observability Platform to drive maximum value from the telemetry data captured, in a consistent, controlled and automated way.
Why should you adopt Observability as Code?

As your infrastructure, application and service technologies evolve, their scale and complexity increase, increasing the volume of data collected from instrumentation tools (including New Relic), and the challenge associated with making sense of the data, bringing it into context, and driving actions off the back of it.

Using Observability as Code to automate the configuration of New Relic addresses this challenge, helping organisations to accelerate adoption, improve stability and drive better governance.

This guide provides guidance on how to approach implementing Observability as Code, offers good practice advice and reference examples to enable you to build and maintain your New Relic platform at speed and at scale.

It leverages automation workflows and provisioning tools to allow organisations to scale observability best practices, whilst reducing manual effort and improving service delivery. Delivering real value to both an IT organization itself and the businesses they support.

## Desired outcomes [#desired-outcomes]
Reducing the costs and risks associated with implementing and maintaining an optimally configured observability solution in rapidly changing and large scale environments.

Specifically, some of the benefits of adopting Observability as Code practices are:

* #### Repeatable, replicable, reusable
Managing New Relic resources through code means that they can easily be repeated, scaled and updated in bulk. Leveraging a modular approach with provisioning tools like terraform allow packaged sets of resources such as dashboards, alerts and workloads to be quickly and easily shared and deployed, accelerating startup time and improving organization wide standards.    
  
* #### Reduced toil
The toil of creating and maintaining New Relic resources managed through code is significantly less than manually managing them via the user interface, especially when working at scale. Whilst the interface lends itself well to discovery and testing, changes to code-managed resources can be bulk applied vastly reducing the time administering the resources. One common approach is to develop alerts and dashboards within the user interface and then when considered mature enough they are then migrated to code-managed resources.  

* #### Documentation and context
The huge variety of resources that can be configured in New Relic may make it difficult to understand just by looking at a single resource why it has been created or configured as it has. Configuration via code allows for commenting and documentation to be included that helps explain why certain choices may have been made, when and by whom.    

* #### Auditable history
 Whilst it is possible to understand who made changes to New Relic resources via the NRAuditEvent event type this does not provide much background as to *why* the changes were made, what their previous state was or who approved the changes to be made. Managing resources via code in tandem with an automated approval based provisioning workflow allows for much clearer visibility of changes and improved governance whilst also providing methods for rollback and recovery.
    
* #### Security
Observability as code allows for stricter controls over the use of API keys for managing New Relic resources. Security is improved by reducing the number of API keys in circulation and ensuring adequate governance is in place  concerning their creation and dissemination. Dissuading users from using their own keys, especially within automated workflows, means the surface area for a key breach or unintended corruption is reduced.  

* #### Efficient, delta changes
Provisioning tools like Terraform make it possible to make delta changes to existing resources. This makes updates quick and efficient as only resources attributes that need changing are changed, with minimal resource destruction and re-creation. This is important as it ensures that the GUIDs of resources such as dashboards and alerts are not changed on update.    

* #### React to external stimuli
Combining Observability as code with automated workflows allows for New Relic resources to be created and amended as a result of external stimuli such as application deployments, infrastructure events or any other data input. For example, you could automatically generate dashboards and alerts that compare key golden signal metrics between code version releases at deployment time.    

* #### Contextual ownership and packaging
Managing resources in code allows for related resources to be managed together. It's easier to comprehend and manage them in one place, in code, than it is when distributed across the user interface. For instance, this allows different teams to manage, view and maintain the resources within their sphere of influence and not have to hunt for  resources they manage.    

* #### Disaster recovery
Occasionally mistakes happen, the wrong resource is updated or deleted. Recovering from these situations with manual resource management is difficult as it's not easy to know what existed before or even if the resource has been changed or lost at all. Observability as code helps protect from these issues by ensuring that any resource can be recreated or reset to the expected configuration. It also creates an opportunity to proactively detect configuration drift.    

* #### Speed of deployment
Observability as code accelerates the speed of deployment by allowing for a common set of resources to be easily shared amongst teams and used to bootstrap observability tooling. This is particularly evident in micro-service architectures where similar application deployment architectures benefit from cookie-cutter module-based New Relic resources. Creating reusable centrally managed modules also helps to standardize common approaches to observability tooling.    

## Key performance indicators [#key-performance-indicators]
The maturity of your Observability as Code deployment can be evaluated in a number of ways. Generally the more resources within an environment that are managed via code the more mature the deployment.

<CollapserGroup>

    <Collapser
        id="resources-managed-kpi"
        title="Ratio of resources managed through code"
    > 

    <img
    src={img_oac_env_maturity}
    title="Environment maturity"
    alt="Percentage of code driven configuration increases with environment maturity"
    />
    <figcaption>
    This diagram illustrates how the percentage of resources managed with code may increase toward production environments.
    </figcaption>


    ### Calculate managed resources
    The proportion of resources managed through code can be used as an indicator of maturity. This KPI can be used to compare the maturity of different environments and also to track over time the progress of your Observability as Code maturity journey.

    First you should decide which resources and at what granularity to include in your calculation. 

    For example, some resources such as alert policies are composed of multiple sub resources (alert conditions). You may want to consider counting just the number of policies or you may choose to go a level deeper and also count the conditions too.

    Once you have decided which resources to include in your KPI you need to identify how many of those resources are managed by code and how many are not.

    You can then calculate the KPI with the following formula:

    Percentage OaC Resource KPI  = (resources_code_managed/(resources_code_managed + resources_not_code_managed)) * 100

    For example:

    |Resource type|Code Managed|Not Code managed|KPI|
    |---|---|---|---|
    |Dashboards|20|13|60%|
    |Alert Policies|10|20|33%|
    |Workloads|5|3|63%|
    |Synthetic Journeys|14|5|74%|
    |**Total**|**49**|**41**|**54%**|

    ### Environment maturity
    It's a familiar pattern for entities from different environments to be instrumented and report to different New Relic accounts. For instance, your production stack might report to a production account, and non-production to another. The ratio of resources provisioned with code compared to those manually provisioned should be higher the closer an environment is to production. Some customers choose to restrict manual access to production environments entirely, enforcing auditable, managed code changes to production configurations.
</Collapser>
</CollapserGroup>

<CollapserGroup>
    <Collapser
        id="shared-resources-kpi"
        title="Ratio of resources managed via shared resources"
    > 
    One of the benefits of adopting Observability as Code is the ability to publish and share configuration easily amongst teams. Building and sharing modules that package up multiple resources in a consistent and standardised manner allows teams to accelerate their deployment, reduce toil and maintain quality. A mature Observability as Code deployment will have a higher ratio of resources that are managed with centralised shared modules.

    ### Calculate shared resources
    Calculating this KPI requires you to know how many of the resources that are managed are by code are provisioned as a result of a shared module. You can make resource deployed via shared modules more easy to identify by ensuring they are well tagged.

    Shared resources KPI = number of resources deployed via shared modules / total number of code managed resources
    </Collapser>
</CollapserGroup>

<CollapserGroup>
    <Collapser
        id="trigger-kpi"
        title="Automatic provisioning based on triggers"
    > 
    Observability as Code offers opportunities to innovate by deploying configuration that is automatically provisioned based on triggers. For example you may automatically provision a dashboard and alert package when a new version of an application is deployed or when a new product is released. A mature Observability as Code deployment will exhibit some of these innovations.

    ### Calculate trigger based provisioning
    There are two KPI's you might consider tracking for trigger based provisioning: 

    - **Number and scale of triggers configured:** This KPI allows you to identify which accounts contain trigger-provisioned resources. You may consider counting the number of *resources* managed by the triggers in addition to a count of individual triggers that have been configured.

    - **Number of invocations of each trigger:** This KPI lets you track how often your triggers are used and helps you identify redundant or significantly noisy triggers
    </Collapser>
</CollapserGroup>

<CollapserGroup>
    <Collapser
        id="calculating-config-drift-kpi"
        title="Configuration drift"
    > 
    Tracking the frequency and scale of configuration drift allows you to evaluate the stability and quality of your Observability pipeline and resources. You can use this KPI to identify those resources that may need need refining and improving.

    ### Calculate configuration drift
    You can calculate a KPI for configuration drift by recording the number of occurrences the configuration drift has been identified. Tracking this over time helps you evaluate how effective your environmental maturity strategy is and discover which resources might need refining.
    </Collapser>
</CollapserGroup>

## Prerequisites [#prerequisites]
Before embarking on Observability as Code with New Relic you should get acquainted with New Relic fundamentals available from [New Relic University](https://learn.newrelic.com/)

You should also:
- Choose and have familiarity with provisioning tool such as Terraform
- Have access to a CI/CD platform that supports automation workflows
- Be familiar with the New Relic platform and API features
- Have determined a a tagging and naming convention or strategy for resources
- Decide on the asset granularity strategy for determining KPIs
- Prepared service account API keys and permissions model for applying changes from CI/CD tools


## Establish current state [#establish-current-state]
Before embarking on adopting Observability as Code practices you should evaluate the current state. You can leverage the maturity assessment concepts discussed above to determine how mature your environments and prioritise which environments to tackle first.

## Improvement process [#improvement-process]
You have decided to adopt Observability as Code with New Relic but are unsure how to get started or you want to avoid common dead ends and bear traps. Here we provide guides on good practice, advice and reference examples to help you confidently adopt Observability as Code.

### Team based resource isolation  [#team-based-resources]
Many teams may be involved in managing resources within a single, or across multiple, New Relic accounts. Observability as Code provides a way to more tightly control the isolation, access and management of resources. Restricting write access to individuals and enforcing changes to be made via managed code allows teams to safely work within the same space without risking affecting each others resources. 

For example, you may have a shared infrastructure team that manages cloud infrastructure on behalf of multiple application teams who each monitor their applications in different New Relic accounts. This shared infrastructure team would manage their own New Relic resources within these accounts alongside the application teams own resources. Restricting user write access and ensuring key resources are only managed via Observability as Code workflows allows the resources from the teams to live together in harmony and reduces the possibly of unauthorized or unintentional change.

<img
  src={img_oac_team_based_access}
  title="Team based resource isolation permission model"
  alt="Team based resource isolation permission model"
/>
<figcaption>
  This diagram illustrates how CI/CD pipelines for different teams may have access to manage isolated resources in multiple overlapping accounts.
</figcaption>

### API keys
Managing resources using the NerdGraph graphQL API or via provisioning tools such as terraform requires the use of [user API keys](/docs/apis/intro-apis/new-relic-api-keys/). New Relic API keys are generated against a user and inherit the permissions of that user. 

### Service accounts
Creating API keys against real human users can cause issues to automated pipelines. For example if that user's permissions change as part of a team move or the user leaves the organization an automation pipeline that relies upon it could fail. 

Consider creating "service account" users that are managed by a central management team that are specifically created for  automation purposes. These teams can then generate and manage API keys for dissemination to other implementing teams. Service accounts can be used to generate multiple API keys ensuring that implementing teams only use their own key. Keys managed in this way are more easily audited and help ensure that permissions are set correctly and remain stable. Individuals should be encouraged not to use their own API keys except for development and testing.

### Automated API key generation
API Keys can be generated via [NerdGraph](/docs/apis/nerdgraph/examples/use-nerdgraph-manage-license-keys-user-keys) allowing for fully automated on-demand API key provisioning. This could be used to automate generation of keys via a portal or service process flow. 

## Automation tools
We recommend using [Terraform](https://www.terraform.io) to manage the provisioning of your New Relic resources. Tools like Terraform allow you to configure resources in code without having to concern yourself with which API's to call or how to maintain a record of what has been created. 

New Relic actively maintains our own [New Relic Terraform provider](https://registry.terraform.io/providers/newrelic/newrelic/latest/docs). Features and issues can be raised on the open source [Github repository](https://github.com/newrelic/terraform-provider-newrelic/issues).

### State management
When managing New Relic resources with Terraform it's important to keep a stable record of the terraform state. Ideally state should be securely stored in a [remote location](https://www.terraform.io/language/state/remote), be version controlled and leverage [state locking](https://www.terraform.io/language/state/locking) in order to ensure stability. 

### Identify managed resources
It is important that you are able to easily identify resources in New Relic that are code managed. This makes it possible not only to evaluate the maturity KPI but also helps users interacting with the UI to understand which resources are code managed and therefore should not be changed manually. 

It is good practice to develop a consistent and prferable organization wide standard for tagging and naming resources that are managed in code. At the very least you should tag and identify that a resource is code managed. For example, you could add the tag `codeManaged=true` and perhaps a suffix or prefix to the resource name, e.g. "Database Perfromance Summary [CM]" to help identify them. Additionally you should consider tagging resources with further useful infomration such as the owning team, the source of the resource or code version for example.

### Dealing with large resource sets
Every resource configured in Terraform needs to be refreshed and evaluated to look for changes when new configurations are applied. As the size of configuration grows the list of resources to check against increases. Each check requires an API call and so large configurations may take some time to complete and may encounter API limits if too many requests are made in parallel. One approach is to reduce the number of resources managed within a single state, breaking down the configuration into parts. Also reducing the [parallelism of Terraform requests](https://www.terraform.io/cli/commands/apply#parallelism-n) can alleviate API limiting. 

### Take a modular approach
Modules are the main way to package and reuse resource configurations with Terraform and can be leveraged to package together any number of New Relic resources. Packaging like this allows for parameter driven deployments. For example, you may have a module that takes an application name and builds an overview dashboard, golden signal alerts and synthetic journey all in one operation.
 
Terraform modules can be [published](https://www.terraform.io/language/modules#published-modules) to remote registries allowing teams to share and consume resource packages developed by other teams.  This provides opportunities to implement standardization and roll out version controlled changes and improvements easily.

## Implementation reference [#implementation-reference]

### Automation workflows
Automation workflows are essential for scaling observability as code to teams and organizations. There are many CI/CD tools and services available that can drive [Terraform workflows](https://www.terraform.io/intro/core-workflow). These allow configuration changes to be discussed and approved whilst also providing an auditable trail of changes.

We recommend adopting a [Terraform workflow](https://www.terraform.io/intro/core-workflow) to enable teams to work together on New Relic configuration. One such workflow leverages the CI/CD capabilites of code versioning systems such as Github, Gitlab and Bitbucket to automatically plan and apply code using built in approval and review mechanisms

<img
  src={img_oac_tf_workflow}
  title="Simple Terraform workflow"
  alt="Example Terraform workflow"
/>
<figcaption>
  This diagram illustrates how a change is raised as a PR which is then approved and merged to main to trigger resource deployment.
</figcaption>

### Example workflow implementations
The following [reference examples](https://github.com/newrelic-experimental/oma-nr-terraform-workflows) demonstrate how to setup a Terraform workflow in a number of different systems:

- [Github Actions Example](https://github.com/newrelic-experimental/oma-nr-terraform-workflows/blob/main/github-action-example) - This example demonstrates how to use [Github actions](https://github.com/features/actions) together with AWS S3 backed state storage.
- [Gitlab Pipeline Example](https://github.com/newrelic-experimental/oma-nr-terraform-workflows/blob/main/gitlab-pipeline-example) - This example demonstrates how to use a [Gitlab pipeline](https://docs.gitlab.com/ee/user/infrastructure/iac/) together with Gitlab http state storage.
- [Bitbucket Pipeline Example](https://github.com/newrelic-experimental/oma-nr-terraform-workflows/blob/main/bitbucket-pipeline-example) - This example demonstrates using a [Bitbucket pipeline](https://bitbucket.org/product/features/pipelines) together with S3 backed state storage.


### Version pinning
When provisioning resources automatically via Observability as Code workflows it's important to ensure the workflow performs the same way on every run. We recommend version pinning the version of the New Relic provider and Terraform used to ensure that unexpected upgrades do not occur causing pipeline failure. If you decide to version pin then you should periodically upgrade and test the provider versions to latest. You can learn more about constraining versions in the [Terraform documentation](https://www.terraform.io/language/expressions/version-constraints). 

### Detecting configuration drift
Understanding configuration drift is important to ensure stability and reliability of your Observability platform. Depending on your strategy for access control and permissions it may be possible that users can change resources in the UI that are also managed by code. Detecting this configuration drift enables you to understand the changes and fix the configuration if necessary.

There are two main modes of operation: 
- **Detect and notify**: In this mode drift is detected and operators are notified. However no remedial changes are made automatically.
- **Detect, remediate and notify**: In this mode drift is detected and where possible also remediated automatically by the workflow.

<img
  src={img_oac_config_drift}
  title="Configuration drift workflow"
  alt="Configuration drift workflow"
/>
<figcaption>
  This diagram illustrates how a configuration drift workflow may be implemented. Detected changes are reported to New Relic where they can be alerted upon and tracked over time. 
</figcaption>

#### Configuration drift reference example
This reference example leverages Gtihub actions to schedule regular terraform plan operations. The number of changes detected is reported to New Relic and the re-apply of the terraform can be optionally initiated.

[Terraform configuration drift example](https://github.com/newrelic-experimental/oma-nr-terraform-workflows/tree/main/github-tf-config-drift)

## Conclusion [#conclusion]

### Best practices to adopt
- Clearly define and implement the KPIâ€™s to measure Observability as  Code maturity.
- Establish and communicate the current state prior to implementing new Observability as Code capabilities.
- Leverage automation wherever possible to accelerate observability delivery across environments.
- Auto document asset created via code.
- Track and address configuration drift.
- Drive extended reuse of assets across environments .

### Value realization 
At the end of this process you should realize the following benefits:

- Easily and effectively communicate your current Observability as Code maturity.
- Reduce the time to observability of your environments.
- Reduce the manual effort required to implement observability and free up productive time.
- Reduce operational risk in your production environments.
- Improve the ability to detect and resolve issues faster.
- Accelerate time to deploy new releases.
- Make telemetry data more actionable for your organisation as a whole.
- Improve your service availability and delivery to the business.
