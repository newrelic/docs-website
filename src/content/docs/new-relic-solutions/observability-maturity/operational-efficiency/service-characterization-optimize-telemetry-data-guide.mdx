---
title: "Service characterization: Optimize your telemetry" 
tags:
  - Observability maturity
  - Operational efficiency 
  - Service characterization
  - Implementation guide
metaDescription: "Our service characterization guide helps you set up the best telemetry possible to describe the runtime operation of your services."
redirects:
  - /docs/apm/agents/manage-apm-agents/agent-data/custom-instrumentation
  - /docs/new-relic-solutions/observability-maturity/operational-efficiency/sc-implementation-guide
---

import omaOeScServiceDiagram from 'images/oma-oe_diagram_sc-service.webp'

import omaOeScTransactionBreakdown from 'images/oma-oe-sc_screenshot-full_transaction-breakdown.webp'

import omaOeScTransactionBreakdownWeighted from 'images/oma-oe-sc-transaction-breakdown-weighted.webp'

import omaOeScTransactionBreakdownHistogramNonNormal from 'images/oma-oe-sc_screenshot-full_transaction-breakdown-histogram-non-normal.webp'

import omaOeScTransactionBreakdownHistogramNormal from 'images/oma-oe-sc_screenshot-full_transaction-breakdown-histogram-normal.webp'

import omaOeScTransactionAttributes from 'images/oma-oe-sc_screenshot-full_transaction-attributes.webp'

import omaOeScErrorAttributes from 'images/oma-oe-sc_screenshot-crop_error-attributes.webp'

import omaOeScTransactionNrqlCustomAttribute from 'images/oma-oe-sc_screenshot-crop_transaction-nrql-custom-attributes.webp'

import omaOeScTransactionNrqlFeatureFlag from 'images/oma-oe-sc_screenshot-crop_transaction-nrql-feature-flag.webp'

import omaOeScSummaryComponents from 'images/oma-oe-sc_screenshot-full_summary-components.webp'

import omaOeScTransactionComponents from 'images/oma-oe-sc_screenshot-crop_transaction-components.webp'

import omaOeScSummaryClient from 'images/oma-oe-sc_screenshot-full_summary-client.webp'

import omaOeScExternalService from 'images/oma-oe-sc_screenshot-full_external-service.webp'

import omaOeScDatabases from 'images/oma-oe-sc_screenshot-full_databases.webp'

import omaOeScSyntheticsMenu from 'images/oma-oe-sc_screenshot-crop_synthetics-menu.webp'

This guide walks you through making sure you have the telemetry needed for monitoring and optimizing your digital services. It's part of our [series on observability maturity](/docs/new-relic-solutions/observability-maturity/introduction). 

## Overview [#overview]

**"Do I have all the telemetry I need to measure the service I'm providing to my customers?"**

With service observability, there is little guidance on how developers can meaningfully contribute to production telemetry definitions. If you are a developer looking for practical advice on how to assess the quality of your telemetry then this guide is for you. Observability practices that link developer expectations with the runtime behavior of production systems are more effective at diagnosing and remediating aberrant conditions than those that don't. The more-direct developer connection produces services that are more robust and performant.

You're a good candidate for using this guide if any of the following are true:
* Your development teams are disconnected from production observability design.
* You have new services/capabilities that run in production and before fully establishing telemetry and alerting.
* You need to provide additional business context to your instrumentation to improve diagnosis and business KPI measurement.
* You employ a highly customized or proprietary software framework.
* Your service is under active development. Legacy services, and services built from commercial-off-the-shelf platforms, tend to be better served with generic instrumentation options.

## Desired outcome [#desired-outcome]

This guide focuses on the metrics derived from your application's runtime operation (its code execution) as well as external measurements of execution (through synthetic testing). Service instrumentation planning is the approach used to describe a single service runtime through telemetry.

Modern monitoring systems provide deep insight into the technical details of service implementation. The power of distributed trace, byte code, or script instrumentation allows operations teams to quickly collect detailed service telemetry. Unfortunately, operations teams are often not in the best position to evaluate the quality of the telemetry gathered from the instrumentation. This challenge is compounded by the fact that service delivery teams are asked to implement telemetry collection for the first time in live production systems.

Exposing inadequately instrumented services to production users for the purposes of refining that instrumentation creates a period that puts customer satisfaction at risk. This burn-in period often becomes difficult to escape as new features are delivered from code bases without a strong linkage between software delivery and observability programs.

Involving developers in instrumentation has the following benefits:

1. Improved troubleshooting:
  * Good telemetry naming gives operations staff a common language to use with developers during incidents, reducing the time to triage and remediate.
  * More precise and contextually relevant telemetry from your service allows for more accurate and actionable detection of faults.

2. Better informed development decisions by:
  * Detecting areas of volatility or unexpected behavior and addressing them.
  * Understanding what dependencies in your code lack redundancy or robustness, and taking measures to refactor the service.
  * Appreciating how end-user cohorts are employing your software. You can better understand where improvements will have the biggest impact.



## Key performance indicators [#key-perf-indicators]

It's important to identify some simple KPIs that help to gauge the ongoing improvements in your software delivery and operations programs. Here are two main types of KPIs to consider as you invest in improved instrumentation.
* **Business KPIs** are aligned to your overall program objectives and should be consistently measured to demonstrate ongoing program improvement for each service.
* **Practitioner KPIs** are used to measure changes in the execution of job functions for those participating in the development and management of services.

We'll examine these in more detail below. 

### Business KPIs [#kpi-business]

Business KPIs include: 

<CollapserGroup>
  <Collapser
    id="kpi-service-quality"
    title="Service quality"
  >
A metric is required to define how well your service is operating. This will depend upon the needs of your organization and the constraints of the services being monitored.

**Goal:** Improved service quality attainment score over time.

**Best practices:**
* Create a graphical representation as a trend of service quality achievement for defined periods (monthly and/or quarterly).
* Service Apdex can provide an effective service-specific quality score. (See [Apdex: Measure user satisfaction](/docs/apm/new-relic-apm/apdex/apdex-measure-user-satisfaction/).)
* A well defined service level management (SLM) approach using SLIs that describe the level of expected operation for service boundaries can be a useful way to establish a single measurement of quality.
  </Collapser>

  <Collapser
    id="kpi-release-frequency"
    title="Release frequency"
  >
"Release frequency" refers to the number of releases for a given service. This should indicate the velocity of the software delivery organization. Often release frequency isn't immediately comparable between development organizations. Instead, weighting high-value releases or features to bugs can provide an improved comparative context.

**Goal:** Consistency of attainment with consistent or improving service quality indicator.

**Best practices:**
* Can be derived from deployment markers or other events sent to New Relic.
* Measure directly from code or project management tools such as Jira, BitBucket, GitHub.
* Consider implementing a collection mechanism to capture release events and store them directly in New Relic. See [New Relic CICD innovation](https://github.com/newrelic-experimental/nr1-innovation-cicd/tree/main/Webhooks) for example JIRA and BitBucket configs.
  </Collapser>
</CollapserGroup>

### Practitioner KPIs [#kpi-practitioner]

Practictioner KPIs include: 

<CollapserGroup>
  <Collapser
    id="kpi-feature-release-frequency"
    title="Feature release frequency"
  >
The "feature release frequency" is a quantification of the percentage of releases that are directly related to new feature development versus bug fixes or technical debt retirement. The relationship between features and fixes will vary between teams and projects based on the history of the service.

**Goal:** A consistent or improving feature release frequency consistent with the service delivery goals.

**Best practices:**

* Practitioner feature release frequency is often acquired in the same manner as the broader release frequency business KPI. This metric is then made available to the development team for the service.
  </Collapser>

  <Collapser
    id="kpi-mean-time-to-close"
    title="Mean time to close"
  >
"Mean time to close" refers to the average duration of alert-driven incidents in New Relic. For more details about improving this, see the [Alert quality management guide](/docs/new-relic-solutions/observability-maturity/aqm-implementation-guide).

**Goal:** Steady decrease of incident close time for identified services.

**Best practices:*** follow the [Alert quality management guide](/docs/new-relic-solutions/observability-maturity/aqm-implementation-guide) to help you understand the behavior of your services through the lens of the alerts defined to help improve service delivery.
  </Collapser>
</CollapserGroup>

## Next Steps [#next-steps]

Follow the correct implementation guide for the layer you're focusing on.    
[Optimize your service telemetry](/docs/new-relic-solutions/observability-maturity/operational-efficiency/service-characterization-optimize-service-telemetry-guide)   
[Optimize your web telemetry](/docs/new-relic-solutions/observability-maturity/operational-efficiency/service-characterization-optimize-web-telemetry-guide)

