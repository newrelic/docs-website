---
title: 'Streaming alerts: key terms and concepts'
tags:
  - Alerts  
  - Get started
redirects:
  - /docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts
  - /docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts
  - /docs/alerts/create-alert/fine-tune/streaming-alerts-key-terms-concepts
  - /docs/alerts/create-alert/fine-tune/choose-your-aggregation-method
freshnessValidatedDate: 2024-10-28
---

The streaming <InlinePopover type="alerts"/> platform checks for incidents based on data that's present or missing in your stream of data, or [signal](/docs/using-new-relic/welcome-new-relic/get-started/glossary#signal), coming into New Relic.

You can use [NRQL conditions](/docs/alerts/alert-conditions/create-alert-conditions/#create-own-query) to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the [streaming algorithm](/docs/using-new-relic/welcome-new-relic/get-started/glossary#streaming-algorithm).

## Why it matters [#why]

Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you.

<img
  title="A diagram that demonstrates how data is streamed into New Relic."
  alt="A diagram that demonstrates how data is streamed into New Relic."
  src="/images/accounts_diagram_streaming-alerts.webp"
/>

<figcaption>
  Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see [Streaming alerts process and descriptions](#streaming-table).
</figcaption>

As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the [NRQL query's `WHERE` clause](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions#sel-where). Rather than inmmediately evaluating this data for incidents, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay and timer allows for slower data points to arrive before the window is aggregated.

Once the delay and timer time have expired, New Relic aggregates the data into a single data point. Alerts then compares the data point to the condition's threshold criteria to determine whether to open an incident.

Even if a data point meets the criteria for an incident, an incident may not be opened. An incident is opened only when data points consistently meet the threshold criteria over a period of time. This is called the threshold duration. If the data points exceed the threshold for an entire threshold duration, we'll send you a notification based on your policy settings.

All of these configurable delays give you more control over how you're alerted to sporadic and missing data.

## Streaming alerts process and descriptions [#streaming-table]

<table class="alternate">
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Process
      </th>

      <th>
        <DNT>
          **Description**
        </DNT>
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Streaming data
      </td>

      <td>
        All data coming into New Relic.
      </td>
    </tr>

    <tr>
      <td>
        `WHERE` clause
      </td>

      <td>
        Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter.
      </td>
    </tr>

    <tr>
      <td>
        Aggregation methods
      </td>

      <td>
        One of three methods that control how data is collected before it's evaluated. They are:

        * Event flow (Default)
        * Event timer
        * Cadence
      </td>
    </tr>

    <tr>
      <td>
        Aggregation window
      </td>

      <td>
        Data with timestamps that fall within this window will be aggregated and then evaluated.
      </td>
    </tr>

    <tr>
      <td>
        Sliding windows
      </td>

      <td>
        When enabled, it causes aggregation windows to overlap, creating smoother charts.

        Use the sliding windows duration to set the amount of time your aggregation windows overlap.
      </td>
    </tr>

    <tr>
      <td>
        Delay and timer
      </td>

      <td>
        A time delay to ensure that all data points arrive in the aggregation window before aggregation starts.
      </td>
    </tr>

    <tr>
      <td>
        Aggregated data
      </td>

      <td>
        Data in the aggregated window is collapsed to a single data point for alert evaluation.
      </td>
    </tr>

    <tr>
      <td>
        Evaluation
      </td>

      <td>
        The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point.
      </td>
    </tr>

    <tr>
      <td>
        Threshold duration
      </td>

      <td>
        A specific duration that determines if an incident is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, an incident opens.

        When a data point lacks data, a custom value is inserted to fill the gap.
      </td>
    </tr>
  </tbody>
</table>

## Streaming method [#streaming-method]

When an application or service is monitored by New Relic, data can arrive in different ways. Some data arrives consistently and predictably, while other data arrives inconsistently and sporadically. Aggregation is how our alerting system gathers data together before analyzing it for exceeding warning or critical threshold levels.

Your data is collected as data points in an aggregation window and then turned into a single numeric value. The data points are aggregated based on your query using methods like `sum`, `average`, `min`, and `max`, among others. This single numeric value is what's used to evaluate the condition's threshold. Once data has been aggregated, no more data points can be added to it. Our different aggregation methods will help you strike a balance between aggregating your data quickly and waiting for enough data points to arrive.

Streaming alerts provide a set of tools to give you greater control over how your data is aggregated before it's evaluated to reduce incorrect notifications you receive. 

You can choose between three different aggregation methods, depending on your needs.

* [Event flow](#event-flow) (default) works best for data that comes in frequently and mostly in order.

* [Event timer](#event-timer) works best for data that arrives infrequently in batches, such as cloud integration data or infrequent error logs.

* [Cadence](#cadence) is our original and inferior aggregation method. It aggregates data on specific time intervals as detected by New Relic's internal wall clock, regardless of data timestamps.

    <img
      title="Choose your aggregation method."
      alt="A flowchart image that helps you decide what aggregation method you should use."
      src="/images/accounts_diagram_streaming-alerts-aggregation-flowchart.webp"
    />

    <figcaption>
      If your data arrives consistently and predictably, use <DNT>**event flow**</DNT>. If your data arrives inconsistently and unpredictably, use <DNT>**event timer**</DNT>.
    </figcaption>

With the correct aggregation method, you're more likely to get notifications you care about, while preventing ones you don't. The most important questions to consider when deciding on your aggregation method: How often does my data arrive? How consistently does my data arrive?

When data arrives frequently and consistently in a linear way, we recommend using [event flow](#event-flow). With event flow, data is aggregated based on data point timestamps, so it's important that data points arrive in a consistent and linear manner. This aggregation method doesn't work as well for data point timestamps that arrive out of order or with a wide span of time within a short period. Event flow is the default aggregation method, because it applies for the most common use cases.

When data arrives sporadically, inconsistently, and out of order, we recommend using [event timer](#event-timer) aggregation.

### Event flow [#event-flow]

Event flow aggregates a window of data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time.

For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay. When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated.

<Callout variant="caution">
  If you expect your data points to arrive more than 65 minutes apart, please use the `Event Timer` method described below.
</Callout>

### Event timer [#event-timer]

Like event flow, event timer will only aggregate data for a given window when data arrives for that window. When a data point arrives for an aggregation window, a timer dedicated to that window starts to count down. If no further data arrives before the timer counts down, the data for that window is aggregated. If more data points arrive before the timer has completed counting down, the timer is reset.

For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer. When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later.

If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0.

If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point.

For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly.

### Cadence [#cadence]

Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive.

We recommend you use one of the other two methods.

