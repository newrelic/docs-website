---
title: Get started with telemetry in context
metaDescription: Get relevant metrics, events, logs, traces, and other telemetry data within the context of your app or host, without additional configuration or context switching in the New Relic One UI.
---

When you're troubleshooting an issue in your app or host, you need all the New Relic One tools at your fingertips. But you don't want to do a lot of context switching across the UI or be overwhelmed by the wealth of information available.

Our telemetry in context functionality gives you an easy way to troubleshoot problems across your apps, services, other entities, and data types, without having to leave the current UI page you're viewing. We curate the data automatically, including entity GUIDs for related APM service entities, so that highly correlated logs are already visible.

![Telemetry in context](./images/demotron6-logs030722.png "Telemetry in context")

<figcaption>
  Drill down into your logs, errors, traces, and spans, all from the APM **Summary** page in New Relic One.
</figcaption>

More importantly, when a problem arises, you immediately have an overall view of the health of **all** your systems, regardless of the type of data in those individual systems and components. But you don't need to waste critical time trying to decide where to start troubleshooting.

We provide a subset of the most relevant data coming from multiple types of telemetry data, so you can quickly focus. This also makes it easier to link your log telemetry data across accounts.

## Get started [#get-started]

Applications don't exist in isolation. The resources you use to monitor, troubleshoot, and improve their performance are both time-critical and complex. You need a simple yet holistic solution to quickly see and act on all your telemetry in context.

Ready to get started?

1. If you don't have one already, [create a New Relic account](https://newrelic.com/signup). It's free, forever.
2. Update to the [supported agent version](#agents) for your apps and hosts.
3. [Enable](#agents) telemetry in context for your agent, and make a few small updates to your configuration file.

That's it! Now, to start troubleshooting with relevant telemetry data in your logs, go to New Relic One:

* Explorer UI at [one.newrelic.com](https://one.newrelic.com)
* Explorer UI for EU region data center if applicable: [one.eu.newrelic.com](https://one.eu.newrelic.com)


Your logs will automatically include attributes such as `span.id`, `trace.id`, `hostname`, `entity.guid`, and more. These make it easier to query and facet on related telemetry data.

You can also add more attributes to make your troubleshooting focus even more precise. For example, you may want to add more attributes to get other key telemetry data specific to your ecosystem.

## APM agent configuration [#agents]

After you enable telemetry in context with the supported agent version and update your agent configuration, no additional installation or configuration is required! Your logs will flow into New Relic with related telemetry data for your apps and hosts.

For detailed information about how to enable telemetry in context and update your configuration, see the documentation for your APM agent:

* Java telemetry in context procedures for agent [v7.6.0 or higher](/docs/release-notes/agent-release-notes/java-release-notes) for Log4j2 and Logback
* .NET telemetry in context procedures for agent [v0.0.0.0 or higher](/docs/release-notes/agent-release-notes/net-release-notes) for Log4Net
* [Ruby telemetry in context procedures](https://docswebsitedevelop-doc7757rubytic.gtsb.io/docs/logs/logs-everywhere/ruby-telemetry-context/) for agent [v8.6.0 or higher](/docs/release-notes/agent-release-notes/ruby-release-notes) (default Logger)

If your APM agent does not support our telemetry in context solution, you can continue to use our [standard logs in context solutions](/docs/logs/logs-context/logs-in-context).

## Ensure data privacy [#data-privacy]

Our log management service automatically masks number patterns that appear to be for items such as credit cards or Social Security numbers. For more information, see our [security documentation](/docs/logs/get-started/new-relics-log-management-security-privacy) for log management.

You can also use our obfuscation options to hash or mask sensitive data in your logs. This is critical, for example:

* If it is impractical or impossible to split sensitive data into separate accounts
* If you want data to be searchable and coherent without sensitive information exposed
* If you want to restrict query capabilities for sensitive data for users without those access rights

For more information, see our [obfuscation documentation](/docs/logs/ui-data/obfuscation-ui/). You can create, read, update, and delete obfuscation expressions and rules via the New Relic One UI or NerdGraph, our New Relic GraphQL explorer.

## Manage your ingest limits [#ingest]

Using telemetry in context functionality will increase your data ingest. Depending on your account's pricing model, this may have an impact on your ingest limits and billing.

<Callout variant="caution">
  If you want to use our telemetry in context solution and you already have an existing log forwarding solution, you must disable it. Otherwise you will be sending duplicate lines, which results in double billing.
</Callout>

For more information about enabling and configuring telemetry in context, see the documentation for your APM agent:

* Java
* .NET
* [Ruby telemetry in context](https://docswebsitedevelop-doc7757rubytic.gtsb.io/docs/logs/logs-everywhere/ruby-telemetry-context/)

**Example:** Your engineering team is troubleshooting a problem with your app, so you want to temporarily raise the limits to maximum data collection in your agent's config file. (By default, the maximum number of logs sampled by your APM agent is approximately 10,000 per minute.) But if you leave higher limits running for several days, this could result in a lot of unnecessary data and wasted money.

To avoid any surprises, we recommend that you use [NRQL queries](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/#data-queries) to create [alert conditions](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/#alerts) to keep track of your ingest limits. For example:

<CollapserGroup>
  
  <Collapser
    id="limits-ui"
    title="View data limits and usage in UI"
  >

  To [review your data limits in the UI](/docs/data-apis/manage-data/view-system-limits): From the [account dropdown](/docs/glossary/glossary/#account-dropdown) in the New Relic One UI, click **Manage your data > Limits**. Or, to view your usage and estimated cost to date, click **View your usage**.

  ![View data and usage from UI](./images/view-limits.png "View data and usage from UI")
  
  </Collapser>

  <Collapser
    id="query-estimate"
    title="NRQL query: estimated cost example"
  >

  To query your [month-to-date estimated cost of your ingested data](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/#month-cost), run this NRQL query:

  ```
  FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month
  ```

  </Collapser>

  <Collapser
    id="nrql-alert"
    title="NRQL alert: usage threshold example"
  >

  To create an alert when your usage exceeds a fixed monthly threshold for gigabytes of data, add this [NRQL query](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/create-nrql-alert-conditions/) to your alert condition:

  ```
  FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform'
  ```

  </Collapser>

</CollapserGroup>

## Example: Troubleshooting poor response time and rising error rates [#response-time-example]

Here is a detailed use case of using telemetry data in context to get to the root cause of a problem:

The on-call engineer receives New Relic alert notification about poor response time and rising error rates for their "Order Composer" app. They need to discover the root cause behind the increase in errors and latency, so they can decide whether to rotate a problematic host out of load balancing or to roll back the most recent release.

To start troubleshooting, they go to New Relic One:

<CollapserGroup>
  <Collapser
    id="when"
    title="When and where did the errors begin?"
  >

  When the engineer looks at the app's **Summary** page, they see many more error logs leading up to the increase in response time. They want to see if the logs can expose the root cause of the problem.

  ![APM summary errors](./images/demotron1-logs030722.png "APM summary errors")

  **How can they quickly decide what's related to the problem?**
  
  They have not set up log collection. But the Ruby agent for their app has been recently updated to include telemetry in context, so the app now automatically receives metrics about its logs. The metrics facet the count by log severity set by Ruby's built-in Logger.

  ![Logs summary](./images/demotron2-logs030722.png "Logs summary")

  **What entities are related?**
  
  On the same UI page, they click the **Logs** chart, so they can review the **Log Summary** view for entities in the New Relic One Explorer. This view shows them when instrumented logs have been collected and when those logs had an `Error` severity level or worse. It also shows them a list of log patterns and what percentage of all logs fit each pattern.

    </Collapser>

    <Collapser
    id="patterns"
    title="What patterns emerge in the logs?"
    >

    In the **Log Patterns** UI, rare error messages have begun to occur frequently, and they now appear in the list. This helps the engineer to focus on problematic logs instead of all the noisy status updates.

    ![Log patterns](./images/demotron3-logs030722.png "Log patterns")

    **What patterns should they focus on?**
    
    The engineer notices an interesting log pattern and wants to view only the logs that fit this pattern. By clicking on it, this adds the pattern's value as a filter to the logs being displayed. This narrows the focus.

    </Collapser>

    <Collapser
    id="log-details"
    title="What can more log details reveal?"
    >

    The engineer wants to see all the values contained in the log record, so they click the **Log Detail** view. This helps them validate that the log itself is meaningful. It also lets them drill down further into either the Kubernetes environment where the app runs, or directly to any distributed traces or APM errors related to the log record.

    ![Log details](./images/demotron4-logs030722.png "Log details")
    
    The engineer decides to look at the APM error where they can see a full stack trace. They can also see logs from their **Errors in-box** UI.
    
    ![Error logs](./images/demotron5-logs030722.png "Error logs")

    </Collapser>

    <Collapser
    id="log-sampling"
    title="What additional test data will help troubleshoot?"
    >

    The troubleshooting team has been running tests to isolate the cause, but not all logs have been collected for the test transactions. The default log collection in their APM agent's config file (approximately 10,000 logs per minute in `application_logging.forwarding.max_samples_stored`) has been useful to validate that the services have an issue. But now they need to turn up the sampling to a higher number for more detailed troubleshooting.

    </Collapser>

    <Collapser
    id="next-steps"
    title="Problem solved. Now what?"
    >
    
    The troubleshooting team determines the problem stems from a recently introduced change, so they roll back that code. To save resources and ingest expenses, they turn down log collection for `application_logging.forwarding.max_samples_stored` in their config file, but they keep log sampling running in case the issue repeats itself.
    
    They also update their runbooks to point to the log patterns page filtered to this app, and [add the runbook to their alert condition](/docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/provide-runbook-instructions-alert-activity/). Next time they get an alert similar to this situation, they can use these lessons learned for faster troubleshooting.

    </Collapser>

</CollapserGroup>

