---
title: No-Code Parsing
tags:
  - Logs
  - Log management
  - UI and data
  - Parsing
metaDescription: Create parsing rules visually without writing Grok or Regex patterns. No-Code Parsing lets you build log transformation rules through an intuitive visual interface.
freshnessValidatedDate: 2026-02-25
---

<Callout title="preview">
  No-Code Parsing is in public preview. This feature is available as part of a preview program pursuant to our [pre-release policies](/docs/licenses/license-information/referenced-policies/new-relic-pre-release-policy).
</Callout>

No-Code Parsing is a visual, code-free way to create log parsing rules without needing to write Grok or Regex patterns. It's designed for anyone who needs to extract meaningful data from logs but lacks deep expertise in pattern matching languages.

## What is No-Code Parsing? [#what-is-no-code-parsing]

Traditional log parsing requires expertise in Grok syntax and regular expressions—skills that not all team members possess. No-Code Parsing removes this barrier by providing an intuitive visual interface to create parsing rules directly from your log data.

With No-Code Parsing, you can:

* Extract attributes visually by selecting and naming fields in your log samples.
* See instant previews as you build rules against real log data.
* Auto-detect common patterns like timestamps, IP addresses, UUIDs, and log levels.
* Test rules in real-time against up to 10 sample logs before deployment.
* Create rules in-context without leaving the Log Detail View.

## Key benefits [#key-benefits]

**Removes the expert tax** — No-Code Parsing enables your entire team to create parsing rules without requiring deep expertise in pattern matching languages. You're no longer dependent on specialists to write and maintain Grok patterns.

**Eliminates error-prone manual pattern writing** — Instead of authoring complex Grok or Regex patterns through trial and error, you'll select fields visually with instant feedback. The system suggests patterns, so you get reliable results faster.

**No context switching** — Create parsing rules directly from the log you're viewing or troubleshooting. You'll stay in your workflow instead of navigating to a separate parsing configuration screen.

**Real-time validation** — See exactly what'll be extracted and how it'll look before you deploy. Test your rule against up to 10 sample logs with side-by-side previews.

**Faster time-to-value** — Create parsing rules in under 5 minutes, compared to hours or days spent learning Grok syntax and debugging patterns. Get logs searchable and queryable quickly.

## Who should use No-Code Parsing? [#personas]

### Primary users

* **Platform and observability engineers** — Centralize log transformation rules across your infrastructure without writing complex patterns.
* **SREs** — Quickly build parsing rules for new applications and services during incident response or scaling events.
* **DevOps teams** — Standardize log ingestion and make log data actionable for your organization.

### Secondary users

* **Application developers** — Self-serve log parsing for debugging application issues without waiting for log experts.
* **Analysts** — Extract business-relevant metrics from application logs without needing to learn Grok or Regex.

## How to access No-Code Parsing [#access]

No-Code Parsing is currently in public preview. To use it, you'll need to opt into the feature:

1. Log in to New Relic.
2. Click your user menu in the bottom left.
3. Select **Administration > Previews & Trials**.
4. Find **No-Code Parsing** and click **Enable Preview**.
5. Once enabled, you'll see No-Code Parsing options in the Logs UI.

<Callout type="tip">
You must have permissions to create parsing rules in New Relic to use No-Code Parsing. If you're not sure whether you have the right permissions, contact your account administrator.
</Callout>

## Parsing modes [#parsing-modes]

No-Code Parsing offers three ways to create rules, each suited for different scenarios:

### Auto-parse mode

Let New Relic automatically detect and extract attributes from your logs. The system identifies common patterns including:

* Timestamps (ISO 8601, Unix epoch, Apache common log format).
* IP addresses and MAC addresses.
* UUIDs and GUIDs.
* Log levels (ERROR, INFO, DEBUG, WARN).
* Hostnames and domain names.

**When to use:** You want a quick starting point and are willing to refine the results.

### Select to parse mode

Manually highlight specific fields in your log samples and name them. This gives you precise control over which attributes to extract and how to name them.

**When to use:** You know exactly which fields you need and want to move quickly.

### Write your own mode

For advanced use cases, switch to traditional Grok or Regex syntax when No-Code Parsing doesn't meet your needs. When you switch to this mode:

* The rule drafted by Auto-parse or Select to parse mode is preserved
* You can manually edit the Grok or Regex patterns
* You can switch back to Auto-parse or Select to parse mode at any time by highlighting new sections

**When to use:** You're dealing with complex, non-standard log formats that need custom patterns, or you're a power user who prefers direct pattern control.

## Creating a parsing rule [#create-parsing-rule]

### Access No-Code Parsing

You can start creating a parsing rule from two locations:

**From the Parsing Rules view:**
1. Go to **Logs > Parsing rules**.
2. Click **Create parsing rule**.
3. Define your matching criteria and run the query.
4. Select which field you want to parse (for example, click `message`).
5. The No-Code Parsing editor opens with sample logs matching your criteria.

**From a log in context:**
1. Go to **Logs** and find a log you want to parse.
2. Click the log to open **Log Detail View**.
3. Click the **...** menu icon.
4. Select **Create ingest-time parsing rule**.
5. The No-Code Parsing editor opens with your log context pre-populated:
   * **Matching criteria** — Automatically filled based on your current query or filter
   * **Field to parse** — Pre-selected based on the field you clicked (typically `message`)
   * You can modify these settings if needed, but they save you manual entry steps

### Step 1: Name your rule and define your matching criteria

At the top of the editor, enter:

* **Rule name** — A descriptive name for your parsing rule (for example, `Apache access log parser`).
* **Matching criteria** — A NRQL `WHERE` clause that determines which logs this rule applies to (for example, `logtype = 'apache'`).

If you started from a log in context, the matching criteria may be pre-populated based on your current log selection.

### Step 2: Select the field to parse

Specify which field in your log you want to parse. Common choices:

* `message` — The main log message (default).
* `raw` — Raw event data.
* Any custom attribute in your logs.

Once you select a field, the editor displays up to 10 sample logs matching your criteria.

### Step 3: Review auto-detected patterns or highlight fields

The editor shows your sample logs. You'll see two options:

**Auto-parse:** Review the patterns New Relic automatically detected. The highlighted sections show what'll be extracted. Click any highlighted section to:
* View the detected pattern type (timestamps, IPs, key-value pairs, etc.)
* Configure pattern settings (delimiters, separators, prefix handling)
* Modify or remove the pattern

**Select to parse:** Manually highlight text you want to extract. The editor suggests a pattern and attribute name. You can:
* Add the pattern to your rule to see a preview
* Configure detected patterns before adding them
* Highlight multiple sections to build complex rules

You can toggle between these approaches as you build your rule. If you want to start fresh, use **Remove all selected patterns** to clear auto-detected patterns and begin manual selection.

### Step 4: Preview the results

The **Parsed** tab shows which fields were successfully extracted from each sample log. The **Not Parsed** tab shows logs that didn't match your criteria.

Review the preview to ensure:

* Your matching criteria capture the right logs.
* The extracted attributes are what you expect.
* Extracted values look correct.

Aim for a 80%+ success rate on your sample logs.

**Working with unparsed samples:**

If you see logs in the **Not Parsed** tab that should be parsed, you can:

1. Click on an unparsed sample log
2. Select **Use this sample** to switch your working context to that log
3. The editor re-runs auto-detection on the new sample
4. Your rule updates to include patterns from this sample
5. Review the combined results across all samples

This helps you create rules that handle variations in your log formats.

### Step 5: Save your rule

Once you're satisfied with your parsing rule, you have two options:

* **Save rule** — Activates the rule immediately. It will apply to all logs ingested after this moment.
* **Save as draft** — Saves your rule configuration without activating it. You can activate it later from the Parsing Rules view.

Your rule only processes logs ingested after activation—it doesn't retroactively parse existing logs.

## Entry points and in-context workflows [#entry-points]

No-Code Parsing is accessible from several places in New Relic, so you can create rules without leaving your current workflow:

### Logs UI

* **From Logs list:** Click a log and open Log Detail View. Use the **...** menu to create an ingest-time parsing rule.
* **From Parsing Rules:** Go to **Logs > Parsing rules** and click **Create parsing rule**.

### Unified Querying Experience (UQE)

* Open Log Detail View from a log in UQE.
* Use the **...** menu to create an ingest-time parsing rule.
* Your current UQE query pre-populates the matching criteria.

### Logs in Context

* When viewing logs from other entities (APM, infrastructure, etc.), open Log Detail View.
* Use the **...** menu to create an ingest-time parsing rule.
* The entity context pre-populates your matching criteria.

## Real-time preview [#real-time-preview]

As you build your rule, No-Code Parsing shows instant feedback:

* **Before state** — The original log with raw data.
* **After state** — The parsed log showing extracted attributes as key:value pairs.
* **Parsing status** — Visual indicators showing which logs parsed successfully.
* **Field accuracy** — Highlighted sections show exactly what'll be extracted.

Switch between the **Parsed** and **Not Parsed** tabs to see which sample logs matched your criteria and which didn't. This real-time feedback helps you catch issues before deployment.

## Pattern detection capabilities [#pattern-detection]

No-Code Parsing's intelligent auto-detection recognizes common patterns:

| Pattern | Examples | Configuration Options |
|---------|----------|----------------------|
| **Timestamps** | `2026-01-29T14:32:15Z`, `1738166335`, `29/Jan/2026:14:32:15 +0000` | Format auto-detected |
| **IP addresses** | `192.168.1.100`, `2001:db8::1` | IPv4 and IPv6 |
| **MAC addresses** | `00:1A:2B:3C:4D:5E`, `00-1A-2B-3C-4D-5E` | Multiple format support |
| **UUIDs** | `550e8400-e29b-41d4-a716-446655440000` | Standard UUID format |
| **Log levels** | `ERROR`, `INFO`, `DEBUG`, `WARN`, `FATAL` | Case-insensitive |
| **Hostnames** | `app-server-01`, `api.example.com` | Domain names included |
| **Key-value pairs** | `user=john id=123 status=active` | Configurable delimiter and separator |

### Key-value pair detection

When No-Code Parsing detects key-value pairs in your logs, you can configure:

* **Delimiter** — The character separating multiple pairs (default: space)
* **Key-value separator** — The character between keys and values (default: `=`)
* **Prefix handling** — Auto-detected fields may include prefixes (like `kvp_`). You can remove these prefixes if you don't want them in your extracted attributes.

Click any highlighted pattern to view and modify its configuration. The preview updates immediately to show how your changes affect the extracted data.

## Naming conventions [#naming-conventions]

When creating attributes through No-Code Parsing, follow these guidelines for consistency:

* Use lowercase with underscores for multi-word attributes: `response_code`, `user_id`, `request_duration_ms`.
* Use only `a-z`, `0-9`, and `_` — no special characters.
* Be descriptive: `user_id` is better than `uid`.
* Include units where relevant: `duration_ms`, `size_bytes`.
* Avoid reserved field names; use `custom_` prefix if needed.

Consistent naming makes queries and analysis easier across your team.

## Supported log formats [#supported-formats]

No-Code Parsing works best with structured or semi-structured logs:

* **Structured** — JSON logs (automatically parsed by New Relic).
* **Key-value pairs** — `key1=value1 key2=value2`.
* **CSV/TSV** — Delimited fields with headers.
* **Space or comma-separated** — Fixed-width or predictable delimiters.
* **Common standards** — Apache access logs, NGINX logs, Syslog.

You can parse any field in your log, not just the `message` field.

## Limitations [#limitations]

**Public preview limitations:**

* Rules are applied to **ingestion-time** parsing only (not query-time).
* You can create up to 100 parsing rules per account.
* Sample preview is limited to 10 logs.
* Target pattern accuracy is 80% on sample logs.

**Scope of extraction:**

* You can extract up to 64 attributes per log message.
* Each attribute value has a 4KB size limit.
* Parsing happens before data enrichment, so enriched fields can't be used in matching criteria.

**Log volume:**

* For high-volume services (>100k logs/min), test thoroughly before deployment.
* Consider using more specific matching criteria to reduce processing overhead.

## Managing parsing rules [#manage-rules]

### View your parsing rules

1. Go to **Logs > Parsing rules**.
2. You'll see all parsing rules, including:
   * Rule name and description.
   * Matching criteria.
   * Creation date and last modified date.
   * Status (Active, Draft, or Disabled).

Draft rules are saved but not yet activated. You can activate them when you're ready to apply them to incoming logs.

### Edit a parsing rule

1. Find the rule in your parsing rules list.
2. Click the rule name.
3. Make changes in the No-Code Parsing editor.
4. Click **Save rule** (or **Save as draft** if you want to keep it inactive).

Changes apply to logs ingested after the update.

### Activate a draft rule

1. Find the draft rule in your parsing rules list.
2. Click the **...** menu.
3. Choose **Activate**.

The rule becomes active immediately and applies to newly ingested logs.

### Disable or delete a parsing rule

1. Find the rule in your parsing rules list.
2. Click the **...** menu.
3. Choose **Disable** (temporarily pause the rule) or **Delete** (remove completely).

Disabling keeps your rule configuration—you can re-enable it later. Deleting removes it permanently.

### Reorder parsing rules

If multiple rules match the same logs, order matters. Only the first matching rule applies:

1. Go to **Logs > Parsing rules**.
2. Click **Manage rule order**.
3. Drag rules to reorder.
4. Click **Save**.

## Comparison with traditional parsing [#comparison]

| Aspect | No-Code Parsing | Traditional (Grok/Regex) |
|--------|-----------------|--------------------------|
| **Learning curve** | Minutes—visual interface | Days—requires Grok/Regex knowledge |
| **Speed to deploy** | Under 5 minutes | 15–60 minutes |
| **Debugging** | Real-time visual feedback | Trial and error with pattern testing |
| **Best for** | Standard/semi-structured formats | Non-standard or complex formats |
| **In-context creation** | Yes—from Log Detail View | No—must go to Parsing Rules |
| **Expertise required** | No | Yes |
| **Pattern flexibility** | Good for common patterns | Unlimited pattern control |

**Choose No-Code Parsing** for standard log formats when you want speed and accessibility.

**Choose traditional parsing** for non-standard formats or when you need advanced pattern control.

For detailed information on Grok and Regex parsing, see [Parsing log data](/docs/logs/ui-data/parsing).

## Best practices [#best-practices]

**Start with auto-detect** — Let No-Code Parsing's pattern recognition do the work, then refine as needed.

**Use representative samples** — Ensure your sample logs cover the variety of formats you'll encounter in production.

**Be specific with matching criteria** — Narrow your rules to specific services, log types, or environments for accuracy and performance. A rule matching `service = 'api'` is better than one matching all logs.

**Name attributes consistently** — Follow a naming convention across all your parsing rules for easier querying and analysis.

**Test before deploying** — Review the preview output to ensure your rule captures what you expect. Check the **Not Parsed** tab to see which logs didn't match.

**Start simple, add complexity gradually** — Begin with one or two extraction patterns per rule, then add more as you validate the results.

**Monitor your rules** — Periodically check that rules are still matching and parsing as expected. Log formats evolve, and you may need to update rules over time.

## Troubleshooting [#troubleshooting]

### Rule isn't parsing logs

**Possible causes:**

* Matching criteria doesn't match your logs.
* Logs don't contain the fields you're trying to extract.
* Parsing rule was disabled or deleted.

**Solutions:**

1. Test your `WHERE` clause with NRQL: `SELECT * FROM Log WHERE your_criteria SINCE 30 minutes ago`.
2. Verify logs contain the expected fields.
3. Confirm the parsing rule is active in **Logs > Parsing rules**.

### Low parsing success rate

**Possible causes:**

* Sample logs aren't representative of production data.
* Extraction patterns are too specific.
* Log format varies more than expected.

**Solutions:**

1. Get fresh samples from different time periods.
2. Review the **Not Parsed** tab to see which logs are failing.
3. Adjust extraction patterns to be more flexible.
4. Use Auto-parse mode for pattern suggestions.

### Extracted values look wrong

**Possible causes:**

* Selections included unwanted whitespace or delimiters.
* Extraction boundary was set incorrectly.
* Log format has embedded delimiters.

**Solutions:**

1. Re-do your field selections, being careful about boundaries.
2. Review the **Parsed** tab to see exactly what's being extracted.
3. Consider using Write Your Own (Grok) mode for complex edge cases.

### Can't see No-Code Parsing option

**Possible causes:**

* Public preview isn't enabled for your account yet.
* Feature is rolling out gradually.

**Solutions:**

1. Go to **Administration > Previews & Trials** and check if No-Code Parsing is available.
2. Contact New Relic support if you need access.
3. Refresh your browser to ensure you have the latest UI.

## Feedback and support [#feedback-support]

No-Code Parsing is in public preview, and we'd love to hear from you:

* **Share feedback** — Use the feedback widget in the No-Code Parsing editor to share what's working and what could improve.
* **Report issues** — Contact New Relic support if you encounter problems.
* **Feature requests** — Tell us what you'd like to see added to No-Code Parsing.

Your feedback helps us improve No-Code Parsing before general availability.

## See also [#see-also]

* [Parsing log data](/docs/logs/ui-data/parsing) — Learn about traditional Grok and Regex parsing.
* [Built-in log parsing rules](/docs/logs/ui-data/built-log-parsing-rules) — Explore pre-built patterns from New Relic.
* [Query log data](/docs/logs/log-management/ui-data/query-logs) — Use parsed attributes in NRQL queries.
* [Logs UI](/docs/logs/ui-data/use-logs-ui) — Overview of the Logs UI and its features.