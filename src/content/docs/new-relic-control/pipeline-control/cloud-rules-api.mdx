---
title: Drop data using Pipeline Control cloud rules
metaDescription: 'Learn how to use the cloud rule API to manage data filtering and processing in New Relic Control.'
freshnessValidatedDate: never
---

One way to [manage your data ingestion](/docs/data-apis/manage-data/manage-data-coming-new-relic) is by using Pipeline Control cloud rules. To create Pipeline cloud rules, you must be on New Relic Compute usage-based pricing.

There are two categories of rules you can create:
* **Drop data rule**
  * Drop entire data types or a data subset _(with optional filter)_, with NRQL in the form of:
    ```sql
    DELETE FROM DATA_TYPE_1, DATA_TYPE_2 (WHERE OPTIONAL_FILTER)
    ```

* **Drop attribute rule**
  * Drop attributes from data types _(with optional filter)_, with NRQL in the form of:
    ```sql
    DELETE dropAttr1, dropAttr2 FROM DATA_TYPE (WHERE OPTIONAL_FILTER)
    ```
  * For this type of rule, you must pass in a non-empty list of **raw** attributes names in the `DELETE` clause.

<Callout variant="tip">
    Pipeline Control cloud rules only apply to data that arrives from the moment you create the rule, they don't delete data that's [already been ingested](/docs/telemetry-data-platform/ingest-manage-data/manage-data/manage-data-retention#data-deletion).
</Callout>


To learn more about what data counts as billable or not, see [Data ingest](/docs/accounts/accounts-billing/new-relic-one-pricing-billing/data-ingest-billing/#usage-calculation).

## Cloud rules data scope [#data-scope]

Use cloud rules to target the following data types:

* APM-reported events
* Browser-reported events
* Mobile-reported events
* Synthetics-reported events
* Custom events (like those generated by the [APM agent APIs](/docs/insights/insights-data-sources/custom-data/insert-custom-events-new-relic-apm-agents) or the [Event API](/docs/insights/insights-data-sources/custom-data/introduction-event-api))
* Log data (you can also [use the UI to drop data](/docs/logs/ui-data/drop-data-drop-filter-rules))
* Distributed tracing spans
* [Default infrastructure monitoring events](/docs/infrastructure/manage-your-data/data-instrumentation/default-infrastructure-monitoring-data) and [infrastructure integrations](/docs/integrations/infrastructure-integrations/get-started/introduction-infrastructure-integrations) events. Some caveats:
    * When you drop this data, the raw data is deleted, but the aggregated `SystemSample`, `ProcessSample`, `NetworkSample` and `StorageSample` events are still available (for more on this, see [Data retention](/docs/data-apis/manage-data/manage-data-retention/#infrastructure-data)). Though still available, this data doesn't count towards ingest and is not billable.
    * Raw infrastructure data is used for alerting, so if you drop that data, you can't alert on it. Because the aggregated data is still available, you may still see that data in charts with time ranges above 59 minutes.

<Callout variant="important">
  On January 7, 2026, drop rules targeting infrastructure events in `SystemSample`, `ProcessSample`, `NetworkSample`, and `StorageSample` will drop aggregated data.
</Callout>

* [Dimensional metrics](/docs/telemetry-data-platform/ingest-manage-data/understand-data/new-relic-data-types#dimensional-metrics). Some caveats:
    * For metrics generated by the [events-to-metrics service](/docs/data-ingest-apis/get-data-new-relic/metric-api/events-metrics-service-create-metrics): Cloud rules won't work but these metrics can be stopped or attributes pruned by disabling or re-configuring the events-to-metric rule.
    * Metric timeslice data can't be dropped with cloud rules. For more information about APM metric timeslice data see [this doc](/docs/data-apis/understand-data/new-relic-data-types/#timeslice-data).

## NRQL restrictions [#restrictions]

* The limit on NRQL query length is **4096** characters. If it exceeds the length, the `INVALID_NRQL_TOO_LONG` error occurs. If you need to drop data based on a longer query that cannot be split, contact your [New Relic support](https://support.newrelic.com).
* `JOIN` and [subqueries](/docs/query-your-data/nrql-new-relic-query-language/get-started/subqueries-in-nrql) are not supported.
* You can provide a [`WHERE`](/docs/query-data/nrql-new-relic-query-language/getting-started/nrql-syntax-clauses-functions#sel-where) clause to select data with specific attributes.
* Features such as `LIMIT`, `TIMESERIES`, `COMPARE WITH`, `FACET`, and other clauses cannot be used.
* `SINCE` and `UNTIL` are not supported. If you have time-specific rules (say, drop everything until a time in the future), use `WHERE timestamp < (epoch milliseconds in the future)`.
* You can't use `SINCE` to drop historical data. Cloud rules only apply to data reported after the rule was created. If you need to delete data that has already been reported, refer to [Delete existing data](/docs/data-apis/manage-data/manage-data-retention/#deleting-data) or contact [New Relic support](https://support.newrelic.com).

## Audit rule history [#history]

To see who created and deleted cloud rules, query your [account audit logs](/docs/insights/use-insights-ui/manage-account-data/query-account-audit-logs-nrauditevent). The [list endpoint](#view-rules) also includes the user ID of the person who created the rule.

## Cautions when dropping data [#caution]

Cloud rules apply to each data point independently. For example, let's look at the following three data drop rules:

<Callout variant="important">
    When creating rules, you are responsible for ensuring that the rules accurately identify and discard the data that meets the conditions that you have established. You are also responsible for monitoring the rule, as well as the data you disclose to New Relic.
</Callout>

```sql
1. DELETE FROM MyEvent WHERE myAttr not in ('staging')
2. DELETE FROM MyEvent WHERE myAttr not in ('production')
3. DELETE FROM MyEvent WHERE myAttr in ('development')
```
These three rules are applied independently to each data point; in summary, all `MyEvent` events containing `myAttr` with any value will be dropped:
* `myAttr: 'staging'` -> matches rule 2
* `myAttr: 'production'` -> matches rule 1
* `myAttr: 'development'` -> matches rules 1, 2, and 3
* `myAttr: 'uuid-random-string'` -> matches rules 1 and 2


New Relic cannot guarantee that this functionality will completely resolve data disclosure concerns you may have. New Relic does not review or monitor how effective the rules you develop are. Always test and retest your queries and, after the drop rule is created, make sure it works as intended.

Creating rules about sensitive data can leak information about what kinds of data you maintain, including the format of your data or systems (for example, through referencing email addresses or specific credit card numbers). Rules you create, including all information in those rules, can be viewed and edited by any user with the relevant role-based access control permissions.

Only new data will be dropped. Existing data [cannot be edited or deleted](/docs/telemetry-data-platform/ingest-manage-data/manage-data/manage-data-retention#data-deletion).

# Managing cloud rules [#how-to]
To create and edit rules, you can either use the [Pipeline Control UI](/docs/todo/replace/with/pipeline/control/ui/usage/doc) or the [NerdGraph](/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph) API explorer _(**[one.newrelic.com](https://one.newrelic.com) > Apps > NerdGraph API explorer**)_.

<Callout variant="caution">
  Use caution when deciding to drop data. The data you drop can't be recovered. For more details on potential issues, see [Caution notes](#caution).
</Callout>

## Use Case Examples [#example-mutations]

<CollapserGroup>
  <Collapser
    id="drop-events"
    title="Drop two event types"
  >
    Let's say you notice you have some event types being sent to New Relic that are not important to you. Also, stopping the source from sending those event types quickly is unrealistic, requiring changes to agents and/or API instrumentation. Using a cloud rule is an easier way to accomplish the same goal.

    Here is an example NerdGraph call that drops two event types: `Event1` and `Event2`.

    ```graphql
    mutation {
      entityManagementCreatePipelineCloudRule(
        pipelineCloudRuleEntity: {
          description: "Event1 and Event2 are unimportant, see ticket DM-1234",
          name: "Drop all data for Event1 and Event2",
          nrql: "DELETE FROM Event1, Event2",
          scope: {
            id: "your_nr_account_id",
            type: ACCOUNT
          }
        }
      ) {
        entity {
          id
          name
          nrql
        }
      }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-specific-events"
    title="Drop events meeting certain criteria"
  >
    Let’s say you have a high volume custom event type that arrives from multiple sources. If you don't find all of that data important, you can use a cloud rule. Here is an example of a cloud rule that filters out events based on specific criteria.

    ```graphql
    mutation {
      entityManagementCreatePipelineCloudRule(
        pipelineCloudRuleEntity: {
          description: "Drops all data for MyCustomEvent that comes from the LoadGeneratingApp in the dev environment, because there is too much and we don’t look at it",
          name: "Drop MyCustomEvent from LoadGeneratingApp in dev",
          nrql: "DELETE FROM MyCustomEvent WHERE appName='LoadGeneratingApp' AND environment='development'",
          scope: {
            id: "your_nr_account_id",
            type: ACCOUNT
          }
        }
      ) {
        entity {
          id
          name
          nrql
        }
      }
    }
    ```
  </Collapser>

  <Collapser
    id="drop-sensitive-data"
    title="Drop sensitive attributes while maintaining the rest of the data"
  >
    Let's say you noticed an event has attributes that contain Personally Identifiable Information (PII). You are working to update your services to stop sending the data, but until then, you need to cease storing further PII in New Relic. Although you could drop all of the data as it comes in the door with `Drop data`, the rest of the data still provides value. Therefore, you can register a cloud rule to remove only the offending PII from your data:

    ```graphql
    mutation {
      entityManagementCreatePipelineCloudRule(
        pipelineCloudRuleEntity: {
          description: "Removes the user name and email fields from MyCustomEvent",
          name: "Drop username and email from MyCustomEvent",
          nrql: "DELETE userName, userEmail FROM MyCustomEvent",
          scope: {
            id: "your_nr_account_id",
            type: ACCOUNT
          }
        }
      ) {
        entity {
          id
          name
          nrql
        }
      }
    }
    ```
  </Collapser>
</CollapserGroup>

## Verify your rule works [#verify]

After you create a cloud rule, you might wish to verify that it is working as expected. The rule should take effect quickly after a successful registration, so try running a `TIMESERIES` version of the query you registered to see that the data drops off.

_Note: Timeseries data is rendered with event time (not processing time) as the x-axis. Since New Relic accepts data with a timestamp up to twenty-four hours in the future, you might see some data that was sent to New Relic before the rule was created but with an event timestamp past rule creation._



<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Cloud rule type
      </th>

      <th>
        NRQL
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `Drop data`
      </td>

      <td>
        <DNT>
          **Cloud rule NRQL:**
        </DNT>

        ```sql
        DELETE FROM MyEvent WHERE foo = bar
        ```

        <DNT>
          **Validation NRQL:**
        </DNT>

        ```sql
        SELECT count(*) FROM MyEvent WHERE foo = bar TIMESERIES
        ```

        This should drop to 0. To verify that it did not affect any thing else, invert the `WHERE` clause.
      </td>
    </tr>

    <tr>
      <td>
        `Drop attributes`
      </td>

      <td>
        <DNT>
          **Cloud rule NRQL:**
        </DNT>

        ```sql
        DELETE dropAttr1, dropAttr2 FROM MyEvent WHERE foo = bar
        ```

        <DNT>
          **Validation NRQL:**
        </DNT>

        ```sql
        SELECT count(dropAttr1), count(dropAttr2) FROM MyEvent WHERE foo = bar TIMESERIES
        ```

        Both lines should drop to 0. To verify that it did not affect events that contained these attributes and still should, invert the `WHERE` clause.
      </td>
    </tr>
  </tbody>
</table>

# NerdGraph Examples [#examples]

## Create cloud rules [#create-rules]

Drop data:
```graphql
mutation {
  entityManagementCreatePipelineCloudRule(
    pipelineCloudRuleEntity: {
      description: "Since we only care about MyEvent in staging and production, let's drop all MyEvent data in the test environment",
      name: "Drop MyEvent in test environment",
      nrql: "DELETE FROM MyEvent where environment = 'test'",
      scope: {
        id: "your_nr_account_id",
        type: ACCOUNT
      }
    }
  ) {
    entity {
      id
      name
      nrql
    }
  }
}
```

Drop attributes:
```graphql
mutation {
  entityManagementCreatePipelineCloudRule(
    pipelineCloudRuleEntity: {
      description: "We don't care about jvmId and targetAttr in the test environment, let's drop those attributes",
      name: "Drop jvmId and targetAttr from MyEvent in test environment",
      nrql: "DELETE jvmId, targetAttr FROM MyEvent where environment = 'test'",
      scope: {
        id: "your_nr_account_id",
        type: ACCOUNT
      }
    }
  ) {
    entity {
      id
      name
      nrql
    }
  }
}
```
## Delete a cloud rule [#delete-rule]

```graphql
mutation {
  entityManagementDelete(id: "MTAyNTY1MHxOR0VQfFBJUEVMSU5FX0NMT1VEX1JVTEV8MDE5NWI0NDYtNjk5My03NGE5LWEyYjktMzBjMzQ1ODM0NTUz") {
    id
  }
}

```

## View cloud rules [#view-rules]

Get a single cloud rule:

```graphql
{
  actor {
    entityManagement {
      entity(id: "MTAyNTY1MHxOR0VQfFBJUEVMSU5FX0NMT1VEX1JVTEV8MDE5NWI0M2UtYmFhNy03NDk3LWI0N2ItNjUyMmEzZDFmZTFi") {
        id
        ... on EntityManagementPipelineCloudRuleEntity {
          id
          name
          description
          nrql
          metadata {
            createdBy {
              id
            }
            createdAt
          }
        }
      }
    }
  }
}
```

List all cloud rules:

```graphql
{
  actor {
    entityManagement {
      entitySearch(query: "type = 'PIPELINE_CLOUD_RULE'") {
        entities {
          id
          type
          ... on EntityManagementPipelineCloudRuleEntity {
            id
            name
            nrql
          }
          metadata {
            createdBy {
              id
            }
          }
        }
      }
    }
  }
}

```

## Non-droppable events and attributes [#non-droppable-data]
You cannot drop the following events and attributes using cloud rules:

<CollapserGroup>
  <Collapser
    id="prohibited-events"
    title="Non-droppable events"
  >
    <table>
      <thead>
        <tr>
          <th>Event type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>`NrAuditEvent`</td>
          <td>Important auditing information about the API usage that can’t be dropped.</td>
        </tr>
        <tr>
          <td>`NrIntegrationError`</td>
          <td>Important information about issues between you and New Relic.</td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="prohibited-attributes"
    title="Non-droppable attributes"
  >
    <table>
      <thead>
        <tr>
          <th>Attribute</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Any `nr.` prefixed attribute</td>
          <td>Used internally by New Relic</td>
          <td></td>
        </tr>
        <tr>
          <td>`timestamp`</td>
          <td>Integral to all data types</td>
        </tr>
        <tr>
          <td>`appId`</td>
          <td>Integral to all data types</td>
        </tr>
        <tr>
          <td>`metricName`</td>
          <td>Integral to the metric data type</td>
        </tr>
        <tr>
          <td>`instrumentation.provider`</td>
          <td>Used for billing and usage data</td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Drop attributes on dimensional metric rollups [#drop-attributes-on-dimensional-metric-rollups]

[Dimensional metrics](/docs/data-apis/understand-data/new-relic-data-types/#metrics-conceptual) aggregate metrics into rollups for long term storage and as a way to optimize longer term queries. [Metric cardinality limits](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes) are applied to this data.

You can use this feature to decide which attributes you don't need for long term storage and query, but would like to maintain for real time queries.

For example, adding `containerId` as an attribute can be useful for live troubleshooting or recent analysis, but may not be needed when querying over longer periods of time for larger trends. Due to how unique something like `containerId` can be, it can quickly drive you towards your [metric cardinality limits](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes) which when hit stops the synthesis of rollups for the remainder of that UTC day.

This feature also allows you to keep the [high cardinality](/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/) attributes on the raw data and drop it from rollups which gives you more control over how quickly you approach your cardinaliity limits.

### Usage

<DNT>**Drop attributes from dimensional metrics rollups**</DNT> (with optional filter). This uses NRQL of the form:

```sql
DELETE dropAttr1, dropAttr2 FROM MetricAggregate (WHERE OPTIONAL_FILTER)
```

Here is an example NerdGraph request:

```graphql
mutation {
  entityManagementCreatePipelineCloudRule(
    pipelineCloudRuleEntity: {
      description: "We don't care about targetAttr in the test environment in dimensional metric rolloups, let's drop those attributes",
      name: "Drop targetAttr from Metric aggregate rollups in test environment",
      nrql: "DELETE targetAttr FROM MetricAggregate where environment = 'test'",
      scope: {
        id: "your_nr_account_id",
        type: ACCOUNT
      }
    }
  ) {
    entity {
      id
      name
      nrql
    }
  }
}
```

To verify it's working, wait 3 to 5 minutes for the rule to be picked up and for aggregate data to be generated. Then assuming the example NRQL above is your pipeline control cloud rule, run the following queries:

```sql
SELECT count(targetAttr) FROM Metric WHERE metricName = 'some.metric' TIMESERIES SINCE 2 hours ago
SELECT count(targetAttr) FROM MetricRaw WHERE metricName = 'some.metric' TIMESERIES SINCE 2 hours ago
```

The first query retrieves metric rollups and should drop to 0 since `containerId` has been dropped per the new drop rule. The second query retrieves metric raws using the `MetricRaw` event type and should continue to hold steady since raw data is not impacted by the new drop rule. For more information on how to see the impact this will have on your cardinality, check out [Understand and query high cardinality metrics](/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics).

### Restrictions

All restrictions that apply to drop attribute rules apply to drop attributes from dimensional metric rollup rules with the additional restriction that you can only target the `MetricAggregate` data type. They also do not work on `Metric` queries targeting data created by an [events to metrics](/docs/data-ingest-apis/get-data-new-relic/metric-api/events-metrics-service-create-metrics) rule or on `Metric` queries targeting [timeslice data](/docs/data-apis/understand-data/metric-data/query-apm-metric-timeslice-data-nrql).

## Learn more

Recommendations for learning more:

* [NerdGraph basics and terminology](/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph#terminology)
* [NRQL basics](/docs/query-data/nrql-new-relic-query-language/getting-started/introduction-nrql)
* Browse the [Support Forum](https://discuss.newrelic.com/c/telemetry-data-platform/dashboards) for community discussions about cloud rules.
* For a deep dive into managing data ingest for a complex organization, see [Data ingest governance](/docs/new-relic-solutions/observability-maturity/operational-efficiency/intro-data-governance).
