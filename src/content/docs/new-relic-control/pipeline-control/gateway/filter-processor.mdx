---
title: Filter processor
metaDescription: 'Use the filter processor to drop unwanted telemetry data or attributes using OTTL boolean expressions.'
freshnessValidatedDate: never
---

The filter processor drops telemetry records or specific attributes based on OTTL (OpenTelemetry Transformation Language) boolean expressions. Use it to remove test data, debug logs, health checks, or any low-value telemetry before it leaves your network.

## When to use filter processor

Use the filter processor when you need to:

- **Drop PII or test environment data**: Remove data that shouldn't leave your network
- **Remove debug-level logs from production**: Filter by severity to reduce noise
- **Filter out health check requests**: Drop repetitive, low-value monitoring traffic
- **Drop metrics with specific prefixes or patterns**: Remove unnecessary metric streams
- **Remove low-value telemetry based on attributes**: Filter by service name, environment, or custom tags

## How filter processor works

The filter processor evaluates OTTL boolean expressions against each telemetry record. **When a condition evaluates to `true`, the record is dropped.**

This is the opposite of many query languages where `WHERE status = 'ERROR'` means "keep errors." In filter processor, `status == 'ERROR'` means "drop errors."

## Configuration

Add a filter processor to your pipeline:

```yaml
configuration:
  simplified/v1:
    steps:
      filter/Logs:
        description: "Drop debug logs and test environment data"
        config:
          logs:
            - 'severity.text == "DEBUG"'
            - 'attributes["environment"] == "test"'
        output: ["probabilistic_sampler/Logs"]
```

**Config fields**:
- `logs`: Array of OTTL boolean expressions for log filtering
- `spans`: Array of OTTL boolean expressions for trace span filtering
- `metrics`: Array of OTTL boolean expressions for metric filtering

**Multiple conditions**: When you provide multiple expressions in the array, they are evaluated with OR logic. If **any** condition is true, the record is dropped.

## OTTL boolean operators

### Comparison operators

- `==` - Equal to
- `!=` - Not equal to
- `<` - Less than
- `<=` - Less than or equal to
- `>` - Greater than
- `>=` - Greater than or equal to

### Logical operators

- `and` - Both conditions must be true
- `or` - Either condition must be true
- `not` - Negates a condition

### Pattern matching

- `matches` - Regex pattern matching

```yaml
logs:
  - 'body matches ".*health.*"'
  - 'attributes["http.url"] matches ".*\\/api\\/v1\\/health.*"'
```

## Complete examples

### Example 1: Drop test environment data

Remove all telemetry from test and development environments:

```yaml
filter/Logs:
  description: "Drop non-production environments"
  config:
    logs:
      - 'attributes["environment"] == "test"'
      - 'attributes["environment"] == "dev"'
      - 'attributes["environment"] == "local"'
  output: ["exportlogs"]
```

### Example 2: Drop debug logs in production

Keep only meaningful log levels in production:

```yaml
filter/Logs:
  description: "Drop debug and trace logs"
  config:
    logs:
      - 'severity.text == "DEBUG"'
      - 'severity.text == "TRACE"'
      - 'severity.number < 9'  # Drop INFO and below
  output: ["probabilistic_sampler/Logs"]
```

**Severity number reference**:
- TRACE = 1-4
- DEBUG = 5-8
- INFO = 9-12
- WARN = 13-16
- ERROR = 17-20
- FATAL = 21-24

### Example 3: Drop health check spans

Remove health check traffic that adds no diagnostic value:

```yaml
filter/Traces:
  description: "Drop health check spans"
  config:
    spans:
      - 'attributes["http.path"] == "/health"'
      - 'attributes["http.path"] == "/healthz"'
      - 'attributes["http.path"] == "/ping"'
      - 'name == "health_check"'
  output: ["exporttraces"]
```

### Example 4: Drop by service name

Filter out specific services or service patterns:

```yaml
filter/Logs:
  description: "Drop deprecated services"
  config:
    logs:
      - 'attributes["service.name"] == "legacy-api-v1"'
      - 'attributes["service.name"] matches ".*-canary"'
  output: ["exportlogs"]
```

### Example 5: Drop metrics with specific prefixes

Remove unnecessary metric streams:

```yaml
filter/Metrics:
  description: "Drop internal metrics"
  config:
    metrics:
      - 'name matches "^internal\\."'
      - 'name matches "^test_"'
      - 'attributes["metric.type"] == "debug"'
  output: ["exportmetrics"]
```

### Example 6: Combined conditions with AND

Drop only when multiple conditions are true:

```yaml
filter/Logs:
  description: "Drop debug logs from specific service in test environment"
  config:
    logs:
      - 'severity.text == "DEBUG" and attributes["service.name"] == "background-worker" and attributes["environment"] == "test"'
  output: ["exportlogs"]
```

### Example 7: Keep errors, drop everything else

Invert the logic to keep only valuable data:

```yaml
filter/Logs:
  description: "Drop non-error logs"
  config:
    logs:
      - 'severity.number < 17'  # Drop everything below ERROR
  output: ["exportlogs"]
```

Or use NOT logic:

```yaml
filter/Logs:
  description: "Drop non-errors"
  config:
    logs:
      - 'not (severity.text == "ERROR" or severity.text == "FATAL")'
  output: ["exportlogs"]
```

### Example 8: Pattern matching in log body

Drop logs containing specific patterns:

```yaml
filter/Logs:
  description: "Drop health check logs by body content"
  config:
    logs:
      - 'body matches ".*health check.*"'
      - 'body matches ".*GET /status.*"'
      - 'body matches ".*200 OK.*monitor.*"'
  output: ["exportlogs"]
```

### Example 9: Drop high-volume, low-value spans

Remove spans that occur frequently but provide little value:

```yaml
filter/Traces:
  description: "Drop fast, successful cache hits"
  config:
    spans:
      - 'attributes["db.operation"] == "get" and duration < 1000000 and attributes["cache.hit"] == true'
  output: ["exporttraces"]
```

**Note**: Duration is in nanoseconds (1ms = 1,000,000 ns).

### Example 10: Drop based on HTTP status

Filter successful requests, keep errors:

```yaml
filter/Traces:
  description: "Drop successful HTTP requests"
  config:
    spans:
      - 'attributes["http.status_code"] < 400'
  output: ["exporttraces"]
```

### Example 11: Multiple conditions with OR

Drop if any condition matches:

```yaml
filter/Logs:
  description: "Drop test data, health checks, or debug logs"
  config:
    logs:
      - 'attributes["environment"] == "test" or body matches ".*health.*" or severity.text == "DEBUG"'
  output: ["exportlogs"]
```

## Drop data vs drop attributes

The filter processor can drop entire records (as shown above) or drop specific attributes from records that are kept.

To drop attributes while keeping the record, you need to use the transform processor's `delete_key()` function, not the filter processor. The filter processor only drops entire records.

**Wrong approach** (this won't work):
```yaml
filter/Logs:
  config:
    logs:
      - 'delete attributes["sensitive_field"]'  # This is not valid
```

**Correct approach** (use transform processor instead):
```yaml
transform/Logs:
  description: "Remove sensitive attribute"
  config:
    log_statements:
      - delete_key(attributes, "sensitive_field")
  output: ["filter/Logs"]
```

## Performance considerations

- **Order matters**: Place filter processors early in your pipeline to drop unwanted data before expensive processing
- **Combine conditions**: Use `and`/`or` logic in a single expression rather than chaining multiple filter processors
- **Regex performance**: Pattern matching with `matches` is more expensive than exact equality checks. Use `==` when possible.

**Example of efficient ordering**:
```yaml
steps:
  receivelogs:
    output: ["filter/Logs"]  # Drop early

  filter/Logs:
    config:
      logs:
        - 'attributes["environment"] == "test"'
    output: ["transform/Logs"]  # Expensive transforms only on kept data

  transform/Logs:
    config:
      log_statements:
        - ParseJSON(body)  # Only parse logs that weren't dropped
    output: ["exportlogs"]
```

## OTTL boolean expression reference

For complete OTTL syntax and additional operators:
- [OTTL boolean expressions](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/README.md)
- [Filter processor documentation](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor)

## Next steps

- Learn about [Transform processor](/docs/new-relic-control/pipeline-control/gateway/transform-processor) for modifying data before filtering
- See [Sampling processor](/docs/new-relic-control/pipeline-control/gateway/sampling-processor) for probabilistic volume reduction
- Review [YAML configuration reference](/docs/new-relic-control/pipeline-control/gateway/yaml-overview) for complete syntax