---
title: Gateway YAML configuration reference
metaDescription: 'YAML configuration syntax reference for creating custom Pipeline Control Gateway configurations.'
freshnessValidatedDate: never
---

This reference covers YAML syntax for advanced users creating custom gateway configurations. For conceptual information, see [Gateway overview](/docs/new-relic-control/pipeline-control/gateway/overview). For a guided experience, use the [Gateway UI](/docs/new-relic-control/pipeline-control/gateway/ui-guide). While the Gateway UI is recommended for most users, YAML configuration offers full control over the telemetry pipeline structure.

## Complete YAML structure

Gateway configurations use a declarative YAML format:

```yaml
version: "2.0.0"
autoscaling:
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 60
configuration:
  simplified/v1:
    steps:
      receivelogs:
        description: "Receive logs from agents"
        output: ["transform/Logs"]

      transform/Logs:
        description: "Add environment metadata"
        config:
          log_statements:
            - set(attributes["environment"], "production")
        output: ["filter/Logs"]

      filter/Logs:
        description: "Drop debug logs"
        config:
          logs:
            - 'severity.text == "DEBUG"'
        output: ["probabilistic_sampler/Logs"]

      probabilistic_sampler/Logs:
        description: "Sample 10% of logs"
        config:
          globalSamplingPercentage: 10
        output: ["exportlogs"]

      exportlogs:
        description: "Export to New Relic"
        output: []
troubleshooting:
  proxy: false
  requestTraceLogs: false
```
### Top-level structure
- `version`: Configuration format version (currently `"2.0.0"`)
- `autoscaling`: Gateway replica scaling configuration
- `configuration.simplified/v1`: Simplified abstraction layer for defining telemetry pipelines
- `troubleshooting`: Debug settings

## Configuration hierarchy
The Gateway configuration follows a directed acyclic graph (DAG) structure where each step defines its behavior and points to the next step in the pipeline using the output field. This creates an explicit data flow: data enters through receivers, flows through processors (transform, filter, sample), and exits through exporters.

### Step naming conventions

- Receivers: receivelogs, receivemetrics, receivetraces
- Processors: processortype/TelemetryType format:
  - Transform: transform/Logs, transform/Metrics, transform/Traces
  - Filter: filter/Logs, filter/Metrics, filter/Traces
  - Sampling: probabilistic_sampler/Logs, probabilistic_sampler/Metrics, probabilistic_sampler/Traces
- Exporters: exportlogs, exportmetrics, exporttraces

### Processor configurations

Gateway supports three primary processor types for transforming, filtering, and sampling telemetry data.

#### Transform processor

Used for modifying, enriching, or parsing telemetry using OTTL (OpenTelemetry Transformation Language).

Config fields:
- log_statements: Array for log transformations (context: log)
- statements: Array for metrics/traces transformations (context: span)

#### Filter processor
Used to drop telemetry records based on boolean expressions.

Config fields:
- logs: Array of OTTL boolean expressions for log filtering
- spans: Array of OTTL boolean expressions for metric/trace filtering

#### Sampling processor
Used to implement probabilistic sampling logic.

Config fields:
- global_sampling_percentage: Default sampling rate (0-100)
- conditionalSamplingRules: Array of conditional rules
  - name: Rule identifier
  - description: Human-readable description
  - sampling_percentage: Sampling rate for matched data (0-100)
  - source_of_randomness: Field to use for randomness (typically trace.id)
  - condition: Attribute matching expression

## Field reference

### Top-level fields

| Field                                      | Type    | Required | Default |
|--------------------------------------------|---------|----------|---------|
| version                                    | string  | Yes      | -       |
| autoscaling.minReplicas                    | integer | No       | 2       |
| autoscaling.maxReplicas                    | integer | No       | 10      |
| autoscaling.targetCPUUtilizationPercentage | integer | No       | 60      |
| configuration.simplified/v1                | object  | Yes      | -       |
| troubleshooting.proxy                      | boolean | No       | false   |
| troubleshooting.requestTraceLogs           | boolean | No       | false   |

### Step fields

| Field       | Type   | Required    | Description                                           |
|-------------|--------|-------------|-------------------------------------------------------|
| description | string | Recommended | Human-readable description                            |
| config      | object | Conditional | Required for processors, omit for receivers/exporters |
| output      | array  | Yes         | Next step names (empty [] for exporters)              |

## Field naming conventions

- Step-level: camelCase (conditionalSamplingRules, log_statements).
- Config-level: snake_case (global_sampling_percentage, sampling_percentage, source_of_randomness).
- Use exact casing from examples (YAML is case-sensitive).

Each step's output array specifies the next step(s).

## Validation and deployment

1. Validate syntax with an YAML linter.
2. Deploy to non-production environment first.
3. Confirm telemetry reaches New Relic correctly.
4. Upload configuration through the gateway UI.

## Additional resources

- https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/ottlfuncs/README.md
- https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/transformprocessor
- https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/filterprocessor
- https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/probabilisticsamplerprocessor