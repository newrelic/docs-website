---
title: Google Cloud Dataflow monitoring integration
tags:
  - Integrations
  - Google Cloud Platform integrations
  - GCP integrations list
metaDescription: 'New Relic Google Cloud Dataflow integration: the data it reports and how to enable it.'
redirects:
  - /docs/integrations/google-cloud-platform-integrations/gcp-integrations-list/google-cloud-dataflow-monitoring-integration
  - /docs/gcp-gcp_dataflow-integration
---

[New Relic's integrations](/docs/infrastructure/integrations-getting-started/getting-started/introduction-infrastructure-integrations) include an integration for reporting your GCP Dataflow data to our products. Here we explain how to activate the integration and what data it collects.

## Activate integration [#activate]

To enable the integration follow standard procedures to [connect your GCP service to New Relic](/docs/connect-google-cloud-platform-services-infrastructure).

## Configuration and polling [#polling]

You can change the polling frequency and filter data using [configuration options](/docs/integrations/new-relic-integrations/getting-started/configure-polling-frequency-data-collection-cloud-integrations).

Default [polling](/docs/integrations/google-cloud-platform-integrations/getting-started/polling-intervals-gcp-integrations) information for the GCP Dataflow integration:

* New Relic polling interval: 5 minutes

## Find and use data [#find-data]

To find your integration data, go to **[one.newrelic.com](https://one.newrelic.com) > Infrastructure > GCP** and select an integration.

Data is attached to the following [event type](/docs/insights/use-insights-ui/getting-started/introduction-new-relic-insights#event-type):

<table>
  <thead>
    <tr>
      <th>
        Entity
      </th>

      <th>
        Event Type
      </th>

      <th>
        Provider
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Job
      </td>

      <td>
        `GcpDataflowJobSample`
      </td>

      <td>
        `GcpDataflowJob`
      </td>
    </tr>
  </tbody>
</table>

For more on how to use your data, see [Understand and use integration data](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Metric data [#metrics]

This integration collects GCP Dataflow data for Job.

### Dataflow Job data

<table>
  <thead>
    <tr>
      <th style={{ width: "275px" }}>
        Metric
      </th>

      <th style={{ width: "150px" }}>
        Unit
      </th>

      <th>
        Description
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        `job.BillableShuffleDataProcessed`
      </td>

      <td>
        Bytes
      </td>

      <td>
        The billable bytes of shuffle data processed by this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.CurrentNumVcpus`
      </td>

      <td>
        Count
      </td>

      <td>
        The number of vCPUs currently being used by this Dataflow job. This is the current number of workers times the number of vCPUs per worker.
      </td>
    </tr>

    <tr>
      <td>
        `job.CurrentShuffleSlots`
      </td>

      <td>
        Count
      </td>

      <td>
        The current shuffle slots used by this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.DataWatermarkAge`
      </td>

      <td>
        Seconds
      </td>

      <td>
        The age (time since event timestamp) up to which all data has been processed by the pipeline.
      </td>
    </tr>

    <tr>
      <td>
        `job.ElapsedTime`
      </td>

      <td>
        Seconds
      </td>

      <td>
        Duration that the current run of this pipeline has been in the Running state so far, in seconds. When a run completes, this stays at the duration of that run until the next run starts.
      </td>
    </tr>

    <tr>
      <td>
        `job.Elements`
      </td>

      <td>
        Count
      </td>

      <td>
        Number of elements added to the pcollection so far.
      </td>
    </tr>

    <tr>
      <td>
        `job.EstimatedBytes`
      </td>

      <td>
        Bytes
      </td>

      <td>
        An estimated number of bytes added to the pcollection so far. Dataflow calculates the average encoded size of elements in a pcollection and mutiplies it by the number of elements.
      </td>
    </tr>

    <tr>
      <td>
        `job.IsFailed`
      </td>

      <td>
        Count
      </td>

      <td>
        Has this job failed.
      </td>
    </tr>

    <tr>
      <td>
        `job.PerStageDataWatermarkAge`
      </td>

      <td>
        Seconds
      </td>

      <td>
        The age (time since event timestamp) up to which all data has been processed by this stage of the pipeline.
      </td>
    </tr>

    <tr>
      <td>
        `job.PerStageSystemLag`
      </td>

      <td>
        Seconds
      </td>

      <td>
        The current maximum duration that an item of data has been processing or awaiting processing in seconds, per pipeline stage.
      </td>
    </tr>

    <tr>
      <td>
        `job.SystemLag`
      </td>

      <td>
        Seconds
      </td>

      <td>
        The current maximum duration that an item of data has been processing or awaiting processing, in seconds.
      </td>
    </tr>

    <tr>
      <td>
        `job.TotalMemoryUsageTime`
      </td>

      <td>
        Other
      </td>

      <td>
        The total GB seconds of memory allocated to this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.TotalPdUsageTime`
      </td>

      <td>
        Other
      </td>

      <td>
        The total GB seconds for all persistent disk used by all workers associated with this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.TotalShuffleDataProcessed`
      </td>

      <td>
        Bytes
      </td>

      <td>
        The total bytes of shuffle data processed by this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.TotalStreamingDataProcessed`
      </td>

      <td>
        Bytes
      </td>

      <td>
        The total bytes of streaming data processed by this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.TotalVcpuTime`
      </td>

      <td>
        Seconds
      </td>

      <td>
        The total vCPU seconds used by this Dataflow job.
      </td>
    </tr>

    <tr>
      <td>
        `job.UserCounter`
      </td>

      <td>
        Count
      </td>

      <td>
        A user-defined counter metric.
      </td>
    </tr>
  </tbody>
</table>
