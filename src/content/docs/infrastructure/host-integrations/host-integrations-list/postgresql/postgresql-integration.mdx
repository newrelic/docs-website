---
title: PostgreSQL monitoring integration
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: "New Relic's PostgreSQL integration: how to install it and configure it, and what data it reports."
redirects:
  - /docs/integrations/host-integrations/host-integrations-list/postgresql-monitoring-integration
  - /docs/integrations/host-integrations/host-integrations-list/postgresql-monitoring-integration
  - /docs/postgresql-integration-new-relic-infrastructure
  - /docs/postgresql-monitoring-integration
  - /docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration
---

import osLinux from 'images/os_icon_linux.png'

import osWindows from 'images/os_icon_windows.png'

import osEcs from 'images/os_icon_ecs.png'

import osk8 from 'images/os_icon_k8.png'

The New Relic PostgreSQL [on-host integration](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) receives and sends inventory metrics from your PostgreSQL instance to the New Relic platform, where you can aggregate and visualize key performance metrics. Data from instances, databases, and clusters helps you find the source of problems.

To install the PostgreSQL monitoring integration, you must run through the following steps:

1. [Install and activate the integration](#install).
2. [Configure the integration](#config).
3. [PostgreSQL users and permissions](#create-user).
4. [Find and use data](#find-and-use).
5. Optionally, see [PostgreSQL's configuration settings](/docs/infrastructure/host-integrations/host-integrations-list/postgresql/postgresql-config).

<Callout variant="important">
  For best results, regularly [update the integration package](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package) and [the infrastructure agent](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent).
</Callout>

## Compatibility and requirements [#req]

### PostgreSQL versions [#postgresql-versions]

Our integration is compatible with PostgreSQL until version 15.

### Supported managed services [#supported-ms]

* Amazon RDS
* Azure Flexible

### Supported operating systems [#supported-os]

* Windows <img style={{ width: '32px', height: '32px'}} class="inline" title="Windows" alt="Windows" src={osWindows}/>
* Linux <img style={{ width: '32px', height: '32px'}} class="inline" title="Linux" alt="Linux" src={osLinux}/>

For a comprehensive list of specific Windows and Linux versions, check the table of [compatible operating systems](/docs/infrastructure/install-infrastructure-agent/get-started/requirements-infrastructure-agent/#operating-systems).

### System requirements [#system-reqs]

* A New Relic account. Don't have one? [Sign up for free!](https://newrelic.com/signup) No credit card required.
* If PostgreSQL is not running on Kubernetes or Amazon ECS, you can [install the infrastructure agent](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) on a Linux or Windows OS host or on a host capable of remotely accessing where PostgreSQL is installed. Otherwise:
  * If running on <img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src={osk8}/>Kubernetes, see [these requirements](/docs/monitor-service-running-kubernetes#requirements).
  * If running on <img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src={osEcs}/>Amazon ECS, see [these requirements](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).

## Install and activate the integration [#install]

To install the PostgreSQL integration, follow the instructions for your environment.

### Linux installation [#linux]

1. Install [the infrastructure agent](/docs/integrations/host-integrations/installation/install-infrastructure-host-integrations/#install), and replace the `INTEGRATION_FILE_NAME` variable with `nri-postgresql`.
2. Change directory to the integrations configuration folder by running:
   ```shell
   cd /etc/newrelic-infra/integrations.d
   ```
3. Copy the sample configuration file by running:
   ```shell
   sudo cp postgresql-config.yml.sample postgresql-config.yml
   ```
4. Edit the `postgresql-config.yml` configuration file with your favorite editor. Check out some [great configuration file examples.](#examples).
5. Before you restart the infrastructure agent, [create a user](#create-user) with `READ` permissions on the required functions.
6. Restart the infrastructure agent. See how to [restart the infrastructure agent in different Linux environments](/docs/infrastructure/install-infrastructure-agent/manage-your-agent/start-stop-restart-infrastructure-agent/#linux).
7. To enable automatic Postgresql parsing and forwarding, copy or rename the `postgresql-log.yml.example` file to `postgresql-log.yml`. You don't need to restart the agent but you may need to update the YML file with the location of your postgresql log files, if you aren't using the default locations. 

   For example:

       ```shell
       sudo cp /etc/newrelic-infra/logging.d/postgresql-log.yml.example /etc/newrelic-infra/logging.d/postgresql-log.yml
       ```  

### Other environments [#other-env]

<CollapserGroup>
  <Collapser
    id="windows-install"
    title={<><img src={osWindows} title="Windows installation" alt="Windows installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/> Windows installation</>}
  >
    1. Download the `nri-postgresql` .MSI installer image from:

       [https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-postgresql/nri-postgresql-amd64.msi](https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-postgresql/nri-postgresql-amd64.msi)
    2. To install from the Windows command prompt, run:

       ```shell
       msiexec.exe /qn /i PATH\TO\nri-postgresql-amd64.msi
       ```
    3. In the Integrations directory, `C:\Program Files\New Relic\newrelic-infra\integrations.d\`, create a copy of the sample configuration file by running:

       ```shell
       cp postgresql-config.yml.sample postgresql-config.yml
       ```
    4. Edit the `postgresql-config.yml` file as described in [postgresql-config.yml sample files](#examples).
    5. [Restart the infrastructure agent](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status).
  </Collapser>

  <Collapser
    id="ecs-install"
    title={<>
      <img
        src={osEcs}
        title="Amazon ECS installation"
        alt="Amazon ECS installation"
        style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}
      />{' '}
      Amazon ECS installation
    </>}
  >
    See [Monitor service running on ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
  </Collapser>

  <Collapser
    id="k8s-install"
    title={<><img src={osk8} title="Kubernetes installation" alt="Kubernetes installation" style={{ height: '32px', width: '32px', verticalAlign: 'middle' }}/> Kubernetes installation</>}
  >
    See [Monitor service running on
    Kubernetes](/docs/monitor-service-running-kubernetes).
  </Collapser>
</CollapserGroup>

Additional notes:

* **Advanced:** Integrations are also available in [tarball format](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball) to allow for install outside of a package manager.
* **On-host integrations do not automatically update.** For best results, regularly [update the integration package](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package) and [the infrastructure agent](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent).

<InstallFeedback />

## Configure the integration [#config]

There are several ways to configure the integration, depending on how you installed it:

* If enabled via <img style={{ width: '32px', height: '32px'}} class="inline" title="Kubernetes" alt="Kubernetes" src={osk8}/>Kubernetes, see [Monitor services running on Kubernetes](/docs/monitor-service-running-kubernetes).
* If enabled via <img style={{ width: '32px', height: '32px'}} class="inline" title="ECS" alt="ECS" src={osEcs}/>Amazon ECS, see [Monitor services running on ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
* If installed on-host, edit the config in the integration's YAML config file, `postgresql-config.yml`. An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference. The configuration file has common settings applicable to all integrations, such as `interval`, `timeout`, `inventory_source`. To read all about these common settings, refer to our [Configuration Format](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/#configuration-basics) document.

<Callout variant="important">
  If you are still using our legacy configuration or definition files, check the [standard configuration format](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/).
</Callout>

Specific settings related to PostgreSQL are defined using the `env` section of the configuration file. These settings control the connection to your PostgreSQL instance as well as other security settings and features. The list of valid settings is described in the next section of this document.

## PostgreSQL users and permissions [#create-user]

Create a user with `SELECT` permissions on:

* `pg_stat_database`
* `pg_stat_database_conflicts`
* `pg_stat_bgwriter`

To create the user for the PostgreSQL integration:

```sql
CREATE USER new_relic WITH PASSWORD MY_PASSWORD;
GRANT SELECT ON pg_stat_database TO new_relic;
GRANT SELECT ON pg_stat_database_conflicts TO new_relic;
GRANT SELECT ON pg_stat_bgwriter TO new_relic;
```

This will allow the integration to gather global metrics related to the PostgreSQL instance.

If you also want to obtain table and index-related metrics (for example, table size and index size), the PostgreSQL role used by the integration (`new_relic`) also needs `SELECT` permissions on the tables from which it will gather metrics from. For example, to allow the integration to collect metrics from all the tables and indexes present in the database (in the public `schema`), use the following:

```sql
GRANT SELECT ON ALL TABLES IN SCHEMA public TO new_relic;
```

If you also want to obtain query-level metrics from the PostgreSQL custom query config file, the PostgreSQL role used by the integration (`new_relic`)  needs to be added to the (`pg_read_all_stats`) role. This is due to the user leveraging the (`pg_stat_statements`) extension.

```sql
GRANT pg_read_all_stats TO new_relic;
```

Enabling the `pg_stat_statements` extension may require you to manually create it from a query prompt:

```sql
CREATE EXTENSION pg_stat_statements;
```

### postgresql-config.yml sample files [#examples]

<CollapserGroup>
  <Collapser
    id="example-postgresSQL-collection-config"
    title="PostgreSQL configuration collection file"
  >
    * JSON array: Interpreted as a list of database names from which to collect all relevant metrics, including any tables and indexes belonging to that database.

      For example:

      ```yml
      collection_list: '["postgres"]'
      ```

    * JSON object: only entities specified in the object will be collected, no automatic discovery will be performed. The levels of JSON are `database name -> schema name -> table name -> index name`.

      For example:

      ```yml
      collection_list: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
      ```

    * `ALL`: collect metrics for all databases, schemas, tables, and indexes discovered.

      For example:

      ```yml
      collection_list: 'ALL'
      ```

      ```yml
      integrations:
        - name: nri-postgresql
          env:
            USERNAME: postgres
            PASSWORD: pass
            HOSTNAME: psql-sample.localnet
            PORT: 6432
            DATABASE: postgres

            COLLECT_DB_LOCK_METRICS: false
            COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
            TIMEOUT:  10
          interval: 15s
          labels:
            env: production
            role: postgresql
          inventory_source: config/postgresql
      ```
  </Collapser>

  <Collapser
    id="example-postgresSQL-managed-db-service-config"
    title="PostgreSQL Azure Flexible and AWS RDS/Aurora configuration file"
  >
    * Azure/AWS SSL Enabled Options: Azure Flexible managed database offerings require SSL to connect. AWS RDS/Aurora may require SSL if your MySQL version is 5.7+ and require_secure_transport is set to ON in your Aurora Parameter Group. To accomodate the SSL requirement, these settings in the postgresql-config.yml need to be set to `true`.

      For example:

      ```yml
      ENABLE_SSL: "true"
      TRUST_SERVER_CERTIFICATE: "true"
      ```

    * Azure/AWS SSL Disabled Options: In addition to the settings above, the following SSL settings should be commented out or removed from the config. This is due to the config trusting the server certificate above.

      For example:

      ```yml
      # SSL_ROOT_CERT_LOCATION: /etc/newrelic-infra/root_cert.crt
      # SSL_CERT_LOCATION: /etc/newrelic-infra/postgresql.crt
      # SSL_KEY_LOCATION: /etc/newrelic-infra/postgresql.key
      ```

    * Summary: Once these settings are in place, the complete Azure/AWS config file should look like the one below. Note: the infra agent and Postgresql integration should be installed on a host with network access to the database instances.

      For example:

      ```yml
      integrations:
        - name: nri-postgresql
          env:
            USERNAME: newrelic
            PASSWORD: password
            HOSTNAME: AWS-or-Azure-instance-name
            PORT: 5432
            DATABASE: postgres
            COLLECT_DB_LOCK_METRICS: false
            COLLECTION_LIST: 'ALL'
            ENABLE_SSL: "true"
            TRUST_SERVER_CERTIFICATE: "true"
            # SSL_ROOT_CERT_LOCATION: /etc/newrelic-infra/root_cert.crt
            # SSL_CERT_LOCATION: /etc/newrelic-infra/postgresql.crt
            # SSL_KEY_LOCATION: /etc/newrelic-infra/postgresql.key
            TIMEOUT:  10
          interval: 15s
          labels:
            env: production
            role: postgresql
          inventory_source: config/postgresql
      ```
  </Collapser>

  <Collapser
    id="example-postgresSQL-SSL-config"
    title="PostgreSQL SSL configuration collection file"
  >
    ```yml
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres

          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '["postgres"]'
          ENABLE_SSL: true
          TRUST_SERVER_CERTIFICATE: false
          SSL_ROOT_CERT_LOCATION: /etc/newrelic-infra/root_cert.crt
          SSL_CERT_LOCATION: /etc/newrelic-infra/postgresql.crt
          SSL_KEY_LOCATION: /etc/newrelic-infra/postgresql.key
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```
  </Collapser>

  <Collapser
    id="example-postgresSQL-custom-query-config"
    title="PostgreSQL custom query"
  >
    ```yml
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres

          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: ALL
          CUSTOM_METRICS_QUERY: >-
            select
              'rows_inserted' as "metric_name",
              'delta' as "metric_type",
              sd.tup_inserted as "metric_value",
              sd.datid as "database_id"
              from pg_stat_database sd;
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```
  </Collapser>

  <Collapser
    id="example-postgresSQL-custom-query-config-file"
    title="PostgreSQL custom query config file"
  >
    An additional YAML configuration file with one or more custom SQL can be defined and the integration will need the path to the file in the CUSTOM_METRICS_CONFIG parameter.

    * postgresql-config.yml

      ```yml
      integrations:
        - name: nri-postgresql
          env:
            USERNAME: postgres
            PASSWORD: pass
            HOSTNAME: psql-sample.localnet
            PORT: 6432
            DATABASE: postgres

            COLLECT_DB_LOCK_METRICS: false
            COLLECTION_LIST: ALL
            CUSTOM_METRICS_CONFIG: "path/to/postgresql-custom-query.yml"
            TIMEOUT:  10
          interval: 15s
          labels:
            env: production
            role: postgresql
          inventory_source: config/postgresql
      ```

    * postgresql-custom-query.yml

      ```yml
      ---
      queries:

        # Metric names are set to the column names in the query results
        - query: >-
            SELECT
            BG.checkpoints_timed AS scheduled_checkpoints_performed,
            BG.checkpoints_req AS requested_checkpoints_performed,
            BG.buffers_checkpoint AS buffers_written_during_checkpoint,
            BG.buffers_clean AS buffers_written_by_background_writer,
            BG.maxwritten_clean AS background_writer_stops,
            BG.buffers_backend AS buffers_written_by_backend,
            BG.buffers_alloc AS buffers_allocated
            FROM pg_stat_bgwriter BG;

          # database defaults to the auth database in the main config
          database: new_frontier_config_dev

          # If not set explicitly here, metric type will default to
          # 'gauge' for numbers and 'attribute' for strings
          metric_types:
            buffers_allocated: rate

          # If unset, sample_name defaults to PostgresqlCustomSample
          sample_name: MyCustomSample
      ```
  </Collapser>
</CollapserGroup>

For more about the general structure of on-host integration configuration, see [Configuration](/docs/integrations/integrations-sdk/file-specifications/host-integration-configuration-overview).

## Configuration options for the integration [#config-options]

For more on how to find and use your data, see [PostgreSQL's configuration settings](/docs/infrastructure/host-integrations/host-integrations-list/postgresql/postgresql-config).

## Find and use data [#find-and-use]

Data from this service is reported to an [integration dashboard](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts).

Metrics are attached to these [event types](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic):

* [PostgresqlDatabaseSample metrics](#databaseSample)
* [PostgresqlIndexSample metrics](#indexSample)
* [PostgresqlInstanceSample metrics](#instanceSample)
* [PostgresqlTableSample metrics](#tableSample)
* [PgBouncerSample metrics](#pgBouncerSample)

You can [query this data](/docs/using-new-relic/data/understand-data/query-new-relic-data) for troubleshooting purposes or to create custom charts and dashboards.

For more on how to find and use your data, see how to [understand integration data](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Metrics collected by the integration [#metrics]

The PostgreSQL integration collects the following metrics. Some metric names are prefixed with a category indicator and a period, such as `db.` or `index.`.

<CollapserGroup>
  <Collapser
    id="databaseSample"
    title="PostgresqlDatabaseSample metrics"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            PostgreSQLDatabaseSample attributes
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `db.connections`
          </td>

          <td>
            Number of backends currently connected to this database.
          </td>
        </tr>

        <tr>
          <td>
            `db.maxconnections`
          </td>

          <td>
            The maximum number of concurrent connections to the database server.
          </td>
        </tr>

        <tr>
          <td>
            `db.commitsPerSecond`
          </td>

          <td>
            Committed transactions per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.rollbacksPerSecond`
          </td>

          <td>
            Transactions rolled back per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.readsPerSecond`
          </td>

          <td>
            Number of disk blocks read in this database per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.bufferHitsPerSecond`
          </td>

          <td>
            Number of times disk blocks were found already in the buffer cache, so that a read was not necessary. This only includes hits in the PostgreSQL buffer cache, not the operating system's file system cache.
          </td>
        </tr>

        <tr>
          <td>
            `db.rowsReturnedPerSecond`
          </td>

          <td>
            Rows returned by queries per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.rowsFetchedPerSecond`
          </td>

          <td>
            Rows fetched by queries per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.rowsInsertedPerSecond`
          </td>

          <td>
            Rows inserted per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.rowsUpdatedPerSecond`
          </td>

          <td>
            Rows updated per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.rowsDeletedPerSecond`
          </td>

          <td>
            Rows deleted per second.
          </td>
        </tr>

        <tr>
          <td>
            `db.conflicts.tablespacePerSecond`
          </td>

          <td>
            Number of queries in this database that have been canceled due to dropped tablespaces.
          </td>
        </tr>

        <tr>
          <td>
            `db.conflicts.locksPerSecond`
          </td>

          <td>
            Number of queries in this database that have been canceled due to lock timeouts.
          </td>
        </tr>

        <tr>
          <td>
            `db.conflicts.snapshotPerSecond`
          </td>

          <td>
            Number of queries in this database that have been canceled due to old snapshots.
          </td>
        </tr>

        <tr>
          <td>
            `db.conflicts.bufferpinPerSecond`
          </td>

          <td>
            Number of queries in this database that have been canceled due to pinned buffers.
          </td>
        </tr>

        <tr>
          <td>
            `db.conflicts.deadlockPerSecond`
          </td>

          <td>
            Number of queries in this database that have been canceled due to deadlocks.
          </td>
        </tr>

        <tr>
          <td>
            `db.tempFilesCreatedPerSecond`
          </td>

          <td>
            Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (for example, sorting or hashing), and regardless of the `log_temp_files` setting.
          </td>
        </tr>

        <tr>
          <td>
            `db.tempWrittenInBytesPerSecond`
          </td>

          <td>
            Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the `log_temp_files` setting.
          </td>
        </tr>

        <tr>
          <td>
            `db.deadlocksPerSecond`
          </td>

          <td>
            Number of deadlocks detected in this database.
          </td>
        </tr>

        <tr>
          <td>
            `db.readTimeInMillisecondsPerSecond`
          </td>

          <td>
            Time spent reading data file blocks by backends in this database, in milliseconds.
          </td>
        </tr>

        <tr>
          <td>
            `db.writeTimeInMillisecondsPerSecond`
          </td>

          <td>
            Time spent writing data file blocks by backends in this database, in milliseconds.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="indexSample"
    title="PostgresqlIndexSample metrics"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            PostgreSQLIndexSample attributes
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `index.sizeInBytes`
          </td>

          <td>
            The size of an index.
          </td>
        </tr>

        <tr>
          <td>
            `index.rowsReadPerSecond`
          </td>

          <td>
            The number of index entries returned by scans on this index.
          </td>
        </tr>

        <tr>
          <td>
            `index.rowsFetchedPerSecond`
          </td>

          <td>
            The number of index entries fetched by scans on this index.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="instanceSample"
    title="PostgresqlInstanceSample metrics"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            PostgreSQLInstanceSample attributes
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `bgwriter.checkpointsScheduledPerSecond`
          </td>

          <td>
            Number of scheduled checkpoints that have been performed.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.checkpointsRequestedPerSecond`
          </td>

          <td>
            Number of requested checkpoints that have been performed.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.buffersWrittenForCheckpointsPerSecond`
          </td>

          <td>
            Number of buffers written during checkpoints.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.buffersWrittenByBackgroundWriterPerSecond`
          </td>

          <td>
            Number of buffers written by the background writer.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.backgroundWriterStopsPerSecond`
          </td>

          <td>
            Number of times the background writer stopped a cleaning scan because it had written too many buffers.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.buffersWrittenByBackendPerSecond`
          </td>

          <td>
            Number of buffers written directly by a backend.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.buffersAllocatedPerSecond`
          </td>

          <td>
            Number of buffers allocated.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.backendFsyncCallsPerSecond`
          </td>

          <td>
            Number of times a backend had to execute its own `fsync` call. Normally the background writer handles them even when the backend does its own write.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.checkpointWriteTimeInMillisecondsPerSecond`
          </td>

          <td>
            Total amount of time that has been spent in the portion of checkpoint processing where files are written to disk, in milliseconds.
          </td>
        </tr>

        <tr>
          <td>
            `bgwriter.checkpointSyncTimeInMillisecondsPerSecond`
          </td>

          <td>
            Total amount of time that has been spent in the portion of checkpoint processing where files are synchronized to disk, in milliseconds.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="tableSample"
    title="PostgresqlTableSample metrics"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            PostgreSQLTableSample attributes
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `table.totalSizeInBytes`
          </td>

          <td>
            The total disk space used by the table, including indexes and TOAST data.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexSizeInBytes`
          </td>

          <td>
            The total disk space used by indexes attached to the specified table.
          </td>
        </tr>

        <tr>
          <td>
            `table.liveRows`
          </td>

          <td>
            Number of live rows.
          </td>
        </tr>

        <tr>
          <td>
            `table.deadRows`
          </td>

          <td>
            Number of dead rows.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexBlocksReadPerSecond`
          </td>

          <td>
            The number of disk blocks read from all indexes on this table.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexBlocksHitPerSecond`
          </td>

          <td>
            The number of buffer hits in all indexes on this table.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexToastBlocksReadPerSecond`
          </td>

          <td>
            The number of disk blocks read from this table's TOAST table index.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexToastBlocksHitPerSecond`
          </td>

          <td>
            The number of buffer hits in this table's TOAST table index.
          </td>
        </tr>

        <tr>
          <td>
            `table.lastVacuum`
          </td>

          <td>
            Time of last vacuum on table.
          </td>
        </tr>

        <tr>
          <td>
            `table.lastAutoVacuum`
          </td>

          <td>
            Time of last automatic vacuum on table.
          </td>
        </tr>

        <tr>
          <td>
            `table.lastAnalyze`
          </td>

          <td>
            Time of last analyze on table.
          </td>
        </tr>

        <tr>
          <td>
            `table.lastAutoAnalyze`
          </td>

          <td>
            Time of last automatic analyze on table.
          </td>
        </tr>

        <tr>
          <td>
            `table.sequentialScansPerSecond`
          </td>

          <td>
            Number of sequential scans initiated on this table per second.
          </td>
        </tr>

        <tr>
          <td>
            `table.sequentialScanRowsFetchedPerSecond`
          </td>

          <td>
            Number of live rows fetched by sequential scans per second.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexScansPerSecond`
          </td>

          <td>
            Number of index scans initiated on this table.
          </td>
        </tr>

        <tr>
          <td>
            `table.indexScanRowsFetchedPerSecon`
          </td>

          <td>
            Number of live rows fetched by index scans.
          </td>
        </tr>

        <tr>
          <td>
            `table.rowsInsertedPerSecond`
          </td>

          <td>
            Rows inserted per second.
          </td>
        </tr>

        <tr>
          <td>
            `table.rowsUpdatedPerSecond`
          </td>

          <td>
            Rows updated per second.
          </td>
        </tr>

        <tr>
          <td>
            `table.rowsDeletedPerSecond`
          </td>

          <td>
            Rows deleted per second.
          </td>
        </tr>

        <tr>
          <td>
            `table.bloatSizeInBytes`
          </td>

          <td>
            Size of bloat in bytes.
          </td>
        </tr>

        <tr>
          <td>
            `table.dataSizeInBytes`
          </td>

          <td>
            Size of disk spaced used by the main fork of the table.
          </td>
        </tr>

        <tr>
          <td>
            `table.bloatRatio`
          </td>

          <td>
            Fraction of table data size that is bloat.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser
    id="pgBouncerSample"
    title="PgBouncerSample metrics"
  >
    <table>
      <thead>
        <tr>
          <th style={{ width: "350px" }}>
            PgBouncerSample attributes
          </th>

          <th>
            Description
          </th>
        </tr>
      </thead>

      <tbody>
        <tr>
          <td>
            `pgbouncer.stats.transactionsPerSecond`
          </td>

          <td>
            The transaction rate.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.queriesPerSecond`
          </td>

          <td>
            The query rate.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.bytesInPerSecond`
          </td>

          <td>
            The total network traffic received.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.bytesOutPerSecond`
          </td>

          <td>
            The total network traffic sent.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.totalTransactionDurationInMillisecondsPerSecond`
          </td>

          <td>
            Time spent by `pgbouncer` in transaction.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.totalQueryDurationInMillisecondsPerSecond`
          </td>

          <td>
            Time spent by `pgbouncer` actively querying PostgreSQL.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.avgTransactionCount`
          </td>

          <td>
            The average number of transactions per second in last stat period.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.avgTransactionDurationInMilliseconds`
          </td>

          <td>
            The average transaction duration.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.avgQueryCount`
          </td>

          <td>
            The average number of queries per second in last stat period.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.avgBytesIn`
          </td>

          <td>
            The client network traffic received.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.avgBytesOut`
          </td>

          <td>
            The client network traffic sent.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.stats.avgQueryDurationInMilliseconds`
          </td>

          <td>
            The average query duration.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.clientConnectionsActive`
          </td>

          <td>
            Client connections linked to server connection and able to process queries.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.clientConnectionsWaiting`
          </td>

          <td>
            Client connections waiting on a server connection.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.serverConnectionsActive`
          </td>

          <td>
            Server connections linked to a client connection.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.serverConnectionsIdle`
          </td>

          <td>
            Server connections idle and ready for a client query.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.serverConnectionsUsed`
          </td>

          <td>
            Server connections idle more than `server_check_delay`, needing `server_check_query`.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.serverConnectionsTested`
          </td>

          <td>
            Server connections currently running either `server_reset_query` or `server_check_query`.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.serverConnectionsLogin`
          </td>

          <td>
            Server connections currently in the process of logging in.
          </td>
        </tr>

        <tr>
          <td>
            `pgbouncer.pools.maxwaitInMilliseconds`
          </td>

          <td>
            Age of oldest unserved client connection.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>
