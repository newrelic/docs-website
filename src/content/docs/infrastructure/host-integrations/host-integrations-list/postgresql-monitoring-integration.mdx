---
title: PostgreSQL monitoring integration
tags:
  - Integrations
  - On-host integrations
  - On-host integrations list
metaDescription: "New Relic's PostgreSQL integration: how to install it and configure it, and what data it reports."
redirects:
  - /docs/integrations/host-integrations/host-integrations-list/postgresql-monitoring-integration
  - /https%3A/docs.newrelic.com/docs/integrations/host-integrations/host-integrations-list/postgresql-monitoring-integration
  - /docs/postgresql-integration-new-relic-infrastructure
  - /docs/postgresql-monitoring-integration
---

The New Relic PostgreSQL [on-host integration](/docs/integrations/host-integrations/getting-started/introduction-host-integrations) receives and sends inventory metrics from your PostgreSQL instance to the New Relic platform, where you can aggregate and visualize key performance metrics. Data from instances, databases, and clusters helps you find the source of problems.

Read on to install the integration, and to see what data we collect. If you do not have one already, [create a New Relic account](https://newrelic.com/signup). It's free, forever.

## Compatibility and requirements [#comp-req]

Our integration is compatible with PostgreSQL 9.0 or higher.

If PostgreSQL is **not** running on Kubernetes or Amazon ECS, you can [install the infrastructure agent](/docs/infrastructure/install-infrastructure-agent/get-started/install-infrastructure-agent-new-relic) on a Linux or Windows OS host where PostgreSQL is installed or on a host capable of remotely accessing where PostgreSQL is installed. Otherwise:

- If running on Kubernetes, see [these requirements](/docs/monitor-service-running-kubernetes#requirements).
- If running on ECS, see [these requirements](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).

## Quick start [#quick]

Instrument your PostgreSQL instance quickly and send your telemetry data with guided install. Our guided install creates a customized CLI command for your environment that downloads and installs the New Relic CLI and the infrastructure agent.

![A screenshot of the guided install CLI.](./images/guided-install-cli.png 'The guided install CLI.')

Ready to get started? Click one of these button to try it out.

<ButtonGroup>
<ButtonLink
  role="button"
  to="https://one.newrelic.com/launcher/nr1-core.explorer?pane=eyJuZXJkbGV0SWQiOiJucjEtY29yZS5saXN0aW5nIn0=&cards[0]=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJvaGkiLCJyZWNpcGVOYW1lIjoicG9zdGdyZXMtb3Blbi1zb3VyY2UtaW50ZWdyYXRpb24iLCJhY3RpdmVDb21wb25lbnQiOiJWVFNPQ29tbWFuZCIsImFjdGl2ZUVudmlyb25tZW50IjoicG9zdGdyZXMtb3Blbi1zb3VyY2UtaW50ZWdyYXRpb24ifQ=="
  variant="primary"
>
  Guided install
</ButtonLink>

<ButtonLink
  role="button"
  to="https://one.eu.newrelic.com/launcher/nr1-core.explorer?pane=eyJuZXJkbGV0SWQiOiJucjEtY29yZS5saXN0aW5nIn0=&cards[0]=eyJuZXJkbGV0SWQiOiJucjEtaW5zdGFsbC1uZXdyZWxpYy5ucjEtaW5zdGFsbC1uZXdyZWxpYyIsInBhdGgiOiJvaGkiLCJyZWNpcGVOYW1lIjoicG9zdGdyZXMtb3Blbi1zb3VyY2UtaW50ZWdyYXRpb24iLCJhY3RpdmVDb21wb25lbnQiOiJWVFNPQ29tbWFuZCIsImFjdGl2ZUVudmlyb25tZW50IjoicG9zdGdyZXMtb3Blbi1zb3VyY2UtaW50ZWdyYXRpb24ifQ=="
  variant="primary"
>
  EU Guided install
</ButtonLink>
</ButtonGroup>

Our guided install uses the infrastructure agent to set up the PostgreSQL integration. Not only that, it discovers other applications and log sources running in your environment and then recommends which ones you should instrument.

The guided install works with most setups. But if it doesn't suit your needs, you can find other methods below to get started monitoring your PostgreSQL instance.

## Install and activate [#install]

To install the PostgreSQL integration, follow the instructions for your environment:

<CollapserGroup>
  <Collapser
    id="ecs-install"
    title="ECS"
  >
    See [Monitor service running on ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
  </Collapser>

{' '}

<Collapser id="k8s-install" title="Kubernetes">
  See [Monitor service running on
  Kubernetes](/docs/monitor-service-running-kubernetes).
</Collapser>

  <Collapser
    id="linux-install"
    title="Linux"
  >
    1. Follow the procedures to [install the infrastructure integration package](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic) using the file name `nri-postgresql`.
    2. Change directory to the integrations folder:

       ```
       cd /etc/newrelic-infra/integrations.d
       ```
    3. Copy of the [sample configuration file](#example-postgresSQL-config):

       ```
       sudo cp postgresql-config.yml.sample postgresql-config.yml
       ```
    4. Edit the `postgresql-config.yml` file as described in the [configuration settings](#config).
    5. Before you restart the infrastructure agent, [create a user](#create-user) with `READ` permissions on the required functions.
    6. [Restart the infrastructure agent.](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status)

  </Collapser>

  <Collapser
    id="windows-install"
    title="Windows"
  >
    1. Download the `nri-postgresql` .MSI installer image from:

       [https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-postgresql/nri-postgresql-amd64.msi](https://download.newrelic.com/infrastructure_agent/windows/integrations/nri-postgresql/nri-postgresql-amd64.msi)
    2. To install from the Windows command prompt, run:

       ```
       msiexec.exe /qn /i <var>PATH\TO\</var>nri-postgresql-amd64.msi
       ```
    3. In the Integrations directory, `C:\Program Files\New Relic\newrelic-infra\integrations.d\`, create a copy of the sample configuration file by running:

       ```
       cp postgresql-config.yml.sample postgresql-config.yml
       ```
    4. Edit the `postgresql-config.yml` file as described in the [configuration settings](#config).
    5. [Restart the infrastructure agent](/docs/infrastructure/new-relic-infrastructure/configuration/start-stop-restart-check-infrastructure-agent-status).

  </Collapser>
</CollapserGroup>

Additional notes:

- **Advanced:** Integrations are also available in [tarball format](/docs/integrations/host-integrations/installation/install-host-integrations-built-new-relic#tarball) to allow for install outside of a package manager.
- **On-host integrations do not automatically update.** For best results, regularly [update the integration package](/docs/integrations/host-integrations/installation/update-infrastructure-host-integration-package) and [the infrastructure agent](/docs/infrastructure/new-relic-infrastructure/installation/update-infrastructure-agent).

## PostgreSQL users and permissions [#create-user]

Create a user with `SELECT` permissions on:

- `pg_stat_database`
- `pg_stat_database_conflicts`
- `pg_stat_bgwriter`

You can complete this step before or after you [configure the `postgresql-config.yml` file](#config). To create the user for the PostgreSQL integration:

```
CREATE USER new_relic WITH PASSWORD '<var>PASSWORD</var>';
GRANT SELECT ON pg_stat_database TO new_relic;
GRANT SELECT ON pg_stat_database_conflicts TO new_relic;
GRANT SELECT ON pg_stat_bgwriter TO new_relic;
```

This will allow the integration to gather global metrics related to the PostgreSQL instance.

If you also want to obtain table and index-related metrics (for example, table size and index size), the PostgreSQL role used by the integration (`new_relic`) also needs `SELECT` permissions on the tables from which it will gather metrics from. For example, to allow the integration to collect metrics from all the tables and indexes present in the database (in the public `schema`), use the following:

```
GRANT SELECT ON ALL TABLES IN SCHEMA public TO new_relic;
```

## Configure the integration [#config]

An integration's YAML-format configuration is where you can place required login credentials and configure how data is collected. Which options you change depend on your setup and preference.

There are several ways to configure the integration, depending on how it was installed:

- If enabled via Kubernetes: see [Monitor services running on Kubernetes](/docs/monitor-service-running-kubernetes).
- If enabled via Amazon ECS: see [Monitor services running on ECS](/docs/integrations/host-integrations/host-integrations-list/monitor-services-running-amazon-ecs).
- If installed on-host: edit the config in the integration's YAML config file, `postgresql-config.yml`.

Config options are below. For an example configuration, see the [example config file](#example-postgresSQL-collection-config).

The configuration file has common settings applicable to all integrations like `interval`, `timeout`, `inventory_source`. To read all about these common settings refer to our [Configuration Format](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-newer-configuration-format/#configuration-basics) document.

<Callout variant="important">
  If you are still using our Legacy configuration/definition files please refer
  to this
  [document](/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-standard-configuration-format/)
  for help.
</Callout>

Specific settings related to PostgreSQL are defined using the `env` section of the configuration file. These settings control the connection to your PostgreSQL instance as well as other security settings and features. The list of valid settings is described in the next section of this document.

### PostgreSQL Instance Settings [#instance-settings]

The PostgreSQL integration collects both Metrics(<strong>M</strong>) and Inventory(<strong>I</strong>) information. Check the **Applies To** column below to find which settings can be used for each specific collection:

<table>
  <thead>
    <tr>
      <th style={{ width: '150px' }}>Setting</th>
      <th>Description</th>
      <th>Default</th>
      <th>Applies To
    </th>
  </tr>
</thead>

  <tbody>
  <tr>
    <td>
      **HOSTNAME**
    </td>
    <td>
      The hostname for the PostgreSQL connection.
    </td>
    <td>
      localhost
    </td>
    <td style={{ "text-align": "center" }}>
      M/I
    </td>
  </tr>

{' '}

<tr>
  <td>**PORT**</td>
  <td>The port where PostgreSQL is running.</td>
  <td>5432</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**USERNAME**</td>
  <td>The user name for the PostgreSQL connection. **Required.**</td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**PASSWORD**</td>
  <td>The password for the PostgreSQL connection. **Required.**</td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

  <tr>
    <td>
      **COLLECTION_LIST**
    </td>
    <td>
      JSON array, a JSON object, or the string literal `ALL` that specifies the entities to be collected. The PostgreSQL user can only collect table and index metrics from tables it has `SELECT` permissions for.

      **Required except for PgBouncer.**

      [Examples](#example-postgresSQL-collection-config).
    </td>
    <td>
      N/A
    </td>
    <td style={{ "text-align": "center" }}>
      M
    </td>

  </tr>

{' '}

<tr>
  <td>**COLLECTION_IGNORE_DATABASE_LIST**</td>
  <td>
    JSON array of database names that will be ignored for metrics collection.
    Typically useful for cases where `COLLECTION_LIST` is set to `ALL` and some
    databases need to be ignored.
  </td>
  <td>'[]'</td>
  <td style={{ 'text-align': 'center' }}>M</td>
</tr>

{' '}

<tr>
  <td>**PGBOUNCER**</td>
  <td>Collect `pgbouncer` metrics.</td>
  <td>false</td>
  <td style={{ 'text-align': 'center' }}>M</td>
</tr>

{' '}

<tr>
  <td>**ENABLE_SSL**</td>
  <td>
    Determines if SSL is enabled. If `true`, `ssl_cert_location` and
    `ssl_key_location` are required.
  </td>
  <td>false</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**TRUST_SERVER_CERTIFICATE**</td>
  <td>
    If `true`, the server certificate is not verified for SSL. If `false`, the
    server certificate identified in `ssl_root_cert_location` is verified.
  </td>
  <td>false</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**SSL_ROOT_CERT_LOCATION**</td>
  <td>
    Absolute path to PEM-encoded root certificate file. Required if
    `trust_server_certificate` is `false`.
  </td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**SSL_CERT_LOCATION**</td>
  <td>
    Absolute path to PEM-encoded client certificate file. Required if
    `enable_ssl` is `true`.
  </td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**SSL_KEY_LOCATION**</td>
  <td>
    Absolute path to PEM-encoded client key file. Required if `enable_ssl` is
    `true`.
  </td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**TIMEOUT**</td>
  <td>maximum wait for connection, in seconds. Set to `0` for no timeout.</td>
  <td>10</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**DATABASE**</td>
  <td>The PostgreSQL database to connect to.</td>
  <td>postgres</td>
  <td style={{ 'text-align': 'center' }}>M/I</td>
</tr>

{' '}

<tr>
  <td>**CUSTOM_METRICS_QUERY**</td>
  <td>
    A SQL query that required `columns metric_name`, `metric_type`, and
    `metric_value.metric_type` can be `gauge`, `rate`, `delta`, or `attribute`.
    Additional columns collected with the query are added to the metric set as
    attributes.
  </td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M</td>
</tr>

{' '}

<tr>
  <td>**CUSTOM_METRICS_CONFIG**</td>
  <td>
    A path to a YAML file with a list of custom queries, along with their metric
    type, database, and sample name overrides. See example for details.
  </td>
  <td>N/A</td>
  <td style={{ 'text-align': 'center' }}>M</td>
</tr>

{' '}

<tr>
  <td>**COLLECT_DB_LOCK_METRICS**</td>
  <td>
    Enable collecting database lock metrics, which can be performance intensive.
  </td>
  <td>false</td>
  <td style={{ 'text-align': 'center' }}>M</td>
</tr>

{' '}

<tr>
  <td>**COLLECT_BLOAT_METRICS**</td>
  <td>Enable tablespace bloat metrics, which can be performance intensive.</td>
  <td>true</td>
  <td style={{ 'text-align': 'center' }}>M</td>
</tr>

{' '}

<tr>
  <td>**METRICS**</td>
  <td>Set to `true` to enable Metrics only collection.</td>
  <td>false</td>
  <td style={{ 'text-align': 'center' }}></td>
</tr>

{' '}

<tr>
  <td>**INVENTORY**</td>
  <td>Set to `true` to enable Inventory only collection.</td>
  <td>false</td>
  <td style={{ 'text-align': 'center' }}></td>
</tr>

  </tbody>
</table>

The values for these settings can be defined in several ways:

- Adding the value directly in the config file. This is the most common way.
- Replacing the values from environment variables using the `{{}}` notation. This requires infrastructure agent v1.14.0+. Read more [here](/docs/infrastructure/install-infrastructure-agent/configuration/configure-infrastructure-agent/#passthrough).
- Using Secrets management. Use this to protect sensible information such as passwords to be exposed in plain text on the configuration file. For more information, see [Secrets management](/docs/integrations/host-integrations/installation/secrets-management).

### Labels/Custom Attributes [#labels]

Environment variables can be used to control config settings, such as your license key, and are then passed through to the Infrastructure agent. For instructions on how to use this feature, see [Configure the Infrastructure agent](/docs/infrastructure/new-relic-infrastructure/configuration/configure-infrastructure-agent#passthrough).
You can further decorate your metrics using labels. Labels allow you to add key/value pairs attributes to your metrics which you can then use to query, filter or group your metrics on.<br/>
Our default sample config file includes examples of labels but, as they are not mandatory, you can remove, modify or add new ones of your choice.

```
 labels:
   env: production
   role: postgresql
```

### Example configuration [#example-config]

Example `postgresql-config.yml` file configuration:

<CollapserGroup>
  <Collapser
    id="example-postgresSQL-collection-config"
    title="PostgreSQL configuration collection file"
  >

    * JSON array: Interpreted as a list of database names from which to collect all relevant metrics, including any tables and indexes belonging to that database.

    For example:

    ``collection_list: '["postgres"]'``


    * JSON object: only entities specified in the object will be collected, no automatic discovery will be performed. The levels of JSON are `database name -> schema name -> table name -> index name`.

    For example:

    ``collection_list: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'``


    * `ALL`: collect metrics for all databases, schemas, tables, and indexes discovered.

    For example:

    ``collection_list: 'ALL'``


    ```
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres

          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

  </Collapser>

  <Collapser
    id="example-postgresSQL-SSL-config"
    title="PostgreSQL SSL configuration collection file"
  >
    ```
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres

          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: '["postgres"]'
          ENABLE_SSL: true
          TRUST_SERVER_CERTIFICATE: false
          SSL_ROOT_CERT_LOCATION: /etc/newrelic-infra/root_cert.crt
          SSL_CERT_LOCATION: /etc/newrelic-infra/postgresql.crt
          SSL_KEY_LOCATION: /etc/newrelic-infra/postgresql.key
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

  </Collapser>
  <Collapser
    id="example-postgresSQL-custom-query-config"
    title="PostgreSQL custom query"
  >
    ```
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres

          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: ALL
          CUSTOM_METRICS_QUERY: >-
            select
              'rows_inserted' as "metric_name",
              'delta' as "metric_type",
              sd.tup_inserted as "metric_value",
              sd.datid as "database_id"
              from pg_stat_database sd;
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

  </Collapser>
  <Collapser
    id="example-postgresSQL-custom-query-config-file"
    title="PostgreSQL custom query config file"
  >
    An additional YAML configuration file with one or more custom SQL can be defined and the integration will need the path to the file in the CUSTOM_METRICS_CONFIG parameter.

    postgresql-config.yml

    ```
    integrations:
      - name: nri-postgresql
        env:
          USERNAME: postgres
          PASSWORD: pass
          HOSTNAME: psql-sample.localnet
          PORT: 6432
          DATABASE: postgres

          COLLECT_DB_LOCK_METRICS: false
          COLLECTION_LIST: ALL
          CUSTOM_METRICS_CONFIG: "path/to/postgresql-custom-query.yml"
          TIMEOUT:  10
        interval: 15s
        labels:
          env: production
          role: postgresql
        inventory_source: config/postgresql
    ```

    postgresql-custom-query.yml

    ```
    ---
    queries:

      # Metric names are set to the column names in the query results
      - query: >-
          SELECT
          BG.checkpoints_timed AS scheduled_checkpoints_performed,
          BG.checkpoints_req AS requested_checkpoints_performed,
          BG.buffers_checkpoint AS buffers_written_during_checkpoint,
          BG.buffers_clean AS buffers_written_by_background_writer,
          BG.maxwritten_clean AS background_writer_stops,
          BG.buffers_backend AS buffers_written_by_backend,
          BG.buffers_alloc AS buffers_allocated
          FROM pg_stat_bgwriter BG;

        # database defaults to the auth database in the main config
        database: new_frontier_config_dev

        # If not set explicitly here, metric type will default to
        # 'gauge' for numbers and 'attribute' for strings
        metric_types:
          buffers_allocated: rate

        # If unset, sample_name defaults to PostgresqlCustomSample
        sample_name: MyCustomSample
    ```

  </Collapser>
</CollapserGroup>

For more about the general structure of on-host integration configuration, see [Configuration](/docs/integrations/integrations-sdk/file-specifications/host-integration-configuration-overview).

## Find and use data [#find-and-use]

Data from this service is reported to an [integration dashboard](/docs/integrations/new-relic-integrations/getting-started/infrastructure-integration-dashboards-charts).

Metrics are attached to these [event types](/docs/using-new-relic/data/understand-data/new-relic-data-types#events-new-relic):

- [`PostgresqlDatabaseSample`](#databaseSample)
- [`PostgresqlIndexSample`](#indexSample)
- [`PostgresqlInstanceSample`](#instanceSample)
- [`PostgresqlTableSample`](#tableSample)
- [`PgBouncerSample`](#pgBouncerSample)

You can [query this data](/docs/using-new-relic/data/understand-data/query-new-relic-data) for troubleshooting purposes or to create custom charts and dashboards.

For more on how to find and use your data, see [Understand integration data](/docs/infrastructure/integrations/find-use-infrastructure-integration-data).

## Metric data [#metrics]

The PostgreSQL integration collects the following database metric attributes. Some attributes apply to [all PostgreSQL event types](#all-metrics). Some metric names are prefixed with a category indicator and a period, such as `db.` or `index.` metric names.

### PostgresqlDatabaseSample metrics [#databaseSample]

These attributes are attached to the `PostgresqlDatabaseSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLDatabaseSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>

  </thead>

  <tbody>
    <tr>
      <td>
        `db.connections`
      </td>

      <td>
        Number of backends currently connected to this database.
      </td>
    </tr>

    <tr>
      <td>
        `db.maxconnections`
      </td>

      <td>
        The maximum number of concurrent connections to the database server.
      </td>
    </tr>

    <tr>
      <td>
        `db.commitsPerSecond`
      </td>

      <td>
        Committed transactions per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rollbacksPerSecond`
      </td>

      <td>
        Transactions rolled back per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.readsPerSecond`
      </td>

      <td>
        Number of disk blocks read in this database per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.bufferHitsPerSecond`
      </td>

      <td>
        Number of times disk blocks were found already in the buffer cache, so that a read was not necessary. This only includes hits in the PostgreSQL buffer cache, not the operating system's file system cache.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsReturnedPerSecond`
      </td>

      <td>
        Rows returned by queries per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsFetchedPerSecond`
      </td>

      <td>
        Rows fetched by queries per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsInsertedPerSecond`
      </td>

      <td>
        Rows inserted per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsUpdatedPerSecond`
      </td>

      <td>
        Rows updated per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.rowsDeletedPerSecond`
      </td>

      <td>
        Rows deleted per second.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.tablespacePerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to dropped tablespaces.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.locksPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to lock timeouts.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.snapshotPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to old snapshots.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.bufferpinPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to pinned buffers.
      </td>
    </tr>

    <tr>
      <td>
        `db.conflicts.deadlockPerSecond`
      </td>

      <td>
        Number of queries in this database that have been canceled due to deadlocks.
      </td>
    </tr>

    <tr>
      <td>
        `db.tempFilesCreatedPerSecond`
      </td>

      <td>
        Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (for example, sorting or hashing), and regardless of the `log_temp_files` setting.
      </td>
    </tr>

    <tr>
      <td>
        `db.tempWrittenInBytesPerSecond`
      </td>

      <td>
        Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the `log_temp_files` setting.
      </td>
    </tr>

    <tr>
      <td>
        `db.deadlocksPerSecond`
      </td>

      <td>
        Number of deadlocks detected in this database.
      </td>
    </tr>

    <tr>
      <td>
        `db.readTimeInMillisecondsPerSecond`
      </td>

      <td>
        Time spent reading data file blocks by backends in this database, in milliseconds.
      </td>
    </tr>

    <tr>
      <td>
        `db.writeTimeInMillisecondsPerSecond`
      </td>

      <td>
        Time spent writing data file blocks by backends in this database, in milliseconds.
      </td>
    </tr>

  </tbody>
</table>

### PostgresqlIndexSample metrics [#indexSample]

These attributes are attached to the `PostgresqlIndexSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLIndexSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>

  </thead>

  <tbody>
    <tr>
      <td>
        `index.sizeInBytes`
      </td>

      <td>
        The size of an index.
      </td>
    </tr>

    <tr>
      <td>
        `index.rowsReadPerSecond`
      </td>

      <td>
        The number of index entries returned by scans on this index.
      </td>
    </tr>

    <tr>
      <td>
        `index.rowsFetchedPerSecond`
      </td>

      <td>
        The number of index entries fetched by scans on this index.
      </td>
    </tr>

  </tbody>
</table>

### PostgresqlInstanceSample metrics [#instanceSample]

These attributes are attached to the `PostgresqlInstanceSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLInstanceSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>

  </thead>

  <tbody>
    <tr>
      <td>
        `bgwriter.checkpointsScheduledPerSecond`
      </td>

      <td>
        Number of scheduled checkpoints that have been performed.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.checkpointsRequestedPerSecond`
      </td>

      <td>
        Number of requested checkpoints that have been performed.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersWrittenForCheckpointsPerSecond`
      </td>

      <td>
        Number of buffers written during checkpoints.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersWrittenByBackgroundWriterPerSecond`
      </td>

      <td>
        Number of buffers written by the background writer.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.backgroundWriterStopsPerSecond`
      </td>

      <td>
        Number of times the background writer stopped a cleaning scan because it had written too many buffers.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersWrittenByBackendPerSecond`
      </td>

      <td>
        Number of buffers written directly by a backend.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.buffersAllocatedPerSecond`
      </td>

      <td>
        Number of buffers allocated.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.backendFsyncCallsPerSecond`
      </td>

      <td>
        Number of times a backend had to execute its own `fsync` call. Normally the background writer handles them even when the backend does its own write.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.checkpointWriteTimeInMillisecondsPerSecond`
      </td>

      <td>
        Total amount of time that has been spent in the portion of checkpoint processing where files are written to disk, in milliseconds.
      </td>
    </tr>

    <tr>
      <td>
        `bgwriter.checkpointSyncTimeInMillisecondsPerSecond`
      </td>

      <td>
        Total amount of time that has been spent in the portion of checkpoint processing where files are synchronized to disk, in milliseconds.
      </td>
    </tr>

  </tbody>
</table>

### PostgresqlTableSample metrics [#tableSample]

These attributes are attached to the `PostgresqlTableSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PostgreSQLTableSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>

  </thead>

  <tbody>
    <tr>
      <td>
        `table.totalSizeInBytes`
      </td>

      <td>
        The total disk space used by the table, including indexes and TOAST data.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexSizeInBytes`
      </td>

      <td>
        The total disk space used by indexes attached to the specified table.
      </td>
    </tr>

    <tr>
      <td>
        `table.liveRows`
      </td>

      <td>
        Number of live rows.
      </td>
    </tr>

    <tr>
      <td>
        `table.deadRows`
      </td>

      <td>
        Number of dead rows.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexBlocksReadPerSecond`
      </td>

      <td>
        The number of disk blocks read from all indexes on this table.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexBlocksHitPerSecond`
      </td>

      <td>
        The number of buffer hits in all indexes on this table.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexToastBlocksReadPerSecond`
      </td>

      <td>
        The number of disk blocks read from this table's TOAST table index.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexToastBlocksHitPerSecond`
      </td>

      <td>
        The number of buffer hits in this table's TOAST table index.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastVacuum`
      </td>

      <td>
        Time of last vacuum on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastAutoVacuum`
      </td>

      <td>
        Time of last automatic vacuum on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastAnalyze`
      </td>

      <td>
        Time of last analyze on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.lastAutoAnalyze`
      </td>

      <td>
        Time of last automatic analyze on table.
      </td>
    </tr>

    <tr>
      <td>
        `table.sequentialScansPerSecond`
      </td>

      <td>
        Number of sequential scans initiated on this table per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.sequentialScanRowsFetchedPerSecond`
      </td>

      <td>
        Number of live rows fetched by sequential scans per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexScansPerSecond`
      </td>

      <td>
        Number of index scans initiated on this table.
      </td>
    </tr>

    <tr>
      <td>
        `table.indexScanRowsFetchedPerSecon`
      </td>

      <td>
        Number of live rows fetched by index scans.
      </td>
    </tr>

    <tr>
      <td>
        `table.rowsInsertedPerSecond`
      </td>

      <td>
        Rows inserted per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.rowsUpdatedPerSecond`
      </td>

      <td>
        Rows updated per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.rowsDeletedPerSecond`
      </td>

      <td>
        Rows deleted per second.
      </td>
    </tr>

    <tr>
      <td>
        `table.bloatSizeInBytes`
      </td>

      <td>
        Size of bloat in bytes.
      </td>
    </tr>

    <tr>
      <td>
        `table.dataSizeInBytes`
      </td>

      <td>
        Size of disk spaced used by the main fork of the table.
      </td>
    </tr>

    <tr>
      <td>
        `table.bloatRatio`
      </td>

      <td>
        Fraction of table data size that is bloat.
      </td>
    </tr>

  </tbody>
</table>

### PgBouncerSample metrics [#pgBouncerSample]

These attributes are attached to the `PgBouncerSample` event type:

<table>
  <thead>
    <tr>
      <th style={{ width: "350px" }}>
        PgBouncerSample attributes
      </th>

      <th>
        Description
      </th>
    </tr>

  </thead>

  <tbody>
    <tr>
      <td>
        `pgbouncer.stats.transactionsPerSecond`
      </td>

      <td>
        The transaction rate.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.queriesPerSecond`
      </td>

      <td>
        The query rate.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.bytesInPerSecond`
      </td>

      <td>
        The total network traffic received.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.bytesOutPerSecond`
      </td>

      <td>
        The total network traffic sent.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.totalTransactionDurationInMillisecondsPerSecond`
      </td>

      <td>
        Time spent by `pgbouncer` in transaction.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.totalQueryDurationInMillisecondsPerSecond`
      </td>

      <td>
        Time spent by `pgbouncer` actively querying PostgreSQL.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgTransactionCount`
      </td>

      <td>
        The average number of transactions per second in last stat period.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgTransactionDurationInMilliseconds`
      </td>

      <td>
        The average transaction duration.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgQueryCount`
      </td>

      <td>
        The average number of queries per second in last stat period.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgBytesIn`
      </td>

      <td>
        The client network traffic received.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgBytesOut`
      </td>

      <td>
        The client network traffic sent.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.stats.avgQueryDurationInMilliseconds`
      </td>

      <td>
        The average query duration.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.clientConnectionsActive`
      </td>

      <td>
        Client connections linked to server connection and able to process queries.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.clientConnectionsWaiting`
      </td>

      <td>
        Client connections waiting on a server connection.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsActive`
      </td>

      <td>
        Server connections linked to a client connection.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsIdle`
      </td>

      <td>
        Server connections idle and ready for a client query.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsUsed`
      </td>

      <td>
        Server connections idle more than `server_check_delay`, needing `server_check_query`.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsTested`
      </td>

      <td>
        Server connections currently running either `server_reset_query` or `server_check_query`.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.serverConnectionsLogin`
      </td>

      <td>
        Server connections currently in the process of logging in.
      </td>
    </tr>

    <tr>
      <td>
        `pgbouncer.pools.maxwaitInMilliseconds`
      </td>

      <td>
        Age of oldest unserved client connection.
      </td>
    </tr>

  </tbody>
</table>

## Inventory data [#inventory]

The PostgreSQL integration collects each setting from `pg_settings` along with its `boot_val` and `reset_val`. The [inventory data](/docs/infrastructure/integrations-getting-started/getting-started/understand-integration-data-data-types#inventory-data) appears on the [Inventory page](/docs/infrastructure/new-relic-infrastructure/infrastructure-ui-pages/infrastructure-inventory-page-search-your-entire-infrastructure), under the **config/postgresql** source.

## Troubleshooting

Here are some troubleshooting tips for the PostgreSQL integration:

- If you have connection problems, make sure you can connect to the cluster from the same box with `psql`.
- If you have problems collecting `PgBouncer` metrics, make sure you are connected to the instance through `PgBouncer`. Default port is `6432`.
- If you get the error message `Error creating list of entities to collect: pq: unsupported startup parameter: extra_float_digits`, set `ignore_startup_parameters = extra_float_digits` in the PgBouncer config file.

## Check the source code [#source-code]

This integration is open source software. That means you can [browse its source code](https://github.com/newrelic/nri-postgresql 'Link opens in a new window.') and send improvements, or create your own fork and build it.
