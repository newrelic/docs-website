---
title: Monitor Elasticsearch with OpenTelemetry
tags:
  - OpenTelemetry
  - Elasticsearch
  - Integrations
  - On-host integrations
  - OTEL
  - Monitoring
description: Get complete visibility into your Elasticsearch clusters with pre-built dashboards, intelligent alerts, and seamless integration with your existing observability stack.
---

The New Relic Elasticsearch OpenTelemetry (OTel) integration provides comprehensive observability for your Elasticsearch clusters using industry-standard OpenTelemetry protocols. By leveraging the OpenTelemetry Collector, you get a unified pipeline that efficiently collects both metrics and logs from your Elasticsearch infrastructure, ensuring fast and reliable monitoring that integrates directly with New Relic.

<Callout variant="important">
**Choose your monitoring approach:** This OpenTelemetry-based integration offers modern, vendor-neutral monitoring. If you prefer our traditional approach or need specific compatibility, see our [standard Elasticsearch integration](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch/elasticsearch-integration).
</Callout>

**Why choose this OpenTelemetry approach?**
- **Unified data collection**: Single collector handles metrics, logs, and traces from Elasticsearch and host systems.
- **Vendor neutrality**: Uses open-source standards that work with any observability platform - no vendor lock-in.
- **High performance**: Built-in batching, compression, and cardinality reduction minimize resource impact.
- **Future-proof architecture**: Built on evolving open standards that adapt as your infrastructure grows.
- **Native New Relic integration**: Optimized data processing and seamless dashboard experience.

**Use case:** An e-commerce company uses Elasticsearch for their product search feature. Using this integration, their operations team can see if their search service is healthy, how fast searches are responding, and get notified before memory runs out - all from one dashboard. When customers start complaining about slow search results, the team can quickly see if it's an Elasticsearch problem, a server issue, or something else by viewing all their monitoring data together.

<img
  title="Elasticsearch OpenTelemetry monitoring dashboard"
  alt="Screenshot showing Elasticsearch cluster health, performance metrics, and resource usage in New Relic dashboards"
  src="/images/elasticsearch-otel-solution.png"
/>

## What you'll get

Monitor your Elasticsearch infrastructure with:

* **Cluster health monitoring**: Track node status, shard distribution, and cluster state in real-time.
* **Performance insights**: Monitor search latency, indexing rates, and JVM performance metrics.
* **Resource utilization**: View CPU, memory, disk, and network usage across all nodes.
* **Proactive alerting**: Get notified before issues impact your users with intelligent thresholds.
* **Full-stack correlation**: Connect Elasticsearch metrics with application and infrastructure data.

<Callout variant="tip">
**Ready to get started?** This integration takes about 15-20 minutes to set up. [Install the Elasticsearch OpenTelemetry integration](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-otel/elasticsearch-otel-integration-install).
</Callout>

---

## Key metrics at a glance

Monitor your Elasticsearch cluster health and performance with these essential metrics:

<table>
  <thead>
    <tr>
      <th style={{ width: "200px" }}>Metric category</th>
      <th>What it measures</th>
      <th style={{ width: "120px" }}>Priority</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>**Cluster health**</td>
      <td>`elasticsearch.cluster.health` - Overall cluster status (green/yellow/red)</td>
      <td>ðŸ”´ Critical</td>
    </tr>
    <tr>
      <td>**Shard status**</td>
      <td>`elasticsearch.cluster.shards` - Unassigned, relocating, or initializing shards</td>
      <td>ðŸ”´ Critical</td>
    </tr>
    <tr>
      <td>**Node availability**</td>
      <td>`elasticsearch.cluster.data_nodes` - Active data nodes in cluster</td>
      <td>ðŸ”´ Critical</td>
    </tr>
    <tr>
      <td>**JVM heap usage**</td>
      <td>`jvm.memory.heap.utilization` - Memory usage percentage</td>
      <td>ðŸ”´ Critical</td>
    </tr>
    <tr>
      <td>**Search performance**</td>
      <td>`elasticsearch.node.operations.time` - Query and fetch latency</td>
      <td>ðŸŸ¡ Important</td>
    </tr>
    <tr>
      <td>**Indexing performance**</td>
      <td>`elasticsearch.node.operations.time` - Index and delete operation timing</td>
      <td>ðŸŸ¡ Important</td>
    </tr>
    <tr>
      <td>**Circuit breakers**</td>
      <td>`elasticsearch.breaker.tripped` - Memory protection triggers</td>
      <td>ðŸŸ¡ Important</td>
    </tr>
    <tr>
      <td>**Resource usage**</td>
      <td>`system.cpu.utilization`, `system.memory.usage` - Host system resources</td>
      <td>ðŸ”µ Monitoring</td>
    </tr>
  </tbody>
</table>

## Complete metrics reference

The integration collects 60+ metrics across cluster, node, JVM, and host infrastructure. Expand the sections below for detailed metric specifications.

<Callout variant="tip">
For the complete catalog of available metrics, see the OpenTelemetry [`elasticsearchreceiver`](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/elasticsearchreceiver) and [`hostmetricsreceiver`](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/hostmetricsreceiver) documentation.
</Callout>

<CollapserGroup>
  <Collapser id="cluster-core" title="Cluster health & circuit breaker metrics (elasticsearchreceiver)">
    <table>
      <thead>
        <tr>
          <th style={{ width: "260px" }}>Metric</th>
          <th>Description</th>
          <th style={{ width: "240px" }}>Attributes</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>`elasticsearch.cluster.in_flight_fetch`</td>
          <td>Shard fetch operations still in flight.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.cluster.nodes`</td>
          <td>Total cluster node count.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.cluster.pending_tasks`</td>
          <td>Pending cluster-level tasks awaiting execution.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.cluster.state_update.time`</td>
          <td>Cumulative time spent updating cluster state.</td>
          <td>
            <InlineCode>state</InlineCode> (any) <br />
            <InlineCode>type</InlineCode> (computation, context_construction, commit, completion, master_apply, notification)
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="index-metrics" title="Index activity metrics (elasticsearchreceiver)">
    <table>
      <thead>
        <tr>
          <th style={{ width: "260px" }}>Metric</th>
          <th>Description</th>
          <th style={{ width: "260px" }}>Attributes</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>`elasticsearch.index.documents`</td>
          <td>Documents per index, split by state.</td>
          <td>
            <InlineCode>state</InlineCode> (active | deleted)<br />
            <InlineCode>aggregation</InlineCode> (primary_shards | total)
          </td>
        </tr>
        <tr>
          <td>`elasticsearch.index.operations.merge.current`</td>
          <td>Active segment merge operations.</td>
          <td><InlineCode>aggregation</InlineCode> (primary_shards | total)</td>
        </tr>
        <tr>
          <td>`elasticsearch.index.operations.time`</td>
          <td>Time spent on index-level operations.</td>
          <td>
            <InlineCode>operation</InlineCode> (index, delete, get, query, fetch, scroll, suggest, merge, refresh, flush, warmer)<br />
            <InlineCode>aggregation</InlineCode> (primary_shards | total)
          </td>
        </tr>
        <tr>
          <td>`elasticsearch.indexing_pressure.memory.total.primary_rejections`</td>
          <td>Cumulative primary-stage indexing rejections.</td>
          <td>â€”</td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="node-activity" title="Node activity & workload metrics (elasticsearchreceiver)">
    <table>
      <thead>
        <tr>
          <th style={{ width: "260px" }}>Metric</th>
          <th>Description</th>
          <th style={{ width: "260px" }}>Attributes</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>`elasticsearch.node.cache.count`</td>
          <td>Query cache hits and misses across node shards.</td>
          <td><InlineCode>type</InlineCode> (hit | miss)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.cache.evictions`</td>
          <td>Node cache evictions.</td>
          <td><InlineCode>cache_name</InlineCode> (fielddata | query)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.cache.memory.usage`</td>
          <td>Cache memory usage in bytes.</td>
          <td><InlineCode>cache_name</InlineCode> (fielddata | query)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.cluster.io`</td>
          <td>Internal cluster network I/O in bytes.</td>
          <td><InlineCode>direction</InlineCode> (received | sent)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.documents`</td>
          <td>Documents hosted by the node.</td>
          <td><InlineCode>state</InlineCode> (active | deleted)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.disk.io.read`</td>
          <td>Disk read throughput (KiB) across file stores.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.disk.io.write`</td>
          <td>Disk write throughput (KiB) across file stores.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.fs.disk.available`</td>
          <td>Disk available to the JVM.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.fs.disk.total`</td>
          <td>Total disk capacity on the node.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.http.connections`</td>
          <td>HTTP connections served by the node.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.ingest.documents.current`</td>
          <td>Documents currently being ingested.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.ingest.operations.failed`</td>
          <td>Cumulative ingest failures.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.open_files`</td>
          <td>Open file descriptors in use.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.operations.completed`</td>
          <td>Operations completed by the node.</td>
          <td><InlineCode>operation</InlineCode> (index, delete, get, query, fetch, scroll, suggest, merge, refresh, flush, warmer)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.operations.current`</td>
          <td>Operations currently in progress.</td>
          <td><InlineCode>operation</InlineCode> (same set)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.operations.get.completed`</td>
          <td>GET hits and misses.</td>
          <td><InlineCode>result</InlineCode> (hit | miss)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.operations.get.time`</td>
          <td>Time spent serving GET hits/misses.</td>
          <td><InlineCode>result</InlineCode> (hit | miss)</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.shards.reserved.size`</td>
          <td>Predicted shard growth due to recoveries.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.node.thread_pool.tasks.finished`</td>
          <td>Tasks finished (or rejected) per thread pool.</td>
          <td>
            <InlineCode>thread_pool_name</InlineCode> (any)<br />
            <InlineCode>state</InlineCode> (rejected | completed)
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="jvm-metrics" title="JVM & OS metrics reported by Elasticsearch (elasticsearchreceiver)">
    <table>
      <thead>
        <tr>
          <th style={{ width: "260px" }}>Metric</th>
          <th>Description</th>
          <th style={{ width: "260px" }}>Attributes</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>`elasticsearch.os.cpu.load_avg.1m`</td>
          <td>One-minute OS load average.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.os.cpu.load_avg.5m`</td>
          <td>Five-minute OS load average.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.os.cpu.load_avg.15m`</td>
          <td>Fifteen-minute OS load average.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`elasticsearch.os.memory`</td>
          <td>Physical memory usage as seen by Elasticsearch.</td>
          <td><InlineCode>state</InlineCode> (free | used)</td>
        </tr>
        <tr>
          <td>`jvm.gc.collections.count`</td>
          <td>Total garbage collection runs.</td>
          <td><InlineCode>name</InlineCode> (collector name)</td>
        </tr>
        <tr>
          <td>`jvm.gc.collections.elapsed`</td>
          <td>Time spent in garbage collection.</td>
          <td><InlineCode>name</InlineCode> (collector name)</td>
        </tr>
        <tr>
          <td>`jvm.memory.heap.max`</td>
          <td>Maximum heap memory available.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`jvm.memory.heap.used`</td>
          <td>Heap memory currently in use.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`jvm.threads.count`</td>
          <td>Active JVM thread count.</td>
          <td>â€”</td>
        </tr>
      </tbody>
    </table>
  </Collapser>

  <Collapser id="hostmetrics" title="Host infrastructure metrics (hostmetricsreceiver)">
    <table>
      <thead>
        <tr>
          <th style={{ width: "280px" }}>Metric</th>
          <th>Description</th>
          <th style={{ width: "220px" }}>Attributes</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>`system.cpu.time`</td>
          <td>Cumulative CPU time split by state.</td>
          <td>
            <InlineCode>cpu</InlineCode> (logical CPU)<br />
            <InlineCode>state</InlineCode> (same set as above)
          </td>
        </tr>
        <tr>
          <td>`system.cpu.load_average.1m`</td>
          <td>One-minute system load average.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`system.cpu.load_average.5m`</td>
          <td>Five-minute system load average.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`system.cpu.load_average.15m`</td>
          <td>Fifteen-minute system load average.</td>
          <td>â€”</td>
        </tr>
        <tr>
          <td>`system.memory.utilization`</td>
          <td>Memory utilization ratio.</td>
          <td><InlineCode>state</InlineCode> (used)</td>
        </tr>
        <tr>
          <td>`system.disk.io`</td>
          <td>Disk I/O throughput per device.</td>
          <td>
            <InlineCode>device</InlineCode> (disk)<br />
            <InlineCode>direction</InlineCode> (read | write)
          </td>
        </tr>
        <tr>
          <td>`system.disk.operations`</td>
          <td>Disk operations per device.</td>
          <td>
            <InlineCode>device</InlineCode><br />
            <InlineCode>direction</InlineCode> (read | write)
          </td>
        </tr>
        <tr>
          <td>`system.filesystem.usage`</td>
          <td>Filesystem capacity by state.</td>
          <td>
            <InlineCode>device</InlineCode><br />
            <InlineCode>state</InlineCode> (used | free | reserved)
          </td>
        </tr>
        <tr>
          <td>`system.filesystem.utilization`</td>
          <td>Filesystem utilization ratio.</td>
          <td>
            <InlineCode>device</InlineCode><br />
            <InlineCode>state</InlineCode> (used)
          </td>
        </tr>
        <tr>
          <td>`system.network.io`</td>
          <td>Network bytes per interface.</td>
          <td>
            <InlineCode>interface</InlineCode><br />
            <InlineCode>direction</InlineCode> (receive | transmit)
          </td>
        </tr>
        <tr>
          <td>`system.network.packets`</td>
          <td>Network packets per interface.</td>
          <td>
            <InlineCode>interface</InlineCode><br />
            <InlineCode>direction</InlineCode> (receive | transmit)
          </td>
        </tr>
        <tr>
          <td>`process.cpu.utilization`</td>
          <td>Percentage of total CPU time used by the process since last scrape, expressed as a value between 0 and 1.</td>
          <td>
            <InlineCode>process.pid</InlineCode> (PID)<br />
            <InlineCode>process.executable.name</InlineCode> (binary name)<br />
            <InlineCode>process.owner</InlineCode> (user)<br />
            <InlineCode>state</InlineCode> (user | system | other)
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Resource Attributes [#resource-attributes]

The following attributes are attached to all metrics to provide identity context within New Relic:

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>Name</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`elasticsearch.cluster.name`</td>
      <td>The name of the elasticsearch cluster.</td>
    </tr>
  </tbody>
</table>

---

## Next steps

After reviewing the metrics and understanding what this integration provides:

1. **[Install the integration](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-otel/elasticsearch-otel-integration-install)** - Follow the step-by-step setup guide.
2. **Set up alerts** - Configure proactive monitoring for critical metrics like cluster health and heap usage.
3. **Create custom dashboards** - Build views tailored to your specific Elasticsearch use cases.
4. **Explore related integrations** - Consider monitoring your application stack with other [OpenTelemetry integrations](/docs/opentelemetry/get-started/opentelemetry-set-up-your-app).