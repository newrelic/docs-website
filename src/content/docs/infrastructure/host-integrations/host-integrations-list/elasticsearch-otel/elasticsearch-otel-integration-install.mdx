---
title: Install Elasticsearch OpenTelemetry integration
tags:
  - OpenTelemetry
  - Elasticsearch
  - Integrations
metaDescription: "Install and configure the OpenTelemetry Collector to monitor Elasticsearch clusters and send data to New Relic."
redirects:
  - /install/elasticsearch-otel
---

Install the New Relic Elasticsearch OpenTelemetry integration to monitor your Elasticsearch clusters with industry-standard protocols. This guide walks you through configuring the OpenTelemetry Collector to collect metrics and logs from your Elasticsearch infrastructure and send them to New Relic.



To install the integration, complete the following steps:

1. [Before you begin](#prerequisites) - Check requirements and prerequisites
2. [Configure the OpenTelemetry Collector](#config) - Set up data collection
3. [Set environment variables](#start) - Configure authentication
4. [Find and use data](#find-and-use) - View your Elasticsearch data in New Relic
5. [Set up alerts](#alerts) - Configure proactive monitoring


## Step 1: Before you begin [#prerequisites]

Ensure you have:

* **Required access privileges** - Elasticsearch cluster admin privileges and New Relic account with <InlinePopover type="licenseKey"/> access
* **Elasticsearch version 7.16 or higher** - This integration requires a modern Elasticsearch cluster
* **Monitor or manage cluster privileges** - If security is enabled, you need either monitor or manage cluster privilege. See the [Elasticsearch security privileges](https://www.elastic.co/docs/reference/elasticsearch/security-privileges) documentation for more details
* **Network connectivity** - Outbound HTTPS connectivity (port 443) to [New Relic's OTLP ingest endpoint](/docs/opentelemetry/best-practices/opentelemetry-otlp)
* **OpenTelemetry Collector** - [OpenTelemetry Collector Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/latest) installed and running on your host. Install via an official package (.deb or .rpm) to ensure the systemd service unit is created correctly
* **Configuration values ready** - You'll need two key values for the configuration:
  * **Elasticsearch endpoint** - Your actual Elasticsearch URL (replace `https://localhost:9200`)
  * **Cluster name** - A unique name to identify your cluster in New Relic


## Step 2: Configure the OpenTelemetry Collector [#config]

Configure the OpenTelemetry Collector to collect metrics and logs from your Elasticsearch cluster. Create or update your configuration file at `/etc/otelcol-contrib/config.yaml`.

The configuration varies based on your Elasticsearch setup and monitoring requirements. Choose the appropriate configuration below:

<CollapserGroup>

   <Collapser id="basic-config" title="Basic Metrics Configuration">
    **Start here if you have:** An unsecured Elasticsearch cluster without authentication or SSL.

    This configuration collects comprehensive metrics from Elasticsearch and host system without authentication:

    <Callout variant="important">
    Replace the `endpoint` value with your Elasticsearch cluster endpoint and update `elasticsearch.cluster.name` in the processor block with a unique name to uniquely identify your cluster in New Relic.
    </Callout>
    
    ```yaml
    # =================================================================================================
# OpenTelemetry Collector Configuration for Elasticsearch and Host
# This configuration collects metrics and logs for a complete observability solution.
# =================================================================================================
# -------------------------------------------------------------------------------------------------
# Receivers
# Receivers define how data gets into the Collector. This config uses four receivers:
# - elasticsearch: to scrape metrics from the Elasticsearch API
# - hostmetrics: to collect system-level metrics from the host itself
# - filelog: to tail Elasticsearch log files
# - otlp: to accept data from other OpenTelemetry-instrumented services
# -------------------------------------------------------------------------------------------------
receivers:
  # The dedicated receiver for Elasticsearch.
  # It automatically discovers the cluster name.
  elasticsearch:
    endpoint: "https://localhost:9200"
    collection_interval: 15s
    metrics:
      elasticsearch.breaker.tripped:
        enabled: true
      elasticsearch.cluster.data_nodes:
        enabled: true
      elasticsearch.cluster.health:
        enabled: true
      elasticsearch.cluster.in_flight_fetch:
        enabled: true
      elasticsearch.cluster.nodes:
        enabled: true
      elasticsearch.cluster.pending_tasks:
        enabled: true
      elasticsearch.cluster.shards:
        enabled: true
      elasticsearch.cluster.state_update.time:
        enabled: true
      elasticsearch.index.documents:
        enabled: true
      elasticsearch.index.operations.merge.current:
        enabled: true
      elasticsearch.index.operations.time:
        enabled: true
      elasticsearch.indexing_pressure.memory.total.primary_rejections:
        enabled: true
      elasticsearch.node.cache.count:
        enabled: true
      elasticsearch.node.cache.evictions:
        enabled: true
      elasticsearch.node.cache.memory.usage:
        enabled: true
      elasticsearch.node.cluster.io:
        enabled: true
      elasticsearch.node.documents:
        enabled: true
      elasticsearch.node.disk.io.read:
        enabled: true
      elasticsearch.node.disk.io.write:
        enabled: true
      elasticsearch.node.fs.disk.available:
        enabled: true
      elasticsearch.node.fs.disk.total:
        enabled: true
      elasticsearch.node.http.connections:
        enabled: true
      elasticsearch.node.ingest.documents.current:
        enabled: true
      elasticsearch.node.ingest.operations.failed:
        enabled: true
      elasticsearch.node.open_files:
        enabled: true
      elasticsearch.node.operations.completed:
        enabled: true
      elasticsearch.node.operations.current:
        enabled: true
      elasticsearch.node.operations.get.completed:
        enabled: true
      elasticsearch.node.operations.get.time:
        enabled: true
      elasticsearch.node.operations.time:
        enabled: true
      elasticsearch.node.shards.reserved.size:
        enabled: true
      elasticsearch.node.thread_pool.tasks.finished:
        enabled: true
      elasticsearch.os.cpu.load_avg.1m:
        enabled: true
      elasticsearch.os.cpu.load_avg.5m:
        enabled: true
      elasticsearch.os.cpu.load_avg.15m:
        enabled: true
      elasticsearch.os.memory:
        enabled: true
      jvm.gc.collections.count:
        enabled: true
      jvm.gc.collections.elapsed:
        enabled: true
      jvm.memory.heap.max:
        enabled: true
      jvm.memory.heap.used:
        enabled: true
      jvm.memory.heap.utilization:
        enabled: true
      jvm.threads.count:
        enabled: true
  hostmetrics:
    collection_interval: 60s # Recommended for cost savings and stability
    scrapers:
      cpu:
        metrics:
          # CPU Utilization and Time are the core metrics
          system.cpu.utilization: {enabled: true}
          system.cpu.time: {enabled: true}
      
      load:
        metrics:
          # Load Averages (used for system health dashboards)
          system.cpu.load_average.1m: {enabled: true}
          system.cpu.load_average.5m: {enabled: true}
          system.cpu.load_average.15m: {enabled: true}
      
      memory:
        metrics:
          # Memory Usage and Utilization
          system.memory.usage: {enabled: true}
          system.memory.utilization: {enabled: true}
      
      disk:
        metrics:
          # Disk I/O operations (throughput)
          system.disk.io: {enabled: true}
          system.disk.operations: {enabled: true}
      
      filesystem:
        metrics:
          # Filesystem usage (disk space capacity)
          system.filesystem.usage: {enabled: true}
          system.filesystem.utilization: {enabled: true}
          
      network:
        # Since this was already working, keeping it simple is best.
        # But for completeness:
        metrics:
          system.network.io: {enabled: true}
          system.network.packets: {enabled: true}
      process:
        metrics:
          process.cpu.utilization:
            enabled: true
        
# -------------------------------------------------------------------------------------------------
# Processors
# -------------------------------------------------------------------------------------------------
processors:
  cumulativetodelta: {}
  resource/cluster_name_override:
    attributes:
      # Use the actual cluster name defined in your Elasticsearch config
      - key: elasticsearch.cluster.name
        value: "<elasticsearch-cluster-name>" # <-- REPLACE THIS WITH A UNIQUE CLUSTER NAME TO UNIQUELY IDENTIFY YOUR CLUSTER IN NEW RELIC
        action: upsert
  resourcedetection:
    detectors: [ system ]
    system:
      resource_attributes:
        host.name:
          enabled: true
        host.id:
          enabled: true
        os.type:
          enabled: true 
  # This processor batches data for more efficient sending.
  batch:
    timeout: 10s
    send_batch_size: 1024
  # 1. CARDINALITY REDUCTION: Drops volatile or redundant attributes
  attributes/cardinality_reduction:
    actions:
      # Filter out VOLATILE PROCESS IDS (High churn)
      - key: process.pid
        action: delete
      - key: process.parent_pid
        action: delete
      # Filter out REDUNDANT/STATIC METADATA (Already known at the Resource level)
      - key: elasticsearch.node.version
        action: delete
      - key: os.type
        action: delete
  transform/metadata_nullify:
    # We use 'metric_statements' to run OTTL logic on the metric signal
    metric_statements:
      - context: metric  # <-- Targets the high-level Metric structure itself
        statements:
          # Sets the 'description' field to an empty string ("")
          - set(description, "")
          # Sets the 'unit' field to an empty string ("")
          - set(unit, "")      
exporters:
  # This exporter sends all data to New Relic via OTLP/HTTP.
  otlphttp:
    endpoint: ${env:NEWRELIC_OTLP_ENDPOINT}
    headers:
      api-key: ${env:NEWRELIC_LICENSE_KEY}   
# -------------------------------------------------------------------------------------------------
# Service
# The service block defines the pipelines. Note the new 'logs' pipeline.
# -------------------------------------------------------------------------------------------------
service:
  pipelines:
    metrics/elasticsearch:
      receivers: [elasticsearch]
      processors: [resourcedetection, resource/cluster_name_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
      exporters: [otlphttp]
    metrics/host:
      receivers: [hostmetrics]
      processors: [resourcedetection,batch]
      exporters: [otlphttp]
    ```
  </Collapser>

  <Collapser id="secure-config" title="Authentication & SSL Configuration">
    **Use this if you have:** A secured Elasticsearch cluster with authentication and/or SSL certificates.

    Add authentication credentials and SSL configuration to the basic configuration above:
    

    ```yaml
    receivers:
      elasticsearch:
        endpoint: "https://localhost:9200"
        username: "elastic"
        password: "your_password"
        tls:
          ca_file: "/etc/elasticsearch/certs/http_ca.crt"
          insecure_skip_verify: false
        collection_interval: 15s
    ```
  </Collapser>

  <Collapser id="logging-config" title="Enable logs (filelog receiver)">
    **Optional:** Include this if you want to send Elasticsearch log files to New Relic in addition to metrics.

    Add the `filelog` receiver configuration to collect and forward Elasticsearch logs. Ensure the `otelcol-contrib` user has `read` access to the log files.

    ```yaml
    receivers:
      filelog:
        include:
          - /var/log/elasticsearch/elasticsearch.log
          - /var/log/elasticsearch/*.log
        start_at: beginning

    service:
      pipelines:
        logs:
          receivers: [filelog]
          processors: [resource/cluster_name_override]
          exporters: [otlphttp]
    ```

    Grant permission by adding the user to the group:
    ```bash
    sudo usermod -a -G elasticsearch otelcol-contrib
    ```
  </Collapser>

  <Collapser id="custom-attributes" title="Add custom metadata">
    **Optional:** Include this if you want to tag your data with custom attributes like environment, team, or region.

    Use the `resource/static_override` processor to add custom metadata tags to all your metrics:

    ```yaml
    processors:
      resource/static_override:
        attributes:
          - key: env
            value: "production"
            action: upsert
    service:
      pipelines:
        metrics/elasticsearch:
          receivers: [elasticsearch]
          processors: [resourcedetection, resource/cluster_name_override, resource/static_override, attributes/cardinality_reduction, cumulativetodelta, transform/metadata_nullify, batch]
          exporters: [otlphttp]
        metrics/host:
          receivers: [hostmetrics]
          processors: [resourcedetection, resource/static_override, batch]
          exporters: [otlphttp]        

    ```
  </Collapser>
</CollapserGroup>

## Step 3: Set environment variables [#start]

Configure authentication by adding your New Relic <InlinePopover type="licenseKey"/> and OTLP endpoint to the collector service.

1. Create a systemd override directory:
   ```bash
   sudo mkdir -p /etc/systemd/system/otelcol-contrib.service.d
   ```
2. Write `environment.conf` with your OTLP endpoint. Replace `YOUR_LICENSE_KEY` with the New Relic license key and `YOUR_OTLP_ENDPOINT` with the appropriate endpoint for your region. Refer to the OTLP endpoint configuration [documentation](https://docs.newrelic.com/docs/opentelemetry/best-practices/opentelemetry-otlp/#configure-endpoint-port-protocol) to select the right endpoint.

   ```bash
   cat <<EOF | sudo tee /etc/systemd/system/otelcol-contrib.service.d/environment.conf
   [Service]
   Environment="NEWRELIC_OTLP_ENDPOINT=YOUR_OTLP_ENDPOINT"
   Environment="NEWRELIC_LICENSE_KEY=YOUR_LICENSE_KEY"
   EOF
   ```
3. Reload systemd and restart the collector:
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl restart otelcol-contrib.service
   ```

## Step 4: View your Elasticsearch data [#find-and-use]

Once the collector is running and sending data, you can view your Elasticsearch metrics in New Relic:

1. Go to **[one.newrelic.com](https://one.newrelic.com) > Integrations & Agents**
2. Search for **Elasticsearch (OpenTelemetry)**
3. Under **Dashboards**, click **Elasticsearch OTEL Monitoring**
4. Select your account and click **View dashboard**

You should see dashboards showing cluster health, performance metrics, and resource usage.

<Callout variant="tip">
**Not seeing data?** It may take a few minutes for data to appear. If you don't see metrics after 10 minutes, check the [troubleshooting section](#troubleshooting) below.
</Callout>

**Next steps with your data:**
- **Explore metrics**: All Elasticsearch metrics are stored as `Metric` [event types](/docs/data-apis/understand-data/new-relic-data-types)
- **Create custom queries**: Use [NRQL](/docs/nrql/get-started/introduction-nrql-new-relics-query-language) to build custom charts and dashboards
- **Set up alerts**: Continue to Step 5 to configure proactive monitoring

## Step 5: Set up alerts [#alerts]

Proactive monitoring with alerts helps you catch issues before they impact your users. To create alert conditions in New Relic:

1. Open [one.newrelic.com > Alerts > Alert Conditions](https://onenr.io/01wZ8MEgZj6).
2. Click **Create condition**.
3. Configure the alert using either **Guided mode** or the **NRQL** query builder.

The alert configurations below are recommended for robust Elasticsearch monitoring:

<CollapserGroup>
  <Collapser id="recommended-alerts" title="Recommended Alert Conditions">
    <table>
      <thead>
        <tr>
          <th style={{ width: "250px" }}>Alert Name</th>
          <th>Threshold Rationale (Example Condition)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>**Unassigned Shards Alert**</td>
          <td>Metric `elasticsearch.cluster.shards` (where `state = 'unassigned'`) is above 0 for at least 5 minutes.</td>
        </tr>
        <tr>
          <td>**Healthy Data Nodes Alert**</td>
          <td>Metric `elasticsearch.cluster.data_nodes` is below your minimum required node count for at least 5 minutes.</td>
        </tr>
        <tr>
          <td>**Heap Usage Too High Alert**</td>
          <td>Heap usage percentage (Used/Max) is above 90% for at least 5 minutes.</td>
        </tr>
        <tr>
          <td>**Pending Tasks Alert**</td>
          <td>Metric `elasticsearch.cluster.pending_tasks` is above 5 for at least 5 minutes.</td>
        </tr>
        <tr>
          <td>**Query Time Slow Alert**</td>
          <td>95th percentile of `elasticsearch.node.operations.time` is above 5ms for at least 2 minutes.</td>
        </tr>
        <tr>
          <td>**Initializing Shards Too Long**</td>
          <td>Metric `elasticsearch.cluster.shards` (where `state = 'initializing'`) is above 0 for at least 5 minutes.</td>
        </tr>
        <tr>
          <td>**Relocating Shards Too Long**</td>
          <td>Metric `elasticsearch.cluster.shards` (where `state = 'relocating'`) is above 0 for at least 5 minutes.</td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## Troubleshoot the Elasticsearch OpenTelemetry integration [#troubleshooting]

If you have completed the installation but don't see data in New Relic, locate the symptom below to find the matching fix.

<CollapserGroup>

  <Collapser id="troubleshoot-collector-stopped" title="Collector service stopped or failed">
    <p><strong>How to check</strong></p>
    ```bash
    sudo systemctl status otelcol-contrib
    ```
    <p><strong>Resolution</strong></p>
    <ul>
      <li>If the service is inactive, start it: <InlineCode>sudo systemctl start otelcol-contrib</InlineCode></li>
      <li>If the service failed, fix configuration errors and restart: <InlineCode>sudo systemctl restart otelcol-contrib</InlineCode></li>
    </ul>
  </Collapser>

  <Collapser id="troubleshoot-collector-logs-errors" title="Collector logs report scraping or export errors">
    <p><strong>How to check</strong></p>
    ```bash
    sudo journalctl -u otelcol-contrib.service -f
    ```
    <p><strong>Resolution</strong></p>
    <p>Review the log output and resolve the root cause (for example, connection problems, authentication failures, or permission issues).</p>
  </Collapser>

  <Collapser id="troubleshoot-connection-refused" title="Connection refused when calling Elasticsearch">
    <p><strong>Error sample</strong>: <InlineCode>dial tcp [::1]:9200: connect: connection refused</InlineCode></p>
    <p><strong>Resolution</strong></p>
    <ul>
      <li>Ensure the <InlineCode>endpoint</InlineCode> in <InlineCode>config.yaml</InlineCode> matches the Elasticsearch host and port.</li>
      <li>Confirm Elasticsearch is running and reachable from the collector host.</li>
    </ul>
  </Collapser>

  <Collapser id="troubleshoot-403" title="403 Forbidden when exporting to New Relic">
    <p><strong>Error sample</strong>: <InlineCode>permanent error: 403 Forbidden</InlineCode></p>
    <p><strong>Resolution</strong></p>
    <ul>
      <li>Verify <InlineCode>NEWRELIC_LICENSE_KEY</InlineCode> in <InlineCode>/etc/systemd/system/otelcol-contrib.service.d/environment.conf</InlineCode>.</li>

      <li>Reload systemd and restart the collector:
      
        ```bash
        sudo systemctl daemon-reload
        sudo systemctl restart otelcol-contrib
        ```
      </li>
    </ul>
  </Collapser>

  <Collapser id="troubleshoot-permission-denied" title="Permission denied when collecting logs">
    <p><strong>Error sample</strong>: <InlineCode>permission denied</InlineCode> or <InlineCode>cannot open file</InlineCode></p>
    <p><strong>Resolution</strong></p>
    <ul>
      <li>Add the collector user to the Elasticsearch group:
        ```bash
        sudo usermod -a -G elasticsearch otelcol-contrib
        ```
      </li>
      <li>Restart the collector: <InlineCode>sudo systemctl restart otelcol-contrib</InlineCode></li>
    </ul>
  </Collapser>

  <Collapser id="troubleshoot-api-reachability" title="Cannot reach the Elasticsearch API from the collector">
    <p><strong>How to check</strong></p>
    ```bash
    # Unsecured cluster
    curl -I http://localhost:9200

    # With authentication
    curl -u username:password -k https://localhost:9200
    ```
    <p><strong>Resolution</strong></p>
    <p>Verify the cluster is healthy, credentials are valid, and firewall or security settings permit access.</p>
  </Collapser>

  <Collapser id="troubleshoot-missing-entity" title="Elasticsearch entity missing in New Relic UI">
    <p><strong>Resolution</strong></p>
    <ul>
      <li>Ensure the <InlineCode>resourcedetection</InlineCode> processor is included in every metrics pipeline.</li>
      <li>Verify <InlineCode>elasticsearch.cluster.name</InlineCode> is set via the <InlineCode>resource/cluster_name_override</InlineCode> processor.</li>
    </ul>
  </Collapser>

  <Collapser id="troubleshoot-logs-missing" title="Metrics present but logs missing">
    <p><strong>Resolution</strong></p>
    <ul>
      <li>Confirm <InlineCode>filelog</InlineCode> receiver paths are correct and absolute.</li>
      <li>Check that the logs pipeline includes both the <InlineCode>filelog</InlineCode> receiver and the <InlineCode>otlphttp</InlineCode> exporter.</li>
    </ul>
  </Collapser>

</CollapserGroup>

