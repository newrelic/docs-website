---
title: Filter Prometheus Metrics
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure Prometheus Configurator
metaDescription: Avoid exceeding New Relic's platform limits and increasing your billing charges by using the Prometheus Configurator's filtering capabilities.
---

Avoid sending Prometheus data that isn't relevant to your monitoring needs. Instead, use filters to ignore or include specific metrics, which helps you control the amount of data you send to New Relic and also avoid additional billing charges.

# Prevent billing increases [#rate-limits]

By default, we use the Prometheus `discovery` and `scrape` annotations, which scrape all the available targets and send all the data that's exposed from those targets. In consequence, you may exceed New Relic's platform limits and increase your billing charges. To help prevent this, use the integration's filtering capabilities.

For more information, see the Prometheus OpenMetrics integration requirements [TODO: Add requirementes](requirements). Also, see the [troubleshooting procedures](TODOL Add troubleshooting).

# Kubernetes target discovery [#k8-target-discovery]

Kubernetes jobs discover targets and scrape targets according to the `target_discovery` configuration. If you use the `pod` and `endpoints` labels, Prometheus creates rules to discover any pod or endpoints in the cluster having an exposed port.

Use the `target_discovery.filter` configuration parameter to filter in the targets that Prometheus scrapes. Use the `label` and `annotation` labels to filter by current conditions, and the `AND` operator for all conditions.

The following example only scrapes `Pods` and `Endpoints` with the `newrelic.io/scrape: true` annotation, and the `k8s.io/app` label with `postgres` or `mysql` as values. For the endpoints, the annotation must be present in the service related to it.

``` yaml
kubernetes:
  jobs:
  - job_name_prefix: example
    target_discovery:
      pod: true
      endpoints: true
      filter:
        annotation:
          # <string>: <regex>
          newrelic.io/scrape: 'true'
        label:
          # <string>: <regex>
          k8s.io/app: '(postgres|mysql)'
```

<Callout variant="tip">
  If you don't add a value for the label or annotation, the filter only checks what exists.
</Callout>

# Metric and label transformations [#metric-label-transformations]

They can be applied on two levels, at job (`static_targets` or `kubernetes`) or at remote write level. If you configure them at job level, the filtering only applies to the metrics of targets scraped by that job. If you apply them at `newrelic_remote_write` level, the filters apply to all metrics that are being sent to New Relic. The metric filter process happens after the metrics had been scraped from the targets.

You can use the `extra_metric_relabel_config` parameter to apply the filters, which adds entries of the [metric_relabel_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) parameter. This parameter is present at `static_targets.jobs`, `kubernetes.jobs`, and the `extra_write_relabel_configs` parameter for `newrelic_remote_write`.

Here's an example of how to use it in different parts of the YAML configuration file:
``` yaml
static_targets:
- name: self-metrics
  urls:
    - 'http://static-service:8181'
  extra_metric_relabel_config:
  # Drop metrics with prefix 'go_' for this target.
  - source_labels: [__name__]
    regex: 'go_.+'
    action: drop

newrelic_remote_write:
  extra_write_relabel_configs:
  # Drop all metrics with the specified name before sent to New Relic.
  - source_labels: [__name__]
    regex: 'metric_name'
    action: drop
```

# YAML file snippet samples [#config-samples]

Add one of these snippet examples in the YAML configuration file from the [metric and label transformations](#metric-label-transformations) section.

## To filter metrics [#drop-keep-metrics]

<CollapserGroup>
  <Collapser
    id="collapser-source"
    title="Filters out metrics whose name start with 'prefix_'"
  >
    ``` yaml
    - source_labels: [__name__]
      regex: 'prefix_.+'
      action: drop
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filters out metrics having a 'k8s.io/app=appLabelValue' Kubernetes label"
  >
    ``` yaml
    - source_labels: [k8s_io_app]
      regex: 'appLabelValue'
      action: drop
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filters out metrics whose name start with 'prefix_' and that have a 'k8s.io/app=appLabelValue' Kubernetes label"
  >
    ``` yaml
    - source_labels: [__name__,k8s_io_app]
      regex: 'prefix_.+;appLabelValue'
      action: drop
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filters out all metrics except the ones whose name start with 'prefix_'"
  >
    ``` yaml
    - source_labels: [__name__]
      regex: 'prefix_.+'
      action: keep
    ```
  </Collapser>
</CollapserGroup>

## To add or remove metric labels [#filter-metric-labels]

<Callout variant="important">
Metric Labels names must comply with [Prometheus DataModel](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels).
</Callout>

<CollapserGroup>
  <Collapser
    id="collapser-source"
    title="Add the 'new_label=newLabelValue' labels to metrics names starting with 'prefix_'"
  >
    ``` yaml
    - source_labels: [__name__]
      regex: 'prefix_.+'
      target_label: new_label
      action: replace
      replacement: newLabelValue
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filter out all metrics the label 'label_name'"
  >
  You can use it to reduce cardinality, but keep in mind that removing identifying labels may make it difficult to ensure proper metric aggregation.

    ``` yaml
    - regex: 'label_name'
      action: labeldrop
    ```
  </Collapser>
</CollapserGroup>
