---
title: "Set up New Relic's Prometheus Agent"
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure Prometheus Configurator
metaDescription: 'TODO'
---

<Callout variant="tip">
  The examples below goes in the `config` section for the agent. Refer to the [installation method](/docs/infrastructure/prometheus-integrations/install-configure-prometheus-agent/install-prometheus-agent) you used to known where you should place it.
</Callout>

# Prevent billing increases [#rate-limits]

Avoid sending Prometheus data that isn't relevant to your monitoring needs. Instead, use filters to ignore or include specific metrics, which helps you control the amount of data you send to New Relic and also avoid additional billing charges.

As explained in the [Installation guide](/docs/infrastructure/prometheus-integrations/install-configure-prometheus-agent/install-prometheus-agent), by default we set up the Prometheus Kubernetes discovery and scrape everything annotated with `prometheus.io/scrape: true`, and send all the data that's exposed from those discovered targets. In consequence, you may exceed New Relic's platform limits and increase your billing charges.

For more information, see the Prometheus Agent requirements [TODO: Add requirements](/requirements). Also, see the [troubleshooting procedures](/add_troubleshooting) TODO: Add troubleshooting .

## Target scrape interval [#target_scrape_interval]

By default, Prometheus Agent will scrape all targets for metrics every 30 seconds as defined at `common.scrape_interval` for all scraping jobs in the configuration. This can be overwritten by any `scrape_interval` is defined in that section.

The following example shows two Kubernetes jobs with different scrape intervals.
``` yaml
common:
  scrape_interval: 30s
kubernetes:
  jobs:
  # this job will use the default scrape_interval defined in common.
  - job_name_prefix: default-targets-with-30s-interval
    target_discovery:
      pod: true
      filter:
        annotation:
          newrelic.io/scrape: 'true'

  - job_name_prefix: slow-targets-with-60s-interval
    scrape_interval: 60s
    target_discovery:
      pod: true
      filter:
        annotation:
          newrelic.io/scrape_slow: 'true'
```

# Kubernetes target discovery [#k8-target-discovery]

Kubernetes jobs discover targets and scrape targets according to the `target_discovery` configuration. If inside the `target_discovery` configuration you set `pod` and `endpoints` toggles to `true`, Prometheus will create rules to discover any pod or endpoint in the cluster having an exposed port.

Use the `target_discovery.filter` configuration parameter to filter in the targets that Prometheus scrapes. Use the `label` and `annotation` labels to filter by current conditions, and the `AND` operator for all conditions.

The following example only scrapes `Pods` and `Endpoints` with the `newrelic.io/scrape: true` annotation, and the `k8s.io/app` label with `postgres` or `mysql` as values. For the endpoints, the annotation must be present in the service related to it.

```yaml
kubernetes:
  jobs:
  - job_name_prefix: example
    target_discovery:
      pod: true
      endpoints: true
      filter:
        annotation:
          # <string>: <regex>
          newrelic.io/scrape: 'true'
        label:
          # <string>: <regex>
          k8s.io/app: '(postgres|mysql)'
```

<Callout variant="tip">
  If you don't add a value for the label or annotation, the filter only checks what exists.
</Callout>

# Metric and label transformations [#metric-label-transformations]

They can be applied at any configuration section, like `static_targets`, `kubernetes`, or `newrelic_remote_write`, but set it at remote write level makes the filtering wider. If you set them at `newrelic_remote_write` level, the filters apply to all metrics that are being sent to New Relic while if you set them at any other section they apply to the metrics scraped by that section. The metric filter process happens after the metrics had been scraped from the targets.

You can use the `extra_metric_relabel_config` parameter to apply the filters, which adds entries of the [metric_relabel_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) parameter. This parameter is present at `static_targets.jobs`, `kubernetes.jobs`, and the `extra_write_relabel_configs` parameter for `newrelic_remote_write`.

Here's an example of how to use it in different parts of the YAML configuration file:
```yaml
static_targets:
- name: self-metrics
  urls:
    - 'http://static-service:8181'
  extra_metric_relabel_config:
  # Drop metrics with prefix 'go_' for this target.
  - source_labels: [__name__]
    regex: 'go_.+'
    action: drop

newrelic_remote_write:
  extra_write_relabel_configs:
  # Drop all metrics with the specified name before sent to New Relic.
  - source_labels: [__name__]
    regex: 'metric_name'
    action: drop
```

# YAML file snippet samples [#config-samples]

Add one of these snippet examples in the YAML configuration file from the [metric and label transformations](#metric-label-transformations) section.

## To filter metrics [#drop-keep-metrics]

<CollapserGroup>
  <Collapser
    id="collapser-source"
    title="Filters out metrics whose name start with 'prefix_'"
  >
    ```yaml
    - source_labels: [__name__]
    regex: 'prefix_.+'
    action: drop
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filters out metrics having a 'k8s.io/app=appLabelValue' Kubernetes label"
  >
    ```yaml
    - source_labels: [k8s_io_app]
    regex: 'appLabelValue'
    action: drop
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filters out metrics whose name start with 'prefix_' and that have a 'k8s.io/app=appLabelValue' Kubernetes label"
  >
    ```yaml
    - source_labels: [__name__,k8s_io_app]
    regex: 'prefix_.+;appLabelValue'
    action: drop
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filters out all metrics except the ones whose name start with 'prefix_'"
  >
    ```yaml
    - source_labels: [__name__]
    regex: 'prefix_.+'
    action: keep
    ```
  </Collapser>
</CollapserGroup>

## To add or remove metric labels [#filter-metric-labels]

<Callout variant="important">
  Metric Labels names must comply with [Prometheus DataModel](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels).
</Callout>

<CollapserGroup>
  <Collapser
    id="collapser-source"
    title="Add the 'new_label=newLabelValue' labels to metrics names starting with 'prefix_'"
  >
    ```yaml
    - source_labels: [__name__]
    regex: 'prefix_.+'
    target_label: new_label
    action: replace
    replacement: newLabelValue
    ```
  </Collapser>
  <Collapser
    id="collapser-source"
    title="Filter out all metrics the label 'label_name'"
  >
    You can use it to reduce cardinality, but keep in mind that removing identifying labels may make it difficult to ensure proper metric aggregation.

    ```yaml
    - regex: 'label_name'
    action: labeldrop
    ```
  </Collapser>
</CollapserGroup>

# Target authorization configuration [#target_authorization_configuration]

Some targets need Auth to be scraped, like No-SQL Databases to fetch data that the user connecting has access, or exporters that expose sensible data in their metrics endpoint. All authorization methods supported by Prometheus can be configured on `static_targets` and `kubernetes` sections.

As explained in the [Installation guide](/docs/infrastructure/prometheus-integrations/install-configure-prometheus-agent/install-prometheus-agent) we create a configuration for Prometheus based on our YAML. This part of the configuration passed to Prometheus as-is from our YAML, so you would refer to Prometheus documentation:
- [TLS](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#tls_config)
- [OAuth2](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#oauth2)
- [Authorization Header](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config)
- Basic Auth

Below there are some examples:
``` yaml
kubernetes:
  jobs:
  - job_name_prefix: skip-verify-on-https-targets
    target_discovery:
      pod: true
      filter:
        annotation:
          newrelic.io/scrape: 'true'
  - job_name_prefix: bearer-token
    target_discovery:
      pod: true
      filter:
        label:
          k8s.io/app: my-app-with-token
    authorization:
      type: Bearer
      credentials_file: '/etc/my-app/token'

startic_targets:
  jobs:
  - job_name: mtls-target
    scheme: https
    targets:
    - 'my-mtls-target:8181'
    tls_config:
      ca_file: '/etc/my-app/client-ca.crt'
      cert_file: '/etc/my-app/client.crt'
      key_file: '/etc/my-app/client.key'

  - job_name: basic-auth-target
    targets:
    - 'my-basic-auth-static:8181'
    basic_auth:
      password_file: '/etc/my-app/pass.htpasswd'
```
