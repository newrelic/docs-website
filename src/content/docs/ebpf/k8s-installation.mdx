---
title: "Install New Relic eBPF agent for Kubernetes"
metaDescription: "Learn how to install and configure the New Relic eBPF agent for your Kubernetes cluster using Helm charts."
tags:
    - New Relic integrations with eBPF
    - New Relic eBPF agent
    - eBPF integration
    - eAPM
    - Kubernetes cluster
    - New Relic eBPF agent for Kubernetes
redirects:
    - /docs/kubernetes-pixie/kubernetes-integration/installation/eapm
freshnessValidatedDate: never
---


You can install the New Relic eBPF agent on your Kubernetes cluster to monitor your entire system health. The eBPF agent provides deep visibility into application performance without requiring code changes or deploying language-specific agents.

## Install New Relic eBPF agent

<Steps>

<Step>

### Before you begin [#requirements]

You must meet the prerequisites outlined in the [eBPF compatibility and requirements](/docs/ebpf/requirements#k8s) documentation for Kubernetes clusters.

</Step>

<Step>


### Install the eBPF agent [#install]

To install the eBPF agent:

1. Log in to your New Relic account.
2. Go to **left navigation pane > + Integration & Agents > eBPF Agent**.
3. On the Select an account screen, select the account you want to install the eBPF agent on, and click **Continue**.
4. On the Select an installation method page, select **Kubernetes**, and click **Continue**.
5. On the Enter your user key screen, select one of the following options, then click **Continue**:

    * **Use an existing key**: If you already have a user key, provide the user key. For more information, refer to [User keys](/docs/apis/intro-apis/new-relic-api-keys/#user-key).
    * **Create a new key**: If you don't have a user key, click **Create a new key** to create one.

6. On the Configure the Kubernetes integration screen:
    
    1. Enter the deployment name for the Kubernetes.
    2. (Optional) Enter the namespace for the integration. The default namespace is `newrelic`.
    3. Click **Continue**.

    <Callout variant="tip">
    If you choose a custom namespace for your New Relic instrumentation (instead of the default `newrelic`), we recommend excluding that namespace from monitoring by adding it to the `dropDataForNamespaces` configuration parameter. This prevents the eBPF agent from monitoring the instrumentation pods themselves. For example, if you use `newrelic-mon` as your namespace, set: `dropDataForNamespaces: ["kube-system", "newrelic-mon"]`.
    </Callout>

7. On the Install the Kubernetes integration screen:

    1. Copy and paste the displayed command to install the eBPF agent on your Kubernetes cluster using Helm.
    2. *(Optional)* To download the `values.yaml` configuration file, click **Download**. For more on the configuration parameters, refer to [K8s configuration parameters](#config-params).
    3. *(Optional)* Update the `values.yaml` file as needed and save it.
    4. *(Optional)* To apply the configuration changes, run the following command:
    
        ```bash
            helm repo update ; helm upgrade --install nr-ebpf-agent newrelic/nr-ebpf-agent -n newrelic --values values.yaml
        ```
    5. To verify the installation, run the following command:

        ```bash
            kubectl get pods -n newrelic
        ```

</Step>

<Step>

### Access the eBPF data in New Relic [#access-data]

Once the eBPF agent is installed, it automatically starts collecting data from your Linux host. You can access this data in New Relic's OpenTelemetry UI. For more information on New Relic OpenTelemetry UI, refer [OpenTelemetry APM UI](/docs/opentelemetry/get-started/apm-monitoring/opentelemetry-apm-ui).

**To view the eBPF data in New Relic:**

1. Go to **[one.newrelic.com](https://one.newrelic.com) > APM & Services**.
2. In the search banner, set the search criteria as `instrumentation.name = nr_ebpf`:
    <img
        style={{ align: 'left' }}
        title="eBPF filters"
        alt="eBPF filter for eBPF data in New Relic OpenTelemetry UI"
        src="/images/ebpf_filters.webp"
    />

</Step>

</Steps>

{/* 
Once your app is instrumented and configured to export data to New Relic, you should be able to find your data in the New Relic UI:

    * Find your entity at <DNT>**All entities > Services - OpenTelemetry**</DNT>. The entity name is set to the value of the app's `service.name` resource attribute. For more information on how New Relic service entities are derived from OpenTelemetry resource attributes, see [Services](/docs/opentelemetry/best-practices/opentelemetry-best-practices-resources/#services).
    * Use [NRQL](/docs/nrql/get-started/introduction-nrql-new-relics-query-language/) to query directly for [traces](https://one.newrelic.com/launcher/nr1-core.explorer?overlay=eyJuZXJkbGV0SWQiOiJkYXRhLWV4cGxvcmF0aW9uLnF1ZXJ5LWJ1aWxkZXIiLCJpbml0aWFsQWN0aXZlSW50ZXJmYWNlIjoibnJxbEVkaXRvciIsImluaXRpYWxOcnFsVmFsdWUiOiIiLCJpbml0aWFsUXVlcmllcyI6W3sibnJxbCI6IkZST00gU3BhbiBTRUxFQ1QgY291bnQoKikgd2hlcmUgbmV3cmVsaWMuc291cmNlPSclb3RscCUnIFRJTUVTRVJJRVMifV0sImluaXRpYWxDaGFydFNldHRpbmdzIjp7ImNoYXJ0VHlwZSI6IkNIQVJUX0xJTkUiLCJsaW1pdCI6NzU0MiwibGlua2VkRW50aXR5R3VpZCI6bnVsbCwibGlua2VkRGFzaGJvYXJkSWQiOm51bGwsInlTY2FsZSI6eyJzdGF0aWMiOmZhbHNlLCJkb21haW4iOltudWxsLG51bGxdfSwieVplcm8iOnRydWV9fQo=), [metrics](https://one.newrelic.com/launcher/nr1-core.explorer?overlay=eyJuZXJkbGV0SWQiOiJkYXRhLWV4cGxvcmF0aW9uLnF1ZXJ5LWJ1aWxkZXIiLCJpbml0aWFsQWN0aXZlSW50ZXJmYWNlIjoibnJxbEVkaXRvciIsImluaXRpYWxOcnFsVmFsdWUiOiIiLCJpbml0aWFsUXVlcmllcyI6W3sibnJxbCI6IkZST00gTWV0cmljIFNFTEVDVCBjb3VudCgqKSB3aGVyZSBuZXdyZWxpYy5zb3VyY2UgTElLRSAnJW90bHAlJyBUSU1FU0VSSUVTIn1dLCJpbml0aWFsQ2hhcnRTZXR0aW5ncyI6eyJjaGFydFR5cGUiOiJDSEFSVF9MSU5FIiwibGltaXQiOjc1NDIsImxpbmtlZEVudGl0eUd1aWQiOm51bGwsImxpbmtlZERhc2hib2FyZElkIjpudWxsLCJ5U2NhbGUiOnsic3RhdGljIjpmYWxzZSwiZG9tYWluIjpbbnVsbCxudWxsXX0sInlaZXJvIjp0cnVlfX0K), and [logs](https://one.newrelic.com/launcher/nr1-core.explorer?overlay=eyJuZXJkbGV0SWQiOiJkYXRhLWV4cGxvcmF0aW9uLnF1ZXJ5LWJ1aWxkZXIiLCJpbml0aWFsQWN0aXZlSW50ZXJmYWNlIjoibnJxbEVkaXRvciIsImluaXRpYWxOcnFsVmFsdWUiOiIiLCJpbml0aWFsUXVlcmllcyI6W3sibnJxbCI6IkZST00gTG9nIFNFTEVDVCBjb3VudCgqKSB3aGVyZSBuZXdyZWxpYy5zb3VyY2U9JyVvdGxwJScgVElNRVNFUklFUyJ9XSwiaW5pdGlhbENoYXJ0U2V0dGluZ3MiOnsiY2hhcnRUeXBlIjoiQ0hBUlRfTElORSIsImxpbWl0Ijo3NTQyLCJsaW5rZWRFbnRpdHlHdWlkIjpudWxsLCJsaW5rZWREYXNoYm9hcmRJZCI6bnVsbCwieVNjYWxlIjp7InN0YXRpYyI6ZmFsc2UsImRvbWFpbiI6W251bGwsbnVsbF19LCJ5WmVybyI6dHJ1ZX19Cg==).
    * See [OpenTelemetry APM UI](/docs/opentelemetry/get-started/apm-monitoring/opentelemetry-apm-ui) for more information.

If you can't find your entity and don't see your data with NRQL, see [OTLP troubleshooting](/docs/opentelemetry/best-practices/opentelemetry-otlp-troubleshooting).
You can find the data collected by the eBPF agent in the New Relic Opentelementry UI.

 */}


## Upgrade the eBPF agent [#upgrade]

To upgrade the eBPF agent in a Kubernetes cluster:

* **For a standard upgrade**: Use the following Helm command to upgrade to the latest version:

```bash
KSM_IMAGE_VERSION="v2.13.0" && helm repo add newrelic https://helm-charts.newrelic.com && helm repo update && kubectl create namespace "newrelic" ; helm upgrade --install nr-ebpf-agent newrelic/nr-ebpf-agent --set licenseKey=<key> --set cluster="<cluster-name>" --namespace=newrelic
```

* **For a specific version upgrade:** To upgrade to a specific version, use the `--version` flag:

```bash
KSM_IMAGE_VERSION="v2.13.0" && helm repo add newrelic https://helm-charts.newrelic.com && helm repo update && kubectl create namespace "newrelic" ; helm upgrade --install nr-ebpf-agent newrelic/nr-ebpf-agent --set licenseKey=<key> --set cluster="<cluster-name>" --namespace=newrelic --version=0.2.5
```

Replace `<key>` with your New Relic license key and `<cluster-name>` with your cluster name.


## Configuration parameters [#config-params]

The [`values.yaml`](https://github.com/newrelic/helm-charts/blob/master/charts/nr-ebpf-agent/values.yaml) file contains the following configuration sections:

<CollapserGroup>

    <Collapser
        id="general-configuration"
        title="General configuration"
    >

These parameters control the core identity and data destination for the eBPF agent.

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`cluster`</td>
            <td>Specifies the name of your Kubernetes cluster. This field is mandatory.</td>
            <td>`String`</td>
            <td>`"production-cluster"`</td>
        </tr>
        <tr>
            <td>`licenseKey`</td>
            <td>Specifies your New Relic license key. Required if `customSecretName` is not used.</td>
            <td>`String`</td>
            <td>`"8356...FFFFNRAL"`</td>
        </tr>
        <tr>
            <td>`nrStaging`</td>
            <td>If `true`, sends data to New Relic's staging environment.</td>
            <td>`Boolean`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`customSecretName`</td>
            <td>Specifies the name of a Kubernetes secret that contains your license key. Use this to avoid providing the key directly.</td>
            <td>`String`</td>
            <td>`"newrelic-license-secret"`</td>
        </tr>
        <tr>
            <td>`customSecretLicenseKey`</td>
            <td>Specifies the key within the secret where the license key value is stored. Used with `customSecretName`.</td>
            <td>`String`</td>
            <td>`"license"`</td>
        </tr>
        <tr>
            <td>`region`</td>
            <td>Specifies your New Relic account region (`US` or `EU`). Required when using `customSecretName`.</td>
            <td>`String`</td>
            <td>`"US"`</td>
        </tr>
        <tr>
            <td>`proxy`</td>
            <td>Specifies the URL of a proxy server, including the port, to route all outgoing agent data through.</td>
            <td>`String`</td>
            <td>`"http://user:pass@host:port"`</td>
        </tr>
        <tr>
            <td>`logLevel`</td>
            <td>Defines the logging verbosity level for the agent. Valid options: `OFF`, `FATAL`, `ERROR`, `WARNING`, `INFO`, `DEBUG`.</td>
            <td>`String`</td>
            <td>`"INFO"`</td>
        </tr>
        <tr>
            <td>`logFilePath`</td>
            <td>Specifies a file path inside the agent container for log output. If the path is invalid, logs are directed to stdout.</td>
            <td>`String`</td>
            <td>`"/var/log/nr-ebpf-agent.log"`</td>
        </tr>
        <tr>
            <td>`downloadedPackagedHeadersPath`</td>
            <td>Sets the absolute path of the complete directory where the required linux headers are manually downloaded and placed for the eBPF agent to use. This is useful under restricted environments where agent is not able to download required linux headers. The required headers are identified by the agent based on the kernel version. The absolute path in case of K8s should also be prepended with /host when necessary. Use only after NR support recommendation.</td>
            <td>`String`</td>
            <td>`"/path/to/downloaded/headers/dir"`</td>
        </tr>
        <tr>
            <td>`distroKernelHeadersPath`</td>
            <td>Sets the absolute path of the complete directory where the linux headers are present for the eBPF agent to use. This is useful where required linux headers could not be installed or path could not be determined. The absolute path in case of K8s should also be prepended with /host when necessary. Use only after NR support recommendation.</td>
            <td>`String`</td>
            <td>`"/host/usr/src/linux-headers-6.8.0-pl"`</td>
        </tr>
        <tr>
            <td>`vizierPort`</td>
            <td>Vizier server port on which agent receives pxl scripts from the client. Default to 12345</td>
            <td>`String`</td>
            <td>`"12345"`</td>
        </tr>
        <tr>
            <td>`tableStoreDataLimitMB`</td>
            <td>Defines the memory limit in Megabytes (MiB) for the agent's internal data store. This is the primary control for RAM usage.</td>
            <td>`String`</td>
            <td>`"500"`</td>
        </tr>
        <tr>
            <td>`apmDataReporting`</td>
            <td>Enable APM data reporting. When enabled, the agent collects and reports application performance monitoring data.</td>
            <td>`String`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`networkMetricsReporting`</td>
            <td>Enable network metrics reporting. When enabled, the agent collects and reports network metrics including TCP statistics. It is renamed from `tcpStatsReporting`. The old name is deprecated however backward compatibility is supported.</td>
            <td>`String`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`tcpStatsReporting(DEPRECATED)`</td>
            <td>Enable TCP statistics reporting. When enabled, the agent collects and reports low level tcp metrics and starts network monitoring.</td>
            <td>`String`</td>
            <td>`true`</td>
        </tr>
    </tbody>
</table>

</Collapser>


    <Collapser
        id="all-data-filters"
        title="All data filters"
    >

This section configure filters to drop all types of Network Metrics and APM data based on provided configuration.

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`allDataFilters.dropNewRelicBundle`</td>
            <td>Drop data from the newrelic namespace and newrelic-bundle services. (RENAMED from `dropDataNewRelic` for clarity. The old name is deprecated but still supported for backward compatibility).</td>
            <td>`Boolean`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`allDataFilters.dropNamespaces`</td>
            <td>List of Kubernetes namespaces for which all data should be dropped by the agent. (RENAMED from `dropDataForNamespaces` for clarity. The old name is deprecated but still supported for backward compatibility).</td>
            <td>`List`</td>
            <td>`["kube-system"]`</td>
        </tr>
        <tr>
            <td>`allDataFilters.dropServiceNameRegex`</td>
            <td>Define a regex to match k8s service names to drop. Example `"kube-dns|otel-collector|\\bblah\\b"`(RENAMED from `dropServiceNameRegex` for clarity. The old name is deprecated but still supported for backward compatibility).</td>
            <td>`String`</td>
            <td>`""`</td>
        </tr>
        <tr>
            <td>`allDataFilters.keepServiceNameRegex`</td>
            <td>This config acts as a bypass for the `dropServiceNameRegex` config. Service names that match this regex will not have their data dropped by the `dropServiceNameRegex`. (RENAMED from `allowServiceNameRegex` for clarity. The old name is deprecated but still supported for backward compatibility).</td>
            <td>`String`</td>
            <td>`""`</td>
        </tr>
        <tr>
            <td>`allDataFilters.dropApmAgentEnabledEntity`</td>
            <td>Drop all data for applications or entities that have NewRelic or OTEL APM agents running.</td>
            <td>`Boolean`</td>
            <td>`"false"`</td>
        </tr>
    </tbody>
</table>

</Collapser>


    <Collapser
        id="apm-data-filters"
        title="APM data filters"
    >

Configure filters to drop ebpf APM data based on config provided

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`apmDataFilters.apmAgentEnabledEntity`</td>
            <td> Drop eBPF APM data for applications/entities that have NewRelic APM/OTel agents running.</td>
            <td>`Boolean`</td>
            <td>`false`</td>
        </tr>
        <tr>
            <td>`apmDataFilters.dropPodLabels`</td>
            <td>Pod labels to match for filtering APM data. Empty map means no label-based filtering. (Example: dropPodLabels: `{ "app": "frontend", "env": "production" }`)</td>
            <td>`String`</td>
            <td>`{}`</td>
        </tr>
        <tr>
            <td>`apmDataFilters.dropEntityName`</td>
            <td>List of entity names to drop ebpf APM data</td>
            <td>`List`</td>
            <td>`[]`</td>
        </tr>
        <tr>
            <td>`apmDataFilters.keepEntityName`</td>
            <td>List of entity names to always keep APM data. By default all entities are kept/enabled. This config bypasses `dropEntityName` filter.</td>
            <td>`List`</td>
            <td>`[]`</td>
        </tr>
    </tbody>
</table>

</Collapser>


    <Collapser
        id="network-metric-data-filters"
        title="Network metrics data filters"
    >

Configure filters to drop/keep Network metrics data based on config provided

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`networkMetricsDataFilter.dropPodLabels`</td>
            <td>Pod labels to match for filtering Network metrics data. Empty map means no label-based filtering. (Example: dropPodLabels: `{ "app": "frontend", "env": "production" }`)</td>
            <td>`String`</td>
            <td>`{}`</td>
        </tr>
        <tr>
            <td>`networkMetricsDataFilter.dropEntityName`</td>
            <td>List of entity names to drop Network metrics data for</td>
            <td>`List`</td>
            <td>`[]`</td>
        </tr>
        <tr>
            <td>`networkMetricsDataFilter.keepEntityName`</td>
            <td>List of entity names to always keep Network metrics data. By default all entities are kept/enabled. This config bypasses `dropEntityName` filter.</td>
            <td>`List`</td>
            <td>`[]`</td>
        </tr>
    </tbody>
</table>

</Collapser>

    <Collapser
        id="protocol-tracing"
        title="Protocol tracing configuration"
    >


This section allows you to enable monitoring for specific network protocols and configure how trace data (spans) is collected. You can enable or disable monitoring for protocols like HTTP, MySQL, and others, and set parameters for span collection based on latency or error rates. The following protocols are supported:

* HTTP
* MySQL
* PostgreSQL
* MongoDB
* Apache Cassandra
* Redis
* Kafka
* DNS


<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`protocols.<protocol-name>.enabled`</td>
            <td>If `true`, enables monitoring for the specified protocol for example, `http`, `mysql`, and any others.</td>
            <td>`Boolean`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`protocols.<protocol-name>.spans.enabled`</td>
            <td>If `true`, exports trace spans for the enabled protocol.</td>
            <td>``Boolean``</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`protocols.<protocol-name>.spans.samplingLatency`</td>
            <td>Defines the latency-based sampling threshold for exporting spans. Valid options: `p1`, `p10`, `p50`, `p90`, `p99`.</td>
            <td>`String`</td>
            <td>`"p90"`</td>
        </tr>
        <tr>
            <td>`protocols.http.spans.samplingErrorRate`</td>
            <td>For HTTP only. Exports spans from any route where the error rate exceeds the specified percentage (1-100).</td>
            <td>`String`</td>
            <td>`"5"`</td>
        </tr>
    </tbody>
</table>

</Collapser>

    <Collapser
        id="daemonset-configs"
        title="DaemonSet configurations"
    >


These sections control the deployment settings for the solution's main components. An asterisk `(*)` denotes the component name.

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`*.image.repository`</td>
            <td>Specifies the container image repository for the component.</td>
            <td>`String`</td>
            <td>`"docker.io/newrelic/newrelic-ebpf-agent"`</td>
        </tr>
        <tr>
            <td>`*.image.pullPolicy`</td>
            <td>Defines the pull policy for the container image.</td>
            <td>`String`</td>
            <td>`"IfNotPresent"`</td>
        </tr>
        <tr>
            <td>`*.image.tag`</td>
            <td>Specifies the version tag of the container image to deploy.</td>
            <td>`String`</td>
            <td>`"agent-0.2.4"`</td>
        </tr>
        <tr>
            <td>`*.resources.limits.memory`</td>
            <td>Defines the maximum memory the container can use.</td>
            <td>`String`</td>
            <td>`"2Gi"`</td>
        </tr>
        <tr>
            <td>`*.resources.limits.cpu`</td>
            <td>Defines the maximum CPU the container can use.</td>
            <td>`String`</td>
            <td>`"1"`</td>
        </tr>
        <tr>
            <td>`*.resources.requests.memory`</td>
            <td>Defines the minimum memory requested for the container at startup.</td>
            <td>`String`</td>
            <td>`"250Mi"`</td>
        </tr>
        <tr>
            <td>`*.resources.requests.cpu`</td>
            <td>Defines the minimum CPU requested for the container at startup.</td>
            <td>`String`</td>
            <td>`"100m"`</td>
        </tr>
        <tr>
            <td>`*.tolerations`</td>
            <td>Defines pod tolerations to allow scheduling on nodes with specific taints.</td>
            <td>`Objects`</td>
            <td>`[{"key": "special", "operator": "Exists"}]`</td>
        </tr>
        <tr>
            <td>`*.affinity`</td>
            <td>Defines pod affinity and anti-affinity rules for scheduling.</td>
            <td>`Object`</td>
            <td>`{}`</td>
        </tr>
        <tr>
            <td>`*.podAnnotations`</td>
            <td>Specifies custom annotations to add to the component's pod.</td>
            <td>`Object`</td>
            <td>`{"iam.amazonaws.com/role": "my-role"}`</td>
        </tr>
    </tbody>
</table>


</Collapser>

    <Collapser
        id="global-pod-scheduling"
        title="Global pod and scheduling configuration"
    >

These parameters apply to all pods deployed by the Helm chart, unless overridden by a component-specific setting.

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`podLabels`</td>
            <td>Specifies additional labels to apply to all pods deployed by the chart.</td>
            <td>`Object`</td>
            <td>`{"team": "observability"}`</td>
        </tr>
        <tr>
            <td>`priorityClassName`</td>
            <td>Specifies the `PriorityClass` for all pods.</td>
            <td>`String`</td>
            <td>`"high-priority"`</td>
        </tr>
        <tr>
            <td>`nodeSelector`</td>
            <td>Constrains pods to only run on nodes with matching labels.</td>
            <td>`Object`</td>
            <td>`{"disktype": "ssd"}`</td>
        </tr>
    </tbody>
</table>

</Collapser>

    <Collapser
        id="tls-configuration"
        title="TLS Configuration"
    >

This section configures secure communication between the eBPF agent and client components.

<table>
    <thead>
        <tr>
            <th>Parameter</th>
            <th>Description</th>
            <th>Data Type</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>`tls.enabled`</td>
            <td>If `true`, enables TLS for internal communication between components.</td>
            <td>`Boolean`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`tls.autoGenerateCert.enabled`</td>
            <td>If `true`, directs Helm to automatically generate a self-signed certificate for TLS.</td>
            <td>`Boolean`</td>
            <td>`true`</td>
        </tr>
        <tr>
            <td>`tls.autoGenerateCert.recreate`</td>
            <td>If `true`, a new certificate is generated on every `helm upgrade`.</td>
            <td>`Boolean`</td>
            <td>`false`</td>
        </tr>
        <tr>
            <td>`tls.autoGenerateCert.certPeriodDays`</td>
            <td>Defines the validity period in days for the auto-generated certificate.</td>
            <td>`Integer`</td>
            <td>`730`</td>
        </tr>
        <tr>
            <td>`tls.certFile`</td>
            <td>Specifies the path to your custom PEM-encoded certificate file. `autoGenerateCert.enabled` must be `false`.</td>
            <td>`String`</td>
            <td>`"my-certs/tls.crt"`</td>
        </tr>
        <tr>
            <td>`tls.keyFile`</td>
            <td>Specifies the path to your custom PEM-encoded private key file.</td>
            <td>`String`</td>
            <td>`"my-certs/tls.key"`</td>
        </tr>
        <tr>
            <td>`tls.caFile`</td>
            <td>Specifies the path to your custom Certificate Authority (CA) certificate file.</td>
            <td>`String`</td>
            <td>`"my-certs/ca.crt"`</td>
        </tr>
    </tbody>
</table>

</Collapser>

</CollapserGroup>





## Uninstall the eBPF agent [#uninstall]

To uninstall the eBPF agent from your Kubernetes cluster:

```bash
helm uninstall nr-ebpf-agent -n newrelic
```

<Callout variant="tip">
This command will remove all eBPF agent components from your cluster. The namespace will remain unless you explicitly delete it.
</Callout>


<DocTiles>
    <DocTile title="eBPF Linux installation" path="/docs/ebpf/linux-installation/">Learn how to set up the New Relic eBPF agent for your Linux host.</DocTile>
    <DocTile title="Troubleshooting eBPF" path="/docs/ebpf/troubleshooting/no-ui-data/">Learn how to troubleshoot issues with the New Relic eBPF agent.</DocTile>
    <DocTile title="eBPF best practices" path="/docs/ebpf/best-practices/">Learn about best practices for using the New Relic eBPF agent.</DocTile>
</DocTiles>